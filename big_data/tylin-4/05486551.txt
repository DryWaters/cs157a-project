An Internet Traf田 Analysis Method with MapReduce Youngseok Lee Chungnam National University Daejeon 305-764 Republic of Korea lee@cnu.ac.kr Wonchul Kang Chungnam National University Daejeon 305-764 Republic of Korea teshi85@cnu.ac.kr Hyeongu Son Chungnam National University Daejeon 305-764 Republic of Korea hgson@cnu.ac.kr Abstract Internet traf田 measurement and analysis have been usually performed on a high performance server that collects and examines packet or ow traces However when we monitor a large volume of traf田 data for detailed statistics a longperiod or a large-scale network it is not easy to handle Tera or Peta-byte traf田 data with a single server Common ways to reduce a large volume of continuously monitored traf田 data are packet sampling or ow aggregation that results in coarse traf田 statistics As distributed parallel processing schemes have been recently developed due to the cloud computing platform and the cluster lesystem they could be usefully applied to analyzing big traf田 data Thus in this paper we propose an Internet ow analysis method based on the MapReduce software framework of the cloud computing platform for a large-scale network From the experiments with an open-source MapReduce system Hadoop we have veri兎d that the MapReduce-based ow analysis method improves the ow statistics computation time by 72 when compared with the popular ow data processing tool ow-tools on a single host In addition we showed that MapReduce-based programs complete the ow analysis job against a single node failure Keywords MapReduce Hadoop cloud computing NetFlow traf田 monitoring I I NTRODUCTION In Internet traf田 measurement and analysis ow-based traf田 monitoring methods are widely deployed throughout Internet Service Providers ISPs because the volume of processed data is reduced and many convenient ow statistics tools are available Cisco NetFlow is the popular o w monitoring format with which we could easily monitor ows passing through routers or switches without observing every packet Though routers or switches do not support NetFlow we could use NetFlow-compatible ow generators such as nProbe to monitor pack et streams in o w units Based on Cisco NetFlow v9 IETF standardizes the ow-based traf田 monitoring method at the IP Flow Information eXport IPFIX  w orking group As netw orks gro w and e v olv e we ha v e to manage and monitor more and more switches and routers for security traf田 engineering Quality of Service QoS and accounting reasons Generally Internet traf田 measurement and analysis are executed on a high performance central server Popular tools such as or Coralreef 5 are usually run on a single host to capture and process packets at a speci田 monitoring point Flow analysis tools such as ow-tools or o wscan  are widely used to generate traf c statistics with NetFlo w data Typically ISPs employ a high-performance server with a large storage system to collect and analyze ow data from many routers However when we anatomize traf田 in a largescale network we are often confronted with hard challenges of handling a huge amount of traf田 data for processing and management For example when ISPs monitor traf田 in a nation-wide network consisting of hundreds or thousands of routers capable of exporting Cisco NetFlow data it is not easy to compute traf田 statistics from many large ow les in short time In order to lessen the volume of continuously streaming ow data we normally use packet sampling or ow aggregation techniques Otherwise after processing packet traces we leave only the statistics information results When we analyze ow data for a large-scale network we need to handle and manage a few Tera or Peta-byte packet or ow les simultaneously When the outbreak of global Internet worms or DDoS attacks happens we also have to process fast a large volume of ow data at once Yet with a single-server approach we are not able to cope ef田iently and quickly with a large measurement data for scalable storage and analysis From recent developments of cluster lesystems and cloud computing platforms we could bene鍍 two features distributed parallel computing and fault tolerance Google Yahoo Amazon and Facebook are rigorously developing or making use of cluster lesystems and cloud computing platforms Google has rst developed the MapReduce programming model for page ranking or web log analysis MapReduce is a software framework that supports distributed computing with two functions of map and reduce on large data sets on clusters Google operates thousands of machines for MapReduce to process large web data sets After Google announced the MapReduce model Yahoo has released an open-source system for the cloud computing platform called Hadoop which could process easily v ery lar ge les with streaming access patterns Amazon provides the Hadoop-based cloud computing service such as Elastic Compute Cloud EC2 or Simple Storage Service S3 Facebook also uses Hadoop to analyze the web log data for its social network service On the other hand cloud computing on cluster lesystems provides easy fault-tolerant services for managing a huge amount of large les Moreover we could build the Hadoopbased large ow analysis system inexpensively with the commodity hardware Hence it is useful to apply distributed 357 978-1-4244-6039-7/10/$26.00 c  2010 IEEE 


parallel computing environments of cluster lesystems and cloud computing systems to the large-scale Internet traf田 measurement and analysis application In this paper we propose an Internet ow analysis method on the cloud computing platform Speci田ally we present a MapReduce-based ow analysis scheme that could easily process Tera or Peta-byte ow les collected from many routers or monitoring servers From experiments on our testbed with four Hadoop data nodes we achieved that ow statistics computation time for large ow les could dramatically decrease when compared with a popular ow analysis tool run on a single host In addition we showed that the MapReducebased ow analysis program nishes successfully against a single-machine failure The remainder of this paper is organized as follows In Section 2 we describe the related work Our MapReducebased ow analysis method is explained in Section 3 and its experimental results are presented in Section 4 Finally Section 5 concludes this paper II R ELATED W ORK Flow analysis tools such as ow-tools owscan or CoralReef are popular and widely used for generating ow statistics such as port or protocol breakdown because the port-based traf田 classi田ation method is reasonable for well-known Internet applications as shown in These o w monitoring tools are usually run on a single server with a large storage system such as RAID or Network Attached Storage NAS To reduce a large volume of observed ow data these tools often aggregate ows or save only ow statistics after analyzing ow les Yet with these tools it is not easy to process quickly a few Tera or Peta-byte ow data in a parallel or distributed way For analyzing traf田 by parallel processing several solutions have been proposed Among them DIPStorage uses a P2P platform called storage tanks to process ow data in a parallel way However each storage tank associated with a speci田 ow processing rule might be increasing the computation overhead Recently many MapReduce programs have been developed by Google Yahoo Amazon etc to analyze big data of web search documents text les or web log Chen et al developed a snort log data analysis method with Hadoop 13 for a large-scale network security application Hive and HBase  are often used with Hadoop for easy management of big data To the best of our knowledge however our work is the rst study to propose an Internet-scale ow analysis method with MapReduce III M AP R EDUCE BASED F LOW A NALYSIS A Overview Figure 1 shows the architecture of our ow measurement and analysis system The cloud platform provides the cluster lesystem and the cloud computing functions Flow data from routers are delivered to the cluster through unicasting or anycasting Cluster nodes are operated by a master node to       Fig 1 Architecture of the proposed ow measurement and analysis system save and process ow data as well as to manage the cluster con堵uration When ow data are archived on the cluster lesystem the MapReduce ow analysis program is run on the cloud platform           Fig 2 Functional components of a cluster node Each cluster node is equipped with a ow collector a distributed cluster lesystem and a MapReduce library as shown in Fig 2 A ow collector receives ow packets stores them to les and moves ow les at local disk to the cluster lesystem NetFlow packets from routers or monitoring servers are usually sent to cluster nodes in unicast Since NetFlow packets are delivered in UDP it does not guarantee the reliability In IPFIX we could use SCTP instead of UDP for reliability Anycasting could be used like DNS to provide load balancing with the cluster nodes when receiving NetFlow packets Then ow data are saved into les associated with each ow-exporting router periodically e.g ve minutes which will be uploaded to the cluster lesystem For the ow collector we use ow-tools for the NetFlow collecting and processing tool Mapper and Reducer will analyze ow data with Hadoop MapReduce library To meet the customized purpose of ow analysis we could implement appropriate Mapper and Reducer programs The distributed lesystem provides easy management of very large les as well as fault358 2010 IEEE/IFIP Network Operations and Management Symposium Workshops 


TABLE I I NPUT FILES Duration Flow count Flow le count Total binary le size Total text le size million GB GB 1 day 3.2 228 0.2 1.2 1 week 19.0 1596 0.3 2.3 1 month 109.1 7068 2.0 13.1 tolerant service For our cloud computing platform we employ Hadoop that provides open MapReduce software framework and cluster le system on the Java virtual machine VM HDFS is suitable for handling very large les with the streaming data access pattern that is a write-once and read-manytimes pattern In HDFS a name node operates management of the lesystem metadata and provides management and control services while a data node supplies block storage and retrieval services A name node at the master will perform recovery and automatic backup of name nodes The block size 64 MB by default and the number of replicated blocks in HDFS could be recon堵ured according to the fault-tolerance policy B Flow Analysis Method with MapReduce In the MapReduce programming model the computation takes a set of input key/value pairs and produces a set of output key/value pairs Map and Reduce are two basic functions in the MapReduce computation Users write Map that takes an input pair and produces intermediate key/value pairs The Hadoop MapReduce library will group the intermediate values according to the same key Reduce that is also written by users will merge the intermediate values for smaller values                       Fig 3 A MapReduce ow analysis program for destination port breakdown To implement various ow analysis programs with MapReduce we have to determine appropriate input key/value pairs for each analysis program For example when we analyze traf田 by port breakdown which sums up the octet count for the port number the key/value pair will be port octet In this work we have written a simple port-breakdown program for the performance evaluation With MapReduce accordingly we could realize typical ow analysis functions provided by well-known Internet traf田 statistics programs Figure 3 shows the procedure of the MapReduce-based program that performs port-breakdown analysis of ow data 1 Input ow les At rst after storing ow data from ow probes on the local disk we move the raw NetFlow v5 les to the cluster lesystem HDFS As the current Hadoop mapper supports only text les for the input format we convert NetFlow les to text-format ones As the size of text-format ow les is much larger than that of binary-format ones we need to support binary ow les to the inputs for Mapper Otherwise the gzipcompressed text ow les could be used for the input format 2 Mapper Our ow mapper reads each ow record split by new lines A ow record has attributes of timestamp IP addresses port protocol ag octet count packet count and interface numbers Though we use only the NetFlow v5 ow format in this work we could extend the supported ow format to NetFlow v9 or IPFIX After reading a ow record we lter out necessary ow attributes for a ow analysis job As shown in Fig 3 when the ow analysis job sums up octet counts per destination port number we set key/value pairs as dst port octets The ow map task will write its temporary results on the local disk 3 Reducer The ow reducer will be called with the inputs as the intermediate values generated by ow mappers As in the port-breakdown example a value list of octets belonging to the same destination port number will be summed up After merging octet values associated with the destination port the ow reducer writes the octet value for each port number IV P ERFORMANCE E VALUATION A Experimental environment For the performance evaluation of ow analysis with MapReduce we built up a small Hadoop testbed consisting of a master node and four data nodes Each node has quadcore 2.83 GHz CPU 4 GB memory and 1.5 TB hard disk HDFS is used for the cluster lesystem All Hadoop nodes are connected with 1 Gigabit Ethernet cards With ow-tools we collected NetFlow v5 packets sent by a ow generation tool nProbe that exports ow data for a Gigabit Ethernet link in our campus network Then we saved exported ows on a le every ve minutes As we captured ow data on a small network of a 24 pre度 subnet a veminute ow le is not enough to assess the performance of MapReduce Thus to evaluate the ow statistics computation 2010 IEEE/IFIP Network Operations and Management Symposium Workshops 359 


time for large data sets we used input ow les collected for one day one week and one month in Table I One-day ow les include about 3.2 million ow records one-week ow les 19.0 million and one-month ow les 108.1 million The binary ow les are used inputs to ow-tools whereas the text ow les to our MapReduce program B Flow statistics computation time   0   0.5   1   1.5   2   2.5   3   3.5   4   4.5   5   108.1   80   60   40   19.0   3.2 Time \(hour Number of flows  million  Port-break Computation Time flow-tools MR\(1   MR\(2   MR\(3   MR\(4   Fig 4 Destination port breakdown completion time:俳w-tools vs MapReduce We compare the popular ow statistics program owtools on a single server with our ow MapReduce program in Fig 4 The purpose of tested programs is to compute the octet count for each destination port number We ran  flow-cat flowdirectory  flow-stat f 5  result  commands of ow-tools to concatenate binary ow les stored in a directory and to calculate the ow statistics for the destination port Our MapReduce program reads text ow les and produces the octet count for each destination port To observe the impacts of the number of data nodes on the performance of the MapReduce program we carried out the experiments with 1 2 3 and 4 data nodes As shown in Fig 4 the port-breakdown computation time of ow-tools increases linearly as the number of input ows grows whereas that of MapReduce does not quickly build up With a single Hadoop data node MR\(1 the MapReduce program for the input les of 3.2 million and 19.0 million ow records does not outperform ow-tools However when we tested the MapReduce program with two or more Hadoop data nodes MR\(2 MR\(3 and MR\(4 we obtained that MapReduce reduces dramatically the ow computation time for all input les Given the input les of 108.1 million ow records it took 4.5 hours for ow-tools to complete the job whereas only 1.25 hours for MapReduce with four Hadoop data nodes MR\(4 The ow statistics computation time of MR\(4 has decreased by 72 for 108.1 million ow records From the experiments we could verify that the MapReduce ow analysis method computes ef田iently ow statistics for a big data set which will be scalable in a large-scale network C Recovery of a single node failure As processes or machines often fail because of software or hardware malfunctions we need to provide a fault-tolerant ow analysis method against failures to the cloud computing platform Among several failure scenarios we have experimented two fault recovery cases for 3.2 million ows as shown in Fig 5 and Fig 6 where a single Hadoop data node fails when either a Map or Reduce task is in progress First Fig 5 depicts how the Map task is recovered after a node among four Hadoop data nodes running Map tasks is forced to reboot A Hadoop data node fails at 4 seconds when the completion percentage of Map tasks is only 9 Thus the Map task is reexecuted at 266 seconds when it nds that the intermediatelymapped results are not complete even though it has already reached 100 Second we can observe that the Reduce task is recovered at 320 seconds after a Hadoop node running Reduce tasks is shutdown at 29 seconds as shown in Fig 6 When a failure occurs it takes longer time for MapReduce to complete the task as given in Table II Under a large data set of 108.2 million ows however MapReduce with four data nodes spent only 1.5 times more seconds to complete the job by recovering Map/Reduce failures Through experiments we have veri兎d that the ow computation job could successfully nish against a single node failure through the Hadoop fault-tolerant service 0 20 40 60 80 100 0 100 200 300 400 500 Task Completion Percentage Time sec When Map Fails Map Node Fails Recovery Begins Map Reduce      Fig 5 MapReduce failure recovery when Map fails 0 20 40 60 80 100 0 100 200 300 400 500 Task Completion Percentage Time sec When Reduce Fails Reduce Node Fails Recovery Begins Map Reduce      Fig 6 MapReduce failure recovery when Reduce fails 360 2010 IEEE/IFIP Network Operations and Management Symposium Workshops 


TABLE II T ASK COMPLETION TIME WITH OR WITHOUT A SINGLE NODE FAILURE  Flow counts Time of MR\(4 Time of MR\(4 with failure seconds seconds 3.2 M 220.2 380.2 19.0 M 2096.7 2588.5 108.2 M 4549.1 6754.4 V C ONCLUSION In this paper we presented a MapReduce-based ow analysis method for a large-scale networks that could analyze ef田iently and quickly big ow data against failures On the Hadoop system we have evaluated the performance of the MapReduce-based ow analysis method by developing a portbreakdown program From the experiments with four Hadoop data nodes we achieved that ow computation time could be dramatically improved by 72 compared with the typical ow analysis tools In addition we showed that the faulttolerant service against a single machine failure could be easily provided by MapReduce-based ow analysis Though our MapReduce-based ow analysis scheme outperforms the legacy single-host tools we need to improve a few drawbacks of the current MapReduce-based approach such as batch processing jobs or text input le formats and to develop convenient ow analysis tools based on MapReduce A CKNOWLEDGMENT This work was partly supported by the MKE\(Ministry of Knowledge Economy Korea under the ITRC\(Information Technology Research Center support program supervised by the NIPA\(National IT Industry Promotion Agency NIPA2010-\(C1090-0902-0016 and partly by the IT R&D program of MKE/KEIT KI001878 CASFI\(Collect Analyze and Share for Future Internet High-Precision Measurement and Analysis R EFERENCES  Cisco NetFlo w  http://www cisco.com/web/go/net俳 w   L Deri nProbe an Open Source NetFlow Probe for Gigabit Networks  TERENA Networking Conference May 2003  J Quittek T  Zseby  B  Claise and S Zander  Requirements for IP Flow Information Export IPFIX  IETF RFC 3917 October 2004  tcpdump http://www tcpdump.or g  CAID A CoralReef Softw are Suite http://www caida.or g/tools/measurement/co alreef  M Fullmer and S Romig The OSU Flow-tools Package and Cisco NetFlow Logs  USENIX LISA 2000  D Plonka FlowScan a Network Traf田 Flow Reporting and Visualizing Tool  USENIX Conference on System Administration 2000  J Dean and S Ghema w at MapReduce Simpli兎d Data Processing on Large Cluster  OSDI 2004  Hadoop http://hadoop.apache.or g  H Kim K Claf fy  M  F omenk o v  D  Barman M F aloutsos and K Lee Internet Traf田 Classi田ation Demysti兎d Myths Caveats and the Best Practices  ACM CoNEXT 2008  C Morariu T  Kramis B Stiller DIPStorage Distributed Architecture for Storage of IP Flow Records  16thWorkshop on Local and Metropolitan Area Networks September 2008  M Roesch Snort Lightweight Intrusion Detection for Networks  USENIX LISA 1999  W  Chen and J W ang Building a Cloud Computing Analysis System for Intrusion Detection System  CloudSlam 2009  Ashish Thusoo Jo ydeep Sen Sarma Namit Jain Zheng Shao Prasad Chakka Suresh Anthony Hao Liu Pete Wyckoff Raghotham Murthy Hive a warehousing solution over a map-reduce framework  Proceedings of the VLDB Endowment Volum e 2  Issue 2 August 2009 Pages 16261629  HBase http://hadoop.apache.or g/hbase 2010 IEEE/IFIP Network Operations and Management Symposium Workshops 361 


 J R Ne w  E  Hasanbelliu and M Aguilar  F acilitating User Interaction with Complex Systems via Hand Gesture Recognition presented at Proceedings of the 2003 Southeastern ACM Conference Savannah GA 2003  Y  W u and T  S Huang V ision-Based Gesture Recognition A Review Gesture-Based Communication in HumanComputer Interaction A Braffort R Gherbi S Gibet J Richardson and D Teil Eds Vol 1739 Lecture Notes in Arti\002cial Intelligence Springer-Verlag Berlin 1999 pp 103115  S Lenman L Bretzner  and B Thuresson Computer visionbased Hand Gesture Interfaces for Human-Computer Interaction Technical Report CID-172 Center for User Oriented IT Design June 2002 
242 


manufacturer value is 249 ns. Our measurements give two zones, depending on whether the local or remote memory are accessed. Indeed, the average access time in the interleaving zone is the average of combining accesses to the local or remote memory. Our outcomes gave an average value of 278,3 ns We can conclude that, when working with codes mapped to cores in a same cell \(especially for those who demand a high level of cache replacement allocated in the same cell  s memory. The access to remote memory becomes very costly, so if cores in both cells must be used, the allocation of the data in the interleaving memory makes sense V. INFLUENCE OF THREAD ALLOCATION ON IRREGULAR CODES A. Ported Technique The next step consisted of porting a parallelisation technique for irregular codes to our target architecture, in order a b c Figure 4. Latency of memory accesses when the data is allocated in memory local to the core \(a b interleaving zone \(c access. The x-axis shows the latency in cycles per memory access. Regions of interest have been zoomed in 150 Table III SPARSE MATRIX-VECTOR PRODUCT \(LEFT REDUCTION \(RIGHT for j = 1 to N do for k = col\(j j +1 i = row\(k Z\(i i k j end for end for for j = 1 to NNZ do i = row\(k Z\(i i end for to check out the effect of thread allocation in an actual application. The chosen technique was IARD [12] \(Irregular Access Region Descriptor characterise irregular codes at run-time which exploits the properties found in the access patterns, expressing them with a structure that allows a strong reduction in storage requirements without loss of relevant information. The lowcost, compact characterisation of the subscript arrays can be used to perform an efficient parallelisation of a wide set of irregular codes In order to test the efficiency of this technique, two well known benchmarks \(Sparse matrix-Dense vector Product and Irregular Reduction parallelised using OpenMP. The pseudocodes are shown in Table III. In both cases, some selected sparse matrices stored in CSC format from the Harwell-Boeing Sparse Matrix Collection [13], which had previously been reordered using this technique, were used as an input. The key features of these matrices are shown in Table IV The compiler used for the experiments was Intel ifort 9.1.052. The baseline compile configuration used in all our tests involved the -O3 option and the interprocedural optimisation \(-ipo B. Influence of Bus Contention To study the influence of the bus contention several scenarios were tested. On the one hand, an intra-cell scenario where the data are allocated in a single cell  s memory and the cores involved belong to the same cell. On the other hand, an inter-cell scenario where the data are fetched from the other cell  s memory and there are cores involved from both cells. Before presenting the results, it is necessary to 


both cells. Before presenting the results, it is necessary to clarify the meaning of a so-called thread distribution. For example, a distribution 15-11-13-9 means that for a onethread execution, the thread will be allocated in Core 15. For Table IV SQUARED-MATRIX INPUT SET USED IN OUR TESTS. Na=MATRIX SIZE Nz =NUMBER OF NON-ZEROS Name Na Nz Description s3dkq4m2 90451 4820892 FEM, cylindrical shell 3dtube 45330 3213618 3-D pressure tube nasasrb 54872 2677324 Shuttle rocket booster struct3 53570 1173694 Finite element bcsstk29 13992 619488 Model of a 767 rear bulkhead bcsstk17 10973 428650 Elevated pressure vessel Table V PERFORMANCE IMPROVEMENT \(% MFLOPS DISTRIBUTION 15-11-13-9 OVER 15-14-13-12 FOR Nc = 2 AND Nc = 4 CORES. DATA ARE ALLOCATED IN CELL 0 MEMORY Matrix Nc Benchmark IrregRed SpMV s3dkq4m2 2 0,0 6,34 1,6 23,9 3dtube 2 0,8 6,64 0,7 13,5 nasasrb 2 2,7 1,44 -1,1 7,7 struct3 2 -1,1 0,74 0,5 1,6 bcsstk29 2 0,9 1,74 1,3 1,8 bcsstk17 2 1,0 0,24 1,5 0,7 two threads, they will be allocated in Cores 15 and 11 and for four threads, they will be in Cores 15, 11, 13 and 9. In the cases where more cores are used and the distribution is not pointed out, it means that the order in which the remaining available cores are assigned is not relevant 1 library was used to allocate all data in the Cell 0 memory and only cores in this cell were used. Several scenarios were set up to study the effect of running the Irregular Reduction and SpMV benchmarks with different distributions, in order to quantify the effect of the bus sharing 15-11-13-9 vs 15-14-13-12: This scenario is focused on 2 and 4 cores. In both benchmarks the sparse matrix must be completely read, which is expected to cause some number of capacity and compulsory cache misses. Therefore, the bigger the matrix, the higher the traffic in the bus, so a performance decrease is expected for the biggest matrices when sharing the bus. At the sight of the results \(Table V a better behaviour of the distribution 15-11-13-9 can be appreciated \(differences over 6% are highlighted biggest matrices \(3dtube, nasasrb and s3dkq4m2 four-core case. Indeed, it was confirmed that the bigger the matrix, the higher the traffic in the bus and the higher the improvement when there are only two threads per bus \(15-11 and 13-9 15-14-1312 can be observed, the traffic is not high enough to be relevant It is noticeable that the most important improvements occur only in the SpMV benchmark, especially for four processors This behaviour happens because SpMV executes a loop which goes through five different arrays, whereas Irregular Reduction goes only through two. So in the former case the cache reuse is smaller than in the latter one. At any given moment, therefore, the SpMV benchmark generates more traffic in the bus than the Irregular Reduction one 15-11-13-9 vs 15-14-11-10: This scenario is focused on 4 cores. The outcomes in Table VI show that there are no noticeable differences between the case when the threads are 151 Table VI PERFORMANCE IMPROVEMENT \(% MFLOPS DISTRIBUTION 15-14-11-10 OVER 15-11-13-9 FOR Nc = 4 CORES DATA ARE ALLOCATED IN CELL 0 MEMORY Matrix Nc 


Matrix Nc Benchmark IrregRed SpMV s3dkq4m2 4 4,1 2,4 3dtube 4 -0,5 1,6 nasasrb 4 0 0,8 struct3 4 0,6 0,3 bcsstk29 4 0,6 -0,2 bcsstk17 4 1,4 0,1 allocated in different sockets and the case when two threads in the same bus share the socket. We know that IARD has no dependencies among the cores involved. Since the outcomes show almost no differences between threads mapped to different cores in different sockets and threads sharing the same socket, we can confirm, then, the conclusion of Section IV-A, which stated that each core behaves as an independent processor regardless of the sockets they are placed in 2 fetching data from a memory module in other cell was studied. Moreover, a comparison was carried out between the automatic thread assignment the system does and our manual assignments. To do that, libnuma was used through its command line tool numactl, in order to allocate all the data in the cell we were working in \(memory 0 memory \(memory 1 memory 2 We intended to infer from these experiments whether the default system behaviour is reliable or, on the contrary another memory allocation policy should be used 15-11-13-9 vs system-assigned: We used the Perfmon2 library to check the system  s default policy to assign threads to cores. This scenario compares a manual allocation with the default one done by the system. We found out that the system assigns the threads without a defined policy changing it in every execution, although it strives to place the threads in separate cells as far as it is possible. Therefore after discarding outliers, we present a range of results inside the standard deviation instead of a single average value. The outcomes in Table VII show a dramatic improvement with our distribution, especially for the biggest matrices \(3dtube nasasrb and s3dkq4m2 cell scenario, there was no distribution that showed such a big difference in the performance, which indeed suggests that the system does not maximise locality Threads spread over both cells: Our second test intended to find out whether the system assignment spreads the threads over two cells, even if there are available cores in the same cell. So the automatic assignment was compared to a manual distribution where the number of involved threads is kept balanced between both cells. The threads were distributed to cores 15-7 for two threads, 15-7-11-3 for four and 15-7-11-3-13-5-9-1 for eight. Focusing on the Table VII PERFORMANCE IMPROVEMENT \(% MFLOPS DISTRIBUTION 15-11-13-9 \(DATA ALLOCATED IN CELL 0 MEMORY OVER AUTOMATIC ASSIGNMENT FOR Nc = 2 AND Nc = 4 CORES AVERAGE, MAXIMUM AND MINIMUM IMPROVEMENTS ARE SHOWN Matrix Nc Benchmark IrregRed SpMV Avg. Max Min Avg. Max Min s3dkq4m2 2 23,8 25,5 23,1 32,5 32,9 32,34 9,8 14,3 7,5 15,0 17,5 13,9 3dtube 2 17,8 20,0 16,3 34,0 34,4 33,84 4,0 7,7 1,5 10,9 13,5 9,1 nasasrb 2 9,5 13,5 7,9 31,6 33,0 31,24 -0,8 4,3 -1,9 14,6 18,0 11,7 struct3 2 -0,3 2,5 -1,1 13,9 17,0 11,54 -1,1 3,0 -1,7 3,6 8,4 1,6 bcsstk29 2 0,1 2,0 -0,3 1,3 5,2 0,64 -1,5 3,8 -2,3 0 2,4 -0,7 bcsstk17 2 0,3 3,3 0 1,6 4,8 1,14 -1,5 10,1 -3,3 0,2 3,2 -0,4 Table VIII PERFORMANCE IMPROVEMENT \(% MFLOPS DISTRIBUTION 15-7-11-3 WITH DATA ALLOCATED IN THE INTERLEAVING ZONE VS. AUTOMATIC DISTRIBUTION FOR Nc = 2 Nc = 4 AND Nc = 8 CORES. AVERAGE, MAXIMUM AND MINIMUM IMPROVEMENTS ARE SHOWN 


IMPROVEMENTS ARE SHOWN Matrix Nc Benchmark IrregRed SpMV Avg. Max Min Avg. Max Min s3dkq4m2 2 -6,9 -5,6 -7,4 4,2 4,4 4,04 -4,5 -0,6 -6,5 0,8 3,0 -0,2 8 -2,0 3,0 -3,0 2,0 6,3 -1,9 3dtube 2 -2,5 -0,8 -3,9 5,3 5,7 5,14 4,4 8,1 1,9 -3,2 -0,9 -4,7 8 2,2 18,3 -2,7 2,4 8,0 -1,7 nasasrb 2 -3,7 -0,2 -5,1 3,0 4,1 2,64 -2,3 2,7 -3,3 -2,5 0,4 -5,0 8 -0,1 12,1 -1,9 6,8 12,6 2,5 struct3 2 1,1 3,9 0,3 -3,6 -1,0 -5,64 0,1 4,3 -0,4 -1,2 3,4 -3,1 8 0,2 6,5 -1,5 3,0 7,3 0,6 bcsstk29 2 0,1 2,1 -0,3 -2,2 1,0 -2,94 -0,1 5,2 -1,0 0,6 3,0 -0,1 8 0,7 11,1 -2,7 -1,4 3,5 -2,6 bcsstk17 2 -0,1 2,9 -0,4 0,9 4,1 0,54 0,5 12,6 -1,4 0,6 3,6 0 8 1,4 20,4 -3,6 -0,6 5,0 -1,8 IARD, where there are no dependencies between threads, the outcomes in Table VIII show that all differences are below 6%, except for some cases in the biggest matrices: nasasrb SpMV, 8 threads IrregRed, 2 threads In general, especially for small matrices, our distribution performs better than the automatic one C. Influence of Cache Coherency Taking into account that this kind of irregular codes strives to maximise the thread locality, we do not expect to notice important performance decreases due to the cache coherency protocols when the input matrices are big enough, since they will be masked by the traffic in the bus. If the matrices fit in each core  s cache, all misses, except the capacity ones, will be solved by the snooping protocol inside the bus, faster than 152 asking the directory. However, this will not usually be the case in real applications, because this type of codes usually operates with matrices far bigger than the cache size VI. CONCLUSIONS This paper presented the results of several tests carried out to characterise FINISTERRAE, an SMP-NUMA machine, in order to study the suitability of applying strategies to parallelise irregular codes initially developed for SMP systems The main factors considered were the thread-to-core distribution and the memory allocation. Firstly, a benchmark was executed to test the performance influence of several cores when sharing a bus and allocating the data in local or remote memory. Secondly, another benchmark was used to evaluate the influence of the cache coherency between two cores when sharing data. Furthermore, another test evaluated the memory access latency depending on the memory module allocated \(local, remote or interleaving At the sight of the results, we can claim that, especially for applications which use the bus intensively, the effect of sharing a bus between two or more cores degrades the performance and should be avoided by spreading the threads among cores in different buses when possible. We must take into account, though, that the test to evaluate the local and remote memory access latencies yielded important differences between them. Therefore, in cases where the threads must be spread in two cells the best policy will be to analyse and split the data in both memory zones, maximising the locality or, when not possible, allocating the data in the interleaving zone Regarding the cache coherency, the effects in the performance are noticeable when dealing with small sizes of data which fit into caches. The more the memory size increases the less significant the effect is. Therefore, for small data sizes, it would be advisable to map the threads on cores in the same bus. For bigger data sizes, the effect of sharing a bus will be more important and it will mask the effect of cache coherency. A noteworthy fact is that every core in the same processor behaves as an independent processor, so we can consider two processors in a bus as four independent 


can consider two processors in a bus as four independent cores After the benchmarking stage, an actual strategy to parallelise irregular codes, successfully tested on SMP architectures, was ported to FINISTERRAE. A set of matrices was chosen and reordered with this strategy, being applied subsequently to the sparse matrix-vector product and the Irregular Reduction benchmarks. Since this code works with sparse data, the effects regarding bus sharing were not as noticeable as in the previous stage. However, it was possible to confirm the importance of spreading the threads among cores in different buses when dealing with big data sizes the behaviour of each core as an independent processor, and the fact that the coherency effects are masked by the bus sharing when increasing the data size As a future work, we intend to develop strategies to guide applications at run-time in the frame of our project, so the conclusions presented here will help to define a thread-tocore mapping and memory allocation policies ACKNOWLEDGEMENTS This work was supported by the MCyT of Spain through the TIN2007-67537-C03-01 project and by the 2008/CE377 contract among HP, CESGA, UDC and USC REFERENCES 1] L. Rauchwerger, N. M. Amato, and D. A. Padua  Run-time methods for parallelizing partially parallel loops  in Proc. of the Int. Conf. on Supercomputing. ACM press, 1995, pp 137  146 2] R. Eigenmann, J. Hoeflinger, and D. Padua  On the automatic parallelization of the perfect benchmarks  IEEE Trans Parallel Distrib. Syst., vol. 9, no. 1, pp. 5  23, 1998 3] E. Gutie  rrez, O. Plata, and E. L. Zapata  A compiler method for the parallel execution of irregular reductions in scalable shared memory multiprocessors  in Proc. of the Int. Conf on Supercomputing, ACM SIGARCH. Springer-Verlag, May 2000, pp. 78  87 4] Galicia Supercomputing Centre, http://www.cesga.es 5] J. W. Tobias Klug, Michael Ott and C. Trinitis  Autopin - automated optimization of thread-to-core pinning on multicore systems  in Transactions on HiPEAC, vol. 3, no. 4, 2008 6] S. Williams, L. Oliker, R. Vuduc, J. Shalf, K. Yelick, and J. Demmel  Optimization of sparse matrix-vector multiplication on emerging multicore platforms  in SC  07: Proc. of the 2007 ACM/IEEE Conf. on Supercomputing. New York NY, USA: ACM, 2007, pp. 1  12 7] M. Norde  n, H. Lo  f, J. Rantakokko, and S. Holmgren  Dynamic data migration for structured amr solvers  International Journal of Parallel Programming, vol. 35, no. 5, pp 477  491, 2007 8] Performance Application Programming Interface http://icl.cs.utk.edu/papi 9] S. Eranian, The perfmon2 Interface Specification. Technical Report HPL-2004-200R1. HP Labs, February 2005 10] Perfmon2 monitoring interface and Pfmon monitoring tool http://perfmon2.sourceforge.net 11] HP Integrity rx7640 Server Quick Specs, http://h18000 www1.hp.com/products/quickspecs/12470 div/12470 div.pdf 12] D.E.Singh, M.J.Martin, and F.F.Rivera  A run-time framework for parallelizing loops with irregular accesses  in Proc Seventh Workshop Languages, Compilers, and Run-Time Systems for Scalable Computers, Washington DC, USA, 2002 13] The Harwell-Boeing Sparse Matrix Collection http://math.nist.gov/MatrixMarket/collections/hb.html 153 pre></body></html 


also be used to define constraints for service selection At run-time, the workflow engine for XML nets interprets and evaluates Filter Schemas and transition inscriptions to filter and create Web service descriptions as XML documents. With process monitoring and administration tools which are usual components of workflow management systems, new criterions and constraints for WS discovery and selection can be incorporated at run-time by reconfiguring transition inscription statements and variable instantiations in Filter Schemas  Instantiating abstract WS transition Figure 4 shows a fragment of the abstract WSC process in Section 5.1 to demonstrate the ability of XML nets in WS discovery. To obtain transport information, Web services whose descriptions are stored in an unknown WSDL repository should be discovered The token count of the place representing the repository is supposed to be unlimited. The abstract transitions find transport info service? and ?get transport information? are used to bind and call Web services at runtime. The incoming arc of the transition ?find transport info service? is a reading connection \(represented by a dashed arc nipulative Filter Schema FS2 used to create Web service descriptions is assigned to the outgoing arc of this transition. FS1 and FS2 are both generated according to WSDL Schema  Adapting abstract WS transition at run-time Suppose that the transition ?get transport information? is used to acquire flight information. Variables in FS1 should be \(partly  3 http://www.w3.org/TR/wsdl#A4.1 4 http://uddi.org/schema/uddi_v3.xsd es supplying flight information. As shown in Figure 5a the variable of the attribute filter ?name? of the element filter ?service? is instantiated with a regular expression for filtering Web services whose name contains the string ?flight?. This regular expression, together with the Filter Schema, is parsed to XQuery/XPath statements in process simulation or execution. If we use a reconfiguration tool to modify the regular expression at run-time as shown for example in Figure 5b, the transition ?get transport information? can then be adapted to acquire other transport information, e.g., train information. After a suitable WSDL document has been found, FS2 is used to create a new WSDL document for the place ?WS description by cloning the discovered document. Figure 5c shows the diagram of FS2 containing the WSDL root element definitions? and an element placeholder, which is used because the internal structure and details of the document to be created are not of interest in the case of document duplication  QoS-aware WS selection XML nets can also be used to select desired Web services if service constraints like QoS or customized preferences are taken into consideration. As WSDL and OWL-S provide no or limited ways for describing Web service?s QoS, we use in this paper OWL-QoS 43], which complements OWL-S with an ontology to specify QoS metrics for Web services, to demonstrate the ability of XML nets for \(QoS-aware Naturally, other Web service ontologies \(e.g., MOQ 11 e.g., WSLA [18 can also be used for this purpose Figure 6 shows another XML net fragment for the acquisition of transport information by selecting OWL 


acquisition of transport information by selecting OWLQoS documents which describe quality of Web services from a repository that contains 3 OWL-QoS documents discovered previously. Similar to the example in Figure 2, the Filter Schema FS1 is used to read and select appropriate OWL-QoS documents, and the Filter Schema FS2 to create new OWL-QoS documents for the place ?OWL-QoS document?. As Filter Schema provides no means for formulating inequality operators like ?&gt;? and ?&lt;=?, which are usually used to express constraints with parameters whose quantitative values are limited to a certain interval, transition inscriptions Figure 4. XML net for Web service discovery Figure 5. Filter Schemas for Web service discovery definitions 1 service name: \\s*flight\\s*/i c definitions service name: \\s*train\\s*/i b a definitions 1 1 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 can be used in combination with Filter Schemas to formulate QoS constrains Suppose that the traveler wants to use only the Web services that cost no more than 100 US Cent. The Filter Schema FS1 should then be created as shown in Figure 7. The variable of the attribute filter ?rdf: resource? of the element filter ?owl: onProperty? is instantiated with a regular expression to filter OWL-QoS documents specifying the property ?costUSCent?. To ensure that the maximal cost of the Web service doesn?t exceed 100 US cent, the inscription of the transition ?select transport info service? should be formulated as owl:maxCardinality &lt;= 100?. In process simulation or execution, the inscription is parsed and integrated into XQuery statements using XPath inequality operators  6. Conclusions  In this paper we presented a WSC method based on XML nets, which inherit advantages of Petri nets such as formal semantics and graphical expression. XML nets have additional strengths in the description of process and data objects, and the exchange of XMLbased structured data. The advantage of using XML nets for WSC is that control flow modeling, data and data flow modeling, and WS discovery and selection can be realized using a uniform powerful modeling language. Some uncomplicated tasks, as illustrated before, can be fulfilled without developing or using additional software components or agents. Naturally XML nets can also be combined with other Web service techniques to fulfill more complicated and demanding tasks  7. Acknowledgement  The authors would like to thank the anonymous referees for many valuable comments on an earlier version of this paper  8. References  1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching 


1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching Web Service Coordination and Composition by Means of Petri Nets: the Case of the Nets-within-Nets Paradigm?, ICSOC 2005, LNCS 3826, pp.185-197, 2005 2] M. ter Beek, A. Bucchiarone, and S. Gnesi, ?Web Service Composition Approaches: From Industrial Standards to Formal Methods?, Second International Conference on Internet and Web Applications and Services \(ICIW?07 Computer Society, 2007 3] X.N. Feng, Q. Liu, and Z. Wang, ?A Web Service Composition Modeling and Evaluation Method Used Petri Net?, LNCS Volume 3842/2006, pp. 905-911, SpringerVerlag, 2006 4] H. Foster, S. Uchitel, J. Magee, and J. Kramer, ?Modelbased verification of Web Service Compositions?, 18th IEEE International Conference on Automated Software Engineering, pp. 152- 161, 2003 5] X. Fu, T. Bultan, and J.W. Su, ?Analysis of Interacting BPEL Web Services?, WWW2004, pp. 17-22, New York USA, May 2004 6] J.D. Ge, H.Y. Hu, P. Lu, H. Hu, and J. L  Translation of Nets Within Nets in Cross-Organizational Software Process Modeling?, SPW 2005, LNCS 3840, pp. 60-375 Springer-Verlag, 2005 7] Group for program system, faculty of Information Technique University Dortmund, ?PDDL?, http://ls5www.cs.uni-dortmund.de/~edelkamp/ipc-4/pddl.html 8] R. Hamadi and B. Benatallah, ?A Petri Net-based Model for Web Service Composition?, Fourteenth Australasian Database Conference \(ADC2003 CRPIT, Vol. 17, pp. 191-200, 2003 9] S. Hinz, K. Schmidt, and C. Stahl, ?Transforming BPEL to Petri Nets?, BPM 2005, LNCS 3649, pp. 220?235, Springer-Verlag, 2005 10] H. Kang, X.L. Yang, and S.M. Yuan, ?Modeling and verification of Web Services Composition based on CPN 2007 IFIP International Conference on Network and Parallel Computing-Workshops, pp. 613-617, 2007 11] H.M. Kim, A. Sengupta, and J. Evermann, "MOQ: Web Services Ontologies for QOS and General Quality EvaluaFigure 6. XML net for Web service selection Figure 7. Filter Schema for QoS-aware WS selection owl:Ontology owl:Class rdfs:subClassOf owl:Restriction rdf :resource : "\\s+#costUSCent owl:onProperty owl:maxCardinality   rdf:RDF Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 tions", European Conference on Information Systems \(ECIS 2005 12] S. Klink, Y. Li, and A. Oberweis, "INCOME2010 - a Toolset for Developing Process-Oriented Information Systems Based on Petri Nets", International Workshop on Petri Nets Tools and APplications \(PNTAP 2008, associated to SIMUTools 2008 March 2008 13] O. Kluge, ?Petri nets as a Semantic Model for message Sequence Chart Specifications?, proceedings of INT 2002 pp. 138-147, 2002 14] K. Lenz and A. Oberweis, ?Inter-Organizational Business Process Management with XML Nets?, H. Ehrig, W Reisig, G. Rozenberg, H. Weber \(Eds gy for Communication Based Systems, LNCS 2472, pp. 243263, Springer-Verlag, 2003 15] K. Lenz and A. Oberweis, "Workflow Services: A Petri Net-Based Approach to Web Services", Int. Symposium on Leveraging Applications of Formal Methods, pp. 35-42, Pa 


Leveraging Applications of Formal Methods, pp. 35-42, Paphos/Cyprus, November 2004 16] L. Lin and I.B. Arpinar, ?Discovery of Semantic Relations between Web Services?, IEEE International Conference on Web Services \(ICWS?06 17] Q. Lin, J.D. Ge, H. Hu, and J. Lu, ?An Approach to Model Cross-Organizational Processes using Object Petri net?, 2007 IEEE Congress on Services \(SERVICES 2007 pp. 146-152, July 2007 18] H. Ludwig, A. Keller, A. Dan, R. P. King, and R Franck, ?Web Service level Agreement \(WSLA Specification version 1.0?, IBM, 2003 19] N. Lohmann, P. Massuthe, C. Stahl, and D. Weinberg Analyzing Interacting BPEL Process?, S. Dustdar, J.L. Fiadeiro, and A. Sheth \(Eds 32, Springer-Verlag, 2006 20] S.A. Mcllraith and T.C. Son, ?Adapting Golog for Composition of Semantic Web Services?, 8th International Conference on Knowledge Representation and Reasoning KR2002 21] S.A. Mcllraith, T.C. Son, and H.L. Zeng, ?Semantic Web Services?, IEEE Intelligent Systems, March/April 2001 16\(2 22] N. Milanovic and M. Malek, ?Current Solution for Web Service Composition?, IEEE Internet Computing, NovemberDecember 2004 23] S. Narayanan and S.A. Mcllraith, ?Simulation, Verification and Automated Composition of Web Service?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 24] The Organization for the Advancement of Structured Information Standards \(OASIS Process Execution Language Version 2.0?, 11 April, 2007 http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.pdf 25] S.R. Ponnekanti and A. Fox, ?SWORD: a Developer Toolkit for Web Services Composition?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 26] Z.Z. Qian, S.L. Lu, and L. Xie, ?Colored Petri Nets Based Automatic Service Composition?, 2007 IEEE AsiaPacific Services Computing Conference, pp. 431-438, 2007 27] C. Ouyang, E. Verbeek, W.M.P. van der Aalst, S. Breutel1, M. Dumas1, and A.H.M. ter Hofstede1, ?Formal semantics and analysis of Control flow in WS-BPEL?, BPM center Technical Report, BPM-05-15, 2005 28] J.H. Rao and X.M. Su, ?A Survey of Automated Web Service Composition Methods?, SWSWPC 2004, LNCS 3387, pp. 43-54, Springer-Verlag, 2005 29] J.H. Rao, P. Kuegas, and M. Matskin, ?Application of Linear Logic to Web Service Composition?, 1st International Conference on Web Services, Las Vegas, USA, June 2003 30] J.H. Rao, P. Kuegas, and M. Matskin, ?Logic-based Web Services Composition: From Service Description to Process Model?, 2004 International Conference on Web Services, pp.446-453, San Diego, USA, July 2004 31] M. Sgroi, A. Kondratyev, Y. Watanabe, L. Lavagno and A. Sangiovanni-Vincentelli, ?Synthesis of Petri Nets from Message Sequence Charts Specifications for Protocol Design?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp. 193-199, 2004 32] W.M.P. Van der Aalst, "The Application of Petri Nets to Workflow Management", The Journal of Circuits, Systems and Computers, 8\(1 33] The World Wide Web Consortium \(W3C Semantic Markup for Web Services?, 22 November, 2004 http://www.w3.org/Submission/OWL-S 34] The World Wide Web Consortium \(W3C vices Choreography Description Language Version 1.0?, 17 December, 2004, http://www.w3.org/TR/2004/WD-ws-cdl10-20041217 35] The World Wide Web Consortium \(W3C vice Choreography Interface \(WSCI 


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






A Replication Strategy Based on Swarm Intelligence in Spatial Data Grid  Ping Zhang, Kunqing Xie  Xiujun Ma  Xiong Li, Yixian Sun Key Laboratory of Machine Perception \(Minister of Education Peking University Beijing, China Corresponding author: kunqing@cis.pku.edu.cn; maxj@cis.pku.edu.cn   Abstract In the spatial data grid, the distribution of query and the data is unevenly some resource become hotspot and the hotspots are changing over time, which may cause the global load unbalanced, this dynamic problem becomes a key challenge in Data Grid. Data replication is a way to deal with this problem which improves data availability, reduces latency and increases 
throughput. In this paper, we present a new replication approach which is adaptive, completely decentralized, and based on swarm intelligence which is intrinsically a bottom-up approach. Every site in the grid system has a single agent, which is serving as containers for data, following simple rules of behavior and without knowing any global information. The strategy that agents follow includes which data to create replica and where the replica is locating. The local interactions and simple action between agents give a fairly optimal replication location solution globally We carried the experiments using OptorSim for the EU Data Grid Testbed 1. Experimental results show that our approach performs better than No replication and when the scale of jobs is 
big, our method will outperform the Economic Model, but the space consumption is proportional Keywords-distribute system; spatia l data grid; data replication swarm intelligence; agent I   I NTRODUCTION  As traditional GIS has many flaws in managing distributed large-scale, heterogeneous spatial data, lots of countries build their own spatial data grid to provide abundant spatial data services. As one class of Data Grid, there may exist millions of files and replicas distributed on hundreds of geographically dispersed storage resources, which are organized to provide an integrated service [1   In this system, the distribution of query and the data is 
unevenly, some resource become hotspot and the hotspots are changing over time, which may cause the global load unbalanced, this dynamic problem becomes a key challenge in Data Grid [2 Da ta r e p lic ati o n is a w a y to d eal w ith th is  problem, which improves data availability, reduces latency and increases throughput. Data replication mainly concerns the decision of when and where to create physical copies of logical data fragments and when and how to update them to maintain data consistency. In this paper, we focus on data replication location problem because the spatial resource is not updated frequently It is not a trivial matter to design a replication location service which is reliable and can provide good performance to 
all the Grid users. Globus and EU Data Grid set projects for finding optimal replication location service in dynamic environment [3 H o w e ve r  t h e  p r ob l e m o f fi nd i ng a n  o p t i m a l  replication scheme in Grid system has been shown to be NPhard for the static case [4  S o i t  is u n lik ely to f i n d a  convergent-optimal algorithm in this dynamic environment, all these replication algorithms are heuristic. On the other side most of the distributed applications exclude any form of centralized structure, requiring control to be completely decentralized which also make the traditional replication algorithms hard to deploy In order to deal with the decentralization and dynamism, we 
present a new replication approach which is adaptive completely decentralized, and based on swarm intelligence which is intrinsically a bottom-up approach. The local interactions and simple actions among agents lead to the emergence of intelligent global behavior, our approach is to find a local optimal solution, with agents’ local interactions and the local solution will spread to the global and give a fairly optimal replication location solution globally. Our work is as following A replication approach based on swarm intelligence is proposed. Every site in the grid system has a single agent which is serving as manager of file data, following simple rules of behavior and without knowing any global information. The 
agent will follow two strategies when it is going to take a replication action: a strategy that selecting which data to create a replica. The agent computes “degree of heat” of every data file on the site according to the local access information. This quota helps the agent select which data replica should be copied and sent to other site, so as to balance the load of local site and reduce the global responding time of that data. And another strategy that finding where the replica is locating Based on every site’s access information and its’ neighbors information, the agent estimates the load which may be transferred to another site with replicate a data cell, and then choosing the fittest site to locate the replica To evaluate our approach we use a simulation package 
called OptorSim [5  As  p a r t  o f  t h e EU D a ta Gr id  p r o j ec t   OptorSim is a Data Grid simulator designed to allow experiments and evaluations of various replication optimization This work was supported by The National High Technology Research and Development Program of China \(863 Key Program\ No.2007AA120502 and the National Natural Science Foundation of China under Grant No.40801046 and No. 60874082 


strategies in a Grid environment. We carry the experiments on a model of the EU Data Grid Testbed 1 sites and their associated network geometry [3   T h e  q u ery in  th e s i m u latio n is submitted with a fixed probability such that some queries are more popular than others. In order to evaluate our approach, we contrast the No replication and the Economic Model method built in OptorSim by using the total job execution time and storage usage as evaluation indicators This paper is organized as follows. Section 2 reviews related works. Section 3 describes the replica strategy we designed. Section 4 shows the experiment scenario. And Section 5 gives experiment result. Section 6 concludes II  R ELATED W ORKS  The replication strategies in Data Grid are classified as bottom-up approach and top down approach n d an i n i t i a l  work on dynamic file replication in Data Grid was done by K Ranganathan and I. Foster [2 h e y propos i n g  s i x repl i cat i o n  strategies: No Replication, Best Client, Cascading, Plain Caching, Cascading plus Caching and Fast Spread. Among all these top-down schemes, Fast Spread strategy gives a relative high performance through various access patterns. However these approach is based on a Hierarchical Gird, and they cannot apply into a P2P Gird directly S. Naseera, T.Vivekanandan and Dr. K.V. Madhu Murthy  dem o n s t r at ed t h at t h e adopt repl i cat i o n ap proach i n D a t a  Grid can reduce the file access cost effectively and improve the data availability in many applications. And maintaining a minimum number  of  replicas  in  an arbitrary  topology is  an NP-complete problem[4 it is u n lik e l y to  f i n d a convergent-optimal algorithm in a dynamic environment just like Data Grid, and the time cost of the regular method is intolerable Rahman et. al opos ed a dy n a m i c repl i ca m a i n t e n a n c e  algorithm in a static replica placement environment which reallocates replicas to new sites if performance reduces over last k time periods. Xin Sun, Kan Li, Yushu Li en t  t h e bidirectional linked list based replica location service \(BLLRLS\ tree-based hierarchical unstructured overlay networks William H. Bell and David G. Cameron give a summary in [9 that the replication algorithms proposed now are based on the assumption that popular files in one site are also popular in other sites. The replication action is triggered when the popularity of a file overcomes a threshold To study the replication and management service in Data Grid, various Grid simulation projects have been undertaken in recent years, such as Grid Sim d OptorSim 5 David G. Cameron , Rub´ en Carvajal-Schiaf  no have done a work about OptorSim h e y  g i v e a co n c l u s i on about  t h e  main advantage of OptorSim wi th respect to the previous simulators. And in [9 illia m H.B e ll a n d Da v i d G.Ca m e ro n  detail the design and implementation of OptorSim and analyze various replication algorithms based on different Grid workloads III  R EPLICATION A PPROACH B ASED O N S WARM I NTELLIGENCE  To solve the replication problem, we propose a replication approach based on swarm intelligence. Inspired by natural bio systems such as ant colonies and bird flocking, a swarm Intelligence system is typically made up of a huge number of simple agents interacting locally with one another and with their environment. Although the agents follow very simple rules, and there is no centralized control dictating how a single agent should behave, local interactions among them lead to the emergence of "intelligent" global behavior Agents have the property of self-governed, adaptive of environmental change, and coordination among themselves which make them very suitable of cooperating complex spatial task in a dynamic and complex distributed system. In the spatial data grid we studied, every site has a single agent which is serving as manager of data at local site. The agent’s behavior is simple and it has nothing global information. Based on sensation of environment and local interactions among them the local solution will spread to the global and give a fairly optimal replication location solution globally The behaviors of an agent at each site are just to select the right data to create replica at the right time and send the replica to the right place. As mentioned above, the two actions of an agent should lead a local solution. So we propose two strategies for these two issues A  A strategy that selecting which data to create replica The first step of a replication strategy is choosing which data to create replica, in our method, the decision is made by the agent on a site, so we define a quota D i represents the degree of heat” of data file i of this site. The larger D i means the file i has much more requests. This quota helps agent on local site select which data replica should be copied and sent to other site, so as to balance the load of local site and reduce the global responding time of that data The degree of heat Di is defined as      The Di rises and falls with requests, and tj is the time since the jth request of this data file. This equation is based on the rational analysis of Anderson and Schooler [1  T h at  i s t o s a y   the heat of degree of a file not only considers the recent requests, but also considers the history access log. And 0.5 has emerged as the default value for the time-based decay parameter  B  A strategy that finding where the replica is locating Before an agent create a replica and chooses where the replica is locating, an agent must know when to take these actions is appropriate. So we define a parameter Li represents the threshold of the CPU load that every site i can bear Li is in the interval [0,1  T h e Li is set at 0.8 in our experiment, which means if an agent has found the CPU load exceeded 80%, it will choose “the hottest” file to make a replica 


As a local solution, the decision of where to place replica is made based on local file access information and neighbor list The algorithm is like this  1  Choose the hottest file h and get the access list of file alist\(h as well as neighbor list of local agent l,nlist\(l  2  j=0 3  While \(j<nlist\(l\size 4   5  Get the jth neighbor of local agent l 6  C=get the number of agent j access file h in alist\(h 7  k = 0 8  While\(k<nlist\(j\.size 9   10  Get the kth neighbor of agent j 11  C+=get the number of agent k access file h in alist\(h 12   13  If\(C>Max 14   15  Max = C 16  Candidate = j 17   18   19  Return Candidate At first we choose the hottest file h based on degree of heat and get the access list of file h the access list record the request number of file h by each site. Then we get the neighbor list of local agent which is the possible candidate sites to place the replica of file h Next the local agent uses the total request number of neighbor cluster as estimated. This number is not only come from jth neighbor’s request, but also from jth  neighbor’s neighbor. That is to say, an agent hope if it selects jth neighbor as the candidate site, the request from jth  neighbor’s neighbor to local site will bring to the jth neighbor as much as possible. Then local agent will choose the neighbor that lead the largest total number of request and make a replica of file h to that site IV  E XPERIMENT S CENARIO  To evaluate our approach we use a simulation package called OptorSim. As part of the EU Data Grid project OptorSim is a Data Grid simulator designed to evaluations of various replication optimization strategies in the grid environment. It also provides the ability to create, delete and replica files in a grid environment. And In this paper we extended the OptorSim toolkit to incorporate the functionality of agent for decision-making process for the replication strategy  Figure 1  The simulated topology of EU DataGrid TestBed1 The study of our replication approach based on swarm intelligence is carried out based on an EU Data Grid Testbed1 in OptorSim. The Grid topology and bandwidth between sites is as shown in Figure 1. The grid comprises 20 sites in the USA and Europe. Each site provides computational and data-storage resources for submitted jobs. And a single site consists of zero or more Computing Elements and zero or more Storage Elements. Computing Elements run jobs that use the data in files stored on Storage Elements. The site CERN \(European Organization for Nuclear Research\ and the site FNAL \(Fermi National Accelerator Laboratory\ have a storage capacity of 100GB each and both of them have no Computing Element. An original copy of each file is stored at one of them. Other sites have one Computing Element and initially empty storage of capacity 50 GB. The file size is 1GB and the total size of the set is 97GB. The distribution of requested files generally follows a Zipf-like distribution [1    We conducted the experiment for a simulated set of high energy physics analysis job from the CDF5858 experiment use case  T h e r e ar e s i x t y p e s  o f  j o b s w i t h no  o v er l a pp ing between the set of files each job requests. The probability of job selection is summarized in Table 1 TABLE I  T HE J OB S ELECTION P ROBABILITY  Job Content Probability Central  Job 0.5 High P t leptons Job 0.2 Inclusive electrons Job 0.1 Inclusive muons Job 0.1 Inclusive E t photons Job 0.07    Job 0.03 V  E XPERIMENT R ESULT  To evaluate the replication strategies in a grid environment we have taken two measures into account, which provided by OptorSim   Total Job Execution Time: the total job execution time is defined as the total time to execute all the jobs. It is an important measure of how the replication strategy is performing [5  FNAL Wisconsion 2.5G 622M Bristol IC RAL Moscow Padova Bari Perugia Catania Roma Firenze Bolo g na Pisa Torin o  CERN L y on LFL UCSD Caltech USA2 USA3 USA1 UK Franc e  Russia Switzerlan d Ital y 622M 622M 622M 2.5G 2.5G 2.5G 2.5G 622M 10G 10G 10G 10G 10G 155M 622M 155M 155M 155M 155M 45M 100M 100M 45M 100M 155M 100M 1G 1G 45M Router Site 


  Storage Resources Usage: The percentage of total storage resources used during the simulation in Grid sites can also be a valuable source of information [5  And in order to evaluate our approach better, we contrast two replication strategies built in OptorSim   No Replication: This algorithm never replicates a file The distribution of initial file replicas is decided at the beginning of the simulation and does not change during its execution [5   Economic Model based on Zipf-like distribution: In this algorithm, data files are “sold” by SEs to either CEs or other SEs. A file is purchased by Computing Elements \(CE\ for running a job and by Storage Elements \(SE\o make an investment. The purchasing action of a SE means the SE gets a replica of the file CEs try to minimize the file purchase cost, while SEs attempt to maximize their profits [5      Our simulations are run varying the number of jobs from 100 to 1000 and to 10000   The Total Job Time of three strategies for increasing number of jobs can be seen in Figure 2 and Figure 3. In Figure 2, with no optimization, the jobs take so much longer than the other two optimization algorithms as all the files requested by jobs have to be transferred from CERN. The single resource site leads a huge time on queue. And when the scale of jobs is small, the time difference is not obvious, but when the number of jobs comes to 10000, the result shows a significant difference  Figure 2  Total Job Time for increasing number of jobs To further explain our method, in Figure 3, we focus on the Economic Model and our method. When number of jobs is small, we find the swarm intelligence strategy costs a little more time than Economic Model, this is because the scale of job is small and the CERN can endure the access pressure for a longer time, which leads agents to take a replica action late That is to say, when the agents start to replica a file and spread it along the Grid, the total jobs will have been done in a short time. However, with the expansion of the jobs scale, our method gets a better and better performance than the Economic Model. When the number of jobs is 10000, the total job time is about 10% faster using our method than Economic Model. That is mainly because the speed of spreading replica over the Grid of our method is faster than Economic Model. The more replicas bring a shorter time. Contrast Figure 3 to Figure 4, we can see, when we make a full use of storage resource, we will get a faster job execution speed, that is trading space for speed  Figure 3  Total Job Time for increasing number of jobs \(Compare Economic Model and Swarm Intelligence Replication Strategies  Figure 4  Storage Resources Usage for increasing number of jobs VI  C ONCLUSION  In this paper, we propose a replication strategy based on swarm intelligence in Spatial Data Grid. Every site in the grid system has a single agent, which is serving as manager of data following simple rules of behavior and without knowing any global information. The local interactions among them lead to the emergence of "intelligent" global behavior.  And we design two strategies that an agent will use when taking a replication action: A strategy for selecting which data should be copied The degree of heat of every data file helps agent on local site select which data replica should be copied and sent to other site. A strategy for finding where the replica should be located Based on every site’s access information and its’ neighbors information, the agent on local site estimates the load which may be transferred to another site with replicate a data cell And then the agent chooses the fittest site to locate the replica In order to evaluate our approach, we contrast the No replication and the Economic Model method by using the total job execution time and storage usage as evaluation indicators Experimental results show that our approach performs better than No replication and when the scale of jobs is big, our method will outperform the Economic Model, but the space consumption is proportional 0 20000 40000 60000 80000 100000 120000 140000 100 1000 10000 Total Job Time \(s Number of Jobs Economic Model Swarm Intelligence No Replication 0 2000 4000 6000 8000 10000 12000 100 1000 10000 Total Job Time \(s Number of Jobs Economic Model Swarm Intelligence 0 10 20 30 40 50 60 70 80 90 100 100 1000 10000 Storage  Resource  Usage Number of Jobs Economic Model Swarm Intelligence No Replication 


In future, we plan to improve the strategies that agents used and make our approach performs better and at the same time makes a more economic usage of the Grid storage R EFERENCES  1  Spatial Data Repositories / GRID Systems http://isferea.jrc.ec.europa.eu/AC TIVITIES/TECHNOL OGIES/Pages/Sp atialDataRepositoriesGRIDSystems.aspx  2  Kavitha R., and Foster I., “Identifying Dynamic Replication Strategies for a HighPerformance Data Grid”, in Proceedings of the Second International Workshop on Grid Computing, 2001, pp 75-86 3  The  Data Grid Project http://www.eu-datagrid.org  4  Garey,  M.  and  Johnson, D.  Computers and  Intractabdity,  1979 5  OptorSim-A Replica Optimiser Simulation http://griddatamanagement.web.cern.ch/grid-datamanagement/optimisation/optor  6  S. Naseera, T.Vivekanandan and Dr. K.V. Madhu Murthy, “Trust Based Data Replication Strategy in a Data Grid”, In proceedings of 2nd International conference on Information Processing, ICIP,Bangalore June 2008, pp. 467-473 7  R.M. Rahman, K. Baker and R. Alhajj, “Replica Placement Design with Static Optimality and Dynamic Maintainability”, Proceedings of the IEEE/ACM International Conference on Cluster Computing and Grid CCGRID 06\, Singapore, May 2006 8  Xin Sun, Kan Li, Yushu Liu , “An Efficient Replica Location Method in Hierarchical P2P Networks in Eigth IEEE/ACIS International Conference on Computer and Information Science ICCI’09 2009 9  William H. Bell, David G. Cameron, Ruben Carvajal-Schiaf  no,A. Paul Millar, Kurt Stockinger, Floriano Zini, “Evaluation of an EconomyBased File Replication Strategy for a Data Grid,” in Proceedings of the 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid CCGrid’03 2003   P. Crosby. EDGSim. http://www.hep.ucl.ac.uk pac/EDGSim   David G. Cameron, Rub´ en Carvajal-Schiaf  no, A. Paul Millar Caitriana Nicholson, Kurt Stockinger, Floriano Zini, “Evaluating Scheduling and Replica Optimisation Strategies in OptorSim,” In 4th International Workshop on Grid Computing Grid’03 2003   Anderson,J.R.,&Schooler,L.J.\(1991\.Re  ections of the environment in memory. Psychological Science, 2, 396–408   Summary of CDF5858 for Metadata Group Steven Hanlon, May 2004 http://www.gridpp.ac.uk/datamanagement/metadata/SubGroups/UseCas es/summaries/cdf5858_summ.html    Qaisar Rasool, Jianzhong Li, George S. Oreku, Shuo Zhang, Donghua Yang, “A Load Balancing Replica Placement Strategy in Data Grid,” in Third International Conference on Digital Information Management ICDIM’ 08 London,United Kingdom, 2008   Naseera, S.  and Murthy, K.V.M., “Agent Based Replica Placement in a Data Grid Environement,” in First International Conference on Computational Intelligence, Communication Systems and Networks  CICSYN '09 9   Kavitha R., and Foster I., “Design and Evaluation of Replication Strategies for a High Performance Data Grid”, Proceedings of Computing and High Energy and Nuclear Physics, 2001   M. Young, The Technical Writer's Handbook. Mill Valley, CA University Science, 1989  


 6 Figure 11 \226 Shock wave formation at Model A \(Zoomed frame   The resulting shock wave can be thus seen on the shadowgraph screen. The following observations were made from this shock pattern  
200  An attached shock wave was observed, inclined at an angle to the flow. Thus the wave maybe an oblique shock wave  Oblique shock waves occur when a supersonic flow is deflected towards itself. The m odels had concave plan form leading edges; therefore the co rners turned the flow into itself giving rise to an oblique shock formation   Figure 12 \226 Supersonic flow over compression corners  In the above diagram, the flow deflection angle is 12 degrees for Model A, as mentioned in section 3. All the streamlines are deflected to the same angle at the shock resulting in uniform parallel flow downstream of the shock Across such a shock wave, the Mach number decreases and the pressure, temperature and density of the fluid increases. The angle that is formed by the shock wave with the corner is called the shock angle   The observed oblique shock was inclined at an angle with Model A. This angle was geom etrically determined to be around 50 degrees. The pressure before the shock, P 1 was found to be 0.2 bar  Therefore, experimental analys is of Model A at Mach 1.73 using a shadowgraph was  50 degrees P 1 0.2 bars  Analysis of Model B  Model B had the same flow deflection angle as that of model A. The shock pattern observed in Model B was identical to the pattern over model A. Therefore its experimentation leaded to similar analysis as done for Model A  However, a different phenomenon was observed during testing of Model B. While increasing the Mach number in the tunnel, the model was seen to roll and pitch up about its axis. This phenomenon could be attributed to two reasons 1  The design of the model gave good aerodynamic properties, which resulted in lifting up of the model 
200  The flow was not one dimensional. Therefore, it rules out the possibility of normal shock wave formation 
 


 7 2  The rolling could be attributed to improper tightening of the screw end of the model into the holder   Analysis of Model C Model C was tested finally at same Mach number and pressure. The frame caught by the high speed motion camera showed a detached shock wave formation in front of the nose  Figure 13 \226 Shock wave formation at Model C   This is the shock which results when the wall deflection angle is greater than max   According to the  M relationship, such shocks have no rigorous analytical treatment as explained in section 5. The shape of the detached shock and its detachment distance depend on the geometry of the object faci ng the flow and the Mach number before the shock  The following observations were made from this shock formation at Model C  
200  The detachment distance was found geometrically to be 0.3cm from the nose  The strength of the detached shock was maximum near the stagnation streamline, where it is approximated as a normal shock, and then it continuously decreases by becoming oblique as seen in the frame  Therefore the experimental analysis of the detached shock wave was 200  Distance of detachment from nose = 0.3cm 200  Shape of the detached shock was studied and could be approximated to be a normal shock  5  T HEORETICAL A NALYSIS   The experimental values of shock angle for Models A and B were verified using the  M relationship. For each wave angle at a given mach number M 1 there is a corresponding flow turning angle that is can also be expressed as a unique function of M 1 and With trigonometric manipulation from the basic isentropic expressions, the final expression can be written to show the dependence of explicitly as    The results for various values of and for different mach numbers can be plotted in form of a curve. This curve is called as oblique shock solution curve. The following 
200  The shape of the detached shock wave was observed to be concave in shape with respect to the nose. It can be approximated to a normal shock 
 


 8  Figure 14 \226 Oblique Shock Solution   observations can be made from the oblique shock solution curve as explained in the later paragraphs   The following observations can be made from the curve 
200  For any given M 1 there is a maximum value of  Therefore, at a given M 1   if  max then no solution is possible for a straight oblique shock wave. In such cases, the shock will be curved and detached 200  When  max there are two possible solutions for each value of and M, having two different wave angles. The large value of is called the strong shock solution and the smaller value of is called as the weak shock solution For strong solution the flow behind the shock becomes subsonic. For weak shock solution the flow remains supersonic, except for a small angle range values slightly smaller than max  200  If 0, then  2, gives rise to normal shock, or decreases to the limiting value that is shock disappears and only Mach waves prevail in the flow field  It is important to note that oblique shocks are essentially compression fronts across which the flow decelerates and the pressure, temperature and density jump to higher values. If the deceleration is such that the Mach number behind the shock continues to be  greater than unity, the shock is termed weak oblique shock If the downstream Mach numbe r becomes less than unity then the shock is called strong oblique shock corresponding to the upper portion of figure 14    It is essential to note that only weak oblique shocks are usually formed and it calls for special arrangements to generate strong oblique shocks  The relationship between the pressure before and after the oblique shock wave can be given by the equation    The Mach number behind the shock M 2 can be determined from the relation  
 


 9   These parameters were calculated using the relations  Analysis of Model A and B  Since both models A and B had same wave deflection angle the analysis gave similar results  For M 1 1.73, ratio of specific heats 1.4 and 12 degrees the ratio of pressure after and before the shock was calculated to be 1.920  The Mach number after the shock was found to be 1.25, it shows that it is still in supersonic regime and therefore the oblique shock formed is a weak oblique shock  Wave angle is also given by the sum of the Mach angle  and small angular difference Therefore      Here is given by the relation   1 1 2 4 \(M 1 2 226 1    That is, for a finite deflection angle the direction of weak oblique shock wave differs from the Mach wave direction  by an amount which is of the same order as   The Mach wave direction was calculated as 35 degrees and was calculated to be around 12 degrees. Sum of these two parameters gave the wave angle to be 40 degrees This is in good accordance with the experimental analysis of Models A and B, which is about 50 degrees  Pressure and temperature before and after the shocks were calculated from the isentropic relationships as the flow was assumed to be isentropic. The following values were determined  P1 = 0.197 bar = 19.7kPa P2 = 0.38 bar = 38kPa  T1 = 187.8 K T2 = 228.6 K  Analysis of Model C  Detached shock was observed near the nose of Model C This shock resulted as the wall deflection angle was greater than max Model C had was designed to have a blunt nose. In such a case, the shock wave remains detached at all supersonic Mach numbers. The flow immediately behind the shock was subsonic. It was difficult to determine the sonic line  The analysis of the flow fiel d associated with detached shock becomes very difficult because of transonic flow which prevails behind the shock. In such a case, the shape of the shock was observed and the detachment distance was determined. It becomes co mplicated to measure the properties in such rarefied flows. Hence the following parameters were found  The detachment distance was found to be 0.3cm from the nose of the model and the shape of the detached shock resembled conventional detached shock wave. However oblique shocks were noticed towards the downstream flow over the model as marked in the picture. The strength of the detached shock waves weakens with the formation of the oblique shock and further weakens until it becomes a Mach line, far away from the object. Unfortunately due to the unavailability of rectangular windows the entire section of the model could not be studied  6. F LUENT S OFTWARE A NALYSIS   Fluent is a general purpose CFD code based on the finite volume method on a collocated grid. Fluent technology offers a wide array of physical models that can be applied to a wide array of industries. Th is software was chosen to compute, analyze and model the flow conditions in and around moving models  The wind tunnel models were modeled in Gambit software package and two dimensional analyses was done. Two dimensional analyses were to simplify the complexities arising from turbulent flow model analysis. The top and side views of the models were meshed using Gambit and were exported to Fluent to model the flow conditions  The 2ddp version in Fluent was used. The flow was modeled using density based solver, k-epsilon viscous model was used and properties of air were assumed to be constant. The analysis was done for normal supersonic cruising conditions at 50000 ft at a pressure of 12000 Pa and temperature 216 K. The Mach number was set to about 1.8 for analyzing Model A and B and sonic Mach number for Model C  Analysis of Model B  The top and sectional side views of the model were plotted and meshed using Gambit mesh solver. The mesh was imported in Fluent and the operating conditions were set as stated in the previous paragraphs. The analysis gave contours of pressure, temperat ure, velocity, Mach number and turbulence      
 


 10    The above contour shows static pressure distribution across the model. It can be seen that th ere is a pressure rise near the nose when the flow first encounters the body  There is a gradual rise in pressure as shown by yellow region. This is due to the reas on that pressure increases after the bow shock about compression corners     The contour above gives the static temperature. A gradual rise in temperature is observed downstream of shock wave This is due to the supersonic flow around the compression around the corners. The static temperature distribution may help in selecting the materials required in certain areas to withstand the conditions at cruising  Mach number variation over the aircraft profile is plotted in the following page. A drop in the Mach number is noticed after the shock formation. This is due to the formation of oblique  shock wave at the nose. The following contour gives the turbulence intensity over the profile 
 


 11   Maximum turbulence is encountered at the wing tips. This could be attributed to the fact that vortex is generated near the trailing edges. This could be minimized by providing alterations to the design of the wing tips. The remaining region around the boundaries seems to be fairly stable and validates this to be a good design The sectional view of Model B was also analyzed. The resulting contours are presented here in the following page    
 


 12  Figure 15 \226 Static Pressure Contour side view of Model A    Figure 16 \226 Static Temperature Contour   Figure 17 \226 Velocity Magnitude Contour   Figure 18 \226 Turbulent Energy Contour  Figure 19 \226 Static Pressure Contour side view of Model B   Figure 20  226  Static Temperature Contour  Figure  21  226  Mach Number Contour  Figure  22  226 Strain Rate Contour 
 


 13 Analysis of Model A The analysis of Model A gave varying results owing to the variation in the profiles of the plan view and the sectional side view. The sectional side view is diamond type unlike that of Model B which is convex in shape. Both are however, ideal supersonic airfoils The sectional side view of Model A shows a rise in pressure behind the shock wave. This is because of the oblique shock wave formation around the compression corners. A drop in pressure is noticed at the expansion corner due to the formation of expansion fan at the convex corners The top view of Model A, when analyzed in Fluent gave the following contours. Formation of a high pressure region ahead of the wing profile sh ows the formation of a bow wave. This may induce very high wave drag and may not be a good optimized model    
 


 14 Analyses of Model C Analyses of Model C were done at Mach 1 to avoid divergence in the solution. The following results were obtained. The analyzed cont our clearly shows a high pressure region ahead of the nose This is the detached shock wave that is formed as seen in the shadowgraph. A region of high pressure exists after the detached shock      
 


 15      7  C ONCLUSION  The results from experimental theoretical and software analysis validate the fabricated models to work well over the supersonic regimes. Models A and B have reduced shock strength. This advantage could be explored in the design of a transcontinental supersonic passenger airliner. The models prove to be aerodynamically efficient and have lesser wave drag However, there were a few shortcomings in this approach The fabrication of such an ai rliner at a bigger scale could 
 


 16 prove to be a challenging task. Installation of engines would have to be looked into from a different aspect This work could be extended to study various other complicated supersonic aircraft profiles; the distribution of pressure, shock pattern and shock strength can be studied Unless efforts are continued on this regard, the viability of an efficient supersonic airc raft is likely to languish  R EFERENCES  1  United States Patent - 4828204 , Supersonic  Airplane by Gottfried O. Friebel, Bellevue, Wash  2 United States Patent \226 5518204, High Efficiency Supersonic Aircraft \226 Richard.R.Tracy  3  Jones, R., 1991. \223The Flying Wing Supersonic Transport.\224 Aeronautical Journal March    A b o o k o n Gas Dy nam i c by  R a t h i n a k ri s hna n    A st udy of Detache d S h oc k wave in 2-D  by Morton      Alperin, CALTECH, 1950 6 In trodu ction to fligh t  b y Ja m e s And e rson   Ai rcra ft De si gn  by  J o hn P F i e l d i ng  A CKNOWLEDGEMENT  The author wishes to express his hearty appreciation to all those people who have been instrumental in successful completion of this work. The author wishes to thank the principal, Dr. J. Shanmugam and management of Velammal Engineering College for their continual support. In particular, the author wishes to mention Mr Vickneshkumar, who has been a source of constant support throughout the project and Mr. Murugan for his kind cooperation and help during the fabrication of the models The author is indebted to Mr. Palani, IIT Madras for his invaluable guidance on FLUENT software and Dr Muruganandam, IIT Madras for his kind permission to conduct the tests in the wind tunnel facility at IIT Last but not the least; the author extends his warm thanks to his father, Mr. Arun Banerjee and his family who have been a great moral support throughout the course of this work       BIOGRAPHY Arijeet Banerjee is a Bachelor of Engineering \(Mechanical Engin eering\ student at Velammal Engineering College, Anna University, Chennai  India. He has completed his senior secondary schooling under the Central Board of Secondary Education. A keen aerospace enthusiast has taken part and won various competitions at both state and national levels. Visit the author at www.arijeetbanerjee.synthasite.com  
 


C. \(2005 Implementation and Use in an Existing Clinical Information System. In Connecting Medical Informatics and Bio-Informatics: Proceedings of MIE2005 - The XIXth International Congress of the European Federation for Medical Informatics, 328-333. IOS Press, 2005  4] Fetterman, D. M. Ethnography, 2nd ed. Thousand Oaks CA: Sage, 1997  5] Furukawa, N.  Ikeda, H.  Kato, Y.  Sako, H. D-Pen: a digital pen system for public and business enterprises. In Frontiers in Handwriting Recognition 2004: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition \(IWFHR-9 2004  6] Guimbreti  re, F. 2003. Paper augmented digital documents. In Proceedings of the 16th Annual ACM Symposium on User interface Software and Technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 UIST ?03 November 2003  7] Holman, D., Vertegaal, R., Altosaar, M., Troje, N., and Johns, D. 2005. Paper windows: interaction techniques for digital paper. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems \(CHI ?05 Portland, Oregon. New York: ACM, 2005  8] Kiewra, K., DuBois, N., Christian, D., McShane, A Meyerhoffer, M., &amp; Roskelley, D. Note-taking functions and techniques. Journal of Educational Psychology, 83 240-245, 1991  9] Kobayashi, K. Combined effects of note-taking/reviewing on learning and enhancements through interventions: a meta-analytic review. Educational Psychology, 26, 459-477, 2006  10] Liao, C., Guimbreti  re, F., and Hinckley, K. 2005 PapierCraft: a command system for interactive paper. In Proceedings of the 18th Annual ACM Symposium on User interface Software and Technology \(UIST ?05 Seattle, WA. New York: ACM, 2005  11] Livescribe. Pulse Smartpen [electronic device http://www.livescribe.com/, last retrieved May 28, 2008  12] Logitech. io2 Digital Pen [electronic device http://www.logitech.com/index.cfm/mice_pointers/digital_ pen/devices/408&amp;cl=us,en, last retrieved May 28, 2008  13] Norrie, M. C., Signer, B., and Weibel, N. Print-n-link weaving the paper web. In Proceedings of the 2006 ACM Symposium on Document Engineering \(DocEng '06 New York: ACM, 2006  14] Randall, D., Harper, R., and Rouncefield, M Fieldwork for Design: Theory and Practice. London Springer-Verlag, 2007  15] Searle, J. R. Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge Univ. Press, 1969  16] Sellen, A. J. and Harper, R. H. The Myth of the Paperless Office. Cambridge, MA: MIT Press, 2003  17] Signer, B. and Norrie, M. C. 2007. PaperPoint: a paper-based presentation and interactive paper prototyping 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






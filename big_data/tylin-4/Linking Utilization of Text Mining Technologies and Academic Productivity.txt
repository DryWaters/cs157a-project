Linking utilization of text mining technologies and academic productivity   Antonina Durfee Citizens Bank, RBS Americas  Antonina.V.Durfee@citizensbank.com  Verne Bacharach Appalachian State University  bacharachvr@appstate.edu     Abstract  With the advent of Web 2.0 digital data gathering and information structuring is taking more and more of knowledge workers time. Various types of knowledge workers including scientists, engineers analysts, and academicians use information to create knowledge. Their labor aims at problem solving 
based on gathered data and information structuring It is generally believed that knowledge workers rely heavily on information technologies to access and to assess information they need to be productive. This hypothesis rests on the assumption that the most productive knowledge workers are the ones who can efficiently utilize current information processing technologies. The primary purpose of this study is to examine the relationship between productivity of knowledge workers and their familiarity and use of modern text processing and complex TM technologies  1. Introduction  The advent of Web 2.0 popularized the Internet as a read and write tool enabling people to publish 
their latest opinions, research, and news in blogs social networks, rss feeds, wikies and online newspapers. As a result, a large quantity of digital textual information is collected in numerous text repositories. For example, Yahoo! clamed to index about 20 billion pages of information. A few years ago, the Internet archive collected about five times more unstructured information than the United States Library of Congress, the largest library in the world People who think for a living such as doctors lawyers, teachers, architects, financial analysts 
researchers and other knowledge workers report being swamped by information. Perhaps more importantly, they also report that they have very few tools to manage that information [1  o f c o ur se s u c h  tools exist so the open question is why do automatic textual knowledge discovery tools remain uncommon and unknown when information in textual databases the Internet being one of them, could give people and corporations a competitive edge Text mining \(TM\ or text analytics \(TA technologies aim at knowledge discovery from 
textual databases by isolating key bits of information from large amounts of text, by identifying relationships among documents, and by inferring new knowledge from them.  TM promises its users the ability to categorize, prioritize, understand and compare documents, and summarize the meaning of any particular document automatically skipping tedious searching, browsing and reading.  TM serves many objectives, such as content tagging summarization, categorization, document navigation thematic analysis, and language detection. It has been 
applied to web site analysis, streaming text, voice recognition output, authorship attribution, email and blog analysis. TM borrows its methods from well established computer science, natural language processing, information retrieval, artificial intelligence, and statistics fields Despite the impression of a rarity of text analytics, content management, and TM technologies, in reality the text analytics industry is growing and maturing to supply a marketplace with a variety of heavily promoted products. At the beginning of new millennium, Tan reported that 
eighty percent of information held in the companies is in textual form h ile an a m oun t of an a l y zed  textual information by knowledge discovery technologies in 2004 was only 17%, that number almost doubles to 33% by the end of year 2006 TM tools range in familiarity, availability usefulness and ease of use [4  Sta n d a r d  w o r d  processors, such as MS WORD with its simple summarization functions, are familiar, widely available, and easy to use. Other intelligent TM technologies such as SPSS Clementine and SAS Text Miner are less familiar and less available to most 
knowledge workers. The biggest impediments blocking the acceptance of TM technologies may be their perceived complexity and their relatively mysterious nature. Both arguments make it difficult to convince companies to invest in buying and utilizing TM technologies Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 
 


There are many design science papers proposing robust TM algorithms reported in the literature and there are numerous anecdotal accounts of successful real world TM applications. There are very few empirical studies that have investigated an individual adoption of TM by knowledge workers and explain why the use of TM tools remains infrequent. This paper aims at exploring the relationship between the utilization of text analytics technologies and productivity of knowledge workers. First, we survey the current state of affairs of text analytic and TM tools by categorizing them into information retrieval standard TM, and intelligent TM ones. Then we investigate the connection between levels of awareness and use of different types of text analytic technologies and productivity of academicians from a regional comprehensive university by conducting exploratory statistical analysis derived from survey data. This paper starts with a discussion of the previous work on knowledge workers productivity and the description of text technologies to support a list of research hypothesis. It follows with a description of the research design and analysis of results. The paper concludes with discussion on limitations and future work   2. Literature Overview  The literature review describes TM technology and its tasks. It continues with a description of the concept of productivity knowledge workers a relationship to information overload resulted from technology, task and behavioral traits  2.1. Foundation and taxonomy of TM  Text has richness of interpretation and meaning with a complicated and ambiguous multilevel structure of tens of thousands of dimensions Structural principles exist in the formation of words morphology of language\ the creation of grammatical sentences \(syntax\d representation of meaning \(semantics\which vary within every individual document and language. The authors and readers of the text often represent the same semantics using different words \(synonymy\ or describe different meanings using words that have various meanings \(polysemy\ [6   TM is an extension on knowledge discovery from databases \(KDD\rocess which identify valid novel, potentially useful, and ultimately understandable patterns in data   T M o r data  mining on textual data is a process of discovering  novel patterns and associations useful for particular purposes from textual databases 8,9,10,1  Depending on knowledge novelty that can be ex tif ied 3 t y p e s of dis c o v eries   w h at  I don t know I don t know \(the most difficult knowledge to mine resulting in novel investigation what I don t know I know \(semi-novel investigation and what I know I don t know \(non-novel investigation This paper builds on the ideas of w h o  classified mining according to types of data to be mined and the types of discovery to be performed Tables 1, 2\ dividing TM into information retrieval \(IR\standard TM, and \(truthful\ntelligent TM Information retrieval IR\ is the process of locating the subset of the documents that are deemed to be relevant to a posed query Standard or real TM is a process of finding semi-novel useful patterns  lth oug h  lex ical s y n t actic pattern s a n d n e w themes already exist in text, they are yet unknown to a reader and the discovery thereof is new Intelligent  TM can be regarded as human-like capability for comprehending complicated structures and creating knowledge outside of data collection  e.g   Which business decisions are prompted by discovered patterns? How can the linguistic features of text be used to create knowledge about the outside world? Does a newly discovered theme in a text collection reflect or validate the reality? Could the hypotheses prompted by found linkages be refined and formulated   Type of investigation and data Non-novel investigation Semi novel investigation Novel investigation Numeric data \(overtly structured alphanumeric Database queries Standard data mining Intelligent data mining Text metada \(structured textual data Information retrieval of metadata Standard metadata mining Intelligent metadata mining Textual data \(inherently covertly structured Information retrieval of full texts Standard text mining Intelligent text mining            Table 1. A classification of data and TM   Information retrieval systems are based on the assumption that the user has a classification system in mind that separates the relevant documents from nonrelevant ones. Traditionally, IR systems are query-based, and they assume that users can describe their information needs explicitly and adequately in the form of a query and rely of language representation as a bag of words The danger of the keyword approach is in using different keywords by different individuals to describe the same concept synonymy\while creating a query. A part of a document that does not include query-matching keyword is ignored by conventional IR systems.  IR can be applied for text categorization, text routing and text filtering Standard TM performs feature extraction and text categorization based on features that enables Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 
 


summary creation and document comparison. Those features are formed not only by index terms or keywords but by their co-occurrences. Text categorization assigns documents to pre-existing categories, called topics or themes  t an dard TM uses statistical and natural language processing methods to explore patterns in text. This general task is accomplished by specific mathematical approaches clustering, feature extraction and thematic indexing 1 u t ze an d Silv er s t ei n  1997\tate that speech recognition, language models, parsing, and machine translations are not TM tasks  T h e res earch ers con s ider clu s teri n g   information extraction, question answering as typical TM tasks. Intelligent TM combines the mathematical approaches of IR and standard TM together with machine learning \(ML\ and artificial intelligence methods to enable interaction between the TM tool and an investigator \(knowledge worker, decision maker  Type of investigation Non-novel investigation Semi novel investigation Novel investigation Information retrieval of full texts uses exact match and best match queries Standard text mining uses statistical methods Intelligent text mining uses interaction between investigator and a tool, AI Compose a query Feature extraction Validate the discovered theme with reality Index text collection Thematic indexing What business decision are implied by Search text relevant to a query Cluster and categorize text Make inferences of textual content Hypothesis formulation Retrieve relevant document Discover link between themes in text \(rule induction Extends knowledge based on extracted features Locate a \(set text/documents Visualize themes/relationships in/among documents Description of Tasks Search and locate relevant to a query document/piece of a document, document extraction, text routing and filtering Create automatic thesauruses, summary topic hierarchy, automatic dictionary, classify new text in a new categories author attribution Create additional knowledge/ hypothesis about reality, predict future state of reality Features                Table 2. Features and tasks of IR, standard and intelligent TM systems   Intelligent TM discovers new patterns that enrich domain knowledge or validate already existing patterns against data domain. In other words intelligent TM should be able to build predictive models or hypothesis. Intelligent TM brings some learning component into analysis by, for instance combining it with predictive data modelling In  an attempt to recognize the semantic peculiarities of text, standard and intelligent TM methods use more elaborated text encoding and representation algorithms \(vector quantization, parsing\ than simple bag-of-word methods  2.2. Productivity and knowledge workers  Knowledge work is an inherently cognitive process which results in various outputs such as analysis, evaluations, instructions, programs, plans decisions o w ledg e work ers are people w i t h a  high degree of education and experience who are eager to see new patterns other many not and turn new ideas into new products and services. The most productive knowledge workers tend to employ the most efficient work meth o th e qu es t i on arises, is there a connection between TM technologies impact knowledge worker productivity In order to examine relationships between productivity, familiarity with and use of text analyzing technologies, it is necessary to have a reliable and valid measure of productivity. For example, in industrial settings, productivity might be measured as the cost of producing a unit of some product with time. In academic settings there are several measures of productivity mostly used in a tenure process. Those measures include but are not limited to scientific publications, number of scientific presentations at professional conferences, or number of journal articles reviewed per year. For this study academics were chosen as an optimally defined subset of knowledge workers because their productivity is reasonably well defined as is the target population. Since academicians are judged and promoted based on their research quality and output it was possible to index productivity by assigning a productivity score to every individual academic in the study. In the present study, this index was used to examine a model relating the use of technologies to productivity in an academic setting Many researchers have investigated the relationship between productivity and the use of information technology in industry   Barnerjee \(2006\ound evidence that suggests a negative influence of technology on productivity, or existence of a productivity paradox at the individual, industry, and national level  Productivity paradox is a perceived lack of productivity gains that result from increased expenditures on information technology. Lehr and Lichtenberg \(1999\ound a positive impact on computers on productivity by studying firm-level  T h ere h a s been littl e research don e w h et h e r  a productivity paradox exists in knowledge worker utilization of information technology While investigating productivity in knowledge work which became a significant portion of work in organizations over past 30 years, Drucker proposed six factors of knowledge worker productivity  Knowledge work productivity depends on a task Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 
 


relies on continuing innovation and learning, requires self management and defines not by quantity of output but by quality of it.  It depends on willingness to work for the organization in preference to all other opportunities o w ledg e  w o rk ers n eed to be  motivated and self disciplined enough to seek new ways such as technology to solve problems H1a: The level of productivity of knowledge workers relates to the to the knowledge about the availability of TM technology H1b: The level of productivity relates to the use of TM products The use and misuse of information technology become critical in times of information overload Wurman \(1990\defined information overloads is the inability to extract needed knowledge from large quantity of information r an d Men g i s 2004\cribed five causes of information overload among which are accelerated production of information, more efficient distribution of information, information tasks and processes, and information technology misuse ll f i v e causes  influence the two fundamental variables of information overload wh ich are the information processing capacity which is for example influenced by personal characteristics and the information processing requirements which are often determined by the nature of the task or process 31,3 r a w ings f r o m t h e res earch abov e are  condensed to the following hypothesis  H2a: Knowledge workers level of information overload will relate to the awareness of availability of TM products that aim at reducing it H2b: Knowledge workers level of information overload will relate to actual use of TM products that aim at reducing it Task complexity is connected to the result of knowledge work based on information seeking and processing behaviou a rv elin a n d Ingw ers e n  2004\tended information seeking research toward tasks and technology by providing a general analytical model of information seeking and retrieval  a u t erberg 1992 piricall y establish e d a need of a person to have some knowledge about dialogue structure of technology and task structure while solving a complex task [35   T o in v e st ig ate t h e  link between task complexity and use of TM technology the following hypothesis are postulated H3a: Cognitive task relates positively to an increase in the awareness of availability of TM technology H3b: Cognitive task relates to a use of TM technology Research on information overload in management and business reports the dual nature of a relationship between performance of an individual and the amount of information to which an individual is exposed [36e s earch ers h a v e f o u n d t h at th e  quality of decisions made by people correlates positively with the amount of information up to a certain point. As the amount of information increases performance rapidly declines u lting i n poorer  information processing and residual information overload [4  Numerous studies have focused on the impact of individual psychological characteristics on information processing behavior.  Personal traits qualification or experience are other important elements that determine at which point information overload may occur. While earlier studies reported limits in personal capacity to process information 32,4 m o re recen t s t u d ies report s p ecif ic li m itatio n factors such as personal skills [44 th e lev el o f  experien e m o ti vation of a pers on 47 the Big Five personality traits [48 o r co gni t i ve st yl e   F o rd et al 20 01 obs erv e d cog n iti v e s t y l es   levels of prior Internet experience and perceptions study approaches, and age and gender as contributing variable to a search behavi  T h e res e arch ers  found that retrieval effectiveness was linked to male gender, low cognitive complexity, and cognitive style. Navarro-Prieto et al. \(1999\pted to relate cognitive personal characteristics of novice and experienced searchers to web searchin e b  expertise was defined as the number of years that searchers used the Internet, the number of years of search engine use, and their primary reason for their use of the Internet \(searching, emailing or shopping  T h ey con c lu ded th a t e x pertis e i n kn o w ledg e  seeking relates to level of experience in knowledge organization and problem representation. The final premise links a level of knowledge of about existence and capabilities of technology with its use H4: The level of awareness concerning availability and capabilities of TM technology relates to its use   3. Research Model  Unlike empirical research of technology adoption that builds on the theoretical concepts of peoples perceptions and attitudes toward technology us is s t u d y ex a m i n e t h e relation s h i p bet w een characteristics of TM technology offered on the market and its use by a specific group of knowledge workers, academics. The model represented in Figure 1 was built on an assumption that the frequency of information technology use depends to some extent on familiarity with the technology; if academics do not know that a particular technology is available then it is reasonable to assume that that technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 
 


will not be used. Second, we included in the model an information overload variable. We hypothesize that the more overloaded people become the more likely they start seeking and use technologies to manage their information overload We developed a research model that combines aspects of TM technology and users characteristics and tasks. The model includes three sets of variables all related to the dependent variable, level of knowledge workers TM usage. The three independent sets of variables include \(1 conventional for IS studies individual control 2\jobrelated control variables \(i.e. type of cognitive task performed, productivity, overload\nology-level awareness variable. Our method of study includes two phases: reviewing features of the existing TM products and surveying knowledge workers cognitive tasks, productivity, information overload, knowledge and use of available technological aid   Figure 1. Research Model  4. Data Collection  A two step data collection process was performed. Firstly, we surveyed the best-known TM products whose feature and tasks are summarized in Table 3. We intentionally omitted software whose primary focus is statistical or mathematical engines not TM \(e.g. MATLAB, Statistica\e collected a list of most known TM products from websites of NEMIS \(Network of Excellence in TM and its Application in Statistics\ and kddnuggets \(forum of knowledge discovery from database professionals and academicians\dly, we administered an online survey to investigate the perceptions of knowledge workers as consumers of TM products The university professors and researchers were chosen as a participating group for a survey because they are active users of textual information in their knowledge creating processes and they follow the six factors of knowledge work posed by  Universities are required to have academically qualified personnel, whose output is quantified by a number of publications, and other outputs on intellectual property. An internet-based survey was made available to all faculty members at a mid-sized comprehensive state university located in the Southeastern U.S.  The survey consisted of 56 questions. 30 yes/no questions were administered to evaluate the level of need, awareness and use of document handling or TM. Questions on research productivity and intensity, and information intensity were open ended \(see Appendix\ yielding 94 people respondents. After filtering the missing data 58 responses were usable for our analysis. The respondents ranged anywhere between 27 to 66 years old and from graduate student to assistant to full professor, 55% of them were female and 45% male from liberal art to business departments. Data was be analyzed using SPSS  5. Results and analysis  5.1. Feature comparison of available TM tools  There are number of tools from such moguls as IBM and more narrow focused SAS to academiabased Text Miner and webSOM that incorporate different mathematical algorithms to solve text related problems. The products are described based on the domain they can be used in, the status of their development, their knowledge sophistication and representation methods. The majority of the presented in Table 3 tools use the following data preparation routines: stemming, synonym list composition, text parsing, and dimension reduction for text filtering and representation Group 1 represents IR tools which assist users in a process of non-novel discovery and navigation within single or multiple documents by choosing satisfactory matches to a submitted query. IR systems are query-based methods, which rely heavily on the use of term \(keywords, items, indexes\traction, i.e SONIA  TextMiner, Sapere Some of IR systems are vertical and domain oriented. As a trend, IR tools use machine learning techniques and support multilingual retrieval from different file formats, e.g ISYS  supports 125 file types DataSetV and dSearch use fuzzy logic for constructing a better formulated query and searching Group 2 represents standard TM tools which determine features in text, create themes based on those features, build links among different themes and text categories, visualize text features and/or summarize text. Main characteristics of these systems are integration of clustering and categorization Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 
 


algorithms, graphical representation of the results and an attempts to hide mathematical complexity. An emerging characteristic is enabling work on-line in real time with different text formats consolidated from various databases. For instance Copernic  searches corporate intranets, servers and public websites and uses vector representation of documents to create unparallel indexes that enable to launch federated search on many indexes. A user can track the appearance of the index in various sources and pinpoint the key concepts of texts to extract the most relevant sentences to produce a condensed version of the original text \(summaries\d ignore irrelevant text Text Summarizer and Copernic Summarizer  compose summaries that not only highlight the main sentences in a document but construct new ones based on the main ideas introduced in text Enkata  enables users not only to identify main concepts and summarize the meaning of a document but to track concept migration and evolution among the documents. As a trend, TM systems target specific vertical business problems, such as e-mail filtering or categorization \(e.g dtSearch  Klarity edical text summarization, or financial news organization \(e.g Factiva   Tools quantity Intended Domain Knowledge Representation Additional Features Group1 Retrieval IR 12 Keyword listing Searching Navigation Browsing Semantic Retrieval Visualization concept mapping Summarization Tracking Routing Summarization Visualization Hypothesis creating Group 3 Intelligent TM 12 Any Language independent Any, e.g Business Intelligence Email Routing E-commerce Knowledge Management Language independent criteria/sorting results, spider technology multilanguage recognition relevancy Group 2 Standard TM 24 Any Multi-tier extracting of terms, online access multiformat support            Table 3. Aggregation of tasks and features of TM products  Group 3 combines intelligent TM tools which are represented by very few products SAS Text Miner and SPSS Predictive Text Analytics  Clementine order to be called intelligent, tools satisfy at least one of the following criteria: adapt in a functional way to a new situation presented by new data \(produce new knowledge of outside world offer a solution to a new situation \(propose possible actions based on analyzed content\ew situations to old ones \(compare content of documents, build hierarchy of knowledge from documents\e a decision on an asymmetric information or ill-defined context \(learn from content of presented documents\ intelligent TM products are tool boxes with different algorithms that require high user proficiency. The tools can handle different types of data so a user can construct complex models for cross validation and verification They offer great graphical capabilities which require an expert to interpret. As a trend those products tend to provide a unified graphical interface to create a flow of processes to build predictive models. Binding sophisticated data and TM algorithms requires very specific mathematical and domain expertise from those who wish to apply them for effective problem solving  5.2. Level of knowledge workers awareness and use of TM products   To assess the reliability of the questionnaire Cronbach s alpha coefficients for the various subscales were calculated as the most widely used measure of internal consistency.  An alpha coefficient of .70 or greater for an existing instrument is generally considered an acceptable measure of reliability In th e cu rrent stu d y  T a ble 4 sh o w s  that the Cronbach s alpha for all subscales except the Information overload construct met or exceeded the required value.  Research productivity construct is a number of intellectual contributions in last five years On average, our respondents produce 4.7 intellectual contributions in last 5 years and spend 14.7 hours a week doing that.  Information overload is a number of emails sent or received, number of web pages and searches related to research processed weekly. Our respondents process on average 21 pieces of digital information daily. The average years of Internet use for research purposes was reported as 10.4 years. We computed all values by averaging the responses of all respondents. The five year period was chosen for two reasons. First, TM products became available and aggressively marketed in this time frame. Second, we wanted to insure active engagement of respondents in knowledge work Cronbach s Alpha RP Research  productivity 4 58 0.333 24.5 4.687 31.885 0.763 IO Information Overload 4 58 4 71.25 21.6 239.59 0.667 CT Cognitive tasks involved in a process of knowledge creation based on text analysis 13 56 1 1.54 1.253 0.027 0.704 TA Level of technology awareness concerning the availability of certain features in TM products 13 56 12 1.592 0.044 0.815 AU Self reported use of various TM products and features 14 56 11.86 1.6097 0.022 0.771 Min Max Mean Var Construct Description  question N                    Table 4. Descriptive statistics and reliability of constructs Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 
 


The correlations and tolerance level values among all independent and control variables were examined to detect any potential problems with multicollinearity. Table 5 presents the correlation matrix showing Pearson s correlation coefficients for all constructs. Information overload \(IO\d with gender negatively, indicating that female researchers receive/send more emails and do more webpage surfing than male respondents, which support findings in ogn iti v e ta s k is pos itiv e l y  correlated with gender, because men answered yes to greater number of cognitive tasks than females Interestingly, longer Internet use is negatively correlated with  awareness of TM technologies \(TA availability. As expected, cognitive task \(CT\ is positively correlated with an awareness of TM features availability \(TA\ which in turn is highly positively correlated with the willingness to use \(AU TM technology Hierarchical regression analysis was the primary analytical method employed. In conducting our hierarchical regression analysis we followed the same procedure as [5 is olate th e inf l u e n ce o f each s e t  of predictor variables on dependent variable. Each block of variables was added sequentially to our regression model resulting into more complex model on each stage. The increased proportion of variance explained R 2 with corresponding p-value\was used to assess whether each block of predictor variables was statistically significant. The standardized regression coefficients determined the direction of effect of each independent variable on actual use. The results are presented in Table 6 In examining demographic control variables we found that neither gender, age, nor prior internet experience were significantly related to the level of TM use. Prior Internet became a significant antecedent with technology awareness mediating TM usage. Contradicting the results of previous studies the longer people use Internet, the less they know about availability of new cutting-edge TM technology and less they use it. One tailed tests of significance were employed to interpret the regression results. Next, we added the job-related variables corresponding to H1-2 simultaneously to the regression model and examined the change in proportion of variance explained R 2 ether with its level of significance and directions of beta coefficients. When we added job-related variables our model became significant at 0.1 level explaining 22.1% of variance R 2 12 p 0.062\. Next technological awareness variable from H4 was added into a model. The amount of variance explained increased dramatically to 65. 8 R 2 60.4 p  0.000\These results appear as Model 3 in Table 6  H1a was not supported The levels of knowledge workers productivity did not force them to gain more awareness of existing TM products which potentially could help them in their knowledge work  150 p 271 H1b was supported Surprisingly the level of productivity is negatively related to the use of TM products   210 p 028\onfirming productivity paradox  H2a-b were not supported The amount and burden of information overload do not related to the use of TM   0.23 p 805\ and did not force knowledge workers to obtain awareness of existing technological help   122 p 364 which seems counterintuitive H3a was supported The quantity and complexity of cognitive tasks relate positively to an increase in the awareness of availability of TM products   312 p 026 H3b was not supported The complexity and number of cognitive tasks to be performed by knowledge workers do not relate to an actual use TM products   027 p 782 H4 was supported When knowledge workers knew about availability of TM technology to complete their cognitive tasks they employed it, making technology awareness the strongest predictor of actual use 758 p 000  Age Gender Experience Research Productivity Information Overload Cognitive Task Technology Awareness Actual Use Age 1 Gender 0.214 1 Experience 0.205 0.115 1 Research Productivity 0.106 0.142 0.252 1 Information Overload 0.033 275 0.074 0.041 1 Cognitive Task 0.018 303 0.09 0.027 0.221 1 Technology Awareness 0.099 0.007 298 0.2 0.192 352 1 Actual Use 0.145 0.07 0.06 0.232 0.096 0.248 727 1                       Correlation is significant at the 0.05 level \(2-tailed Correlation is significant at the 0.01 level \(2-tailed  Table 5. Correlation coefficients  Model 1 Model 2 Model 3 Demographic Job-related Tech. awareness Controls controls controls Age 0.179 0.208 0.7 Gender 0.133 0.215 0.089 Prior Internet Experi e 0.74 0.057 0.213 Research Productivity 0.324 0.21 Information Overload 0.07 0.023 Cognitive Task 0.264 0.027 Technology Awareness 0.758 N565656 R 2 0.04 0.221 0.658 Adjusted R 2 0.019 0.12 0.604 Model F 0.683 2.181 12.342 p rior model R 2  0.181 0.436 F for R 2 3.572 57.294 Model Statistics Notes: Dependent variable Actual Usage of TM products Values reported in top half of a table are beta values p<0.10; **p<0.05 Control Variables Job-related Variables Technology Variable   Table 6. Hierarchical regression results  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 
 


6. Discussion, limitations and conclusion  Taken as a whole, nearly 70% of the variance in a knowledge workers level of TM usage was explained by the constructs in Figure 1. Three out of seven hypotheses in our model were supported by the data. Longer experience with Internet, the higher knowledge of existing TM products; the more likely knowledge workers will incorporate them in their job. However, more intense usage of TM does not correspond to higher productivity. Possible explanation of negative impact of use of TM on research productivity is that TM products are cumbersome to use, as reported by many analysts and thus do not increase productivity. It seems that people invest too much time in learning how to use technologies rather than producing new knowledge in terms of scientific contributions TM products provide wide range of capabilities for text searching, retrieval, summarization, analysis and visualization. Some vendors offer tools for retrieving information, some for performing traditional TM operations, such as classification and summarization, some offer toolboxes for intelligent TM. According to a principal of a consulting agency on analytics, a well tuned TM system still gives only 85% accuracy at a very high cost ll o f t h os e  capabilities attempt to echo cognitive processes and tasks that researchers or analyst deploy while finding reading and analyzing relevant textual data in order to come up to some conclusions or predictions. Our empirical research confirmed that there was no task that TM vendors try to automate which is not performed by anyone of our respondents manually in their knowledge work. The large availability of digitalized text and information overload \(with 48 received and 23 sent emails weekly, which translates in 9.3 and 4.5 emails daily colossal number of letters received or send daily for a researcher 20 years ago\makes the need for effective TM tools obvious A market of TM software tools is responding quickly to the growing need. Our empirical research did not confirm the relationship between pressure experienced by knowledge workers and their tendency to use TM products. While 87% of respondents used IR tools, only 18% of them used TM products declining to modest 7% of those who used intelligent TM products. This drastic numbers are due to poor visibility of TM and intelligent TM products. While 87.5% of people know about availability of IR tools, only 31% and 18% of respondents know about TM and intelligent TM tools respectively Another finding supports productivity paradox notion. It appears that intelligent TM solutions of today are possible for vertical application but they require highly skilled professionals and lack user friendliness. They incorporate not only processes of TM but also include domain specific expertise in form of ML inference from domain specific data. To obtain user friendliness, TM industry needs to settle with fixed terminology and standards to indicate industry maturity.  Another open question remains in all these applications: how to integrate domain knowledge with the results of TM tools. The interpretation and evaluation of the discovered patterns are still cumbersome and include intensive human involvement. The requirements for welltrained users who can interact with TM systems are still obligatory. Managers - heavy consumers of textual information - rarely have the time or technical expertise to master complicated TM applications and to gain the experience to recognize valuable discovered patterns One can argue about the limitation of the chosen technologies and number of respondents. The information about TM products was gathered mostly from webpages, white and technological papers of the companies, industry reports and scientific conferences proceedings. As a part of our future research we plan to survey the needs of users from more diverse settings In the present study, we explored the relationship between productivity of knowledge workers, their level of familiarity and use of text processing and complex TM technologies. Our empirical research confirmed that people who know about the availability of TM tools are more likely to use them and that the cognitive tasks that people perform in a process of creating knowledge correlate with users  awareness of availability of TM tools. Interestingly neither information nor research intensity can predict a level of cognitive tasks for a researcher. Gender influences both information intensity and level of cognitive tasks values. Number of years spent using Internet for doing research influences also information intensity that a researcher has. More experienced users have higher information overload and thus can benefit from TM more  8. References  1  Cooper, D. \(2006\. "Knowledge Workers." Canadian Business 79\(20\: 59 2  Ferneda et. al, 2002 3  Tan, A. \(1999\M: The state of the art and the challenges PAKDD-99, Workshop on Knowledge Discovery from Advanced Databases \(KDAD'99 Beijing, China 4  Eckerson \(2007\, TM, Teradata Warehouse Institute San Diego, CA, August, 2007 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 
 


5  Fayyad, U. and R. Uthurusamy \(2002\Evolving Data Mining into Solutions for Insights Communications of the ACM 45\(8\8-31 6  Manning, C. and H. Shutze \(1999\ Collocations Foundations of Statistical Natural Language Processing Cambridge, MA, The MIT Press: 141-177 7  Fayyad, U., G. Piatetsky-Shapiro, et al. \(1996\. "The KDD Process for Extracting Useful Knowledge from Volumes of Data." Communications of the ACM  39\(11\: 27-34 8  Dörre, J., P. Gerstl, et al. \(1999\M: Finding Nuggets in Mountains of Textual Data KDD-99, Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Diego USA, ACM 9  Thuraisingham, B. \(1999\ata mining: technologies techniques, tools, and trends. CRC Press Florida 10  Nasukawa, T. and T. Nagano \(2001\Text analysis and knowledge mining system." IBM Systems journal  40\(4\: 967-984 11  Hearst, M. \(1999\ntangling Text Data Mining 37th Annual Meeting of the Association for Computational Linguistics \(ACL'99\ryland, USA, ACM Press 12  Berson, A. and S. J. Sminth \(1997\ata warehousing data mining, and OLAP  13  Kroeze, J., M. Matthee, et al. \(2003\ Differentiating Data- and Text-Mining Terminology  in SAICSIT 14  van Rijsbergen, C. \(1979\ Information Retrieval Second Edition London:, Butterworths 15  Mach, R. and M. Hehenberger \(2002\. "Text-based knowledge discovery: search and mining of lifescience documents." Drug discovery today 7\(\(11 Suppl.\ S89-S98 16  Riloff, E. and L. Hollaar \(1996\"Text Databases and Information Retrieval." ACM Computing Surveys  28\(1\: 133-134 17  Lewis, D. \(1992\ature Selection and Feature Extraction for Text Categorization Speech and Natural Language Workshop 18  Hand et al. \(2002\, Data Mining Techniques 19  Schutze, H. and C. Silverstein \(1997\Projection for Efficient Document Clustering SIGIR 97 Philadelphia, PA, USA, ACM Press   New York, NY USA 20  Kloptchenko, A. \(2003\etermining Companies  Future Financial Performance from Their Past Quarterly Reports First Annual Pre-ICIS Workshop on Decision Support Systems, Seattle, USA 21  Davis, G. \(1999\A research perspective for information systems and example of emerging area of research." Information Systems Frontiers 1\(3\: 195203 22  Davis, G. \(2002\. "Anytime/Anyplace Computing and the Future of Knowledge Work." Communications of the ACM 45\(12\: 67-73 23  Peslak, A. \(2005\. "The Educational Productivity Paradox." Communications of the ACM 48\(10\: 111114 24  Brynjolfsson, E. \(1993\ "The Productivity Paradox of Information Technology." Communications of the ACM 36\(12\: 67-77 25  Jones, E. and C. Chung \(2006\"A Methodology for Measuring Engineering Knowledge Work Productivity." Engineering Management Journal  18\(1\2-38 26  Barnerjee, D. \(2006\ "Information technology productivity growth, and reduced leisure: revisitng end of history"." Working USA: The Journal of Labor and Society 9: 199-213 27  Lehr, B. and F. Lichtenberg \(1999\Information technology and its impact on productivity: Firm-level evidence from government and private data sources The Canadian Journal of Economics 32\(2\: 335-362 28  Drucker, P. \(1999\. "Knowledge -Worker Productivity: The Biggest Challenge." California Management Review 41\(2\9-94 29  Wurman, R. S. 1990. Information anxiety. What to do when information doesn t tell you what you need to know. New York: Bantam Books  30  Epper, M.J., & Mengis, J. \(2004\he concept of information overload: A review of literature from organization science, accounting, marketing,, MIS and related disciplines The Information Society 20 5\5-44 31  Galbraith, J. R. 1974. Organization design: An information processing view. Interfaces, 3: 28-36 32  Tushman, M. L., & Nadler, D. A. 1978. Information Processing as an Integrating Concept in Organizational Design. Academy of Management Review, 3: 613-625 33  Byström K., Järvelin K. \(1995\, Task complexity affects information seeking and use,  Information Processing and management, vol. 31, issue 2, pp 191213 34  Järvelin, K., & Ingwersen, P. \(2004\. Information seeking research needs extension toward tasks and technology. Information Research, 10\(1\ No. 212   35  Rauterberg, M., \(1992\ Method of a Quantitative Measurement of Cognitive Complexity Human-Computer Interaction Tasks and Organizations 1992, pp. 295-307  36  Schick, A. G., Gorden, L. A., & Haka, S. 1990 Information overload: A temporal approach Accounting Organizations and Society, 15: 199-220 37  Ackoff, R. L. 1967. Management misinformation systems. Management Science, 14: 147-156 38  Jacoby, J. 1984. Perspectives on information overload Journal of consumer Research, 10: 432-436 39  Keller, K. L., & Staelin, R. 1987. Effects of quality and quantity of information on decision effectiveness The Journal of Consumer Research, 14: 200-213 40  Malhotra, N. K. 1984. Reflections on the information overload paradigm in consumer decision making. The Journal of Consumer Research, 10: 436-441 41  Chewning, E. C., Jr., & Harrell, A. M., 1990. The effect of information load on decision makers cue utilization levels and decision quality in a financial distress decision task. Accounting 42  O Reilly, C. A. 1980. Individuals and information overload in organizations: Is more necessarily better Academy of Management Journal, 23: 684-696 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


43  Jacoby, J., Speller, D. E., & Berning, C. K. 1974 Brand choice behavior as a function of information load: Replication and extension. The Journal of Consumer Research, 1: 33-43 44  Owen, R. S. 1992. Clarifying the simple assumption of the information load paradigm. Advances in Consumer Research, 19: 770-776 45  Swain, M. R., & Haka, S. F. 2000. Effects of information load on capital budgeting decisions Behavioral Research in Accounting, 12: 171-199 46  Ford., N., D. Miller, et al. \(2005\eb Search Strategies and Human Individual Differences: A Combined Analysis. Journal of American Society for Information Science and Technology 56 \(7\: 757-764 47  Muller, T. E. 1984. Buyer response to variations in product information load. Psychological Review, 63 81-97 48  Heinström, J. \(2003\Five personality dimensions and their influence on information behaviour Information Research 9 \(1 49  Navarro-Prieto, Scaife, Rogers  \(1999\ognitive Strategies in web Searching 50  Jenkins, C., C. Corritore, et al. \(2003\Patterns of Information Seeking on the Web: A qualitative study of domain expertise and web expertise." IT& Society  3 \(winter \4-89 51  Nunnally, J. C.  \(1978 Psychometric theory 2 nd  ed.\w York:  McGraw-Hill 52  Venkatesh, V., Morris, M, \(2000\, Why Don't Men Ever Stop to Ask for Directions? Gender, Social Influence, and Their Role in Technology Acceptance and Usage Behavior MIS Quarterly Vol. 24, No. 1 pp. 115-139 53  Galliva, A., A. Spitler, et al. \(2005\Does Information Technology Training Really Matter? A Social Information Processing Analysis of Coworkers' Influence on IT Usage in the Workplace Journal of Management Information Systems 22\(1 153-192 54  Grimes, S. \(2006\Search for Meaning." Intelligent Enterprise 9\(1  Appendix 1  age , 2. gender, 3. position, 4. department Research Intensity and Experience how many hours per week do you spend doing your research reading, collecting, designing studies, analyzing data, writing how many conference presentation have you made in the past 5 years; how many conference papers have you published in the past 5 years; how many articles have you published in scholarly journals in the past 5 years; how many journal articles have you referred in the past 5 years; how many grant proposals have you submitted in the past 5 years Information Intensity and Digital Media Dependency Please assess approximately how many emails do you receive daily; how many emails do you send daily; how many pages of  research information do you read daily; how many websites relevant to your research do you visit daily; how many web searches do you make daily; how many years have you used the Internet as a tool for doing your academic research Text-related activities and the use of appropriate technology yes/no Information Retrieval do you search for text documents; are you aware of computer based search technologies that can help you to find a document; do you use computer, online or digital library search engines  \(e.g Google, ask Jeeves, Microsoft msn\ to locate relevant research documents; do you retrieve relevant documents; do you know about computer document retrieval technologies; do you use search engines to prompt you to a location for the relevant documents online;  do you use search your computer s options to open documents that you have found; do you browse documents before considering if they are relevant to your research; do you know about computer technologies that can help you  open a document do you use computer technologies that display the content of documents \(e.g., word processor, Adobe Reader, etc.\; do you store copies of relevant documents either as print out hardcopies or in digital softcopy form ; do you know about computer technologies that help you store and retrieve documents; do you use a computer based file organizer technology such as Windows Explorer to store and retrieve your documents  TM do you organize and sort your textual documents; do you know about computer technologies that sort and organize documents; do you use computer technologies like Windows Explorer to organize and sort documents;  do you compare content of your documents when you analyze them ; do you know about computer technologies that help to compare the content of documents; do you use a computer technology like Compare to compare digital documents; do you try to identify main concepts in documents; do you know of  computer technologies that can identify main concepts in documents; do you use computer technologies to locate main concepts or topics in documents \(e.g., Enkata, Copernic\; do you keep notes of or organize main points of documents relevant to your research; do you know about a computer technology that can assist you in keeping track and organizing main points in documents; do you use a computer technology to summarize main points of document \(e.g., Word Autosummarizer or Monarch\; do you build taxonomies/hierarchies of documents by locating and tracking main concepts introduced in them; are you aware of computer technology that can build a hierarchy of your documents based on the main concepts relevant to your research; do you create taxonomies or hierarchies of documents using appropriate computer technology \(e.g., Inxight, Leximanser, Factiva  Intelligent TM do you formulate hypothesis based on documents that you ve read do you know about a computer technology that can help you to come up with the hypothesis from the research literature; do you use technology \(ex. SPSS Clementine Text Miner or SAS Text Miner \ to help you come up with you research hypothesis; Do you build predictive models based on knowledge you gathered after reading documents relevant to your research; do you know about a computer technology that builds predictive models from textual documents; do you use computer technology to help you to come up with predictive models, for instance, SAS Text Miner or IBM Intelligent Miner; Do you try to locate discrepancies or intentions for deception by comparing facts or claims in documents describing the same instance/phenomena from various sources; do you know about a computer technology that might help you compare documents and find discrepancies in them \( for instance plagiarism programs\; do you use technology \(ex. SAS Text Miner or SPSS Text Miner\o find deception or discrepancies in or among documents; do you verify concepts/themes found in documents relevant to your research through other data sources are you aware of computer technologies that can help you verify your hypotheses with new data; do you use computer technology to verify your findings with new evidences, for instance, SAS Text Miner or SPSS Text Miner Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


System communication model because it better adjusts to the application characteristics of an aerospace mission while the other models are too simple for our purposes The Point-to-Point communication model is the simplest model for a distributed application In this model the distributed elements must implement the communications one by one specifying the target of every communication and assuming communication loses or service redundancies inside the object code This model has been extensively used in telephony applications using protocol stacks to reduce error message treatment As the application complexity increases it requires higher and higher bandwidths and more complex developments because the connection pipes increase exponentially In the case of the Client-Server model the distributed application must create differentiated objects for data providers and data consumers The paradigm of Client-Server has been extensively used in the Internet and also in database accessing applications because it adjusts easily to network requirements and it is simple and intuitive to develop applications In fact Client-Server model is the base of network 002le systems database management systems and Internet services e-mail browser etc Most middleware approaches like SUN RPC CORBA or Web Services are also designed under this paradigm The Client-Server model has been extensively used with good results but mainly when information is centralized In this case the server centralizes the accesses to data and minimizes the possible race conditions of data modi\002cations Some of their weaknesses are poor performance possibility of bottlenecks and poor robustness because of the single point of failure The Data Distribution Service model arose as a solution of most novel distributed applications today It promotes a publish/subscribe model for sending and receiving data events and commands among the nodes Nodes that are producing information publish that information and other nodes can subscribe to them The middleware layer takes care of delivering the information to all subscribers that declare an interest in that topic The Data Distribution Services model has been shown as a very good solution for many-to-many communication frameworks They are also very ef\002cient for distributing time-critical information For the speci\002c characteristics of an aerospace mission which may have lots of systems which may interact many-tomany the proposed solution is based in this paradigm Many Data Distribution Services frameworks have been already developed each one contributing with new primitives for such open communication scenario In our proposal we implement only the communication primitives required by a minimalistic distributed embedded system in order to keep it simple and soft real-time compliant The mission and payload control has been used as a motivating example and guiding application Next sections describe the proposed communication primitives which have been classi\002ed in four types Variables Events Remote Invocation and File Transmission Variables As variables we mean the transmission of structured and generally short information from a service to one or more additional services of the distributed system This information is sent at regular intervals or each time a substantial change in its value occurs This relative caducity of the information allows to send it in a best-effort way The system should be able to tolerate the loss of one or more of these data transmissions This communication primitive follows the publicationsubscription paradigm A service can provide zero or more variables Each of them is composed of a basic type boolean integer 003oating point real character string etc or by a composition vector struct or union of basic types From the point of view of the allowed data types in a variable our middleware is similar to a C-like language By means of its service container a service announces the availability of its variables This way other services present in the distributed embedded system can subscribe themselves to one or more of these variables From the moment a service subscribes to a variable the provider service is responsible for sending it with the accorded quality of service characteristics In any case the services using this communication primitive should tolerate the loss of some variable values If this situation goes on the service container will warn of this timeout circumstance to the affected services The provider service can specify the variable validity as a quality of service parameter When a variable value is lost the subscribed services can receive previous values as long as they are still valid In addition the middleware has a mechanism that guarantees an initial exact value for the services that need it The service container maps this sort of communication over UDP packets in broadcast or multicast mode when the underlying network allows it This sort of transmission allows optimizing the bandwidth use because one packet sent can arrive to multiple nodes in the distributed embedded system Events Events are similar to variables in the sense that both work following the publication-subscription paradigm The main difference is that events opposite to variables guarantee the reception of the sent information to all the subscribed services The utility of events is to inform of punctual and important facts to all the services that care about Some examples can be error alarms or warnings indication of arrival at speci\002c points of the mission start of some pre-programmed actions like taking a photo etc Events can contain associated information error codes current position etc or have meaning 11 


by themselves When they carry additional information data is coded the same way as in the variable communication primitive In the case of events an important fact that has to be taken into account apart from correct reception of the message by all subscribers is that latency due to reception and processing may be critical A typical solution to this problem is the reservation of time slots in both the processor and the network The publisher and subscriber services interact with other services always using the service container like in the variable case Finally this communication primitive is mapped by the service container over TCP or over UDP using a mechanism to acknowledge and resend lost packets This speci\002c retransmission mechanism in the application layer is more ef\002cient for event messages than the generic case provided by the TCP stack Remote invocation Most middleware implements some way of distributed computing based on the remote procedure call paradigm for example ONC RPC CORBA or Web Services However for some distributed embedded domains the data publicationsubscription or global data space paradigm seem more appropriate For this reason we provide a 002rst-class set of publishsubscribe communication primitives Nevertheless remote invocation is an intuitive way to model some sort of interactions between services Some examples can be the activation and deactivation of actuators or calling a service for some form of calculation Thus in addition to variables and events the services can expose a set of functions that other services can invoke or call remotely The functions exposed by a service can have an arbitrary number of parameters and optionally a return value This communication primitive implements two-way point-topoint communication between two services one acts as a client and the other as server The client service is always the initiator or the communication and the server service location is abstracted by the middleware However a difference from previous communication primitives is that the client service is not continuously subscribed nor connected to the server service Their relation is occasional and delimited by the time the invocation is executed During middleware initialization the services check that all the functions they need to properly accomplish their task are provided by one or more services available in the network Redundancy and fault-tolerance are managed by the middleware that can also redirect remote calls to server services statically or dynamically Static allocations of the client-server relationships are useful in critical services where resources like CPU time or network bandwidth are pre-allocated On the other hand runtime information can be used to redirect calls to non-critical services to the server where best performance is expected  For this load balancing techniques are used Upon service failure if another service is implementing the same functionality the middleware will detect the situation and redirect requests to the redundant service This allows the system to continue its mission although perhaps in a degraded mode If no service provides the requested function the middleware will warn the system to take the programmed emergency procedure In some cases both event and function primitives can be applied to realize a functionality In this case in our current implementation events seem faster than their function equivalent This communication primitive is generally mapped by the service container over TCP but UDP plus retransmission at the middleware level can be also used However this primitive is never mapped over broadcast or multicast given that is always a point-to-point communication File-based Transmission In our preliminary prototypes it has been discovered that some requirements of the mission are not ful\002lled by the proposed communication primitives In some cases there is the need to transfer with safety continuous media This continuous media includes generated photography images con\002guration 002les or services program code to be uploaded to the service containers Some modi\002cations could be done to the previous primitives to accept this sort of information transfer But 002nally a speci\002c primitive has been developed to treat this case given the huge performance bene\002ts that can be attained This primitive is used basically to transfer long 002le-structured information from a node to another and is implemented mapped directly over TCP Internal Implementation MAREA has been designed with interoperability and 003exibility in mind Their internals have been distributed in several layers allowing the addition of new components such as transports and codi\002cations MAREA has its components distributed in four layers Protocol Encoding Presentation and Transport This distribution loosely resembles the PEPt architecture from The transport layer is the lowest level layer on the MAREA stack It is on charge of sending and receiving data from the underlying network and to interface to the upper Encoding layer The MAREA middleware is message based so the transport layer is especially well suited for datagram based networking i.e UDP In the case of stream based communications the transport layer implementation has two options 12 


Figure 9  MAREA Internal Implementation The 002gure shows the internal delivery of data between components on the same local network a one stream can be opened for each message and after its sending the stream is closed b as the stream initialization usually require a long handshaking phase it is better for performance to reuse the established connections waiting for new messages to be send to the same destination through a unique stream In its current status MAREA offers an UDPTransport TCPTransport and PersistentTCPTransport They implement basic UDP and TCP transports for MAREA messages In the case of PersistentTCPTransport as the 002rst connection with other node is established it is cached in a table indexed by node All the following messages between the nodes that have established the connection are sent through this connection For this transport a speci\002c transport has been designed to dissect the stream into messages Basically each message is preceded by a header that indicates the length of the next message This way the receiving transport layer knows when a message is complete and it can pass it to the upper Encoding layer MAREA transport layer is not limited to IP based communication Although the most common connection between MAREA containers is IP over Ethernet or Wi-Fi other simpler networks are possible for example serial RF modems Each of these connections are represented in MAREA by an ITransport interface This interface provides access to the underlying device and allows to send and receive data and to get link status information i.e link quality expected bandwidth and latency This modular approach allows to easily add new datalinks to the system The encoding layer is on charge of transforming MAREA messages into byte arrays and vice versa Data received in the transport layer is cut into datagrams and sent to the upper encoding layer Here the received bytes are translated into a message that can be processed by the upper layers In a similar way when the Service container needs to communicate with other Service containers it forwards a Message to the encoding layer that transforms it into a coded byte array MAREA provides several coders and decoders to allow easy interoperability and devices/network adaptability Depending on the selected encoding the balance between codi\002cation latency and network bandwidth needed to transmit the encoded message can be modi\002ed Currently MAREA supports one optimized binary encoder and one text-readable XML encoder Finally the Protocol layer is on charge of scheduling the message depending on its priority and after that process it Control messages managing the discovery publication and subscription of services are managed on this layer while data messages are feed to the subscribed services All the services provide a common interface to get noti\002cations and data from the container and other services The service interface contains operations to manage the following operations Start This operation is invoked for all the initial services at container startup A service should respond to this call by allocating its needed resources and start performing its functionality Stop A service is asked to 002nish by receiving this call Container issues this call at system shutdown recon\002guration or during problem containment Run Usually a service requires a thread to perform its job The Run function contains the code to be executed by this main thread VariableChanged When a subscribed Variable primitive gets new data the container calls this function in the subscribed services The function acts as a callback returning the originating service and the sent data EventFired This is the equivalent callback but for Event primitives FunctionCall Finally Function primitives are noti\002ed by issuing this call in the producer service The service executes the indicated operation and returns the results to the container which will send them to the calling service 13 017 017 017 017 017 017 


The service container will issue this operations on the different services as they are initiated stopped or they receive new data from others services In addition the service container will contact with other containers in the local network to discover new services and manage remote publications and subscriptions More details about the protocol between containers are given in the next subsection Figure 9 shows three different views of a MAREA service container receiving and processing a message through its different layers In the leftmost 002gure we can see two service containers deployed over the same aircraft internal network More speci\002cally the Mission Control service noti\002es the Video Camera service to take an aerial photo by using a Variable communication primitive In the central 002gure we focus on what happens inside the service container and its layers First we found the Transport layer where the different transports keep the communication with other service containers Next we found the Encoding layer where the raw data received in a transport is decoded to be scheduled and processed in the upper Protocol layer In the rightmost 002gure the Mission Control noti\002es the Video Camera by using a Variable primitive so the VariableChanged callback is called for all the subscribed services in the container Then each service will react to the input according its functionality 6 G ROUND S EGMENT AND MANET O PERATION Adhoc networks are packet-based multi-node networks that are gaining popularity in other cooperative environments because they do not need a central point of organization like an access point in Wi-Fi networks and they can be selfcon\002gured as nodes appear and disappear If we add dynamism and mobility we reach the concept of MANET Mobile Adhoc Network 13 14 MANETs can extend a network more than the range of a single node range because their inherent multi-hoping capability allows the use of intermediate nodes to propagate packets to its destination Sensi\002re Support Terminal for Ground Squads One of the environments in which the technology has in\003uenced less is the forest 002re\002ghting techniques In this scenario it usually work small groups of 002remen squads organized all around a 002re truck The 002re truck commonly carries a GPS receiver and a radio unit to be in contact with a coordinating base station The Red-Eye system offers the ground squads a PDA system that can receive the set of hot-spots they have been tasked by the controller The PDA set feeds back the position of the squad given its attached GPS The PDA set can also be instrumented in order to feedback other information like temperature humidity level and wind speed and direction These data samples are designed to be sporadic because they need the proper placement of the sensors However the GPS position will be continuously transmitted The main advantage of using a MANET infrastructure is that information can get to the squads either directly from the Red-Eye helicopter of relayed from some other ground squad thus minimizing the 223out of coverage\224 situations Also having a continuous monitoring of the ground squads will improve their ef\002ciency as well as prevent dangerous situations in case of major changes in the evolution of the wild\002re These limited means generates some grave problems dif\002culty for knowing the location and state of the 002re brigades and lack of updated information for the decision taking This situation is make worse by the fact that communication is dif\002cult in these conditions Brigades usually work in zones of dif\002cult access and which lack adequate communication infrastructures They mostly use voice communication over radio and then is dif\002cult to transmit concretely 002re state or positions over the terrain We propose to alleviate these drawbacks by the usage of a distributed system For this application each 002reman will carry a personal digital assistant PDA device communicating with a central base station where all the information is centralized and keep a global vision of the situation The PDA is a small and light device secured to the 002reman arm This way the PDA does not disturb during the 002reman work and he can use the device with his free hand The functionalities provided by the device are receive and present information from the Base Station This include voice messages images picture or videos text messages maps and associated GPS coordinates It can also send these sort of messages Meanwhile the brigade is carrying the PDA its attached sensors are gathering useful information to the base station brigades realtime location temperature and humidity This way the base center can have an updated picture of the 002re and the effectives All the PDAs and the base station conform a mobile ad-hoc network or MANET Obviously this network does not guaranties a perfect coverage however it offers 003exibility and mobility while its coverage can be improved by using repeaters installed in the trucks or in the aerial means The PDA includes a service container and several services that implement the client application Client Application Sensor Module Storage Module and Map Database 017 Sensor module interact with the GPS receiver and the humidity and temperature sensors It can broadcast this data at regular intervals using the variables temperature  humidity and position  In case of an extreme temperature detected it can send an alarm to the base station using the event primitive 017 Storage module is a common component used in most of the applications following this architecture It represents a 14 


002le system where other components can store and retrieve information in a hierarchical way 017 The Map Database is a higher level of abstraction component that allows the storage and retrieval of geo-referenced information mainly maps All 002le-structured information i.e maps or images that is need to be sent to several brigades can be sent using the 002le transfer primitive of the middleware This primitive optimizes the bandwidth usage when multicast networks are used Communication Gateway In air-ground communications it is very common to use different links to support communication at different ranges and to provide redundancy in the case a link is down These pointto-point links usually do not support multicast and may have associated costs economical or power-consumption that restrict their usage to speci\002c situations or very important transmissions In this case the system should be intelligent enough to send the data through the most appropriate channel This decision should be based on the type and length of the data to send the current quality of the different links and the mission status At the same time the communication should be as much uniform and transparent to the services as possible in order to allow the deployment of the same services in different missions over different network relays MAREA has a speci\002c system called Communication Gateway that it is on charge of managing air-to-air and air-to-ground communications Their main purpose is to make the network transparent to the different services that use it Our middleware assumes a highspeed Ethernet-like network that interconnects the different service containers This local area network provides a very good bandwidth/cost ratio and very high reliability Communication Gateway requirements\227 The basic requirements that the Communication Gateway has to ful\002ll are 017 Support for several datalinks The vehicle will have several datalinks that the services should use in command and transparent manner New datalinks should be easily con\002gured to be used 017 Network hardware and protocol independence The services should not be modi\002ed because using one network technology or another The underlying network can use IP or not For example most RF modems provide a wireless RS-232 link this means no data transmission integrity no error correction and no retransmissions MAREA Transport component implementation should resolve this transport-speci\002c problematic while encapsulating and hiding these details to the rest of the system 017 Transparent handover between networks When a communication session has been established between two remote service containers changing from a datalink to other should be transparent to the services involved Imagine that we are using a high-throughput 802.11a WiFi connection to while the helicopter is near the ground station as the distance increases signal will decrease and the Communication Gateway will change to RF modem communication Established sessions will hand over from a datalink to the other 017 Prioritize traf\002c from different services When the available bandwidth is not enough for all the required data 003ows the Communication Gateway should prioritize the traf\002c from speci\002c services Other traf\002c can be discarded postponed its transmission or stored in persistent medium for later processing on ground For example command data should be prioritized always over telemetry data 017 Using simultaneously several networks for higher throughputs If a vehicle con\002guration provides several datalinks and in a speci\002c point of the mission there is a high throughput necessity and they are available the MAREA container should distribute the generated data through the different datalinks Imagine that we have two RF modem on different bands and we want to download to ground a high-resolution aerial photo by using the two RF modems simultaneously we will be able to 002nish the job in half the time 017 Security and encryption The MAREA protocol has some security checks but in general it has not need to cope with malicious services because the internal local network can be considered safe When the communications are done external to this network and using a wireless channel the possibilities that this channel can be attacked are highly increased Some effort is done in this area although the current implementation of the current gateway lacks these features System architecture\227 The idea of the communication gateway is to add a new layer on the stack that will manage the multiple datalinks and decide which to use for each data 003ow This process is dynamic as it depends on the links status Link status can change from available to unavailable in any moment of the mission on that case the Communication Gateway will be on charge to transparently handover the communications from one link to other One advantage of separating this functionality on an independent layer is that the service containers present on internal networks not needing handover and multiple network interface functionalities can remove completely this layer avoiding all the resources cost Communication Gateway layer is installed between the Protocol and Encoding layers just before deciding which encoding use It only processes output messages Input messages are bypassed and their differentiation is performed at the scheduling done by the Protocol layer Messages from high priority services are queued before An XML con\002guration 002le de\002nes which transports to use and which policies to apply to each sort of packets The packets are mainly classi\002ed by their producer and their consumer In addition to this static information the Communication Gateway receives dynamic information from the Transport layer mainly the link status of all the transports enabled The Transport components on the transport layer has been extended to be able to provide this information 15 


All information related to link status and interfaces are stored in a component called Network Manager The Network Manager it is on charge on relating addresses with its link status With this both dynamic and static information the Selector component decides to which interface send each Message Services and service container layers use speci\002c objects called TransportAddress to identify the recipient of a Message This object not only carries the address of the underlying speci\002c networks for example its IP address but also information about the encoding to use This TransportAddress will be used by the lower layers to select the appropriate encoding and interface Communication Gateway only needs to route the Message through the lower layers by changing the TransportAddress of the Message Figure 10  Communication Gateway architecture The 002gure shows the layers of the MAREA middleware interacting with Communication Gateway A general view of the architecture is shown in Figure 10 After being processed by the Protocol layer two packets arrive at the Communication Gateway With the information gathered from the Transport layer and stored in the Network Manager about the two Link available the Selector decides which route to use The XML con\002guration 002les de\002nes that the Messages from Service 1 are encoded in binary and sent through network 1 Wi-Fi while the Messages from Service 2 are encoded also in binary but sent through network 2 RF In addition to the Communication Gateway layer a speci\002c SerialTransport has been implemented to be able to use Radio Frequency Modems based on RS-232 interaces for example the Digi 2.4Ghz XStream module 7 C ONCLUSIONS AND F UTURE W ORK Having aerial resources working in a command and control over wild\002res may improve the overall extinguishing process Improving the awareness trough those monitoring systems may will maximize the ef\002ciency of the available resources and at the same time improve the safety of the personnel working on the 002re However the complexity of integrating these monitoring systems together with the traditional aerial resources is a complex and unsolved task The Red-Eye system is a partial solution to this task Its objective is to provide hot-spot detection over areas in which other aerial resources has been temporally removed It has been identi\002ed that this scenario may provide important bene\002ts in terms of ef\002ciency Red-Eye will allow aerial and ground resources to be employed on other 002re fronts by reducing the number of resources that need to be kept on the 002eld one a 002re front has been controlled Red-Eye works on top of a middleware speci\002cally designed for avionics MAREA provides a full distributed paradigm to the avionics designers Each avionics semantic is encapsulated into a service or piece of software which realizes a function Data communication between services are always conducted through the middleware The physical location of the services is transparent to the designers being MAREA responsible of the service discovery location and execution The main targets in the MAREA development process have been the communications ef\002ciency the transparent service location and the automatic selection of the physical link for the communications The communications ef\002ciency is de\002ned as the relation between the transfer speed and system cost The paper presents also the second layer the gateway This layer has information from the lowest layer about all the available links and their status The gateway using a con\002guration 002le decides the best physical channel Service ubiquity is the 002nal result for avionics designers A CKNOWLEDGMENTS This work has been partially funded by Ministry of Science and Education of Spain under contract CICYT TIN 200763927 This work has been co-\002nanced by the European Organisation for the Safety of Air Navigation EUROCONTROL under its CARE INO III programme The content of the work does not necessarily re\003ect the of\002cial position of EUROCONTROL on the matter R EFERENCES  223Upnp forum 224 http://www upnp.or g Online A v ailable http://www.upnp.org  Y  Kaufman C Justice L Flynn J K endall E Prins L Giglio D Ward W Menzel and A Setzer 223Potential global 002re monitoring from eos-modis,\224 Journal of Geophysical Research  vol 103 no 32 pp 215\226238 1992  L Giglio J Descloitres C Justice and Y  Kaufman 16 


223An enhanced contextual 002re detection algorithm for MODIS,\224 Photogrammetric Engineering and Remote Sensing  vol 87 pp 273\226282 2003  D Ro y  P  Le wis and C Justice 223Burned area mapping using multi-temporal moderate spatial resolution data a bi-directional re\003ectance model-based expectation approach,\224 Remote Sensing of Environment  vol 83 pp 263\226286 2003  223National inf ared opera tions historical perspecti v e 224 Remote Sensing Applications Center August 2004  223Designing and implementing a near real-time wildland 002re information system,\224 Jet Propulsion Laboratory California Institute of Technology 1989  J D Nichols 223Fire\003y system concept 224 in Proc SPIE Vol 1540 p 202-206 Infrared Technology XVII Bjorn F Andresen Marija S Scholl Irving J Spiro Eds  ser Presented at the Society of Photo-Optical Instrumentation Engineers SPIE Conference B F Andresen M Scholl and I J Spiro Eds vol 1540 Dec 1991 pp 202\226206  D Wright T  Y otsumata and N El-Sheimy  223Real time identi\002cation and location of forest 002re hotspots from geo-referenced thermal images,\224 International Archives of Photogrammetry Remote Sensing and Spatial Information Sciences  vol 35 no 2 pp 13\22618 2004 also AIAA Paper 89\2260269 Jan 1989  E P astor  C Barrado P  Ro yo J Lopez E Santamaria X Prats  and J M Batlle 223Red-eye A helicopter-based architecture for tactical wild\002re monitoring strategies,\224 in IEEE Aerospace Conference  Big Sky Montana IEEE 2009  J Lopez P  Ro yo E P astor  C B arrado and E Santamaria 223A middleware architecture for unmanned aircraft avionics,\224 in ACM/IFIP/USEUNIX 8th Int Middleware Conference  NewPort California Nov 2007  H Carr  223PEPt A minimal RPC architecture 224 in OTM 2003  Italy Nov 2003  A Ne yem S Ochoa and J Pino 223Supporting mobile collaboration with service-oriented mobile unit groupware Design implementation and use,\224 in Groupware Design Implementation and Use  vol LNCS 4154 2006 pp 228\226245  M T entori and J F a v ela 223 Acti vity-a w are computing in mobile collaborative working environments,\224 in Groupware Design Implementation and Use  vol LNCS 4715 2007 pp 337\226353  A Ne yem S Ochoa J Pino and M Bor ges 223Supporting group decision making and coordination in urban disasters relief efforts,\224 International Journal of Decision Systems  vol 16 no 2 pp 143\226172 2007 B IOGRAPHY  Enric Pastor is a Computer Science Engineer and holds Ph.D also in Computer Science from the Technical University of Catalonia Spain Currently he is an associate professor at the Castelldefels School of Technology His research background includes the development of CAD tools for the automatic design of synchronous and asynchronous circuits and CAV tools for the formal veri\002cation of concurrent systems He has published more than 30 journals and conference papers in these 002elds Dr Pastor is leading the ICARUS Intelligent Communications and Avionics for Robust Unmanned Aerial Systems Research Group completely focused on the development of systems that support and facilitate practical applications of UAS technology The ICARUS group is especially interested in developing wildland 002re monitoring tools and strategies both using UAS technology and classical vehicles The ICARUS group has published more that 25 research papers on UAS technology in the last three years Marc Sole holds a Ph D 2009 On Computer Sciences by the Technical University of Catalonia where he is also an Assistant Professor in the Computer Sciences Faculty of Barcelona His Ph.D thesis was focused on automated formal veri\002cation of timed concurrent systems Research interests include formal veri\002cation process mining data anonymization and UAS He belongs to the ICARUS research group Juan Lopez is an assistant professor at the Technical University of Catalonia Its main interests are embedded software architectures and unmanned aircraft systems design Currently he is working in middleware based avionics architectures for UAS 17 


Pablo Royo received a degree in Telecommunication Engineering from the Technical University of Catalonia Now he is an assistant professor at the Technical University of Catalonia His research interests include the Unmanned Aerial System design and their application in autonomous intelligent applications Cristina Barrado holds a Ph D on Computer Sciences by the Technical University of Catalonia where she is also an Associate Professor at the Castelldefels School of Technology Spain She has been teaching operating systems since 1990 and currently a course of Digital Avionics Systems Her Ph.D Thesis was focused on automatic extraction of low level parallelism on loops at compile time She belongs to the ICARUS Research Group which target is the research on Unmanned Aerial Systems their architecture their civil uses and their integration into the airspace 18 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






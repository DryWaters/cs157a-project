Handling Signiﬁcant Scale Difference for Object Retrieval in a Supermarket Yuhang Zhang   Lei Wang   Richard Hartley  and Hongdong Li   The Australian National University  NICTA Email  yuhang.zhang lei.wang richard.hartley hongdong.li  anu.edu.au Abstract We propose an object retrieval application which can retrieve user speciﬁed objects from a big supermarket Signiﬁcant and unpredictable scale difference between the 
query and the database image is the major obstacle encountered The widely used local invariant features show their deﬁciency in such an occasion To improve the situation we rst design a new weighting scheme which can assess the repeatability of local features against scale variance Also another method which deals with scale difference through retrieving a query under multiple scales is also developed Our methods have been tested on a real image database collected from a local supermarket and outperform the existing local invariant feature based image retrieval approaches A new spatial check method is also brieﬂy discussed Keywords image retrieval local feature scale invariance 
I I NTRODUCTION Recent years have seen quite some successful content based image retrieval systems which can nd objects from video or image set   2  3 O ne salient general character of these applications is to describe images with local invariant features Local invariant features hold many appealing advantages One of them is the scale invariance which has demonstrated excellent performance in the existing image retrieval systems In this work we conduct an object retrieval in a supermarket Differently we show the deﬁciency of local invariant features in handling signiﬁcant scale difference in image retrieval and introduce our multi-scale methods to improve the situation As shown in Figure 1 our query 
image contains the query object generally under a very large scale In contrast the corresponding database image contains the queried object under a much smaller scale together with many clutters Moreover since the query is to be submitted by a user the retrieval system cannot know the exact scale of queries in advance and thus cannot down sample each query image with a predeﬁned ratio We choose supermarket as our object retrieval context since it provides a comprehensive test for the capability of an object recognition system Nowadays a typical supermarket carries around 50  000 different products  T his d i v ersity provide a critical challenge to the discriminative capability 
of an object recognition system Moreover in a supermarket We thank the Coles store located in Woden Plaza ACT Their understanding and support make this work possible and are highly appreciated each individual object presents itself among strong clutters The illumination on different objects varies as they are located on different level of shelf A big variety also lies in the viewing directions towards different objects Occlusion and scale difference is also possible We analyze the deﬁciency of local invariant features and review the general framework of visual word based image retrieval in the section of literature review A brief introduction to our previous work will also be conducted 
We then introduce our new proposed methods and compare its performance with existing methods in experiments The proposed methods tackle signiﬁcant scale difference with two tactics The rst is through adaptively assigning the weight of local features visual words according to their repeatability over different scales The second is through describing a query under different scales and retrieving each version of the query independently The nal retrieval result is then constructed by combining the retrieval results obtained under multiple scales A new spatial check mechanism will also be brieﬂy introduced before the conclusion II L ITERATURE R EVIEW To handle scale variance Harris-Laplace detector 
 w orks in tw o s teps  rstly  a scale-space representation of the Harris function is created and the initial interest points are detected by selecting the local maxima in each 3  3 co-scale neighborhood under each scale secondly the extrema of the LoG Laplacian of Gaussian are searched for each initial interest point in the scale space within a variance range between 0  7  1  4  namely the identiﬁcation of the characteristic scale The location of the extrema of the LoG or the characteristic scale of the initial interest point is determined by the image pattern but not the scale in which the image pattern is presented Thus identical 
features can be extracted from an image even though the image is presented in different scales This scale invariance mechanism is inherited by Harris-Afﬁne detector and Hessian-Afﬁne detector Ho we v e r  as mentioned in their work the repeatability of Harris-Laplace feature is no more than 70 even after a scale change of merely 1  4  That is because many points as well as information in the image disappears after a reduction in resolution For SIFT Scale Invariant Feature Transform feature  t he image is rstly 
2009 Digital Image Computing: Techniques and Applications 978-0-7695-3866-2/09 $26.00 © 2009 IEEE DOI 10.1109/DICTA.2009.79 494 
2009 Digital Image Computing: Techniques and Applications 978-0-7695-3866-2/09 $26.00 © 2009 IEEE DOI 10.1109/DICTA.2009.79 465 
2009 Digital Image Computing: Techniques and Applications 978-0-7695-3866-2/09 $26.00 © 2009 IEEE DOI 10.1109/DICTA.2009.79 508 
2009 Digital Image Computing: Techniques and Applications 978-0-7695-3866-2/09 $26.00 © 2009 IEEE DOI 10.1109/DICTA.2009.79 468 
 


Figure 1 Query and database image example the top is the query image containing the query object in a very large scale the bottom is one of the database image containing the queried object in a much smaller scale together with much clutters down-sampled into sequential octaves Then within each octave the image is convolved with a Gaussian kernel to build the scale space representation from which the local extrema of the DoG Difference of Gaussian is detected By resampling images at each octave features are extracted under all possible resolutions and a large range of scales can be covered However SIFT still bears the problem of dropping off features as the scale of the original image declines Figure 2 gives an intuitive illustration of above discussion The original image top is down-sampled at the rate of 2:1 middle and 4:1 bottom respectively HarrisAfﬁne features are then detected under each scale Let us now assume that the top image is the query and the images at the middle and the bottom are to be retrieved from the database Obviously the number of features extracted from the query is much larger than that extracted from the two relevant images in the database Does it hurt The extra features from the query will not only nd no true match but also generate a considerable number of false matches with irrelevant images In the framework of visual word based image retrieval through clustering a feature is always matched to some others Hence an irrelevant image may accumulate a higher score than a relevant image does In our experiments this problem forms the bottleneck of retrieval performance The general framework of visual word based image retrieval  is as follo ws F irst l ocal in v a riant features are extracted from each image The extracted features are then clustered to generate visual words  Features in Figure 2 Local feature extraction under different scales From top to bottom are the original image 2:1 down sampled image and 4:1 down sampled image Hessian-Afﬁne features marked as yellow ellipses are extracted from each of the tree images individually As the scale of the image goes down the number of extracted features declines sharply the same cluster are treated as matched and assigned the same label namely the same visual word ID Each image is then described by the visual words that it contains in the form of a high-dimensional vector Each dimension of the vector corresponds to one type of visual word To achieve high retrieval accuracy each dimension of the vector can be assigned a tf-idf term frequency–inverse document frequency weight a s s ho wn in Equation 1  w ij is the weight of visual word i in image j  n j is the number of visual words in image j  n ij is the number of occurrences of visual word i in image j  N i is the number of images in the database that contain visual word i  N is the number of images in the database The more a visual word appears in the database the less important it is in describing an image the more it appears in an individual image the more important it is in describing this image During retrieval the similarity between two images is computed as the L p norm distance between their corresponding vectors A larger distance indicates a smaller similarity As shown in Equation 2 d mn is the L p norm distance between image m and n  v m and v n are the two vectors corresponding to the two images To achieve high retrieval speed invert le is used to index the images in the database That is for each visual word the invert le records all the images that contain this visual word Given a query only images in the database sharing the same visual words with the query are assessed Our work generally follows above framework but develops new mechanisms to handle large scale difference which will be discussed in the next section w ij  n ij  n j log N N i 1 
495 
466 
509 
469 
 


d mn      v m   v m  p  v n  v n  p     p 2 The work in this paper is an extension of our previous work In 9 w e s ho wed t hat the L p norm distance does not perform well when retrieving objects from strong background clutters Instead an inner-product in Equation 3 was proposed in t o m easure t he similarity between the query and each database image Note that the similarity between two images is proportional to the inner-product between their corresponding vectors That is to say instead of measuring the difference between the two images we assess the similarity between them directly Moreover Equation 1 has been modiﬁed to Equation 4 in According to Equation 1 the weight of each visual words is affected by not only the number of itself but also the number of other visual words in the same image In such a manner the existence of irrelevant clutters will affect the matching score between identical visual words Besides in a supermarket multiple copies of one product are often placed together on a shelf According to Equation 1 the existence of multiple copies will also change the weight of visual words In this way a relevant image containing a single true match in strong clutters may be beaten by an irrelevant image containing multiple copies of false match in weak clutters Therefore Equation 1 was replaced by Equation 4 in which the weight of a visual word is only determined by its occurrence frequency in the database d  mn   v m  v n  3 w  ij   log N N i  if n ij  0 0  otherwise 4 In to a v o id the p roblem of lar g e s cale d if ference each query was manually down sampled to a similar scale to the true matches in the database This drawback has to be removed in order to handle practical retrieval tasks so in this work we avoid the manually down sampling and propose new methods to handle the large scale difference III M ULTI SCALE I MAGE R ETRIEVAL WITH L OCAL I NVARIANT F EATURES As stated above scale difference leads to the imbalance in feature numbers between the query and its true matches in the database The extra features from the larger scale generate mismatches and cause retrieval to fail We handle this deﬁciency in the following two ways A Adaptively Assigning Weight before Retrieval The rst way is through adaptively assigning weights to different visual words Weighting visual words is not a new mechanism in the literature however previous works do not pay sufﬁcient attention to the repeatability of visual words over scale variance 3 Based o n our pre v ious discussion a proper weighting scheme should depress the weight of extra words produced by larger scale and increase the weight of consistent words that can be found under a sequence of scales To check the repeatability of a visual word with regard to a query object we resize the query image into multiple scales and then describe each scale of the query with the same vocabulary As we can imagine some of the visual words can survive multiple scales whereas some cannot We then assign weight to each visual word through Equation 5  w ij is the weight of visual word i in query image j  q ijk is the number of occurrences of visual word i in image j under scale k  q jk is the total number of visual words in query image j under scale k  Through Equation 5 a visual word surviving more scales becomes more important for a query Note that the usage of q jk indicates that a visual word appearing under a scale where few visual words can be found has higher weight This is reasonable because these visual words are more consistent against scale change  w ij   k q ijk q jk log N N i 5 Note that we only resize the query image but not the database images because resizing all images in the database and extract features under all possible scales not only demand enormous computation time but also require huge storage space For the database images we still weight each visual word according to Equation 4 which can effectively handle background clutters and multiple copies of the same object Besides assessing the repeatability of each visual word Equation 5 also gives each query a more comprehensive description because it brings features extracted from multiple scales into one bag Building an expanded description of the query image is not a new idea in the literature Whereas the work in  e xpands the query description based on the images in the database our expansion focuses on the scale aspect and does not require additional images In latter sections we will refer this method as A  B Combine Matching Scores after Retrieval In Section III-A we assign weights to visual words according to its repeatability over different scales Parallel to that method we can simply treat the query under different scales as independent queries After performing retrieval with each of them individually we combine the results from different scales to form a nal result for the original query Both methods in current section and the next section follow this idea Denote the matching score obtained by the query m under scale k with database image n as  d mkn  Since the combination is implemented over multiple scales we cannot compute the matching score  d mkn simply using Equation 3 That is 
496 
467 
510 
470 
 


because a query under a larger scale usually has more visual words However through Equation 3 having more visual words tends to generate higher matching score If so the query under the largest scale will dominate the combination We modify Equation 3 to Equation 6 v mk represents the query image m under scale k  v n represents the database image n  The denominator  v mk  v mk  computes the innerproduct between the query image m under the scale k and itself Through Equation 6 possessing more visual words no longer results in a higher matching score Hence a query image under a larger scale does not hold a dominating position any more  d mkn   v mk  v n    v mk  v mk  6 Deﬁne that  d mkn reaches its maximum at the scale k   Obviously  d mk  n suggests the highest matching score that the database image n can obtain with the query image m under all scales If they are true match k  indicates the scale under which the database image n can match most of the visual words possessed by the query image m In other words the feature imbalance between the two relevant images is approximately removed If they are not true match k  only indicates a scale under which the query looks most similar to an irrelevant database image n  Two relevant images under the same scale are more similar than two irrelevant images under their most similar scales are Thus we construct the nal retrieval result by sorting all database images according to its  d mk   namely the highest matching score between itself and the query under all scales We label this method as B1  In our problem a relevant database image cannot always obtain a higher matching score than an irrelevant database image does under all scales Hence we pick the scale under which the database image can obtain the highest score in Method B1 for comparison Actually it is even less likely for an irrelevant database image to always beat a relevant image under all scales That is so say if we accumulate the total matching score between a database image and the query image under all scales relevant images should more likely obtain higher total scores than irrelevant images do Hence in Method B2 we construct the nal matching score for each database image by summing up the matching scores under all possible scales and then sort C Combine Sorting Ranks after Retrieval Besides matching scores each database image also gets multiple sorting ranks when being retrieved against the query under multiple scales Like combining matching scores we can also combine these ranks to construct a nal result We cannot sort the database images according to their best rank because there are more than one rst which we cannot distinguish We cannot simply sum up all ranks of each database image either otherwise the nal rank of a database Figure 3 Similar but not identical objects the same bottle the same brand and the same cup on the labels but different coffee for customers We treat them as two different objects during retrieval although many identical local features can surely be extracted from them image will be dominated by its lower ranks note that lower ranks are represented as large numbers Instead we only sum up the best sequential n ranks of each database image as shown in Equation 7 where R denotes rank The value of n is to be determined experimentally We label this method as C  R nal  min i  R i  R i 1    R i  n  1  7 IV E XPERIMENTAL R ESULT Our images are collected from a local Coles supermarket Totally eighteen 30-meter-long shelves and all the products on them have been captured by 3  153 images as the database 1  300 additional images of the objects on the shelves have been taken and used as query images As illustrated by Figure 1 each query image contains a single object under quite large a scale and each database image contains three or more levels of a market shelf including all the objects on the shelf All the 3  153 database images and 300 query images are used in our experiments Each image is either 2  272  1  704 or 2  592  1  944 in size which is much larger than most known image database  12 T his h igh resolution is necessary to hold sufﬁcient information for each object appearing in the image The ground truth is built by manually checking the query image against each database image Only completely identical objects are treated as true matches That is to say retrieving NESCAF  E BLEND 43 out when NESCAF  E DECAF see Figure 3 is queried is wrong From all the 3  153 database images we detected 51  537  169 Hessian-Afﬁne features in total Some of the Hessian-Afﬁne features are shown in Figure 4 These Hessian-Afﬁne features are then described with SIFT descriptors  each of which i s a 128 dimensional unit vector We then use hierarchical k means to cluster the 51  537  169 unit vectors into 1,000,000 clusters over 3 levels the branch factor k  100 on each level Thus we obtain a visual vocabulary containing 1,000,000 visual words Each image is then described with these visual words 1 this image set together with the queries and the ground truth has been made available on web http://yuhang.rsise.anu.edu.au 
497 
468 
511 
471 
 


Figure 4 Some Hessian-Afﬁne features detected from one of the database images the top is the database image and the bottom are some of the Hessian-Afﬁne feature detected Invert le is used to index the database images which reduces the retrieval time to no more than 0  025 seconds per query on a Linux server equipped with Dual Core 2.8GHz CPU and 4G RAM We also implement the retrieval on other machines and nd the retrieval speed is mainly constrained by the size of RAM To show how the scale of query images impacts the retrieval performance we resize each query image into 10 different scales with a scale step factor of 1  25 and implement retrieval under each scale Figure 6 shows the retrieval performance with local invariant features given the queries under 10 different scales The horizontal axis is the number of returned images The vertical axis is the percentage of queries that have found at least one true match ALOT among the retrieved images According to the descending order of retrieval performance the ten scales arerankedas6574382190 Scale-6 gives the best performance because most true matches happen around this scale However we cannot know this scale in advance and scale-6 may not perform best if we use another set of queries or retrieve in another database Giving the worst performance scale-0 corresponds to the original scale of the query image It performs worst because it suffers most from the problem of feature number imbalance This will be the retrieval result if we solely rely on local features to Figure 5 Visual word example in this graph we show 4 different visual words The number in front of each row is the word ID The thumbnail images following the word ID are some of the Hessian-Afﬁne features clustered to the same visual word As expected the Hessian-Afﬁne features that belongs to the same visual word are quite similar Note that their color can be different because the features are extracted from grey-value images Besides the visual word 10267 and 10269 are slightly similar to each other That is also reasonable Their word ID should be read as 1  02  67 and 1  02  69  which suggests that they were ever in the same cluster during hierarchical k means Only at the bottom level of the hierarchy were they separated    0 5 10 15 20 30 40 50 60 70 80 90 The number of retrieved images ALOT \(in percentage   scale0 scale1 scale2 scale3 scale4 scale5 scale6 scale7 scale8 scale9 Figure 6 Retrieval with local invariant features under a single scale From scale-0 to scale-9 the query images are down sampled to 1  25 0 to 1  25  9 times of their original scales Although local invariant features are used the retrieval performance varies dramatically as the scale of the query changes ALOT stands for At Least One True match handle scale difference as in 2 3 Scale-7 scale-8 and scale-9 do not perform well either because the queries are down sized to too small scales which cannot provide sufﬁcient information about the query This paper proposes four methods to tackle the scale difference Method A is to assign weight to visual words according to its repeatability over scale variance Method B1 is to sort all database images according to its highest matching score with the query under different scales Method B2 is to sort all database images according to its 
498 
469 
512 
472 
 


total matching score Method C is to sort all database images according to the sum of its best sequential n ranks We empirically set n 4 in method C  Figure 7 shows the performance of all the proposed methods when implemented with 10 different scales The four proposed methods achieve comparable results and all of them outperform scale-0 in Figure 6 which solely relies on local invariant features to handle scale difference To achieve fast retrieval speed it is preferable to retrieve on few scales only Thus we test our methods on a smaller number of scales Scale step is increased to 1  5 and the retrieval is implemented on 5 different scales Note that the scale range is kept as it was  1  25 10 005 1  5 5  Under such a conﬁguration n 3 optimizes the performance of method C  The performance of all methods is presented in Figure 8 Compared with the result in Figure 7 the performance of Method A  B1 and B2 slightly declines In contrast the performance of Method C not only holds up but also rises 3 percents at the rst returned image Moreover when retrieval is implemented under 5 different scales Method C performs almost as good as scale-6 the best one in Figure 6 Over 60 of the queries nd true matches in the rst returned image Over 75 of the queries nd true matches in the top 5 returned images The four proposed methods constantly achieve better results than scale-0 in Figure 6 Figure 9 and Figure 10 show some of the queries and the top 2 database images retrieved by method C  Figure 11 particularly demonstrates our system’s capability in distinguishing similar objects V S PATIAL C HECK ON V ISUAL W ORD Spatial check has been a popular post-veriﬁcation mechanism in the literature of local invariant feature based image retrieval   2  15 B y checking the s patial consistenc y between the p nearest neighbors of the two matched local features false matches are removed However the spatial check method used in the literature usually checks the position of afﬁne features corresponding to each visual word after retrieval which not only requires recording the onimage-position of each visual word but also consumes much computation during runtime Here we shift the spatial check from feature level to visual word level When building the invert le following the entry of each visual word there are not only all the images containing this word but also the 15 spatial nearest visual words precomputed in each image In this manner we could implement the spatial check simultaneously as retrieving That is only those visual words which not only have identical word ID but also have at least two identical neighbors out of the 15 nearest ones are treated as matched As shown in the top row of Figure 12 two images left and right containing common regions are captured The common area between them is cropped out with yellow rectangle The second row shows all the matched features based on visual word ID only False  0 5 10 15 20 30 40 50 60 70 80 90 The number of retrieved images ALOT \(in percentage   A B1 B2 C Figure 7 Retrieval under 10 different scales with the four proposed methods A assign the weight of visual words according to their repeatability over different scales B1 retrieve the query in multiple scales independently and sort the database images according to their highest matching scores B1 retrieve the query in multiple scales independently and sort the database images according to their total matching scores C retrieve the query in multiple scales independently and sort the database images according to their best sequential 4 ranks The performance of the four proposed methods are comparable ALOT stands for At Least One True  0 5 10 15 20 30 40 50 60 70 80 90 The number of retrieved images ALOT \(in percentage   A B1 B2 C Figure 8 Retrieval under 5 different scales with the four proposed methods whereas the other three methods suffer a decline in performance Method C slightly goes up and becomes the obvious best ALOT stands for At Least One True 
499 
470 
513 
473 
 


Figure 9 Retrieval Examples the left column are the queries the middle and the right columns are the rst and the second returned images by Method C Figure 10 Retrieval Examples the left column are the queries the middle and the right columns are the rst and the second returned images by Method C 
500 
471 
514 
474 
 


Figure 11 Finding NESCAF  E of the particular type we enlarge the corresponding region in the database image to show that we have found exactly the same object Figure 12 Visual word based spatial check rst row original images second row matches based on visual word ID third row matches approved by visual word based spatial check fourth row remaining false matches matches out of the common area are observed The third row shows the matches approved by the visual word based spatial check After removing those false matches only 7 matches out of the common area are left They are actually true matches As the bottom row shows these 7 matches are caused by different objects manufactured by the same corporation thus sharing the same brand VI C ONCLUSION We proposed an object retrieval application in the environment of a supermarket Our methods successfully make up the deﬁciency of local invariant features in dealing with large scale difference and improve the retrieval performance With the invert le even the query is retrieved under 10 different scales the retrieval time for each query does not exceed 0  25 seconds The major increased computation time is caused by the feature extraction under multiple scales Future work can be devoted to boosting the speed of feature extraction under multiple scales R EFERENCES  J  S i v ic F  S chaf f a litzk y  a nd A Zisserman  Ef cient object retrieval from videos in EUSIPCO 04  2004  J  S i v ic and A  Z isserman  V i deo google A t e x t r etrie v al approach to object matching in videos in ICCV 03  2003  D  N ister a nd H Ste wenius Scalable recognition w ith a vocabulary tree in CVPR 06  2006 pp 2161–2168  M  Nestle  The s oft s ell ho w t he food industry s hapes our diets Nutrition Action Healthletter  2002  K  M ik olajczyk a nd C Schmid Scale  af ne i n v ariant interest point detectors IJCV  vol 60 no 1 pp 63–86 2004  K  M ik olajczyk T  T uytelaars C Schmid A Zisserman J Matas F Schaffalitzky T Kadir and L V Gool A comparison of afﬁne region detectors IJCV  vol 65 no 1-2 pp 43–72 2005  D  G  L o we Distincti v e i mage features from s cale-in v a riant keypoints IJCV  vol 60 no 2 pp 91–110 2004  F  J urie and B  T riggs  Creating e f  cient c odebooks for visual recognition in ICCV  2005 pp 604–610  Y  Z hang L W a ng R I Hartle y  and H  L i Where s the weet-bix in ACCV 1  vol 4843 2007 pp 800–810  O Chum J Philbin J  S i v ic M  I sard a nd A Zisserman Total recall Automatic query expansion with a generative feature model for object retrieval in ICCV  2007  L Fei-Fei R Fer gus a nd P  Perona  Learning generati v e visual models from few training examples An incremental bayesian approach tested on 101 object categories in CVPRW 04  2004 p 178  A T o rralba K P  Murphy  W  T  F reeman a nd M A Rubin Context-based vision system for place and object recognition in ICCV 03  2003 p 273  K Mik o lajczyk a nd C Schmid  A performance e v aluation of local descriptors PAMI  vol 27 pp 1615–1630 2005  C Schmid a nd R Mohr   Local grayv a lue i n v ariants f or image retrieval PAMI  vol 19 no 5 pp 530–535 1997  J Philbin O Chum M Isard J Si vic and A  Z isserman Object retrieval with large vocabularies and fast spatial matching in CVPR  2007 
501 
472 
515 
475 
 


Service delivery should require a contract between the service owner and the service user. Service acquisition can be affected via different models depending on the nature of both the owner and the user. For example, if the service owner is a commercial firm and the user is the Federal government, in most cases the government is required to conduct a fair and open solicitation to acquire the service Service contracts may be directly affected by the initial provider/consumer relationship. Some commodity services may be created by one organization and consumed by another.  These will follow the more traditional direct and brokered contract formats.  Other services will be developed within an enterprise and consumed by another business unit or division of the same enterprise Contracts will most likely reflect cost recovery or direct expense models There are numerous mechanisms for electronic payment for services rendered. Two models of particular interest to the service migration model are PayPal and eBay. In both, the client establishes an account for automatic payment upon acknowledgement of a contract. Once the account is debited, the service is transferred to the client. Both of these methods incorporate mechanisms for disputes including nondelivery and quality of service  8.1  Information Transport Costs and Controls  Services implemented in software represent a capability that is likely to be subject to taxation. If not in the United States, certainly overseas, such as the European Union s Value-Added Tax. The application code for services may be treated as a manufactured object, although clearly it is not quite Transport of service application code across national boundaries raises some interesting legal problems that will have to be thrashed out in the coming years For example, can service application code transit national borders in a manner similar to an airplane flying through a countries national airspace In the United States, many businesses already make use of software services located outside our boundaries. Today, it is largely restricted to shipping data overseas. But, technical progress has encouraged fragmentation within the service sector. In the future as certain countries develop indigenous software development capabilities at cheaper cost than companies in the US, companies may find it \(much cheaper to import the services rather than export the data. Since data/information is a fundamental asset of many corporations, this will serve to protect corporate information, but at the expense of purchasing services from foreign providers Many countries restrict the export of data, even if it belongs to multinational corporations, beyond their boundaries. And, many countries are seeing the transport of services as subject to tariff\(s\ust like tangible goods  9  Assessing Utility, ROI, and Risk  The table below summarizes the attributes of a service migration ESA and the issues and needs they address  Service Migration ESA Attribute Addresses Issue or Environmental NeedCondition API w/ data receipt/emit attribute broadcasting; list dependencies Consumer opt-in and multiplatform support Exposes Candidate Services Service Discovery and automatic negotiation Predefined, Limited Transaction Commodity based scaling serving multiple user types Adapts to Operational Context Complies with local policies and other services Service Eviction Capability manages Clean-up and Removal Graceful exit and termination under various conditions Possesses Knowledge of Integration Environment Predictable and compliant execution Self Configurable Leverages local resources in a platform compatible manner Dynamic Service Composition and Delivery Load and configure in response to user demand Security Execution Directives Consistent reliable auditable logging and local security policy compliance  The business utility of on-demand services is hypothesized to be high because on-demand acquisition of data analysis and processing services is likely to increase organizational flexibility. This is an Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


important characteristic in an age of dynamic change mergers, outsourcing, and extensive competition Utility will also increase because exposed services provide otherwise walled off information to users with rights to the service and its underlying data Organizationally-controlled libraries of composable application services would strengthen reuse and cross-organizational sharing of processes, limit N+2 reuse costs. Finally, user experimentation will be more frequently possible with vendors offering nocost trials or limited usage, low fee experiments that will encourage innovation in IT and in the design of programs for services Controls for ROI, and cost-benefit analysis will be strengthened because large single vendor sources will not be mandated. Instead, service consumers can assemble large complex solutions organically by procuring many small and relatively inexpensive services a few at a time.  This spreads the spending plan for the enterprise over time and across multiple suppliers and directly supports incremental development approaches Enterprises using assimilated ESAs composed of multiple services will reduces risks as they transfer the complexities associated with maintaining a highly available hosting environment to external partners who would specialize in that line of business, thus limiting their own risks  10  Future Work and Conclusions  We have suggested a new model for providing services within enterprise system architecture Exploration of this new model requires a theoretical analysis of the economic and business utility issues; a functional analysis to determine the types of services amenable to this model; and a prototype system to explore the design, development, and implementation of the infrastructure, the services, and their execution We have briefly described a new approach to an ESA: a service migration concept that extends the notion of a service-oriented architecture. We have address several, but not all, of the challenges that can affect the implementation of such an approach and suggested some solutions. Our intent is to open a dialogue on this approach and solicit feedback from interested parties. We are developing a research program to explore some of the ideas expressed here and welcome collaboration from other interested parties  11  References  1 A r m our, F K a is le r, S., a nd S L i u A Bi g P i c t ure L o ok  at Enterprise Architectures IEEE IT Professional Vol 1\(1\999a. Translated into Japanese and reprinted in Nikkei Computer 1999.9.13 issue, Tokyo, Japan  2 A r m our, F., K a is le r, S., a nd S. L i u B uil d ing a n  Enterprise Architecture Step-by-Step IEEE IT Professional Vol. 1\(3\, 1999b  3 A r m our, F. a nd S. K a is le r Enterprise Architecture Agile Transition and Implementation  IEEE IT Professional Nov/Dec 2001, pp. 30-37  4 Erl  T hom a s 20 05  Service-oriented Architecture Concepts, Technology, and Design Upper Saddle River Prentice Hall PTR  5 Fie l di ng R  T  2000 Architectural Styles and the Design of Network-based Software Architectures Ph.D Dissertation, Dept. of Information and Computer Science Univ. of California, Irvine http://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arc h_style.htm    ler, S  an d F  A r m o u r. 200 5 Enterprise Architecting: Critical Challenges 39 th Hawaii International Conference on Systems Sciences Waikoloa, Hawaii   a i s l e r, S  2 005 S o f t w a re Paradi g m s  Joh n Wi l e y  Sons, New York  8 Mil o jic ic D F. D oug la s  Y  P a i nda v e ine  e t a l 20 00   Process Migration ACM Computing Surveys, 32\(3 241-299  9  P o l l a k B  E d 20 06   Ultra-Large-Scale Systems: The Software Challenge of the Future CMU Software Engineering Institute, Pittsburgh, PA  10 Sm ith, J  M. 19 88  A Survey of Process Migration Mechanisms  ACM-SIGOPS Operating Systems Review  pp. 28-40  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


11 nI KK t nn nn nd nd nd nd X yz yz y y z z a      13 The heading estimate  can then be calculated geometrically using the relative displacement of the lateral components of the intersection line in the navigation frame x = East and y = North 14        min,max min,max,atan2  xx yy II II?  \(14 4. THEORETICAL PERFORMANCE USING SYNTHESIZED FEATURES Simulation Procedure This section will describe a simulation that was developed to assess the theoretical heading accuracy possible from ALS data and a perfect synthesized feature.  The first step of the simulation was to define the scanner parameters that reflect those likely to be used in a flight test: 30 lines per second, 10,000 pulses per second, and a  30 deg field of view.  ALS angles, times, and ranges were then simulated using these parameters.  A ground feature was synthesized by replacing the simulated ranges at the correct ground positions with those calculated according to the desired feature parameters \(i.e. plane equations synthesis and plane intersection procedure described in this section is summarized in the block diagram shown in Figure 8  Figure 8: Feature Synthesis and Plane Intersection Block Diagram Table 1: Simulation Parameters Parameter Value Aircraft Altitude 350, m Points in Surface 1 127 Points in Surface 2 248 Feature Length 25.79, m Feature Width 51.12, m The synthesized feature for this paper was based on airborne measurements of the size, location, and roof slope parameters of the AEC hangar at the Ohio University Airport.  For an aircraft at ~350m altitude in the simulation the synthesized hangar would be illuminated by 127 points 


on surface 1 and 248 points on surface 2 contained within a feature footprint with dimensions of 25.79 m long x 51.12 m wide as summarized in Table 1.  The flight profile from a January 2005 flight test [7] was used to establish the aircraft position and orientation over the two second flight duration needed to extract the simulated feature.  For the data collection phase, the hangar building was over flown while collecting GPS, INS, and ALS data.  In the synthesis phase actual GPS and INS information were used, but the ALS data was replaced with simulated data so that the ALS measurement errors could be controlled.  The heading derived from the measured ALS flight data will be compared with the simulation in the next section Two existing simulators were used to generate the ALS scan angle and ranges measurements [9].  An angle simulator was used to produce an array of angles and times that correspond to the laser scanner parameters.  A range simulator was used to produce range estimates by calculating the geometric difference between the ALS height and the terrain crossing \(simulated using a Digital Terrain Elevation Data \(DTED terrain crossing was found by increasing the range until it intersected the terrain and then iterated until the height accuracy was within some threshold \(1 ?m in this case The simulated range accuracy was determined from the height accuracy using the geometric relationship described in \(15 7 cos dHdR =  \(15 where dR = Range accuracy dH = Height accuracy ALS scan angle The top subplot of Figure 9 illustrates the range accuracy threshold used by the simulator \(determined from the height error and \(15 can be seen in the bottom subplot of Figure 9 because of the range iteration technique.  A 1 ?m height accuracy \(iteration threshold sufficiently small \(i.e. approximating true range influence the standard deviation of the final simulated range measurement \(i.e. true range + sensor noise better represent the capabilities of the true ALS, 25 mm of Additive White Gaussian Noise \(AWGN range measurement as shown in the top subplot of Figure 10 following with the Gaussian distribution function shown in the bottom subplot.  The DTED accuracy was not important for this analysis since only the range measurements to the simulated feature were required for the orientation calculations.  The range to the DTED merely provides terrain measurements for height contrast in the feature extraction algorithms  Figure 9: Range Error Distribution from the Simulator   Figure 10: Range Error + Noise Distribution with 25 mm Noise The feature was synthesized by calculating its height using the planar equations for surface 1 and surface 2 of the AEC hangar roof and the illuminated ground pulse positions as shown in \(16 2 22 11   BH BH   


 Surface Surface V V 16 where V = Vertical height H = Horizontal position vector   B = Plane parameters \(Surface 1 or Surface 2 Pulses that fall within a predetermined space \(represented by white space in Figure 11 points.  The DTED terrain heights at these positions were replaced with feature heights from a feature database prior to range simulation. The synthesized feature is shown in Figure 12  Figure 11: Synthesized Feature Footprint   Figure 12: Synthesized Feature Extraction Simulation Results for Typical System Performance Once a feature has been simulated, the feature extraction and plane intersection algorithms described in the previous section are used to determine the feature orientation.  The result of the least squares plane fit is shown in Figure 13 Notice that a gap is present near the ridgeline in Figure 13 This is due to the exclusion of the actual ridge point Because the peak of the roof contains a ridge cap, inclusion of these points in surface 1 or surface 2 would distort the results.  By using the plane intersection method, these few points \(16 hundred other points would remain in the plane.  The height residuals after subtracting the plane fit are shown in Figure 14.  As expected, these height residuals reflect the same accuracy  25 mm 1 shown previously in Figure 10.  The plane residuals shown in Figure 14 can be used to measure the range accuracy directly from the data.  The next section will describe how to use this information to predict the heading accuracy 8  Figure 13: Data Point Segregation and Plane Fit   Figure 14: Plane Fit Residuals The plane parameters, 1B  and 2B  are then used to find the equation of the intersection line as is shown in Figure 15 The intersection line contains heading information for comparison with some reference data.  In this case, the reference was derived from the same range simulation without noise  Figure 15: Plane / Plane Intersection Line Multiple repetitions of the synthesized feature extraction and plane intersection algorithm were used to determine the repeatable accuracy of the technique over 5000 Monte Carlo runs as shown by the block diagram in Figure 8.  The resulting 1? heading accuracy is shown in Figure 16 for  25 mm 1? ALS range accuracy  Figure 16: Heading Accuracy for 25 mm Range Error The error performance is summarized in Table 2.  The bias term is statistically zero \(as would be expected from the zero mean AWGN added to the simulated range heading error is better than a tenth of a degree Table 2: Heading Error Summary Error Type Magnitude Heading Error Mean 4.0778 x 10-4, deg 1? Heading Standard Deviation 0.0395, deg 0.69, mrad 


1? Heading Standard Deviation 0.0395, deg 0.69, mrad Sensitivity Analysis for Varying System Performance In order to understand how the heading error varies with parameters such as laser ranging accuracy, position accuracy, and heading bias, a sensitivity analysis was conducted.  For computational efficiency the number of repetitions at each parameter setting was reduced to 1000 For each set of 1000 repetitions of the plane intersection algorithm, the one parameter was linearly increased and its affect on the heading accuracy was assessed.  The range accuracy will be considered first, whereby the simulated range noise was increase in 46 steps from 0.001m until 0.31m.  The heading error is computed by comparing the noisy simulated feature intersection with a noise-free feature intersection.  Figure 17 shows the increase in heading standard deviation as the range standard deviation increases while Figure 18 shows the rate of change of the standard deviation per unit of range noise.  Although not shown here the heading resolution bias is zero-mean up to 15 cm and increases to almost 0.6 deg for 30 cm of range noise 9  Figure 17: Heading Error Standard Deviation  Figure 18: Heading Error Standard Deviation Growth Rate per Unit of Range Noise The results shown in Figure 17 illustrate a fairly linear increase in heading error growth for small range errors \(less than 12 cm rate of error growth is constant \(~1.53 deg/m range error.  The results shown in the previous section can be directly estimated using these figures.  If a range noise standard deviation of 25 mm is multiplied by a 1.53 deg/m error growth rate, the predicted heading accuracy would be 0.668 mrad.  This predicted accuracy is approximately the same as the accuracy found from simulation summarized in Table 2 The next parameter to be considered was a constant heading bias.  For the algorithm presented in this paper, the heading bias must be consistent with the position error as would be the case for an IMU operating in a dead reckoning mode Consequently, a heading error was simulated from 0 to 2 degrees in the inertial measurements and then the ENU position was corrupted using the erroneous heading in the direction cosines matrix.  Figure 19 illustrates the residual heading resolution error bias after the simulated heading bias has been removed.  Figure 20 illustrates the standard deviation of the heading resolution error  Figure 19: Heading Resolution Error Bias as a Function of Injected Heading Bias   Figure 20: Heading Resolution Error Standard Deviation as a Function of Injected Heading Bias Up to 2 deg of injected heading bias, there is not discernable effect on the heading resolution accuracy in either the mean or the standard deviation.  This illustrates that the algorithm can detect a constant heading bias without sensitivity to its magnitude The final parameter to be considered was position noise The position noise was varied linearly from 0 to 10 cm in 48 steps.  The response of the error mean to position noise is shown in Figure 21 while the response of the error standard deviation to position noise is shown in Figure 22 10  Figure 21: Heading Resolution Error Bias as a Function of Injected Position Noise   Figure 22: Heading Resolution Error Standard 


Figure 22: Heading Resolution Error Standard Deviation as a Function of Injected Position Noise As the injected position noise increases, the heading error bias remained nearly constant at the mm-level as would be expected since the injected position noise was AWGN Similarly, the heading error standard deviation increases as the injected position noise increases.  As with the laser range noise, the position noise will also determine the heading determination standard deviation.  Inertial positions are generally low noise \(better than 1 cm source is not felt to be as significant of a contributor \(&lt; 0.04 deg As an aside, it is interesting to note that this error will increase slightly as the aircraft height increases.  This is thought to be due to the reduced number of laser pulses that comprise each plane in the intersection equation.  For example, if the aircraft height increases from 350m to 400 m, the pulse count decreases to 68 pulses in surface 1 and 141 pulses in surface 2.  The heading accuracy will decrease by approximately 0.01 degrees 5. FLIGHT TEST PROOF OF CONCEPT  Figure 23: Flight Path over AEC Hangar The flight test data was collected in January 2005 and provided ALS measurements containing several features at the Ohio University Airport including the AEC hangar [7 The flight path over the hangar is shown in Figure 23.  The ALS settings during this flight test were more optimal for this application than for mapping since the gaps between scan lines was large compared to the gap between pulses in a line.  In September 2005, a static GPS survey was conducted \(relative to the KUNI GPS Continuously Operating Reference Station the AEC hangar.  The GPS survey provided an absolute reference to compare with the ALS measurements.  The lateral measurement accuracy of this survey was thought to be on the order of  20 cm because of antenna placement uncertainty Planes were fit to the ALS data from each side of the hangar roof as described previously as shown in Figure 24.  The plane fits are shown in lighter colors \(cyan and magenta than the measured data \(blue and red  Figure 24: Two Planes fit to the Data  Figure 24 is only intended to provide an overview since the plane fit residuals contain more information as shown in Figure 25.  The plane fit residuals indicate 9 cm of height accuracy \(1 11  Figure 25: Plane Fit Residuals The resulting plane intersection line was overlaid on the ALS measurements as shown in Figure 26.  The line was a close visual match, but when comparing the calculated line with the surveyed line, slight errors can be observed  Figure 26: Line Formed by Plane Intersection A closer examination of the two lines in the horizontal plane reveals their differences in the heading as shown in Figure 27  Figure 27: Intersection Line Comparison As mentioned previously, the measured plane-fit residuals provide an indication of the heading accuracy that could be expected from the real data if the survey was perfect.  Since the flight test residuals were within the linear region of the empirical error curves shown in Figure 17, the expected heading accuracy should be predictable.  Since the measured range accuracy is 9 cm \(from the plane-ft residuals heading accuracy is expected to be 0.1377 deg \(at 1.53 


deg/m to 2.4 mrad.  This accuracy is better than the typical heading alignment accuracy of a commercial navigation grade INS The actual heading angle of the two vectors is summarized in Table 3 Table 3: Hangar Ridge Vector Comparison Heading Survey 60.9436, deg Intersection 61.8772, deg Difference 0.9336, deg 16.29, mrad The importance of this proof of concept was to demonstrate the technique and to show that the accuracy can be predicted.  In this case there are several sources of uncertainty that might explain part of the performance degradation The reference survey introduced lateral antenna placement errors of  20cm.  The antenna placement uncertainty is expected to be the dominant error source in the measured data presented here.  Over a 25 m baseline, a  20 cm placement error will become a 0.916 deg pointing error worst case prediction using flight test data Further effort is needed to make a more accurate ground feature survey, but the concept of heading determination from ALS plane intersections has been demonstrated 6. CONCLUSIONS This paper presented results that leverage the accuracy and high number of \(i.e., oversampled measurements along with a priori surveyed features to determine airborne platform heading.  Plane fitting has the affect of averaging the oversampled measurements and can deliver mrad-level heading observations.  The ALS-derived heading information shown in this paper could be used to periodically calibrate tactical grade IMU heading biases while in flight, to perform an ALS / IMU calibration prior to a terrain aided landing, or simply to stabilize the inertial heading measurements when GPS is unavailable.  A simulation was presented to show the theoretical performance of heading determination from plane intersections using typical ALS parameters.  With a perfect survey, the heading accuracy was better than 1 mrad.  Using the same simulation software, a theoretical sensitivity analysis was conducted to determine the effect of range noise, heading bias, and position noise on the heading accuracy.  The heading standard deviation was shown to be a function of the range measurement and position standard deviations.  Inertial positions are generally low noise, so this error source was not deemed to be as significant of a contributor as the range noise.  The heading error magnitude did not change the performance in a noticeable way. This theoretical performance assessment was then compared with 12 flight test data.  While the flight test performance was not as good as expected, the error sources were justified.  Even with large survey uncertainties, the heading measurement performance was still within 1 deg.  If a better survey was available, the flight test results were expected to be accurate to within a few mrad Operationally, there are many things than can be done to improve these results.  This paper discussed flight over a single building.  Accuracy can potentially be improved by flying over multiple buildings of larger sizes and at lower altitudes or other types of features.  Additionally, the heading error growth rates could be predicted by tracking the heading change while flying over a building or between two buildings.  With careful attention to calibration and measurement accuracy, these heading alignments can potentially be made at a higher accuracy than a navigation grade INS can align its heading REFERENCES 1] Schenk, T  Modeling and recovering systematic 


1] Schenk, T  Modeling and recovering systematic errors in airborne laser scanners  Proceedings of the OEEPE workshop on Airborne Laserscanning and Interferometric SAR for Detailed Digital Elevation Models, OEEPE Publication no. 40, 2001, pp. 40-48  2] Crombaghs, M.J.E., Brugelmann, R., and d Min, E.J  On the Adjustment of Overlapping Strips of Laseraltimeter Height Data  International Archives of Photogrammetry and Remote Sensing, 2000, 33 B3/1   3] Dickman, J., and Uijt de Haag, M  Aircraft Heading Measurement Potential from an Airborne Laser Scanner Using Edge Extraction  Proceedings of the IEEE Aerospace Conference, March 3-10, 2007  4] Kraus, K., Pfeifer, N  Determination of Terrain Models in Wooded Areas with Airborne Laser Scanner Data  ISPRS Journal of Photogrammetry and Remote Sensing, 1998, 53, pp. 193-203  5] Maas, H., Vosselman, G  Two Algorithms for Extracting Building Models from Raw Laser Altimetry Data  ISPRS Journal of Photogrammetry and Remote Sensing, 1999, 54, pp. 193-203  6] Venable, D., Campbell, J., and Uijt de Haag, M  Feature Extraction and Separation in Airborne Laser Scanner Terrain Integrity Monitors  Digital Avionics Systems Conference, 2005  7] Campbell, J. L., M. Uijt de Haag, van Graas, F  Terrain Referenced Precision Approach Guidance   Proceedings of the ION National Technical Meeting 2005, San Diego, CA, January 24-26, 2005, pp. 643653  8] http://www.geom.umn.edu/software/download/COPYI NG.html, accessed May 2007  9] V. Nguyen, et. al  A Comparison of Line Extraction Algorithms Using 2D Laser Rangefinder for Indoor Mobile Robotics  Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, Aug. 2-6, 2005, pp. 1929-1934  10] Vadlamani, A  Preliminary Design and Analysis of a LIDAR Based Obstacle Detection System   Proceedings of the 24th Digital Avionics Systems Conference  13 BIOGRAPHY Jeff Dickman graduated from Ohio University in 2008 with a Ph.D in Electrical Engineering His research emphasizes navigation system integration and sensor stabilization.  He has also been involved with GPS landing system research and antenna design and measurement.  He is presently working on vision-aided navigation systems.  He is a member of the IEEE ION, AIAA, Eta Kappa Nu, and Tau Beta Pi  Maarten Uijt de Haag is an Associate Professor of Electrical Engineering at Ohio University and a Principal Investigator with the Ohio University 


Investigator with the Ohio University Avionics Engineering Center.  He earned his Ph.D. from Ohio University and holds a B.S.E.E. and M.S.E.E from Delft University of Technology located in the Netherlands.  He has been involved with GPS landing systems  research, advanced signal processing techniques for GPS receivers, GPS/INS integrated systems, and terrain-referenced navigation systems.  The latter includes the development of terrain data base integrity monitors as an enabling technology for Synthetic Vision Systems and autonomous aircraft operation      pre></body></html 


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 



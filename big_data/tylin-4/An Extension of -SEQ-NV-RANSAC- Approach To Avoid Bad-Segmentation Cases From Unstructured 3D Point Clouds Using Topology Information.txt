An Extension of \215SEQ-NV-RANSAC\216 Approach To Avoid Bad-segmentation Cases From Unstructured 3D Point Clouds Using Topology Information Tarek M. Awwad State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing Wuhan University, China Eng_Tarek_Aww20@hotmail.com Qing Zhu State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing Wuhan University, China zhuqing@lmars.whu.edu.cn Qiaoxiong Li State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing Wuhan University, China liqiaoxiong1@163.com 
Abstract 
204 
Recently many applications require an automatic processing of massive unstructured 3D point clouds in order to extract planar surfaces of man-made objects. While segmentation is the essential step in feature extracting process, but badsegmentation results \(i.e. Under and Over-segmentation\till standing as a big obstacle to extract planar surfaces with best fit reality. In this paper, we propose an extension of \215SEQ-NVRANSAC\216 approach to avoid the bad-segmentation problems using topology information and intuitive threshold value. First, in order to avoid the under-segmentation problem, we check each one group which resulted from original \215SEQ-NV-RANSAC\216 approach to get all neighbours points which have Euclidean 
distance less than the threshold value as a one surface group T his process will be repeated until no more points can be adding to that surface group. Then a new surface group will be created to check the remaining points. Second, in order to solve the oversegmentation, we propose three checks; the similarity of normal vectors \(NV\ the perpendicular distance and the intersection zone using bounding box test 
I I NTRODUCTION Terrestrial Laser Scanner \(TLS\ta are provided in massive unstructured 3D point clouds \(randomly distributed 
Keywords-component; TLS; unstructured; 3D point clouds planar surface; RANSAC; under-segmentation;  over-segmentation 
since  the spatial point distribution and the point density cannot be assumed as fixed [1 A l s o  in th e c a s e  of 2  5D ran g e  im ages  once two or more such images are registered; the resulting data loses its 2.5D character and has to be represented as an unstructured 3D point cloud [2   M a ny a p p l i c a t i o ns  suc h a s  3 D  modelling, documentation, reconstruction, restoration and asbuilt surveys, require automatic processing to extract planar surfaces of the recorded man-made objects. The goal is creating a precise and proper realistic 3D model that best fits reality [3 sh o w t h e si tu at io n an d co n d itio n o f o b j ect  The segmentation is the most important step in the feature extracting process, since the extraction of features of the 
different building elements basically depends on the accuracy of the segmentation st u a l l y s e gm e n t a t i on  f o r massive unstructured 3D point clouds leads to badsegmentation results that consists of; \(1\der-segmentation several features segmented to one segment; and \(2\versegmentation: one feature segmented to several segments Therefore, the bad-segmentation results are still standing as a big obstacle to extract even planar surfaces with best fit reality In this paper, we propose an extension of \215SEQ-NVRANSAC\216 approach [5 to a v oi d th e ba ds e g m en tati on ca s e s  for planar surfaces from massive unstructured 3D point clouds as respect to a common acquisition data II R ELATED W 
ORK The segmentation process is defined generally as a grouping of elements such as points into one region, which shares similar spatial properties. Many algorithms have been designed to segment planar surfaces from point clouds using one of three distinct methods; region growing  cl u s t e r i n g  of  features [1 an d m odel f itt i n g 7  8   W h il e th e l as t  on e is  based on fitting geometric primitive shapes, the first two are based on geometric criteria for grouping homogeneous regions The region growing method, by [9  id en tif ie s  homogeneous elements in data that is restricted to one seed element. It does suffer from main difficult disadvantage of having to define the correct seed element, since if the definition 
is wrong, the error will grows and all processes will fail Therefore, it can be considered as a sensitive method for noisy data. Also, when it is utilized for segmentation of unstructured point clouds, it leads to bad-segmentation results [6  The method based on clustering features offers a flexible way to identify homogeneous elements in the data based on attributes, without being restricted to one specific element. But computationally clustering multidimensional features for large data volumes is very expensive. Also it is sensitive to the noisy data, since it is influenced by the quality of the computed attributes [1 th en it c a n  b e le a d s to  b a d seg m e n tatio n r e su lts   
The model fitting method is based on fitting geometric primitive shapes, and then the points are conformed by the mathematical representation that would be grouped as one segment. Two widely known algorithms in line with model fitting methods are the RANSAC \(Random Sample Consensus algorithm [1 n d t h e Ho ugh-t r a nsfor m a l gor i t h m 1 1  W h i l e  these two algorithms were used before for processing point clouds with major aim of constructing 3D building models, an important comparison has been made between them in terms of 978-1-4244-4994-1/09/$25.00 \2512009 IEEE 
 


processing time and sensitivity to cloud characteristics using Airborne Laser Scanner \(ALS\data in [1 th e au th ors s h o w  that; the RANSAC algorithm is more efficient than the Houghtransform algorithm, since the difference in processing time is negligible between them even when data size is very large and Hough-transform is also very sensitive to the segmentation parameters values Several variation for RANSAC algorithm, to segment planar surfaces, have been suggested such as the adaptive RANSAC algorithm [13  N o r m al Driv en RA NSA C a l g o r ith m  ND-RANSAC\7 an d s e q u e n tial a p p l i cat io n  o f RA NSA C [8    The RANSAC algorithm has the great advantage of being robust, even with the existence of much noise. On the other hand, it has suffered from spurious results of parallel-gradual planar surfaces. In order to avoid the spurious planar surfaces we proposed in [5 an a p pr oa ch c a ll ed S e qNVR A NS A C  using additional normal vector \(NV\heck between each point and the hypothesis RANSAC plane, which is created based on three random points. Huge point clouds of LIESMARS faÁade are used, as shown in Fig. 1, as a clear example of massive unstructured 3D point clouds obtained of a complex faÁade While all main planar surfaces of the complex faÁade which have many different levels, orientations and includes parallel-gradual planar surfaces, are segmented successfully to groups in sequence \(Seq\d automatically using çSeq-NVRANSACé without any spurious results as shown in Fig. 2, but there still are some groups having bad-segmentation cases Figure 1 Full point clouds  of LIESMARS faÁade \(2,663,333\, as examble for a complex object Figure 2 Eighty-two groups of planar surfaces are segmened by Seq-NV-RANSAC Fig. 3 shows some examples for under-segmentation cases for example, while the yellow colour shows those points are grouped to one group, but in reality it includes many different beams. Also Fig. 4 shows examples for over-segmentation while the red and blue colours are grouped to two groups, but in reality the two groups are belong to only one surface Figure 3 Examples of some groups having under-segmentation problem shown by one colour for each group Figure 4 Examples of oversegmentation problem shows by different colours for one surface In this paper, we propose an extension of çSEQ-NVRANSACé approach to avoid bad-segmentation problems using topology information under an intuitive threshold value III M ETHODOLOGY A Under-segmentation Under-segmentation problem defines as a several features are segmented as a one group \(see Fig. 3\. It arises when encountering special cases such as two or more planar surfaces having the same NV and being at the same level. That problem can be solved by using the topology properties for point clouds and surfaces since all surfaces which are in one group should have a space area between them, due to features which were segmented to other groups. Therefore, in one group which is including more than one surface, all point clouds which are involving to the same surface should become neighbours under a restricted threshold value for Euclidean distance th UE Which is choosing practically based on smaller space distance between different adjacent planar surfaces The methodology is used for modifying çSEQ-NVRANSACé approach, to avoid under-segmentation problem, is based on choosing a random point from that group under study and acquire the neighbours for that point under threshold value th UE which is based on fixed distance neighbours method FDN\and the metric distance used is the Euclidean distance       3 2 1 n i i i i i E E E E E 002  Then choose second point from accepted neighboursê points. This process will be repeated automatically until no more point clouds can be added to that surface group. If there still are some points not accepted yet in the input group, then a new surface group will be created in the output file to check these remaining points B Over-segmentation Over-segmentation defines as one feature is segmented to several groups \(see Fig. 4\ It arises due to the influence of the noisy points on the calculation of initial NV, which leads to a big difference between the calculated NV of that point and the hypothesis RANSAC plane. The choice of the tolerance \(Tol threshold value, in original çSEQ-NV-RANSACé, may be leads to the same results. Also over-segmentation problem can be solved by using the topology propertiesê for point clouds and surfaces since these groups which are involves to one surface should be shares in three parameters; \(1\ the similarity of NV, \(2\ small perpendicular distance P D as in \(1\, between each point that located in one group and plane equation of another group under study, and \(3\he intersection zone between these two groups  2 2 2       z y x z y x n n n d Z n Y n X n PD          1 Methodology to solve over-segmentation is based on three steps; firstly clustering whole groups according to NV under threshold value th n 003 Since NV direction is based on the sequence for choosing the three random points by RANSAC therefore our check considers the opposite NV direction Secondly grouped every cluster group again based on the average summation of perpendicular distances \(AveSumDis as in \(2\ween one group and total points \(PointNo\hich located in another group using threshold value for minimum summation of perpendicular distances \(MinSumDis  i No Po PD AveSumDis  int    2 004  2 
 


Thirdly  check groups, which have the same NV and MinSumDis\, using threshold value for minimum number of points \(MinPointNo\ into intersection zone by calculating the bounding box for every group. Then groups are achieving the three conditions together, should be involves to one surface IV E XPERIMENTAL R ESULTS A ND A NALYSIS A Under-segmentation As shown in Fig. 3, the yellow colour shows a clear example for under-segmentation case. Therefore a restricted threshold value th UE is added to solve that problem based on the smaller space distance between different adjacent two planar surfaces using Octree to speed up this step. The threshold value th UE must be a balance between the space distance for adjacent planar surfaces, shown in Fig. 5Öcase 2 and the space distance inside one planar surface, shown in Fig 5Öcase 1. The space distance inside one surface is due to holes and\\or shadow in the data acquisition The importance for choosing the value of threshold th UE carefully is due to that; it is should be selecting practically. For example; if th UE is setting bigger than the smaller distance between adjacent two planar surfaces, then although undersegmentation problem can be solved successfully for one element such as the red beams in Fig. 5, but over-segmentation problem will be arisen again in other elements such as the stairs and \\ or ground, since they will be divided to several groups Figure 5 Examples of space distance, \(Case 1\ is inside one planar surface and \(Case 2\ is between different adjacent two planar surfaces Fig. 6 shows the under-segmentation problem is solved successfully for beams without any bad effect on the other surfaces, stairs and ground data by setting th UE 100 Finally, while Fig. 2 shows Eighty-two groups of planar groups were segmented by çSeq-NV-RANSACé, Fig. 7 shows three hundred and sixty-three groups of planar surfaces are segmented successfully and automatically after solving the under-segmentation problem using threshold value th UE 100 Figure 6 Under-segmentation problem is solved successfully for beams data without any bad effect on the other surfaces Figure 7 Three hundred and sixtythree groups of planar surfaces are segmented by the modification of Seq-NV-RANSACé problem B Over-segmentation According to Fig. 7, while the under-segmentation problem is solved successfully, but obviously the over-segmentation problem is displayed for many different surfaces. Fig. 8-b and Fig. 9-b show the most common two cases as examples of over-segmentation problem by different colours for each group Figure 8  Figure 9 Different two examples of over-segmentation cases. \(a\ Original surfaces b\he  results are displayed by different colours for each one group The methodology for solving over-segmentation problem is based on using three threshold values to select and merge groups; \(1 th n  the similarity of NV with considering opposite NV direction, \(2\ MinSumDis: minimum summation of perpendicular distances, and \(3\MinPointNo: minimum numbers of points are existing in the intersection zone By analysis the three hundred and sixty-three groups of planar surfaces, shown in Fig. 7, we conclude that; no ideal and constant values for the three threshold values to achieve all surfaces by one trial. For example, while a lot of groups which have over-segmentation problem can be selected and merged by using threshold values th n  5, MinSumDis = 20 and MinPointNo = 50\, there are other groups canêt be segmented yet. This problem still exists until remove these surfaces which were merged successfully. Then repeat the previous process again for remaining groups using a new threshold values Therefore, this process are classified as a semi-automatic process, since the main steps to select and merge groups will be done automatically and then the user will selects the accepted surfaces and remove it and then decide to stop or continue to the next trial. Fig.10 shows two hundred and eighty-one groups of LIESMARS faÁade are segmented automatically using the initial three threshold values as a first trial Figure 10 Two hundred and eighty-one groups of planar surfaces are segmented automatically from the first  trial Fig. 11 shows one hundred final surfaces are accepted by user after first trial and Fig. 12 shows one hundred and eightyone groups are remained from first trial Figure 11 One hundred planar surfaces are accepted finally by user after first trial Figure 12 One hundred and eighty-one groups are remained after first trial 
 


Since many trials were needed to segment all planar surfaces successfully, Table I shows the inputs and the results for each trial respectively TABLE I THE INPUTS AND THE RESULTS FOR EACH TRIAL RESPECTIVELY Trial No Total No of input groups Threshold Values Total No. of output groups from oversegmentation step By User  th n  MinSumDis MinPointNo Accepted surfaces remaining groups 1 363 5 20 50 281 100 181 2 181 5 30 50 114 60 54 3 54 5 51 50 50 11 39 4 39 20 51 50 33 19 14      Finally, By comparing the final results are obtaind by modified çSeq-NV-RANSACé shown in Fig. 13, the original point clouds shown in Fig. 1 and the results are obtained by original çSeq-NV-RANSACé shown in Fig. 2, obviously all main planar surfaces \(one hundred and ninety surfaces\h as the stairs, walls, ground, windows and beams are segmented successfully without any bad-segmentation results using the modified çSeq-NV-RANSACé approach Figure 13 One hundred and ninety planar surf aces are segmented successfully as final surfaces by the modification of çSeq-NV-RANSAC V CONCLUSION AND FUTURE WORK This paper presents an extension of çSeq-NV-RANSAC Approach to avoid bad-segmentation results \(i.e. under and over-segmentation\ from unstructured 3D point clouds using the topology information and an intuitive threshold values While under-segmentation process is considered as an automatic process, the over-segmentation process is considered as a semi-automatic process Finally, modified çSeq-NV-RANSACé approach has potential results since the main stated objectives of this paper are achieved successfully, brings an improvement in quality of the final results and increases the degree of automation of surface extraction. Consequently, it encourages the automatic creation of 3D models directly from 3D point clouds. Also it should be worked well based on any segmentation results even if these point clouds are acquired by different acquisition data source such as ALS or through image matching, Since usually the acquisition data sources acquire unstructured 3D point clouds and our proposed approach needs only the coordinates of point clouds \(X, Y, and Z\ and the initial groups for the planar surface Future work will focus on determination of threshold parameters adaptively and edges extraction A CKNOWLEDGEMENTS This paper is supported by National Basic Research Program of China \(973 Program, No. 2010CB731800 National Natural Science Foundation of China \(40871212 and 40721001\nd the National High Technology Research and Development Program of China \(2008AA121600 R EFERENCES 1 S F i l i n  S ur f a ce cl us te r i ng f r o m a i r b o r ne l a s e r s c a n ni ng  da ta   in  International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, vol. 34, pp. 119-124, 2002 2 T Ra bb an i, F  v a n de n H e uv e l an d G  V o s s e l m ann  S e g m e ntat io n o f  Point Clouds Using Smoothness Constraint," International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, vol. 36, pp. 248-253, 2006 3 F  R e m o n d i n o, "F rom p o i n t c l oud t o s u rfac e: th e m o d e li n g an d visualization problem," International Archives of Photogrammetry Remote Sensing and Spatial Information Sciences, vol. 34, 2003 4 P Ro dr g ue z G o nz l ve z  D   G o nz le z A g uil er a, an d J  G  m e z  L a ho z   From Point Cloud to Surface: Modeling Structures in Laser Scanner Point Clouds," in Proceedings of the ISPRS Workshop Laser Scanning 2007 and SilviLaser 2007, vol. 36 \(3/W52\. Espoo, Finland 2007, pp. 338-343 5 T M. A w w a d an d Q  Z h u  A n im pr o v e d s e g m e n tatio n a ppr o a ch f o r  planar surfaces from unstructured 3D point clouds PHOTOGRAMM REC., in press 6 S P u a n d G  V o s s e l m an A uto m a tic Ex tr ac tio n o f  Bu il di ng F e atur e s  From Terrestrial Laser Scanning," International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences vol. 36, Dresden, Germany, pp. 5, 2006 7 F Br e t ar a n d M  Ro ux  E x t r a c t io n o f 3D pl a n ar pr im i t iv e s f r o m r a w  airborne laser data: a normal driven RANSAC approach," in IAPR Conference on Machine Vision Applications. Tsukuba  Science City Japan, 2005, pp. 452-455 8 H Bo ul aas s a l  T   L a nde s  P  G r us s e nm ey er and F  T a r s haK u r d i   Automatic segmentation of building facades using terrestrial laser data," in Proceedings of the ISPRS Workshop Laser Scanning 2007 and SilviLaser 2007, vol. 36 \(3/W52\ Espoo, Finland, 2007, pp. 6570 9 P  J   B e s l a n d  R   C  J a i n  Segm en t a ti on th rou gh va ri ab le-ord er  surface fitting," IEEE T PATTERN ANAL, vol. 10, pp. 167-192 1988 10 M  A  F i sch l e r an d R   C Bo l l e s, "Ran d o m sam p l e co n s e n s u s  a  paradigm for model fitting with applications to image analysis Communications of the ACM, vol. 24, pp. 381-395, 1981  P V  C  Hou gh M eth od an d m e a n s for rec ogn i z i n g c o m p lex patterns," U. S. Patent 3069654., 1962 12 F  T a r s haK u r di, T  L a nde s  a n d P  G r us s e nm e y e r  H o u g h t r a ns f o r m  and extended RANSAC algorithms for automatic detection of 3D building roof planes from lidar data," in Proceedings of the ISPRS Workshop Laser Scanning 2007 and SilviLaser 2007, vol. 36 3/W52\. Espoo, Finland, 2007, pp. 407-412  R  Ha rt ley a n d A   Zi s s e rm a n  Mu lt iple Vi e w  Geom et r y i n C o m put er Vision, Second Edition ed: Cambridge university press, 2003, pp 117-121 
 


5 Figure 8 Borrow Pit truth DEM   Figure 9  Image of the Lakebed captured by the thirty degree fov camera   Figure 10: Lakebed DEM  Lakebed  The Lakebed is the second man made target site and is also located at NASA Dryden Flight Research Center.  With its flat, featureless surface, the naturally occurring dry lakebed is an ideal site for determining the LIDAR\325s ability to detect targets.  To this end, nine hemispheres of various sizes and albedos, a s ingle one meter cardboard cube, a cluster of four one meter cardboard cubes and eleven attitude targets where placed there.  The site was surveyed and a truth DEM was created  Figure 9  and Figure 10 show t he Lakebed site as seen by the thirty degree field of view camera and the truth DEM, respectively  Mars Hill  Seen in Figure 11 Mars Hill is the only naturally occurring target sight of FT1.   Located within Death Valley National Pa rk this site is approximately 200 miles away from the Lakebed and Borrow Pit.  With its natural rocks, slopes and lack of vegetation this site is a perfect analog for lunar terrain.  Plywood attitude targets, seen as white dots on the right of the hill and cardboard boxes were placed at Mars Hill   Figure 11  Mars Hill captured by the thirty degree fov camera   5  T RAJECTORY R E CONSTRUCTION  Overview  For FT1 the objective of the trajectory reconstruction process is to provide the position and attitude of the LIDAR for every LIDAR sample relative to a target Initially, it was proposed to develop an Extended Kalman Filter EKF to produce the LIDAR attitude and position by combining the GPS position  data the IMU  angular rate data  and the camera based attitude estimates However the development of the filter stalled  In order to provide results in a more timely fashion a simpler method was adopted  The new process is as follows  To begin the raw GPS data is processed to pro duce the position measurements accurate to a standard deviation of two centimeters.  Second, the images produced by the wide angle camera are manually sorted through to find images 5% Rock Field  10% Rock Field  Artificial  Craters  Cardboard  Boxes  


 6  that contain six or more attitude targets  Once the images were identified  they are used to determine the camera attitude Because the cameras infrequently captured images of the attitude targets the camera generated attitudes are used to initialize IMU based attitude  propagation   Finally g yro propagation is combined with t he GPS measurement to provide the full LIDAR pose \(postion and attitude  T his section details the reconstruction process  Initially w e present the GPS processing methodology followed by the imagery based attitude estimation process  After that t he equations used to propagate the attitude estimate based on the IMU data are given   Finally we provide how the camera estimates, gyroscope propagation and GPS position data are all combined to re produce the LIDAR pose  G PS Data Processing  The  GPS hardware co nfiguration of FT1 consists of two receivers, one is a static base station on the ground, and the other mounted on the helicopter. The data recorded by both receivers is analyzed to derive the precise positions of each  To obtain the precise position of a receiver, the data logged by the receiver is processed together with satellite orbit position and clock information. The quality of the GPS orbit and clock information used in the data processing defines the accuracy of the receiver position solution  In the final processing of the GPS data for FT1  we use the precise GPS orbit and clock information called the FLINN product. This product is produced at JPL by processing tracking data from 80 globally distributed ground stations, with about 10 days  latency and 3 cm accuracy The product is routinely generated and submitted to Interna tional GNSS Service IGS\to support precise applications i n science and industry communities           Figure 12  GPS data post processing for trajectory reconstruction  Our solution approach is illustrat ed in  Figure 12 At the left of the image is the data collected during a flight.  The center column represents a GPS processing method and the right hand side is the product and its solution accuracy  Each method is now described in detail  Base Station Static Point Positioning 321 The base station receiver d ata is processed using the FLINN GPS orbit and clock product The combination of GPS measurements at two different frequencies, commonly known as L1 and L2 are used to remove the effect of the ionosphere on the  measurements To further improve accuracy data points with tracking elevation angle below seven degrees are excluded Given two hours or longer hours of data the typical accuracy of the static point position solution is three centimeters  Helicopter Kinematic Point Positioning 321 Initially, the flight receiver data is processed to determine the helicopter\325s position using a kinematic point positioning technique  Again L1 and L2 GPS measurem ents are used to remove the effect of the ionosphere  Then using the best FLINN GPS orbit and clock information, the absolute the kinematic point positioning is determined to within twenty centimeters Here, the main error source for the solution is the correlation between the troposphere delay and the position height component   This solution is used as the initial trajectory for the relative positioning solution  Helicopter Kinematic Relative Positioning 321 The base station receiver data and the flight r eceiver data are processed together to determine the helicopter\325s position relative to the base station. In the relative positioning, those errors that are common to both the base station receiver data and the flight receiver data, such as the GPS orbit an d clock errors and troposphere and ionosphere delay errors, cancel out over a short baseline In our process the base station position is fixed to the st atic point positioning solution and the helicopter\325s position is solved iteratively starting with the kinematic point positioning solution To do so we use the GPS pseudorange and carrier pha se measurement at frequency L1   Typically the helicopter\325s position error relative to the bas e station has a two centimeter standard deviation   Image Based Attitude Estimation  The objective of the image based attitude estimation is to provide attitude measurements while over a test site  Because the image based attitude estimation does not drift as the IMU does it serves as an anchor point  for the IMU data processing and the final trajectory reconstruction  The initially proposed procedure for the image based attitude estimation was the following  First the image sequences containing a sufficient number of attitude targets were manually extracted  Then using these images the image pose was estimated.  Last we appl ied a bundle adjustment using the estimated pose and selected track features of an image series to improve attitude and position estimates  However many image sequences  contained a lack of distinguishable features  or the target field was Flight  Receiver  Data  Kinematic  Point  Positioning  20 cm level  Trajectory  GPS  Orbit & Clock  Data  Differential  Positioning  Process  2 cm level  Relative  Trajectory  Base  Receiver  Data  Static  Point  Positioning  3 cm level  Static  Position  


7 relatively small compared to the full  image For these  bundle adjustment produced bad results  Therefore a method was adopted that relied on the  kinemat ic relative GPS position rather than estimating it from imagery This method is as follows  Image Rectification  and  Attitude Target Extraction 321 Initially  seq uences of images containing six or more attitude targets were found Prior to inspection we use d the camera CAHVOR model 4  to rectify each image.  Then  a manual scan was  made of every eighth frame  If any attitude targets were  seen the skipped frames were  examined to determine the exact frame in which the targets initia lly appeared.  By comparing this frame to the surveyed locations of the attitude targets each target was  identified and its x  and y pixel loca tion were  recorded Th e se  locations  are  then used to initialize an automatic tracking algorithm  To track  the target locations each image frame in a sequence  containing the attitude targets wa s passed through a Scale Invariant Feature Transform SIFT Keypoint De tector 7  Comparing the SIFT points between consecutive images allow ed  for the computation of the Homography transform which map ped  the pixels from one image into the next   By i nitializing the locations of the targets in the first frame with a location recorded earlier the  Homography transform is  applie d to propagate the x and y pixel locations forward through the entire  series When  h owever there was  poor matching between pictures the propagation fail ed  When  the above f ail ed  the algorithm automatically shift ed  the target grid of one image horizontally and vertically over the other.  For every shift, the normalized sum of the pixel  values  under the targets is computed and the optimal shift was  found  Since the targets a re white this is the shift at which the sum of pixels is the maximum  In order for automatic shifting to succeed the targets must clearly contrast the background and the target grid s in both frames must be relatively in the same configuration  When  either condition was not met, the automatic shift algorithm fail ed  In this case a target was  hand selected and the shift from one image to the next was manually determined.  All targets were shifted by this amount and the x and y pixel location propagation continue d  Starting with the manual shift the local maximum was found to find the best local target location  When the propagation of the target locations completed the results were visually inspected for correctness by plotting the predicted attitude target locations back onto the image frames Figure 13 illustrates the entire target tracking algorithm  Solving for the Camera Attitude 321 Once a series of rectified images are produced and the pixel locations of the targets a re known, the attitude of the camera can be found.  For a CAHVOR calibrated camera, every x and y pixel location corresponds to a known three dimensional ray expressed in the camera frame.  Given the set of three dimensional points P i  expressed in the GPS  frame and a corresponding set of two dimensional points v i  expressed in image coordinates the x,y pixel locations  it is possible to derive a unit length ray v i in the camera frame using the camera calibration data Let r  be the camera location as measu red by the  GPS  and w i    w 1  311 w n  be a set of unit length rays from the camera to each P i i.e    1  where || . || is the vector norm  T hen solving for the full camera pose amounts to computing the rotation between w i and set v i  v 1, \311 v n To do so, we define V as the n  3 matrix consisting of  v i   W as the n  3 matrix consisting of w i  and R as the rotation matrix that rotates V T such that  W T RV T   2  In practice 2 does not have an exact solution and is computed either by  R=AB T  where A  B T W T V  is the singular value decomposition of W T V  or by  R=Pinv\(W where Pinv is the Moore Penrose pseudoinverse Note that if W T W  is non singular  then  Pinv\(W T W  W T W 1 W T  and, therefore  R = \(W T W 1 W T V    Figure 13: Block diagram of target tracking algorithm   Auto Adjustment Automatic Shift  


8 Next, we find the best attitude estimate using the RANdom SAmple Consensus RANSAC method  3 From the set P i   P 1  311 P n  th r ee points are selected and used to form an attitude estimate.  Using the resulting R matrix, the attitude targets are pro jected into the image and the projection error is calculated  Using a predetermined threshold erroneous members of  P i  are identi fied and rejected  Then the best attitude estimate is that formed from the remaining points  The resulting matrix R is the image based attitude estimate   IMU Based Attitude Propagation  For a given flight the resulting imagery based attitude estimates exist only when the wide angle camera capture d a sufficient number of attitude targets which occurred at a maximum rate of once a second Given the high rotational velocities of the gimbal this was  insufficient for  reconstructing the LIDAR trajectory  To this end we determine the attitude ever y 2.5 milliseconds using the LN 200 gyroscope s  To use the gyroscope s we first define an inertial frame.  Then, using the camera attitude estimates  to initialize the attitude  we propagated the attitude over the t ime that the  LIDAR was sampling data   The following sections provide the details of each step  T he inertial frame 321 We utilize an  Earth Centered Inertial ECI\frame We define the inertial frame to be the location of the WGS84 frame at the initial time  in a flight that the wide angle camera captures enough  attitude targets to produce an attitude estimate  Determining the initial attitude  from a series of attitude estimates 321 In this section, we find the initial attitude of the IMU relative to our ECI frame   The attitude of the IMU relative to the inertial frame is denoted M R I   This was  determined for every imagery based attitude estimate The product of the image based estimates was the attitude of the camera with respect to the GPS  frame.  Call it  E R C  From the i th estimate  E R C i   the IMU attitude relative to the initial frame was determined by the successive rotations  M R I i  M R C  E R C i  1  E R I t    3 Here  M R C  is the kn own rotation between IMU frame and the camera frame  and E R I accounts for the rotation between the GPS frame and the ECI frame  For propagating attitudes quaternions are numerically better suited. Therefore, each  M R I i  is converted to the equivalent quaternion  M q I i   Now that we expressed the attitude of the IMU re lative to an inertial frame in quaternion form we  propagated  it using the delta angles measured by the gyroscopes and using the 4     M q k 1 I  1 4  1 2 T  1  1 4 T    2 2  1 8 T    3 3                     M q k I  4 Here   and 1 4 is the 4  4 identity matrix The angles  x   y and  z are the angles provided by the x  y and z gyroscope measurements, respectively.  This equation is the result of truncating the infinite series expansion of the quaternion kinematic equation 8   Recall that image based attitude estimates are only available when the camera images at least six attitude targets.  Also the estimates come from sequen ces of consecutive  images For each sequence we attempt to find a good initial attitude to begin our  propagation of the attitude over the entire flight To start, we s elected  the initial estimate  from a sequence  and propagate d  the attitude  forward until the end of it  Note that each sequence  was  a small  portion of the entire flight Figure 14 shows an example of  M q I  generated from a section of data collected over the  Borrow Pit target site.  As seen here, the image based attitude estimates agree with the gyroscope propagation    Figure 14 Plot of attitude estimate based on camera vers us attitude propagated with IMU  Having both a propag ated quaternion and camera based  estimates during the same time span we found the mean error between them  For clarity we now denote the propagated quaternion as M p I and retain the M q I notation for attitude estimates  The  error quaternion mapping the Camera Estimate  321 IMU Propagation  q 1  q 4  q 3  q 2  Note   Jumps at  t 40 and  t 120 are the result of quaternion properization   Seconds since targets appeared in camera field of view   0  50  100  150  200  150  0.8  0 6  0 4  0 2  0.0  0.2  0.4  0.6  0.8  1  0 0 0 0.0 0.2 0.4 0.6 0.8 Quaternion Elements \(Unitless   


9 difference between the propagated attitude and the estimated attitude is given by  q e  M p I  1    M q I   5  Here   M p I  1  is the inverse  quaternion of  M p I  and   is the quaternion product  From the error quaternion the equivalent Euler angle of rotation   and unit Euler axis of rotation a  can be determined. Using   and a we define the scalar error quantity e s    and the vector error e v e s a   At this point   we have an error vector e v  and scalar e s  for every attitude estimate Taking u e to be the mean of all e v and u s to be the mean off all e s  we create the correction quaternion q c  u e T  sin u s 2  cos u s 2 T   Applying the correction quaternion to first camera based estimate  M q I 1 provide d the initial quaternion used to propagate the attitude for the entire flight, such that M q I 0  M q I 1  q c   To illustrate the effects of this procedure, we include  Figure 16  which because of its size has been placed  in the Appendix Here, f rames \(A\ and \(B\ are the value s of e s and e v  respectively created when the attitude was propagated starting at  M q I 1 a nd C and D was propagated starting at M q I 0  By improving the starting point the maximum scalar error e s has dropped from 0.26 degrees to 0.18 degrees and the standard deviation has dropped from 0.06 degrees to 0.03 degrees.  The vector error has the same shape, but now has zero mean  Determining the attitude of the IMU with respect to ECI 321 During a flight several passes at the target site are made At each pass, the wide angle camera takes a series of images used to estimate the attitude  S ee Figure 15   This figure shows the IMU LIDAR and camera timestamps for the second Borrow Pit flight  Here nine sequences  of attitude estimates are clearly visible  However it can be seen that LIDAR data is available between each sequence To provide attitude estimates between each series we propagate the estimates using the IMU.  As the propagation continues the estimate accuracy degrades due to error sources such as the gyroscope bias and numerical inaccuraci es Here we attempt to compensate for these errors   Minutes since start of data acquisition  Figure 15 Sample t imes of IMU, LIDAR and camera  Initially, it was proposed to combine GPS, camera data and the IMU with an EKF  However  development of the filter stalled and remains the subject of future work.  For FT1  we utilize d the following ad hoc method We beg an by finding the initial quaternio n for each sequence of image based attitude estimates  as determined by the previous section In addition to q 0 the standard deviation of e s for each  sequence  was calculated.  Starting from the initial quaternion of each sequence we propagate the attitude across the entire flight While propagating the accuracy of the attitude was  also tracked via   k t  0  b\(t k t q0   6 where  0   is the standard deviation of e s  for a given sequence    indicates the absolute value b is an arbitrary scale factor  t k is the timestamp of the k th measurement and t q0  is the timestamp  of  q 0  Take  M  to be the number of imaged based attitude estimate.  For the flight illustrated in Figure 15  M 9.  Since we propagated the attitude starting at each sequence 325s  q 0  there were  M  different propagated attitudes at every time step  Each of these were  combined using a weigh t ed average     7  where   j  and  a j  are the Euler angle and axis that defin e a propagated quaternion p j w j   j 1 is the weight of p j and W is the sum of all weights  Notice, that by using  and a  u is the average of the attitudes axis angle form    Finally for every time step u  was  converted to the quaternion M q I u     v T  sin   _ cos   T where v  u  u and   u 2 Also note that this scheme favors samples where there is good camera and IMU agreement  Constructing the LIDAR trajectory  The objective of the trajectory reconstruction  effort was  to determine the position and attitude of the LIDAR with respect to a target  site  Finding the attitude requires the following successive rotations  T q L  T q E    E q I t   M q I  1    M q L   8  Above T q E  and M q L  are the known relative attitudes The first i s the attitude of the target frame relative to the GPS  frame and the latter is the attitude of the LIDAR with respect to the IMU frame.  The other term introduced in \(8 E q I t is the attitude of the GPS frame with r espect to the ECI frame at time t  To  find the position of the LIDAR in the target frame we first linearly interpolate d  the 1 Hz GPS position measurement  r L/E  to the 8 Hz necessary for the LIDAR Then   we remove d  the offset between the GPS  and target frame r E/T  and rotate d the interpolated measurements from the GPS  frame into the target frame  using the rotation matrix T R E which is the rotation matrix equivalent to \(8  r T  T R E r L/E 320 r E/T   9  The attitude provided by \(8\ and the GPS measured position via 9 gave  the full pose of the LIDAR for each flight  0  80  70  60  50  40  30  20  10  


 10  6  I NSTRUMENT V ERIFICATION  To verify the accuracy of the reconstructed trajectory we  us ed the LIDAR by shift ing the LIDAR data until the minimum correlation error between the sensor data and truth DEM was found T he LIDAR camera boresite vector corresponds to the LIDAR z axis and t he sensor array rows and columns define the x and y axes  Therefore, any position shift in the z direction can be interpreted as a range error.  Shifts in the x and y axes co rrespond to yaw   and pitch  errors as follows   tan 1  y d  z  1    10   tan 1   x d  z  1    11  where  x   y and  z  represent the x, y and z shifts, and d is the distance to the target. Notice that yaw is the rotation abou t the LIDAR y axis  and pitch is the rotation about the LIDAR x axis R oll and pitch errors have been calculated using this method for Lakebed and Borrow Pit flights and plotted in Figure 17 A and Figure 18 A respectively  Additionally, we compare d the attitude determined by \(7\ to the image based estimates and plotted the results in  Figure 17 B and Figure 18  B   The maximum observed errors  observed by the LIDAR during the Borrow Pit flight were 0.25 and 0.16 degrees for pitch and yaw respectively These are comparable to the camera generated values of 0.12 and 0.15 degrees \(seed Figure 17 B\\.  For the Lakebed flight, seen in Figure 18  A the maximum LIDAR determined error was 0.37 and 0.58 degrees for pitch and yaw respectively  However the pitch and yaw errors seen in Figure 18  B for the cameras were significantly worse 0.33 and 2.50 degrees, respectively  In Figure 17 B and Figure 18  B  a non random process noise is apparent and is the likely cause of the larger than expected errors.  Currently, the source of this error has not been identified  however f or the ad hoc method described here  gyroscope scale factor errors, sense axis misalignments and bias have not been accounted for Additional error sources for the camera and IMU include the numerical inaccuracies introduced by 4 and timing errors For the LIDAR the largest source of e rror is the timing uncertainty. Efforts have been made to identify the timing of the LIDAR sampling.  Unfortunately, it changes from flight to flight and is not easily identifiable  Despite the larger than expected error the trajectory reconstruction me thod was s ufficient enough to place the LIDAR hazards within one meter horizontally of the truth hazards  The combination of the mainly horizontal trajectory errors and the time varying range bias inherent to the LIDAR caused the LIDAR data to be misaligne d relative to the truth DEM. To eliminate this misalignment, the flash LIDAR data and truth DEM were correlated using a procedure based on the HRN algorithm 6 was used. The end result was precise alignment to 1 DEM pixel \(0.1m or less  Even though the results from the method presented here were sufficient to achieve the ALHAT objectives i t may be desirable in the future to try to  achieve the expected attitude performance of 0.71 degrees   In that case  methods to identify the error sources will be developed  One such option is the use of an unconstrained nonlinear optimization  such as the MATLAB\250 function fminsearch   By formulating the effects that gyroscope misalignments, biases and timing offsets has on the propagated trajectory the parameter  values that minimize error between the camera estimates and the propagated trajectories can be found Although this approach is simple, the time for the nonlinear optimizer to find the parameters will be gre at  and it will not compensate for the numerical inaccuracies  A more complex alternative is to complete the EKF and extend it to an optimal smoother.  The filter will directly solve for gyroscope biases and drift due to the averaging between sensors and  reduce the impact of the numerical By running the filter multiple times and observing the effects that shifting timing offsets has on the filter residuals the best timing offset of the camera and IMU can be identified  Similarly by shifting the timing of the LIDAR samples and observing the effects on  x   y and  z the best LIDAR offset for each flight can be found  7  C ONCLUSIONS  The expected performance of the reference system was .12 cm for position and 0 071 degrees for attitude.  Although the ma ximum observed attitude error of 0.33 degrees was five times worse than expected the error for the Borrow Pit flight never exceeded the FT1 requirement However this was not the case for the Lakebed flight Examination of the error  seen in  Figure 17 B and Figure 18   B clearly demonstrates a yet unidentified, non random process noise By compensating for gyroscope misalignments, scale factor errors, gyro biases and timing, this error should dramatically reduce Despite the larger than expected errors, this method was sufficient to achieve the FT1 ALHAT objectives.  In case a better level of accuracy is required in the future, the  sources of error will be analyzed and the methods to compensate for them will be developed  Two approaches are the use of an unconstrained nonlinear optimizer or the development of an Extended Kalman Filter.  The results of these efforts are expected to achieve the expected 0.071 degree performance for FT1  A CKNOWLEDGMENT S  We thank Asif Ahmed of the Jet Propulsion Laboratory for his guidance  patience and tutelage during the trajectory reconstruction effort  The work described in this publication was performed at the Jet Propulsion Laboratory California Institute of 


 11  Technology under contract from the National Aeronautics and Space Administration The work was funded by the NASA Exploration Technology Development Program and would not have been possible without the flash LIDAR  sensor provide by NASA Langley and the field test system provided by JPL  R EFERENCES  1  Bulyshev Alexander Pierrotte t Diego Amzajerdian Farzin; Busch, George; Vanek, Michael; Reisse, Robert 322Processing of three dimensional flash lidar terrain images generating from an airborne platform\323 roc SPIE, Vol. 7329 April 2009  2  Epp  Chirold and Tom Smith, \322Autonomous Precisio n Landing and Hazard Detection and Avoidance Technology ALHAT\,\323 Proc IEEE Aerospace Conf Big Sky, MT, March 2007  3  Fischler Martin A and Robert C Bolles Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography  Comm Of the ACM 24 June 1981 381 320 395  4  Gennery D.B 322Least Squares Camera Calibration Including Lens Distortion  and Automatic Editing of Calibration Points,\323 Workshop Calibration  and Orientation of Cameras in Computer Vision XVI I Congress  of the International Society of Photogrammetry and Remote Sensing Washington DC, August  2, 1992  5  Johnson Andrew E Jason A Keim and Tonislav Ivanov  322Analysis of Flash Lidar Field Test Data  for Safe Lunar Landing\323 IEEE Aerospace Conferenc e  March 6 13, 2010, Big Sky, Montana  expected  6  Johnson  Andrew E  and Miguel SanMartin Motion Estimation from Laser Ranging for Autonomous Comet Landing Proc Int'l Conf Robotics and Automation pp. 132 138, April 2000  7  Lowe, David G. "Distinctive image features from scale invariant keypoints International Journal of Computer Vision vol. 60.2 \(2004\: 91 110  8  Wertz, James R Spacecraft Attitude Determination and Control  Boston Kluwer Academic Publishers 1978  558 566  9  Melvin \(Jay\ White II, Tom Criss, and Dewey Adams  322 APLNav Terrain Relative Navigation Helicopter Field Testing 323 AIAA Guidance Navigation and Control Conference  August 2009, Chicago, Illinois   B IOGRAPHY  Jason Keim received his B S.B.M.E from the University of Southern California and  M.S.M.E from California State University, Los Angeles. Since 2002, Jason has been a member of the Guidance and Control Analysis Group at the NASA Jet Propulsion Laboratory. His primary focus has been the development and validation of formation flight algorithms and technologies for missions such as NASA Starlight TPF and DARPA F6  Additionally, he has contributed to the autonomous surface operations of the Mars Science Laboratory data processing and t rajectory reconstruction for the Autonomous Landing and Hazard Avoidance Technology program and other research and technology development programs  Dr Sohrab Mobasser is a Senior Member of the Engineering Staff at the National Aeronautics and Space Admi nistration\325s NASA Jet Propulsion Laboratory JPL Sohrab has more than 26 years of aerospace industry experience most of it in spacecraft attitude determination His work can be found on many planetary missions from the Galileo mission to Jupiter to t he successful Pathfinder mission to Mars and the Cassini mission to Saturn His current interests are new technology and applications for autonomous spacecraft attitude determination  Sohrab is the Field Test Lead for ALHAT project    Dr Yang Cheng  Dr Y ang Cheng is senior staff member at JPL and he has been involved in many NASA and reimbursable robotic projects for many years He is the key algorithm developer for the Descent Image Motion Estimation System \(DIMES which played a critical role for Mars Exploration Rovers landing safely on Mars. He was also the key software developer for the MER onboard visual odometry which has been used during critical rover maneuvers and traverses.  In addition, he was also involved in novel vision algorithm developme nt for future Mars and Lunar safe and pinpoint landing   Tonislav Ivanov is an Associate Member of Technical Staff in the Computer Vision Group at JPL He works on lidar data processing  field test setup, and is helping develop the hazard detection algori thm for the Autonomous  Landing and Hazard Avoidance Project He also works on recognition using stereo data for robot human awareness and lunar terrain characterization for future missions to the Moon    320  


12 Dr Da Kuang  received his Ph.D in Aerospace Engineering from The University of Texas at Austin in 1995. He joined the Orbiter and Radio Metric Systems Group at JPL in 1996 His work has been focused on analyzing GPS and GPS like tracking data for precise orbit determ ination and precise relative positioning  Dr Andrew Johnson  is a Principal Member of Technical Staff in the Optical Navigation Group at JPL  He is the JPL Project Manager and  terrain sensing algorithm lead for the Autonomous Landing and Hazard Avoida nce Project which is developing technology for safe and precise landing for the next generation manned lunar lander At JPL he works on development validation and flight implementation of computer vision systems for planetary landers and Mars rovers  Ha nnah R Goldberg  received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively. She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano class spacecraft and microsystems   Garen Khanoyan  is a member of the Advanced Co mputer Systems  Technologies group at JPL He has been involved with field testing activities and the development of the Command  Data Storage Unit since 2008 for ALHAT and MSL projects. Garen received his B S.E.E and M S.C.S from the University of Southern California   David B. Natzic received his B.S.C.S. from the Department of  Computer Science at the Universi ty of Management and Technology He has been employed as a n Associate Member of Technical Staff in the Guidance Navigation and Control Group at JPL Dave Joined JPL in 1992 and currently serves as a n  essential ALHAT team member focusing on the design integration and field testing of Flash LIDAR instruments onboard aerial platforms 


13 A PPENDIX    Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view    A         B      Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view   C         D Figure 16  The error between the propagated and estimated attitude  A is the scalar error and B is the vector error before the corrections.  \(C\ is the scalar error and \(D\ is the vector error after the correction   200  180  160  140  120  100  80  60  40  20  0  200  180  160  140  120  100  80  60  40  20  200  180  160  140  120  100  80  60  40  20   200  180  160  140  120  100  80  60  40  20  0.35  0.30  0.25  0.10  0.05  0  0  Degrees  0.20 0.15  0.35  0.30  0.25  0.10  0.05  0  Degrees  0.20  0.15  0  0.15  0.10  0  0.15  0.20  0.25  Degrees  0.05  0.10  0.05  0.15  0.10  0  0.15  0.20  Degrees  0.05  0.10  0.05  0  


14   A        B  Figure 17: Yaw and pitch errors from second Borrow Pit flight for \(A\ the LIDAR and \(B\ the camera      A        B  Figure 18: Yaw and pitch errors from the third Lakebed flight for \(A\ the LIDAR and \(B\ the camera  Degrees  Seconds into flight  Seconds into flight  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  500  2000  2500  1000  1500  3000  3500  Seconds into flight  500  2000  2500  1000  1500  3000  3500  Seconds into flight  1000  1500  500  2000  2500  0  0.20  1000  1500  500  2000  2500  0  0.20  


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






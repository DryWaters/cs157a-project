Computer security is undeniably important in IT era nowdays Most computer users today are fighting for either by battling viruses spam phishing or other malware or by fending 
Trusted Computing Opportunities  Risks 
Nor Fatimah Bt Awang Department of Computer Science Faculty of Defense Science and Technology National Defense University of Malaysia Kuala Lumpur Malaysia norfatimah@upnm edu.my 
Abstract 
off schemes to compromise privacy and extract confidential information With these worries in mind the Trusted Computing Group TCG was established to develop specifications for trusted computing building blocks and software interfaces that could address the problems and aims to enhance security by using the transitive properties of trust However the implementation of this technology seems to have consequences for many people At present there is no standard mechanism for establishing trust in the Trusted Computing TC on a particular machine The TC specification is not rigidly defined when it 
comes to implementation leaving many open issues for research and development efforts There are major issues especially related to privacy One big worry is the potential loss of anonymity and the threat of unwanted surveillance and even control TC also affects areas other than purely technical ones The capabilities of TC technology have legal as well as economic consequences The main legal concerns are copyright anti-trust law data privacy law and digital rights management the impact on which are not yet clear This paper will discuss the TC in concept and study on the 
opportunities and risks of the system in existing computing system environment particularly related to security matters hardware support needed for all the major feature groups in Next-Generation Secure Computing Base NGSCB Therefore a single body or organisation is crucially needed to streamline end-to-end trusted platform requirements and to further drive in developing standard guidelines and specifications As a result in 8 th April 2003 a not-for-profit industry-standards organization namely as Trusted Computing Group TCG was formed to develop defme and promote open vendor-neutral industry specifications for trusted computing[I 
TCG has extended it scope beyond PCs to other devices and system such as storage mobile devices servers 
I 
infrastructures and peripherals A bigger workgroup has been created to defme implementation architectures for respective element The Storage Work Group for example plans to build on existing TCG technologies and address standards for security services on dedicated storage systems such as disk drives removable media drives flash storage and multiple storage device systems To date TCG specifications have been developed for desktop and portable computers mobile devices storage devices and the network itself Of course these specifications only provide an improved level of trust if they are implemented Figure 
I 
Trusted Computing Group Standard N ote books Des 
kt ops Sec urity ha rd ware Input devic es C re de ntials O pera ti ng Ap plicati on s  
I 1 
syst ems M obi le r.J t2J 
p ho nes 8 
INTRODUCTION There are many promising approaches to improve security in computing environment in all possible angles and aspects ego redesigning operating systems changing programming methodologies or altering the PC's hardware itself This broad term as well as scope drives a mix of initiatives by individual 
PM s 225 
 
  
TRUSTED 273\253 
S to rage 
CoMPlITlNG GROUP  
I 
Savers 
processor manufacturers software makers service providers networking and original equipment manufacturers\(OEM to respond to the well-known security challenges Microsoft has started with a software-based project referred as the Microsoft Next-Generation Secure Computing Base or NGSCB which specifies software changes that take advantage of the security benefits made available by a planned new PC hardware  On the other hand Intel and AMD are in midst of developing a processor-based solution namely as Intel's LaGrande Technology LT and AMD's Secure Execution Mode SEM respectively in order to provide 
Keywords-component Trusted Computing security network 
Digital Object Identifier 10.4108I/CST.COLLABORATECOM2009.8402 http://dx doi.org/10.41081ICST.COLLABORATECOM2009.8402 
 


Data and Network Protector from Virus and Malware 
B Secure Online Transaction 
Digital Object Identifier 10.41 OB/ICST COLLABORA TECOM2009 B402 http://dx.doi.org/10.410B/ICST COLLABORA TECOM2009 B402 
II OPPORTUNITY OF TRUSTED COMPUTING The Trusted Computing TC offers several opportunities over proprietary hardware security solutions and inherently hardware security is stronger than software-only approaches Existing research shows that the TC can be used to establish trust in the software executing on a computer 
Trusted Computing would allow companies to create a digital rights management system which would be very hard to circumvent though not impossible An example is downloading a music file Remote attestation could be used so that the music file would refuse to play except on a specific music player that enforces the record company's rules Sealed storage would prevent the user from opening the file with another player or another computer The music would be played in curtained memory which would prevent the user from making an unrestricted copy of the file while it is playing and secure I/O would prevent capturing what is being sent to the sound system Circumventing such a system would require either manipulation of the computer's hardware capturing the analogue and possibly degraded signal using a recording device or a microphone or breaking the encryption algorithm  III TRUSTED COMPUTING CONCEPTS The demand that gave birth to the trusted computing system normally originated from military or security related agencies They are the users or groups that are very cautious about every single aspect of security threats to their operations and organizations Therefore most of trusted computing system has been developed according to military security models and requirements A secure military personal computers built from common off-the-shelf components has been a long dream of the military and security agencies world-wide as it's would save large amounts of money Common requirements of such a system are as  225 Any data on the system must be wiped out both before and after it is used 225 The system must be able to securely identify itself 225 The user must be able to securely identify himself 225 Information passed to the system must not be visible during the transfer 
This threat arises from the fact that mobile devices or notebook computers are more susceptible to be stolen than their desktop counterparts Once stolen notebooks can be subject to a variety of hardware as well as software attacks It is often found that the stolen data is more valuable than just the cost of the notebook TCG has introduced a Trusted Computing Platform TCP that serve a feature of trusted drive that encrypts all data directly on the drive and the encryption speed matches the throughput of the drive interface so the process is essentially unobservable to the user in normal operation If a trusted drive is stolen repurposed or taken out of service it remains protected Simple user and security ID keys make end of life and repurposing instantaneous and secure In the enterprise a trusted storage system allows authorized access to critical data while preventing unauthorized access or modification of that data In addition to an unobservable cryptographic processing of secrets and use of custom logic to provide fast secure operation for the cryptographic functions protecting data on a hard drive requires tight access control for secret information Once again the TCP provides the key with its hardware-based key generating capability 
Notebooks often operate outside of corporate frrewalls Also they use various means of communication to access the corporate network or the Internet There are a number of ways in which a determined hacker can attack the communication channel used by the notebook to steal the data being transceived To protect customer and employee data from Internet\255 based attacks Personal information Manager PIM software secured by the hardware based chip in TCP isolates contact information passwords bank access codes and credit card numbers With multi-factor authentication some employees reach their programs with a single factor while others require at least dual-factor authentication for network access providing the appropriate level of security for each department Instead of using third-party vendors to encrypt content before backing it up these transactions are now performed locally in house With encryption keys residing locally in the TCP copies are automatically passed to the Key Transfer Manager Server providing both protected and recoverable information 
In today's security environment a worm virus or other malware on a PC that connects to the network can easily spread across it Relying on anti-virus and personal frrewall software for portable computers is not acceptable for a secure corporate network An authorized user can gain access to the network from an external site to simply check email If the user's computer has a virus or rootkit a software tool that conceals running processes these unwanted software items can spread to the network By taking advantage of the TCP deceptive or lying endpoints can be detected Using the hardware-based security of the TCP for integrity measurement and remote attestation the limitations of software-based protection can be overcome With the TCP the specification establishes a level of trust in the state of an endpoint and also ensures the presence status and software version of mandated applications 
C 
D Digital Rights Management 
A Storage Protection 
 


A Attestation 
No Standard Testing Procedure 
B Hardware Failure D No Interoperability 
225 Confidential information on the system must not be available to other processes running on the system All of these objectives could be accomplished as follows A system is designed that has no hard disk but lots of RAM This is becoming more doable now that 64-bit architecture chips are shipping but even 2 gigabytes of RAM is sufficient for most purposes especially the fact that RAM is easier to erase than a hard disk The machine boots to the network over an Internet Protocol Security IPsec card and a server at the other end loads a secure operating system into the RAM These requirements have motivate most of sectors related to trusted computing system to innovate or create an integrated platform that cover the criteria It may now be possible to build such a system using a Trusted Platform Module TPM module at its core The basis of Trusted Computing as defined by TCG is a collection of one or more security devices that can be embedded within a Trusted Computing Platform The first device defmed by TCG is the TPM which is encapsulated within a Trusted Computing Platform by affixing a single chip to the motherboard or embedding the functionality within another silicon component The TPM is typically a microcontroller that stores passwords digital keys and certificates to provide unique identification Either a standalone integrated circuit IC or embedded in another IC such as an Ethernet controller the TPM uses standard software interfaces to work with other security methods to deploy secure applications The other critical supporting component in completing trusted computing model is TCG Software Stack TSS TSS is a module that similar to Microsoft Next-Generation Secure Computing Base module or NGSCB The TSS is comprised of modules and components that provide the supporting functionality to the TPM Based on the TCG specification certain functions and services are outside of the scope of the TPM hardware These functions and services are delivered using the host CPU and system memory The TSS provides the necessary software architecture to support the offloading of security functions from the TPM to the main CPU and memory resources of the system TSS communications with the TPM can occur either locally or remotely The TSS provides a standard set of application programming interfaces APIs so that application vendors can use the TPM IV RISKS OF TRUSTED COMPUTING It is clear that trusted computing hardware provides security benefits when nicely blended with right software that is prepared to take advantage of it But trusted computing has been received skeptically and remains controversial Some of the controversy is based on misconceptions but much of it is relevance Trusted computing TC has many implications including some benefits for large corporations Here discuss more about risks involved in TC 
By using Remote Platform Attestation an unauthorized changes to software can be detected via a network For the legitimate user it is a best feature to detect tampering This attestation technique involve third party to check the software running on the system in order to create certificate to system This third party can get sensitive information about the user's device and able to influence privacy by linking requests of the customer because of the usage of unique keys like the Endorsement Key For computer device attestation technique is performed using hash value Hash value is created and checked against a database to verify the values as correct Hash value could be invalid if an unknown program is running on the computing device and thus a service provider can deny services Remote attestation could cause other problems Currently web sites can be visited using a number of web browsers though certain websites may be formatted such that some browsers cannot decipher their code Some browsers have found a way to get around that problem by emulating other browsers With remote attestation a website could check the internet browser being used and refuse to display on any browser other than the specified one like Internet Explorer so even emulating the browser would not work Any hardware component including the TC hardware itself has the potential to fail or to be upgraded and replaced A user might rightly conclude that the mere possibility of being irrevocably cut-off from access to his or her own information or to years worth of expensive work-products with no opportunity for recovery of that information is  The concept of basing ownership or usage restrictions upon the verifiable identity of a particular piece of computing hardware may be perceived by the user as problematic if the equipment in question malfunctions TPM has a unique key and this key identifies a single TPM and also the main key for all further operations TPM is embedded on the motherboard and all important keys are stored and used inside the TPM That means for instance a software lisence for a certain computing device could be bound to hardware integrated keys C The TCG only released a specification but no conformance tests are forced onto the vendors Up to now there is no feasible test methods to judge whether they are compliant to TCG specifications or not Therefore it may be difficult for an end user to tell whether his trusted platform is compliant to the whole specification or only to a subset of it as there isn't any a prototype with full funtion can test TPM Non-corformance and bugs of TPM can lead to serious security problems Trusted Computing requests that all software and hardware vendors will follow the technical specifications released by the Trusted Computing Group in order to allow interoperability 
Digital Object Identifier 10.41 OB/ICST COLLABORA TECOM2009 B402 http://dx.doi.org/10.410BI/CST.COLLABORA TECOM2009.B402 
 


Malfunction of Software or Application 
Fairness 
Users should retain control over their personal information and decide the conditions they want it Service providers should treat users with fairness and integrity This is essential for protecting privacy and promoting flexibility Users are permitted to completely disable or modify all endorsement keys in order to give complete privacy and freedom This basically will offer flexibility to users to reuse or reinstall software to new computers or terminals This feature is critical for software that bind with TPM in order to operate and open source-source softwares that often changed on source code 
F Open Source Software 
Digital Object Identifier 10.41 OB/ICST COLLABORA TECOM2009 B402 http://dx.doi.org/10.410BI/CST.COLLABORA TECOM2009.B402 
D Open platform development model 
E Cryptographic Issues 
Encourage the open development model that enables any party to develop hardware software or system platformsbased on TCG specifications and to preserving consumer freedom of  TPM togther with software developers should make peer-to-peer communication within community easier Where group of computer that is safe from outsider 
Many software systems need to provide services continuously and uninterruptedly Meanwhile these software systems need to keep evolving continuously to fix bugs add functions improve algorithms adapt to new running environments and platforms or prevent potential problems 
B Choice and Control 
v 
RECOMMENDATIONS The TCG technical committee considered few intiatives to improve the weaknesses and risks from the existing TC privacy policies The TCG privacy model generally follows the privacy guiding principles established by the World Wide Web Consortium W3C P3P working group6 
between different trusted software stacks However even now there are interoperability problems between the TrouSerS trusted software stack released as open source software by IBM and Hewlett-Packard's   Another problem is the fact that the technical specifications are still changing so it is unclear which is the standard implementation of the trusted stack 
The technical idea underlying trusted computing is that the computer includes a digital encryption and signature device and the keys are kept secret by manufacturers Proprietary programs will use the TPM to control which other programs can be run which documents or data can be accessed and what programs can be pass them to These programs will continually download new authorization rules through the Internet and impose those rules automatically refuses to obtain the new rules periodically from the Internet might causes some capabilities will automatically cease to function This situation makes online evolution an important issue in the field of software maintenance and evolution On the other hand one of TPM most important role is to protect data from virus or worm attacks by comparing in and out value as a mechanism to identify threats from outside for instance the trusted boot functions provide the ability to store in Platform Configuration Registers PCR hashes of configuration information throughout the boot sequence Once booted data such as symmetric keys for encrypted files can be sealed under a PCR The sealed data can only be unsealed if the PCR has the same value as at the time of sealing Thus if an attempt is made to boot an alternative system or a virus has back-door the operating system the PCR value will not match and the unseal will fail thus protecting the data To overcome the situation software providers and TPM should provide timely and effective notices of their information practices software providers and TPM should provide effective tools for users to access these notices and make decisions based on them eg alarm of pop up message to remind users on mismatch value prior to delete any data automatically 
 
Currently the specification from TCG does not allowed the owner of the system or the owner of the computer to load an alternate trusted storage root It also prevent anyone from running an operating system or running other software of their choice Users should be given the ability to make meaningful choices about the collection operating system and applications and disclosure of personal Users should be allowed to completely disabled the TPM or it is easily unplugged as praticed by IBM on LPC bus daugtherboard Computers or terminals must be workable with or without presence of TPM TPM should act as an added features and independent in which not inter-dependent with other components or softwares This feature can avoid sofware developers from abusing the TPM and limit users choice C 
A Notice and Communication 
TCG uses standard algorithms like RSA and SHA-l But like SHA-1 will not fulfil near future security requirements and should be substituted by better Implement cryptographic chips in TPM platform has introduces a lot of security-related improvement and also a lot of memory usage then it will slow the process 
Trusted computing puts the existence of free operating systems and free applications at risk as TPM will block this kind of software Some versions of trusted computing would require the operating system to be specifically authorized by a particular company Free operating systems could not be installed Some versions of trusted computing would require every program to be specifically authorized by the operating system developer To run free applications on such a system could be a On the other words the downloaded videos and music can be played only on one specified computer Digital Right Management technology in Trusted Computing will prevents users from freely sharing and using potentially copyrighted or private files without explicit permission G 
Integrity 
 


 
Proceedings of the 2006 A CM sy mpos ium on Applied computing  
fair play with the  Frits chip  Huanguo Zhang  Jie Luo  Fei Yan  Mingd i Xu  Fan He  Jing Zhan   A Practical Solution to Trusted Computing Platform Testing  17 Thomas Hardjono   Strengthening Enterprise Application Using Trusted platform Modules   A Practical Guide to Trusted Computing http my  safaribooksonline com/9780 132398428/ch 131evIsec14 REFERENCES  Trusted Computing Group  TCG Specification Architecture Overview  http www tru stedcomoutinggroup org/groupsrrCG I 4 Architecture Over view pdf  P3P Guiding Principles h ttp    w w w  w 3  o r g/T R  N O T E-P 3 PI Oprinciples  David Safford  2002  Clarifying Misinformation on TCPA IBM Research 
Dijon France  283-287  Free Free Software Free Society selected essays of Richard M Stallman  http  shop.fsf.org/product/free-software-free-societv  Ruediger Weis  Stefan Lucks  Andreas Bogk 2004 TC 
 Trusted Computing  http en.wikipedia org/wiki/Trusted Computing  Trusted Computing Group  TCG Software Stack TSS Specification  http://www trustedcomputinggroup org/specsrrSS  Trusted Computing Promise and Risk http www eff.orgwotrustedcomputing-promise-and-risk  Frank Molsberry  Brian Berger   E n h anc i n g IT Security with Trusted Comput ing Group Standards  http www.dell com/powersolutions TCPA of Control  Safford  David  T ak e http www.linuxjoumal.com/art icle/6633 5 Yianna Danidou  Legal Implications of Trusted Computing  http www bileta.ac uk/Document..1020Librarv I/Legal%20Impli cations%200 f''1020Trusted 20Computing pdf  Eimear Gallery   W h o are the TCG and what are the trusted computing concepts  http www.trust2008.eu/downloadslEdu Event Monday/2 Eimear Gallery Who is the TCG and what are TC concept s pdf monitoring are allowed to share-files and information without complex authentication process This features also will make data-backup activities on other hardware become easier VI CONCLUSIONS One of the frequent issues related to network security is the lack of strong device or machine identities for computer systems connected to the corporate network For instance the IP networking industry has purely relied on ethernet MAC address on the NIC hardware of PC client computers to identify the computer as an endpoint within the network the found in The available Software-only security solutions may not be sufficient to protect networks or information from threats Even firewalls protecting intranet environments can prove inadequate especially when software attacks bypass the firewall or originate from internal Therefore combination of Hardware 
Software based embedded security solutions crucially important element of secure environments With Trusted Computing TC the computer will consistently behave in specific ways and those behaviors will be enforced by hardware and software The primary TCG specifications rely on the Trusted Platform Module TPM hardware component which is in widespread deployment and the TCG Software Stack TSS which developers can use as a foundation for various applications Unfortunately Trusted Computing is a young technology and struggling with some drawbacks For example questions on the issue of privacy the internet and TC from a new perspective TC is primarily seen as a threat to privacy as a political concept giving multinational companies access to information we would prefer to keep private Unsurprisingly the TC has provoked and given rise to number of controversies between its proponents and opponents This is due to the fact that the aim of TCG will provide more trustworthiness from the point of view of software vendors and the content industry but will be less trustworthy and freedom from the point of view of their owners Fortunately the TCG as well as independent researchers is working seriously to address the limitations and weakness of the TC For instance Open Platform Development Model initiative will improve TC platform openness and flexibility in offering benefits to both vendors and users TC can be very useful for secure infrastructure commons if its limitations and critical points are carefully taken into account and ultimately will covert all the risks to opportunities in which will develop a better secured community  Siani Person  Tru sted Computing Platform the next security solution  http www hpl.hp.com/techreports 2002/HPL-2002-221.pdf  Sundeep Bajikar   T ru s t e d Platform Module TPM based Security on Notebook PCs White Paper 11 Protecting Your Vital Business Data with Trusted Platform Module http  www.intel.com/design/mobile platform/downioadrrrusted Platform M odule White Paper.pdf  David Challener  Kent Yoder A Practical Guide to Trusted Comput ing IBM Press 2008 77-92 13 Burmester M and Mulholland  J 2006 The advent of trusted computing  implications for digital forensic s  
Digital Object Identifier 10.41 OBI/CST COLLABORATECOM2009.B402 http://dx.doi.org/10.410B//CST COLLABORATECOM2009.B402 
1.2 
 


  6 where the notation is used to indicate the measurement in the bearing cell corresponding to The likelihood of the two-node measurement set   conditioned on the target present hypothesis \(the numerator of the likelihood ratio\mply the product of the two target present probabilities since target presence is more likely when the data follows the target present distribution in both sensors. In contrast, the target absent hypothesis is the composite hypothesis that either \(a\th measurements are drawn from the target absent density or \(b\measurement is drawn from the target present hypothesis and one from the target absent hypothesis. Therefore, in following with the GLRT, the denominator of the likelihood ratio is computed as the maximum over the three atomic hypotheses from both sensors from sensor 1 and from sensor 2, and from sensor 1 and from sensor 2 4  S INGLE T ARGET D ETECTION AND T RACKING I MPLEMENTATION  This section describes how the mathematics of Section 3 is implemented. The approach we take here utilizes a discrete grid representation of the posterior. In contrast, other work 5 a s em p l oyed a p a rticle ap prox im atio n to th e relevan t  posteriors. As discussed earlier there are tradeoffs involved in the two approaches Representation of target state probability We represent the target state probability on a 4D discrete grid \(corresponding to the four dimensional state vector     cells. The spatial extent of this grid dictates the overall region where targets may be detected. The cell resolution must be carefully chosen based on the sensors and geometry to allow sufficient accuracy. Figure 3 gi ves an example of marginal PDFs as represented on a discrete grid The tradeoffs involved in grid resolution include the following: \(i\rithm speed is roughly linear in the number of grid cells. The number of the grid cells is the product of cells in each of the spatial and each of the velocity dimensions. This fact rewards minimizing of the number of cells either by limiting the overall region upon which the PDF is approximated or making the discretization coarse. \(ii\Single-target tr acking performance degrades as the grid cells become coarser In particular, since the sensor to target state mapping is nonlinear, performance breaks down substantially above certain cell resolution sizes depending on the sensor geometry\Both of these phenomena will be illustrated later Temporal update of the tracking probability The temporal evolution of the probability density on can be expressed in continuous time using a partial differential equation. We wish to compute    from    The relation between these two densities can be expressed as                Using \(i\econd order Taylor series approximation to     ii\ming the 223nearly constant velocity\224 model for the transition density    and \(iii\g small we find the Fokker-Planck equation  This derivation is given in more detail in the Appendix  Figure 3\226 Grid-based represent ation of the target state density. Left: Th e 4D posterior margin alized to give the probability density. Right: The marginal 


  7 In the following discussion we use this transition model Other models can be incorporated similarly, including models which use roadway constraints and higher order motion terms In the experiments we discuss later, this model is valid \(i.e the diffusivity of the target is captured statistically by the diffusivity coefficient in the model\es where robust modeling of the target dynamics is not possible, one typically appeals to a multiple model approach [13 wh i c h adds robustness to the filtering by allowing it to select from a number of candidate motion models The state probability density is represented on a discrete grid and so this differential equation must be used to update that representation. This discrete update is computed from time to time  using a backward Euler method as              13 This approach has nice stability properties in both and For more details, see [1  This is illustrated graphically in Figure 4, where the left hand side represents the posterior from the k th time step and the right hand side represents the prediction for the k+1 th  time step. The white dot represents the true target position In this example, the target is moving in the positive x  direction, causing the probability mass to evolve preferentially along the positive x direction This computation method is linear in the number of grid cells used in the discretizatio n. Linear dependence on grid cell number is achieved using the backward Euler method above, yielding a tridiagonal system of equations which is efficiently solved using Thom as\222 algorithm Fi gu r e 5  illustrates this dependency from empirical tests  Figure 5\226 Computation is linear in number of grid cells Temporal update of the target present probability The target present and absent probabilities are updated according to the simple mixing model described in eq. \(8 corresponding physically to targets arriving and leaving at a constant rate. Since this is a discrete PMF with only two possible events \(target present and target absent implemented by simply storing a single floating point number corresponding to the target present probability Measurement update of the tracking probability As discussed above, evaluating the measurement likelihood for each cell performs the target state probability update   14 This simply requires computation of the likelihood ratio at each cell Specializing again to the two-node, bearings only situation, at each time step each sensor node makes measurements at all \(discretized bearings \(beams he sensor model describes statistically the likelihood of each measurem ent conditioned on target  Figure 4\226 The temporal update of th e target state probability density 


  8 present, as illustrated in Figure 6. Note that different node locations yield different beam widths and spatial information By assumption, the joint likelihood of the measurements conditioned on target present \(the numerator\he product of the two individual likelihoods \(i.e., the noise is independent from sensor to sensor  15 where from the end of Section 3 we know   16 Here is the bearing cell \(beam\ into which projects at sensor node 1. Therefore, for each grid cell in the discrete representation of we compute the hypothesis probability as proportional to    17 As mentioned above, the hypothesis \(the denominator of the likelihood ratio\rresponds to the composite hypothesis that either \(i\neither sensor has target energy in the target bearing, or \(ii\ one of the two sensors \(but not both\has energy in the target bearing. Therefore, the probability of the hypothesis is evaluated by appealing to the GLRT as          18 Finally, the measurement update for cell is computed as           19 Measurement update of the target present probability As discussed in Section 3, the measurement update of the target present probability is performed as    20 By comparison, it is seen that the inner term in this integral is the measurement update done on the target state probability density \(eq. \(14\\erefore, the update of the target present and absent probabilities simply requires summing the \(non-normalized\et state probability after the measurement update is performed, followed by a normalization step which forces  For computational purposes, it is desirable that the target state grid contain the fewest number of cells that allow robust estimation. Cells which contain zero probability mass are useless computation and should be avoided. However since we are tracking moving ta rgets, the locations of the grid cells needed to estimate the target state density change over time. Therefore, we use a moving grid, which constantly re-centers around the estimated state of the target every update. In practice, we onl y allow the grid to translate a small number of cells at each time step, which minimizes the chance that a small number of bad measurements can shift the target off the grid  Figure 6\226 Single Sensor conditional likelihoods 


  9 On Grid Resolution As mentioned to earlier, the resolution \(spacing\of the target detection and tracking spatial grid cells is of critical importance. In our method, we choose to allow each cell center to represent the entire cell. An alternative approach would treat each cell as containing many sub-cells and requiring a weighted update. This has a similar computational burden as making the grid cell finer, and provides a benefit in the single target tracking case However, in the multitarget tracking case discussed later it introduces other problems. A discussion of these problems is deferred until later In the single target tracking case where cell centers represent the cell, the main c oncern is to ensure the cell spacing is fine enough. Th is avoids cases where the conditional likelihood has energy in large parts of a cell but does not overlap with the cell center. Figure 7 illustrates this. In this figure, cell boundaries are indicated by white lines, and cell centers by black dots. The true target location is given by the green dot. The conditional probability density is indicated by the color scale showing the intersection of the two sensor node beams. Because the grid resolution is insufficient, the cell center in the cell the target actually occupies does not corr espond to the peak of the conditional as it should. This mismatch leads to the target containing cell incorrectly r eceiving low likelihood in the measurement update  Figure 7 - Grid cells must be spaced finely enough to avoid degenerate cases where no cell center corresponds to the peak of the likelihood function The remedy for this issue is to make the cells more finely spaced. Also note that unless the grid cells are spaced grossly inadequately \(as they are in the example given Figure 11 later\is problem does typically does not persist from time step to time step as the target is moving. The most catastrophic consequence of poor grid cell resolution is track fragmentation. In the case of overly coarse cell discretization, the track existence probability will be artificially driven lower resu lting in \(incorrectly\moving the track. A new track would then be instituted very shortly On Computational Requirements The dominant properties that e ffect computations are \(i number of grid cells and \(ii\he number of targets. Section 5 discusses algorithm scaling with the number of targets. Here we focus on the single target case and note that the algorithm scales linearly with number of grid cells \(which is the product      Figure 8 illustrates empirically the tradeoff between cell resolution, tracking, and algorithm run time in the single target detection and tracking case. As the grid cell resolution decreases \(i.e., the number of cells used to represent the probability density increase\e tracking error decreases. It reaches an asymptote which is dictated by the sensor resolution. Furthermore, as the grid cell resolution decreases i.e., the number of grid cells increases\the computation time increases   Figure 8 \226 For single target tracking, performance improves as grid cells become more finely spaced. This is at the cost of increased computation time A second way to deal with th e degeneracy caused by large grid cells is to compute the cell likelihood function by weighting the likelihood of the beams into which the cell projects. In other words, inst ead of using the cell center to represent the entire cell, treat the cell as the continuum of points it represents.  Doing this exactly is computationally prohibitive, but approximate methods such as averaging discrete points in a cell are feasible. This is a net computation savings over simply making the grid cells smaller because it avoids increasing the number of cells that require temporal update In the multitarget case, the problem is more complicated Since many cells will correspond to the peak of the conditional likelihood, blindly shrinking cell size or interpolating the conditional will lead to false \(double initializations of targets. We will discuss this further in Sections 6 and 7 


  10 5  M ULTITARGET D ETECTION AND T RACKING T HEORY  In principle, multiple target detection and tracking requires estimation of the joint multitarget probability density   21 where denotes the number of targets present at time k   and  are the individual states of those targets The state space of this joint multitarget probability density grows exponentially with the number of targets and hence precise computation grows ex ponentially as well. Bruteforce multitarget discrete grid representations of this high dimensional posterior become intractable with more than two or three targets in a fo ur dimensional state space Fortunately, high fidelity modeling of the joint coupling is only necessary when targets are close together, i.e., widely spaced targets can be treated nearly optimally by solving multiple single target detection and tracking problems. In the \(unrealistic\g case, where all targets are well separated in measurement space numerical estimation of the joint density grows linearly with the number of targets rather than exponentially A more sophisticated approach to this problem is to automatically factorize the joint density into small groups of targets which must be treated jointly and develop a computational solution which is a compromise between the exponential growth of the joint computation and the linear growth of the fully factored computation. A detailed discussion of a joint density adaptive factorization approach and the precise algorithmic details in a related environment are discussed at length in [5  and  6    In our present implementation, we have chosen to simply treat the multiple target situation as a collection of single target detection and tracking problems. To account for the sub-optimality of this approach when targets are nearby in measurement space, we employ a data-censoring algorithm which operates when targets are close - i.e., we make the approximation    22 and censor some of the data fr om nearby trackers to prevent improper evaluation of the conditional likelihood Future work will extend this to high fidelity sensor modeling and joint density calculation for closely spaced targets when necessary. A sk etch of this extension analogous to the approach in [5 ws. Fi rst, th e target state and relevant uncertainty will be estimated for each target. Then those targets th at are close together will be treated in clusters. The \(now joint\ probability density for the cluster of targets will be temporally and measurement updated as a group. This computation is superlinear in the number of targets, but will only operate on targets in that cluster, rather than the entire target set. This method allows for careful physics-based modeling of the sensor returns when targets are close together e.g., including the expected coherent sums of energy from nearby targets and accurately modeling sidelobe interference\d will allow for more effective handling of crossing targets and convoy movements 6  A MBIGUOUS T ARGETS  In addition to left-right ambigu ity arising from linear arrays in the present setting there are intersection ambiguities. In the multisensor, multitarget, bearings-only environment we study here there are ambiguities arising from the \(persistent intersection of bearing measur ements across sensors from e.g., \(sensor 1, target 1\and \(sensor 2, target 2 Figure 9 gives an example of this phenomenon, by showing the multisensory conditional lik elihood surface in a highSNR and low-SNR case, respectivel y. In this example, there are two passive sensors, one lo cated at the northeast and one at the southeast of the surveillance region. There are two real targets indicated by white circles. Each passive sensor receives high energy at the b earings corresponding to the true targets as expected. This results in \(correct intersections at the true locati ons of the targets. However there are also false intersections, which correspond to the mismatched beams \(i.e., a beam from sensor 1, target 1 intersection with a beam from sensor 2, target 2 


  11 Ambiguous targets often move physically for some time and for that time are indistinguishable from real targets. This short term phenomenon is not a problem with the tracker but is a fundamental issue of physics. However, over time, the ambiguous targets can be distinguished from real targets in a tracking environment as they will move in a non-physical manner. Typically this non-physical motion takes the form of a jump movement as the ambiguities approach a line of symmetry defined by the nodes Figure 10 provides an illustration of this behavior. For the first 500 time steps \(shown at left\both the true targets green\d the ambiguous targ ets \(red\anner that is plausible physically. Ho wever, as shown at right after time step 500 the ambiguous targets move in a dramatically non-physical manner. This behavior is common and in this case is co rrelated with the ambiguity position moving through a sensor line of symmetry 7  M ULTITARGET D ETECTION   T RACKING I MPLEMENTATION  As discussed earlier, we have chosen to factorize the joint density into a collection of single target densities. This approach is optimal when targ ets are well separated but is inappropriate as targets beco me close in sensor space Future work includes an adaptive approach which will appropriately treat these closel y spaced targets jointly. In the present work however, we employ an engineering approach to cope with this sub optimality which prevents measurement sharing among cl osely spaced trackers. These algorithmic modifications mean that the final product is not simply multiple single target detection and tracking algorithms running in parallel First, we partition the surveillance region into multiple overlapping static detection grids. Each detection grid is a single target detector as described above for detecting   Figure 9 \226 Bearings intersections corresponding to true targets \(white circles nd ambiguous intersections There are two sensors, located NE and SE of the image, resp ectively. Each sensor has hi gh energy returns at the bearings corresponding to the true targ ets, yielding intersections at the true target locations. However, there are also false intersections between, for example, \(s ensor 1, target 1\ and \(sensor 2, target 2   Figure 10\226 Left: true and ambiguous trajectories for the fi rst 500 time steps of the simulation. Right: After time step 500, the ambiguous targets make large non-physical jumps 


  12 targets in its sub-region. We compute the target present hypothesis independently for each detector grid. It is desirable that each detector gr id is small in total spatial extent to allow detection of closely spaced targets since each individual detection grid is only capable of accurately modeling the target absent/present hypothesis when there is either a single target presen t or no targets present. In contrast, it is desirable that each grid is large enough \(in total spatial extent\o capture multiple time steps of measurements on a moving target to allow accurate computation of the target present hypothesis Second, the single target detector/tracker equations discussed above\update each detector grid. The temporal and measurement updates proceed as if there were a single target present on the grid, updating the target present hypothesis with the new data. In this manner, each detector grid performs the Bayes-optimal single target detection and tracking algorithm for its spatial region If the target present hypothesis associated with a detector exceeds a threshold, the algorith m declares a new target and initializes a tracking grid to follow the target. This target grid is mobile and continually re-centered on the predicted target location. It is desirable that this tracking grid is as small as feasible for both computational reasons and also to allow multiple closely spaced targets to be tracked on their own grids. However, the grid must be large enough in spatial extent to account for temporal uncertainties in target motion and measurement error The individual target temporal updates proceed exactly as in the single target case. The measurement updates of the detection and tracking grids use a measurement-censoring step not present in the single target tracker. This measurement censoring step is executed in lieu of fully estimating the joint multitarget density, and should be looked upon as an engineering method for dealing with closely spaced targets that is less costly than fully estimating the joint density. In experiments with real data it has been found that this method often provides sufficient accuracy to perform adequate tracking. However, it is our plan to look at joint density estimation as in [5  fu ture work To elaborate, measurements that fall into the spatial extent of any tracker are censored from the detectors. Second trackers compete for measurem ents based on their prior probabilities. These steps prevent multiple targets from being incorrectly detected at the same location, and also prevent multiple nearby trackers from simply following the strongest target On Grid Resolution Like the case of single target tracking, it is important that grid cell spatial resolution be chosen judiciously. If grid cells are too coarse, it is possible no cell centers will project into the maximum of the conditional likelihood \(refer back to Figure 7\However, even if the grid size too large, the behavior of the tracker may not be catastrophic. Typical behavior is that a detector initiates a track; the tracker follows the target for some period of time and terminates the track; then the detector reinitiates a tracker on the same target. Figure 11 illustrates the effect of grid cell resolution on tracking performance. The left panel shows performance when the grid is too coarsely spaced. The red dots show track termination points, and illustrate that a single target track is routinely broken and restarted when the grid spacing is too coarse. The right panel shows performance when grid spacing is appropriately sel ected. All track s are followed throughout the entire vignette w ith no track fragmentation Unlike the case of single target tracking, the multitarget case exhibits problems when the grid resolution is too small. In particular, since the multitarget detectors constantly seek new targets, small grid cell resolution can have the unintended consequence of allowing energy from the conditional update to bleed onto both a tracker \(correctly and the underlying detector \(incorrectly\nd thus generate   Figure 11 \226 Left: Multitarget tracking with \(too\coarse grid resolution. Right: Multitarget tracking with appropriately selected resolution. In both panels, red dots show track termi nation points, green lines show true target trajectories, and the other colo red lines show the track estimates 


  13 false \(double\argets Figure 12 illustrates this situation. The conditional update correctly updates the tracker wh ich is tasked with following the target. However, the detector which is partially spatially coincident with the tracker also receives energy from the conditional update. This can lead the detector to initiate falsely\second target nearby the first target This effect can be countered a number of ways. First, we can adjust the speed at which the tracker re-centers itself The double initialization phenomenon occurs when the PDF peaks near the edge of the tracker grid. However, this method has the side effect of potentially allowing probability to fall off of the grid in low SNR environments causing track loss. Of course if the SNR is low enough or measurement outages occur tracks will be dropped. Second a guardband around the tracker that does not allow any detector sufficiently near the tracker to receive reinforcement via the conditional density can mitigate the double target problem. However, this has the side effect of preventing detection of closely spaced targets. Third increasing the spatial extent of the tracker has a similar effect as the using a guardband. It does require increased computation, but generates a better representation of the posterior There are several engineering tradeoffs. The first is that large tracker grids \(or large guard bands\ prevent falsely detecting new targets because of conditional probability spill over. However, if applied too aggressively, this will prevent correctly detecting cl osely spaced targets. Second quick tracker grid translation correctly centers the target mass, again preventing spillover into nearby detectors However, overly liberal trac ker repositioning may in fact move trackers to spurious energy locations and drop true targets off of the finite grid On Ambiguous Targets As discussed earlier, ambiguous targets will eventually move non-physically and this will cause the tracker to remove them via its natural prediction and update process Figure 13 illustrates this phenomenon. There are two real targets that create two persistent ambiguities. All four are detected and tracked automati cally. The ambiguous targets however, eventually move non-physically due to their reliance on the node bearing angles. The tracker automatically penalizes the non-physical motion and the targets\222 present hypothesis decrease quickly over time Ambiguous target removal is done automatically in the Bayesian framework as follows The PDF on target state is predicted forward in time according to the kinematic model True targets will have behavior consistent with the kinematic model \(note the kinematic model is a statistical model so it is predicting a range of possibilities for the future target state\biguous targets may behave consistently with this model for a period of time, but eventually they will appear to perform a non-physical maneuver \(these epochs typically come when the ambiguous target crosses a line of symmetry in the sensor\this point, the predicted target position will be in strong disagreement with the inco ming measurements on that target. This mismatch in predicted target position and measurements leads to a decr ease in the target present hypothesis as calculated in eq. \(4\long, only true targets remain   Figure 12 \226 Improper selection of grid resolution leads to multiple initializations on the same target. Left Measurement update of a Tracker \(red=highest likelih ood, blue=lowest\Right Measurement update of a detector which lies near the Tracker.  Since the track er size has been improperly chosen, some energy from the measurements of a single target leak s on to the detector. This can le ad to false double-initializations 


  14 8  C ONCLUSION  This paper has described a Bayesian approach to detecting and tracking multiple moving targets using acoustic data from multiple passive arrays In contrast to traditional undersea acoustic systems, which develop tracks at the single array level and require track association, our approach fuses data at the m easurement level and operates directly in the target state space We have detailed a well known nonlinear filtering approach to single target detection and tracking [1, 4 and desc ri be d our computationally efficient finite-grid approach to the required density estimation. We have furthermore extended this to the multiple target case by employing a bank of single target detector tracke rs and approximation methods that adjust for closely spaced targets. This approximate approach avoids fully treating the computationally complex joint multitarget problem Future work includes modified approaches to posterior estimation including dynamic grid extent, dynamic grid resolution, and particle filtering. It is anticipated that adaptive sampling of the posterior will lead to computational savings. Furthermore, future work includes more detailed modeling and estimation of closely spaced targets allowing a more accurate representation of the joint target density. Naively implemented, this implies exponential growth \(in the number of targets\r the probability state space being es timated. However, recent work in a related tracking domain on adaptive density factorization [5 c h a stic sa m p lin g  p article filtering    pr ovi de m e t h o d s t h at m i t i g at e t h i s com put at i o n gr owt h  when the full joint density is treated  A PPENDIX  This section discusses the details of how the single target probability density is time evolved on a discrete grid. This discussion is similar to that found elsewhere [15, 14, 13 We wish to compute the single target probability density at time      from the density at time     The relation between these two densities can be expressed using the law of total probability as                We expand     using a second order Taylor series as               where  is the vector of partial derivatives, i.e and is the matrix of second order partial derivatives Then the relation of \(23\ approximated as   Figure 13\226 Left: P h1 over time for four targets, two of which are real and two of which are ambiguous. Although the ambiguous intersections are persistent, eventually the false targets ha ve non-physical motion. The target present hypothesis quickly goes to zero for these targets and they are elimin ated. Right: the tracker estimate of target position and red circles indicating the removal point fo r the false targets 


  15             Where denotes the expectation with respect to the transition distribution    and the omitted terms involve similar terms involving and and cross terms between the and coordinates We use the nearly constant velocity \(NCV\model to specify the transition distribution    This assumption corresponds to one where the target moves at constant velocity except for random jump changes \(i.e nearly constant velocity\is is a plausible model when  is small as it is here Specifically, the NCV model assumes step changes in target velocity defined by the Ito Equations     This model implies  and likewise for  It is furthermore assumed that th e noise processes in each coordinate are independent Under this model, we can eval uate the required terms from 25\ as follows          And likewise for terms involving and Notice that all cross terms \(e.g  have expectation due to the assumption that the noise process is independent in the two coordinates This model simplifies \(25\ to         where the terms omitted are replicas involving the  coordinate Under the assumption that is small, this can be rewritten as    For implementation, this is approximated using an implicit Euler scheme wh ere      Where the indices  represent the discrete    locations where the probability mass is captured Likewise, using forward differencing      and          and similarly for the y coordinate system When substituted into \(28\is leads to a series of equations of the form                This series of equations defi ne the probability at each point at time  It can be efficiently solved via Thomas\222 algorithm \(rather than simply inverted\he matrix is tridiagonal     


  16 R EFERENCES    R o y E. Bet h el Benjam i n Shapo, C h r i st opher M   Kreucher, \223PDF Detection and Tracking\224, under review IEEE Transactions on Aerospace and Electronic Systems  2 y. E B eth e l an d G. J. Paras, \223A PDF Mu lt it arg et Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 30, no. 2, pp. 386-403, April 1994 3   R o y E  B e t h e l a n d G  J  P a r a s  223 A P D F M u l t i s e n s o r  Multitarget Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 34, no. 1, pp. 153-168 January 1998  L   D   Stone, C. A. Bar l ow, and T. L Corwin, \223Bayesian  Multiple Target Tracking\224  Boston: Artech House, 1999  l la and A. Hero, \223Multitarget Tracking using the Joint Multitarget Probability Density\224 IEEE Transactions on Aerosp ace and Electronic Systems  vol. 41, no. 4, pp. 1396-1414, October 2005  M  M o relande, C. Kreucher, K. Kastella, \223A Bay e sian  Approach to Multiple Target Detection and Tracking\224 IEEE Transactions on Signal Processing vol. 55, no. 5 pp. 1589-1604, May 2007  B  Shapo, and R  E B e t h el  223An Overvi ew of t h e Probability Density Function \(PDF\er\224 Oceans 2006 Boston, Sept. 2006  R oy L. St r e it 223M ult i s ensor M ul tit arget Int e nsit y Fil t er 224  International Conference on Information Fusion  Cologne, Germany July 2008  M  Ort on and W Fi t z geral d 223A B a y e si an approach t o  tracking multiple targets using sensor arrays and particle filters\224 IEEE Transactions on Signal Processing, vol. 50 no. 2, pages 216-223, Feb 2002  A. Doucet B Vo, C Andri e u, and M Davy 223Par t i c le filtering for multi-target tracking and sensor management\224, IEEE International Conference on Information Fusion, 2002  H Van T r ees, \223Det ecti o n Est i m a t i on, and M odul at i o n  Theory IV:  Optimum Array Processing\224  J. C St ri k w erda, Fi nit e  Di fference Sch e m e s and Partial Differential Equations, Ch apman & Hall, New York 1989   K. Kast el la and C Kreucher, \223M ult i p l e  M odel Nonl i n ear  Filtering for Low Signal Ground Target Applications\224 IEEE Transactions on Aerospace and Electronic Systems vol. 41, no. 2, April 2005, pp. 549-564  Z. Tang and \334. \326zg\374n er, \223Sensor Fu si on for Target Track Maintenance with Multiple UAVs based on Bayesian Filtering Method and Hospitability Map\224 Proceedings of the 42 nd IEEE Conference on Decision and Control pages 19-24, December 2003  K. Kast ell a 223Fi n it e di ff erence m e t hods for no nl i n ear filtering and automatic target recognition\224 MultitargetMultisensor Tracking: Applications and Advances vol III, pages 233-258, Artech House, 2000 B IOGRAPHY  Chris Kreucher received his Ph.D. in Electrical Engineering from the University of Michigan in 2005. He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan. From 1998 to 2007, he was a Staff Scientist at General Dynamics Advanced Information Systems' Michigan Research & Development Facility \(formerly ERIM\. His current research interests include nonlinear filtering \(specifically particle filtering Bayesian methods of multitarget tracking, self localization information theoretic sensor management, and distributed swarm management Ben Shapo earned his Ph.D. in El ectrical Engineering in 1996 from the University of Michigan.  He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan.  From 2003 to 2008 he was a Lead Engineer at General Dynamics, where he contributed to a number of RF and acoustics signal processing and tracking efforts.  Dr. Shapo has 12 years experience in the DoD research community in the areas of detection, tracking, and data fusion, with emphasis on highfidelity simulations and applying new methods to real data  Dr. Roy Bethel is currently employed at The MITRE Corporation in McLean, VA. He has been actively involved in development, testing, and evaluation of signal processing and detection and tracking systems. In particular, he has developed many systems that have been implemented on United States Navy airborne, surface, and submerged platforms. He is currently engaged in research and development of innovative approaches to multitarget detection and tracking  A CKNOWLEDGEMENTS  This work was partially funded by the Office of Naval Research contract N00014-08-C-0275. The authors would like to thank Dr. John Tague for his support, and Mr. Scott Spencer and Dr. Charles Choi for their assistance 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 



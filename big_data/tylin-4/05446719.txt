  1 A 320 Mbps Flexible Discrete Wavelet Transform Processor for Extreme Environments  Paul Winterrowd 1 Chad Orbe 1 Sterling Whitaker 1 Eric Cameron 1 Ronald  Nelson 1 Gary Maki 1 Dave Fisher 2 Pen-Shu Yeh 2 
 1 CAMBR/U. Idaho, address 721 Lochsa Street Ste. 8, Post Falls, Idaho 83854, USA, pwinter@cambr.uidaho.edu corbe@cambr.uidaho.edu, whitaker@cambr.uidaho.edu ecameron@cambr.uidaho.edu, ronels@cambr.uidaho.edu 
gmaki@cambr.uidaho.edu 
2 NASA/GSFC, Code 567, Greenbelt, MD 20771, USA david.y.fisher@nasa.gov, penshu.yeh@nasa.gov    Abstract 227 A 320 Mbps radiation-tolerant discrete wavelet transform application specific integrated circuit \(ASIC has been developed 12 The ASIC chip implements the discrete wavelet transform functionality specified by the Consultative Committee for Space Data Systems \(CCSDS recommendation for Image Data Compression. Input sample precision is configurable up to 16 bit values, and the filter functions in both integer and floating modes are also highly configurable.  The design is implemented in 0.25um CMOS utilizing a custom library de 
signed around radiation-hardby-design \(RHBD\echniques and targeted operation from 55 to 125 degree C.  The chip has been verified functionally and under radiated conditions demonstrating an LET onset threshold greater than 55 LET and latchup immunity beyond 120 LET.  A pl an is in place to further test the functionality of this ASIC at extremely low temperatures at the GSFC cryogenic test facilities Table of Contents 1  I NTRODUCTION 1  2  A LGORITHM O VERVIEW 1 
 3  ASIC  A RCHITECTURE 2  4  ASIC  I MPLEMENTATION 4  5  RHBD  P ERFORMANCE 4  6  C RYOGENIC P ERFORMANCE 6  7  
C ONCLUSION 6  A CKNOWLEDGEMENTS 6  R EFERENCES 6  B IOGRAPHY 7    1  I NTRODUCTION  The CCSDS Image data compression recommendation   released in 2005, specifies a two-dimensional \(2-d\screte wavelet transform as part of the compression algorithm  
 1 978-1-4244-3888-4/10 25.00 \2512010 IEEE 2 IEEEAC paper#1554 Version 2, Updated 2009:10:30 This specification outlines several modes, including a 9/7 Integer and a 9/7 Float transform and the requirement that the transform be able to process data generated from both frame-based and push-broom sensors; the latter utilizes satellite motion along track to continuously sweep a 1dimensional \(1-d\sensor footprint across the satellite ground cover. The use of the integer wavelet allows fully lossless compression to be performed in addition to userprogrammed lossy compression modes No radiation-hardened wavelet processor has been flown in 
space for performing data compression. Earlier 2-d spaceborne lossy compressors were based on a 2-d discrete cosine transform \(DCT hard ASIC form to execute JPEG-like algorithms [9 Th es e rad-hard DCT chips, some implemented on SPOT-5 satellite\222s high-resolution instruments, provide less than 20 Msamples/sec on fixed 8bit or 10-bit input data  Implementation of a single-level 2-d DWT for space application has been studied on a proposed coarse-grain architecture without real hardware results  El ect roni cs implementing similar 2-d DWT in a JPEG2000 compression scheme is available in comme rcial-grade electronics [12 which is un-suitable for space applications In this paper, the architecture for implementing a 3-level 2-d 
DWT is first described, this architecture is applicable to the lifting scheme used in the Integer DWT as well as the direct filtering scheme used in the Float DWT [1 e sin g l eevent-transient \(SET\ mitigation technique necessary to achieve space flight worthy st atus is then provided along with radiation test result and power usage measurement 2  A LGORITHM O VERVIEW  The Discrete Wavelet Transform \(DWT\s designed to decorrelate an image, decomposing it into several subbands Each subband is a smaller version of the image, but filtered to represent primarily a limited range of spatial frequencies 


single stage 2-d DW ass horizontal high-pass vertical lowof LL2 subband c d e ass horizontal low-pass vertical hi h\(a\ \(b c Figure 1 Single Level Two-Dimensional DWT Decomposition of an Image \(from       2 This ASIC implements the 3 level 2-dimensional DWT by repeated application of a one-dimensional DWT This one-dimensional DWT is first applied to the rows of the image, and then to the columns of the transformed image, as illustrated in Figure 1. It uses 9 taps to compute low-pass output, and 7 taps to compute high-pass output alternating between these two on each subsequent value The transform is, thus, referred to as a \2239/7\224 DWT under the usual naming convention.  Subsequent stages of the transform are applied to the low-pass horizontal / low-pass vertical subband output from the previous stage, producing the pyramidal decomposition described in  and shown i n  figure 2. The CCSDS calls for 3 stages of DWT decomposition, decomposing an image into 10 subbands, as illustrated in Figure 2 The CCSDS outlines two 9/7 transforms.  The floatingpoint filter [7 is im p l em en ted u s in g fix ed p o i n t arith m etic with enough precision to avoid data loss\ves improved performance at low bit rates, while the integer filter [8 erm its lo ssless co m p ressio n   3  ASIC  A RCHITECTURE  The DWT ASIC processes input image data in 3 steps.  In the first step, since data is r eceived in a line by line fashion the DWT chip performs the first level horizontal wavelet  HH2 HL2 LH2 HH1 LL2 HH2 HL2 HH3 HL3 LH2 LH3 LL3  Figure 2 Example of 3-Level Two-Dimensional DW T Decomposition of an Image \(from   LH1 HL1 1-d DW T of each row 1-d DW T of each column g p g p g p p p T of original image single stage 2-d DWT of LL1 subband single stage 2-d DW T horizontal lo wass horizontal high-pass horizontal high-pass ve rtica l hi hass horizontal low-pass vertical lowass original image orig in al ima a LL1 LH1 HH1 HL1 LH1 HH1 HL1 


  3 filtering and writes the results to external RAM In the second step the DWT begins processing a 32-pixel high \223strip\224 of the image, read ing the data in a column-bycolumn fashion from the external RAM.  Note that if the image height is greater than 32 then the DWT must read pixels above and/or below this strip in order to properly implement the specified filter function Next, the ASIC performs the first level vertical filtering and both the horizontal and vertical filtering for the next two levels of the transform and writes the results back to the external RAM \(but in an orde r that reflects the \22332-pixel wide strip\224 approach\he third and final step, the DWT chip reads the data back from external RAM in a horizontal 8-by-8 block sequence for processing by downstream modules.  This 8-by-8 block is shown in figure 3 and is the smallest square image producing at least one pixel in each sub-band The architecture which implements this data flow contains six major blocks: the external memory interface, the main control block, the out put block, the serial interface by which the ASIC is programmed, the vertical and horizontal processors and the MAC block as shown in figure 4   The control block serves many functions. It controls the flow of information between all the other blocks and keeps the data pipeline full, prioritiz ing which blocks get access to the memory interface in order to keep the processors, MAC and output blocks as busy as possible.  This was done by using a queue approach All the major blocks have queues of data to work on and/or queues of commands to execute.  The memory interface, for example, has a command queue that contains either read or write commands with the corresponding address \(and data in the case of the write\The Vertical/Horizontal Processors have queues of incoming data.  The first horizontal processor is fed by the chips incoming data stream.  As discussed above, this is then output to memory and read back in, in a column by-column fashion and feeds the next processor to feed the fi rst vertical processor.  Each subsequent processor is fed from its predecessor decimating when required.  And the output block has a large queue fed from the memory interface The control block attempts to keep all of these queues half full, with the output block having priority \(when the chip is operating at full capacity for a given frequency any \223gaps\224 in the output stream can never be \223recovered\224 and will eventually lead to an internal fifo overflow few exceptions to this rule in that the MAC is on a fixed processor rotation that reflects the expected peak data rates from the various processors \(and corresponding ratios of data since higher level processors are processing roughly one quarter or one sixteenth of the data\he memory interface must always give prio rity to a memory write from the MAC unit since it\222s data is not buffered The vertical and horizontal processors serve two functions reordering and reflecting.  Re ordering is required only from the horizontal processors that must rearrange the incoming  Figure 3 \226 A local DWT block formed from the 64 shaded pixels taken from ten sub-bands \(from   To/From RAM Serial I/F BPE Data Data In Figure 4 226 DWT ASIC Major Modules DWT FIFO Control Memory Interface MAC Vertical Horizontal Processors Serial I/F Output 


  4 data, which was read from memory in a column-by-column fashion, back into a line-by-line data stream.  Reflecting is required due to the CCSDS specification of the 1-d filter This specification dictates that pixels at the edge of an image must be \223reflected\224 in a specific way.  Certain control bits are passed along with each pixel from the control block to facilitate both of these tasks The MAC block receives 9 24-b it values from the vertical and horizontal processors with some control bits that specify whether the values should be run through the lowpass or high-pass filter.  These values are then processed and the results are sent back to the control block which sends them on to the memory block and/or back to downstream processors  The output block receives pr ocessed 8x8 blocks from the control block which it retrieves from external memory.  The output block reorders the values in these 8x8 blocks into the sequence expected by the downstream module and is also responsible for final weighting, as per the CCSDS specification, for the integer transform The DWT ASIC currently supports image/scan-line width up to 8192 pixels.  Image widths must be larger than or equal to 32 and divisible by 8.  Image heights must be divisible by 32, ranging from 32 to 8192 or can be set to infinite for push broom sensors.  Thus, the minimum image size that can be processed is 32x32. The ASIC supports a maximum clock rate of 100 Mhz and the input data rate must not exceed 1/5 of the frequency of this clock \(though a FIFO is present so bursts can be tolerated over the short term\producing a maximum processing rate of 20 Megasamples/s. Detailed DWT ASIC information is available in [4 4  ASIC  I MPLEMENTATION  The DWT ASIC is implemented in a 0.25\265 CMOS process utilizing radiation-hard-by-design \(RHBD\techniques developed at CAMBR/U. Idaho and elsewhere The memory cells utilized in the design are based on the SERT \(Single Event Resistant Topology\l As i t s  name implies, this cell is immune to single bit state changes and, due to internal redundancy, is able to return to its initial state after a single node upset In order to attenuate the eff ects of single event transients SETs\in the logic, the HDL was synthesized to a dual rail implementation.  This allows the memory cells to determine 0,0\ invalid values 0,1 1,0 For global signals where dua l rail redundancy would have been costly, such as the clock tree, the drivers were all sized sufficiently large so as to be immune to SET\222s up to the targeted LET threshold 5  RHBD  P ERFORMANCE  Radiation testing for this part was conducted at the Radiation Effects Facility at Texas A&M\222s Cyclotron Institute Test conditions for sensitive area versus LET measurements were at room temperature with parts run at 40 Mhz \(board frequency was limited due to an issue not related to the DWT ASIC\of the process, core voltage was kept at a specified 2.5 V and I/O voltage was kept at 3.3 V.  All sample points were run to a total fluence of 1e7 particles per cm 2  The test setup was composed, primarily, of a custom test board with two programmable FPGA modules and three DWT\222s as shown in figure 5.  One FPGA was responsible for pattern generation while the second chip was responsible for logical comparisons between the DUTs.  For each sample point an individual DWT chip was targeted with the particle beam and the output was compared to the 223golden\224 DUT on the board.  Each device was run with a configuration chosen to maximize internal logic gate usage  The pattern generator \(FPGA\med to reset the chip, configure it and then feed it a set of random vectors of specified length.  This consisted of a reset followed by several thousand vectors.  At 40 Mhz this test was being repeated several thousand times per second.  Given the nature of these devices, one SEU event can lead to many errors on the output.  Thus, if there were any errors at all during a single run of the vector set \(or if there were several thousand errors during that run\t was counted as one SEU The results are summarized in table 1 and figure 6. The LET onset for the fit value in figure 6 was 55 LET.  Note that the sensitive area is calculated by multiplying the errors by the Figure 5 226 Example Radiation Test Board 


  5 inverse of the average particle strikes per square micron for each test and in table 1 this value has been further multiplied by 2.5 to conservatively estimate increased sensitivity when the chip speed is increased from 40 Mhz to 100 Mhz Table 1: DWT Sensitive Area Beam Angle LET\(eff\error s Sen. area um^2 Ar 55 15.7 0 0 Ag 0 44.6 0 0 Ag 30 51.7 0 0 Kr 55 52.6 0 0 Ag 45 63.8 5 125 Ag 50 70.5 2 50 Ho 0 71.9 3 75 Ag 55 79.5 5 125 Ho 30 83.2 5 125 Ho 45 102.4 40 1000 Ho 50 112.9 83 2075 Ho 55 127.1 104 2600   Latchup testing was performed at 50 Mhz with the core voltage at 2.75V and the I/O voltage at 3.63 V \(both of which are 10% over nominal and the maximum allowed voltage by the process ain, each individual run was taken to a total fluence of 1e7 particles per cm 2 All parts being irradiated were de-lidde d while the reference part was not de-lidded.  The devices were heated to 80C using MINCO heaters mounted above and below the cavity as shown in figure 5.  The temperature of the silicon itself was measured before and after each test using an IR thermometer with a large distance to spot ratio.  In order to verify that the temperature was not fluctuating unduly during irradiation a thermistor was mounted to the back of the device and monitored throughout the test as shown in figure 7 Parts were positioned in each test so that the center of the die was 4.5 cm from the beam ex it aperture.  In this process there is approximately 9.1 um of material \(primarily silicon dioxide and aluminum wiring\ween the air and the transistor junction.  Even at high angles, this leaves the beam well above the Bragg peak.  Current was monitored during each test and the peak value noted.  A summary of Figure 7 226 Back Mounted Thermistor Figure 6 226 DWT Sensitive Area Graph 


  6 the results are shown in table 2.  Each test was run to a total fluence of 10^7 ions/cm^2 with a beam energy of 15 MeV/amu.  Note that the starting and peak currents shown in table 2 are for the core and I/O ring respectively.  No discernable increase in current was measured at any point in the testing Laboratory testing of the DWT ASIC at room temperature shows the chip\222s top speed is over 40% more than the design target of 20 Msample/sec.  The power consumption measured in figure 8 is well within the design target. From figure 8, the rad-hard DWT ASIC consumes 0.163 watt/Msamples/sec processing  6  C RYOGENIC P ERFORMANCE  A plan is in place to test this part at cryogenic temperatures at the GSFC cryogenic test facilities maintained by the Parts, Packaging and Assembly Technologies Office 7  C ONCLUSION  A high-speed low-power flex ible space ready discrete wavelet transform ASIC operating at over 20 Msamples/sec was successfully developed.  No other radiation-hardened wavelet processor for performing data compression is currently flying in space.  Im plementing the 9/7 Float DWT algorithm on an embedded processor, and attaining the 20 Msamples/sec data rate, would require roughly 600 32-bit Mflops, 50 million 32-bit memory data accesses per second assuming there is enough memory to store the entire image\and the control code would likely exceed 500 Mops This DWT ASIC implements the discrete wavelet transform functionality recommended in the CCSDS Image Data Compression The ASIC is fully immune to single-eventlatchup past 120 LET and singl e-event-upset up to 55 LET as validated by testing at Texas A&M University Cyclotron Institute\222s Radiation Effects Facility. This chip is currently undergoing qualification at Aeroflex for a NASA mission A CKNOWLEDGEMENTS  The development of this ASIC and the development of the standard cell library it was synthesized in has been funded by grants from the National Aeronautics and Space Administration R EFERENCES    Image Data Compression Recommendation for Space Data Systems Standards, CCSDS 122.0-B-1, Blue Book Issue 1. Washington D.C.: CCSDS, November, 2005 available from www.ccsds.org   Image Data Compression Information Report for Space Data Systems Standards, CCSDS 120.1-G-1, Green Book Issue 1. Washington D.C.: CCSDS,  June 2007, available from www.ccsds.org    Pen-Shu Yeh, Phi l i ppe Arm b rust er, Aaron Ki el y B a rt  Masschelein, Gilles Moury Christoph Schaefer, Carole Thiebaut, \223 The New CCSDS Image Data Compression Recommendation\223 Proc. of the IEEE 2005 Aerospace Conference Big Sky, Montana, March 2005 Table 2: Latchup Test Results Beam Angl e Eff LET Starting Temp Endin g Temp Starting Current A Peak Current A Au 0 87.5 80.2 C 80.0 C 0.54/0.61 0.54/0.61 Au 0 87.5 79.9 C 80.1 C 0.54/0.60 0.54/0.60 Au 0 87.5 79.5 C 80.0 C 0.53/0.59 0.53/0.59 Au 0 87.5 81.0 C 80.0 C 0.55/0.61 0.55/0.61 Au 0 87.5 79.5 C 80.5 C 0.97/0.51 0.97/0.51 Au 0 87.5 79.8 C 81.0 C 0.96/0.50 0.97/0.50 Au 0 87.5 79.9 C 80.4 C 1.0/0.48 1.0/0.48 Au 50 137.2 80.0 C 81.2 C 0.97/0.50 0.97/0.50 Au 50 137.2 81.0 C 80.1 C 1.0/0.49 1.0/0.49 Fi g ure 8 \226 DWT Power Usa g e 


  7  T Prelim inary Specification Version 0.6, available from CAMBR, 721 Lochsa Street Ste. 8, Post Falls, Idaho 83854  Q. Shi G. M a ki 223New Desi gn Techni ques for SEU Immune Circuits\224 Proc. of the 9 th Nasa Symposium on VLSI Design Pages 7.4.1-7.4.16, November 2000 6 S. G. Mallat, \223A Th eo ry fo r Mu ltireso l u tio n Sig n al Decomposition: The Wavelet Representation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol. 11, no. 7, pp. 674--693, July 1989   JPEG2000: Image Compression Fundamentals Standards and Practice D. Taubman, M. Marcellin Kluwer Academic Publishers, 2002   A R  C a l d erbank, I Daubechi e s, W Swel dens, B L. Yeo 223Wavelet Transforms that Ma p Integers to Integers,\224 Appl. Comput. Harmon. Anal vol. 5, pp. 332\226369, July 1998  Joi n t Phot ographi c Expert s Group  ISO/IEC JTC 1/SC 29/WG 1 - Coding of Still Pictures \(SC 29/WG 1 Structure  http://www.jpeg.org  10] Alcatel Space Industries presentation information 2002  Saji d B a l o ch, Tughrul Arsl an, Adri an St oi ca R adi a t i on Hardened Coarse-Grain Rec onfigurable Architecture for Space Applications," ipdps, pp.189, 2007 IEEE International Parallel and Distributed Processing Symposium, 2007  See product spec for JPEG2000 vi deo codec http://www.analog.com  B IOGRAPHY   Paul Winterrowd received his B.S.E.E degree from the University of Idaho Moscow in 1990.  He worked as a VLSI design engineer for Advanced Hardware Architectures from 1992 to 1998, for Hewlett-Packard from 1998 to 2004 and most recently at the Center for Advanced Microelectronics and Biomolecular Research from 2004 to present Chad Orbe received his B.S.E.E degree from the University of Idaho Moscow in 2001.  He worked internships at both Micron and Agilent He was a VLSI design engineer for Advanced Hardware Architectures before joining the staff of the Center for Advanced Microelectronics and Biomolecular Research where he led the design of an image compression chip for space applications based on the bit plane encoding algorithm. He currently leads the development of a companion bit plane decoding chip Sterling R. Whitaker S'76M'77-SM'97\ received the B S.E.E. degree from Brigham Young University, Provo, UT, in 1977, and the M.S. and Ph.D degrees, both in electrical engineering from the University of Idaho, Moscow, in 1982 and 1988, respectively.  He is currently a Research Professor with the Center for Advanced Microelectronics and Biomolecular Research.  He was previously an Associate Professor at the University of New Mexico, Albuquerque His industrial experience includes American Microsystems Inc. \(1977-1985\ and AKM DesignTek \(1995-1997\.  His current research interest is in high-performance application-specific processors for the space environment He holds 13 U.S. patents, has published 95 papers, and has been a key contributor on 73 in tegrated circuit designs Eric Cameron graduated from the University of New Mexico in 1994 with a Bachelor of Science in Computer Science with a minor in Mathematics He is currently employed with the Center for Advanced Microelectronics and Biomolecular Research at the University of Idaho as a research engineer and information systems administrator.  His main areas of interest include biosensor work, particularly at the device-computer interface computer systems security and data integrity, and computer modeling of custom integrated circuits Ron Nelson received his B.S.E.E and M.S.E.E. from the University of Idaho, Moscow in 1997 and 2000 respectively.  He has been a research engineer with the Center for Advanced Microelectronics and Biomolecular Research since 2003 and is working on electronic biosensor development and low power electronics for space applications.  His professional interests include power electronics, distribution, and power flow control, time domain electromagnetic simulations, and automated instrumentation design  


  8 Gary K. Maki S'63-M'69SM'02\ received the B.S.E.E degree from Michigan Technological University Houghton, and the M.S. and Ph.D degrees in electrical engineering from the University of Missouri, Rolla.  He is currently a professor emeritus in the Electrical and Computer Engineering Department at the University of Idaho Moscow.  Before retiring he held the position of director for the Center for Advanced Microelectronis and Biomolecular Research for several years.  He held a similar position at the University of New Mexico, Albuquerque.  Current research interests range from high performance electronics to biomolecular electronic sensors.  He has served on boards with the Hewlett Packard Laboratories Science Advisory Board, University Space Research Association Technology Board, the NASA Data System Working Group and the USDA national nanotechnology grant selection board.  He has authored in excess of 75 papers and holds 7 patents Pen-Shu Yeh works for NASA\222s Goddard Space Flight Center. She has been leading the development of data compression and onboard processing technology for over twenty years at Goddard. She has supported various space missions in implementing data compression and currently represents GSFC to the Data Compression Working Group within CCSDS. Pen-Shu Yeh received a Ph.D in Electrical Engineering in 1981 from Stanford University after completing a BSEE at the National Taiwan University and a MSEE at the University of Washington in Seattle. Her research interests include signal processing, pattern recognition, computer vision and implementation using radiation-hard space electronics Dave Fisher has worked for NASA Goddard Space Flight Center since 1995. He has been developing high-speed digital subsystems in applications involving receiver telemetry processing as well as technology development projects for space communica tion.  He has developed and demonstrated over Gbps channel coding and over 430 Mbps band-width efficient modul ation subsystems utilizing ASICs designed by the CAMBR U Idaho. Most recently he has completed a 320 Mbps reconfigurable data compression test bed for testing the DWT and BPE ASICs   


memory module, creating a bottle-neck in the memory accesses Besides, both OpenMP and SMPSs require scheduling schemes that although conscious of the locality \(and this is somehow a quite static feature adapt to other sources of imbalance in the systems. More specific for SMPSs, increasing the threshold of number of tasks in the graph would enable to better exploit the temporal locality that appears in computations far away in the original source code Acknowledgments The authors acknowledge the financial support of the Comision Interministerial de Ciencia y Tecnologa \(CICYT Contract TIN2007-60625 research agreement References 1] cOMPunity. The community of OpenMP users researchers, tool developers and provider website http://www.compunity.org/, 2006 2] E. Ayguade  N. Copty, A. Duran, J. Hoeflinger, Y. Lin, and G. Zhang. A proposal for task parallelism in OpenMP. In Proceedings of the 3rd International Workshop on OpenMP June 2006 3] J.M. Perez, R.M. Badia, and J.Labarta. A dependencyaware task-based programming environment for multi-core architectures. In Proceedings of IEEE Cluster Computing 2008, 2008 4] E. Ayguade  A. Duran, J. Hoeflinger, F. Massaioli, and X. Teruel. An experimental evaluation of the new openmp tasking model. In Proceedings of the 20th International Workshop on Languages and Compilers for Parallel Computing 2007 5] J. M. Perez, P. Bellens, R. M. Badia, and J. Labarta. CellSs Programming the Cell/B.E. made easier. IBM Journal of Research and Development, 51\(5 6] M. Frigo, C. E. Leiserson, and K. H. Randall. The implementation of the cilk-5 multithreaded language. SIGPLAN Notices, 33\(5  223, 1998 7] M. Gonzalez, E. Ayguade  X. Martorell, and J. Labarta Exploiting pipelined executions in OpenMP. In Proceedings of the 32nd Annual International Conference on Parallel Processing, pages 153  160, Oct 2003 8] A. Duran, J.M. Perez, E. Ayguade, R.M. Badia, and J. Labarta. Extending the OpenMP tasking model to allow dependent tasks. In Proceedings of the 4th International Workshop on OpenMP, 2008 9] G. Juckeland, M.S. Muller, W.E. Nagel, and S Pflu. Accessing data on sgi altix: An experience with reality. In Proceedings of WMPI 2006, 2006 10] A. Kayi, E. Kornkven, T. El-Ghazawi, and G. Newby. Application performance tuning for clusters with ccnuma nodes In Computational Science and Engineering, 2008. CSE  08 11th IEEE International Conference on, pages 245  252, July 2008 11] R. Ferrer, M. Gonza  lez, F. Silla, X. Martorell, and E. Ayguade  Evaluation of memory performance on the cell be with the sarc programming model. In Proceedings of MEDEA workshop \(PACT 12] HPCS. The hpc challenge benchmark http://icl.cs.utk.edu/hpcc/index.html 13] Jesu  s Labarta, Sergi Girona, Vincent Pillet, Toni Cortes and Luis Gregoris. DiP: A parallel program development environment. In Proceedings of the 2nd International EuroPar Conference \(EuroPar 96 445 pre></body></html 


in preferences for a category of items. The selection of segment is done by selecting highly rated popular items with similar characteristics. Segmented attack is focused on those users who have highly rated majority of the selected items present in the segment For example, group of users who have highly rated at least any three of the five most popular animation movies form a segment of users interested in animation movies. An attacker with intent to promote a new animation movie will find it beneficial to mount a segmented attack against a segment of user interested in animation movies In our work, we study the effect of our filler item strategies in further improving the effectiveness of insegment attacks against both user-based and itembased attacks. In segment attack, filler items are randomly selected and assigned the minimum value in the rating scale. The reasoning behind assignment of minimum value to the filler item has not been explained in detail in any of the literature on segmented attack.  We provide below details of our filler item strategies for segment attack  7.1 Strategy SUL  This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TL category. In our approach to improve effectiveness of the attack, we need to create malicious users that are similar to those genuine users who have rated the target item with a lower value and also belong to the segment of users targeted by the segmented attack. So, to improve similarity, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a lower scale. For example for an attack against a segment of users interested in animation movies i.e., those users who have rated highly at least any three of the five most popular movies in animation genre, a filler item is assigned the average rating given to it by those users who have rated the target item at a lower rating and have rated highly at least one of the five animation movies that define the segment  7.2 Strategy SUH This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TH category. To improve effectiveness of a segment attack, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a higher scale  7.3 Strategy SIL  This strategy is followed when a segment attack is mounted against an item-based CF system and the target item falls in TL category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a lower scale. The strategy used is similar to Strategy IL Filler items are selected the way explained in section 6.1  7.4 Strategy SIH  This strategy is followed when a segment attack is mounted against an item-based CF system and the 


target item falls in TH category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a higher Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 scale. The strategy used is similar to Strategy IH Filler items are selected the way explained in section 6.2  8. Experimental evaluation and discussion  We performed the experimental evaluation of our strategies on the publicly available MovieLens data set [8]. This is the most widely used dataset in recommender systems research. MovieLens consists of 100,000 ratings made by 943 users on 1682 movies. Each user in the data set has rated at least 20 movies and each movie has been rated at least once A timestamp value is associated with each user movie, and rating combination. The data set also contains information on the demographic detail \(age sex, occupation, and zip code information \(genre and release date The ratings are made in a scale of 1 to 5, where 5 indicate extreme likeness for an item and 1 dislike We evaluated effectiveness of the proposed strategies on user-based and item-based collaborative algorithm. For similarity calculation and prediction in user-based CF algorithm, equations 1 and 2 stated in section 3 were used. Similarly, equations 3 and 4 stated in section 3 were used for computing similarity and prediction value for item-based CF algorithm We used a neighborhood size of k = 20 for prediction calculation. Case amplification value of 10 was used while calculating correlation and only positive correlations values were considered for computing predictions To conduct our evaluation, we selected a sample 20 items. Out of the 20 items, 10 items belonged to TL  category while remaining 10 items to TH category All the 20 items were selected randomly from a larger set of items belonging to each category. We also randomly selected a sample of 50 target users Target users selected were those who have never rated any of the 20 test items. Each of the target items was attacked individually and the prediction shift was calculated by averaging the prediction shift observed for each user. The final prediction shift for the attack is the average prediction over all items used in the test. Equation 6 was used to calculate the metric For implementation of segmented attack we followed the same guidelines as stated in [3]. Horror segment was selected as the target segment. Five of the most popular horror movies were selected to represent the segment. These five movies selected formed the selected item set in the attack profiles constructed. The five movies are Alien, Psycho, The Shining, Jaws, and The Birds. Users who have given a rating of 4 or 5 to at least any 3 of the five movies were identified as the target segment against which the attack was focused. For calculating prediction shift we selected 50 of the users from this target segment to form the test user set. While implementing the segment attack, selected items were given a rating of 5 and the randomly selected filler items were assigned a value 1 All experiments were conducted for ?Size of attack? values 1%, 3%, 6%, 12%, and 15%.  ?Size of attack? represents number of attack profiles added as a percentage of pre-attack profiles. 1% ?Size of attack? implies 10 attack profiles were added to a 


attack? implies 10 attack profiles were added to a system of 1000 genuine users. On the basis of the results reported in [4] that best results are reported when a filler size of 3% is used in an average attack we used a filler size of 3% for all our tests i.e., 3 % of 1682 items which is approximately 50 filler items For attacks against user-based collaborative filtering systems we used six strategies: Strategy UL, Strategy UH, Strategy SUL, Strategy SUH, segment attack and average attack. Similarly, for attacks against item based collaborative filtering systems we used six strategies: Strategy IL, Strategy IH Strategy SIL Strategy SIH, segment attack and average attack. For average attack, filler item strategy used was the same as in an average attack i.e., the mean of the filler item was assigned to it. Segment attack was implemented as explained earlier. Category TL, Category TH Strategy UL, Strategy UH, Strategy IL, Strategy IH Strategy SUL, Strategy SUH, Strategy SIL and Strategy SIH were implemented the way explained earlier in section 4, section 5, section 6 and section 7 respectively. For attacks against item-based CF while selecting filler items from set IF, only items with minimum frequency count of 10 were considered Figure 2 and Figure 3 show the effectiveness of our attacks when calculated for all users against systems using user-based collaborative filtering for recommendations.  Figure 2 shows the prediction shift values of attacks Strategy UL and average attack for items belonging to TL category. From the graph it?s obvious that for items in TL category, Strategy UL outperforms average attack model for all values of attack size. Similarly, Figure 3 shows the prediction shift values for the attack strategies Strategy UH and average attack for items belonging to TH category From the graph it can be concluded that for items belonging to TH category, Strategy UH performs much better than average attack over lower values of attack size. At attack size of 12 % and 15% both attack have similar effectiveness Figure 4 and Figure 5 show the effectiveness of our attacks when calculated for all users against systems using item-based collaborative filtering for recommendations.  Figure 4 shows the prediction shift values of Strategy IL and average attack for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 items belonging to TL category. Similarly, Figure 5 shows the prediction shift values for the Strategy IH and average attack for items belonging to TH category. From Figure 4 and 5 it can be concluded that both Strategy IL and Strategy IH perform substantially better than average attack over all values of attack size. It can also be observed that our attack strategies are more effective against itembased systems than user-based systems Figure 6, 7, 8, and 9 show the effectiveness of our filler based attack strategies for in-segment users. We observe that for attacks against both user-based and item-based CF systems the effectiveness of our filler based strategies is comparable to the best available attack model for in-segment attacks i.e., segment attack. However, in Figure 8 we observe that filler item strategy SIL performs better than segment attack. Because of the low knowledge cost involved in segment attack, we can conclude that for most scenarios segment attack is a better attack model for in-segment attacks than filler based attack models Experimental results clearly show that our approach of selecting a strategy based on target item rating distribution outperforms the best available attack model i.e., average model. One drawback of 


attack model i.e., average model. One drawback of our attack strategies is its high knowledge cost However, automated software agents can help diminish the cost. One approach that can be used to decrease the cost is to use a subset of users while selecting filler items. For example, in attacks against item-based systems, while implementing Strategy IH instead of selecting all users who have rated target item as 4 or 5 as members of the set UH. , we only select 20 users. Selection of items for set IF will then be performed using the data of the 20 users in set UH Similarly, in case of attacks against user-based systems, while implementing Strategy UH instead of assigning a filler item IF the average rating given to it by the set of users UH. , we assign IF the average rating given to it by a subset of 5 randomly selected users from UH. In future work we plan to experimentally verify the effectiveness of these cost reduction approaches    Figure 2:   Attack on TL category of items against user-based collaborative filtering system   Figure 3:   Attack on TH   category of items against user-based collaborative filtering system   Figure 4:   Attack on TL category of items against item-based collaborative filtering system  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8  Figure 5:   Attack on TH category of items against item-based collaborative filtering system   Figure 6:   Attack on TL category of items against user-based collaborative filtering system   Figure 7:   Attack on TH   category of items against user-based collaborative filtering system    Figure 8:   Attack on TL category of items against item-based collaborative filtering system   Figure 9:   Attack on TH category of items against item-based collaborative filtering system  9. Conclusion  This paper provides an effective approach towards constructing attack models. We show the importance of target item and filler items in construction of successful attack strategies. Through experiments we show that our approach of intelligent selection of filler items based on target item rating distribution results in substantial improvement over the baseline average attack. We also compare our approach with the well known in-segment approach and conclude that our approach gives slightly improved results. In future, we plan to examine the filler items strategies for other attack models, and also create algorithms to improve robustness and stability of recommender systems against shilling attacks 


systems against shilling attacks  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9  10. References  1] Lam, S., and Riedl, J. 2004. Shilling Recommender Systems for Fun and Profit, In Proceedings of the 13th International WWW Conference 2] Mehta, B., Hofmann, T., and Nejdl, W. 2007. Robust Collaborative Filtering, In Proceedings of the 2007 ACM Conference on Recommender Systems, 49-56 3] Mobasher, B., Burke, R., Bhaumik, R., and Williams C. 2007. Towards Trustworthy Recommender Systems: An Analysis of Attack Models and Algorithm Robustness, ACM Transactions on Internet Technology, 7\(2007 4] Burke, R., Mobasher, B., and Bhaumik, R. 2005 Limited Knowledge Shilling Attacks in Collaborative Filtering Systems, In Proceedings of Workshop on Intelligent Techniques for Web Personalization 5] Konstan, J., Miller, B., Maltz, D., Herlocker, J Gordon, L., and Riedl, J. 1997.  GroupLens: Applying Collaborative Filtering to Usenet News Communications of the ACM, 40, 3\(1997 6] Herlocker, J., Konstan, J., Borchers, A., and Riedl J.1999. An Algorithm Framework for Performing Collaborative Filtering, In Proceedings of  SIGIR ACM, 77-87 7] Sarwar, B., Karypis, G., Konstan, J., and Riedl, J 2001. Item-based Collaborative Filtering of Recommendation Algorithms. In Proceedings of the 10th International WWW Conference 8] MovieLens data set,www.grouplens.org  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


 Current Time \(min  Healthy Failure Expected Just-in-time line Actual Remaining Life  Figure 17. Results of failure prognosis 0 100 200 300 400 500 600 700 800 900 1000 0 0.02 0.04 0.06 0.08 0.1 0.12 Time \(min Sp al l S iz e  m m 2 Interpolation of spall growth according to feature values 0 100 200 300 400 500 600 700 800 900 1000 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Time \(min Fe a tu re V a lu e    Interpolation of feature value with noise Interpolation of feature vlaue snapshot with ground truth data 11 CONCLUSIONS This paper shows that enhancements to diagnostic techniques are desirable as well as attainable additions to Health and Usage Monitoring Systems \(HUMS particularly in the case of rotorcraft component monitoring Enhancements like those presented support CBM efforts primarily in two ways: reduce the sensitivity of diagnostic processes to both signal noise and variations in environmental and operating conditions, and improve the performance of detection systems as well as the task of fault identification \(e.g., severity quantification instantiation of reliable prognostics Representative examples, motivated by the interest of the U.S. Army in transitioning from time-based \(using TBO definitions drive train bearing, illustrates the potential benefits of 


pursuing an integrated approach to diagnostics and prognostics, combining technologies for enhanced data preprocessing, advanced diagnostic-support algorithms, fusion at the sensor/feature levels, and an adequate framework for false alarm mitigation and uncertainty management. An architecture for achieving such integration is presented, with emphasis on supporting a robust performance of diagnostics operations, even in the presence of such kinds of disturbances as those observed in data acquired by HUMS vibration sensors. The present study also gives relevance to seeded fault because the technologies discussed can integrate knowledge about damage mechanism interactions or physics-of-failure models, as well as make use of multiple-sensor and multiple-feature data sets representative of known fault conditions For this reason, the team behind this project is evaluating a potential opportunity to perform a series of tests on rotorcraft drive train bearings with varying fault severities and under multiple, though realistic, operating conditions Such tests are being planned to provide algorithm/model validations, as well as diagnostic/prognostic performance assessments, in support of providing the U.S. Army with technologies that make detection systems more robust allow for the implementation of prognostics, and extend the useful life of drive train components. Component degradation testing thus remains as future, follow-up work to the research reported in this document ACKNOWLEDGMENTS This work has been partially supported with a cooperative agreement by the Army Research Laboratory under contract number W911NF-07-2-0075. In addition to the primary authors, we would like to thank government and contractor representatives from organizations supporting the Army Utility \(Blackhawk Estes, Mr. Carlos Rivera, and Dr. Jon Keller. This work has also benefitted greatly from consultations with other Army Research Laboratory and NASA Glenn researchers such as Dr. Timothy Krantz, Dr. David Lewicki, Dr. Harry Decker Dr. Hiralal Khatri, Mr. Ken Ranney and Mr. Kwok Tom REFERENCES 1] Branhof, R.W., Grabill, P., Grant, L., and Keller, J.A  Application of Automated Rotor Smoothing Using Continuous Vibration Measurements  American Helicopter Society 61st annual forum, Grapevine, Texas June 1  3, 2005 2] Dora, R., Wright, J., Hess, R., and Boydstun, B  Utility of the IMD HUMS in an Operational Setting on the UH60L Blackhawk  American Helicopter Society 60th annual forum, Baltimore, Maryland, May 7  10, 2004 3] Zakrajsek, J.J., Dempsey, P.J., et al  Rotorcraft Health Management Issues and Challenges  NASA report TM  2006-214022. February, 2006 4] Suggs, D.T., and Wade, D.R  Vibration Based Maintenance Credits for the UH-60 Oil Cooler Fan Assembly  American Helicopter Society, CBM Specialists Meeting, Huntsville, Alabama, February 13 2008 5] Baker, C., Marble, S., Morton, B.P., and Smith, B.J  Failure Modes and Prognostic Techniques for H-60 Tail Rotor Drive System Bearings  IEEEAC paper #1122 IEEE, 2007 6] Keller, J.A., Branhof, R., Dunaway, D., and Grabill, P  Examples of Condition Based Maintenance with the Vibration Management Enhancement Program   American Helicopter Society 61st Annual Forum Grapevine, Texas, June 1  3, 2005 7] Zhang, B., Sconyers, C., Byington, C.S., Patrick, R Orchard, M.E., and Vachtsevanos, G.J  Anomaly Detection: A Robust Approach to Detection of 


Detection: A Robust Approach to Detection of Unanticipated Faults  International Conference on Prognostics and Health Management, Denver, Colorado October 6-9, 2008 8] Byington, C.S., Watson, M., Lee, H., and Hollins, M  Sensor-level Fusion to Enhance Health and Usage Monitoring Systems  American Helicopter Society, 64th Annual Forum, Montreal, Canada, April 29-May 1, 2008 9] Engel, S.J., Gilmartin, B.J., Bongort, K., and Hess, A  Prognostics, the Real Issues Involved With Predicting Life Remaining  Proceedings of the IEEE Aerospace Conference, Big Sky, Montana, March 18-25, 2000 12 BIOGRAPHY Romano Patrick is a Project Manager at Impact Technologies. He received a Ph.D. in Electrical Engineering from the Georgia Institute of Technology specializing in model-based machine health diagnostics and prognostics. He also holds an MBA from Georgia Tech and degrees from U Texas, Arlington and U. Panamericana, Mexico. With career focus on interdisciplinary integration of technologies, his recent work involves practicable diagnostics/prognostics design for complex systems, such as rotorcraft drive trains Past experience includes automation and design for a variety of industrial and government sponsors \(DARPA, Lockheed Martin, Northrop Grumman, etc and program coordination at U. Panamericana, and some entrepreneurial R&amp;D Matthew J. Smith is a Senior Project Engineer at Impact Technologies. During his tenure with Impact, Matthew has performed multiple efforts pertaining to bearing vibration analysis, diagnostic and prognostic system development, and experimental study of faulted system reponse and fault progression. Previously, as a research assistant at Penn State and the NASA Glenn Research Center, Matthew performed experimental and analytical oil-free bearing analyses Matthew received his B.S. and M.S. degrees in Mechanical Engineering from The Pennsylvania State University. His research interests include: prognostic health assessment for bearing and actuator systems, grease degradation modeling and fault classifier development Bin Zhang received his Ph.D. degree from Nanyang Technological University, Singapore in 2007. He received his BE and MSE degrees from Nanjing University of Science and Technology, China, in 1993 and 1999, respectively. He is a senior member of IEEE. From 2005 to present, he has been a Post-Doc with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta GA His current research interests are fault diagnosis and failure prognosis, systems and control, digital signal processing learning control, intelligent systems and their applications to robotics, power electronics and various mechanical systems Carl S. Byington is a Professional Engineer and the Director of Systems Engineering at Impact Technologies. He directs R&amp;D in pursuit of advanced, automated systems health management for land-based, shipboard, and airborne machinery for military and commercial customers. He is Chairman of the Machinery Diagnostics &amp; Prognostics Committee of ASME and a member of IEEE, AIAA, SAE and AHS. He has a BS degree in Mechanical Engineering from the University of Pennsylvania and an MS in Aeronautical Engineering from George Washington University, and has published over 60 papers, book chapters, magazine and journal articles related to diagnostics and prognostics technologies George Vachtsevanos is Professor Emeritus at the Georgia Institute of Technology and also serves as the Chief Scientist at Impact Technologies, LLC. He directed the Intelligent Control Systems laboratory at Georgia Tech for the past 28 years where faculty and students are conducting research in fault diagnosis/prognosis and fault-tolerant control of engineering systems, intelligent control of industrial 


engineering systems, intelligent control of industrial processes, neurotechnology and cardiotechnology, and unmanned systems. His research work has been sponsored by government and industry and has published over 250 technical papers in his area of expertise. He is the lead author of a book on "Intelligent Fault Diagnosis and Prognosis of Engineering Systems" published by Wiley in 2006. He is the recipient of the Georgia Tech Interdisciplinary Activities award and the ECE Distinguished Professor award Romeo de la Cruz del Rosario, Jr. is the Chief of the Electronics Technology Branch at the U.S. Army Research Laboratory. He also serves as the Army Technology Objective ATO P&amp;D Operational Readiness and Condition Based Maintenance He received the B.E.E. degree from the Catholic University of America, Washington, D.C., and the M.S.E. and Ph.D degrees in Electrical and Computer Engineering from the Johns Hopkins University, Baltimore, MD. Since 1991 he has been an engineer at the Harry Diamond Laboratory then U.S Army Research Laboratory working in several areas including high power microwave technology characterization &amp; modeling of heterostructure RF devices and fabrication and failure analysis of electron devices and circuits  pre></body></html 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






An Integrated UAV Navigation System Based on Aerial Image Matching  Gianpaolo Conte and Patrick Doherty Department of Computer and Information Science Arti\002cial Intelligence and Integrated Computer System Division Link 250 oping University Link 250 oping SWEDEN giaco@ida.liu.se Abstract\227 The aim of this paper is to explore the possibility of using geo-referenced satellite or aerial images to augment an Unmanned Aerial Vehicle 050UAV\051 navigation system in case of GPS failure A vision based navigation system which combines inertial sensors visual odometer and registration of a UAV on-board video to a given geo-referenced aerial image has been developed and tested on real 003ight-test data The experimental results show that it is possible to extract useful 
position information from aerial imagery even when the UAV is 003ying at low altitude It is shown that such information can be used in an automated way to compensate the drift of the UAV state estimation which occurs when only inertial sensors and visual odometer are used T ABLE OF C ONTENTS 1 I NTRODUCTION                                    1 2 R ELATED WORK                                   3 3 S YSTEM DESCRIPTION 
                            3 4 V ISUAL ODOMETER                                4 5 I MAGE REGISTRATION                             5 6 UAV PLATFORM                                   6 7 E XPERIMENTAL RESULTS                         
7 8 C ONCLUSIONS AND FUTURE WORK               8 A CKNOWLEDGEMENTS                            8 R EFERENCES                                      8 B IOGRAPHY                                        10 1 I 
NTRODUCTION The work presented in this paper is done in the context of a larger research project on autonomous UAVs carried out at the Department of Computer and Information Science at Link 250 oping University.The primary goal of such a project is in the development of an integrated hardware/software UAV platform for fully autonomous missions in an urban environment One of the main concerns which prevents the use of UAV systems in populated areas is the safety issue State of the art UAV systems are still not able to guarantee an acceptable  1-4244-1488-1/08 25  00 c 015 2008 IEEE IEEEAC Paper 1276 Version I Updated 23/10/2007 
level of safety to convince aviation authorities to authorize the use of such a system in populated areas 050except in rare cases such as war zones\051 There are several problems which have to be solved before unmanned aircrafts can be introduced in the civilian airspace One of them is GPS integrity A standard UAV navigation system often relies on GPS and inertial sensors 050INS\051 If the GPS signal for some reason becomes unavailable or corrupted the state estimation solution provided by the INS alone drifts in time and will be unusable after a few seconds 050especially for small-size UAVs which use low-cost INS\051 The GPS signal also becomes unreliable when operating close to obstacles due to multi-path re\003ections In addition it is quite vulnerable to jamming 050especially for a GPS operating on civilian frequencies\051 A GPS jammer can be 
found on the market quite easily and instructions on how to build such device can be found on the Internet Therefore UAVs which rely blindly on a GPS signal are quite vulnerable to malicious actions For this reason a navigation system for autonomous UAVs must be able to cope with short and long term GPS fallouts The research community is making a great effort to solve this problem in different ways One potential solution is based on enhancing a UAV navigation system using a suitable vision system A video camera is an appealing sensor which can be used to solve navigation related problems Almost every UAV already has a video camera as a standard sensor in its payload package Compared to other sensors e.g laser video cameras are quite light and less power hungry A color image contains a huge amount of information which could be 
used for several purposes On the other hand passive video cameras are quite sensitive to environmental light conditions Abrupt illumination changes in the environment 050for example sun re\003ections\051 represent a great challenge for a vision system which is supposed to provide position information robustly Visual navigation for UAVs has been a topic of great interest in our research group Great effort has been put into the development of a vision-based autonomous landing functionality In a vision-based landing system which uses an arti\002cial landing pattern is described The system is capable of landing an unmanned helicopter autonomously without using the 1 


Figure 1  The Rmax helicopter GPS position information The problem addressed in this paper is concerned with the capability of an UAV to be able to navigate to home base in case the GPS signal is lost 050\224homing\224 problem\051 An experimental autonomous UAV platform based on the commercial Yamaha RMAX helicopter 050Figure 1\051 is used as a test-bed for the development and testing of a navigation architecture which can cope with GPS failures The navigation system proposed replaces the GPS signal combining together a visual odometer and an algorithm which registers the on-board video to a geo-referenced satellite or aerial images Such images must be available on-board the UAV beforehand The growing availability of high resolution satellite images 050for example provided by Google Earth\051 makes this topic very interesting In the near future access to high resolution images for many areas of the world will not represent a problem any longer The navigation architecture proposed to solve this problem fuses information obtained from an INS composed of three gyros and three accelerometers a monocular video camera and a barometric pressure sensor Sensor information is fused using a Kalman 002lter to estimate the full UAV state 050position velocity and attitude\051 Two image processing techniques feature tracking and image registration are used to update the navigation 002lter during the time the GPS is unavailable A KLT feature tracker implementation is used to track cor ner features in the on-board video image from subsequent frames An odometer function uses the KLT results to calculate the distance traveled by the UAV Since the distance calculated by the odometer is affected by drift a mechanism which compensates for the drift error is still needed For this purpose a geo-referenced image registration module is used When the image registration is performed correctly it is possible to calculate the absolute position of the UAV which is drift-free In other words the position information obtained is similar to the one provided by the GPS Due to the fact that registering the on-board image to an inFigure 2  Vision-aided sensor fusion architecture correct location may introduce an even larger position error the fundamental problem to be solved is the detection of correct and incorrect image registrations The contribution of this paper is in the development of a method showing how to detect incorrect image registration At this point one could think of using only the drift-free position calculated through image registration to update the navigation 002lter without the need for the odometer The problem is that the success rate of the image registration process is very much related to the kind of terrain the UAV is 003ying over Terrains with 224robust\224 features like road intersections are easier to match while unstructured terrain such as rural areas are dif\002cult to match The visual odometer used here works reasonably well also in unstructured environments For this reason the combination of the two techniques gives robustness to the approach The vision-aided sensor fusion architecture proposed is displayed in Figure 2 It can be noticed how the GPS position signal when it is not available is replaced with the position information provided by the vision system In particular the position calculated using the visual odometer and image registration are fused together and the resulting position is used to update the Kalman 002lter The architecture proposed in Figure 2 has been tested on real 003ight-test data and on-board video The GPS track of the 003ight path shown in Figure 3 is used to validate the results of the non-GPS navigation approach presented in this work During this 003ight inertial data barometric altitude and onboard video were acquired Such data are used in this work to demonstrate the possibility without using the GPS to 003y the closed loop path of Figure 3 without accumulating drift error at the end of the path The total path length is about 1 kilometer 2 


Figure 3  GPS track of the UAV 003ight path used for the experiment 2 R ELATED WORK Many research groups are dealing with non-GPS navigation problems One technique which could be applied to this kind of problems is the so called Simultaneous Localization and Mapping 050SLAM\051 The goal of SLAM is to localize a robot in the environment while mapping it at the same time Prior knowledge of the environment is not required Although SLAM is becoming a standard technique for indoor robotic applications it still represents a challenge when applied to large outdoor environments A rich literature is available on this topic 4 5 6 Some e xamples of SLAM applied to aerial vehicles can be found in 8 Compared to the navigation approach used in this paper the SLAM technique has the advantage of not requiring any a priori maps of the environment On the other hand the SLAM approach makes sense when robots have to close loops in other words the robot has to come back to previously visited landmarks in order to decrease the position uncertainty This could be a potential limiting factor for UAV applications If a UAV has lost its GPS signal probably the best navigation strategy is the one which minimizes the risk of crashing in populated areas It is possible that 003ying back home using previously visited sites is not the safest strategy while 003ying different routes might be more preferable For this reason we think that a navigation functionality based on aerial image matching has great potential for this application and gives more 003exibility as regards choosing emergency 003ight routes in case of GPS failure An application similar to the one described in this paper which uses aerial image matching for aircraft position estimation can be found in Here the authors try to estimate an aircraft position through matching a sequence of onboard images to a geo-referenced image The on-board images are taken from a downward looking camera mounted on a manned aircraft A matching method which uses the Hausdorff distance is investigated There also exists other kinds of terrain navigation methods which are not based on aerial images but on terrain elevation models In this case a measurement of the 003ight altitude relative to the ground is required Matching the ground elevation pro\002le measured with a radar altimeter for example to an elevation database allows for aircraft localization An application of this method can be found in The localization system has been implemented successfully on some military jet 002ghters In the case of UAVs and more speci\002cally for unmanned helicopters this method does not appear to be appropriate Compared to jet 002ghters UAV helicopters 003y short distances at very low speed so the altitude variation for such 003ying platforms is quite poor in terms of allowing ground pro\002le matching 3 S YSTEM DESCRIPTION The vision-aided sensor fusion architecture tested in this work is composed of several modules 050see Figure 2\051 A traditional Kalman 002lter is used to fuse an INS sensor 0503 accelerometers and 3 gyros\051 with a position sensor 050vision system in this case\051 An INS mechanization function performs the time integration of the inertial sensors while the Kalman 002lter function estimates the INS errors The errors estimated by the Kalman 002lter are then used to correct the INS solution The Kalman 002lter implemented uses 12 states 3 dimensional position error 3 dimensional velocity error 3 attitude angle error 050pitch roll heading\051 and 3 accelerometer biases The Kalman 002lter uses the position update from the vision system to estimate such errors As mentioned before the vision system combines two techniques to calculate the position of the UAV visual odometer and image registration The next two sections describe an implementation of the two methods in details Both odometer and image registration calculate the UAV position The odometer delivers 4Hz position update The position update calculated from the image registration algorithm occurs only when a reliable matching is found The method developed to discriminate between reliable and unreliable matching is described in section 5 When a reliable position update from the image registration module is not available the output from the visual odometer is directly taken to update the 002lter When a reliable image registration is obtained usually it produces a position jump when compared to the position calculated from the odometer Such position discontinuity can be large especially when the time elapsed between two valid registrations is large For this reason the Kalman 002lter cannot be updated directly with the position calculated from the image registration module the risk would be the generation of instabilities The registration update is then introduced gradually over time and it is treated as a correction added to the odometer solution 3 


4 V ISUAL ODOMETER The visual odometer developed in this work is based on the KLT feature tracker The KLT algorithm tracks point features from two subsequent frames The algorithm selects a number of features in an image according to a 224goodness\224 criteria described in Then it tries to re-associate the same features in the next image frame The association is done by a minimization of a sum of squared differences criteria over patches taken around the features in the 002rst image This association criteria gives very good results when the feature displacement is not too large Therefore it is important that the algorithm has a low execution time The faster the algorithm is the more successful is the association process The KLT algorithm is very ef\002cient and can run at 20-30Hz In this application 50 features in the image are tracked Once the features are detected in the image frame they are projected onto the real world using Equation 1 P n  R n c 2 4 x=f x y=f y 1 3 5 d 0501\051 where R n c is the transformation matrix between the camera frame 050 c 051 and the helicopter navigation frame 050 n 051 x and y represent the pixel position of the feature being tracked in the image plane f x and f y are the focal lengths of the camera in the x and y directions d is the feature depth The navigation frame is a local geodetic frame which has its origin coinciding with that of the INS sensor with the X n axis pointing toward the geodetic north the Z n axis orthogonal to the reference geodetic ellipsoid pointing down and the Y n axis completing a right-handed orthogonal frame The transformation matrix R n c is composed by a sequence of rotations which take into account the camera orientation relative to the UAV body and the UAV attitudes 050the UAV attitude angles are taken from the Kalman 002lter as it is shown in Figure 2\051 Details on the de\002nition of the different reference frames and coordinate transformation from the camera to the navigation frame can be found in Since the camera in the experiment presented here is looking perpendicular downward the feature depth d is assumed to be equal to the UAV altitude relative to the ground The depth is then calculated using a barometric pressure sensor 050the atmospheric pressure at the ground level is taken before take-off then the differential pressure during 003ight can be converted into ground altitude\051 This way of calculating the ground altitude works if the ground is essentially 003at The 003atness assumption can be removed by a direct measurement of the ground altitude For this purpose our group is investigating the possibility of using a radar or laser altimeter on-board the UAV There are also other methods to estimate the ground altitude One way is to use passive vision 050downward lookFigure 4  Visual odometer between two consecutive UAV positions ing camera\051 Several works have shown that this is possible achieving good accuracy 14 Figure 4 represents the UAV observing the same feature 050which will be addressed with the j index\051 from two different locations The UAV displacement 001 P e relative to an Earth\002xed reference frame 050 e 051 and calculated using the feature j  is given by Equation 2 001 P e j  P n j 2 000 P n j 1  R n c 2 2 4 x j 2 f x y j 2 f y 1 3 5 d 2 000 R n c 1 2 4 x j 1 f x y j 1 f y 1 3 5 d 1 0502\051 The Earth-\002xed reference frame 050 e 051 has the same orientation of the navigation frame 050 n 051 but it is 002xed relative to the Earth The UAV displacement between two subsequent frames is calculated by averaging the displacement of all the features tracked in the image The resulting averaged displacement is then 001 P e avg  1  nf eat nf eat X j 1 001 P e j 0503\051 where nf eat is the number of features tracked In the experiment described in this paper 50 features were tracked in each frame Finally the position at a certain time t calculated by the odometer function is 4 


P 050 t 051  P 050 t 0 051  X t 001 P e avg 050 t 051 0504\051 where P 050 t 0 051 is the position at time t 0 when the last useful GPS reading was available As is shown in Figure 2 the position calculated from the odometer is used to update the navigation 002lter Experimental results show that the visual odometer alone combined with the INS gives drift-free velocity and attitude estimation 050it would not be possible using only the INS\051 This means that once the GPS is lost the UAV can still be controlled using proper attitude and velocity information This result is obtained without image registration i.e without using any given information of the environment The position uncertainty grows though The next section describes the technique used to solve this problem 5 I MAGE REGISTRATION The image registration technique developed here is based on edge matching A Sobel edge detector is applied to both the geo-referenced image and the image taken from the on-board video camera The choice of using edge features derives from the fact that edges are quite robust to environmental illumination changes The geo-referenced and the video camera image are generally taken at different times it can be months or years it has to be expected that the illumination conditions will differ Therefore it is necessary to choose features which are robust to illumination changes Another important factor to be considered is the altitude of the UAV from the ground The higher the UAV 003ies the more structure from the environment can be captured The consequence of this is that image registration is more reliable at higher altitude Another challenge lies in the fact that the environment changes over time It can be that a reference image is obsolete after some time due to the change in the environment Considering that small details change quite fast 050e.g car moving on the road\051 while large structures tend to be more static 050e.g roads buildings...\051 003ying at higher altitude makes the registration more robust to small dynamic changes in the environment The image registration process is represented in the block diagram in Figure 5 After the on-board color image is converted into gray scale a median 002lter is applied The 002lter is applied in order to remove small details which are visible from the onboard camera but not visible from the reference image The median 002lter has the well-suited property of removing small details while preserving the edges sharp After 002ltering the Sobel edge detector is applied The image is then scaled and aligned to the reference image Scaling is performed converting the on-board image to the resolution of the reference image The scale factor s is calculated using Equation 5 and it is different in x and y direction of the image plane since the Figure 5  Image registration schematic on-board images used do not have squared pixels 022 s x s y 023  040 1  f x 1  f y  d 017 I res 0505\051 d  as for the odometer is the ground altitude given by the pressure sensor and I res is the resolution of the reference image The alignment of the on-board image with the reference image is done using the heading information estimated by the 002lter The reference image is processed as follows It is converted into gray scale and the Sobel edge detector is applied This is done only at the beginning the resulting edge image is then kept in memory and used during the visual navigation The UAV position predicted by the Kalman 002lter 050Figure 2\051 is used as the center of a restricted search area in the reference image The purpose is to disregard areas of the image too far from the estimated UAV position Since the position uncertainty grows when there is no update from the registration process also the search area should grow in the same way This is not implemented yet in the system the experimental results which will be presented later are obtained using a 002xed size uncertainty window After both images have been processed as explained above a matching algorithm tries to 002nd the position in the cropped reference image which gives the best match with the video camera image The position that results the greatest number of overlapping pixels between the edges of the two images is taken as matching result The matching criteria used although quite simple give a reasonable success rate Moreover it can be used for on-line applications The registration algorithm described runs at around 1Hz on a normal laptop computer A screen shot which shows how the two images 5 


Figure 6  Processing and matching of the geo-referenced image and of the on-board image are processed and then matched is shown in Figure 6 Once the matching is obtained the on-board image can be geo-referenced and the absolute position of the UAV can be calculated The most dif\002cult part is to decide whether to take the position as a good match or not In other words it has to be detected whether the matching is an outlier and then rejected or can be used to update the 002lter The outlier detection is not an easy matter since there are areas where the outliers are predominant compared to the good matches One idea would be to segment the reference image and assign different matching probability values for different areas Prior knowledge can be applied in this process For example it is known that image registration in urban areas is more reliable than in rural areas or that road intersections result in more stable matching than road segments By doing this a different degree of uncertainty can be assigned to the matching based on the location where the match has occurred The uncertainty can then be used to update the navigation 002lter This method would require a huge amount of off-line image preprocessing which should be applied to the reference image before it could be used and would be unpractical for large images The outliers detection method applied here does not require any image preprocessing It is based on the observation that in areas where the matching is unreliable the matched position is very noisy While in areas where the matching is reliable the position noise decreases The rejection criteria applied is based on the analysis of the position difference between the predicted position coming from the 002lter and the position given by the matching algorithm This difference when the algorithm is matching the right location is usually quite constant with a low noise level The outlier rejection method implemented is based on the standard deviation analysis of such a difference The standard deviation is calculated over a sliding time window of a 002xed size The algorithm analyzes the position difference of for example the last 30 matching results and if the standard deviation is below a cerFigure 7  Detection of a good match tain threshold the averaged position in such time window is taken as good match If the standard deviation is above the threshold the matched position is rejected Figure 7 shows how this method has the potential for detecting good matches In the upper part of Figure 7 there is a picture of an area where a good match was detected 050big picture\051 and a picture of an on-board camera view 050small picture\051 In the lower part of Figure 7 the time history of the difference between the predicted position and the matched position is depicted The standard deviation of the position difference calculated using a sliding window with the last 30 matches is shown at the bottom of the picture It can be observed that when the match becomes stable the standard deviation drops A good choice of threshold value and size of the sliding window is essential for the success of the method 6 UAV PLATFORM The algorithm proposed has been tested using 003ight-test data collected from an autonomous UAV helicopter The helicopter is based on a commercial Yamaha RMAX UAV helicopter 050Figure 1\051 The total helicopter length is 3.6 m 050including main rotor\051 It is powered by a 21 hp two-stroke engine and it has a maximum take-off weight of 95 kg 6 


The avionic was developed in the Department of Computer and Information Science at Link 250 oping University and has been integrated in the RMAX helicopter The platform developed is capable of fully autonomous 003ight from take-off to landing The sensors used for the navigation algorithm described in this paper consist of an inertial measurement unit 050three accelerometers and three gyros\051 which provides the helicopter's acceleration and angular rate along the three body axes a barometric altitude sensor and a monocular CCD video camera mounted on a pan/tilt unit The avionic system is based on 3 embedded computers The primary 003ight computer is a PC104 PentiumIII 700MHz It implements the low-level control system which includes the control modes 050take-off hovering path following landing etc.\051 sensor data acquisition and the communication with the helicopter platform The second computer also a PC104 PentiumIII 700MHz implements the image processing functionalities and controls the camera pan-tilt unit The third computer is a PC104 Pentium-M 1.4GHz and implements highlevel functionalities such as path-planning task-planning etc Network communication between computers is physically realized with serial line RS232C and Ethernet Ethernet is mainly used for remote login and 002le transfer while serial lines are used for hard real-time networking 7 E XPERIMENTAL RESULTS The 003ight data shown were collected during a 003ight-test campaign in a training area in south of Sweden The resolution of the reference image used for image registration is of 0.5 meters/pixel Sensor data and on-board video were recorded during an autonomous 003ight The helicopter autonomously 003ew a preplanned path using a path following functionality implemented in the software architecture The helicopter 003e w at 60 meters above the ground at a 003ight speed of 3m/s The video camera was looking downwards and 002xed with the helicopter body The video was recorded on-board and synchronized with the sensor data The synchronization is performed by automatically turning on a light diode when the sensor data starts to be recorded The light diode is visible in the camera frame The video is recorded on tape using an on-board video recorder and the synchronization with the sensor data is done manually off-line The video sequence is recorded at 25Hz frame rate For the experiment described here the video frames were sampled at 4Hz The on-board sensor data are recorded at different sample rates Table 1 provides the characteristics of the sensors used in the experiment The results of the navigation algorithm proposed in this paper are compared with the navigation solution given by an onboard INS/GPS Kalman 002lter running on-line The Kalman 002lter fuses the inertial sensors with GPS position data and Table 1  Available characteristics of the sensor used in the navigation algorithm provides the full helicopter state estimate Figure 8 displays the results of the UAV position and velocity obtained from the integration between INS and visual odometer without image registration The position calculated using the odometer is used to update the Kalman 002lter The 002gure shows a comparison between the reference position and velocity given by the on-board INS/GPS system the solution INS/visual odometer described in this paper and the INS alone GPS failure has been simulated and occurs at time t  1660sec It can be observed that the INS solution alone starts to drifts rapidly thus the helicopter cannot be controlled safely after GPS failure The solution given by the INS/odometer stabilizes the velocity in the sense that the velocity drift is removed In addition the position drift is reduced dramatically compared to the INS stand alone solution Plots of the attitude angles are not reported here but the INS/odometer provides drift-free attitude angle estimation INS/odometer integration could be used to survive temporary GPS black-out by controlling UAV attitude and velocity This result is obtained without using prior environment information If the UAV has to cover small distances the solution obtained from the INS/odometer could be enough On the other hand if the distance to cover is large a mechanism to compensate for the position drift is needed The full drift-free solution proposed here using geo-referenced image registration has been tested on 003ight-test data and the results are shown in Figure 9 The helicopter 003ew a closed loop path of around 1 kilometer length GPS failure was simulated after few seconds from the starting point From this point the drift-free vision system using odometer and image registration replaces the GPS in the Kalman 002lter The dashed line represents the 003ight path measured by the GPS while the continuous line represents the solution given by the vision-aided navigation scheme described in this paper and represented in Figure 2 The visual odometer and the image registration module run in parallel As discussed in section 3 when an update from the image registration is available it usually gives a position discontinuity compared to the odometer Introducing a position jump in the Kalman 002lter could cause instability problems In order to avoid this problem the update correction from the image registration is introduced gradually over time Figure 9 7 


Figure 8  Integration of the odometer and INS without using image registration Prior knowledge of the environment has not been used yet shows that after the GPS failure the position begins to drift This means that the image matching has not detected a stable match The choice of the standard deviation threshold was set to 1.4 meters The 002rst stable match detected was approximately at the 002rst road intersection It can be noticed that the helicopter position begins to return on the actual path 003own by the helicopter The second stable match was detected almost at the end of the path The drift correction is introduced in the navigation system and the 002nal position error at the end of the path is around 3 meters Other features during the path were matched correctly but they were not stable enough to be taken as position update This experiment shows that even only few good matches are enough to compensate for the position drift 8 C ONCLUSIONS AND FUTURE WORK The experimental vision-aided navigation system architecture described in this paper has the potential to provide a drift-free navigation solution The results presented are quite encouraging although more tests are needed in order to 002ne tune the method It is essential also to collect data from different kind of terrains in order to exploit the potential of the method In the future experiments a wide angle camera lens will be tested The one used here was of 45 degrees We expect that using a wide angle lens will improve the image registration robustness as a larger part of the environment structure can be captured in the image A radar altimeter will also be integrated in the helicopter in order to provide direct ground altitude measurement In this way the 003at world assumption can be removed Another interesting investigation which will be done in the future is to verify the possibility of using satellite images from Google Earth The interesting part is that they are available and for free Google Earth contains an enormous amount of information and in the future it is not unlikely that they could be used to navigate UAVs A CKNOWLEDGMENTS This work is supported in part by the National Aeronautics Research Program NFFP04-S4202 and the Swedish Foundation for Strategic Research 050SSF\051 Strategic Research Center MOVIII I would also like to acknowledge my colleague Maria Hempel for reading this paper and giving useful comments R EFERENCES   T Merz S Duranti and G Conte 223Autonomous landing of an unmanned aerial helicopter based on vision and inertial sensing,\224 in Proc of the 9th International Symposium on Experimental Robotics  2004   C Tomasi and T Kanade 223Detection and tracking of 8 


Figure 9  Vision-aided navigation experiment using image registration for position drift compensation point features,\224 Carnegie Mellon University Tech Rep CMU-CS-91-132 April 1991   T Bailey and H Durrant-Whyte 223Simultaneous localization and mapping 050SLAM\051 Part II,\224 IEEE Robotics  Automation Magazine  vol 13 no 3 pp 108\226117 Sep 2006   H Durrant-Whyte and T Bailey 223Simultaneous localization and mapping 050SLAM\051 Part I,\224 IEEE Robotics  Automation Magazine  vol 13 no 2 pp 99\226110 Jun 2006   S Thrun W Burgard and D Fox Probabilistic Robotics  ser Intelligent Robotics and Autonomous Agents Cambridge MA USA The MIT Press 2005   A Davison 223Real-Time Simultaneous Localization and Mapping with a Single Camera,\224 in IEEE International Conference on Computer Vision  October 2003 pp 1403\2261410   J Kim and S Sukkarieh 223Real-time implementation of airborne inertial-slam,\224 Robot Auton Syst  vol 55 no 1 pp 62\22671 2007   T Lemaire C Berger I Jung and S Lacroix 223Visionbased slam Stereo and monocular approaches,\224 IJCV  vol 74 no 3 pp 343\226364 September 2007   D G Sim R H Park R C Kim S U Lee and I C Kim 223Integrated position estimation using aerial image sequences,\224 IEEE Trans Pattern Anal Mach Intell  vol 24 no 1 pp 1\22618 2002   N Bergman L Ljung and F Gustafsson 223Pointmass 002lter and cramer-rao bound for terrain-aided navigation,\224 in Proc of the 36th IEEE Conference on Decision and Control  1997   J Shi and C Tomasi 223Good features to track,\224 in IEEE Conference on Computer Vision and Pattern Recognition 050CVPR'94\051  Seattle 1994   D B Barber J D Redding T W McLain R W Beard and C N Taylor 223Vision-based target geo-location using a 002xed-wing miniature air vehicle.\224 Journal of Intelligent and Robotic Systems  vol 47 no 4 pp 361\226382 2006   A Moe 223Passive aircraft altitude estimation using computer vision,\224 Dept EE Link 250 oping University SE581 83 Link 250 oping Sweden Lic Thesis LiU-Tek-Lic2000:43 September 2000 thesis No 847 ISBN 917219-827-3   L Matthies R Szeliski and T Kanade 223Kalman 002lterbased algorithms for estimating depth from image sequences,\224 Robotics Institute Carnegie Mellon Univer9 


sity Pittsburgh PA Tech Rep CMU-RI-TR-88-01 January 1988   G Conte 223Navigation functionalities for an autonomous uav helicopter,\224 Dept of Computer and Information Science Link 250 oping University SE-581 83 Link 250 oping Sweden Lic Thesis LiU-Tek-Lic-2007:16 March 2007 thesis No 1307 ISBN 978-91-85715-350 B IOGRAPHY Gianpaolo Conte is a PhD student at the Department of Computer and Information Science Link 250 oping University Sweden He obtained the Licentiate degree at the same University and the Aerospace Engineering degree at Turin Polytechnic He is interested in navigation and control problem for UAVs He is also working on the development of Micro Aerial Vehicles platforms Patrick Doherty is a Professor at the Department of Computer and Information Science 050IDA\051 Link 250 oping University 050LiU\051 Sweden He is director of the Arti\002cial Intelligence and Integrated Computer Systems Division at IDA and his research interests are in the area of knowledge representation automated planning autonomous systems approximate reasoning and UAV technologies 10 


 11 R EFERENCES     Reddy, M.K. and S.M. Reddy 223Detecting FET Stuck-Open Faults in CMOS Latc hes and Flip-Flops,\224 IEEE Design and Test of Computers Vol. 3 , No. 5 , pp. 17-26, October 1986   2 R Mad g e , M. Vilg is, a nd V. Bhide, "Achieving Ultra High Quality and Reliability in Deep Sub-Micron Technologies using Metal Layer Configurable Platform ASICs", MAPLD 2005    Kewal Sal u ja, \223Di g i t a l Sy st em Fundam e nt al s, Lect ure 11\224, Department of Electrical Engineering, University of Wisconsin Madison    Yu W e i  Papos ng  M oo Ki t Lee Peng W e ng Ng C h i n  Hu Ong, \223IDDQ Test Challenges in Nanotechnologies: A Manufacturing Test Strategy\224, Asian Test Symposium 2007. ATS apos;07. 16 th Volume , Issue , 8-11 Oct. 2007 Page\(s\211 \226 211  NASA GSFC Advi sory NA-GSFC 2004-06   Dan El ft m a nn, Sol o m on W o l d ay and M i nal  Sawant  New Burn In \(BI\ethodology for Testing of Blank and Programmed Actel 0.15 \265m RTAX-S FPGAs MAPLD 2005   M i nal Sawant Dan El ft m a nn,  W e rner van den Abeel an John McCollum, Solomon Wolday and Jonathan Alexander 223Post Programming Burn-in of Actel O.25um FPGA\222s\224 MAPLD 2002  B IOGRAPHY   John worked 2 years at Faichild R&D on bipolar switching performance specifically platinum dopedlife time control and the development of Ion Implantation.  He worked 15 years at Intel developing Intel's first bipolar PROM, Ion Implantation, the world's first 16K DRAM, as well as 64K and 256K DRAMs.  Mr. McCollum developed Intel's first dual layer metal CMOS technology for the 386 microprocessor.  He co-founded Actel and worked the last 20 years on process, antifuse and flash cell development and FPGA Architecture at Actel.  He holds over 50 patents   covering Process Technology, Antifuse and NVM technology, FPGA Architecture, Analog Processing and Radiation Hardening.  He has presented numerous papers at IEDM, MAPLD, CSME, SPWG, and the FPGA Symposium. He is currently a Fellow in the Technology Development Department 


Time Time 50 350   10 0                   10 1                   10 2 12.5 50 350   10 0                   10 1  12 expected from Figure 7, the width of the uncertainty region is compressed by the curvature of the monopulse response resulting in a detection-primitive with greater uncertainty than the variance admits.  A filter lag or so-called cluster tracking can easily result in a 5% or greater offset and degraded consistency.  After 300 seconds the curves peak up because the target is appr oaching a low-elevation beampoint limit.  This occurs anytime a target is tracked into the edge of the radar\222s field of re gard and can lead to radar-toradar handover difficulty         300 300 80  s D 2 k,1 k y    s D 2 k,1 k y   100 150 200 250 10 1                    10 5 1 0  Figure 8 - Consistency versus distance from beam center Monopulse Mismatch The next set of curves plotted in Figure 9 show the sensitivity of detection-primitive consistency to a mismatch in the monopulse slope.  All of these curves were generated using a linear monopulse response derived from the slope of the true monopulse response at beam center.  The slope of the 80% curve is 0.8 times th e beam-center slope; the 90 curve is 0.9 times the beam-center slope; and so on for 100%, 110% and 120%.  Again, the order of curves in the graph is the same as the legend order A steep slope tends to expand y I 222s uncertainty while a gentle slope tends to compress it.  An expanded uncertainty leads to a smaller consistency while a compressed uncertainty leads to a larger consistency.  This behavior can be observed in the family of curves in Figure 9.  Curves for the steeper slopes are on the botto m while curves for more gentle slopes are on top.  The notable feature of this set of curves is that the sensitivity to a mismatch in the monopulse slope is not very significant       100 150 200 250 10 1                    90 100 110 120  Figure 9 - Consistency versus monopulse mismatch Range-Bias Error The complex nature of the monopulse radar models presents ample opportunity to introduce errors in the software implementation.  One such e rror introduced in a \275 rangecell-width bias in the detection-primitive range which in turn resulted in a significant degradation to 2 9 k D The fact that 2 9 k D is measured in different coordinates compared to the bias made it difficult to determine which value or algorithm was to blame.  Examining the intermediate consistency values led directly to the error source A comparison between biased 2 1 k D  2 2 k D and 2 3 k D values and unbiased 2 2 k D values is shown in Figure 10.  The unbiased 2 2 k D is the bottom-most curve and the biased 2 3 k D is the top-most curve with a value around 80.  This large value for 2 3 k D indicates that there is a lot more uncertainty in the range measur ements compared to what is predicted by the range varian ce.  Since the range-variance calculation is easy to confirm, the problem must be in the algorithms that model or manipulate range A notable feature of Figure 10 is the sensitivity of the centroiding algorithm to range bias in the detection primitives.  The range bias is ba rely noticeable in the biased 2 1 k D and 2 2 k D curves.  Of course, if the unbiased 2 2 k D  curve existed as a baseline it would be relatively easy to spot the error 


Time Time Time 50 350   10 0                   10 1                   10 2 50 350   10 1                   10 0                   10 1 50 350   10 0                   10 1  13         Isolated No SNR Adjust  Figure 11 - Centroiding for isolated range cells Filter Tuning Now that the centroided m easurements are reasonably consistent, the parameters that govern track filtering can be examined.  As previously promised, the effects and corrections for atmospheric refr action and sensor bias have been disabled so that 2 8 k D can be analyzed using a sliding window.  Of course the full analysis would include these effects and 2 8 k D at each time step would be collected and averaged over many trials Plots of the effect of changing process noise in a nearlyconstant-velocity filter are shown in Figure 12 and Figure 13 for Cartesian position and velocity respectively.  In both figures, the plotted values have been divided by 3 so that the desired value is always 1.  Increasing the process noise up to a point should increase the updated uncertainty and reduce 2 8 k D values.  Except near th e end of the trajectory when the measurements are off of beam center, the curves in Figure 12 and Figure 13 appear inconclusive for this expected trend If 2 8 k D values are way out of range there are additional intermediate filter values that can be examined.  For example, the state extrapolati on algorithms can be examined by comparing the consistency of 1 210 Isolated With SNR Adjust 300 300 300 0.005 212 212 212 212 212 kkkk T kkkk D xhzSxhz 35        s D 2 k Range   D 2 k,2 biased D 2 k,1 biased D 2 k,2  Figure 10 - Range bias error in detection primitive Centroiding Algorithm From Section 3, assuming that the centroided-range uncertainty for an isolated range cell is the same as its detection-primitive uncertainty may be incorrect Collecting and plotting 2 3 k D values only from isolated range-cell measurements can be used to analyze such assumptions.  The plots in Figure 11 compare differences between the isolated-cell algorithm defined in Section 3, an algorithm that modifies the uncertainty based on the SNR in the isolated cell, and the 2 3 k D values from all measurements 34\was used to modify the range uncertainty for the upper line labeled Isolated with SNR Adjust    4 22  2 2  resRi o R R Rn bdp bm  s D 2 k,3 Range    s D 2 k,8 Position     212 1 can also be examined using \(35 The residual is also commonly used to determine the assignment cost  212 kk z  P  k  k1 with z k The consistency of the innovation covariance k T kkkkk RHPHS 100 150 200 250 10 1                    D 2 k,3 biased 100 150 200 250 10 2                    100 150 200 250 10 1                    0.5 50  Figure 12 \226 Position consistency, filter tuning example  r  t t 34 If the All Centroided curve \(middle\as the baseline doing nothing \(lower\imates the uncertainty and 33\imates the uncertainty.  Dividing by the square root of the observed SNR leads to a more consistent covariance; however, there is currently no statistical evaluation to justify it             210 210 1 1 1 2 All Centroided 


Time 50 350   10 1                   10 0                   10 1  14         300 0.005  s D 2 k,8 Velocity   100 150 200 250 10 2                    0.5 50  Figure 13 \226 Position consistency, filter tuning example 5  C ONCLUSION  Calculating and observing the behavior of covariance consistency at different levels  in the radar signal processing chain represents a very powerfu l tool that can be used to assess the accuracy and softwa re implementation of radar signal-processing algorithms.  Analyzing covariance consistency is applicable to radar systems both in the field and in simulations.  The primary challenge in both arenas comes down to properly accounting for the true target states that contribute to detections, detection primitives measurements, and state estimates For a fielded radar syst em, achieving covariance consistency is usually a s econdary consideration behind achieving and maintaining track s.  Indeed, until recently radar specifications did not even include requirements for covariance consistency.  Recent covariance consistency requirements stem from the fact that the use of radar systems in sensor netting applications is on the rise Currently the combined e ffects of off-beam-center measurements, atmospheric correction, bias correction clustering and centrioding, data association, and filtering on state covariance consistency throughout a target\222s trajectory are not well known.  This is particularly true for radars using wideband waveforms and multiple hypotheses or multiple frame trackers.  Numerical results presented here indicate that algorithms early in the radar signal processing chain can significantly degrad e covariance consistency and that some errors are better tolerated than others For a simulated target in a modeled system, truth relative to some global reference is known. However, transforming truth through different refere nce frames and accounting for changes that occur during various radar processing algorithms is not as simple as it appears.  The techniques in this paper help expose this hidden complexity and provide a framework for discussing and expanding the future development of covariance consistency techniques.  Such future developments include issues related to mapping truth through the convolution operation typically used to simulate wideband signal processing and the fast Fourier transforms typically used in pulse-Doppler processing.  Sophisticated tracking algorithms that carry multiple hypotheses, associate across multiple frames, or weight the association of multiple targets within a single frame pose significant challenges in properly associating truth with state estimates.  Additional work, including an investigation of track-to-truth assignment, is needed before covariance consistency techniques can be applied to these algorithms Another area that needs furthe r analysis is the use of a sliding window to approximate the covariance behavior expected during a set of Monte-Carlo trials.  Various timedependent variables such as the target\222s range and orientation, the transmit waveform, the radar\222s antenna patterns toward the target, missed detections, and false alarms could easily viol ate the assumption that measurement conditions are nearly stationary over the time of the window.  It is importa nt to understand the conditions when this assumption is violated Finally, the examples presented here included a relatively benign arrangement of targets.  Further analysis in dense target environments with the related increase in merged detections, merged measurements, and impure tracks is needed.  Further analysis for targets traveling over different trajectories is also needed Even so, the techniques presented here can be extended to many of these analyses R EFERENCES  1  S. Blackman and R. Popoli Design and Analysis of Modern Tracking Systems Artech House, 1999 2  Y. Bar-Shalom and X. R. Li Multitarget-Multisensor Tracking: Principles and  Techniques YBS Publishing, Storrs, CT, 1995 3  Y. Bar-Shalom, Editor Multi-target-Multi-sensor Tracking: Advanced Applications and  Vol. I Artech House, Norwood, MA, 1990 4  D. B. Reid, \223An Algorithm for Tracking Multiple Targets,\224 IEEE Trans. on Automatic Control Vol. 24 pp. 843-854, December 1979 5  T. Kurien, \223Issues in the Design of Practical Multitarget Tracking Algorithms,\224 in Multitarget-Multisensor Tracking Y. Bar-Shalom \(ed.\43-83, Artech House, 1990 6  R.P.S. Mahler, Statistical Multisource-Multitarget Information Fusion, Artech House, 2007 


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



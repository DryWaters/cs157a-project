With the development of RFID applications, the rapidly increasing number of companies actively participated in the RFID system development and the RFID devices which adopt the different communications protocol. So the RFID Middleware becomes a very hot topic. RFID middleware is a new breed of application software which facilitates data 
The research of RFID Middleware\220s Data Management Model Wang Yan 
The logistics institute  School of Control Science and Engineering Shandong University jingshi Road,Shandong,P.R.China 250061 
an, Zhao Xiaofeng,Wu Yaohua,Xu Peipei 
y 1978_wyy@163.com 
Abstract 
communication between automatic identification equipments like RFID readers and enterprise applications. At the same time, the data of the application program are written in the tag and data security is very important to ensure application software security such as WMS, ERP. This paper refers to data management model of RFID Middle to increase the data security and tag capacity and describe the architecture of RFID Middleware. Because the capacity of tag is limited, the store space of the ciphertext is must be considered and it is possible that the key table is very big in order to reduce the query speed. So this system   used two-step encryption and 
adopted improved the transposition encryption. To increase the storing capacity of RFID tag, this paper adopt LZW compression algorithm.  The RFID Middle rapidly becomes the common interface of different RFID devices 
Introduction of  RFID technology  
 Index Terms- Radio frequency identification, RFID Middleware, Data filtration, Data security, Data compression 
 RFID is a generic technology concept that refers to the use of radio waves to identify objects. RFID is a non-contact interrogation method for identification of objects. An RFID system essentially consists of three parts 
I INTRODUCTION 
the RFID tag itself, the RFID reader device, and a backend information management system. The RFID tag consists of a silicon chip that can hold a certain amount of data \(such as a unique identification number\, and an antenna that is used to communicate with the remote reader device. The reader device communicates with the RFID tag by means of sending and receiving radio frequency waves    Many of us are unaware of the fact that we are surrounded with applications of radio frequency identification \(RFID\. It has affected our daily lives in many different aspects. RFID developed and improved fast during 1970s and 80s. More applications took place in the 1980s 
Most common implementations during decade were tracking of animals and vehicles. RFID was also used in factory automation F ID c a n  be used in supply chain to improve inventory control. The use of RFID should greatly reduce the level of shrinkage that occurs in the supply chain by providing increased visibility of individual cases of product. [14   These applications provide security, safety and convenience. We can use RFID in preventing auto and merchandise theft, collecting tolls without stopping managing traffic, controlling access to buildings, gates and more. So RFID technology has been widely adopted for supply chain management purposes. Its inherent 
identification capabilities provide the opportunity to trace products from the producer to the retailer, offering insight to the various levels of the supply chai    I n a w o r d  t h e  introduction of RFID changed the data gathering mode rather than the Application Business 
B Introduction of  RFID Middleware 
 With the development of RFID applications, the rapidly increasing number of companies actively participated in the RFID system development and the increasing sales record of RFID systems and the RFID devices which adopt the different communications protocol. Facing the various applications of RFID, the enterprises meet the first question 
that is how to make the existing information system to connect the RFID reader.  The essence of the question is the interface between the application system and hardware of RFID. So, the key is how to get the accurate data and ensure the reliability of the data. The traditional method of Application to Application is to use middleware. In a similar way, the solution of middleware architecture is the core technology RFID Middleware is a new breed of software system which facilitates data communication between automatic identification equipments like RFID readers and enterprise applications. Recently, the development of RFID Middleware technology has become very active in various 
fields such as manufacturing companies and material flow systems. Also, the researches for RFID Middleware systems have been performed continuously and the related software packages have appeared in the market. The rapidly increasing number of companies actively participated in the RFID system develop and the increasing sales record of RFID systems show the importance of RFID middleware systems.[4 Fi g  1 s h o w s R FI D Mi d d l e w a r e Sy st e m  Architecture 2565 


 Fig .1  RFID middleware System Architecture  RFID Middleware systems receive tag data from variable RFID readers that identify and read RFID tag and collect, filter, and a group of tag data to transmit the processed tag data to application program such as WMS ERP. The responsibility of RFID Middleware systems is to collect and filter the r eceived tag data, and deliver the filtered tag data to applications programs. In RFID system the middleware is a sort of software that resides between the RFID readers and enterprise applications. The middleware takes the raw data from the reader, filter it and passes on the useful event data to back-end systems. Tag data that middleware handles can be information that is involved in individual's privacy, or has important value of corporations  T h e s e c o n d f i n g e r s h o w t h e f u n c t i o n s o f R F ID  Middleware    Fig. 2 the functions of RFID Middleware  The heart of the utility is that RFID makes gathering information about physical objects easy. Middleware plays a key role to deliver tag data in real time, which resides between readers and enterprise applications in RFID Systems. Therefore, the data management of RFID Middleware is very important. This paper emphasized this model which is shown in Fig. 3      Fig.3  RFID Middle Data management model  The rest of the paper is organized as follows. In section 2, we present the background of the RFID Middleware Section 3 introduces the improvement of transposition cipher adopted by RFID Middleware to increase the data security. Section 4 introduces RFID Middleware using the compression algorithm in order that RFID tag can store more data. Section 5 tests the performance of RFID middleware Finally, In Section 6   concludes s this paper   II THE BACKGROUND OF RFID MIDDLEWARE  Sun, IBM, BEA, SAP, Oracle, i-Konect, etc. introduced their RFID Middleware products. And some research groups also propose their solutions, such as the E-Business Technology Institute \(ETI\ of the University of Hong Kong Institute of Computing Technology, Chinese Academy of Sciences, etc. SUN-MEE PARK proposed that the RFID Middleware system supporting priority service with the Buffer Management Component consists of the Reader Interface Component, the Buffer Management Component the ALE Component and the EPCIS Component. Buffer management component consists of the buffers that buffer the received tag data and the buffer manager that gives the different priorities to the buffers in processing the tag data in the buffers. Also, the buffer manager provides the time managing, priority managing and data size managing functions. [6   Each RFID Middleware has respective characteristics But they donêt deal the RFID tag data in terms of data security and compression to increase the quantity of storing data III THE RESEARCH OF RFID MIDDLEWAREêS DATA SECURITY  Although many methods were introduced to guarantee to data security of RFID tag, most of them come down to the hardware.[7 F r o m th e v i ew o f s o f t w a r e  w e u s e t h e authentication of RFID reader and the method of data encryption. The authentication of RFID reader which is the first security safeguard is to defend the RFID data which canêt be identified by the wrongful reader ,that can be achieved by giving the reader a label of çright:é item, which write the right of RFID reader. When the RFID reader send the request of reading the RFID tag, the RFID Middleware firstly verify the right of reader, if the çrighté item is  one the reader can read the RFID tag, or the reader is rejected and closed. The data encryption protects the RFID data which can be identified by the unlawful reader. The mechanism of data encryption can be described as follows 8       D E K C P S   1  P  expresses the space of plaintext   C  expresses the space of ciphertext  K  is the key or the space of key E  is Encryption Algorithm D  is Decryption Algorithm If the key is K, the Encryption and Decryption Algorithm can be used by E k and D k then  Cryptosystem can be described as follows        K K K D E K C P S  2   P E C K  3 2566 


     P E D C D P K K K   4 1  K E is  the Inverse Function of K E 1 1 and     K K K K D E E D 5 Equation 3 shows that P is encrypted by the E k to equal ciphertext C Equation 4 show C is decrypted by the D k to equal plaintext P The classical encryption Algorithm has two type replacement encryption and transposition encryption. The replacement encryption is to replace the char of plaintext by the other char, number and so on, but the position of each char is not changed. The transposition encryption is to disorder the plaintext and the chars are not changed. In other words, the plaintext can be input a picture and the other order chars are output shown in Fig. 4  Fig. 4  the description of Encryption Algorithm Because the capacity of tag is limited, the store space of the ciphertext is must be considered and it is possible that the key table is very big in order to reduce the query speed So this system adopted improved the transposition encryption and used two step encryption. The first step is the transposed transposition encryption. The string can be encrypted by the transposition and one M X 4 matrix is built in which M based on the capacity of tag, for example the capacity of tag is 256 chars, then M=256/4=64 according the transposition encryption, the ciphertext C 1 can be accepted. The second step is binary transpos ition encryption that makes each binary char of C 1 invert order transposition encryption. For example the ASCII of çré is 114, the binary of r is ç01110010é, then inversed 01110010é and the other binary ç01001110é can be obtained. The decimal number is 78, which is the char of Né. Repeated the procedure, the full string can be encrypted as shown in Fig. 5 Fig.5 the encrypted string process IV THE RESEARCH OF RFID MIDDLEWAREêS DATA COMPRESSION The data compression can be mainly divided loseless compression and losssy compression. To ensure the security of data, we must adopt the loseless compression which wipes off the redundancy information and doesnêt influence the information entropy, at the same time ,the compressed information can be recovered. The target is to wipe off the maximum of removing redundancy information[9  T h e r e  are many data compression algorithm. In RFID Middleware software, on account of efficiency\( both space and time there is a need to keep the data in compressed form for as much as possible, even when it is being searched. So we selected the Lzw compression algorithm. A string table must be built to store the data. If the other data matches the data stored string table, the index of string table can be output. Because of the index bytes less than the bytes of fact data that increases the compression rate. The string table neednêt transport with the data and is dynamic generation   The compression algorithm can be described as follows step1 initialization build a string table step2  read the first input char set the prefix    string f  step3   read the next char  if\( no char output f char, exit if f x exist in string table f x  f repeat Step3 Else  if f x not exist in string table  output f char   f x can be added to S string table x  f repeat Step3 LZW compression algorithm data flow can be described as follows  Fig.6  LZW compression algorithm data flow VT HE PERFORMANCE TEST OF RFID  MIDDLEWARE 2567 


 After we finished the RFID Middleware software we built a simple testing environment  The hardware environment as follows  TABLE I T HE HARDWARE ENVIRONMENT RFID device IF4 and IF5 of internec XCRF-500 of Yuanwanggu  host CPU>=1.0G memory>=256M hard disk>=20G os Windows XP Professional N et  10  100M application WMS  The WMS using the DLL of RFID Middleware had finished the input and output of whole pallet and the testing performance has The Stability testing of system  The control test of system The reading and accurate rate of RFID tag The security testing of RFID tag The data compression testing The result of testing  Run two hours, the system worked properly and use few CPU and memory The number of input and output whole pallet is 50 The reading accurate rate is 100% and this system can update the right data  The data compression function is proper VI C ONCLUSION RFID is the hottest spot of current research. It can be used in wide area, including logistics, guard system ticket management, airline express, mobile business automatization etc. Many industries are absorbed in the RFID product and application, the RFID Middleware becomes very important. But the data security and compression is a problem. This paper used two two-double method to protect the data in tag-labels One is the verification of the reader and the other is data encryption. Because of the capacity of tag, this paper used two-step encryption and improved the data security. We proposed the method of data compression for some special areas. We can use tagês memory more sufficient and save the cost for applications  R EFERENCE 1  G a r y M  G a u k l e r  R F ID  in s u p p l y c h a i n  A d is s e r t a t io n s u b m it te d  to the department of management science and engineering and the committee on graduate studies of Stanford university . The degree of doctor of philosophy 2 rry l a n d t a n d  Ba rb a r a Ca t l i n    S h r o u d s  o f T i m e T h e  h i s t o r y o f  RFIDé.Aim ver1.0 Oct,1,2001 http://www/aimglobal.org 3 B a dr i N a t h  Fr a n k l i n R e y n o l d s a n d R oy W a nt   R FI D T e c h nol o g y  and Applications  IEEE Pervasive Computing, vol. 5, no.1, pp 22-24, Jan.-March 2006 4 L o ad B a l a nc i n g  Me t h od U s i n g C o nnec t i on  P o o l i n R F I D  Middleware   Sung-Mee Park, Jeong-Hwan Song, Chae-Soo Kim, Jung-Ja Kim  Dept. of Industrial and Management Systems Engineering, Dong-A UniversityLoad Balancing Method Using Connection Pool in RFID Middleware Sung-Mee Park, Jeong-Hwan Song, Chae-Soo Kim, Jung-Ja Kim  Dept. of Industrial and Management Systems Engineering Dong-A UniversityLoad 5 A u t h o r i z a t i o n P o l i c y fo r M i d d l e w a r e   i n RF ID S y s t e m  T a e s u n g  Kim and Howon Kims 6 ID M i d d l e w a r e S y s t e m S u p p o r t i n g P r i o r i t y S e r v i c e   Sung-Mee Park, Jeong-Hwan Song, Woo-Yong Choi, Chae-Soo Kim, Sang-Wan Lee and Jung-Ja KimDept. of Industrial and Management Systems Engineering, Dong-A University 7 a n j a y E S a rm a  S t e p h e n  A  We i s  Da n i e l W  E n g e l s  RF ID  Systems Sanjay E.Sarma, Stephen A.Weis, Daniel W.Engels RFID Systems and Secruity and Privacy Implications. Workshop on Cryptographic Hardware and Embedded Systems,2002 8  Z h ang zeze ng  Z h a o l i n  T he E n c r yp t i o n A l go r i t h m of com p u t e r   Microelectronics institute of publishing house 9 l a u s H o lt z  T h e E v o l u tio n  o f  Lo s s l e s s D a ta Co m p r e s s i o n  Techniques WES C ON  9 3  Co n f e r e n c e  R e c o r d   C A  US A   28-30 Sep, 1993:140-145 10 K i da  T   T a k e da  M    Shi n oha r a  A   e t c    Mu l t i pl e pa t t er n ma t c hi ng  in LZW compressed text. Data Compression Conference Snowbird, UT, USA,30 Mar, Apr, 1998:103-112 11 A Ju e l s   RF ID  se c u ri t y a n d  p r i v a c y  a r e se a r c h  s u rv e y J S e l e c t e d  Areas in Communications, IEEE Journal, Feb, 2006: 35-48  A v o i ne   G    O echs l i n  P   A s c al a b l e  and p r ov abl y s e c u r e  hash-based RFID protocol[C  P e r v a s i v e C o m p u t i ng a n d  Communications Workshops, Third IEEE International Conference, 8-12 March, 2005:110-114 13 G ild a s  A v o i n e  Eti e n n e D y s l i P h ili p p e O e c h s l in R e d u c i n g t i m e  complexity in RFID systems[M   L e c t u r e N o te s i n  Co m p u t e r  Science. Heidelberg: Springer Berlin, 2005:291-306  J e f f r e y R o be r t T aze l aar   M i c h i g a n S t at e U n i v e r s i t y i n  p a r t i a l  fulfillment of the requirements for the degree of master of science. The effect of tag orientation and package content on the readability of  RFID 2568 


 T a b l e  1   E x a m p l e  c o n d i t i o n a l  p r o b a b i l i t y  t a b l e d  f o r  S u c c e e d  i n  o b t a i n i n g  p a s s w o r d   Existence of default passwords T F Passwords used in multiple systems T F T F Personnel susceptible to social engineering T F T F T F T F Success 0.9 0.8 0.8 0.7 0.8 0.7 0.7 0.1 Failure 0.1 0.2 0.2 0.3 0.2 0.3 0.3 0.9  T a b l e  2   E x a m p l e  c o n d i t i o n a l  p r o b a b i l i t y  t a b l e  f o r  P a s s w o r d  Y  u s e d  i n  m u l t i p l e  s y s t e m s      Passwords assigned automatically True False True 0.07 0.95 False 0.93 0.05 4  Using abstract models for defense graphs 4.1  Abstract models Thus far in the paper the focus have been on the analysis framework and how to derive a value of security \(or expected losses due to lack of security We now turn to the design or management of information systems. In recent years model based design and management of information systems have gained much attention and increased in popularity There are many propositions on how to do this, and for information systems design the Unified Modeling Language \(UML\ is the de-facto standard language For information system management a number of enterprise architecture frameworks have been proposed. A common denominator for these modeling languages is that they are designed from the point of view of what exists rather than what the models should be used for. The concept of abstract models has been proposed to avoid th e pu rpos e o f t h e s e i s to  merge analysis frameworks, such as extended influence diagrams, and modeling languages so that the analysis can be performed on scenarios modeled according the abstract model An abstract model comprise of four components entities, entity relationships, attributes and attribute relationships. The first three of these components can be recognized from standard modeling languages such as the class diagrams of the UML. Entities are a central component in most modeling languages and can as in class diagrams be used to represent concepts of relevance for the model. These can be either physical artifacts, such as computer and person or more concepts such as data and procedure Entities are represented in a similar was as classes in UML are: a rectangular box with the name of the entity specified at its top Entities can in abstract models be connected through entity relationships. These entity relationships are depicted as lines spanning between the entities with roles names and multiplicities declared at the endpoints Attributes of abstract models are as in UML held by entities and are depicted as squared boxes within the entity belong to. However, unlike in UML, they are random variables or utility variables of finite domains In other words the attributes of the abstract model are the chance and utility nodes of the extended influence diagram Finally, and thus naturally, abstract models in addition to other modeling languages have the attribute relationship. This is relationship is the same as the relationship in the extended influence diagrams and is either causal or definitional. If this attribute relationship spans two entities, it is always associated with a particular entity relationship, which is denoted by the dashed line, for indicating which entity relationship that is the reason why the attribute relationship exists. Cf. Figure 6         F i g u r e  6   E x a m p l e  o f  a n  a b s t r a c t  m o d e l   Abstract models can thus be seen as metamodels enhanced with extended influence diagrams. This enhancement is not as straight forward as it seem.  The reason for this is that the extended influence diagram does not differentiate between the instantiated and abstract modes. For instance, as a result of the multiplicities of entity relationships, the number of parents an attribute has may differ between instances of the abstract model. One way to handle this when describing the instantiated extended influence diagram is to use aggregation functions to specify the Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


conditional decency an attribute has on its parents Examples of such aggregation functions are AND  OR  AVERAGE and MAX  4.2  Generating abstract models from defense graphs Schech o in ts ou t t h at th e stru c t u r e of attac k  trees depends on the system architecture and the choice of countermeasures. For example, in architectures that contain confidential data, attacks compromising the access control of this data are relevant. The countermeasures included in the architecture are also of relevance since the attack vectors that are available depend on these. The attacks bypassing an access control mechanism based on biometrics does for instance differ from attack against an access control mechanism based on passwords. Also, the multiplicity of countermeasures is of importance since additional countermeasures introduce additional hinders for adversaries Abstract models offer a way of handling these dependencies by dictating the attribute relationships as a consequence of an entity relationship. With this as a basis, it can be expressed how the relationship between attack-goals depend on the entities included in a model and their relationships to each other The nodes of a defense graph, expressed as a extended influence diagram, are typically associated with some entity to which they belong.  Based on this the entities that are relevant for the assessment can be identified and populated with the appropriate attributes For example, the node Password Strength can be interpreted as the entity Password holding the attribute Strength  If an entity relationship shall be included in an abstract model depend on the structure of the associated extended influence diagram. The entity relationships of relevance are those that determine if an attribute relationship shall exist in an instantiated version of the model. The example abstract model in Figure 6 does for instance have the entity relationship includes since this relationship between a system and component would result in attribute relationships between their attributes 4.3  An example abstract model over password protection The attributes of the extended influence diagram in Figure 5 refers several concepts that needs to be investigated in a security assessment. The objective is to protect some data and vital for this is the password authentication mechanisms which protects software such as application and operating systems The password authentication mechanism uses passwords to grant or deny access and these passwords could or should be governed by a password policy The persons  who own the passwords have an influence on security related attributes according to the extended influence diagram and should also be considered in the assessment. Furthermore, if password holders are covered security training and awareness program is influencing the probability that these individuals have received training and participated in awareness sessions Hence, this aspect should also be included The entities are included because they hold attributes that are of relevance to the assessment. For example, the entity password is relevant because they should have strength The persons holding the passwords are relevant since their susceptibility to social engineering influence the difficulty to perform attacks For personnel, the participation in awareness and training programs is believed to influence their susceptibility to social engineering, hence if they are covered by such programs is also of relevance. The password authentication mechanism itself holds attributes such as strength of password hash and if there is an active password checker in use. These defensive attributes and the attributes representing attack goals and sub-goals give rise to the abstract model in Figure 1  Relationships among attributes in the abstract model should exist if they will lead to an attribute relationship in an instantiated model. For instance, in an instantiated abstract model the entity relationship owns  between a person and a password would imply that the person s attribute Has participated in security awareness session influence strength of the password If a password s strength is influencing the minimum password strength of an authentication mechanism depends on whether it gives access to that particular password authentication mechanism. In the same way a password protection mechanism s attributes will only influence the difficulty of bypassing logical access control of software if it protects that specific application or operating system. The attribute relationships that these en tity relationships are associated with is shown with dashed lines Figure 7 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


 Person Password policy Has participated in security awareness session Password Application Training and awareness program Password authentication mechanism Operating system Suceed bypassing logical access control Succeed bypassing password authentication Existence of default passwords Size of salt Strength of password hashing Existence of password policy Password used in multiple systems Minimum password strength Succeed with brute force attack Strength Passwords assigned automatically Limited number of logon attempts Use of active password checker Succeed in obtaining password Succeed with dictionary attack Is default Has received security training Covered by security awareness and training program Suceed bypassing logical access control Susceptible to social engineering          Personnel ssusceptible to social engineering         Data Consequence of unathorized access Suceed bypassing logical access control   Existence   Existence  Require access to Provides access to 0 Provides access to 0 0 0 Require access to Protects Protects Is protected by Is protected by 0 0 0 0 Governs Is goverened by 1 0..1 Is covered by Covers 1 0 Is owned by Owns 1 0 Gives access to Provide access to 1 1    F i g u r e  7   A b s t r a c t  m o d e l  b a s e d  t o  t h e  e x t e n d e d  i n f l u e n c e  d i a g r a m  i n  F i g u r e  5   5  Instantiating the abstract model 5.1  Evidence collection A security assessment typically involves data collection in terms of interviews, documentation studies, log reviews, deriving various metrics penetration tests and more. The purpose of this is to collect information \(evidence\ about matters that are believed to influence security to facilitate analysis. One part of this information collection serves to identify the entities that need to be investigated and their relationship to each other. Another part of the data collection concerns the quality of various attributes and analyzing how these qualities influence security In relation to the framework presented herein the first part of information serves to scope the model based on the entities and relations available in the metamodel. The second part will add evidence to the state of attributes that influence the security. Evidence on attributes state can be added by for example studying documents, performing interviews, from firsthand experience, or form penetration testing There is always some uncertainty as to whether the evidences has credibility and reflect the actual state of attribut pen e tration test w i l l f o r in s t an c e  provide a high degree of confidence in results if the simulated attack is successful while unsuccessful attempts do not ensure the nonexistence of vulnerabilities. Documents describing systems may be old and obsolete, persons interviewed may be biased etc. Furthermore, some attributes are harder to assess directly than others and the evidence collected on these will consequently be vaguer. Abstract models allow the uncertainty of collected information to be included in the assessment by expressing evidence on the state of attributes through chance nodes. These evidence chance nodes are influenced by the state of the assessed attribute In Figure 8 evidence obtained from an interview on the use of automatic password checker is depicted as an ellipse. Table 3 expresses the significance of this of evidence by describing the expected outcome of the interview based on the possible states of assessed attribute. In this example, the system administrator would give the answer true with 95 percents probability if there is an automatic password checker With 10 percents probability the system administrator would wrongfully answer true even if there was no automatic password checker Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


 T a b l e  3   A  c o n d i t i o n a l  p r o b a b i l i t y  t a b l e  s p e c i f y i n g  c r e d i b i l i t y  o f  e v i d e n c e  o n  t h e  u s e  o f  a u t o m a t i c  p a s s w o r d  c h e c k e r   Administrator s answer T F Automatic password checker True 0.95 0.10 False 0.05 0.90 While there may be numerous attributes influencing the security according to an abstract model, evidence on all of these does not have to be collected. However the more evidence that is collected, the more certain the result is. A method for dealing with the tradeoff between data collection cost and its impact in abstract models has been presented by  5.2  Constructing the concrete model By instantiating the abstract model, a concrete model can be created. The model depicted in Figure 8  is a concrete model based on the abstract model in Figure 7 In this example the data for which expected losses is assessed are customer records and strategic plans To base an abstract model on an extended influence diagram that expresses the defense graph has direct benefits. Firstly, it ensures that the model used for assessment, and consequently the data collected for it contains the data needed to for generating and assessing security using defense graphs. Secondly since the model only covers the parts that are of relevance to the assessment, the assessment will only focus on things of relevance to its result. Furthermore it is from an instantiated abstract model straightforward and supported by tools o deri v e t h e a t t r i b u t e s  attribute relationships, and conditional probability tables. Using an abstract model, the modeler will only have to model the entities, their relationships, and the state of attributes to assess the security Shown in Figure 8 is the expected loss from unauthorized access to the strategic plans. This depends on the probability that an adversary will succeed bypassing the logical access control of the ERP Client. This in turn depends on the attributes of its password protection mechanism, and so on Based on the entities instantiated in the concrete model and the relationship among these, a network of attributes can be derived. This network will correspond to an extended influence diagram expressing a defense graph. The attributes to be included can be derived from the entities that have been instantiated. And since the attribute relationships are associated with entity relationships, these can be derived based on the entity relationships that exist in the concrete model Together with evidence, like the interview system administrators, Bayesian inference can be used derive a value of attributes in the same way they can in an influence diagram. This would include deriving the probability that certain attacks succeed; the expected consequence of attack attempts; and an index comparing the expected losses of today s solution and the optimal one. Furthermore, this can be done even if the evidence is incoherent, or incomplete   F i g u r e  8   A  c o n c r e t e  m o d e l  o f  t h e  a s s e s s e d  e n t e r p r i s e   E n t i t i e s  a n d  e v i d e n c e  o n  t h e i r  a t t r i b u t e s  e n a b l e  t h e  p r o b a b i l i t y  o f  a t t a c k s  s u c c e s s  t o  b e  i n f e r r e d  a n d  t h e  e x p e c t e d  l o s s  t o  b e  c a l c u l a t e d   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


6  Discussion  When modeling security, or anything else for that matter, there is typically a tradeoff between completeness and feasibility on one hand, and simplicity and accuracy on the other. Models of attacks against cyber technology is no different, in fact attack graphs growing large is a known problem ce identifying all plausible attack steps and defense mechanisms prior an evaluation could become a daunting task. A suggested solution to the problem proposed by Liu and Hong s t o us e Ba y e s i a n  networks to express attack graphs In a similar manner is the method proposed in this paper using extended influence diagrams, which also is form of Bayesian networks, to enable a compact representation of both attack graphs and defense mechanisms. By taking advantage of the probabilistic expressiveness of these Bayesian networks, the complexity of graphs can be reduced to a desirable size. This allows models to be created, without enumerating all plausible attacks or specifying them to the last detail, and instead include the uncertainty that is a result of keeping models on a high level. This also enables models to express uncertainty related to for instance access success that is a result of unknown novel, attacks. By introducing this uncertainty to the analysis framework it is also possible to refine it iteratively. The more we learn about certain attacks and how to protect against them \(by case studies experiments or otherwise\he more we can reduce the uncertainties in the framework. In other words, the quality of results is related to how well we have prepared the analysis framework Except for managing the problem with knowing exactly all kinds of attacks and how to defend oneself against them, there is also always a practical problem of assessing cyber security with respect to our current knowledge. Typically in real world situations there are so many things that we know have a bearing on cyber security that there are an enormous amount of information about the state of the world that are needed for performing the security analysis. To collect all this data with high confidence take substantial efforts, if possible at all. However, the level of certainty in the results that is the highest imaginable. These two parameters thus need to be traded against each other by the decision maker. By using abstract models to generate defense graphs, and provide evidence on attribute states together with their credibility, a model based on incomplete information can provide a value on security that also provide an indication of the certainty of this value  7  Conclusions Model based design and is an established approach for management of information systems. For these models to support decision making relating to cyber security, the models of systems, software, and enterprises need to include the factors that influence security This paper has shown how defense graphs expressed with extended influence diagrams can be merged with the concept abstract models. Used as a metamodel this type of abstract model will include all the components necessary to perform a security assessment based on an architecture model. In addition to this, it will express how these components influence each other and how to derive a value on security and expected losses from an instantiated model 8  References 1  Y. Liu and M. Hong, Network vulnerability assessment using Bayesian networks, Proceedings of Data Mining Intrusion detection, Information assurance and Data networks security, Orlando, Florida, USA, 2005, pp 6171 2  S. Bistarelli, F. Fioravanti, P. Peretti, Defense trees for economic evaluation of security investments Proceedings of Availability, Reliability and Security ARES\ienna, Austria, 2006, pp. 8 3  S. Bistarelli, F. Fioravanti, P. Peretti, Using CP-nets as a Guide for Countermeasure Selection, Proceedings of the 2007 ACM symposium on Applied computing, Seoul Korea, 2007, pp. 300 - 304 4  P. Johnson, R. Lagerstrom, P. Narman, M. Simonsson Enterprise Architecture Analysis  with Extended Influence Diagrams. Information System Frontiers, 9\(2 Springer Netherlands, 2007, pp. 163-180 5  R. Shachter, Evaluating influence diagrams. Operations Research, 34\(6\, Institute for Operations Research and the Management Sciences, Hanover Maryland, 1986 pp. 871-882 6  Neapolitan, R. Learning Bayesian Networks. PrenticeHall, Inc. Upper Saddle River, NJ, USA 2003 7  Jensen, F.V., Bayesian Networks and Decision Graphs Springer New York, S ecaucus, NJ, USA 2001 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


8  R. Shachter, Probabilistic inference and influence diagrams. Operations Research, 36\(4\ Hanover Maryland, 1988, pp. 36-40 9  B.A Gran, Use of Bayesian Belief Networks when combining disparate sources of information in the safety assessment of software-based systems. International Journal of Systems Science, 33\(6\, 2002, pp. 529-542 10  M.J. Druzdzel and L.C. van der Gaag, Elicitation of Probabilities for Belief Networks: Combining Qualitative and Quantitative Information, Proceeding of the 11th Conference on Uncertainty in Artificial Intelligence, 1995, pp. 141-148 11  M.J. Druzdzel and L.C. van der Gaag, Building probabilistic networks: where do the numbers come from?, IEEE Transactions on Knowledge Data Engineering, 12\(4\, 2000, pp. 481 6 12  R. Lagerstrˆm, P. Johnson, P. N‰rman , Extended Influence Diagram Generation, Proceedings of the Interoperability for Enterprise Software and Applications Conference, 2007 13  M. Howard and D. C. LeBlanc. Writing Secure Code Microsoft Press, Redmond, WA, USA, 2002 14  P. Johnson, E. Johansson, T. Sommestad, and J. Ullberg A Tool for Enterprise Architecture Analysis, In Proceedings of Enterprise Distributed Object Computing Conference, 2007, pp. 142-142 15  S. E. Schechter. Computer Security Strength & Risk: A Quantitative Approach. PhD thesis, Harvard University 2004 16  B. Schneier. Attack trees: Modeling security threats. Dr Dobb s Journal, 1999 17  N. L. Foster. The application of software and safety engineering techniques to security protocol development. PhD thesis, Univ. of York, Dep. Of Computer Science, 2002 18  S. Jha, O. Sheyner, and J. Wing. Two formal analyses of attack graphs. In Proc. of the 15th Computer Security Foundation Workshop, June 2002 19  O. Sheyner Scenario Graphs and Attack Graphs  Carnegie Mellon University, April 2004. PhD Thesis 20  O. Sheyner and J.M. Wing Tools for Generating and Analyzing Attack Graphs Proceedings of Works hop on Formal Methods for Components and Objects, 2004 pp. 344-371 21  J.J.C.H. Ryan and D.J. Ryan, Expected benefits of information security investments, Computers Security, 25\(8\ 2006, pp 579-588 22  W.J. Caelli, D. Longley, and A.B. Tickle. A methodology for describing information and physical security architectures. Proceedings of the IFIP TC11 Eigth International Conference on Information Security IFIP/Sec 92, volume A-15 of IFIP Transactions, pages 277 296. Elsevier, May 27 29, 1992 23  S. Vidali and A. Jones, Analyzing Threat Agents Their Attributes, School of Computing, University of Glamorgan, Technical Report CS-05-04, 2005 24  R. Vaughn, R. Henning, and A. Siraj, Information assurance Measures and Metrics:  State of Practice and Proposed Taxonomy. Pro ceedings of 36th Hawaiian International Conference on System Sciences, 2003, pp 331-334 25  E. Johansson, Assessment of Enterprise Information Security - How to make it Credible and Efficient, PhD Thesis, Royal Institute of Technology \(KTH 26  S. Bistarelli, M. Dall Aglio, P. Peretti Strategic games on defense trees Formal Aspects in Security and Trust Springer Berlin / Heidelberg, 2007, pp. 1-15 27  J. Pamula, P. Ammann, A. Jajodia, V. Swarup., A weakest-adversary security metric for network configuration security analysis, Conference on Computer and Communications Security, Proceedings of the 2nd ACM workshop on Quality of protection 2006 28  D.J. Leversage, E.  James,, Estimating a System's Mean Time-to-Compromise, IEEE Security & Privacy Volume 6, Issue 1, pp. 52-60. 2008 29  P. Manadhata,, J. Wing,., M.  Flynn, and M. McQueen Measuring the attack surfaces of two FTP daemons. in Proceedings of the 2nd ACM workshop on Quality of protection, ACM Press, New York, 2006, 3-10 30  C. Philips,  L.P Swiler , Graph-Based System for Network-Vulnerability Analysis, Proceedings of the 1998 workshop on New security paradigms, 1998 31  T. Sommestad,  M. Ekstedt, P. Johnson, Combining defense graphs and enterprise architecture models for security analysis, Proceedings of the 12th IEEE International Enterprise Computing Conference September 2008 32  P. N‰rman, P. Johnson, R. Lagerstrˆm,  U. Franke, M Ekstedt,. Data Collection Prioritization for Software Quality Analysis, Second International Workshop on Software Quality and Maintainability, Athens, Greece April 1, 2008 33  P. Ammann, D. Wijesekera, and S. Kaushik Scalable graph-based network vulnerability analysis in Proceedings of the 9th ACM conference on Computer and communications security, pp. 217 224, November 2002  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


  11 to request, review, and propose changes to the current state of the science plan Distributed Operations 227 Cassini distributed all aspects of the instrument operations to the science teams. Science Teams were required to develop the spacecraft commanding for pointing the spacecraft. Th is significantly complicated the interfaces and coordination required by the JPL science and sequencing teams. The distribution of internal instrument commanding and monitoring instrument health and safety worked well. Dedicated full-time operations personnel were required at all instrument sites. The liaison between the distributed sites and JPL required definition of a strong JPL Investigation Scientist \(i.e., Experiment Representative\le Distributed operations is a two-edged sword. Scientists personally worked operations and were better able to optimize for their science objectives. Their insight provided the feedback necessary to quickly respond to science discoveries in the science selection and uplink processes This allowed the operations team to capitalize on truly extraordinary opportunities to a degree not thought possible However, this was at the cost of doing science analysis and publishing science results Software Development 227 The Cassini mission deferred most of its ground software development until post launch. In fact, considerable effort was spent accelerating the development of the tools required to plan the Jupiter flyby observations in 2001. For the start of the science integration for Cassini\222s prime mission, many of the ground software planning tools were immature or unavailable. To compensate, homegrown tool development occurred at the instrument sites and within science planning. System engineering of these types of ground software tools was lacking. A better paradigm would have been to develop the operations and ground system\222s architecture, requirements models, and software to a level sufficient to support operations pre-launch. Sufficient project resources needed to be applied to Phase B/C/D development. The science planning tools should be developed to a sufficient level during these phases such that th ey can be used as part of evaluating the ground and flight system requirements and capabilities. Based on this evaluation, refinements could be made during cruise and throughout the mission to the unified ground and flight system architecture and software requirements Programmatic  Project Science 227The orbiter consists of 8 Principal Investigator \(PI\struments and 4 Facility Instrument with corresponding Team Leads. In a ddition, there are 5 different science discipline teams: Rings, Saturn, Titan, Icy Satellites and Magnetosphere. The Project Science leader ship needed to be highly involved in the tactical and strategic science planning activities. The consensus building culture used on Cassini was time consuming. The Project Science support staff should be funded adequately to allow the Project Scientist to participate in the integration process. Clear Project Science guidelines are very helpful Instruments 227 Instrument Flight Rule development must be mature pre-launch. Instruments should be designed to minimize impacts on the operations of the other instruments, e.g., radiator placement. Data compression internal to instruments is vital. For Cassini, the science instruments had internal sequencing memory for storing instrument commanding for upcoming sequence. This allowed the science teams th e ability to send real-time noninteractive instrument commands that bypass the sequencing process by using the Automated Sequence Processor \(ASP  In-flight Testing 227 The targeted gravity assist flybys provided a unique opportunity to exercise the ground system on realistic science data acquisition scenarios that simulates the operational environment during the Tour phase of the prime mission. This also had the advantage of providing the science instrument teams an opportunity to acquire useful science data for the purposes of instrument checkout and science data analysis. The in-flight exercises should use the processes, procedures, software, and ground system capabilities in the same manner, to the extent possible, as will be used during Tour and Orbital operations The entire flight team \(mission planning, science planning sequencing, spacecraft, naviga tion, and science teams should be fully engaged to provide the maximum benefit to the Project 7  C ONCLUSION  Even though Cassini was a NASA flagship mission maximizing the science return was a challenge to science planning operations. Decisions aimed at saving both prelaunch and operations costs added considerable complexity to both the spacecraft and the ground system. Among the key ones were removing the scan platform, opting for distributed operations rather than co-location, and delaying development of some flight software and most of the ground system until after launch Understanding the operational challenges to maximizing Cassini science return and the successful techniques employed to overcome those challenges as presented in this paper should be of value to other deep space science missions.  Future missions should carefully consider the following advice 200  Pay careful attention to operational scenarios in development cost saving decisions, both spacecraft and ground. Additional, more sophisticated commanding constructs may be required in operations to compensate for lack of spacecraft capabilities. Ground management of stressed or 


  12 degraded spacecraft components will be labor intensive   R EFERENCES    N. Vanderm ey and B G. Paczkowski 223The C a ssi ni Huygens Mission Overview,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Andrew M i shki n and B a rbara Larsen 223Im p l e m e nt i ng Distributed Operations: A Comparison of Two Deep Space Missions,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006 3 Barb ara Larsen 223Bu ilt Bu t No t Used Need ed  Bu t No t Built: Ground System Guidance Based On CassiniHuygens Experience,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Spi l k er, Li nda J \(edi t o r o  a R i nged Wold\224,NASA SP-533, 1997  Jennifer Long Maxwell, W illiam M Heventhal, III, and Shahram Javidnia, \223The Cassini-Huygens Sequence Development Process\224, 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Paczkowski  B G, \223C assi ni Sci e nce Pl anni ng Process\224 2004 AIAA SpaceOps Conference Proceedings, May 17 21, 2004 200  Recognize that lack of margin in any resource required for science return will require compensatory staffing. Pr edefined, prevalidated options for resource management such a power modes can compensate. Tools that validate resource allocation are essential 200  Anticipate alternative costs for failing to meet MOS development schedules. The ground system needs to have reached sufficient maturity to support key operations tasks before those tasks commence 200  Distributed science operations introduces delays and complications to sequence development, which must be managed in science planning. System engineering will need to deal with overlap in and conflict between ground systems 200  Acknowledge that complexity in any form\227 spacecraft design, science objectives, MOS architecture\227may be managed to enhance science return but the science planning operations must be funded and structured to manage that complexity The processes to develop science commanding will be lengthy and highly iterative In the end, with an appropriate funding profile, adequate and timely staffing, and effective processes and tools all the facets of mission complexity can be managed to extract amazing science return 8  A CKNOWLEDGEMENTS  The authors would like to acknowledge the dedication and hard work done by the Cassini-Huygens Flight and Science Teams. Without their efforts the unrivaled science collected by the Cassini mission would not have been achieved This work was performed at the Jet Propulsion Laboratory California Institute of Technol ogy, under contract with the National Aeronautics and Space Administration  251 2008 California Institute of Technology. Government sponsorship acknowledged 


  13 B IOGRAPHY  Brian Paczkowski is currently the Deputy Section Manager of the Planning and Execution Section within the Systems and Software Division at JPL. Prior to that he spent 9 years as the Cassini Science Planning Manager responsible for the development and implementation of the Science Operations Plan. Prior to Cassini, he was the Science Planning and Operations Team Chief for the Galileo Mission to Jupiter. He has also been involved with the pre-launch development of the science instruments on Galileo, Comet Rendezvous and Asteroid Flyby \(CRAF\ and Cassini missions. He has a BS in Astronomy from Villanova University and did graduate studies in Astronomy at Ohio State University  Barbara Larsen  is the Mission Operations System Engineer for the Cassini Mission. She is also on the science planning staff and previously worked in system engineering for the Mission Sequence Subsystem. She has a MS in Mathematics from California State University Long Beach and a BS in Mathematics from USC Trina Ray  is currently the Titan Orbiter Science Team \(TOST\ co-chair and the Science System Engineer for the Project Scientist for Cassini. She has been working on the Cassini Mission since before launch as an instrument operations lead for the Radio Science Team, and then as part of the Science Planning Team supporting Titan integrati on and sequence development She has a MS in Astronomy from San Diego State University and a BS in Physics, Astronomy option from CSUN  


  14  


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



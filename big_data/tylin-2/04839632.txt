  1 Web Services for Multiplatform Exploratory Analysis of Level 2 and 3 NEWS Merged A-Train Data  Hook Hua 818 hook.hua@jpl.nasa.gov Eric Fetzer 818 eric.j.fetzer@jpl.nasa.gov Amy Braverman 818 amy.braverman@jpl.nasa.gov Seungwon Lee 818 seungwon.lee@jpl.nasa.gov Mathew Henderson 818 matthew.henderson@jpl.nasa.gov Steven Lewis 818 steven.j.lewis@jpl.nasa.gov Van Dang 818 van.dang@jpl.nasa.gov Manuel de la Torre Juarez 818 manuel.delatorrejuarez@jpl.nasa.gov Alexandre Guillaume 818 alexandre.guillaume@jpl.nasa.gov Jet Propulsion Laboratory/California Institute of 
Technology, 4800 Oak Grove Dr ive, Pasadena, CA 91109   Abstract 227To simplify access to large and complex satellite data sets for climate analysis and model verification, a service-oriented architecture-based tool was developed to help study long-term and global-scale trends in climate water and energy cycle, and weather variability. NASA\222s ATrain satellite constellation set of Level 2 data can be used to enable creation of climatol ogies that include correlation between observed temperature, water vapor and cloud properties from the A-Train sensors. However, the volume and inhomogeneity of Level 2 data have typically been difficult or time consuming to search and acquire. This tends to result in small-scale or short-term analysis. Instead of imposing on the user an often rigid and limiting webbased analysis environment, we recognize the need for well 
designed distributed services so that users can perform analysis in their own familiar computing environments Voluminous merged Level 2 data containing the various instrument data from the ATrain have recently been generated. Scientists next want to efficiently access selected sets of this merged data and perform their analysis. Serverside capabilities were develope d to off-load processing and reduce the amount of data to be transferred to the client Correspondingly, client-side processing APIs were developed to enable scientists to perform analysis of voluminous server-side data from within their own familiar computing environment \(Java, Python, Matlab, IDL C/C++, and Fortran90 12  T ABLE OF C ONTENTS  1  I 
NTRODUCTION 1  2  NEWS  L EVEL 2  D ATA O VERVIEW 2  3  A PPROACH 3  4  M ERGING THE A-T RAIN D ATA 4  5  D ATA S ERVICES A RCHITECTURE 5 
 1  1 978-1-4244-2622-5/09 25.00 \2512009 IEEE 2 IEEEAC paper#1605 Version 3 Updated 2009-01-09 6  E NDPOINT S ERVER D EVELOPMENT  6  7  C LIENT I MPLEMENTATION FOR A NALYSIS E NVIRONMENTS  11  8  NEWS  L EVEL 2  
P RODUCTS  12  9  NEWS  L EVEL 3  P RODUCTS  13  10  A NALYSIS R ESULTS  14  11  R ELEVANT W ORK  16  12  C ONCLUSIONS  17  12  F UTURE 
W ORK  17  R EFERENCES  18  B IOGRAPHY  19  1  I NTRODUCTION  Scientists routinely perform conditional subsetting and summarization on Earth science Level 2 data \(geophysical state derived from directly observed radiances\n order to capture the trends and correlations hidden in the voluminous data and to feed the data into their global models. Recently, a NASA and Energy and Water cycle Study \(NEWS st ar ted to create a merged Level 2 data set containing information from multiple instruments 
of NASA\222s A-Train satellite constellation in a common spatial and temporal resolution. However, the immense volume and inhomogeneity of Level 2 data from a large number of instruments restrict the analyses to small-scale and short-term scopes. Level 3 data, where geophysical parameters that have been spatially and/or temporally summarized from Level 2 data, are currently produced in advance and have limited selections so that a majority of scientists develop their own tool to customize Level 3 data from Level 2 data. This results in redundancy of work in the community and the dwindling use of Level 3 data available in NASA\222s distributed active archive centers Existing data access approaches require manual FTP-like or web portal interaction and therefore force the scientist to 


  2 break away from their familiar data analysis environments Our targeted services aim to bring seamless data interconnectedness back into their multiplatform working environments. By developing distributed components in a multitude of programming environments commonly used by scientists, it will improve scientific data discovery, access delivery, and manipulation. This enables streamlining of scientific data processing and analysis by minimizing the manual intervention previously required and bringing the new capabilities into the scientist\222s familiar working environments. The programming environments supported include Java, Python, IDL, Matlab, C/C++, and Fortran90 This enables a higher level of capability through seamless data search, access, processing, and analysis. These services can be used to analyze A-Train sensor data in order to investigate long-term and global-scale trends in climate water and energy cycle and weather variability. Previously there did not exist a capability to discover and access data from the A-Train\222s multiple instruments as merged multiparameter data sets This paper discusses how we applied service-oriented technologies to facilitate the discovery, access, and custom hydrological analysis for studying long-term and globalscale trends in climate, water and energy cycle, and weather variability. We will discuss the voluminous and inhomogeneity nature of the merged A-Train instrument dataset. We will then show our approach that addresses the accessibility issues related th is data. This includes the architectural view as well as both server and multiple client side approaches. It then descri bes the services developed for the NEWS merged data for averaging, subsetting, and statistical summarization. Finally, we present a result using the services for an interc omparison between different instrument data 2  NEWS  L EVEL 2  D ATA O VERVIEW  A-Train Our services leverage data from the suite of sensors in the NASA\222s A-Train satellite constellation that is collecting detailed, simultaneous observations of atmospheric state over a period of years and decad es. The A-Train consists of a series of satellites flying in formation crossing the equator within a few minutes of one another in the \223Afternoon\224 around 1:30pm local time. It consists of Aura, PARASOL CALIPSO, CloudSat, Aqua, and soon OCO \(figure 1 Aqua for example, carries the Atmospheric Infrared Sounder \(AIRS\instrument \(which can detect water vapor and temperature\the Advanced Microwave Sounding Radiometer for \(AMSR-E rument \(which can detect cloud liquid water information\and the Moderate Resolution Infrared Sounder \(MODIS\instrument \(which can detect cloud top heights  Figure 1. The Afternoon or "A-Train" satellite constellation consists of the satellites flying in formation Aura, PARASOL, CALIPS, CloudSat, Aqua, and soon OCO  NEWS The NASA and Energy and Wa ter cycle Study \(NEWS project led by Dr. Eric Fetzer \(a Co-Investigator of this project\has been generating a merged Level 2 \(L2 containing information from the A-Train instruments in a common spatial and temporal resolution. The L2 data set of the A-Train constellation of satellites is very large and we are not aware of other reasonable approaches to formally summarize the data as the one presented here NEWS Level 2 data contain temperature, atmospheric water vapor, cloud fraction, cloud-top temperature and pressure Table 1. Water quantities and instruments in the A-Train Quantity Instrument Across Track Coverage Vertical Resolution Temperature AIRS 1500 km 1 km Lower tropospheric water vapor AIRS 30 points 2 km Upper tropospheric water vapor Combined AIRS and MLS 1 point 2-4 km Stratospheric water vapor MLS 1 point 4 km Cloud fraction Cloud-top temperature and pressure Combined AIRS and MODIS 90 points 1 km Cloud liquid water Combined AMSR-E and CloudSat 1 point 1 km Cloud-ice Combined MLS, AMSU, and CloudSat 1 point 2-4 km 


  3 cloud liquid water, and cloud water ice data from several ATrain instruments and CloudSat, summarized in table 1 Temperature field data are taken from Atmospheric Infrared Sounder \(AIRS\icrowave Limb Sound \(MLS 2 data. Atmospheric water vapor data are also obtained from AIRS and MLS. Cloud fraction and cloud-top temperature and pressure data are taken from AIRS and Moderate Resolution Infrared Sounder \(MODIS\loud liquid water data are collected from Advanced Microwave Sounding Radiometer for Earth Observ ing System \(AMSR-E sources of cloud water ice data are Advanced Microwave Sounder \(AMSU\SR-E, MLS, and AMSU-B. Cloud ice and liquid water content data are also obtained from CloudSat. The physical parameters from A-Train instruments and CloudSat are merged and placed on a common, regular, nested spatial grid through appropriate interpolation schemes depending on the quantity. The errors in each data source and the mapping are estimated 3  A PPROACH  Our emphasis is to enhance the accessibility and analysis of the merged NEWS data by providing commonly used services and facilitating more seamless data access for users. Current popular processing done by the NEWS science community includes performing averages and subsets of the merged data for further analysis. A statistical summarization service is also being developed to help analyze the correlations between the observed atmospheric quantities Data To enable the science objectiv e of creating climatologies that include correlation between observed quantities requires the use of merged data from the A-Train sensors Collectively they provide a detailed record of observations of temperature, water vapor and cloud properties across multiple instruments.  The A-Train data record created was specifically designed to preser ve the critical instantaneous relationship between highly variable atmospheric water components. However, no methodology has been previously developed to comp rehensively characterize the variability, and covariability, of global satellite observations from any source.  We addressed this shortcoming by applying a well-established statistical summarization technique to this data set, and describe multi-year behavior of in the A-Train observations Services These set of products are being generated either offline or by on-demand services and delivered seamlessly to users As shown in figure 2, the A-Train set of Level 2 instrument data \(AIRS, MODIS, AMSR-E, MLS, and CloudSat.\are being merged offline to create a merged product that preserves the relationship of observed atmospheric water properties. An on-demand averaging service is offered to create custom global-scaled averages as NetCDF products Care was taken to allow creation of yearly, monthly weekly, daily, and hourly averages. More specifically, the monthly averages follow the calendar months \(as opposed to fixed 30-day months\o capture trends typically studied by the atmospheric community. An on-demand subsetting service was also developed to create custom subsets of the merged Level 2 data matching the temporal and spatial constraints of the user. A subset of the parameters of interest can also be specified in the generated NetCDF products  Figure 2. The NEWS data products and Web Services To support this set of offline and on-demand services required the development of Web Service endpoints that handle the remote invocations for the processing and data access. Emphasis was placed on the client usability where we want to infuse direct Web Service interaction with the server endpoints seamlessly into a multitude of analysis environments Emphasis was given to the needs of the scientists to enable them to discover and access multiple instrument data for their research. We developed client-side modules that fit into the needs of the scientists, while still leveraging the remote processing services on the server. Since the server contains and has access to a large volume of data delegating the search and processing of long-term and global-scale data to the server would be more beneficial This avoids needless and repeated downloading of massive amounts of data by various clients to perform potentially the same processing. Additionally, by providing a rich set of client-side APIs in a variety of popular analysis platforms we can facility \223exploratory computing\224 where scientists can serendipitously process, analyze, and explore the data A major benefit of utilizing Web Services is the true interoperable nature of its implementations. We developed one set of server-side Web Services, and multiple sets of client-side services that can in teract with each other. This enables the reuse potential of the science processing from 


  4 multiple heterogeneous environments and from multiple different implementations 4  M ERGING THE A-T RAIN D ATA  To support hydrological analysis for studying trends in climate, water and energy cycle, and weather variability requires access to the various instrument data from the ATrain. A merging of the data from the multiple instruments into one collective data product is the first critical step for long-term and global-scale studies Creating Merged Data Products Formalisms for creating a merged data product from two component data sets are described in and [3 The merged product using these methods is essentially an error and resolution-weighted mean of the input data sets, with associated uncertainty estimat es.  These techniques require footprint-by-footprint information about component data set errors in the case of [3] or retrieval averaging kernels for   Furt herm ore t h ese m e t hods assum e t h at ret r i e val bi ases are very well quantified or have been minimized through a well-formulated retrieval algorithm.  Consequently, a formal merged product requires component data sources from well-understood and validated sources.  Importantly the component data sources must contain detailed information about retrieval uncertainties, and contain minimal or well-described biases In our work we are planning to create merged data from two source instruments: AIRS and the Microwave Limb Sounder \(MLS\S has been functioning since September 2002, and MLS was launched in July 2004, and has the legacy of a similar instrument flown on the Upper Atmosphere Research Satellite beginning in 1991.  Because AIRS and MLS fly in NASA's A-Train satellite constellation, their observations are collocated in space and differ in time by only about 8 minutes \(figure 1\ The observations from these two instruments are validated, and their relative uncertainties for temperature [4 d water vapor  acterized.  Consequently, we are planning to provide merged temperature and water vapor fields from MLS and AIRS.  The resulting products will have vertical resolution extending from the surface into the middle mesosphere.  They will consist of single fields of temperature and water vapor, without direct reference to the source instruments Sorting Data into Latitude/Longitude Boxes The merging techniques that ar e employed require that each data point be sorted into a lat/lon box, where the size of each box is adjusted by the 223increment\224 variable.  The change in the size of each box along the latitude and longitude currently is not inde pendent of each other.  At each data point, the latitude a nd longitude value associated with it has been converted to the center of the box that is closest to it in order to determine which set of values should be averaged together.  Th e algorithm is as follows lat_center = floor\(LAT/increment\increment+increment/2 lon_center= floor\(LON/increment\*increment+increment/2 where \223increment\224 is the size of each lat/lon box in degrees LAT and LON are the latitude and longitude of the data point, and lat_center and lon_center are the center of the boxes .  This basically translates to lat_edge <= LAT < lat_edge + increment lon_edge <= LON < lon_edge + increment The data set has \223increment\224 equaling 0.5 degrees.  Not only does the data have to be regridded spatially, but it has to be regridded temporally as well.  Since each data point has a time associated with it, when it is regridded spatially the timing of each data point is also merged.  The tracks of each instrument cross each othe r at the poles and at other regions within a day. This leads to a temporal regridding of many hours, but is prevented by regridding within a 90minute track so that track crossings do not occur AIRS Currently, the AIRS data consists 1  temperature profile 2  temperature profile error estimate 3  water vapor profile 4  water vapor profile error estimate 5  total water vapor 6  total water vapor error estimate 7  cloud fraction 8  cloud fraction error estimate 9  cloud top temperature 10  cloud top temperature estimate These quantities are not averag ed within a lat/lon box Since the regridded boxes are at 0.5-degree resolution and AIRS resolution at the equator is similar to that, the nearest neighbor technique was employed so that the AIRS data was very much unchanged.  The data deviating from that technique are the cloud fraction and cloud top temperature Since they both come at a sma ller resolution that is the size of the AMSU footprint, and not the AIRS footprint, it is about 9 times smaller.  The 9 data points for each AMSU footprint approximately equaling one AIRS footprint is 


  5 averaged, then it is treated in the same manner as the other variables, subjected to nearest neighbor method for regridding. Only valid data values are averaged together All the data have been filtere d according to how the level 3 AIRS data products are filtered AMSRE The AMSRE data comes already on a regular grid of 0.25x0.25 degrees.  The data products are 1  total water vapor 2  standard deviation of total water vapor 3  number of data points of total water vapor within each regridded box 4  cloud liquid water 5  standard deviation of cloud liquid water 6  number of data points of cloud liquid water within each regridded box 7  sea surface temperature 8  standard deviation of sea surface temperature 9  number of data points of sea surface temperature within each regridded box 10  rain rate 11  standard deviation of rain rate 12  number of data points of rain rate within each regridded box All of AMSRE data are aver aged within each regridded box. Only valid data values are averaged together to derive the data products with their standard deviation and number data points MLS The MLS data products are 1  water vapor profile 2  water vapor profile error estimate 3  total ice water content 4  profile ice water content 5  profile ice water content error estimate The MLS data products were converted to reflect measurements comparable to AIRS\222 standard levels.  For ice water content profile, it was converted to a layer quantity and summed up in order to get the total ice water content from pressure levels of 237.1378 mb \226 61.89647 mb.   The precision estimate was calculated according to the MLS recommended method.  The water vapor profile was converted from a level quantity to a layer quantity matching AIRS standard pressure layers.  The same technique was applied to derive the error estimate for water vapor profile CF-Metadata The generated merged product contains measured quantities from various A-Train instruments. But to maximize interoperability of data access, we adopted the climate and forecast \(CF\e conventions define what each da ta variable represents and its temporal and spatial properties. This enables a consistent set of comparable properties among different data sources and visualization tools that support the CF conventions. The CF conventions have been gaining acceptance by various projects and groups, including the NASA Earth Science Data Systems Worki whi c h have representations from the various major Earth science data centers 5  D ATA S ERVICES A RCHITECTURE  The merged NEWS Level 2 data being generated by Fetzer\222s NEWS project are uploaded to the NEWS Data Information Center \(NDIC r distribution to the NEWS science comm access limitations only allow SFTP access of the data on the NDIC server with no central data catalog. This mechanism precludes other programmatic forms of automated data access. Figure 3 below illustrates the manual approach and the redundant processing that results from independent client-side processing of the same set of data  Figure 3. Older limited access capabilities from SFTP 


  6 only access to NEWS merged Level 2 data. Illustrates the redundant and non-reusabl e processing of manual data access  We leveraged Service Oriented Architecture \(SOA technologies to avoid the redundant downloading and processing of the voluminous data sets by promoting serverside processing and client-sid e data access. Our services enable scientists to customize the conditional subsetting of voluminous NEWS Level 2 data and the production of Level 3 data using a customizable Level 3 Quantization data reduction technique. An implicit benefit of these services is the transparent data search and access mechanism that previously was done manually in a separate step. The services include a temporal and spatial query that searches for the merged Level 2 data that matches the user\222s given space-time constraints Enabling Distributed Exploratory Computing We understand that scientists routinely utilize their own trusted code and/or perform analysis in their own familiar working environments of choice. Rather than developing another web portal or new data access tool that forces the scientists to depart from their working environments, we developed service-oriented components that can be integrated into their own code environments \(figure 4 below\This facilitates the \223exploratory computing\224 that scientists are familiar with where they can remain fully in their analysis environment and serendipitously explore the data  Figure 4. Overview of th e distributed system for accessing and manipulating the merged NEWS data Multiple Web Service client s enable users to perform analysis directly within their familiar computing environments  By taking the proven Web Services-based approach, we ensure interoperability across different platforms and strengthen the interconnectedness and reuse of the Earth science data. This will not only promote actual use of service-oriented architectures, but also facilitate the streamlining of transparent access and manipulation of Earth science data from within scientists\222 own tools. For example, users can within th eir own Matlab analysis code call a function to get global-scale monthly averages of data in a given time period of water vapor. This seamlessly performs a remote query for all merged NEWS data on the server matching the space-time bounding box, and then averages by calendar month all water vapor data. The results are seamlessly downloaded to the user\222s machine from within the Matlab environment. The Matlab function call then returns with the data files that can immediately be used for analysis right within Matlab Data Storage Conventions The voluminous instrument and merged NEWS Level 2 data files that are stored on the server can potentially increase complexity in file access. Typically this can be addressed by indexing the files with a crawler that populates a searchable database. Earth sc ience data systems have also tried creating in-house crawlers that populate scalable database such as the open source MySQL and PostgresSQL Others have also tried using the open source Lucene search engine for fully i  Regardless of data files being index and cataloged additional methods can be applied to increase file access performance. We store data files following a consistent file and path-naming scheme where data files are located under directories for instrument names, year, month, and day From this approach, one can generate the full file path location of the data given just the data\222s type and timestamp. When reading the f iles for processing, no search is then required to find the corresponding set matching a temporal range 6  E NDPOINT S ERVER D EVELOPMENT  A set of proven SOA technologies have coalesced into the Web Services Protocol Stack. Built upon common web standards, Web Services can ensure interoperability in a distributed environment. Additionally, the proliferation of open source implementations adhering to these standards ensure that we do not get lock ed-in with a specific vendor\222s proprietary implementation. We utilized this set of proven protocols to create our distributed architecture for Level 2 and Level 3 data processing We also leveraged the proven Simple Object Access Protocol \(SOAP\ng platform-independent XML messages over a distributed network environment Using SOAP enables platform-independent Remote Procedure Calls \(RPC ws us to create interoperable remote method calls to the backend data processing of subsetting, clustering, and summarization. One major benefit of SOAP is its ability to work over various transport 


  7 protocols, though http/https is the most common and versatile With SOAP enabling the calling of remote methods, we also create Web Services Description Language \(WSDL\XML documents that define each of the exposed interfaces WSDL provides a programmatic way to define the public interface names, arguments, and re turned information that is independent of the underlying platform, programming language, and therefore native data types Collectively, this set of Web Services protocols enables us to develop an architecture that promotes reuse at the service level rather than code level. SOAs facilitate the exposing of legacy processes as reusable services. We first developed an averaging service of the merge NEWS Level 2 data Averages are easily understandable from the science community and are an immediately useful capability to provide. Then leveraging the same infrastructural developments, a subsetting service created, followed by an offline Level 3Q quantitative summary service We took a layered architecture approach where each layer is responsible for a well-defined role. Figure 5 below shows an example for the averaging service that takes as input the set of merged A-Train Level 2 data and produces globalscale averages of a specific time range  Figure 5. The layered architecture of the Web Service clients and Web Service endpoints  Web Service Endpoints To maximize interoperability between all of our multiplatform clients, we want to utilize more standards compliant implementations of Web Services. Sun\222s Java API for XML Web Services \(JAX-WS\has a reference implementation that supports JAX-WS 2.0/2.1 \(JSR 224 WS-I Basic Profile 1.1, WS-I Attachments Profile 1.0, WSI Simple SOAP Binding Profile 1.0, WS-Addressing 1.0 Core, SOAP Binding, and WSDL Bindi  With JAX-WS, we were able to quickly develop Web Services endpoints utilizing Java annotations that generate much of the boilerplate code. By marking Java code with metadata annotations, JAX-WS was able to generate both client and server code that performs much of the SOAP functionality. JAX-WS also includes JAXB that performs the datatype marshalling/unmarshalling to and from SOAP XML representations Processing Layer Naturally there may alread y exist tested and proven processing code that scientists want to make available as a service. We require the ability to wrap into a Web Service executables that were developed in IDL, Matlab, Python native C/C++, and Fortran. By executing this layer as a forked process, the Web Services layer is shielded from process and memory issues related to the processing code Unstable processing code should not bring down the Web Services as well We developed Java-based abstractions that exposed the generic interaction to IDL, Matlab, Python, and C. By defining a domain neutral interface to each of these platforms from Java, we were ab le to quickly integrate any domain-specific processing code into the Java environment 223Business Logic\224 Model Layer To reduce the complexity of interacting with the processing layer, we developed a \223business logic\224 model layer that defines an interface to a model representation of the processing. This allows us age of the model interface without having to know specifics of interacting with the lower-level process execution mechanism. An example of this benefit would be replacing a current IDL processing engine with a Matlab varian t, where the model interface would not need to be modified Invocation Sandboxes To avoid conflicts arising from near simultaneous service calls, it became clear that each service request must be given its own process environment and directory space within which to work.  Every new invocation of a Web Service creates a sandbox environment on the server that serves to house the working environment for that endpoint invocation.  Each sandbox is given a unique name that corresponds to the specific service being requested, the unique date/time timestamp, and a process id. This ensures that each sandbox is unique and avoids the possibility of process collision. The invocations sandboxes are automatically removed when a service is done. Any data that needs persistence are moved out of the sandbox to more permanent directory locations Long Processing Times Unlike commonplace Web Services such as those for getting stock quotes, the processing services presented here 


  8 often have long run times. Depending on the temporal and spatial range of data requested, processing wall-clock times may range from minutes to weeks. The notion of a service call changes from a quick \223getting\224 of a data product, to an 223ordering\224 of a product. The normal synchronous aspect of the services must then be changed to an asynchronous model Job Management Additionally with long-running services, there will inevitably be overlapping processing times on the server Therefore given the finite computing resources available overloading the computational resources with simultaneous service requests should be avoided. We require the ability to define the appropriate level of computational resources to be utilized and want any remaining service requests to be queued until sufficient computing resources are available This then maximizes processo r utilization of each service request Distributed resource management \(DRM\stems can be leveraged to manage the distribution of workload to available compute resources Each Web Service request would map to a job request on the processing server. DRMs can monitor the current state of all resources and assign the jobs to the best-suited resources Rather than directly interfacing with one specific DRM implementation, we leveraged the Open Grid Forum\222s Distributed Resource Management Application \(DRMAA pronounced \223drama\224\API for job submission, monitoring control, and retrieval of resu lts Thi s l a nguage and vendor agnostic API frees us from language specific implementations, as well as vendor specific implementations of job management, and allows us to focus on the abstract representation of resource management This API is supported by several different vendors of job scheduling implementations, including Sun Grid Engine SGE and Torque.  Though bot h Torque and SGE fi t  our requirement of an open source scheduler, Torque is still based on an older PBS implementation and does not offer the scalability and Java bindings that SGE does Asynchronous Services By default, a Web Service call is a synchronous call where a request is sent from the client to the server and blocks until a response is available to be sent back to the client \(figure 6\ut for long running processing routines, it is impractical to hold a network connection and block until the service has completed. A scientist on the client side may not be able to wait for the response after a completed longrunning job. We want to enable complete network disconnects where the client may be potentially shut down Additionally, service calls where seamless data access is intrinsic would require the gene rated data to be downloaded as well before the service call unblocks and completes. The client user would have to wait for both processing and downloading times There have been extensions to existing web services-based standards to augment with asynchronous capabilities. WSNotification, a standards-base d approach to enable eventdriven capabilities to Web Se rvices using the publishsubscribe pattern. OASIS\222 Web Services Notification WSN\ses this notification pattern to allow subscribing to a Web Service\222s event information and be notified of such information. OGC\222s Web Pr ocessing Service \(WPS spatially referenced data have been augmented with  OGC\222s W e b Notification Service \(WNS\so provides messaged-based notifications between services. By using client-side modules, each web service client can receive notifications without resorting to polling. However, all of these approaches require a richer set of clients that may only be available in Web Service-rich language platforms such as Java. Our goal requires that our asynchronous solution work in more simpler and less rich platforms such as C and IDL What we desire is a simpler approach that minimizes clientside requirements of running any form of a messaging server. Preferably, the solution should be simple enough to work with clients that have a minimal capable of doing HTTP GET, such as a basic REST service call  Figure 6. Sequence diagram showing potentially long blocking calls for long processing times from Web Services Asynchronous Services using Web Services A more desirable model of behavior would be to use Asynchronous Web Services \(figure 7\he one synchronous blocking call is par titioned into smaller atomic Web Service calls. The Apache Axis2 project and Sun\222s JAX-WS Reference Implementation provide a set of asynchronous atomic calls that allow a service client to submit a service, check if it is done, and then get the results 


  9 when it is done. However, even this model does not fit the desired model of behavior  Figure 7. Sequence diagram showing the push and pull methods from Asynchronous Web Services  Asynchronous Web Services can use either a Synchronous or Asynchronous MEP \(Message Exchange Protocol transmitting and receiving protoc ol messages.  There are two methods supported for both synchronous and asynchronous MEP types:  polling and callback. Both support non-blocking client side behavior The polling method represents the \223pull\224 model of processing where the client determines when the response is received.  The callback method has the client passing a callback handler to the Web Service Endpoint. This callback is essentially an endpoint on the client side running in a separate thread that waits for the server to respond.  The callback method represents the \223push\224 model of processing where the server determin es the notification For polling-based asynchronous MEP, we find that the client still needs to be active while it polls. That is, a service submission would normally return a response object that is used to check if the job is done. That same response object is also used later to retrieve the results when available. For long duration processing times, the client must still maintain the same response object. Though the response object may in principle be marshalled out for longer persistence implementation-specific network connection reliance be prove to be impractical. The preferred approach would be to move the role of asynchronous waiting from the Web Services request/response objects down further to the job scheduler The remaining option would be to use normal synchronous Web Service calls, but cleanly se parate the different atomic operations into individual synchronous Web Service calls These individual calls consists of submitting a job canceling a job, getting the status of the job \(running cancelled, etc\ting the progress of the job \(console output, etc\and finally getting the results of the job \(figure 8\ Each synchronous call is then delegated to an underlying job manager for the actual service job management. Collectively, the client is provided with an asynchronous service model For particularly long running service jobs, we find that users also want to see progress of the processing activity. In addition to getting the status of the job state \(such as queued, running, done, cancelled\so provide the capability to see progressive real-time output form the processing job. Our service endpoint manages a console buffer of a processing job\222s STDOUT/STDERR. When a Web Service call to get the progress of a particular job is invoked, the current buffer contents of the progress is returned and then flushed from the server-side buffer. This enables clients to build GUI applications on top of this asynchronous service and see the real-time console output of the server-side processing on their client GUI window Additionally, the console refresh rate, determined by the client, can be adjusted to an appropriate rate for that client\222s usage. Other approaches are possible including publishing the progress to a custom Atom feed. But here, the console content is only handled and retrieved when the client needs it  Figure 8. Sequence diagram showing atomic synchronous calls that implement job management capabilities of a service  Though callbacks \(registerable handlers\ally the preferred paradigm over polling, this client example demonstrates the utility of keeping it simple. We require maintaining a set of lightweight Web Service clients across multiple platforms. Not all platforms and Web Service APIs support asynchronous Web Services. For true callbacks 


  10 implementations would also require the clients to run Web Service endpoints of their own This asynchronous service model that is composed of synchronous atomic Web Service calls can also be used at varying levels of complexity as desired by the client user For the novice, the service \223submit-isDone-get\224 sequence can be encapsulated into one simple function call. For the intermediate user, the same aggregated function call can also provide real-time notifications \(Observer design pattern\job currently running on the server. For the advance user network disconnects and client shutdown after a service job has been submitted can be achieved. The unique job id that is returned upon service submission can be stored for persistence enabling users to submit a product request from laptop, shutdown their laptop, and restartup at later time to retrieve the generated products Using AXIS2 and JAX-WS for the various client-side implementations introduces an extra dependency for users of some clients and therefore is less preferable. We also want to maximize ease-of-use for the user where we lessen the burden of installation, set up, and library dependencies Whenever possible, we used the \223vanilla\224 SOAP implementation that is intr insically available for each platform to keep the client footprints small Another intended use of our services is to be orchestratable by Web Services-enabled workflow engines. The callback approach to asynchronous Web Services is currently not as interoperable as standard synchronous Web Services However, current Web Service workflow engines can be set up to operate with standard Web Services that have the atomic actions exposed as multiple synchronous Web Service calls that poll for when a job request is done before continuing Data Delivery Once processing has completed, the service response is returned to the user. In th e Earth science domain, these results typically are generated data products that may be large in size. Given that the SOAP approach to Web Service uses XML as the underlying content being transferred transferring binary data in the SOAP message would not be efficient for large binary data sizes. Large binary file data support in XML currently still exhibits technical and performance issues. Approaches ex ist to encode binary data in various encoding schemes such as MIME and base64 More recently, there have b een new W3C recommendations for handling large binary data transfers such as XML-binary Optimized Packaging \(XOP Transmission Optimization Mechanism \(MTOM and Resource Representation SOAP Header Bl  However these new extensions may not be supported or compatible with all the client platforms that we need to support \(such as Matlab, IDL, and Python We settled on an approach that is compatible across the major client platforms. Rather then forcing data to be encoded in any scheme in SOAP, we simply allow the binary data to be transferred efficiently in standard http/https. When a Web Service job has completed, the generated product data files are placed in a unique URLaccessible location, and these UR Ls are sent back in the service response. The clients are then responsible for downloading the product files from the URLs A side benefit of this approach is observed when orchestrating our services fro m workflows. The URL results from one workflow operator are passed onto the next operator, which then is responsible for pulling the data from the given URLs. This method allows each operator to control the rate of accessing th e previous operator\222s data results OPeNDAP Another mechanism we support for data access is Data Access Protocol  \(DAP\ore specifically, we leverage the  for requesting and transporting data that is generated by the services. OPeNDAP also enables remote subsetting of data using constraint expressions, and the translation of data from one format to another. HDF5 data has been recently shown to work well over OPeNDAP using the Hy  The OPeNDAP protocol in recent years has become more widely used and accepted in the Earth Science community The Earth System Grid \(ESG on Environment and Water \(CREW\two large Earth science data centers using OPeNDAP for data access Date Time Handling For time handling, leveraging the Java GregorianCalendar simplifies handling timezones, time ranges, as well as correct leap years.  The bus iness logic model layer fully leverages the GregorianCalendar model to allow us to support manipulating multiple time granules, from seconds to years, and of any duration for each time granule. There is also a related XMLGregorianCalendar that we leverage for representation of W3C XML Schema 1.0 date/time datatypes across the Web Services For averaging, given a particular start and end time in GregorianCalendar format, along with an integer time duration amount, the model is able to determine the correct time ranges \(i.e. number of averaged files\d partitions the work accordingly for the av eraging engine \(in this case the engine is IDL\anCalendar individual time elements are retrieved and passed on to the engine for 


  11 processing, and the result is a list of files that propagates up to the server side layer For subsetting, latitude and longitude values are handled at the model layer, and translated \(when necessary correct coordinate values for the underlying engine.  Also to reduce the number of parameters a user would need to provide, we support user inputs of date/time string using the ISO 8601 format, the International Standard for the representation of dates and tim For exam pl e t h e input string \2232008-10-31T12:00:00Z\224, would be converted into a GregorianCalendar inst ance representing that exact date/time for the model layer Using the combination of GregorianCalendar and the ISO 8601 standard allows us to easily handle timezone-aware and timezone-na\357ve inputs. Internally to our \223business logic\224 model layer, all date/times are timezone-aware and set to the UTC timezone to match most of the instrument data conventions. But if the user provides a timezone-na\357ve date/time, that is with no timezone specified, then we promote it to UTC standard time. We also support user input in any timezone here we leverage the GregorianCalendar to convert any timezone to the UTC internal representation This simplifies science studies where users simply provide the local time at the area of interest to query data for  7  C LIENT I MPLEMENTATION FOR A NALYSIS E NVIRONMENTS  We implemented client-side modules to adapt to the major working environments favored by most scientists: \(1 4\thon, \(5\/C++, and \(6 Fortran90. Unlike other approaches that force the scientists to leave their familiar working environment to access data our services tool set brings the data access and manipulation back into their working envi ronments. Whenever possible we also aimed to develop the ability to automatically download and construct the native data objects in each respectively environment. This eliminates the need for the end user to worry about data file downloads, local file management, and loading them into in-memory data arrays for manipulation. A consistent experience is given to the user, both across the different tools and across the different platforms, with common interfaces and usage conventions This form of seamless integration directly facilitates the transparent access and manipula tion of heterogeneous data as called for by NASA\222s ACCESS NRA goals Java The Java client was designed to be an importable jar library from any user Java application. Since the Web Service endpoint server was already written with Sun\222s JAX-WS Reference Implementation, we also chose the same for the Java client implementation. This maximizes interoperability since both client and server utilize the same library. The client contains high-level methods for calling the Web Service and automatically downloading the custom-created files, allowing the entire process of service querying and downloading data to be contained in a single method call Lower level methods are also exposed in the service allowing the user more fine-grain control over the data flow and interface with the Web Services Matlab Mathwork\222s Matlab is a popular working environment used by scientists to perform science analysis. The 2008 release of Matlab has built-in support fo r Web Services with autocode-generation from WSDL URLs. It leverages the Java integration that Mathworks has already worked into Matlab We leveraged this built-in capability to develop Matlab modules that access the same server-side Web Services for Level 2 and Level 3 data access and manipulation Our Matlab service client consists of a number of .m files file extension for Matlab custom code\and requires no Java package dependencies beyond the JVM native to the Matlab environment.  Built-in SOAP functions help to create, send, and parse the SOAP message, which is used to communicate with our remotely hosted Web Services For automatic data file downloads, classes and methods standard with Java version 1.5 \(standard with Matlab 7.6 were used to access and download the files via http.  The resulting client allows all of the Web Services and downloading functionality to be transparent to a user Matlab supports the construction and handling of full Java data objects and the invocation of Java class methods directly form within Matlab. We made use of built-in functions that served as the bridge between a Matlab script and a SOAP service call \(createSoapMessage.m callSoapService.m, and parseSoapResponse.m\. These built-in SOAP functions in Matlab constrained us to passing a narrow range of Matlab data types due an incomplete set of Matlab datatype to W3C SOAP datatypes. Particularly the date-time and arrays of strings must be manually handled as more primitive types Two methods of datetime passing were settled upon.  One relies simply upon passing a tuple representation of datetime\227a number for the year, and others for the month, day hour, minute, and second.  While such a method worked well \(converting simple numerical data types\t was seen to be cumbersome and made for far less readable code to have to use six parameters to specify a single datetime.  We turned then using short char acter strings to represent datetimes, following the ISO 8601 standard.  Data type conversion of character strings between Matlab and XML is similarly easy as numerical types, and made for very concise and readable function calls 


  12 Passing arrays of strings required a retreat from any kind of array-like data structure.  Instead, a single, long string was created from an array of strings in Matlab, separated by a distinct delimiter \(a \223,\224 in this case\s single long string is passed through the service interface to the endpoint server, which then parses the string back into a list format before continuing on with the rest of the call sequence IDL ITT\222s IDL is another powerful visualization and analysis tool popular with the Earth science analysis community  Unl i k e M a t l a b, IDL \(as of versi on 7.0 have any built-in Web Services support. IDL can be made to speak the Web Services languages via an IDL-Java bridge delegating the Web Services capability to a linked Java library.  This does allow calling the Web Services, but there were some issues encountered along the way First, the IDL-Java bridge connectivity required some setup and handling by the end user. Environment variables and jar classpaths must be properly configured. While this is easily resolve with an installer, there was a strong desire to minimize the IDL client foot print to where there are no dependencies. We wanted to provide an IDL client code that could be dropped into a directory somewhere and should \223just work\224 Second, there are some known issues working with objects in IDL. We encountered memory errors during execution which appeared to be a memory leak in the IDL-Java bridge there was previously a known memory leak that had been patched\also ex tra overhead when interfacing between IDL and Java where data is converted from Java objects to IDL types Our current effort is focused on building a \223poor man\222s\224 SOAP as part of our IDL client that will allow us to directly call and interface with the Web Services, without having to go through Java.  We plan to utilize IDL\222s built-in simple http support to send manually constructed SOAP messages Though this approach forgoes the robustness of the JAXWS implementation, it will however provide a pure IDL client to our end users with no external dependencies Python The Python scripting environment has become a popular working environment for fast prototyping and exploratory science processing. Among all of the clients here, the Python Web Services client is the most trivial. We leveraged the suds package, a lightweight SOAP client for consuming Web Services in Pyt Though ot her open-source Python Web Service packages exist \(such as ZSI\we have found suds to be the most easy to use and more dynamic in nature. Suds does not require class code generation and can read WSDLs at runtime to dynamically construct a proxy object with an interface representing the WSDL C/C We want any C/C++ client to be able to interact with the server-side Web Services of Level 2 and Level 3 data generation. By using the using the popular open-source gSOAP Toolkit for SOAP Web Services package  client-side modules can interact with the data generation services developed on the server-side. gSOAP also includes facilities to autogenerate C/C++ RPC code from our published WSDL definition files of the Web Service on the server. We have also found that gSOAP has a good selfcontained XML bindings facility Fortran Fortran90 modules can be made capable of remotely accessing and the Level 2 and Level 3 data. Though Fortran has no built-in libraries to perform Web Services, we leveraged our C/C++ Web Service API via gSOAP to do the work. Fortran can call an 223externed\224 C Web Service API and pass back the relevant data into the Fortran environment. This would enable Fortran to fully delegate the Web Services operations to the C/C++ implementation 8  NEWS  L EVEL 2  P RODUCTS  With the availability of the software infrastructure supporting server-side processing, and seamless client-side data query and access, downstream data products can now be generated from the source merged NEWS Level 2 data Averaged One of the most common wa ys to summarize the large amount of data is to calculate the averages of data within a given temporal and spatial boundary. For example, it is very useful for scientists to make daily, weekly, monthly averages of some parameters in a regular latitude-longitudepressure grid, make a global map of the average, and analyze any global patterns and trends. In order to facilitate the needs, we developed an averaging Web Service to generate averaged data products that a user can customize The input arguments for the averaging Web Service are the time range, time granule, and a list of parameter names to produce averaged products with. The time range specifies the start and end time to access the NEWS data from. The time granule specifies the aver aging time period. The list of parameter names specifies the choice of parameters that are requested to make averaged products Subsetted Subsetting a data set is a fundamental way to access specific data from a large collection of data. We developed a usercustomizable subsetting Web Service that supports three general subsetting conditions 1  Spatial condition \(latitude, longitude, vertical range 


  13 2  Temporal condition \(e.g. from 2002-05 to 2002-07 3  Parameter selection \(e.g. te mperature and atmospheric water vapor only The combination of these three conditions allows a user to subset data in time, location, and parameter space 9  NEWS  L EVEL 3  P RODUCTS  Many of these quantities in NEWS L2 product interact through fundamental physical processes \(e.g. temperature affects cloudiness, and also the converse\ Consequently the observations should be treated as statistically separate variables, though traditiona l methods of summarizing satellite data do just that. We applied statistical clustering methods to a multiple-parameter set of observations from the A-Train instruments over the multi-year record. The resulting Level 3 quantitative summaries are made accessible through our serv ice-oriented tool Level 3Q Level 3Q data sets are statistical summaries of underlying Level 2 data. Like traditional Level 3 products they are 223gridded\224 in the sense that they provide a summary of Level 2 data belonging to space-time grid cells. These cells are typically defined as one or fi ve degree spatial regions over a time period of one or eight days, or one calendar month Unlike traditional Level 3 products, the Level 3Q \(L3Q grid cell summaries provide nonparametric multivariate estimates of the joint probability distributions of multiple geophysical parameters. Distribution estimates are derived from the underlying Level 2 data using informationtheoretic principles that balance the quality of the estimate against the amount of data reduction achieved  Figure 9. Raw and summarized data for one grid cell Raw data belonging to that grid cell can be listed in a data table with one row for each of N data points and one column for each variable \(here, two alternate representation: a scatter plot. In both cases each data point has weight 1. On the right are two representations of the compressed summary. The data table has K<<N rows and two extra columns showing cluster count and distortion. Counts are shown in the corresponding scatter plot by the bar heights  Data reduction replaces a larg e number of individual data points with a smaller number of representative data points and associated weights and quality measures. Figure 9 illustrates the basic concept. The idea is to treat a set of coincident measurement of different geophysical parameters for the same footprint as a multivariate vector, and collect all such vectors belonging to a given spatial-temporal grid cell as a set of points in high-dimensional data space. These data are partitioned into disjoi nt groups, called clusters, and we report the following statistic s for each: i\the centroid which is the representative, ii\he number or proportion of original data points assigned to it, and iii\the average squared distance between member data points and the centroid. This latter quantity is also called the cluster distortion The method that assigns data points to clusters is an adaptation of a signal-processing algorithm called Entropyconstrained Vector Quantizati EC VQ i s si m i l a r t o  the well-known K-means clusteri  Kmeans finds an assignment of raw data points to K clusters that minimize distortion. ECVQ finds an assignment that minimizes a quantity based partly on distortion, but also on the entropy of the probability distribution defined by the clustering. Entropy is a measure of information-theoretic complexity, and it is also well known that greater complexity is required to achieve lower distorti  ECVQ was originally proposed as a way of estimating this trade-off. The algorithm may find fewer than K groups as it attempts to balance the competing goals of fidelity to the original data and parsimony of representation.  This produces the smallest, or more properly, the least complex output data set that achieves a given level of fidelity to the original data. Our version of ECVQ is adapted in a number of ways for use as a massive data set reduction tool. These are described in detail in  and 26  W e  have al so previously employed our version of ECVQ to produce monthly summaries of Atmospheric Infrared Sounder data  The algorithm\222s output is best thought of as an estimate of the multivariate distribution of the data in a given space-time grid box. The original data have a distribution that puts probability  N on each multivariate data point, where N is the number of data points. ECVQ coarsens this distribution by collecting similar points into clusters, representing them by cluster centroids, and assigning probabilities N k k where N k is the number of point assigned to the k th cluster. In addition we also report the within-cluster mean squared error distortion\, which is a measure of the quality of the cluster representative as a stand-in for the original data assigned to it 1 N to cluster  


  14 10  A NALYSIS R ESULTS  AIRS, AMSR-E, MODIS and CLOUDSAT data have been merged into a dataset by the NEWS effort, and a framework of Web Services for averaging, subsetting and statistical analysis have been developed. Collectively it facilitates the data access and analysis of hydr ological processes. Here we present an example usage of instrument intercomparison Comparing Data Products Prior to Merging A necessary step in creating a formal merged data product is intercomparison of component data sets.  This ensures that the mutual random and systematic differences between the two data sets are quantified.  This approach does not provide information about absolute bias, which can be obtained only from comparisons with unbiased standard data sets.  For example, wate r vapor and temperature biases are typically constrained through comparisons with in situ observations as from radiosonde.  Such comparisons are usually the responsibility of the data provides, so the analyses described below assume some knowledge of satellite measurement biases An example of comparing component data sets is presented here with a single atmospheric state variable, in this case observed by AIRS \(Atmos pheric Infrared Sounder AMSR-E \(Advanced Microwave Scanning Radiometer for EOS\For this example five variables \(AIRS Total Water column, AMSR-E total water column, AIRS cloud fraction AIRS total water error estimate, AMSR-E liquid water path stemming from two different instruments \(AIRS and AMSR-E\pared and correlated The Atmospheric InfraRed Sounder \(AIRS\he Advanced Microwave Scanning Radiometer \(AMSR-E\are two instruments aboard the AQUA spacecraft. AMSR-E estimates water vapor over water surfaces and AIRS estimates water vapor over ocean and land. A map of the daily average of terrestrial water vapor column is shown in figure 10. This figure maps th e AIRS estimate of average total \(column\er vapor in mm during March 2003 at a spatial resolution of 1 degree in latitude and longitude  Figure 10. Map of averaged AIRS Total column water vapor for 2003-03   Figure 11. Scatter plot of monthly AIRS and AMSR-E column water vapor. AIRS and AMSR-E water vapor agree very well on the co incident locations  A similar a subset of AMSR-E water vapor over the ocean was prepared with our services and merged with the AIRS dataset at the same spatial and temporal resolutions. A scatter plot of the values estimated with AMSR-E is compared to the collocated va lue of AIRS in figure 11 Figure 11 also shows a red line to mark the location where all points should fall if the AIRS and AMSR-E estimates were the same. The figure shows a tendency by AMSR-E to estimate higher total water vapor than AIRS. However there are locations where AIRS does show higher values. A map of the averaged differences \(AIRS-AMSR-E\15 selected monthly means between the years 2003--2006 is shown in figure 12 This map highlights locations where each instrument tends to overe stimate compared with the other. Blue tones identify regions where AIRS estimates are larger than AMSR-E and shades of brown locate the regions where the opposite is true 


  15  Figure 12. Map of average differences over 15 months between AIRS and AMSR-R water vapor  Figure 12 highlights regions th at are characterized by different hydrological regimes. AIRS overestimates coincide with regions where cold western boundary currents cause frequent cold marine stratocumuli. AMSR-E tends to estimate higher total water vapor in regions characterized by warm sea surface temperatures and frequent convective activity. This result is consistent with previous comparisons    Figure 13. AIRS Total Cloud Fraction sum for 2003-03 Sum over all pressure levels AIRS is an IR measurement that cannot estimate water vapor in regions overcast with optically thick clouds. This property introduces a bias that depends on the cloud fraction. Figure 13 shows an estimate of the cloud fraction using a surrogate for cloud fraction over several AIRS pressure levels. It adds up the cloud fraction at the different levels \(because there may be overlaps, the sum over all pressure levels can be larger than one between the areas with large cloud fraction sums and large AMSR-E overestimates with respect to AIRS and vice versa, areas with the smallest cloud fraction sums coincide with the areas with large AIRS water vapor estimates A proxy for the "thickness" of the clouds in the overcast regions is the liquid water content of such clouds. The advantage of this proxy over others is that it also conveys information about the physical and hydrological characteristics of the scenes co rrelated with the differences Figure 14 shows a PDF of the differences as a function of AIRS water vapor and AMSR-E cloud liquid water path. A black contour line marks the change of sign in the differences. It shows that AIRS estimates higher total water vapor at low liquid water paths with a characteristic quasilinear increase between 5--20 mm. AMSR-E estimates larger total water vapor at 1 x 1 degree regions where the liquid water path is high. The pattern of the differences raises questions about why does AMSR-E estimates differ so quickly from AIRS at low water vapor contents and low liquid water paths  Figure 14. AIRS-AMSR-E differences \(in mm function of AIRS total water and AMSR-E cloud liquid water for the month 2003-03  


  16  Figure 15. AIRS-AMSRE differences as a function of AIRS error estimate over one day  AIRS has an error estimate of the total water vapor value that it calculates. The diffe rences between AIRS and AMSR-E are shown as a function of this estimate in figure 15 and very little correlation is found 11  R ELEVANT W ORK  Merged A-Train Level 2 Data A merged product that preserves the relationship of observed atmospheric water properties facilitates the hydrological studies by enabling scientists to get directly at the model data without worrying about the logistics of finding, collecting, and coordinating the measured quantities from different instruments. Previously there did not exist a capability to discover and access data from the A-Train\222s multiple instruments as merged multi-parameter data sets Enabling Orchestratable Service Workflows Our distributed service-oriented approach of loosely coupled services also enable s a higher level of reusability and orchestration with other services. Increasing numbers of workflow engines are already supporting Web Services as components/operators, which can then be orchestrated together into higher-level meta/virtual services SciFlo, a Scientific Dataflow Execution Environment, is a workflow engine that already supports assembling reusable SOAP Services, native execu tables, local command-line scripts, and codes into a distributed computing flow \(a graph of operators\8 SciFlo can u tilize o u r g en eric SOAP services as part of a larger coordinated data flow The Taverna Workbench is a free software tool for designing and executing workflows. Like SciFlo, it can orchestrate SOAP-based Web Services as components within a workflow. Taverna provides a visual editor to construct and edit the sequence of services in the workflow We have found that Taverna can dynamically introspect a given WSDL and construct the workflow component interface representing it Giovanni Giovanni, an acronym for the Goddard Earth Sciences Data and Information Services Cent er, or GES DISC, Interactive Online Visualization and Analys is Infrastructure, is a webbased tool to help visualize Earth science data  It  provides a simple and intuitive way to visualize, analyze and access vast amounts of Eart h science remote sensing data without having to download the data. Similar to the services developed here, it addresses the difficulties of traditional data acquisition and analysis methods by moving the complexity to the server-side Giovanni provides multiple in terface instances based on instrument and measurement ty pes. For example, the \223ATrain Along CloudSat Track Inst ance\224 can provide plots of vertical profiles of clouds, temperature, humidity, cloud and aerosol classification across the multiple instruments of the A-Train A distinction between Givanni\222s A-Train data and the data set in this paper is that we are using a formal merged product of the A-Train. We leverage the NEWS effort that is based on error- and resolution-weighted mean of the input data sets, with associated uncertainty estimates. This provides a formal model of the collective A-Train observations rather than the collection of the individual instrument measurements Each of Giovanni\222s multiple interface instances provides a very simple and easy to use web interface. However, we recognized that sometimes scientists want more than the simple interfaces. Some scien tists may want to process Level 3 products using their own trusted code, or may want to perform variations of their own plots. With Giovanni, the individual scientist wanting more custom advanced capabilities must depend on the Giovanni development team Giovanni is based on the web portal paradigm where users visit a web page and use web tools to find and visualize data. Similar to Giovanni, our client APIs also make data acquisition more seamless. However, our services are based on the different paradigm were the power and flexibility of data analysis and processing are shifted back into the scientists own familiar computing environments. We realize that scientists generally want to perform \223exploratory computing\224 where they can sere ndipitously analyze the data using their own familiar and trusted code 


  17 Giovanni 2 was inherently synchronous where processing was bounded to a single http session. Long service running times still require the user to hold the same http session Similar to our asynchronous Web Service we discussed, the upcoming Giovanni 3 will be supporting asynchronous sessions. They will be using a RSS feed to monitor the service request. Version 3 will also be based on a servicesoriented architecture, wher e Giovanni services can be offered as a standard SOAP Web Services. This is similar to our approach, as well as SciFlo\222s services 12  C ONCLUSIONS  To achieve the science research goal of investigating longterm and global-scale trends in climate, water and energy cycle, and weather variability, we enhanced and improved on existing algorithms to work with distributed and heterogeneous data and information systems infrastructure By developing a service-oriented architecture for discovering, accessing, and mani pulating of NEWS merged A-Train data sets, we can strengthen the interconnectedness and reusability of these services across broader range of Earth science investigations The merged NEWS Level 2 data is a formal model containing the voluminous data from the AIRS, AMSR-E MLS, MODIS, and CloudSat instruments. Previously scientists wanting to perform long-term and global-scale studies encompassing simultaneous measured quantities would quickly face a data acce ss hurdle of first finding the data, then manually downloading them, and finally merging the data into a cohesive model\227before starting their analysis. Additionally the voluminous nature of the data particularly because of the MODIS data\each scientist potentially downloading the same data resulting in redundancy of reprocessing on the client sides. Our paradigm pushes more of the commonly repeated processing onto the server side. Moreover, this avoids repeated downloading of the same data among the science users. We can deliver customi zed averaged, subsetted, and summarized data of the merged A-Train observations to the scientists for them to immediately begin their analysis work We recognized that scientists also often want to perform 223exploratory computing\224 where they can freely explore the aspects of the data and run serendipitous exploration in their own familiar environment. We developed client-side distributed APIs in popular analysis environments such as Matlab, IDL, and Python. Our APIs hide the complexity of Web Services and allow the service capabilities to be embedded in the scientists own computing environments By purposely avoiding the \223web portal\224 paradigm and providing the suite of platform specific APIs in each of these language platforms, we enable the scientists to remain within their own familiar environments to select, process and download the data seamlessly into their environment for their own further analysis. Alternative methods involving web portals force the scientists to leave the environment and manually interact with the web portal to search and download the data We can examine not only long-term changes in amplitude of a single variable but also those among multiple variables Our L3Q clustering method was specifically designed to preserve information about the covariability of multiple observations, such as those from the A-Train.  Weather and climate variability is characterized by changes among atmospheric observables, but those changes have been limited by a lack of observations and analytical techniques We are not aware of any multi-parameter analyses to date The full potential of the A-Train climate record will not be realized until the multi-parameter climatology is understood. The work presented is one method of approaching this difficult problem Our service tool addresses several objectives of the NASA Earth science data community including 1\mprove interoperability to facilitate the transparent access and manipulation of heterogeneous and distributed data by science users, 2\ransition and deploy existing Earth science research analysis tools and software using a 223Service Oriented Architecture\224 \(SOA\ to enhance their reuse potential for other science domains and improve overall awareness and access of these tools by a broad community, 3\ increase users\222 ability to customize their discovery, access, deliv ery, manipulation, and preferred format of data and information 12  F UTURE W ORK  On-demand Level 3T Summaries from Level 3Q We plan to develop services for creating custom summaries of the L3Q data into more refined Level 3T summaries L3T\create their own custom Level 3 products on demand from L3Q. The custom Level 3 products are the transformation of L3Q data based on user-specific objectives such as regression and correlation analyses. The cust om production will generate not only the transformed data but also the statistical estimation of the accuracy of the summarized data based on the distribution of L3Q and the quality of L3Q Delegating the Temporal-Spatial Data Querying Currently, our processing layer utilizes existing and legacy processing code that was developed in IDL, Matlab, and C++. Though the original intent was to be able to adapt existing code and wrap as a service, this meant maintaining its original form of accessing the source data for processing Small modifications were made to enable these codes to quickly access the data based on file path and file naming schemes. However, we want to decouple the file accessibility and processing roles 


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



 1 CubeSat Communications Transceiver for Increased Data Throughput  Christopher Clark, Andrew Chin, Petras Karuza, Daniel Rumsey, David Hinkley The Aerospace Corporation P.O. Box 92957 Los Angeles, CA  90009-2957 310-336-1018 chris.j.clark@aero.org   Abstract 227CubeSat communication links require small size low power, and low cost transceivers.  Link parameters resulting from the satellite\222s Low Earth Orbit \(LEO impair transceiver performance, degrading mission data 
throughput. This paper describes the characteristics and control of a new CubeSat transceiver. The new transceiver provides an estimated 300% increase in data throughput for a typical 45\226degree maximum elevation angle LEO pass over the Aerocube-2 transceiver 12   T ABLE OF C ONTENTS  1  I NTRODUCTION 1  2  LEO 
 L INK P ARAMETERS 2  3  T RANSCEIVER C HARACTERISTICS 3  4  T RANSCEIVER C ONTROL A LGORITHM 3  5  
C ONCLUSION 4  R EFERENCES 5 B IOGRAPHY 5   1  I NTRODUCTION  There has been considerable in terest in the development of inexpensive, Low Earth Orbit \(LEO\ased satellites for scientific missions.  This has spurred the development of the 
CubeSat standard [1 e stan d ard  d efin es satellite size as a 10 centimeter cube and weight as less than 1 kilogram The goal of the standard is to make the launching of these satellites easy by providing a reliable deployment system A recent example of a coordi nated CubeSat deployment occurred in April 2007 with the launch of seven CubeSats using the DNEPR launch vehicle. The CubeSats were launched into a nearly circular, 700 km polar orbit.  One of the CubeSat\222s deployed was The Aerospace Corporation\222s Aerocube-2, shown in Figure 1.  The communications transceiver of Aerocube-2 operated in the 900\226928 MHz 
Industrial Scientific Medicine \(ISM\ frequency band with a data rate of 38.4 Kbps.  Though this transceiver has been very reliable, it is not optimized for orbital operations.  A 1  1 978-1-4244-2622-5/09 25.00 \2512009 IEEE 2 IEEEAC paper #1737, Version 2, Updated January 5, 2009 new transceiver, presented here, has features that will maximize data throughput  
Figure 1.  The Aerocube-2 CubeSat For CubeSat missions, the DC power supplied to the satellite subsystems is at a premium.  This is due to the physical limitations of the on-board Li-Ion batteries and available area for solar cells [2  The DC power const r ai nt s are critical to CubeSat transceiver design and operation Transceiver DC power requireme nts are primarily set by the transmit power amplifier \(PA\ Frequency-shift-keying FSK\odulation is often chosen for its constant envelope property, allowing saturated PA operation with low DC 
power consumption.  In transmit mode, the Aerocube-2 transceiver provides 2W RF output power from 8 W of DC power. High performance FSK receivers can be implemented with relatively low DC power consumption  ode, the transceiver consum es 0.9 W  of DC power while providing a sensitivity level of \226105 dBm 38.4 Kbps data rate, 0.01 packet-error rate \(PER bytes/packet The RF port of the satellite tr ansceiver is connected to a transmit/receive microstrip pa tch antenna.  This antenna 


 2 was chosen for its low profile and isotropic \(spherical pattern coverage.  It provides a worst case loss of 10 dB over 90% of isotropic pattern coverage. The Aerocube-2 mission achieved communications link closure using a 28 dB gain, 16 foot diameter dish antenna at the El Segundo CA ground station.  The ground station operated with 10 dB higher RF output power than the satellite.  This helped ensure error-free control of th e satellite transceiver through the uplink path 261 is to denote the two opposite values of Doppler shift that occur when the satellite is moving directly towards \(+\ \(\226\ the ground station 112 110 108 106 104 102 100 0 100 200 300 400 500 600 700 800 900 Elapsed Time \(s Receive Signal Power \(dBm  Figure 2.  LEO Pass Receive Power vs. Time 25 20 15 10 5 0 5 10 15 20 25 0 100 200 300 400 500 600 700 800 900 Elapsed Time \(s Frequency \(KHz  Figure 3.  LEO Pass Doppler Shift vs. Time One method of dealing with Doppler shift is to increase the bandwidth of the receiver filters on both ends of the link so that even with the Doppler sh ift, the modulated transmitted signal is always contained w ithin the receiver bandwidth Since the extra bandwidth adds thermal noise, the sensitivity performance is reduced. Additional degradation can occur with this method since the signal is not centered in the band of the FSK demodulator. The preferred method is to use an automatic frequency control \(AFC where the signal remains in th e center of the receiver filter without requiring continual manual adjustment of the receiver tuner frequency.  The receiver bandwidth can also always be set to the value in which the optimal sensitivity is achieved throughout the LEO pass, regardless of data rate and Doppler shift.  The AFC system must be designed to The purpose of this paper is to discuss the development of a new CubeSat transceiver to increase mission data throughput.  Section 2 presents the relevant parameters of a CubeSat LEO link.  Section 3 discusses the transceiver characteristics necessary to exploit the link parameters while simultaneously meeting the small size, low power and low cost constraints.  Section 4 presents the transceiver\222s control algorithm which helps optimize the data throughput performance. Section 5 summarizes the expected data throughput performance and provides suggestions for future improvement 2  LEO  L INK P ARAMETERS  During a CubeSat LEO pass, the elevation angle goes through a cyclical variation; smallest at the beginning and end \(when the satellite is on the horizon\, and highest at the middle of the path \(when the satellite is at the zenith the elevation angle of the ground station antenna increases the propagation distance shortens and the atmospheric loss and signal delay correspondingly decreases. Since the CubeSat transceiver transmits with a constant output power the decrease in link loss during the pass will result in a variation of received signal power. Figure 2 shows received signal power from the El Segundo ground station for a typical 45\226degree maximum elevation angle LEO pass, with the satellite transceiver PA operating at 1 W RF output power.   The ground station antenna noise temperature also varies during the pass, but since the receiver noise temperature is dominant, the system noise power remains effectively constant.  Theref ore the data rates that are possible during a pass can be estimated using the sensitivity of the transceiver and the received signal power.  When the received power is higher, the data rate can be increased providing improved data throughput for the pass In addition to the variable received signal power, the ground station also observes variable Doppler RF frequency shift during the pass.  The Doppler shift is the apparent shift in RF frequency caused by the velocity of a satellite relative to the ground station.  It is a function of both the absolute RF frequency of the transmitter and the relative velocity  This shift in RF frequency must be estimated and compensated for in order to enable reliabl e and efficient communication Figure 3 shows the Doppler frequency shift curve for a typical LEO pass as experienced from the El Segundo ground station  The use of 


 3 reliably acquire and track both the rate and range of the expected Doppler shifted frequency 3  T RANSCEIVER C HARACTERISTICS   In order to obtain adjustable data rate and AFC capabilities along with small size and low power, the Texas Instruments CC1101 single chip transcei was eval uat e d.  The transmitter section of the chip has configurable data rates up to 500 kbps and provides up to 10 mW RF output power while using only 100 mW of DC power. The receiver section has adjustable channel filter bandwidths between 58 and 812 kHz and consumes only 50 mW DC power.  An internal 64 byte FIFO is used for efficient packet handling data buffering, and burst transmissions.  The CC1101 is designed to be interfaced w ith a programmable intelligent computer \(PIC\rol and data flow purposes.  An important feature of the CC 1101 is the ability to estimate both received signal strengt h indication \(RSSI frequency offset.  These indicators allow for increased data throughput by enabling optimal adjustment of data rate receiver bandwidth and RF frequency throughput the LEO pass                       Figure 4.  CubeSat Transceiver Block Diagram  A block diagram of a CubeSat transceiver using the CC1101 is shown in Figure 4.  In addition to the PIC several external RF components are included to improve performance.  The low noise amplifier \(LNA\des 1.3 dB noise figure and 17 dB gain.  The PA provides 1 Watt saturated output power with up to 32 dB small signal gain Single pole double-throw \(SPDT\tches are required to allow connection of the LNA and PA to the antenna RF In/Out port.  A bidirectional data/control path exists between the PIC and the CC1101.  The PIC also controls the SPDT switches and turns o ff the PA and LNA whenever they are not in use to minimize DC power consumption.  A 26 MHz temperature compensated crystal oscillator TCXO\s used as the frequency reference for the CC1101 This enhances the both phase noise and temperature stability performance of the transceiver  Figure 5 shows the average sensitivity performance of three fabricated CubeSat transceiver units.  The 0.01 PER sensitivity is \226120 dBm at 250 bps data rate and degrades to 22694 dBm at 500 kbps.  This performance is approximately 6 dB better than the CC1101 chip alone.  The improvement is due to the lower overall recei ver noise figure achieved by using the off-chip LNA.  The performance is also a 6 dB improvement over the Aerocube-2 transceiver at the 38.4 kbps data rate  125 120 115 110 105 100 95 90 0 1 10 100 1000 Data Rate \(Kbps Sensitivity \(dBm  Figure 5.  CubeSat Transceiver Sensitivity  4  T RANSCEIVER C ONTROL A LGORITHM  This section describes a simple transceiver control algorithm \(TCA LEO pass.  A simplified flow chart of the TCA is shown in Figure 6.  The ground station transceiver functions as the master in a master/slave configuration.  The acquisition mode of the TCA is shown in the first three blocks.  In this mode, both the ground station a nd satellite transceivers are set to the nominal center RF frequency and lowest data rate The ground station transceiver continually sends command CMD\from the satellite transceiver.   Once an acknowledgement is received, the ground station transceiver begins the data transfer mode as shown in the bottom three blocks of Figure 6 


 4  Figure 6.  Transceiver Control Algorithm   In data transfer mode, the satellite transceiver sends payload data to the ground station in frames of 20 packets.  The ground station transceiver recei ves the data and identifies packets with errors for auto matic-repeat-query \(ARQ transmission. It also accurately determines the RF frequency and RSSI by averaging the values estimated from each packet. From this information a new data rate and receiver bandwidth is determined using a look up table \(LUT to maximize data throughput.  The RF frequency of the ground station transceiver RF frequency is then adjusted to minimize the effects of Doppler shift.  A CMD packet requesting more data is then sent to the satellite transceiver In addition to the new data rate and receiver BW, ARQ information is provided to identify which packets need to be resent from the last frame.   The algorithm will automatically revert back to acquisition mode if data from the satellite is not received within the allotted time-out period To fully take advantage of the transceiver\222s adjustable data rate capability, a continuously vari able data rate is required  discrete step-size LUT and overhead time limit the achievable performance.  A fixed amount of overhead is due to execution/control times within the PIC and CC1101. Overhead is required for the preamble synchronization and CRC bits w ithin each packet.  Signal propagation time also results in an overhead between 6 and 20 ms for each frame during the pass.  To estimate data throughput, simulations were performed using the expected overhead, as well as the received signal power and transceiver sensitivity from Figures 2 and 5, respectively Figure 7 shows a performance comparison of the Aerocube2 transceiver to the new transceiver using the TCA.  Data throughput is increased due to both the extended data transfer period and higher data rates.  A data throughput increase of 300% can be achieved. Further improvement is possible by using a higher speed, more powerful PIC to decrease the execution/c ontrol overhead time  Figure 7.  TCA Simulated Data Rate vs. Time 5  C ONCLUSION  This paper describes the development of a Cubesat transceiver for increased data throughput.  The design is based on a commercial transceiver chip developed for the 900\226928 MHz ISM band.  The tran sceiver\222s sensitivity at a 38.4 kbps data rate is 6 dB better than the previously used Aerocube-2 transceiver.  The new transceiver allows for the flexible adjustment of data rate, receiver bandwidth, and RF frequency throughout a given LEO pass.  The effects of variable received signal power and Doppler shifted RF frequency can be minimized with a control algorithm that effectively utilizes the transceiver\222s capabilities.  A simulation for a typical 45\226degree maximum elevation pass has shown that the data throughput performance can be increased by 300%.  Further improvement is possible by using a higher speed, more powerful PIC to decrease the execution/control overhead time  


 5 R EFERENCES  1  A. Toorian, E. Blundell, J. Puig-Suari, R. Twiggs 223CubeSats as Responsive Satellites,\224 AIAA-2005-3001 in Proceedings of 3 rd Responsive Space Conference 2005 2  J. Halpine, S. Liu, E. Simburger, H. Yoo, D. Hinkley, D Rumsey, \223Pico-Satellite Solar Cell Testbed Qualification Testing\224, in Proceedings of  4 th World Conference on Photovoltaic Energy Conversion, 2007 3  E. Grayver, B. Daneshrad, \223A Low Power All-Digital FSK Receiver for Space Applications,\224 IEEE Transactions on Communications, Vol. 49, No. 5, May 2001 4  CC1101 Data Sheet Revision C, SWRS061C, 5/22/2008 Texas Instruments 5  A. Kantak, \223Bit Rate Determination for a Satellite Communications Link,\224 AIAA-94-1085, in Proceedings of 15 th International Satellite Systems Conference, 1994  B IOGRAPHY  Christopher Clark received the BSEE and MSEE degrees from the University of Maryland, College Park, in 1983 and 1986 respectively From 1984 to 1986 he worked for the Watkins-Johnson Company where he was responsible for the design and development of RF receiving systems. From 1986 to 1992 he worked for TRW, Inc. \(now NGST\ where he developed HEMT and HBT GaAs MMICs for satellite payloads.  From 1992 to 1999 he worked at The Aerospace Corporation where he was involved in the design of space communication systems.  From 1999 to 2003 he was a Principal Engineer at Multilink Technology Corporation, where he was re sponsible for the development of transceivers for use in fiber optic telecommunication systems. He is currently a Senior Engineering Specialist at The Aerospace Corporation in the Communication Electronics Department, Electr onic Systems Division.  His work involves the design, analysis, and hardware development for several s pace communication systems    


Figure 6  Edge detection algorithm applied to 002gure 2 Figure 7  Masks for each test image at threshold 88 Image Reconstruction Figure 8 demonstrates our proposed method for image reconstruction using evolved 002lters The original image is decomposed with a discrete wavelet transform and then subjected to a desired amount of quantization Simultaneously the image is subjected to an edge detection algorithm The resulting edge image is converted to a binary mask In a deployed image processing system both the quantized image signal and the binary mask are subjected to lossless encoding such as Huffman encoding and then transmitted The recei ving system decodes the quantized signal and the mask and decodes the signal The image is reconstructed using two evolved image 002lters the 002rst having been evolved to reduce error near object edges the second evolved to reduce Figure 8  Image decomposition and reconstruction with evolved 002lters targeting edge-adjacent and non-edge-adjacent portions of images 6 


error either across the entire image or speci\002cally in areas not adjacent to object edges The reconstruction algorithm then employs the binary mask to select the appropriate portions of each preliminary reconstructed image and then combine them into a single 002nal image During evolution of the 002lter designed to reduce error near edges the entire training image is reconstructed but 002tness is only calculated at the pixel positions located within the black portions of the mask enclosing the edges identi\002ed by the edge detection algorithm for the provided training image This approach forces the GA to evolve a 002lter that improves image reconstruction near object edges Section 5 describes the development of this 002lter The 002lter used to reconstruct the remaining areas of images may be optimized to either reduce error across an entire image or to speci\002cally reduce the error in the portions of an image not adjacent to object edges 050not selected by the binary mask\051 These two approaches are contrasted in section 6 For clarity we refer to 002lters evolved using the entire image as globally evolved 002lters and to 002lters evolved using the edge-enclosing masks as locally evolved 002lters Locally evolved 002lters are optimized either for the edge-adjacent or non-edge-adjacent portions of images as noted 4 P RELIMINARY E XPERIMENTS The edge detection algorithm generates a greyscale image isolating the edges within a satellite image as shown in 002gure 6 Edges are then isolated through the generation of a binary mask separating dark pixels from light pixels in the edge image Our initial experiments seek to identify an appropriate pixel shade threshold for binary mask generation that ultimately provides improved image reconstruction near object edges Preliminary analysis indicates satisfactory MSE results using appropriate mask threshold determination on selected satellite images Mask Threshold Determination The creation of the binary mask used to isolate the edge portions of the training image requires a set threshold This threshold dictates the required strength of the edge detection output for a given pixel position to be considered part of an edge for the mask In the range 0 000   lower thresholds select fewer areas of the image as edges Higher thresholds enclose a higher portion of the training image To determine an appropriate setting for the edge threshold several GA runs are conducted using the U.S Air Force museum image from 002gure 2 At a quantization level of 64 and one level of decomposition the MSE of the image reconstructed using the Daub4 DWT 000 1 is 138.13 A globally evolved 002lter used as a baseline for comparison achieves a reconstruction MSE of 106.108 representing a reduction of 23.18 Local 002lters for the reconstruction of object edges are evolved using edge masks generated at various threshold settings ranging from 48 up to 192 Recall that during evolution MSE 002tness is only assessed near the object edges of the training image as Figure 9   MSE improvement in masked region of edgeevolved 002lter against Daub4 wavelet 050dashed\051 and globally evolved 002lter 050dotted\051 indicated by the mask created at the given threshold At each threshold the locally evolved 002lter response is compared to the Daub4 DWT 000 1 response and the globally evolved 002lter response for the edge portions of the training image isolated by the mask The  reductions in MSE of the local 002lter against the global 002lter and the wavelet are plotted in 002gure 9 The local 002lters exhibit a reduction typically ranging from 14\22616 against the Daub4 wavelet Against the globally evolved 002lter the local 002lters demonstrate an improvement of 21.30 at a conservative threshold of 48 The degree of improvement steadily declines as the threshold increases but remains signi\002cant at thresholds below 120 This makes sense because at low thresholds only dark positions of the edge detection algorithm indicating large intensity transitions between neighboring pixels 050strong edges\051 are encompassed by the mask images At higher thresholds the masks are less selective and encompass larger portions of the image The two plots cross at a threshold of 112 at this point the responses of the wavelet and the globally evolved 002lter are approximately equal From this point the wavelet outperforms the global 002lter in the mask-encompassed portion of the image to an increasing degree as the threshold decreases The reverse is true as the threshold increases This con\002rms that the globally evolved 002lter while reducing error across the entire image actually increases reconstruction error near object edges However the locally evolved 002lters provide consistent improvement near object edges Figure 10 plots the overall reduction in MSE with the image reconstructed using the combined locally and globally evolved 002lters versus the globally evolved 002lter alone at each tested threshold level Improvement ranges from 1.98\2262.25 at thresholds under 120 with the best performance coming at a threshold of 104 At this threshold the MSE reduces from 106.11 to 103.72 a reduction of 2.25 While this may not 7 


Figure 10   MSE improvement for entire image using combined reconstruction over reconstruction with globally evolved 002lter only seem to be a signi\002cant improvement across the entire image this improvement occurs strictly near object edges such as building outlines or aircraft pro\002les The portions of the image most critical for intelligence analysis demonstrate signi\002cantly improved reconstruction Performance on Selected Satellite Images The results above demonstrate trends in 002lter response but because each is the result of a single GA run on a single image statistically sound conclusions may not yet be drawn In order to assess the performance of the proposed technique on a wider range of conditions replicated GA experiments are conducted at multiple threshold levels for the four satellite images presented in 002gure 5 For each image a global reconstruction 002lter is evolved as well as an edge-isolated local 002lter using masks created at threshold levels 48 88 and 104 in a single experimental replication Fifteen total replications are conducted for each image The responses of the wavelet the globally evolved 002lter and the locally evolved 002lter are recorded at each threshold level for the mask-enclosed portion of the image Table 1  MSE of images reconstructed with Daub4 wavelet and globally evolved 002lters Table 1 presents the MSE of each image reconstructed with the Daub4 DWT 000 1 and the average MSE achieved with the globally evolved 002lters across all replications Evolved 002lters reduce MSE by between 13.57 and 20.51 on average deTable 2   of images covered by masks created at each threshold Table 3  Mean  MSE reduction in area enclosed by masks using combined 002lter reconstruction pending on the image The masks created for each threshold encompass varying amounts of the training images Table 2 provides the  of each image enclosed by the masks for each threshold value The masks for the Baghdad image encompass between 24.67 and 41.56 of the image as seen in 002gure 7 050top right\051 the large number of structures in this image lead to a large number of edges in the image The remaining images are much more edge sparse with the Air Force museum image containing the smallest percent covered by the edge mask The locally evolved 002lters are compared within the maskenclosed regions for each image in table 3 This table shows the average reduction of MSE over the wavelet 050top\051 and over the evolved 002lters 050bottom\051 for the given image The best result and any results not statistically signi\002cantly different are shown in bold for each image T-tests at signi\002cance level 013  0  05 provides assessments of the differences between results Within the mask-enclosed region the local 002lters perform very well compared to the wavelet The threshold value does not appear to strongly in\003uence performance 8 


Table 4  Mean  MSE reduction of entire images using combined 002lter reconstruction for the given images The local 002lters demonstrate the best performance at a threshold of 104 for two images and only slightly lower than the best performance for the two remaining images Compared to the globally evolved 002lters the local 002lters show signi\002cantly improved results for three of four images with the best performance typically coming at a threshold of 48 consistent with the plot in 002gure 9 demonstrating greater improvement over the globally evolved 002lter at smaller threshold values The locally evolved 002lters provide only minor improvement over the global 002lters for the Baghdad image Recall from table 2 this image contains the greatest degree of edge transitions Filters trained on this image exert a relatively large amount of selective pressure on 002lters providing improved reconstruction near object edges Images containing fewer edges provide less evolutionary pressure preferring improved reconstruction across the entire image at the expense of reconstruction near edges Table 4 shows MSE improvement when combining the global and local 002lters for reconstruction The top portion shows improvement over the Daub4 DWT 000 1 when the mask-covered portion of the image is reconstructed with the local 002lter and the remainder with the wavelet Because masks enclose a small portion of each image improvement is modest These small gains are measured across the entire image though all improvement comes near edges  Not surprisingly the greatest error reduction comes for the Baghdad image containing the largest mask coverage The best improvement comes at a mask threshold of 104 for each image consistent with the trends illustrated in 002gure 10 The lower portion of table 4 provides results seen for reconstruction using both local and global evolved 002lters over use of globally-evolved 002lters alone The Baghdad image demonstrates the smallest improvements this image provides suf\002cient selection pressure for edge reconstruction as a training image The remaining images show reconstruction improvement of between 2.22 and 3.41 even though a relatively small portion of each image is covered by the mask The best improvements typically occur at the 104 threshold where a larger amount of image coverage provides greater room for improvement 5 R ECONSTRUCTION A DJACENT TO E DGES Because image transforms evolved for global reconstruction of an entire image demonstrate increased error near object edges we place emphasis upon the reduction of reconstruction error near edges The evolution of a robust image 002lter for near-edge reconstruction requires the identi\002cation of training images that result in 002lters that perform well on the reconstruction of unseen images 50 GA runs are conducted to evolve 002lters for near-edge reconstruction Each run employs one of the 50 unique available satellite images as the training image Images are referenced according to their number in the satellite image set as reported in the 002rst image would be referred to as sat01 The GA attempts to minimize the MSE within the edge-adjacent portions of the training image during 002lter evolution After evolution the resulting reconstruction 002lter's performance is assessed across all 50 satellite images We suspect that the abundance of object edges within a training image may in\003uence its performance as a training image For each evolved 002lter 002gure 11 plots the average  MSE reduction near edges compared to the Daub4 DWT 000 1 002lter obtained across all 50 images plotted against the  of that 002lter's training image enclosed by the binary edge detection mask obtained at a mask generation threshold of 88 050see section 4\051 From this plot it appears that there is a loose correlation between training image edge abundance and the performance of that image's corresponding evolved 002lter performance Training images with fewer than 10 of their pixels near object edges perform significantly worse than the Daub4 DWT 000 1 002lter On the other hand several images with greater than 25 of pixels near edges result in 002lters providing an average MSE reconstruction improvement near edges of approximately 17 Not all images with an abundance of pixels near edges provide strong performance as training images however It appears that the abundance of pixels near object edges is an important factor in the training performance of images but there may be other important factors as yet unidenti\002ed that play an important role in training image performance as well Images in the satellite set are also ranked according to their reconstruction dif\002culty as test images For each test image the  MSE improvement over the DWT 000 1 002lter is averaged across each of the 50 evolved transform 002lters The average improvement for each test image is plotted against the  of pixels near edges in 002gure 12 Some images are very dif\002cult for the evolved 002lters to reconstruct while others demonstrate an average improvement of nearly 10 over the DWT 000 1 002lter regardless of the evolved 002lter used Based on the seemingly random distribution of points in the plot there does not 9 


Figure 11  Scatterplot of MSE  improvement in edgeadjacent portions of training images against  of training images adjacent to object edges Improvement is averaged across all test images appear to be any correlation between an image's edge abundance and its dif\002culty as a reconstruction test case Figure 12  Scatterplot of MSE  improvement in edgeadjacent portions of test images against  of test images adjacent to object edges Improvement is averaged across 002lters evolved for reconstructing the edge-adjacent portions of images A single GA run using each training image enables an initial ranking of the training images but is insuf\002cient to identify a single best image To identify a single best training image for edge-adjacent reconstruction 30 GA replications are performed for each of the 002ve best initially-ranked training images 30 replications provide a suf\002cient sampling to enable a robust statistical analysis of the results For each replication the average performance of the evolved 002lter is assessed as the average percentage reduction of MSE for reconstruction in the binary mask-enclosing areas of each of the 50 satellite images Table 5 reports statistics collected across Table 5  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image all 30 replications for each image Image sat30 provides the best mean and median performance as a training image Filters evolves using this image provide an average MSE reduction of 17.02 across all images in the satellite set for the reconstruction of pixels near object edges We conducted a series of hypothesis tests comparing the results of the sat30 training replications with the replications obtained for each of the other top-ranked training images All tests are conducted at a con\002dence level 013  0  05  Lilliefors tests determine the normality of the replicated results Only the results for the sat39 training image do not strongly con\002rm to a normal distribution though with a p-value of 0.0423 they only slightly fail this test Since the results of all replication sets are largely normal we compare the mean values of results using standard two-sided t-tests We also compare the medians using the more conservative non-parametric Wilcoxon ranksum tests and compare the distributions directly using the non-parametric Kolmogrov-Smirnov test The results of these tests indicate that while the sat30 image provides the best performance for training edge-targeted reconstruction 002lters the sat17 image provides statistically equivalent performance The remaining three training images demonstrate strong performance but do not provide as great of an improvement over the Daub4 DWT 000 1 002lter for reconstructing near-edge pixels One of the replications obtained using the sat30 training image provides the best observed chromosome for the reconstruction of images near edges The corresponding low and high frequency reconstruction 002lter coef\002cients are as fol10 


lows Low R  f 0  4794  0  7915  0  2302  000 0  0892 g High R  f\000 0  2013  000 0  0246  0  6493  000 0  2917 g 0507\051 Across all 50 satellite images this 002lter reduces the MSE of pixels reconstructed near object edges by an average of 17.10 over the Daub4 DWT 000 1 002lter with a standard deviation of 1.66 The worst improvement was 12.69 with improvement reaching as high as 20.91 This consistent performance demonstrates that the evolved 002lter is well suited for the reconstruction of unseen images and is not the result of overtraining by the genetic algorithm for the provided training image 6 R ECONSTRUCTION N ONADJACENT TO E DGES In reconstruction 002lters are e v olv ed to pro vide impro v ed reconstruction for entire satellite images with no particular emphasis upon the reconstruction of pixels near object edges The experiments presented in follo w the same e xperimental framework presented here with 30 GA replications comparing the performance of the 5 top-ranked training images for global reconstruction 002lter evolution The best 002lter coef\002cients obtained for global image reconstruction are as follows Low R  f 0  4702  0  7654  0  2373  000 0  0620 g High R  f\000 0  1979  000 0  0316  0  6372  000 0  2921 g 0508\051 The performance of globally evolved 002lters provides signi\002cant improvement over the Daub4 DWT 000 1 002lter under conditions subject to quantization error In the areas of images not selected by the edge detection mask 050not adjacent to object edges\051 the 002lter shown in equation 8 reduces the MSE by an average of 14.98 with a standard deviation of 2.12 While this 002lter may provide suf\002cient performance for the reconstruction of pixels not adjacent to edges we conduct a series of experiments to determine whether 002lters evolved only to improve non-edge adjacent reconstruction provide improved reconstruction In these experiments 002tness is assessed by the GA as the reconstruction error only in pixels not covered by the binary edge detection masks  As before an initial set of 50 GA runs evolve 002lters using each of the satellite images for training The top-5 initially ranked training images are each used in a set of 30 replicated GA experiments The results of these experiments are summarized in table 6 In this case all 002ve replication sets pass a Lilliefors test for normality The sat08 image provides the best training performance resulting in an average improvement of 15.87 with a standard deviation of 0.18 across all 50 satellite images A series of hypothesis tests comparing the sat08 replication results to the results obtained for the other best-ranked training images demonstrate that the sat31 and sat04 training images provide statistically equivalent performance Any of these three images provide Table 6  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of non-edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image strong performance for the training of 002lters designed for reconstructing the pixels in an image One of the 002lters obtained using sat04 as a training image provides the best observed performance for reconstruction away from edges The coef\002cients for this 002lter are Low R  f 0  4593  0  7322  0  2493  000 0  0253 g High R  f\000 0  1858  000 0  0130  0  6700  000 0  2692 g 0509\051 Across the entire set of 50 satellite images this 002lter achieves a 16.18 mean MSE improvement with a 2.52 standard deviation in the areas of the images not covered by their respective binary edge masks The median improvement is 16.65 with a minimum and maximum improvement of 7.81 and 20.54 respectively This 002lter outperforms the best globally evolved 002lter shown in equations 8 by an average of 1.42 in the reconstruction of pixels not adjacent to object edges with a standard deviation of 1.70 The maximum improvement is 6.24 This 002lter outperforms the globally evolved 002lter for 37 of the 50 satellite images Among the images for which the global 002lter exhibits better improvement its performance is not greater than 1.65 better than this 002lter In general the 002lter optimized for the reconstruction of nonedge-adjacent pixels provides improved reconstruction over a globally evolved 002lter These results justify the use of two locally evolved 002lters for image reconstruction one for the reconstruction of the image covered by the binary edge mask and the other for the remainder of the image 11 


7 D ISCUSSION The image reconstruction scheme illustrated in 002gure 8 requires two separate evolved reconstruction 002lters one for reconstruction of the image near object edges and the other for reconstruction away from edges The 002lters presented in equations 7 and 9 are optimized to reconstruct the edgeadjacent and non-edge adjacent portions of images respectively Using these combined 002lters to reconstruct all of the satellite images results in a mean MSE improvement of 16.53 with a standard deviation of 1.91 The improvement ranges from a minimum of 8.94 up to a maximum of 20.59 In contrast the best globally evolved 002lter in equation 8 only provides a mean improvement of 15.21 with a standard deviation of 1.78 Overall improvement with the global 002lter ranged from 8.83 up to 19.04 Our proposed image reconstruction approach utilizing edge and non-edgetargeted optimized 002lters improves upon the performance of both the Daub4 DWT 000 1 002lter and the best identi\002ed globallyevolved 002lter By utilizing 002lters optimized for high-spacial frequency changes for reconstruction near edges and 002lters optimized for low-spacial frequency changes for non-edgeadjacent edges we are able to realize better reconstruction resolution than a single 002lter optimized for an entire image permits The successful optimization of robust image transforms requires the careful selection of an appropriate image for training during evolution The scatter plot in 002gure 11 demonstrates the importance of training image selection Several training images result in 002lters that fail to improve upon the performance of the standard inverse wavelet transform in the reconstruction of the collected satellite images This is due to overtraining by the genetic algorithm The GA discovers a 002lter that provides strong reconstruction of the supplied training image but the resulting 002lter does not generalize well to the remaining satellite images and may provide signi\002cantly worse performance than the wavelet Though we recognize the importance of training image selection to the ultimate performance of the resulting evolved image 002lters the identi\002cation of salient image features governing an image's suitability for GA training remains an open research question Figure 13 shows the 002ve best training images for near-edge reconstruction 002lter optimization while 002gure 14 shows the 002ve worst images Filters trained upon the best images provide strong performance across the entire satellite image set In contrast 002lters trained using the worst images demonstrate very poor performance While there appears to be a loose correlation between performance and the number of near-edge pixels in the training image 050see 002gure 11\051 there are likely other factors at play as well These factors may include the distribution of light and dark pixel intensities in the image the shape and direction of long and short object edges or the rotational axis of the training image relative to the distribution of object edges The good training images tend to contain many small boxed objects such as houses oil storage tanks and hangers while the poor training edges contain fewer buildings The distribution of buildings/small geometric objects may in\003uence an image's training performance in an as yet unforseen manner Future research should focus upon the factors impacting an image's suitability as a GA training sample This may lead to the identi\002cation of improved training samples outside of the current image database and thus leading to greater performance from evolved image 002lters 8 C ONCLUSIONS Existing techniques of 002lter evolution potentially provide signi\002cant improvement over standard wavelet transforms but they may increase the error present near the edges of objects Image processing applications such as target recognition and intelligence gathering cannot afford this resolution loss in the most critical sections of the image The use of an edge detection algorithm and an edge-enclosing mask allows the evolution of reconstruction 002lters that improve the reconstruction resolution near object edges by as much as 20 under conditions subject to high quantization error Likewise 002lters evolved with emphasis upon the reconstruction of pixels not adjacent to object edges outperform existing 002lter optimization techniques through the remaining portions of images By ignoring edges such 002lters demonstrate an improved response over globally evolved 002lters to the edge-sparse portions of images Reconstruction combining 002lters optimized for near edge and non-edge adjacent performance provides a robust reconstruction algorithm suitable for applications requiring maximum object resolution while maintaining maximal compression ratios Results indicate that there may exist a correlation between the degree of edges within an image and the potential improvement a locally evolved 002lter may provide Future experiments should focus on images containing a wide range of edge sparseness or abundance while studying the in\003uence of other image properties upon a given image's suitability as a training sample Experiments should focus on the determination of appropriate mask creation thresholds for images of various edge abundance These experiments will lead to the development of a system that given an image determines the appropriate threshold setting and selection of appropriate 002lters from a library of previously evolved 002lters Recent related research has focused upon the optimization of image transform 002lters of greater length and complexity designed to outperform wavelets at greater levels of multiple resolution analysis regardless of quantization level As the complexity of evolved transforms increases the separation of the reconstruction task into unique 002lters for the reconstruction of pixels adjacent and non-adjacent to object edges may be of further bene\002t Further research will establish the performance of this reconstruction strategy upon increasingly complex image transform 002lters Lossy image processing systems that maintain high resolution near object edges improve the amount of useful intelligence 12 


Figure 13  The 002ve best training images for 002lter evolution of edge-adjacent image portion reconstruction Figure 14  The 002ve worst training images for 002lter evolution of edge-adjacent image portion reconstruction that may be gathered from images reconstructed using this approach This improved performance may be of particular interest to the scienti\002c defense and homeland security communities that require the transmission of copious amounts of data over bandwidth-limited channels without signi\002cant loss of observational information A CKNOWLEDGMENTS The authors thank the U.S Air Force Research Laboratory Sensors Directorate 050Dr Robert Ewing\051 and the U.S Air Force Of\002ce of Scienti\002c Research 050Computational Mathematics\051 for their support R EFERENCES   C E Shannon and W Weaver The Mathematical Theory of Communication  University of Illinois Press 1964   A Gersho and M Gray Vector Quantization and Signal Compression  Kulwer Academic Publishers 1991   B E Usevitch 223A tutorial on modern lossy wavelet image compression foundations of jpeg 2000,\224 IEEE Signal Processing Magazine  pp 22\22635 September 2001   I Daubechies Ten Lectures on Wavelets  SIAM 1992   G Davis and A Nosratinia 223Wavelet-based image coding an overview,\224 Applied and Computational Control Signals and Circuits  vol 1 no 1 1998   M R Peterson G B Lamont and F Moore 223Improved evolutioanry search for image reconstruction transforms,\224 in Proceedings of the IEEE World Congress on Computational Intelligence  2006 pp 9785\2269792   A Skodras C Christopoulos and T Ebrahimi 223The jpeg 2000 still image compression standard,\224 pp 36\22658 2001   J Walker A Primer on Wavelets and Their Scienti\002c Applications  CRC Press 1999   D A Huffman 223A method for the construction of minimum redundancy codes.\224 in Proceedings of the IRE  vol 40 1952 pp 1098\2261101   M Lankhorst and M van der Lann 223Wavelet-based signal approximations with genetic algorithms,\224 in Proceedings of the 4th Annual Conference on Evolutionary Programming  1995 pp 237\226255   E Jones P Runkle N Dasgupta L Couchman and L Carin 223Genetic algorithm wavelet design for signal classi\002cation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 23 no 8 pp 890\226895 August 2001   U Grasemann and R Miikkulainen 223Evolving wavelets using a coevolutionary genetic algorithm and lifting,\224 in Proceedings of the Genetic and Evolutionary Computation Conference GECCO-04  ser Lecture Notes in Computer Science vol 3103 Springer-Verlag 2004 pp 969\226980   F Moore 223A genetic algorithm for optimized reconstruction of quantized signals,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 1  2005 pp 105\226111   A Bruckmann T Schell and A Uhl 223Evolving subband structures for wavelet packet based image compression using genetic algorithms with non-additive cost functions,\224 in Proceedings of the International Conference on Wavelets and Multiscale Methods  1998 13 


  Y Hill S O'Keefe and D Thiel 223An investigation of wavelet design using genetic algorithms,\224 in Microelectronic Engineering Research Conference  2001   B S Rani and S Renganathan 223Wavelet based texture classi\002cation with evolutionary clustering networks,\224 in TENCON 2003 IEEE Conference on Convergent Technologies for Asia-Paci\002c Region  vol 1 2003 pp 239\226 243   U Grasemann and R Miikkulainen 223Effective image compression using evolved wavelets,\224 in Proceedings of the Genetic and Evolutionary Computation Conference 050GECCO'05\051  2005 pp 1961\2261968   W Sweldens 223The lifting scheme a custom-design construction of biorthogonal wavelets,\224 Journal of Aplied and Computational Harmonic Analysis  vol 3 no 2 pp 186\226200 1996   T Hopper C M Brislawn and J N Bradley 223Wsq gray-scale 002ngerprint image compression speci\002cation,\224 Federal Bureau of Investigation Tech Rep IAFIS-IC-0110 February 1993   F Moore 223A genetic algorithm for evolving improved mra transforms,\224 WSEAS Transactions on Signal Processing  vol 1 no 1 pp 97\226104 2005   F Moore P Marshall and E Balster 223Evolved transforms for image reconstruction,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 3  2005 pp 2310\2262316   Google 223Google earth plus,\224 http://earth.google.com 2006   M R Peterson G B Lamont F Moore and P Marshall 223A satellite image set for the evolution of image transforms for defense applications,\224 in GECCO 07 Proceedings of the 2007 GECCO conference companion on Genetic and evolutionary computation  New York NY USA ACM Press 2007 pp 2901\2262906   A H Wright 223Genetic algorithms for real parameter optimization,\224 in Foundations of Genetic Agorithms  G Rawlins Ed San Mateo Morgan-Kaufman 1991 pp 205\226220   I E Sobel 223Camera models and machine perception,\224 Ph.D dissertation Electrical Engineering Department Stanford University Stanford CA 1970   Y Yang 223Color edge detection and segmentation using vector analysis,\224 Master's thesis University of Toronto Toronto Canada 1995   D Kaur and L Ying 223Creating a neuro-fuzzy model by combining 002ltered images with various 002ltering operators for the detection of edges in new images,\224 2006 technical report University of Toledo   B J Babb F W Moore and P Marshall 223Evolved multiresolution analysis transforms for improved image compression and reconstruction under quantization,\224 in IEEE Symposium on Computational Intelligence in Image and Signal Processing  2007 pp 202\226207 B IOGRAPHY Michael Peterson received his B.S degree in Computer Engineering and his M.S degree in Computer Science from Wright State University in 2001 and 2003 respectively He is currently a Ph.D candidate in Computer Science and Engineering at Wright State University Since 2005 he has worked in the Evolutionary Computation Laboratory at the U.S Air Force Institute of Technology where he has developed a robust methodology for the evolution of wavelet-based image reconstruction transforms His research interests include evolutionary and bio-inspired computation signal and image processing pattern recognition and bioinformatics Gary Lamont received the B.S degree in physics and the M.S.E.E and Ph.D degrees from the University of Minnesota Minneapolis in 1961 1967 and 1970 respectively He is currently a Professor of Electrical and Computer Engineering at the Air Force Institute of Technology Wright-Patterson AFB OH where he directs the parallel and distributed computing and the evolutionary computation research groups Previously he was an Engineering Systems Analyst for the Honeywell Corporation for six years He has authored or coauthored a book several book chapters and over 100 papers His current research interests include parallel/distributed computation evolutionary computation 050genetic algorithms evolutionary strategies\051 combinatorial optimization problems 050single objective multiobjective\051 formal methods software engineering digital signal processing intelligent and distributed control systems computational and numerical methods and computer-aided design 14 


CONCLUSIONS Given that this project was intended to estimate missions lying 10-15 years out we structured it differently than one intended to estimate contemporary projects A variety of conventional techniques were not used as we felt they would over fit training observations and thus not be suitable for prediction We also were not sure which approach would work so we tried many We heavily favored ensemble methods where models are combined because we surmised that any one model could not be guaranteed to have the best view of the future However a single neural network ultimately yielded the most competitive results Another finding was that methods built upon simple models such as with three variables generally did work best not surprisingly because they were less likely to over fit calibration data A graph of the three best methods is shown in figure 18 with estimates for the same missions sorted by cost For the neural network calibration occurred until just before the results shown for continuous boosting calibration occurred no more recently than 15 years prior to the results and for Adaboost calibration also occurred up until the results shown A graph sorted by year is not shown we think it instructive that no results seemed to degrade over time As mentioned but obvious from figure 17 the neural network performs best followed by Adaboost and then continuous boosting It is interesting to note that the three cases in which the neural network goes haywire and predicts too low also correspond to worst performances for the Adaboost method pointing to exceptional data points We will be further investigating these regularly errant results and other outliers which may result in estimating improvements ACKNOWLEDGEMENTS This work was carried out under Small Business Innovation Research contract FS9453-05-C-0023 with the Air Force Research Lab The authors wish to gratefully acknowledge Judy Fennelly and later Ross Wainwright our technical points of contact at AFRL for their continuous support and encouragement Our contract officer Timothy Provencio also provided invaluable assistance Our critical seed stock of data was provided by Joseph Hamaker who previously was Director of NASA Headquarters Cost Analysis Division and now is Senior Cost Analyst with SAIC Ainsley Chong and Dale Martin USAF Ret also lent considerable assistance with data gathering APPENDIX A MISSIONS COLLECTED Active Cavity Radiometer Irradiance Monitor Satellite Active Magnetospheric Particle Tracer Explorer Adeos Advanced Communications Technology Satellite Advanced Composition Explorer Alexis Amos-I AMSC-1 Anik El Anik E2 Applications Technology Satellite-I Applications Technology Satellite-2 Applications Technology Satellite-5 All MREs Lu 1.00 0.75 l 0.50l 0.25 l 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75-2.00oi v 1   Cost o N X  X~~~~~Cl Figure 16 Comparison of estimating error for three best methods 15 


Applications Technology Satellite-6 Aqua Argos Atmospheric Explorer AURA Aurora 2 Calipso Cassini Cassini Spacecraft  Huygens Probe Chandra X Ray Observatory CHIPSat Clark Clementine CloudSat COBE Columbia 5 Contour CRRES DART Dawn DBS-1 Deep Impact Flyby Spacecraft  Impactor Deep Space 1 Deep Space 2 Defense Meteorological Satellite Program-5D Defense Meteorological Satellite Program-5D3 Defense Support Program DSCS 3 FIO DSCS 3 F7 DSCS I DSCS-II DSCS-IIIA DSCS-IIIB Dynamics Explorer-I Dynamics Explorer-2 Earth Observing Satellite 1 Earth Radiation Budget Experiment EchoStar 5 Extreme Ultraviolet Explorer Far Ultraviolet Spectroscopic Explorer FAST FLTSATCOM 6 Galaxy 5 Galaxy 11 Galaxy Evolution Explorer Galileo Orbiter  Probe Gamma Ray Large Area Space Telescope GE 1 GE 5 Genesis GFO 1 Globalstar 8 Glomr GOES 3 GOES 9 GOES N GPS-1 GPS-IIR GPSMYP GRACE Gravity Probe-B GRO/Compton Gamma Ray Observatory GStar4 Hayabusa HEAO-1 HEAO-2 HEAO-3 HESSI-II High Energy Transient Explorer-II HETE HST ICESat Ikonos IMAGE IMP-H Inmarsat 3-F5 Intelsat K INTELSAT-II INTELSAT-IV International Ultraviolet Explorer Iridium James Webb Space Telescope Jason 1 JAWSAT KEPLER KOMPSAT LANDSAT1 LANDSAT-4 LANDSAT-7 Lewis Lunar Orbiter Lunar Prospector Magellan Magsat Mariner-4 Mariner-6 Mariner-8 Mariner1 0 MARISAT Mars Exploration Rover Mars Express/Beagle 2 Mars Global Surveyor Mars Observer Mars Odyssey Mars Surveyor 2001 Orbiter Mars Pathfinder  Sojourner Rovers Mars Polar Lander Mars Reconnaissance Orbiter Mars Telecommunication Orbiter Mars Climate Orbiter Messenger Meteor Mid-course Space Experiment MightySat Milstar 3  Adv EHF Model-35 Morelos NATO III Near Earth Asteroid Rendezvous NEAR Shoemaker New Horizons 16 


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



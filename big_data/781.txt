Software Product Lines and Configurable Product Bases in Business Applications A Case from Financial Services  Paul D. Witman California Lutheran University witman@ieee.org    Abstract  Software Product Lines \(SPLs\ovide a methodology for creating products based on a common set of core assets. In an environment that is already broadly successful with software reuse, including large-grained software reuse, can Software Product Lines provide a framework to understand the successes of the organization? This paper presents a case study of a large financial institutionês internal software development group, and its use of SPL me 
thods and maturities  Adoption of SPL methods in business applications and the organization to support them is examined. Two different SPL maturity levels are observed, and the organization has made explicit choices about maturity levels vs. time to market requirements    1. Introduction and Motivation  While there has been much research on software reuse at the fine- and medium-grained levels, there is relatively little published on actual case studies of large-grained software reuse within corporate environments. This study focuses on a very large diversi 
fied financial services corporation, with significant software development capabilities, and their experience with large-grained reuse. It further examines how the organization has used and benefitted from Software Product Line \(SPL\methods and maturities in its development practices. The organization has a long history of successful reuse at various levels of granularity, and recently was required to begin to build and manage an additional variation to their product line We have previously defined large-grained soft 
ware reuse as object-code reuse of entire applications and systems, across environments with differing requirements for business rules, languages, presentation styles, and other elements [1  Th i s i s f u n d am en t a l l y  similar to Bosch s configurable product base  CPB\e highest defined level of SPL maturity The varying product requirements are accommodated via business rules and other runtime-binding configuration tools that enable the same object code to behave differently depending on how it is configured 
Bosch views CPBs as a higher level of maturity than SPLs. As such, it would seem unlikely that an organization would deliberately move from a CPB to a SPL maturity level. However, there is evidence from this organization that the two maturity levels may in fact coexist for the same product line, allowing the benefits of both Much work has been done on software reuse in fine and medium granularities objects, subroutines 
etc.  Relatively little work on very large-grained reuse of business applications within an organization is visible in the literature for example, reusing an Internet banking application set for independent business units in North America, Europe, and Asia  all with relatively little customization and rewriting as compared to commercial systems BigFinancial \(not its real name\d the BigFinancial Technology Center \(BTC\ in particular, have created a large number of software and hardware systems \(large building blocks\at have been reused 
in multiple businesses and countries. More recently BTC has created a product line from the core assets of its Internet banking platform and applications BigFinancial and BTC thus provide a rich source of data for case studies to examine the characteristics of those products, such as system infrastructure, automated teller machines, and Internet banking systems and why they ve been successful BTC is a technology development unit of BigFinancial, operating primarily in the western United States. Approximately 500 people are employed by 
BTC, and it is organized to deliver both products and platform components to BigFinancial. BTC s product line includes system platforms, consumer Internet banking systems, teller systems, and system management tools. BTC has previously demonstrated itself to be very successful in building many of these products as CPBs. It supports unique requirements Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


via business rules that control application behavior at runtim Potential research questions were developed in discussions with BTC research sponsors.  Some of those questions are noted below, as foundational to proposing a research design   How does BTC apply software product line methods to their products   How does the organization manage domain and application engineering   Why would a development organization choose different SPL maturity levels for portions of the same product line   Do BTC s products represent an instance of successful application of SPL methods outside of embedded systems environments  2. Literature Review  A Software Product Line approach [3u ggests that software components can be treated similarly to artifacts of physical manufacturing reusable parts that contribute to consistency across a product line as well as to improved efficiencies in manufacturing. Benefits of such reuse include the high levels of commonality of such features as user interfaces  h ich i n creas e s s w itc h i n g cos t s an d cus t o m er  loyalty in some domains. This can logically extend to banking systems in the form of common functionality and user interfaces across systems within a business and across business units Clements and Northrop define a software product line as a set of software-intensive systems sharing a common, managed set of features that satisfy the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way  T h e y t h en ide n tify the three essential activities for a successful SPL approach, including core asset development, product line development, and management Bosch i n e s a ran g e of s o f t w a re produ ct line maturity levels. The main stream of these maturity levels flows as follows   Independent products   Standard infrastructure - operating system application server, etc   Platform - capturing all common functionality   Software product line - as defined by Clements and Northr    Configurable product base large-grained reuse with configurable behavior In addition, Bosch identifies two hybrid maturity levels. These are a Program of Product Lines, wherein multiple product lines are assembled into a program of product lines, supporting a wide range of product families for very large systems, and Product Populations, where a single SPL can cover more than a single domain of products Bosch [2 f u r t he r i d e n t i fi e s  fo ur o r ga ni z a t i o na l  models in organizations using an SPL approach These include   Development department no specialization   Business unit development application engineering specialized by product   Domain Engineering separate domain engineering for one or more products   Hierarchical domain engineering hierarchy of domain engineering groups, supporting platform and product function core assets of a SPL Moving from a traditional model to one supporting software product lines requires a transition process. Clements et ent a n  A doption Factory pattern, focusing attention on product process, and organization, and defining three phases of adoption including establishment of context, establishment of production capability, and operation of the product line. Key to the initial adoption are behaviors such as mining existing assets to create the core assets from which products may be developed Mohan and Ramesh i d e i n s i gh t s on change management patterns in software product lines. They note three major patterns of issues in change management, including interdependencies among changes in separate variants and reinvented variations. They also recommend solutions to these issues, including modularized changes and variation points, careful tracking of variations, and knowledge sharing to facilitate reuse Various authors have touched on software reuse and Software Product Lines in banking technology For example, Banke alu ated th e i m pact of software reuse on development productivity in a banking organization, finding significant improvements in productivity and increases in reuse as the organization matured. Griss [10, 11 ook ed at con struction of banking components as part of a product line, and evaluated the feasibility \(in an experimental setting\ of this form of implementation. Gomaa and Webber alu ated th e e x tensibilit y of a n a u tomated teller machine SPL using a technique called variation points. However, there appears to be little published work that directly addresses the actual use of SPL methods in banking and banking technology organizations Software Product Line practices seem at this time to be concentrated in embedded systems environments. Numerous SPL case studies are published Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


e.g t m o s t are f o c u s e d o n e m bedded sy s tems. In addition, the SPL Hall of Fame ides an overview of exemplary adopters of SPL techniques, as nominated and inducted at Software Product Line conferences from 2000 - 2007. Only two of 16 entries are non-embedded application systems. As BTC is building systems clearly outside of the embedded systems environment, it will be useful to understand if they are successfully applying SPL methods in the banking application environment   3. Methods  In evaluating the research questions and research subject, a case study appeared to be an appropriate methodology. Yin c ribes th ree con d itio n s  to be evaluated in determining the type of methodology to be used.  These include the type of research questions to be asked, the control that the researcher has or needs over subjects behavior, and the degree of focus on contemporary vs. historical events Key research questions for this study are of the how and why form.  No control of subjects behavior was required to conduct the study, as the objective was to study what had happened relatively recently and what is happening leading to a focus on contemporary events  ides a s e t of t h ree criteria t h at c h a racterize situations appropriate for a case study First, where there are more variables of interest than data points available; second, where there is a need to examine multiple sources of evidence, and third where there is preexisting theory on which the case might be based. Multiple sources of evidence, including archival documents, interviews, and physical artifacts, were available and can contribute to the data collection required for this re search.  Due to the ability, within BTC, to replicate the case study process across multiple cases, and to gain greater robustness of the results, a multiple-case study was appropriate Interviews were conducted, and detailed product documents reviewed, between May, 2006 and June 2007. Interviews were semi-structured, with initial questions provided to the interviewee in advance to allow for preparation. Additional questions were added during the interviews, where appropriate, to address topics raised in the discussion. Where permitted by the interviewee, interviews were recorded. Interview notes were published in detail to the interviewee within 48 hours of the interview, allowing for their review to improve validity and reliability of the data Key to the design of a rigorous case study was early attention to establishment and retention of validity and reliability r itical ele m e n t s of t h e plan included construct, internal, and external validity, as well as reliability Construct validity was addressed by a series of steps, including the use of multiple sources of evidence, establishing and maintaining a chain of evidence, and asking key contacts at the research subject organization to review drafts of the research. Internal validity was addressed by conducting patternmatching and explanation-building as the research progressed External validity in case research requires analytic generalization, rather than statistical generalization as is used in survey research n al y t ic g e n e rali zation refers to the use of a theory derived from or enhanced during a case study being used as the foundation for study of new cases [16 Rep licatio n lo g i c  was readily leveraged in this case, as multiple cases were used. The generalization problem in case studies is similar to that of the natural sciences, as in experiments these results will have to be replicated with similar conditions to be demonstrated to be gene  Reliability was dealt with via two mechanisms These were the use of a detailed case study protocol and the development and maintenance of a case study database [15  T h ese tools prov ide th e ability  f o r another investigator to review the same raw material and come to similar conclusions  4. BTC Case Study  4.1 History of software development and reuse Prior work with BTC provided an initial model to explain their success with large-grained software reus T h is  m odel con s ide r ed elem e n ts t h at m i gh t  affect both organizational intent and organizational practices that enabled success. Since that initial review, additional data have come to light indicating the possibility of additional SPL practices contributing to the organization s success Use of SPL practices may contribute to more effective management of large-grained reuse environments, via the discipline of variant definition and management, as well as via the explicit separation of application- from domain-engineering team  BTC provides primarily domain engineering functions, while its regional technology partners provide primarily application engineering functions The authors conducted initial interviews in May and June, 2006, with BTC management to evaluate the potential cases to be used for the case studies Approximately 20 cases were offered by BTC, across numerous product lines, and dating back as far as the mid-1990s. Three cases, out of the initial set of 20 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


were reviewed in detail during those interviews, focusing on cases that establish the historical track record of BTC in creating and deploying reusable software at both medium and large granularities From this initial set of data, the researcher evaluated the contribution each case could make to both theoretical and literal replications of result  The researcher considered whether it would be useful to examine older cases \(e.g., BTC s work on ATM systems and early versions of Internet banking\t to document the older cases history at a high level, in addition to detailed study of more contemporary cases. However, those cases pre-dated any elements of SPL approaches, and thus were rejected for this study In addition to the interviews, high-level project summary documents were reviewed for each of the selected cases.  These documents identified implementation locations and timeframes, along with software version information.  Physical artifacts, in the form of Internet banking implementations viewable on the Internet, were also reviewed to further triangulate the data available from interviews and documents For the purposes of this study, two of the three key projects were further analyzed. The first of these the Java Banking Toolkit \(JBT\, provided the foundation for large-grained reuse of numerous banking service applications across multiple business units The second, Worldwide Single Signon \(WSSO\pported federation of servers and services using a single user-visible credential set Initial findings indicated that several current and recent projects showed significant reuse across independent business units that could have made alternative technology development decisions. The results are summarized in Table 1 It is worth noting that several business units used local solutions rather than reusing the shared components. Reasons for this vary, but the most commonly cited reason was an imperfect fit of the reusable application with local requirements. These requirements gaps were progressively narrowed over time, causing the numbers of businesses using local solutions to decrease. Regulatory issues and market requirements also impacted some products, such as ATM systems that required specific functionality not available in the shared software and hardware products. An example of this is cash accepting features commonly used in Japan  Table 1. Selected reuse results Project Reused in Business Units System Infrastructure Consumer Internet banking Automated Teller Machines All users of BTC s legacy Internet banking components  35 businesses worldwide Three units used a local solution System Infrastructure Internet banking  Small Business Approximately 4 business units worldwide Internet banking Europe 15 business units Internet banking Asia 10 business units One unit used a local solution Internet banking Latin America 6 business units Two units used a local solution Internet banking North America 4 business units Source: BigFinancial, BTC 4.2 Interviewees and documents BigFinancial and BTC provided access to a significant number of senior managers and key line employees to provide information about their relevant areas of expertise related to this study. The interviewees included   Director of Development for BTC provided background on projects and overview of practices and organization at BTC   Director of Overseas Deployment for BTC responsible for configuration and delivery of BTC s products to its BigFinancial operations units primarily outside the US provided insights into how BTC s products were deployed, and how a single code base was maintained   Chief Architect for BTC, responsible for architecture of BTC s product sets provided technical details about BTC s products and architectures   Lead engineer for BTC s Worldwide SSO product provided detailed insights into the evolution of the product over time, and the integration with the Java Banking Toolkit   Technology Head for BigFinancial s lead deployment region for JBT provided insights into the viability of the Java Banking Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


Toolkit to satisfy a wide range of business needs from the same object code   Director of United States Consumer Business Deployment for BTC provided insight into the rationale for creating a separate JBT application code base, and beginning to operate more like a Software Product Line BTC provided access to all documentation for the chosen products, including business and technical requirements, design documents, test plans and reports, and various administrative documents, including project plans and meeting notes. Across the two products, over 1100 documents were provided and used as foundation to the interviews, and to provide triangulation on the information provided by the interviewees  4.3 BTC Organization Organizationally \(see Figure 1\, BTC is part of BigFinancial s North American technology organization, with an indirect reporting relationship to the corporate technology organization. While geographically separate, it is placed as a peer to regional and local technology units, providing technology products and expertise to the regional and local technology and business units. It also acts to help deliver new functionality developed at regional business units to other regions, serving as a center of expertise for channeling functional enhancements between regions, for building globally reusable components, and for improving component quality and development processes. This commonality of experience encourages construction of global products, driving domain engineering up and application engineering down Despite BTC s organizational peer relationship it operates in some ways at a more corporate level than its regional technology partners. It is responsible for coordination of activities across the regional units, and is also responsible for the domain engineering function that builds core assets to meet the aggregated requirements of the regions. BTC s central role in providing expertise to the regional units enables BigFinancial s success in increasing the ratio of domain engineering to application engineering BTC s primary development role is focused on domain engineering, as suggested by Bosch o r a  CPB maturity level. There is also an element of a hierarchical domain engineering function at BigFinancial, with lesser amounts of domain engineering taking place in the regional technology units. BTC s deployment groups and the regional technology units in creating the configurations that control the behavior of the core assets, also perform application engineering functions to create products meeting the specific requirements for each deployment In recent years, BigFinancial has started to centralize technology activity into its regional technology organizations, and to remove technology units from individual lines of business. This has contributed to minimizing organizational barriers to reuse as there are now fewer organizations with the technical expertise to propose and implement alternative offerings. As such, it simplifies the organizational negotiation around what solution to choose for a given technology problem. In addition, the business units growth of experience over the years with BTC and with its product line and associated processes software, financial, etc.\o contribute to the quality of the interaction model among the organizations There are signs of globalization across the regional technology units as well, with certain regional groups taking on inter-regional responsibility for specific areas of technology development and support This promotes inter-regional commonality of technology choices, helping to ensure improved reusability of systems globally, and reducing overall costs Software development at BTC includes functions focusing on selection and integration of vendor and open-source components which will ultimately be used as core assets. In addition, the development group is responsible for the creation of software to extend and integrate those components, including tools to support language and rule configuration These functions are all part of the domain engineering process, and given the late binding of variability of the products, the bulk of BTC s engineering is classified as domain engineering BTC does perform some additional application engineering, in the form of applications built for a specific business unit, and collaborates with its regional technology partners to build some of those applications as well. BTC is thus performing application engineering, leveraging components from the core assets \(infrastructure, platform, and domain components\ild app lications specific to a business or regional need. BTC s development group has responsibility for quality assurance and performance testing for the core assets, and is also responsible for field support for the regional technology units BTC is responsible for managing deployments to all regions. Within BTC, there are two organizational units for managing deployments, one focused on the US consumer banking market, and one focused on all non-US markets, and some specific lines of business in the US market. These BTC units are comprised of relationship and project managers who work with their counterparts in the regions and businesses to gather requirements, manage projects, and plan depProceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


loyments, installations and support of the global products. The deployment groups are also responsible for creating the configuration packages that will govern the product behavior  4.4 Java Banking Toolkit \(JBT\d Applications In the late 1990 s, BTC was responsible for creation of system infrastructure components, built on top of industry-standard commercial operating systems and components, to support the banking functionality required by its customers within BigFinancial. The functions of these infrastructure components included systems management, high-reliability logging processes, high-availability mechanisms, and other features not readily available in commercial products at the time that the components were created. The same infrastructure components were used to support consumer Internet banking as well as automated teller machines. The Internet banking services will be identified, for this study, as the Legacy Internet Banking product \(LIB The requirements for the Java Banking Toolkit JBT\ the successor to LIB called for several major functional elements. The requirements were broken out among the infrastructural elements, supporting the various planned application packages, and the applications themselves. The applications delivered with the initial release of JBT included a consumer Internet banking application set, an account activity and balance alerting function, and a portal toolset Each of these applications was designed to be reused intact in each business unit around the world requiring only changes to business rules and language phrases that may be unique to a business. One of the fundamental requirements for each of the JBT applications was to include capabilities that were designed to be common to and shared by as many business units as possible, while allowing for all necessary business-specific variability, according to the requirements documents for the products Such variability was planned for in the requirements process, mining from the LIB infrastructure and applications, as well as the legacy portal and alerts services that were already in production. Examples of the region- and business-specific variability include language variations, compliance with local regulatory requirements, and functionality based on local and regional competitive requirements All core banking service functionality is supported by a single global application set. There remain, in some cases, region-specific functions required by a specific business or region. The JBT architecture allows for those region-specific applications to be developed by the regional technology unit as required, often leveraging core assets as the foundation An overview of the JBT architecture is shown in Figure 2. The core component of the architecture is a model-view-controller package, based on the opensource Struts and Tiles package. These components are extended to implement the domain requirements Configuration settings for business rules, language choices, personalization, and the like are bound at runtime, based on settings in the configuration backing store. The platform connects to banking data sources \(hosts\rough a variety of custom connection components. Specific message routing decisions are made by a message broker, independent of the model logic, to separate business logic from data sources The United States \(US\sumer business unit of BigFinancial made the decision in the early 2000s to separate its code base from the global code base for its account acquisition and marketing functions These have since operated totally autonomously to the global portal services functions used in the other regions More recently, the US consumer business also chose to create its own version of the account servicing application components used by the other regions. According to the US Deployment Director this was done based on the greater requirements imposed by the US consumer business, and the need to deliver more quickly than was possible with a configurable product base. This represented an implicit decision to move to a lower maturity level per Bosch s framework, with the expectation of faster time to market for those components The existing global code base was mined as a starting point for creation of a US-specific application set. Some updates to the US-specific application set are returned to the global code base to be shared with other regions, while others are more unique to the US environment, and remain as applicationspecific components BTC manages this US variability with two separate application engineering teams responsible for the US application components, working alongside the domain engineering teams that produce the global applications and infrastructure. Two teams are used to provide sufficient capacity for the volume of new development required by the US business. These application engineering teams use components shared with the domain engineering teams, and may create variants of those components. They may also at times return the variants to the domain engineering team for integration into future global application releases This appears to follow some of the patterns proposed by Mohan and Ramesh [8   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


With numerous independent operators of the software systems delivered by BTC, managing revision levels is a challenge. Users with a critical bug or small feature request often want that feature delivered on top of their current version, which may not be the latest stable version available from BTC. As a result variants sometimes must be created from older versions, with those content items added to the latest version at a future release  4.5 Worldwide Single Signon \(WSSO The Worldwide Single Signon \(WSSO\functionality was conceived in the late 1990s. Early versions of online banking functionality were becoming more readily available, and additional Internet-facing features were being created by both internal groups at BigFinancial and by vendors and partners. BigFinancial s various business units were attempting to offer a rich consumer experience on the web, but to do so they were required to integrate offerings from multiple sources, servers, and vendors. The WSSO product is delivered independently for reuse across numerous products within BigFinancial, and is also delivered as a core asset component of the JBT product The initial version of WSSO was built in 1999 and its first target was services for small business banking. This version leveraged a commercial encryption package to create a secure token that was encrypted and signed by the authenticating entity and was verified and decrypted by the relying entity Contents of the token included such data items as basic customer identification information, transaction time stamp, and other demographic data that could be used by the relying entity to establish a session for the end user Additional functionality was added to the initial package over the next few years, including components for session coordination, support for additional encryption models and token formats, and support for additional operating platforms. This latter addition was accomplished while porting the code to Java from the original C++. With each successive version the product was delivered in object-code form to all customers, and made configurable and backwardscompatible, thus operating as a CPB BTC reports that WSSO is actively reused in a number of product lines within BigFinancial, and in cooperation with third party vendors and business partners. Products integrating WSSO included consumer and small business offerings, and ranged from portal services to credit card services, payment services, and alerting services. In addition to WSSO s use within JBT \(for portals, Internet banking, and alerts\ also reused independently \(e.g., for account opening, online statements, and brokerage services The requirements for WSSO have evolved through the years, both with additional usage within BigFinancial and among its partners, and as technology needs of the businesses have changed. As noted previously, the initial requirements focused on a single business, but the initial design supported extensibility for other environments and encryption models  5. Observations and Limitations  5.1 Observations While operating strictly on a code-reuse/single code base model, BigFinancial and BTC exhibit significant usage of SPL methods and practices as extended by Bosch n bu i l d i n g a conf i g u r abl e product base. The details of exactly how BTC develops and reuses its components were critical to that evaluation. It was found, after review of BTC s activities that BTC s traditional \(large-grained reuse\model does not directly match Clements and Northrop s SPL concepts for its global applications. BTC s practice was to modify only business rules and other configurations, rather than modifying parts of the product line components to provide features specific to a particular product incarnation. Thus BTC was found to be operating at a CPB rather than a SPL maturity level JBT operates as a configurable product base in many respects. The majority of the total functionality for each business unit is provided by a shared, globally reused code base, configured at run time. BigFinancial extends that model with region-specific applications that are often based on existing core assets and are often returned to the global asset base for reuse regionally or globally. BTC s mining of prior legacy products for core assets for reuse also appear to use at least part of the Adoption Factory pattern  T h is en ables both B T C  an d Big F i n an cial s regional technology groups to more quickly build or configure applications for JBT to meet business needs. It is also worth noting that the SPL model appears to function effectively across wide geographic separation JBT s US application set has recently been created as a separate product line, based on the core assets from the global application set, and appears to be managed as one application set derived from and built on the global application base. In these ways BTC appears to be using SPL methods, in the evolution of variants from a common code base BTC s development group operates primarily as a domain engineering function, while its deployment groups and the regional technology units operate as Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


application engineering functions. BigFinancial s organization structure is unusual in that BTC is placed organizationally as a peer to its regional technology partners, but functions more at a corporate level to provide various technology leadership functions, including performance and quality assurance processes, global requirements leadership, and coordination across regional units BTC and BigFinancial made an explicit decision to move from a configurable product base to a software product line for the US version of its JBT product set. Based on its own observations about time to market for domain-engineered components, BTC determined that it would achieve faster time to market by using a software product line for its US customer. This is supported by the literature, noting that initial time to market for reusable components is often longer than for custom-built components This combination of CPB and SPL maturities for a single product line may be a new combination of maturity levels not fully accounted for by Bosch Only the Program of Product Lines integrates CPB and SPL matu T C s usage for its US and global Java Banking Toolkit applications does not match the model of multiple separate SPLs being combined into a larger SPL, as described by Bosch BTC s WSSO product also operates as a CPB WSSO fulfills a specific set of functions in a configurable way, and is reused intact across all products that integrate it. WSSO s reuse does not come in the form of developing more instances from a common set of core assets. Rather, WSSO is itself reused, intact, to support the needs of each of the various businesses in a highly configurable fashion. In that sense given WSSO s function as a component of JBT, it operates as a core asset for the Java Banking Toolkit  It is used in the construction of products on the JBT platform for those products that require Single Signon capabilities Like the JBT product, the WSSO product also tends to behave like a product line on a temporary basis as well. New feature requirements or bug fixes are required to be applied to an older version, creating a variant that is later merged back into the domain artifacts An additional instance of the SPL maturity level may well be used in applications being created for the credit card, mortgage, and consumer finance operations of BigFinancial. These groups may leverage the US model and mine from the core asset base of global applications, creating separate variants from those that are unique to their individual business needs BTC s central role in BigFinancial clearly contributes to BigFinancial s success in high-maturity SPL approaches. In this role, BTC is positioned to support domain analysis in what Neighbors called a strategic planning role 1 s u pportin g agg r eg a tion of product line requirements across regions, and supporting the sharing of core assets for construction of applications. BTC s history of successful reuse, and its long relationship with its regional technology partners, enables it to ope rate in a leadership role despite its peer relationship in the organization chart SPL methods were thus used by BTC to extend their capabilities to deliver products to customers The SPL methods appear to operate in synergy with BTC s existing large-grained reuse model. The SPL methods enable BTC to continue to build globallyreusable applications \(as a configurable product base\while supporting a software product line model for its US customer  5.2 Limitations  This study looked at only one institution, and focused on one primary development organization within that institution. This clearly limits the generalizability of the study.  The study is limited to the banking industry, and to a multi-national banking organization, and so its findings may not be applicable to smaller institutions or to other industries While BTC s work shows elements of the use of SPL methods and practices, neither BTC nor BigFinancial staff was focused on this stream of work Therefore, inferences about what is actually happening are based on evidence provided by the research subjects, and not based on a demonstrated program of compliance to SPL methods and practices  6. Conclusions and directions for future research  The two cases \(JBT and WSSO\amined here have shown significant use of high-maturity SPL methods and practices. The organization has made an unusual choice to operate one of its product lines both as a configurable product base and as a software product line. This appears to be a new variation on the maturity levels defined by Bosch e w o u l d  argue that organizations will make pragmatic decisions about software development models to best optimize resource and delivery requirements for their clients The organization is operating outside the area of embedded systems, and thus provides another source of evidence of the potential applicability of these methods in business application systems. Further BTC and its BigFinancial technology partners are operating as internal technology suppliers, offering another variation from the more commonly-seen SPL adopters such as software or systems vendors. BigFiProceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


nancial s organizational model provides examples of the separation of domain and application engineering functions Future research opportunities include the observation of ongoing change management at BTC, to validate that SPL methods and practices are indeed sustained, and to observe changes in maturity over time. BTC has now been introduced to the concepts of the Software Product Line and Configurable Product Base, and may choose to adopt these maturity levels more explicitly We will also seek out other application software vendors or internal development groups using this approach, to attempt to gather more evidence of SPL adoption in application systems. Numerous opportunities for such adoption exist, primarily in the licensed software environment, where large packages of core components are delivered to clients and customized to their specific needs In addition, the growing market for Software as a Service \(SaaS\will provide opportunities for research on applications of Configurable Product Bases. SaaS vendors appear to use a configurable product base to support their high degree of scalability and rapid delivery  7. Acknowledgements  The author is grateful to the research subjects for their candid input, and especially to Dr. Timo K‰kˆl and the reviewers for their constructive feedback  8. References    Wit m an P  an d T  R y a n  Innovation in Large-Grained Software Reuse: A Case from Banking in Hawaii International Conference on System Sciences 2007. Waikoloa, HI: IEEE Computer Society  Bos ch  J Maturity and Evolution in Software Product Lines: Approaches, Artefacts and Organization in Software Product Lines 2002, Springer Berlin: Heidelberg Germany. p. 247-262   C l e m en t s P. an d L  M. Nort h rop Software Product Lines: Practices and Patterns 1st ed. The SEI series in software engineering 2002: Addison-Wesley Professional. 608 4 iss  M  L   Software reuse: From library to factory IBM SYSTEMS JOURNAL, 1993 32 4\ p. 548-566 5 r ue ge r   C W    New Methods in Software Product Line Practice Communications of the ACM, 2006 49 12\ p. 37-40   Malan R   an d K Wen t zel  Economics of Software Reuse Revisited 1993, HewlettPackard Software Technology Laboratory Irvine, CA. p. 19   C l e m en t s P  C et al  Getting There from Here: A Roadmap for Software Product Line Adoption Communications of the ACM 2006 49 12\ p. 33-36 8 M o ha n  K  a n d B   Ra me s h   Change Management Patterns in Software Product Lines  Communications of the ACM, 2006 49 12 p. 68-72   Ban k e r, R  D. an d R  J. Kauf fm an  Reuse and Productivity in Integrated Computer-Aided Software Engineering: An Empirical Study  MIS Quarterly, 1991 14 3\ p. 374-401  Gris s   M L   Implementing Product-Line Features with Component Reuse in 6th International Conference on Software Reuse  2000. Vienna, Austria  Gris s   M L  Product Line Architectures in Component-Based Software Engineering Putting the Pieces Together G.T. Heineman and W. Councill, Editors. 2001, AddisonWesley   Go m aa, H. an d D L  Webber Modeling adaptive and evolvable software product lines using the variation point model in 37th Annual Hawaii International Conference on System Sciences 2004. Hawaii: IEEE  Bos ch  J Product Line Architectures in Industry: A Case Study in ICSE '99 1999 ACM: Los Angeles, CA. p. 544-554 14  So ft w a r e E ngi ne e r i n g I n s t i t ut e   Software Product Line Hall of Fame 2008  [cited 2008 May Av ai lable f r o m   http://www.sei.cmu.edu/productlines plp_hof.html   Yin   R  K Case Study Research: Design and Methods 3rd ed. Applied Social Research Methods Series. 2003, Thousand Oaks, CA Sage Publishing. 181  Sm al i n g   A  Inductive, analogical, and communicative generalization International Journal of Qualitative Methods, 2003 2 1 p. Article 5  L ee A  S  A Scientific Methodology for MIS Case Studies MIS Quarterly, 1989 13 1\ p 33-52  Nei g h bors  J Software Construction using Components in Department of Information and Computer Science 1980, University of California, Irvine: Irvine, CA. p. 75   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


          Figure 1. BigFinancial/BTC Organization Structure   Promos J2EE App Server Promos  Figure 2. Java Banking Toolkit Architecture Overview  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


California Mexicali Mexico He is currently completing the requirements for the Master's in Science in Electrical Engineering at California State University Long Beach 11 


 12 7  C ONCLUSIONS AND F UTURE W ORK  This research task started with an all-FORTRAN implementation of the FTIR spectrometry algorithm converted it to C code, and developed a number of H W/SW systems on the V4FX60 hybrid-FPGA The execution ti me of the all software C implementation of the FTIR spectrometry algorithm was recorded and used for comparison as a base case Two software-based optimizations were applied that reduced the executi on time by more than 4.5x These included modifying the cod e to use all single-precision math library functions no n-ANSI when dealing with single-precision data and utilizi ng the IBM Performance Libraries  Perflib  to improve the speed of all single and double-precision arithmetic The idea of using a DP-only Perflib was introduced and then used in conjunction with the single-precision APU-FPU to fu rther improve system performance The bulk of the research dealt with looking into ha rdwarebased improvements to the FTIR spectrometry system  These included the Xilinx APU-FPU, and a single-pre cision dot-product co-processor The APU-FPU delivered significant speedup for all single-precision floati ng-point operations The dot-product co-processor although ineffective in the FTIR spectrometry system due to poor spatial locality of the data, showed nearly a 2x im provement over the APU-FPU when working with smaller, sequent ially accessed data sets Furthermore it was implemented  as a load/store-based APU-connected FCM thus establishin g a reference for creating similar APU co-processors T he design of a non-system-bused CPU-coupled co-process or is frequently overlooked in design guides yet it is a  very effective way to offload software routines to hardw are implementation The ML410 development board on which all of this w ork was conducted, hosts the V4FX60 hybrid-FPGA contain ing two PPC405 processors This research task focused o n optimizing the performance of the FTIR spectrometry  algorithm on a single PPC405 core, however, the des ign can be extended to utilize both available cores. Figure 16 on the following page shows a dual-core design that can be  implemented on the ML410 board The two PPC405 processors each have dedicated PLB interfaces but s hare a common OPB. On the common OPB, the processors need to negotiate access to the RS232 UART and SystemACE CF  controller. This negotiation can be done through du al-ported shared BRAM accessible by each processor from thei r respective PLB. The ML410 board has two external me mory interfaces that are both utilized in this concept PPC405 CPU0 uses the DDR2 DIMM 256 Mbytes while PPC405 CPU1 utilizes the DDR on-board component memory 64  Mbytes\. Each of the processors has some dedicated on-chip memory OCM connected through OCM interface The instruction side OCM is particularly necessary so e ach processor can store its own boot code in its own on chip memory as booting both processors from external mem ory may not be possible Both processors have their own FPUs connected on dedicated FCB interfaces Since the processing of individual interferograms is a comple tely independent task an up to 2x reduction in executio n time may be possible with a dual-core system However o ne bottleneck that may limit the speedup is negotiatin g access to the shared CF card controller Additional improvement to the overall performance o f the FTIR spectrometry system may be possible by rewriti ng the software in C. The automatic conversion from FORTRA N to C using f2c most likely does not produce optimal code, and it is certainly not appealing to read Some functio ns may also need to be rewritten with an optimized pattern  of data access This can help in cases such as the dot-prod uct coprocessor Further performance improvement may be achieved by trying a different compiler one that is specifical ly targeted for the embedded PPC405 processor A V2P performanc e study done at the NASA Goddard Space Flight Center concluded that using the WindRiver Diab DCC 5.2 com piler provides a 38 performance increase over the GNU-GC C 3.4 compiler The comparison was based on running a  Dhrystone benchmark application on a 400 MHz PPC405 design The GNU-GCC compiler achieved 458 DMIPS while the WindRiver Diab DCC achieved 628 DMIPS as  reported by Xilinx\ [10   Implementing additional hardware co-processors may result in the further reduction of execution time Using t he dotproduct design as a reference the FFT function fo r example can be implemented in the hardware This w ill help in the spectrum computation component of the s oftware processing. It may be necessary to re-arrange the d ata access pattern for optimal co-processor performance to av oid the pitfall seen when deploying the dot-product core Finally, no embedded processing system is complete without an OS. Linux is a good choice and is supported by X ilinx in EDK It is important to first finalize the hardware  design prior to deploying the OS Support for the APU may be lacking in Linux and getting the OS to recognize th e hardware FPU may be a project in itself For the FTIR spectrometry algorithm this research task started the process of moving from an all software system to a mixed HW/SW implementation on the V4FX60 hybridFPGA In the best case a more than 8x speedup was achieved compared to the FTIR base system This implementation, although nearly 2x faster the V2P s ystem at NASA JPL still lags behind the current state-of-th e-art space processor  the BAE RAD750 However the marg in between the two was narrowed down significantly and with further research as suggested above will most lik ely be eliminated altogether Directly benefiting from the  work presented in this paper is a 3-year JPL technology 


 13 development task that will support the MATMOS on-bo ard processing implementation for a future flight i nstrument   Fig. 16 Dual-core concept targeting ML410 development boar d 


 14 R EFERENCES  1  D L Bekker Hardware and Software Optimization of Fourier Transform Infrared Spectrometry on HybridFPGAs  MS Thesis Rochester Institute of Technology Rochester NY August 2007 Available http://hdl.handle.net/1850/4805  2  P J Pingree J.-F L Blavier G C Toon and D  L Bekker An FPGA/SoC Approach to On-Board Data Processing  Enabling New Mars Science with Smart Payloads in IEEE Aerospace Conference 2007  Big Sky MT March 2007 Available http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnu mber=4 144550&arnumber=4161501  3  S I Feldman D M Gay M W Maimone and N L Schryer, ìA Fortran-to-C Converter,î Computing Scie nce Technical Report 149, AT&T Bell Laboratories, Murra y Hill NJ March 22 1995 Available http://www.netlib.org/f2c/f2c.pdf  4  IBM PowerPC Embedded Processor Performance Libraries tech rep IBM Microelectronics Divisi on Hopewell Junction, NY, December 12 2003 5  Virtex-4 Data Sheet: DC and Switching Characterist ics Datasheet DS302 Xilinx Inc San Jose CA March 27 2007 Available http://www.xilinx.com/bvdocs/publications/ds302.pdf  6  ML410 Embedded Development Platform  Xilinx Inc San Jose CA March 6 2007 Available http://www.xilinx.com/bvdocs/userguides/ug085.pdf  7  G Toon J.-F Blavier M McAuley and A Kiely Advanced On-Board Science Data Processing System for a Mars-orbiting FTIR Spectrometer R&TD Task 01STCR  R.05.023.048 NASA Jet Propulsion Laboratory Pasadena, CA, 2005 8  APU Floating-Point Unit v3.0 product specificati on Xilinx Inc San Jose CA January 26 2007 Availa ble http://www.xilinx.com/bvdocs/ipcenter/data_sheet/ap u_fp u.pdf  9  PowerPC 405 Processor Block Reference Guide Xilinx Inc San Jose CA July 20 2005 Available www.xilinx.com/bvdocs/userguides/ug018.pdf  10  D. Petrick, ìAnalyzing the Xilinx Virtex-II Pro Pow erPC with the Dhrystone Benchmark Applications,î tech. r ep NASA Goddard Space Flight Center Greenbelt Maryland Available http://klabs.org/DEI/Processor/PowerPC/v2pro_ppc_pe rf ormance_petrick.doc  B IOGRAPHY  Dmitriy Bekker has just completed his Masters Degree in Computer Engineering at the Rochester Institute of Technology in Rochester NY His areas of interest include FPGAs embedded systems digital signal processing and system architecture. He has coop  internship experience working at Brookhaven National Laboratory Syracuse Research Corporation NASA Dryden Flight Research Center, and the Jet Propulsion Laboratory. He recen tly won in the 2006 IEEE Student Design Contest for his pro ject in autonomous vehicle navigation. He is a member of IE EE Dr Lukowiak is an assistant professor in the Computer Engineering Department at Rochester Institute of Technology in Rochester NY His research interests are concentrated in the area of multidisciplinary projects that require modeling and hardware implementations FPGA and ASIC of data processing systems Dr Marcin Lukowi ak obtained his Ph.D in Technical Sciences from the P oznan University of Technology in October 2001 Muhammad Shaaban is an associate professor of computer engineering at the Rochester Institute of Technology His research interests include high performance computing processor microarchitecture heterogeneous and reconfigurable computing Shaaban has a PhD in Computer Engineering from the University of Souther n California. He is a senior member of the IEEE Dr. Blavier first joined the JPLMkIV Team in August 1985 as a contractor from Ball Aerospace He participated in the MkIV campaigns in McMurdo Antarctica groundbased and from Punta Arenas Chile NASA DC-8 In late 1987, he started graduate work with Profs Delbouille and Dubois at the University  of LiËge Belgium his research tasks included install ing the 


 15 Fourier transform spectrometers at the Internationa l Scientific Station of the Jungfraujoch Switzerland  for atmospheric measurements and at the Institute of Astrophysics in LiËge for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engin eer and participated in all the MkIV campaigns since th en \(one DC-8 campaign 19 balloon campaigns Dr J.-F Bla vier obtained his Ph.D in Physics from the University o f LiËge in July 1998 Paula Pingree is a Senior Engineer in the Instruments and Science Data Systems Division at JPL She has been involved in the design integration test and operation of several JPL flight projects most recently Deep Impact DI She has worked on the Tunable Laser Spectrometer development for the 2009 Mars Rover and is presently the Electronics CogE for the Juno Mission s Microwave Radiometer She also enjoys research and technology development for Smart Payloads in her s pare time Paula has a Bachelor of Engineering degree i n Electrical Engineering from Stevens Institute of Te chnology in Hoboken, NJ, and an MSEE degree from California State University Northridge.  She is a member of IEEE 


  16  Figure 15. AIRS-AMSRE differences as a function of AIRS error estimate over one day  AIRS has an error estimate of the total water vapor value that it calculates. The diffe rences between AIRS and AMSR-E are shown as a function of this estimate in figure 15 and very little correlation is found 11  R ELEVANT W ORK  Merged A-Train Level 2 Data A merged product that preserves the relationship of observed atmospheric water properties facilitates the hydrological studies by enabling scientists to get directly at the model data without worrying about the logistics of finding, collecting, and coordinating the measured quantities from different instruments. Previously there did not exist a capability to discover and access data from the A-Train\222s multiple instruments as merged multi-parameter data sets Enabling Orchestratable Service Workflows Our distributed service-oriented approach of loosely coupled services also enable s a higher level of reusability and orchestration with other services. Increasing numbers of workflow engines are already supporting Web Services as components/operators, which can then be orchestrated together into higher-level meta/virtual services SciFlo, a Scientific Dataflow Execution Environment, is a workflow engine that already supports assembling reusable SOAP Services, native execu tables, local command-line scripts, and codes into a distributed computing flow \(a graph of operators\8 SciFlo can u tilize o u r g en eric SOAP services as part of a larger coordinated data flow The Taverna Workbench is a free software tool for designing and executing workflows. Like SciFlo, it can orchestrate SOAP-based Web Services as components within a workflow. Taverna provides a visual editor to construct and edit the sequence of services in the workflow We have found that Taverna can dynamically introspect a given WSDL and construct the workflow component interface representing it Giovanni Giovanni, an acronym for the Goddard Earth Sciences Data and Information Services Cent er, or GES DISC, Interactive Online Visualization and Analys is Infrastructure, is a webbased tool to help visualize Earth science data  It  provides a simple and intuitive way to visualize, analyze and access vast amounts of Eart h science remote sensing data without having to download the data. Similar to the services developed here, it addresses the difficulties of traditional data acquisition and analysis methods by moving the complexity to the server-side Giovanni provides multiple in terface instances based on instrument and measurement ty pes. For example, the \223ATrain Along CloudSat Track Inst ance\224 can provide plots of vertical profiles of clouds, temperature, humidity, cloud and aerosol classification across the multiple instruments of the A-Train A distinction between Givanni\222s A-Train data and the data set in this paper is that we are using a formal merged product of the A-Train. We leverage the NEWS effort that is based on error- and resolution-weighted mean of the input data sets, with associated uncertainty estimates. This provides a formal model of the collective A-Train observations rather than the collection of the individual instrument measurements Each of Giovanni\222s multiple interface instances provides a very simple and easy to use web interface. However, we recognized that sometimes scientists want more than the simple interfaces. Some scien tists may want to process Level 3 products using their own trusted code, or may want to perform variations of their own plots. With Giovanni, the individual scientist wanting more custom advanced capabilities must depend on the Giovanni development team Giovanni is based on the web portal paradigm where users visit a web page and use web tools to find and visualize data. Similar to Giovanni, our client APIs also make data acquisition more seamless. However, our services are based on the different paradigm were the power and flexibility of data analysis and processing are shifted back into the scientists own familiar computing environments. We realize that scientists generally want to perform \223exploratory computing\224 where they can sere ndipitously analyze the data using their own familiar and trusted code 


  17 Giovanni 2 was inherently synchronous where processing was bounded to a single http session. Long service running times still require the user to hold the same http session Similar to our asynchronous Web Service we discussed, the upcoming Giovanni 3 will be supporting asynchronous sessions. They will be using a RSS feed to monitor the service request. Version 3 will also be based on a servicesoriented architecture, wher e Giovanni services can be offered as a standard SOAP Web Services. This is similar to our approach, as well as SciFlo\222s services 12  C ONCLUSIONS  To achieve the science research goal of investigating longterm and global-scale trends in climate, water and energy cycle, and weather variability, we enhanced and improved on existing algorithms to work with distributed and heterogeneous data and information systems infrastructure By developing a service-oriented architecture for discovering, accessing, and mani pulating of NEWS merged A-Train data sets, we can strengthen the interconnectedness and reusability of these services across broader range of Earth science investigations The merged NEWS Level 2 data is a formal model containing the voluminous data from the AIRS, AMSR-E MLS, MODIS, and CloudSat instruments. Previously scientists wanting to perform long-term and global-scale studies encompassing simultaneous measured quantities would quickly face a data acce ss hurdle of first finding the data, then manually downloading them, and finally merging the data into a cohesive model\227before starting their analysis. Additionally the voluminous nature of the data particularly because of the MODIS data\each scientist potentially downloading the same data resulting in redundancy of reprocessing on the client sides. Our paradigm pushes more of the commonly repeated processing onto the server side. Moreover, this avoids repeated downloading of the same data among the science users. We can deliver customi zed averaged, subsetted, and summarized data of the merged A-Train observations to the scientists for them to immediately begin their analysis work We recognized that scientists also often want to perform 223exploratory computing\224 where they can freely explore the aspects of the data and run serendipitous exploration in their own familiar environment. We developed client-side distributed APIs in popular analysis environments such as Matlab, IDL, and Python. Our APIs hide the complexity of Web Services and allow the service capabilities to be embedded in the scientists own computing environments By purposely avoiding the \223web portal\224 paradigm and providing the suite of platform specific APIs in each of these language platforms, we enable the scientists to remain within their own familiar environments to select, process and download the data seamlessly into their environment for their own further analysis. Alternative methods involving web portals force the scientists to leave the environment and manually interact with the web portal to search and download the data We can examine not only long-term changes in amplitude of a single variable but also those among multiple variables Our L3Q clustering method was specifically designed to preserve information about the covariability of multiple observations, such as those from the A-Train.  Weather and climate variability is characterized by changes among atmospheric observables, but those changes have been limited by a lack of observations and analytical techniques We are not aware of any multi-parameter analyses to date The full potential of the A-Train climate record will not be realized until the multi-parameter climatology is understood. The work presented is one method of approaching this difficult problem Our service tool addresses several objectives of the NASA Earth science data community including 1\mprove interoperability to facilitate the transparent access and manipulation of heterogeneous and distributed data by science users, 2\ransition and deploy existing Earth science research analysis tools and software using a 223Service Oriented Architecture\224 \(SOA\ to enhance their reuse potential for other science domains and improve overall awareness and access of these tools by a broad community, 3\ increase users\222 ability to customize their discovery, access, deliv ery, manipulation, and preferred format of data and information 12  F UTURE W ORK  On-demand Level 3T Summaries from Level 3Q We plan to develop services for creating custom summaries of the L3Q data into more refined Level 3T summaries L3T\create their own custom Level 3 products on demand from L3Q. The custom Level 3 products are the transformation of L3Q data based on user-specific objectives such as regression and correlation analyses. The cust om production will generate not only the transformed data but also the statistical estimation of the accuracy of the summarized data based on the distribution of L3Q and the quality of L3Q Delegating the Temporal-Spatial Data Querying Currently, our processing layer utilizes existing and legacy processing code that was developed in IDL, Matlab, and C++. Though the original intent was to be able to adapt existing code and wrap as a service, this meant maintaining its original form of accessing the source data for processing Small modifications were made to enable these codes to quickly access the data based on file path and file naming schemes. However, we want to decouple the file accessibility and processing roles 


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



A Rough Set Foundation for Spatial Data Mining Involving Vague Regions Theresa Beaubouef Computer Science Depaltment Southeastem Louisiana University Hammond LA 70402 USA Abstract  The RCC and egg-yolk methods have proven useful for representation of vague regions in spatial data Here we model them using rough set theory. This then develops the hasis to allow a rough set approach to uncertainty in spatial relationships for association NI and other forms of spatial data mining 1 INTRODUCTION Spatial databases and qualitative reasoning about spatial data are active areas of research encompassing artificial intelligence, databases and information systems, data mining 
geometry, geography, and many more research fields. Results from research in spatial data and reasoning are especially useful in geographic information systems CIS spatial databases containing data that is geo-referenced to specific locations on the earth, along with mechanisms for reasoning about this spatial data As with any system that attempts to model some aspects of the real world, there must be some mechanism for the management of uncertainty. Uncertainty management is particularly necessary in resolving a myriad ofproblems inherent in spatial information systems I A spatial database is a collection of data conceming objects located in some reference space, which attempts to model some enterprise in the real world. The real world abounds in uncertainty, and any attempt to model aspects of the world should include some mechanism for incorporating 
uncertainty. There may be uncertainty in the understanding of the enterprise or in the quality or meaning of the data. There may be uncertainty in the model, which leads to uncertainty in entities or the attributes describing them. And at a higher level, there may be uncertainty about the level of uncertainty prevalent in various aspects of the database In data mining applications, one must not only be aware of uncertainty, but also to exploit it in an effort to discover relationships in data that might not have been discovered otherwise A fundamental aspect of spatial data mining requiring uncertainty management is topology. Included in topology are relationships between various spatial data entities Of particular interest are topological relations associated with regions having indeterminate, vague 
or otherwise uncertain boundaries. Spatial relations such as intersects, adjacent overlaps etc have been used in discovering association rules and generalized attributes for spatial data[2]-[3 We have also developed an extension to spatial association rules mining using a fuzzy set approach to represent the uncertainly in the spatial relationships used io the rules 4 In this paper we develop the basis to also allow a rough set 0-7803-7280-8/02/$10.00 02002 IEEE 767 Frederick E.Pehy Naval Research Laboratory Mapping Charting and Geodesy Stennis Space Center MS 39529 Sabbatical leave from Tulane University New Orleans LA approach to uncertainty in spatial relationships for association 
rules and other forms of spatial data mining In relational databases it has been demonstrated that uncertainty may be managed via rough set techniques by incorporating rough sets into the underlying data model 5 and through rough querying of crisp data 6 In a previous work 7 we pointed out those areas peculiar to spatial databases and GIS which are in need of uncertainty management and suggest ways in which rough sets techniques may be used to alleviate the problems to result in a better overall system Most of these unresolved problems are mentioned in one form or another in  11 which also provides an excellent background for spatial information 
systems In this paper we focus on the problem of uncertainty in topological structures in spatial data, and in particular to spatial regions with uncertain boundaries. We investigate the application of rough sets 8 for improving the RCC 9 and egg-yolk lo models This will result in better uncertainty management in general, for the spatial data system, and better results for data mining applications II ROUGH SETS AND UNCERTAINTY IN DATA Rough set theory, introduced by Pawlak PI is a technique for dealmg with uncertainty and for identifying cause-effect relationships in databases as a form of data mining and database learning 
 1 I It has also been used for improved information retrieval  121 and for uncertainty management in relational databases 5]-[6 Rough sets involve the following U is the universe which cannot be empty R is the indiscemibility relation or equivalence relation A  R an ordered pair is called an approximation space x denotes the equivalence class ofR containing x for any element x of U elementav se*i in A  the equivalence classes of R definable set in A 
 any f~te union of elementary sets in A Hence, the approximation space A results when an equivalence relation R is imposed upon the universe U This partitions U into equivalence classes called elementary sets that may be used to define other sets in A A rough set X is then defined in terms of the definable sets in A by the following lower approximation ofXin A is the set upper approximation of X in A is the set Ru={x I IXIR GXl  RX=\(x\200U 1 xIRnX#Q 


We may also describe the set approximations in terms of regions Given upper and lower approximations R X and U of X the R-positive region of X is POSR\(X a the R-negative region of X is NEGn\(X  U  R X and the boundary or R-borderline region of X is BNR\(X  EX  X X is called Rdefinable if and only if X  lower and upper approximation regions are not equal and X is rough with respect to R In Fig 1 the universe U is partitioned into equivalence classes denoted by rectangles. Those classes in the lower approximation of X POSR\(X are denoted with the letter P and classes in NEGR\(X by the letter N Other classes belong to the boundary region of the upper approximation U   X Otherwise, the Consider the following example Let U  BRIDGE ROAD STREET AVENUE FACTORY Let the equivalence relation R be defmed as follows R   road street avenue factory PLANT, FOREST WOODS BEACH FIELD MEADOW FOREST  BEACH FIELD MEADOW Given some set X  BRIDGE ROAD STREET AVENUE FOREST, WCODS we can define it in terms of its lower and upper approximations  RX  BRIDGE ROAD, STREET AVENIIE and R X  BRIDGE ROAD STREET AVENUE, FACTORY  PLANT, FOREST WOODS The major rough set concepts of interest are the use of an indiscemibility relation to partition domains into equivalence classes and the use of lower and upper approximation regions to allow the distinction between certain and possible or partial inclusion in a rough set The indiscemibility relation allows us to goup items based on some definition of 221equivalence\222 as it relates to the application domain We may use this partitioning to increase or decrease the granularity of a domain to group items together that are considered indiscemible for a given purpose, or to 223bin\224 ordered domains into range groups Data mining applications may vary the partitioning of don\224 in systematic ways m the attempt to discover relationships or rules in the data. The indiscemibility relation is fundamental to rough sets The approximation regions can only be defmed in terms of the indiscemibility relation and the equivalence classes it creates certain results encountered in querying an ordinary spatial database system we may employ the use of the boundary region information in addition to that of the lower approximation region. The results in the lower approximation region are certain They correspond to exact matches The boundary region of the upper approximation contains those results that are possible but not certain. Data mining techniques which are based on rough sets discover both certain and possible rules om the data The approximation regions play an important role in the discussion of vague regions and topological relationships presented in a later section all types of databases systems. Spatial databases and GIS contain descriptive as well as positional data The various forms of uncertainty occur in both types of data so many of the issues discussed below apply to ordinary databases as well See 5,6 for in-depth discussion of implementation of rough set uncertainly in non-spatial\databases These same techniques including integration of data from multiple sources, time-variant data, uncertain data imprecision in measurement, inconsistent wording of descriptive data and 223binning\224 or grouping of data into fixed categories also are employed in spatial contexts 7 Often spatial data is associated with a particular grid The positions are set up in a regular matrix-like structure and data values are associated with point locations on the grid There is a tradeoff between the resolution or scale of the grid and the amount of system resources necessary to store and process the data. Higher resolutions provide greater information, but at a cost of memory space and execution time Data mining applications using high resolution data may sample it at a lower resolution in an effort to improve performance or to remove \223noise\224 which may prevent general relationships from being discovered By taking a rough set viewpoint one can see that there is indiscemibility inherent in the process of gridding or rasterizing data. A data item at a particular grid point in essence may represent data near the point as well This is due to the fact that often point data must be mapped to the grid using techniques such as nearest-neighbor, averaging or statistics We may set up our rough set indiscemibility relation so that the entire spatial area is partitioned into equivalence classes where each point on the grid belongs to an equivalence class If we change the resolution of the grid we are in fact changing the granularity of the partitioning resulting in fewer, but larger classes The approximation regions of rough sets come into play whenever information concerning spatial data regions is accessed Consider a region such as a forest One can reasonably conclude that any grid point identified as FOREST that is surrounded on all sides by grid points also identified as FOREST is in fact a point represented by the feature FOREST However, consider points identified as FOREST that are adjacent to points identified as MEADOW In order to allowpossible results in addition to the obvious Many of the problems associated with data are prevalent in 0-7803-7280-8/02/$10.00 02002 IEEE 768 


Is it not possible that these points represent meadow area as well as forest area but were identified as FOREST in the classification process? Likewise, points identified as MEADOW but adjacent to FOREST points may represent areas that contain part of the forest This uncertainty maps naturally to the use of the approximation regions of the rough set theory, where the lower approximation region represents certain data and the boundary region of the upper approximation represents uncertain data It applies to spatial database querying and spatial database mining operations If we force a finer granulation of the partitioning \(increase the grid resolution\a smaller boundary region results As the partitioning becomes finer and finer, fmally a point is reached where the boundary region is non-existent. Then the upper and lower approximation regions are the same and there is no uncertainty in the spatial data The RCC and egg-yolk methods, which we discuss in later sections are approaches for handling regions with uncertain boundaries. They use two levels for outlining the vague boundary, which basically corresponds to the approximation regions of rough set theory. These methods, however, provide no facilities for partitioning the domain into equivalence classes as done in rough sets via the indiscemibility relation In fact, Roy and Stell I31 discuss the shortcomings of the egg-yolk method if it is to be applied to discrete rather than continuous space. They suggest that the egg-yolk method can be used in a multi-resolution context for a f~te level of precision and that an extension to the framework may be appropriate. By varying the partitioning in rough sets we can increase or decrease the level of uncertainty present. This results in changes to the approximation regions that define the rough set representation of a region with indeterminate or vague boundaries. The idea that rough sets can in fact improve on other spatial data frameworks by quantifying the uncertainty in terms of varying levels of indiscemibility is part of the motivation behind this research 111 TOPOLOGICAL UNCERTAINTY IN SPATIAL DATA In GIS or spatial databases, it is often the case that we need information conceming the relative positions or distances of objects Is object A udjacenf lo object B Or is object A near object B The first question appears to be fairly straightforward. The system must simply check all the edges of both objects to see if any parts of them are coincident This gives the certuin results. However, often in GIS data is input either automatically via scanners or digitized by humans, and in both cases it is easy for error in position of data objects to occur. Therefore we may also want to have the system check to see if object B is very near object A, to derive thepossible result. If so the user could be informed that \223it is not certain hut it is possible that A is adjacent to B.\224 Assume we are investigating coastal bird feeding habitats and trying to uncover any relationships that might exist between the number of bird sigbtings and coastal structure One species of bird may require low flat coastal land for feeding on small shellfish. Other types may feed on insects found near their nesting sites in the sides of cliffs. Suppose that for a particular location the system rems results based on the possibility that a high cliff is adjacent to the sea where birds have been sighted that feed in areas of flat coastal land We may then be led to investigate the influence of the tides in the area to determine whether low beaches alongside the cliffs are exposed at low tide by rough sets in comparably. Connection is similar to adjacency but related to vector or line type objects rather than area objects. Two objects are connected if they have a common meeting point on one end of each of the objects It is very easy for spatial data of this type, especially if the data is from different sources to not match up precisely We may then want to also define what would constitute possible connection, based on perhaps the distance between the objects and the length and orientation of the linear features For example if one road feature varying in curvature, but generally oriented from west to east, ends at some point A and we find a second road, also oriented in an east/west fashion near its beginning at point B a short distance away from A we may conclude that possibly these two road features are connected, even though they share no common Overlap can be defined in a manner similar to that of nearness with the user deciding how much overlap is required for the lower approximation. Coincidence of a single point may constitute possible overlap as can very close proximity of two objects, if there is a high degree of positional error involved in the data Inclusion is related to overlap in the following way. If an object A is completely surrounded by some object B perhaps we can conclude certainly that A is included in B lacking additional information about the objects If tbe objects overlap, then it ispossible that one object includes the other Approximation regions can be defmed to reflect these concepts as well Rough sets, RCC theory, and egg-yolk approaches are useful for managing the types of uncertainty and vagueness related to topology, a few of which were just briefly discussed. These include concepts such as nearness contiguity, connection, orientation, inclusion, and overlap of spatial entities We will consider next some of the topological relationships associated with vague regions and how they relate to each other using the RCC approach The concepts of connection and overlap can be managed point IV RCC-8 THEORY OF SPATIAL REGIONS RCC-8 theory 9 is a qualitative reasoning technique for spatial data based on regions rather than points. For any two simple regions, relations are defined that may hold between them The eight base relations that bold between two given simple regions are depicted in Figure 2 below One and only one of these relations can hold for a pair of vague regions They are PO \(Partially Overlapping\TPP \(Tangential Proper Part\NTPP \(Non-Tangential Proper Part EQ Equal NTPPI \(Non-Tangential Proper Part Inverse TPPl 0-7803-7280-8/02/$10.00 022002 IEEE 769 


Tangential Proper Part Inverse\EC \(Externally Connected and DC \(Disconnected PO\(X,Y TPP\(X,Y NTPP\(X,Y EQ\(X,Y NTPPI\(X,Y TPPI\(X,Y EC\(X,Y DC\(X,Y Figure 1 In IO the RCC method is extended to regions with vague boundaries rather than simple regions In that work only five of the above RCC-8 relations are applicable \(called RCC-5 These include PO Partially Overlapping\PP Proper Part when TPP and NTPP are combined EQ Equal\PPI \(Proper Part Inverse, when NTPPI and TPPI are combined\and DR Distinct Regions, when EC and DC are combined 1 2 3 4 5 6 I 8 9 10 11 12 30 42 46 Figure 3 A sample ofthe 46 possible relationships between regions X dashed line and Y dotted line A solid line indicates coincidence of an X and Y region boundary See IO for the complete listing There are a large number of relationships that can occur between two vague regions, since each vague region has two boundaries The research in IO lists all the possible relationships and clusters them into a hierarchy based on RCC relations and the effects of 223crisping\224 A sample of the some of the 46 possible relationships is depicted in Figure 3 V ROUGH SET MODELING OF RCC-8 RELATIONS Recall that a rough set is comprised of two crisp regions each of these regions defined in terms of the underlying equivalence relation There are two ways that we can approach using rough set techniques with RCC-8 spatial relationships. The first, somewhat trivial but illustrative is to compare the upper and lower approximation regions of a rough set with each of the RCC-8 relations The second approach is to consider each of the regions as being rough This approach results in a far greater number of possibilities some of which can be found in Figure 3 In relating the approximation regions of a rough set separately with the two regions in an RCC-8 relation it is easy to see that only five of the RCC 8 relations are possible: TPP\(X,Y\NTPP\(X,Y\EQ\(X,Y\TPPI\(X,Y and NTPPI\(X,Y This is because in a rough set the lower approximation region must be a subset of the upper approximation region This condition does not hold true for the relations PO\(X,Y EC\(X,Y or DC\(X,Y Also note that for the EQ\(X,Y\relation, the upper and lower approximation regions are equal, resulting in a crisp set having no uncertainty. We are not interested, however, in simply combining two crisp regions in a relationship and expressing those as a single rough set. What we are interested in are the spatial relationships occurring between two vague regions each represented as a rough set Let us now consider the RCC-8 relations in terms of two vague regions denoted by rough sets X and Y defined on some approximation space The determination of whether or not a relationship holds for these two rough regions can also be expressed as a rough set In the discussion that follows the RCC-8 relations will be expressed in terms of rough set approximation regions In IO the 46 relationships are listed along with \223possible\224 representation of each of the RCC-8 relationships The word 223possible\224 is used here because there is more generality present than when using rough sets to express the relationships The RCC-8 relationships can be described in terms of CERTAINLY HOLDS or POSSIBLY HOLDS if rough sets are used in this manner as well as for defining the regions themselves Y are disconnected ais is certainly true when Y  0 and RX n RY  0 whichcan be seen inFigure 3 Sample 1 However, it is possible that the relation holds whena n Y  0 and EX n RY  0 This occurs in samples 2-13 19,28,34 and 42 some of which may be found in Figure 3 In IO we fmd that an additional sample Sample 1 also belongs to the relationship There is no distinction between those that are certain and those that are possible. With rough set representation there is such a distinction, resulting in greater information. \(Consult IO for the complete list of relationship region figures For the EQ\(X,Y\relationship to hold certainly X  RY and EX  z Y The EQ relationship possibly holds when Rx  RY and either R X R Y or Y R X. There are only twoadditional samples included in this possible region for the relationship In lo there are about 18 possibilities because the restriction on the inner boundaries being equal is relaxed. For rough sets where this inner boundary is defined by the lower approximation region, equality must hold The DC\(X,Y\relationship holds when the rough sets X and n    0-7803-7280-8/02/$10.00 02002 IEEE I 770 


The relations TPP\(X,Y\and NTPP\(X,Y\are indistinguishable in rough sets theory. They together denote inclusion of rough set X in rough set Y In rough set terms, X c Y whenu E Y and R X c k Y The relations TPPI\(X,Y and NTPPI\(X,Y are analogous to TPP\(X,Y and NTPP\(X,Y One may simply exchange the X and Y in the relation and discussion for TPP or NF\222P to get the same results Grouped together these four relations certainly hold for 9 samples and possibly hold for Sample 46 In IO all but five of the pairs may be categorized as having this relationship Partial overlap PO\(X,Y\implies that X and Y are not equal hut that they have some part in common Rough set expression of this relationship involves intersection and equality This relationship will certainly hold whenever n BY  0 and R X n k Y  0 It will possibly bold when X n k Y  0 These results are identical to the 41 samples in IO that meet the requirements for partially overlapping denote that two rough sets intersect at exactly one point, the EC\(X,Y\relationship does not apply It expresses the same relationship as those belonging to the possible region for the PO relationship discussed previously It is evident from the discussion above that rough sets can be used to model relationships for vague regions defined by the RCC method By allowing the expression of belonging to the relationship to be either certain or possible, however, we gain greater insight into the relationship, therefore greater   Because rough set theory does not allow us to specifically called \223immediate conceptual neighbors\224 if 223each can be transformed into the other by a process of gradual, continuous change that does not involve passage through any third relation.\224 The RCCJ relations include DR \(Distinct Regions with no overlap EQ Equal: the regions are the same\PO the regions Partially Overlap\PP \(Proper Part the first region is entirely contained within the second\and PPI Proper Part Inverse: the fust region entirely contains the second\For egg-yolk pairs a yolk is a PP of its own egg The 46 configurations of egg-yolk pairs were then clustered into 13 groups based on RCC-5 relations between complete crispings or relations that are 223mutually crispable\224 see Figure 4 The clusters each relate to one or more additional clusters via a crisping relationship or a subset relationship between a set of complete crispings. Each configuration of a cluster can be crisped to the cluster pointed to by the arrow via one of these relationships knowledge. Rough sets also provide the indiscemibility relation, which aids in quantifying the uncertainty through the approximation regions We now consider another approach for vague regions VI EGG-YOLK APPROACH boundaries we may he inclined to use the Yolk aPProach In this approach concentric subregions make up a vague Figure 3 Clustering ofthe 46 relations IO using RCC-5 relations between complete crispings ofthe configurations Note that no hierarchy or order within the c~ustm is shown here for simplification If we are only concerned ahout the vagueness of region with inner subregions having the property that they are \221crisper\222 than outer subregions. These regions indicate a type of membership in the vague region The simplest case, is that of two subregions In this most corn case the center region is known as the yolk, the outer region surrounding the yolk is known as the white, and the entire region as the egg The yolk and egg comespond to boundary regions ofrough sets. Rough set theory has only these two approximation regions, unlike the possible numerous subregions that make of the indiscemibility relation in rough sets we can vary the partitioning to increase or decrease the level of uncertainty VII ROUGH SET APPROACH TO EGG YOLK CLUSTERING we will now re-examine the cluste\224ng ofegg-yolk pairs this time noting the relationships for each cluster based on mathematical principles from rough sets. Recall that crisping\224 from the egg-yo& theory can he a fjer partitioning on the domain for rough sets to forcing First recall definitions for categorizing the clusters Two rough sets X and Y are equal, X  Y ifm  Y and RX  RY up vague region in the egg-yolk method. However, because   The intersection of two rough sets is eiven hv             o   present, resulting in changes to the approximation regions Let us now consider suecificallv the results of Cohn and  R\(XnY XnY RY Gotts lo In this Paper they delineate 46 possible egg-yok of the possible relationships between two vague regions They then relate the egg-yolk configurations to dyadic of their RCC-5 theory of spatial regions. Pairs ofrelations are The subset relationship x c Y implies that C RY Look again at Figure 3 but now with clusters in terms of rough sets instead of RCC-5 relations Let X denote the first egg \(dashed line\and Y denote the second \(dotted line in c Y and k x pairs \(see Figure 3 for a representative sample\showing all  ofthe type c meaning C~C with y 0-7803-7280-8/02/$10.00 02002 IEEE 71 1 


each egg pair. We see the following bold for the clusters A XnY B:~~RY=D RxnR~#0 UCRY C:U~RY=O Rx~RY#B E:I~~RY RxnR~+a wnR~t0  D  RXnRY RXnkY RYC RX RX~BY+~;UC RY F XnY#0 XtY G:un&Y#0 Rx~RY#D RY+D Hac Rxnky;rgc Rx nRY I EXCRY J RYCU;K RX=&Y L U n BY  0 X cRY;BY c RX;RX nRY  0  RXn&Y#a BYC RX  M RY W A comparison of the rough set relationships expressed for each cluster with the RCC relationships denoted for the clusters in Figure 4 reveals similar properties. Consider, for example, cluster M This cluster is based on the RCC relations EQ and PPI which means that the regions might be equal or that region X entirely contains region Y In rough sets, this relationship is defmed through the use of the approximation regions The upper approximation region of Y is equal to the lower approximation of X We know certainly then that Y is contained in X It is also possible, however that X and Y are the same \(equal Rough set techniques for information retrieval and data mining in spatial databases and GIS may be applied to models with vague regions expressed by the egg-yolk model and those based on the RCC theory. Rough sets provides a solid mathematical foundation for vague regions that is compatible with other spatial data theories and methods, yet offers an added ability to refine the indiscemibility VIII CONCLUSION Spatial and geographical information systems will continue to play an ever-increasing role in applications based on spatial data Uncertainty management will be necessary for any of these applications and rough sets RCC and egg-yolk methods are appropriate for the representation of vague regions in spatial data Rough sets however, can also model indiscemibility and allow for the change of granularity of the partitioning through its indiscemibility relation Changing the indiscemibility relation has an effect on the boundaries of the vague regions because the lower and upper approximation regions are defined in terms of this indiscemibility. Rough se1 techniques can also be used to define spatial relationships themselves So there is a distinction between combinations that certainly meet the RCC-8 relationship requirements and those that possibly meet the requirements The rough set approach, therefore is very useful in defining vague spatial regions with indeterminate boundaries and in defining spatial relationships holding between vague regions We have also shown how the clustering of egg-yolk pairs by RCC-5 relations can be expressed in terms of operations using rough sets. We believe that rough set techniques can further enhance the egg-yolk approach and are investigating the interrelationships between rough set egg-yolk, RCC and other spatial models We are also investigating the impact of vagueness and uncertainty expressed with these theories on the querying and mining of spatial data allowing a rough set approach to uncertainty in spatial relationships for association rules and other forms of spatial data mining References I R Laurini and D Thompson Fundamentals ofSpotio1 Infomation Systems Academic Press, London, 1992 2 K Kopenki and J Ha\224 224Discovery of Spatial Association Rules in Geographic Information Databases\224 Pmc Sh Int Symp On Large SpatiolDotabmes Panland MN pp. 47-66 1995 3 W Lu J Han and B. Ooi, \223Discovery of General Knowledge in Large Spatial Databases\224 Proe Far East Workshop on Geographic Information System Singapore, pp.275-289, 1993  M Cobb R Ladner, and F Petry, \223Data Mining of Fuuy Association Rules for Spatial Data\224 to appear in Tram On Geographic Infomotion Systems 2002 Database and its Algebra with Rough Set Techniques,\224 Computational Intelligence Vol 11 No. 2, pp. 233-245 May 1995  Beaubouef T and Petry F 223Rough Querying of Crisp Data in Relational Databases,\224 Thirdlnl Workshop on Rough Sets andSofl Computing ESSC94 San lose Califomia, November 1994 7 T Beaubouef F Petry and J Breckenridge, \223Rough Set Based Uncertainty Management for Spatial Databases and Geographical Infomtion Systems,\224 in So Compuling in fnduslriol Appli=~ti~nr ed Y Suzuki Springer-Verlag, London 2000 E Z Pawlak 223Rough Sets,\224lnr Joumal ofMan-MochineShrdies vol 21 pp 127-134, 1984 9 D Rattdell 2 Cui, and A Cahn 223A spatial logic based on regions and connection,.l Pmc 3\224lnt Conf On Knowledge Representation and Reaming San Mateo, pp 165-176, 1992 Indeterminate Boundaries,\224 in Geographic Objects with lndeteminote Boundark ed P Burrough and A Frank\GISDATA II European Science Foundation, chapter 12, 1996 Rough Sets Analysis of Quantitative Information,\224 First lnt Workhop on Rough Sets Poland, 1992 information retrieval,\224lnt Jou 4/Mon-MochineStudier 34, pp. 657 671.1991 I31 A Roy and I Stell 223Spatial Relations Between Indeterminate Regions,\224 Int Joumol ofApproximate Reaming Vol. 27 pp205-234,200l  T Beaubouef F Petry and B. Buckles, \223Extension ofthe Relational IO A Cohn and N Gotts 221The 221Egg-Yolk\222 Representation of Regions with I I R Slowinski 223A Generalization afthe Indiseemibility Relatian for I21 P. Srinivasan 223The importance ofrough approximations for Acknowledgments We would like to thank the Naval Research Laboratory\222s Base Program, program element number PE 060243SN for sponsoring this research 0-7803-7280-8/02/$10.00 02002 IEEE 772 


Apriori  M-Apriori DHP BIHP MI HP     E F Figure 5 Comparison of execution times Figure 7 Effect of Till hash table size on the candidates IHP MI HP Figure 6 Effect of multipass partition size in M[HP Figure 8 Effect of Till hash table size on the execution time The effect of the Till hash table size was examined in a series of runs with a minimum support leViel of 2.5% and Till hash table sizes of 10, 25, 50, 100, 250 and 500 entries. Figure 7 shows that there is a sharp reduction in the number of candidate 2-itemsets as the number of Till hash table entries increases up to 250 but only a modest decrease after that In Figure 8 we see that the change in the size of Till hash table, and hence the change in the number of candidate itemsets has little effect upon the total execution time until it becomes as large as 500 entries At this point the effect of candidate pruning clearly offsets the overhead of using the Till hash tables The above results suggest that the MI HP algorithm is more effective than Apriori DHP, M-Apriori and IHP algorithms for mining frequent itemsets from text documents. The next tests were conducted to e'i'aluate how well MI HP scaled in terms of the number of documents to be processed and the number of frequent itemsets mined There were four document collections used for the scalability test a two-week collection \(from 3/2/1992 to 3/13/1992 of 1,739 documents; a one-month collection \(April 1990\of 3,568 documents; a two-mC collection \(September and October of 1991\of 7,361 documents; and the largest collection was for three months \(January, February, and March in 1992\containing 10,163 documents The minimum support level was 1.75% for all test runs In Figure 9 we see that the time per frequent itemset mined increases proportionally with the number of documents in the collection. This suggests that MI HP will scale linearly with respect to the number of documents processed. In Figure 10 we see that the time per frequent itemset mined decreases as the minimum support level decreases. The time per candidate itemset processed was constant at about 1 msec. The decrease in time per frequent itemset mined is due to the increase in the number of candidate itemsets that become frequent itemsets as the minimum support level rlecreases 5 Conclusions The main conclusions that can be drawn from this study are centered around the nature of the text databases and the use of the mined association rules The distribution of words in text document collections Minimum Support  Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


Figure 10 Time per frequent itemset mined 3,568 documents and the number of unique words in a document hlake the problem of finding frequent itemsets i.e s~ts of words in text databases very different from the c~e of traditional point-of-sale transaction databases i This difference motivated us to develop a new MI HP iMul tipass with Inverted Hashing and Pruning algoltithm for text databases Our performance analyses show that the mult~pass approach can be effective with text databases i The key performance factor appears to be the reduction in the amount of required memory space The ultipass approach reduces the number of objects in rf1emory during each pass by partitioning the frequetlt 1itemsets and processes each partition separately Moreover Inverted Hashing and Pruning IHP can prune some, of the candidate itemsets generated for  each pass on the database efficiently Since a lot of Till hash tables are pruned before we count the otcurrences of the candidate 2-itemsets most of the emI ory used for holding the Till hash tables in thelfirst pass on the database is available to hold the c~ndidate 2-itemsets for the second and subsequent p~ses In large part this effect is a result of the distribution of word occurrences discussed in Section 2 The large number of words with very low occurrence rates resuits in a situation that the preponderance of the Till hash tables generated in the first pass are pruned prior to the initiation of the second pass References  R Agrawal and R Srikant Fast Algorithms for Mining Association Rules Proc of the 2Oth VLDB Con 1994 pp 487-499  M S Chen J Han and P S Yu Data Mining An Overview from a Database Perspective IEEE 1rans on Knowledge and Data Engineering Vol 8 No.6 Dec 1996 pp 866-883  R Feldman and H Hirsh Finding Associations in Collections of Text Machine Learning and Data Mining Methods and Applications R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223-240  R Feldman I Dagen and H Hirsh Mining Text Using Keyword Distributions Journal of Intelligent Information Systems Vol 10 No.3 1998 pp 281300  M Gordon and 8 Dumais Using Latent Semantic Indexing for Literature Based Discovery Journal of the Amer Soc of Info Science Vol 49 No.8 June 1998 pp 674-685  J Holt and S M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems Vol 3, No.2 SpringerVerlag 2001 pp 168-183  J Holt and S M Chung Mining Association Rules Using Inverted Hashing and Pruning Information Processing Letters Vol 83 No.4 Elsevier Science 2002 pp 211-220  J S Park M S Chen and P S Yu Using a HashBased Method with Transaction Trimming for Mining Association Rules IEEE 1rans on Knowledge and Data Engineering Vol 9 No.5 Sep/Oct 1997 pp 813-825  G Salton Automatic Text Processing the transformation analysis and retrieval of information by computer Addison-Wesley Publishing 1988  A Savasere E Omiecinski and S Navathe An Efficient Algorithm for Mining Association Rules in Large Databases Proc of the 21st VLDB Con 1995 pp 432-444 1  E M Voorhees and D K Harmon editors The Fifth Text Retrieval Conference National Institute of standards and Technology 1997  Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


 0 5 10 15 20 25 30 35 40 10 15 20 25 30 average number of items in transactions T I=6 D=200K  o f d ata p rocessed 0 50 100 150 200 250 300 350 400 450 500 ti m e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 5 Pruning and CPU time varying T 0 2000 4000 6000 8000 10000 12000 14000 10 15 20 25 30 average number of items in transactions T I=6 D=200K number o f r andom I  Os SG-table SG-tree Figure 6 Random I/Os varying T 0 5 10 15 20 25 30 35 40 6121824 average length of large itemsets I T=30 D=200K  o f d ata p rocessed 0 50 100 150 200 250 300 350 400 450 500 ti m e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 7 Pruning and CPU time varying I 0 2000 4000 6000 8000 10000 12000 14000 6121824 average length of large itemsets I T=30 D=200K numbe r of ra ndom I  O s SG-table SG-tree Figure 8 Random I/Os varying I 0 2 4 6 8 10 12 14 16 T=10,I=6 T=20,I=12 T=30,I=18 T=40,I=24 T=50,I=30 Varying T and I I/T=0.6 D=200K  o f d ata p rocessed 0 20 40 60 80 100 120 140 160 tim e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 9 Pruning and CPU time 336xed I/T 0 200 400 600 800 1000 1200 1400 1600 1800 2000 T=10,I=6 I=12 T=30,I=18 I=24 T=50,I=30 Varying T and I I/T=0.6 D=200K numbe r of ra ndom I  Os SG-table SG-tree Figure 10 Random I/Os 336xed I/T 0 1 2 3 4 5 6 7 100 00 300 400 500 Data set cardinality T=10 I=6  o f d ata p rocessed 0 10 20 30 40 50 60 70 80 90 ti m e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 11 Pruning and CPU time varying D 0 10 20 30 40 50 60 0 1 to 3 4 to 10 11 to 20 20 distance of nearest neighbor T30.I18.D200K  o f d at a p rocessed 0 100 200 300 400 500 600 700 800 time m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 12 Pruning and CPU time var 000 000 003 005 007 t  83  Proceedings of the 19th International Conference on Data Engineering \(ICDE\22203 1063-6382/03 $ 17.00 \251 2003 IEEE 


shows a pattern similar to the CPU cost as in the previous experiments During the experiments we observed that queries having a close nearest neighbor were processed fast using both structures whereas for cases with distant neighbors the SG\226tree was signi\036cantly faster than the SG\226table We validated this observation by running 1000 queries on the T30.I18.D200K dataset and averaging the query costs for various distance ranges of the nearest neighbor Figure 12 shows the average pruning an d CPU cost for 036ve distance ranges When the distance is small search is fast for both methods actually for distances in the range 1\2263 the SG\226 table outperforms the SG\226tree However the distant cases are handled much faster by the SG\226tree showing that this access method is more robust to 221outlier\222 queries As a general conclusion from this set of experiments the SG\226tree is a more ef\036cient and robust access method than the SG\226table in addition to its other inherent advantages dynamic data handling independence to hard-wired constants In the next subsection we compare the indexes for other query types on both synthetic and real data 5.4 Real data nd other queries Figures 13 and 14 show the performance of the indexes for 000 NN queries on the T30.I18.D200K synthetic dataset and the CENSUS dataset respectively for various values of 000  The results for each experimental instance were averaged over 100 queries In both 036gures for small to medium values of 000 the SG\226tree is signi\036cantly faster than the SG\226 table When 000 is large  001 003 005 005 005  the fraction of the data that need to be visited becomes too large for the indexes to be useful This is due to the fact that the search space becomes less appropriate for search For example when 000 t 003 005 005 005 005 we observed that the average distance of the 000 th neighbor is very large 31.81 for T30.I18.D200K and 18.06 for CENSUS and very close to the average distance of all transactions from f  This is due to the 221dimensionality curse\222 effect 3 o ften o b s erv e d i n h ig h d i men s io n a l search problems Observe that the SG\226tree is less sensitive to this effect since its performance degenerates at a smaller pace especially for the real dataset We also compared the indexes for similarity range queries Figures 15 and 16 The same datasets and queries as before are used and the distance threshold from the query varies from 2 to 10 For r t 020  the SG\226table outperforms the SG\226tree on the synthetic dataset In all other cases the tree is much faster Observe that on the real dataset in particular for both 000 NN queries and range queries the performance difference quite large in favor of the tree This indicates that the structure can perform very well in real life cases  0 10 20 30 40 50 60 70 80 90 100 1 10 100 1000 10000 k-nn search varying k T30.I18.D200K  o f d ata p rocessed 0 200 400 600 800 1000 1200 1400 time\(msec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 13 021 NN queries T30.I18.D200K 0 10 20 30 40 50 60 70 80 90 100 1 10 100 1000 10000 k-nn search varying k CENSUS  o f d ata p rocessed 0 100 200 300 400 500 600 tim e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 14 022 NN queries CENSUS 5.5 Dynamic data changes In this experiment we compare the structures simulating a case where the nature of the data changes dynamically We generated a synthetic dataset T10.I6.D100K and built an SG\226table and SG\226tree for it We then gradually updated the structures by inserting batches of 100K transactions each with the same characteristics i.e T=10 I=6 but putting different seeds to the random generator i.e the large itemsets used were different for each batch We ran nearest neighbor queries on the two structures after each insertion phase The queries for phase 023 after batch 023 has been inserted 024 026 023 026 032  are generated as follows For each query i a random number 033 from 1 to 023 is chosen and ii the generator parameters i.e large itemsets for batch 033 are used to produce the query For example a query for the phase where the dataset contains 300K data is generated using randomly one of the generators of batches 1 2 or 3 Figure 17 shows the average pruning ef\036ciency and CPU time of the two structures Initially both have similar performance but as more data with different characteristics are inserted into the structures the performance of the SG\226table degenerates since it is optimized for the 036rst 100K data  84  Proceedings of the 19th International Conference on Data Engineering \(ICDE\22203 1063-6382/03 $ 17.00 \251 2003 IEEE 


 0 5 10 15 20 25 30 35 40 246810 similarity range queries varying epsilon T30.I18.D200K  o f d at a p r o cessed 0 50 100 150 200 250 300 350 400 tim e m s e c  SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 15 Range queries T30.I18.D200K 0 10 20 30 40 50 60 70 80 246810 similarity range queries varying epsilon CENSUS  o f d ata p r o cessed 0 50 100 150 200 250 300 350 400 ti me\(msec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 16 Range queries CENSUS On the other hand the SG\226tree is robust to updates and exhibits very good query performance since each batch contains skewed data generated from a different collection of large itemsets 6 Conclusions and Future Work We presented a hierarchical indexing method for similarity search in sets and categorical data The SG\226tree is a disk-based height-balanced tr ee that organizes 036xed-length bitmaps and is appropriate for various query types We have shown how several branch-and-bound methods which apply on R\226tree-like structures can be adapted for ef\036cient similarity search on the SG\226tree Extensive experimental evaluation has shown that the SG\226tree is in most cases much faster than the SG\226table a previous hash-based index The advantages of the SG\226tree can be summarized as follows 000 It is ef\036cient and robust to various data types both categorical and set data and characteristics cardinality density dimensionality It is a versatile structure that can be used for several query types 000 The tree is dynamically adapted to updates and re0 2 4 6 8 10 12 100 200 300 400 500 Dataset cardinality T=10 I=6  o f d ata p rocessed 0 20 40 60 80 100 120 140 160 180 200 tim e m sec SG-table\(%data SG-tree\(%data SG-table\(time SG-tree\(time Figure 17 NN search after dynamic updates quires no preprocessing of the data Thus it can be useful for analyzing data which change dynamically over time 001 It relies on no hardwired constants and requires no tuning using a-priori de\036ned parameters 001 It is a disk-based paginated data structure so it can operate with limited memory resources and dynamically changing memory resources Caching policies previously used for the B 002 226tree and the R\226tree can be seamlessly applied on this structure There are several directions for extending the current work In our study we used hamming distance as the similarity metric However the SG\226tree can also be de\036ned tuned and searched for other set theoretic similarity metrics For example if the Jaccar d coef\036cient is used the lower distance bound in fact the upper similarity bound for nearest neighbor search can be de\036ned by 003 005 007 b n f 016 007 020 021 023 024 026 030 003 005 007 b n f 026  We plan to test the effectiveness of the structure using alternative metrics Another direction or future work is to study methods for bulk-loading SG\226trees instead of inserting the data oneby-one We can adapt categor ical clustering algorithms 12 for t hi s purpos e Anot her a pproach i s t o s o rt t h e transactions using gray codes as key in analogy to using space-\036lling curves for bulk-loading multidimensional data to an R\226tree 17  A lternati v ely  hashing t echniques can be used to group similar signatures together The resulting 221globally-optimized\222 tree could have much better quality characteristics while being built faster In a reverse direction we can investigate whether the SG\226tree can be used for clustering large dynamic collections of set and categorical data The cost of existing methods is at least 035 n   026 and the tree could be used to derive good clusters much faster e.g by merging the leaf nodes using their signatures as guides Finally we plan to empirically test the ef\036ciency of the tree to the query types discussed in Section 4.2 In  85  Proceedings of the 19th International Conference on Data Engineering \(ICDE\22203 1063-6382/03 $ 17.00 \251 2003 IEEE 


addition for some data types search can be further optimized For example if the indexed categorical data have 223xed-dimensionality 000 we know that the area of each indexed signature is 223xed to 000  We can use this property to derive stricter lower bounds for the directory node entries 001  instead of the rather relaxed 002 004 006 006 t 013 r 001 020 022 004 025 027 For this example a better bound is 002 004 006 006 t 013 r 001 020 022 004 025 027 033 t 000 037    t 001 020 022 004 025 r 013 027 027  We plan to study such search optimizations using domain properties or statistics from the indexed data References  C  C  A ggarw al  J  L  W ol f and P  S  Y u A N e w Method for Similarity Indexing of Market Basket Data SIGMOD Conference  pages 407\205418 1999  R  A gra w al and R  S ri kant  F as t A l gori t h ms for M i n ing Association Rules in Large Databases VLDB Conference  pages 487\205499 1994  K  S  B e y er  J  G ol ds t e i n  R  R amakri s hnan and U Shaft When Is 215Nearest Neighbor\216 Meaningful International Conference on Database Theory  pages 217\205235 1999  T  B ri nkhof f H.-P  K ri e g el  a nd B  S e e g er  E f 223 ci ent Processing of Spatial Joins Using R-Trees SIGMOD Conference  pages 237\205246 1993  A  C orral  Y  Manol opoul os  Y  T heodori d i s  a nd M Vassilakopoulos Closest Pair Queries in Spatial Databases SIGMOD Conference  pages 189\205200 2000  A  P  d e V ries N  M amoulis N  N es a nd M K e r sten Ef\223cient k-NN Search on Vertically Decomposed Data SIGMOD Conference  pages 322\205333 2002  U  D eppisch S-T r ee A D ynamic B alanced Signature Index for Of\223ce Retrieval ACM SIGIR Conference  pages 77\20587 1986  V  G aede a nd O G 250 unther Multidimensional Access Methods ACM Computing Surveys  30\(2\170\205231 1998  V  G ant i  J  Gehrk e  a nd R  R a makri s hnan C A C T US 205 clustering categorical data using summaries ACM SIGKDD Conference on Knowledge Discovery and Data mining  pages 73\20583 1999  D Gi bs on J  M Kl ei nber g  a nd P  R a gha v a n C l us tering Categorical Data An Approach Based on Dynamical Systems VLDB Conference  pages 311\205322 1998  A Gi oni s  D Gunopul os  a nd N K oudas  Ef 223 c i e nt and Tunable Similar Set Retrieval SIGMOD Conference  2001  S  Guha R  R as t ogi  a nd K S h i m  R OC K A R obust Clustering Algorithm for Categorical Attributes International Conference on Data Engineering  pages 512\205521 1999  A Gut t m an R T rees  A Dynami c I nde x S t r uct u re for Spatial Searching SIGMOD Conference  pages 47\205 57 1984  S  Hel m er and G  M oerk ot t e  A S t udy of F our Inde x Structures for Set-Valued Attributes of Low Cardinality Technical Report University of Mannheim  number 2/99 1999  G R Hjaltason a nd H Samet Distance Bro w sing in Spatial Databases TODS  24\(2\265\205318 1999  A K J a i n and R  C  D ubes  Algorithms for Clustering Data  Prentice-Hall 1988  I Kamel a nd C  F a louts o s  Hilbert R tree An Improved R-tree using Fractals VLDB Conference  pages 500\205509 1994  F  K o rn N  S i d i r opoul os  C  F al out s o s  E S i e g el  a nd Z Protopapas Fast Nearest Neighbor Search in Medical Image Databases VLDB Conference  pages 215\205 226 1996  N K oudas a nd K C  S e vci k  H i g h D i m ens i onal S i m i larity Joins Algorithms and Performance Evaluation International Conference on Data Engineering  pages 466\205475 1998  N R ous s opoul os  S  K el l e y  and F  V i n cent  Neares t Neighbor Queries SIGMOD Conference  pages 71\205 79 1995  Y  S a kurai  M  Y os hi ka w a  S  U emura and H  K oj i m a The A-tree An Index Structure for High-Dimensional Spaces Using Relative Approximation VLDB Conference  pages 516\205526 2000  The U C I KDD Archi v e ht t p    kdd.i c s  uci  edu 23 R W e b e r  H.-J S ch ek  a n d S Blo tt A Q u a n titative Analysis and e Study for SimilaritySearch Methods in High-Dimensional Spaces VLDB Conference  pages 194\205205 1998  86  Proceedings of the 19th International Conference on Data Engineering \(ICDE\22203 1063-6382/03 $ 17.00 \251 2003 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 



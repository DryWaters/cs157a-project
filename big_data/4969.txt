002 002 002  002 
Weizhong Zhao  VenkataSwamy Martha  Xiaowei Xu 
PSCAN A Parallel Structural Clustering Algorithm for Big Networks in MapReduce 
Big data such as complex networks with over millions of vertices and edges is infeasible to process using con 
Abstract 
College of Information Engineering Xiangtan University Xiangtan China University of Arkansas at Little Rock Little Rock AR USA vxmartha@ualr.edu wxzhao1@ualr.edu xwxu@ualr.edu 
ventional computation MapReduce is a programming model that empowers us to analyze big data in a cluster of computers In this paper we propose a Parallel Structural Clustering Algorithm for big Networks PSCAN in MapReduce for the detection of clusters or community structures in big networks such as Twitter PSCAN is based on the structural clustering algorithm of SCAN which not only nds cluster accurately but also identiìes vertices playing special roles such as hubs and outliers An empirical evaluation of PSCAN using both real and synthetic networks demonstrated an outstanding performance in terms of accuracy and running time We 
analyzed a Twitter network with over 40 million users and 1.4 billion follower/following relationships by using PSCAN on a Hadoop cluster with 15 computers The result shows that PSCAN successfully detected interesting communities of people who share common interests 
Keywords 
Network clustering algorithms community structures big data MapReduce Hadoop 
I I NTRODUCTION We have been facing explosive growth of data Recently the term of big data is often used to describe the huge amount of data that has been collected in many areas such as sensors used to collect climate information surveillance 
cameras for digital videos signals of cellular phones webpages in the internet and user posts in social media to just name a few The pace of data growth is approaching and in many cases has already outgrown our capability to storage process and analyze data which is a major challenge in almost every business today Many of the big data are highly complex which can only be represented as big graphs with millions of vertices and edges The data or networks require distributed and parallel processing with over thousands of computers Apache Hadoop cluster is a major distributed system used by many businesses to process the big data due to its outstanding scalability of growing the system 
with additional computers exibility of processing both structured and unstructured data fault tolerance of computer system failures and convenience of parallel programming model of MapReduce In this paper we propose a parallel clustering algorithm for big networks in MapReduce of Apache Hadoop Network clustering is an important tool for analysis of large graphs including social and biological networks Many network clustering algorithms have been successfully used for analysis of large networks We focus on the clustering algorithm of SCAN a structural clustering algorithm because of its accuracy of nding clusters and vertices playing special 
roles as well as its linear time complexity which is scalable to large networks Speciìcally SCAN nds clusters by using breadth-ìrst search of the graph and claims a visited vertex as a new member of the cluster if its structural similarity which is a normalized measure of shared neighbors with a current cluster member is larger than or equal to a real parameter 
 Therefore a straightforward parallelization of SCAN algorithm would be using a parallel breadth-ìrst search algorithm in MapReduce as described in The parallel breadth-ìrst search is implemented using an iterative MapReduce job where each iteration expands the search frontier by only one 
002 
hop from the source Therefore the number of iterations is the diameter of the graph or the largest distance between any pair of vertices in the graph Although this number is small in average according to the well-known six degrees of separation of social networks it is quite large for some big networks based on our experiments Therefore we propose a fast Parallel Structural Clustering Algorithm for big Networks PSCAN in MapReduce as follows First the structural similarity is calculated for each edge of the graph Then the graph is pruned by cutting off the edges with the structural similarity less than the threshold 
002 
 Finally the clusters are identiìed by nding connected components in the pruned graph The advantage of PSCAN over the straightforward parallelization is signiìcantly reduced MapReduce job iterations which makes it scalable to big networks as demonstrated in our empirical evaluation The paper is organized as follows We review related work in section II PSCAN algorithm is presented in section III An empirical evaluation of PSCAN is performed by using both synthetic and real big networks The experiment results 
2013 IEEE 27th International Conference on Advanced Information Networking and Applications 1550-445X/13 $26.00 © 2013 IEEE DOI 10.1109/AINA.2013.47 862 


  
s i i i i i i i i i i i i i i i i i 
002 002 002 002 v v v v  v  v i   s v v v v v v v v v v v v v v v v v v v v v v v v v v v v v v v 
A Parallel Calculation of Structural Similarity PCSS 
are presented in section IV Finally we conclude the paper with future work in section V II R ELATED W ORK Finding clusters or community structures is one of the fundamental task for network analysis There are many algorithms having been proposed and successfully used across many disciplines A more comprehensive overview can be found in A brief re vie w of representati v e algorithms and other related work are presented as follows Network clustering has been rst applied in biology and social sciences for taxonomy and sociology Since many networks have hierarchical structures hierarchical clustering algorithms have been successfully used Lik e netw ork clustering graph partitioning algorithms aim to divide vertices into groups such that the number of edges lying between groups is minimized One of the earliest method is the KernighanLin algorithm which is still used in parallel computing circuit partitioning and layout Spectral clustering algorithms have been successfully applied in image processing which nds clusters by using eigenvectors of the adjacency matrix of the graph Normalized cut technique is a good example of spectral clustering algorithms  Modularity  an objecti v e or quality function originally deìned by Newman and Girvan has been used by many network clustering algorithms for the detection of community structures Optimization of modularity is an NP complete problem Therefore most algorithms nd approximate solutions by using greedy search including  In man y applications clusters may o v erlap with each other Network clustering algorithms have been proposed to nd clusters that share some common vertices One of the popular approach is the Clique Percolation Method CPM  All methods discussed above have a time complexity that is not scalable to large networks Scalable methods are devised to cluster large networks in linear or nearly linear time complexity with the size of the network A good representative of scalable network clustering algorithms is the Structural Clustering Algorithm for Networks SCAN  which is an e xtension of the density based clustering algorithm DBSCAN for large networks Even a scalable algorithm like SCAN alone canêt efìciently handle big networks with millions of vertices and edges Therefore parallel algorithms using modern computational infrastructures such as Hadoop cluster is required A remarkable work is which implemented a label propagation algorithm in MapReduce for detecting community structures in a Twitter network containing 40 million users and 1.4 billion edges However the implemented label propagation algorithm is not deterministic which means the clustering result may vary for the same input graph Moreover the bipartite or nearly bipartite subgraphs lead to the oscillations of cluster labels which is especially true in cases where communities take the form of a star graph In this paper we focus on SCAN and propose a Parallel SCAN PSCAN for detecting community structures in big networks in MapReduce III PSCAN A LGORITHM IN M AP R EDUCE In this section we present a Parallel Structural Clustering Algorithm for Networks PSCAN in MapReduce Given one real parameter and input undirected network represented in adjacency list PSCAN nds clusters and a possible empty set of outliers and hubs in which structural similarity of each edge in each cluster is larger than or equal to and no edge adjacent to outliers or hubs with structural similarity larger than or equal to  The basic idea of PSCAN is as follows Firstly it calculates the structural similarity of edges then it cuts off the edges with structural similarity less than  nally it nds all the connected components in the pruned network each of which is a cluster and the vertices that are not part of any cluster are either outliers or hubs Note that all of the three steps can be executed in parallel in MapReduce In order to calculate the structural similarity of one edge we just need the adjacency lists of two vertices adjacent to the edge The calculation of the structural similarity of different edges is independent Therefore it can be executed simultaneously in MapReduce by using two functions a mapper and a reducer respectively More speciìcally the mapper takes a pair of key value as input where the key is the input vertex and the value is its adjacency list To illustrate our algorithm we take the vertex and its adjacency list as an example For each neighbor  f  we know that there is an undirected edge between and  In order to represent the edge uniquely it is represented using the vertex pair in an increasing order of the vertices adjacent to the edge For example if precedes  the edge between and is represented as   or it is represented as   Without loss of generality we assume precedes  For each neighbor of vertex  the mapper emit a key value pair in which the key is the edge   and the value is the adjacency list of  If the input vertex in the mapper is  we know that is a neighbor in the adjacency list of  When it processes the vertex  the mapper will emit a key value pair in which the key is also the edge   and the value is the adjacency list of  In the reducer for the key   the corresponding values will include the adjacency lists of and  Therefore we can calculate the structural similarity of   in the reducer All the edges in the network can be processed in the same way Thereby the 
 1 2 1 2 
863 


002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 
i i i i 
Algorithm 1 Input Output Algorithm 2 Input Output Algorithm 3 Input Output 
key value v key values B Cutting off Edges C Label Propagation for Connected Components LPCC D Time Complexity 
structural similarity of edges can be calculated in parallel in MapReduce The pseudo codes of the mapper and the reducer is summarized in algorithm 1 and algorithm 2 respectively PCSS Mapper  is the input vertex is the adjacency list of the input vertex   where the is the edge connecting the input vertex and its neighbor and is the adjacency list of the input vertex 1 Get the input vertex ID and its adjacency list from pair 2 For each neighbor in the adjacency list do If Take  s  else Take  s  Take the adjacency list of vertex as  Emit  3 End For PCSS Reducer  is one edge includes the adjacency lists of the two vertices adjacent to the edge   where the is the edge and is structural similarity of the edge 1 Get the adjacency lists of the two vertices from the  2 Calculate the structural similarity of the edge 3 Take namely the edge as the  4 Take the structural similarity of the edge as  5 Emit  The output of the previous step is the edge list with structural similarity of each edge Given the threshold  we can cut off the edges with structural similarity less than  Actually we can do the cutting procedure in the reducer of previous step in which we just emit the edges whose structural similarity is larger than or equal to  After the cutting phase we get several connected components each of which is recognized as a cluster Then we nd the connected components to get the nal clustering result Inspired by the idea of label propagation we can nd connected components in parallel from different vertices Recently the same idea is also proposed by The basic idea is that we label all the vertices in one connected component as the smallest or largest ID of vertices in the connected component More speciìcally we rst prepare the input to the format of vertex ID structure information in which the structure information includes status label and adjacency list of the vertex Each vertex has two status activated and inactivated The activated vertex needs propagate its current label to its neighbors while the inactivated vertex doesnêt need to do that At beginning each vertex is initialized as activated and its label is its own ID Then the label propagation proceeds in an iterative way Each iteration is a MapReduce job In the mapper each of the activated vertex propagates its label to all of its neighbors and passes its structure information to the reducer For the inactivated vertex it just passes the structure information to the reducer In the reducer for each vertex if the smallest label propagated from its neighbors is less or larger than its current label we update the label as the new one and set the vertex as activated If the label need not change we set the vertex as inactivated The procedure iterates until there is no label updated in one iteration Finally vertices with the same label are in the same connected component which is taken as a cluster The algorithm is summarized in algorithms 3 4 and 5 LPCC  A network in the format of adjacency list  All of the connected components in the network 1 Initialize the label of each node as its own ID and the status is activated 2 Iterate LPCC Mapper LPCC Reduce 3 Until all nodes are inactivated The time complexity of calculating the structural similarity of edges is linear with the number of edges The step of nding connected components takes a running time which is in the order of the diameters of the connected components Since many of the social networks have an average diameter of six which is known as six degrees of separation the overall running time of PSCAN is linear with the number of edges in the graph IV E MPIRICAL E VALUATION We empirically evaluated the performance of the proposed algorithm for clustering big undirected networks All of the experiments were conducted on a cluster of 15 computers each of which includes 8 core 2.6 GHz processors and 16GB of memory Hadoop version 1.0.0 and Java 1.6.0-31 are used as the MapReduce system for all the experiments 
key value  key value key/value v v<v v v key v v key v value key value key value  key value values key key value key value  002 002 002 
864 


002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 
i i 
LPCC Mapper  is the input vertex ID is the structure information status label and adjacency list of the input vertex   where the is a vertex ID and is the label or the structure information of the input vertex 1 Get the vertex ID status label and its adjacency list from pair 2 If the vertex is activated For each neighbor in the adjacency list Take as  Take the label of the input vertex as  Emit  3 End if 4 Take the vertex ID as  5 Take the structure information of the vertex as  6 Emit  LPCC Reducer  is vertex ID includes the structure information of the vertex and the labels from its neighbors   where the is the vertex ID and is the updated structure information of the vertex 1 For each in  If the is the structure information Store the structure information temporarily else Find the smallest label from the neighbors 2 If the smallest label from its neighbors is less than its current label Set the vertex as activated and update the label in the structure information as the smallest label 3 else Update the status as inactivated in structure information of the vertex 4 Take  namely the vertex ID as  5 Take the updated structure information of the vertex as  6 Emit  To evaluate the performance of our algorithm we use both synthetic and real datasets The rst set of synthetic datasets is generated to evaluate the accuracy of our algorithm by using the benchmark data generator proposed in The generated synthetic graphs have built-in community structures and can be used as a benchmark to evaluate the clustering accuracy Moreover in the synthetic graphs the distributions of vertex degree and community size are both power laws which are two important characteristics of many real networks The statistics of the generated benchmark graphs are presented in Table I Table I B ENCHMARK G RAPH Graph  nodes  edges  clusters Graph-5k 5,000 35,626 278 Graph-10k 10,000 70,365 598 Graph-20k 20,000 143,521 1008 Graph-40k 40,000 285,275 2030 Graph-80k 80,000 576,642 3876 Graph-160k 160,000 2,293,255 4115 To evaluate the scalability of PSCAN the second set of synthetic graphs is generated by using Barabasi graph model  The graphs generated by Barabasi model is a scale-free network However we do not know the real community structures in the graphs Therefore we only use them to evaluate the running time of our algorithm We could use the benchmark graph generator in for the purpose Ho we v er  it is too slow and failed to generate a graph with one million vertices after running more than a week The statistics of the generated graphs using Barabasi model are presented in Table II Table II B ARABASI G RAPH Graph  nodes  edges Barabasi-1M 1,000,000 13,999,895 Barabasi-2M 2,000,000 27,999,895 Barabasi-3M 3,000,000 33,999,847 Barabasi-4M 4,000,000 59,999,880 Twitter dataset collected by Kwak et al has follo wer/follo wing relationship between twitter users The Twitter dataset has nearly 42 million vertices and 1.4 billion edges We treat Twitter as an undirected graph by removing the directions of edges in the original graph Moreover we remove the vertices whose degrees larger than 20 because they are most likely the hubs according to the theory of structural clustering After preprocessing Twitter dataset contains 25,017,493 vertices and 46,417,485 edges To this end we use benchmark graphs to evaluate the accuracy of clustering results For each graph we tried ve different in step 0.2 from 0 to 1 and took the clustering result that maximizes the modularity  as the nal result W e used the Adjust Rand Inde x ARI  and the Normalized Mutual Information NMI 4 to evaluate the clustering accuracy For the perfect clustering 
key value key values A Datasets 1 Synthetic Datasets 2 Real Datasets B Evaluation Methodology 1 Clustering Accuracy 
Algorithm 4 Input Output Algorithm 5 Input Output 
key value  key value key/value v v key value key value  key value key value  key value  key value value values value key key value key value  002 
865 


running-time on 4 computers running-time on computers 
Table III C LUSTERING ACCURACY Graph ARI NMI Graph-5k 0.997 0.999 Graph-10k 0.998 0.999 Graph-20k 0.969 0.977 Graph-40k 0.981 0.988 Graph-80k 0.971 0.987 Graph-160k 0.999 0.999 result the ARI and NMI values are both equal to 1 In general the larger the ARI and NMI values are the better the clustering quality is The clustering accuracy results are presented in Table III The results show that PSCAN can nd the clusters outliers or hubs in each graph effectively Especially for Graph-5k Graph-10k and Graph-160k PSCAN successfully identiìed nearly all of the clusters outliers or hubs in the graphs The reason is that PSCAN always produces the same result as the original SCAN algorithm which is v ery accurate for clustering large networks Therefore PSCAN performs effectively in clustering big graphs 
2 Running Time Performance m m m 
002 Relative speedup 
To this end we employ Barabasi graphs to evaluate the speedup scaleup and sizeup performance of our algorithm Since we will only evaluate the efìciency of PSCAN and not its accuracy we set the same when tested on different Barabasi graphs Moreover we set the number of iterations for nding connected components as six assuming of six degrees of separation To measure the speedup we kept the graphs constant and increased the number of computers in the system We have tested the speedup on different Barabasi graphs on different Hadoop clusters with 4 8 and 15 computers respectively In our experiments the relative speedup given by the larger system with computers is deìned as 1 The results are presented in Figure 1 As the gure shows our algorithm has a very good speedup performance From the relative speedup in Figure 1\(b we noticed that the larger graphs have an improved speedup performance The reason is that increasing the size of the graphs reduced the percentage of the overall time spent in communication and I/O operations Scaleup measures the ability to grow both the system and the graph size Speciìcally we have evaluated running time on Barabasi-1M on a Hadoop cluster with 4 computers running time on Barabasi-2M on a Hadoop cluster with 8 computers and running time on Barabasi-4M on a Hadoop cluster with 15 computers respectively Each running time a Speedup b Relative Speedup Figure 1 Speedup divided by running time on Barabasi-1M on the Hadoop cluster with 4 computers is the relative scaleup result The ideal scaleup is a horizontal line with value 1 in the vertical axis in relative scaleup result However ideal scaleup is difìcult to achieve because of the communication and I/O cost increasing when the scale of Hadoop cluster grows Figure 2 shows the scaleup results Clearly the PSCAN algorithm scales very well Similarly the larger graphs show a better scaleup performance To measure the performance of sizeup we hold the number of computers in the system constant and increase the size of graphs Sizeup measures how much longer it takes on a given system when the graph size is times larger than the original graph The relative sizeup is deìned 
   
m 
866 


running-time for clustering  running-time for clustering 
a Scaleup b Relative Scaleup Figure 2 Scaleup as follows 
Relative sizeup  
   
2 In evaluating sizeup of PSCAN we have xed the number of computers as 4 8 and 15 respectively Figure 3 shows the results on different scale of Hadoop clusters The graph shows that PSCAN has a very good sizeup performance Speciìcally the results in Figure 3\(b show that the sizeup of PSCAN is better when the scale of cluster and size of graphs become larger Since we run PSCAN on preprocessed Twitter dataset we apply certain post-processing to a Sizeup b Relative Sizeup Figure 3 Sizeup guarantee the accuracy of the clustering result For a large degree larger than 20 vertex in original Twitter network if its neighbors in the clustering result are assigned to different communities the vertex is classiìed as a hub according to the structural clustering theory If its neighbors in the clustering result are classiìed as outliers the large degree vertex should be the center of a community and the neighbors are identiìed as members in the community with the large degree vertex as the core based on the structural clustering theory Our experiments on the Twitter network found meaningful clusters A cluster obtained by PSCAN for Twitter network represents a group of people who share common interests and other features Manual investigation on some 
DB m 3 Results on Twitter 
m DB DB 
867 


of the clusters revealed that PSCAN identiìes two users of a cluster although there is no direct follower/following relation exists but sharing some common interests Such capability of PSCAN helped us to nd users from a city an organization or a country It is not feasible to discuss all the clusters here one of the interesting clusters is a cluster representing twitter pages of BBC weather channel and weather alerts The cluster of 20 members all representing BBC weather related pages is found There are many such clusters that represents a group of users who share some common interests There is no base line of communities in Twitter to measure accuracy of the clustering but our manual observations found the accuracy is signiìcant Moreover the experiment is designed to prove the feasibility of SCAN in MapReduce framework because SCAN is proved to be accurate enough for clustering The experiment on Twitter data proved the accuracy and scalability of PSCAN V C ONCLUSIONS AND F UTURE W ORK We present a parallel structural clustering algorithm PSCAN for big networks in MapReduce in this paper PSCAN identiìes clusters as well as vertices playing critical roles such as outliers and hubs in big networks with billions of edges in three steps namely calculating structural similarity of edges cutting off edges with low structural similarity and nding connected components All the steps can be executed in parallel in MapReduce The time complexity of PSCAN is linear with the number of edges in the graph Our empirical evaluation demonstrated an accurate clustering result and an excellent running time in terms of scaleup sizeup and speedup Moreover we applied PSCAN for analysis of a Twitter social network with over 40 million users and 1.4 billions of follower/following relationships The result shows that PSCAN can nd interesting communities of people sharing common interests or other features In the future we plan to further investigate the performance of PSCAN by applying it for the analysis of some really big networks in real world A CKNOWLEDGMENT This project was funded by Acxiom Corporation The authors are grateful for invaluable collaboration with Kevin Liles and Derek Leonard throughout the project This work was supported in part by the National Science Foundation under Grant CRI CNS-0855248 Grant EPS-0701890 Grant EPS-0918970 Grant MRI CNS-0619069 and OISE0729792 Weizhong Zhao would like to thank the support of the National Natural Science Foundation of China No 61105052 R EFERENCES  A Lancichinetti S F ortunato and F  Radicchi 
 Physical Review E 78 046110 2008  S Y ook H Jeong and A Barabasi  In PNAS Proceedings of the National Academy of Science pages 13382-13386 October 2002  L Hubert and P  Arabie  Journal of Classiìcation 193C 218 1985  A Strehl J Ghosh R Moone y   Proceedings of the workshop on artiìcial intelligence for web search pp 58-64 2000  X.Xu N.Y uruk Z Feng T  Schweiger  Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining pp 824-833 2007  Bin W u Y aHong Du  2010 International Conference on Artiìcial Intelligence and Computational Intelligence AICI vol.3 no pp.122-126 23-24 Oct 2010  Usha Nandini Ragha v an Rka Albert and Soundar K umara  Phys Rev E 76 036106 2007  M E J Ne wman and M Girv an  Phys Rev E 69 026113 2004  Jimmy Lin and Chris Dyer   Morgan and Claypool Publishers 2010 pp 94-101  Santo F ortunato  Physics Reports Volume 486 Issues 35 February 2010 Pages 75-174 ISSN 0370-1573 10.1016/j.physrep.2009.11.002  Jia wei Han Micheline Kamber  and Jian Pei  3rd edition Morgan Kaufmann 2011  B.W  K ernighan S Lin  Bell Syst Tech J 49 1970 291307  J Shi J Malik  IEEE Trans Pattern Anal Mach Intell 22 8 2000 888905  U Brandes D Delling M Gaertler  R G  orke M Hoefer Z Nikolski D Wagner  URL http://digbib ubka.unikarlsruhe.de/volltexte/documents/3255  A Clauset M.E.J Ne wman C Moore  Phys Rev E 70 6 2004 066111  G P alla I Der  enyi I Farkas T Vicsek  Nature 435 2005 814818  Martin Ester  Hans-Peter Krie gel J  org Sander Xiaowei Xu  Proceedings of the Second International Conference on Knowledge Discovery and Data Mining KDD-96 AAAI Press pp 226231 ISBN 1-57735004-9 
Benchmark graphs for testing community detection algorithms Modeling the internetês large scale topology Comparing partitions Impact of similarity measures on web-page clustering SCAN a structural clustering algorithm for networks Cloud-based Connected Component Algorithm Near linear time algorithm to detect community structures in large-scale networks Finding and evaluating community structure in networks Data-Intensive Text Processing with MapReduce Community detection in graphs Data Mining Concepts and Techniques An efìcient heuristic procedure for partitioning graphs Normalized cuts and image segmentation On modularity npcompleteness and beyond Finding community structure in very large networks Uncovering the overlapping community structure of complex networks in nature and society A density-based algorithm for discovering clusters in large spatial databases with noise 
868 


 Akshay U Bhat  http://www.akshaybhat.com/LPMR 2008  Hae w oon Kw ak Changhyun Lee Hosung P ark and Sue Moon  WWW 2010 April 2630 2010 
Scalable Community Detection using Label Propagation  Map-Reduce What is Twitter a Social Network or a News Media 
869 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






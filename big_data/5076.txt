Discovery of Association Rules from Data including Missing Values Shigeaki Sakurai Kouichirou Mori and Ryohei Orihara Corporate Research  Development Center Toshiba Corporation 1 Komukai-Toshiba-cho Saiwai-ku Kawasaki 212-8582 Japan Email  shigeaki.sakurai kouichirou1.mori ryohei.orihara  toshiba.co.jp Abstract This paper proposes a method that deals with missing values in the discovery of association rules The method deals with items composed of attributes and attribute values The method calculates two kinds of support One is characteristic support and the other is possible support The former is based on the number of examples that do not include missing values in attributes composing target items The latter is based on the number of examples that do not include missing values in all attributes The method extracts all item sets whose characteristic supports are larger than or equal to the prede\036ned threshold The paper evaluates the proposed method by comparing it with the previous method and veri\036es the effect of the proposed method I I NTRODUCTION The discovery method of frequent patterns starts from basket analysis of receipts collected from retail businesses It is possible for the method to efﬁciently generate candidates of frequent patterns by using the monotonic property of the patterns  2 The p roperty is called t he Apriori p roperty  Also it is possible for the method to speedily discover the patterns by devising a storage method for the data  11 However the method deals with transactions composed of different items Here each transaction corresponds to a receipt Each item has two values One value shows that the item is included in the receipt and the other value shows that the item is not included On the other hand in the case of examples composed of some attributes each attribute can be larger than or equal to three values If the discovery method discovers frequent patterns from the data the method requires transfer of the original values to the values composed of two values That is the preprocessing generates items composed of attributes and their attribute values The number of generated items corresponds to the number of attribute values The preprocessing tends to generate many items As the number of items is large the discovery method requires generation of huge candidate patterns The number of candidate patterns increases exponentially because the method requires checking the combination of items Therefore if the discovery method deals with the examples it is important to decrease the number of candidates Also in the case of the examples the examples do not always have all attribute values That is some attribute values are missing The values are called missing values The values are usually preprocessed by the three kinds of methods The rst one gets rid of examples including the missing values The second one completes missing values by referring to distribution of attribute values related to the missing values  The t hird one re g a rds m issing v a lues as speciﬁc attrib ute values However the rst method cannot use the information of remaining attribute values in examples including the missing values The second method cannot always infer appropriate attribute values and assigns wrong attribute values to the missing values The wrong attribute values may discover wrong patterns The third method may discover patterns whose meaning cannot be interpreted This is because the missing values are equally dealt with even if the missing values can originally have different meanings Therefore it is necessary to efﬁciently deal with the missing values These methods are common preprocessing methods in the eld of machine learning and do not always aim at the discovery of frequent patterns Some methods have been proposed for the discovery of association rules Ragel completes missing values by using association rules discovered from the data including missing values Ragel d i v ides a database composed of examples into the valid databases Here the database that does not include missing values is valid database In the valid database Ragel r edeﬁnes the support and the conﬁdence and discovers association rules based on the support and the conﬁdence Shen and Chen propose a method that composes association rules and reuses them in order to improve the validity of both association rules and completed missing values Shintani di vides a database including missing values into some databases not including missing values and discovers association rules from the divided databases Here the number of examples including the rules the support of the rules and the conﬁdence of the rules are larger than or equal to use-deﬁned thresholds Othman and Yahia  introduce the concept of rob u stness f or association rules and aim to select robust association rules for the completion of the missing values However these methods based on the completion have the problem corresponding to the second common preprocessing method Also the other methods do not always sufﬁciently use the property between the attributes and their attribute values in order to efﬁciently discover the association rules Thus this paper proposes a new method that decreases the number of candidates by using the property between attributes and attribute values Also the method sufﬁciently uses the information of examples including missing values We can anticipate that the method discovers more valid frequent 
International Conference on Complex, Intelligent and Software Intensive Systems 978-0-7695-3575-3/09 $25.00 © 2009 IEEE DOI 10.1109/CISIS.2009.92 67 
International Conference on Complex, Intelligent and Software Intensive Systems 978-0-7695-3575-3/09 $25.00 © 2009 IEEE DOI 10.1109/CISIS.2009.92 67 


patterns We note that we discover the frequent patterns and do not discover association rules in this paper but we can easily discover the association rules from the frequent patterns by evaluating the conﬁdence of the frequent patterns Lastly this paper veriﬁes the effectiveness of the proposed method by comparing it with the previous preprocessing II D ISCOVERY OF FREQUENT PATTERNS A Expression of items The original discovery method of frequent patterns deals with transactions such as receipts of the retail elds The transactions are composed of items that have two values Here one value shows that the item is included in a transaction and the other value shows that the item is not included in it Therefore the method cannot deal directly with data composed of some attributes and their attribute values This is because some attributes are larger than or equal to three values The data is called tabular structured data hereafter If we try to discover frequent patterns from the data it is necessary to divide each attribute into items composed of two values in the preprocessing For example an attribute is given blood pressure and it has three attribute values high normal and low The combinations of the attribute and its attribute values blood pressure high blood pressure normal and blood pressure low are regarded as items composed of two values In general if each example of the data t is given by Formula 1 the example is interpreted as items deﬁned by Formula 2 Here A i   i 1  2   m  is an attribute a ix i is an attribute value of the attribute A i  m is the number of attribute values composing examples and the combination of an attribute and an attribute value A i  a ix i is an item  a 1 x 1 a 2 x 2   a mx m  1  A 1  a 1 x 1 A 2  a 2 x 2   A m  a mx m  2 B Missing values First we note the data as shown in Table I Here a speciﬁc attribute of each example has at most an attribute value Also in this table  shows a missing value This table includes missing values corresponding to respective attributes A 1 and A 2  TABLE I E XAMPLES INCLUDING MISSING VALUES A 1 A 2 t 1 a 11 a 21 t 2 a 11 t 3 a 12 a 21 t 4 a 22 t 5 a 12 a 22 t 6 a 13 a 23 If two examples t 2 and t 4 including a missing value are deleted from the data the frequencies of attribute values a 11  a 12 and a 13 of the attribute A 1 are 1 2 and 1 and the frequencies of attribute values a 21  a 22  and a 23 of the attribute A 2 are 2 1 and 1 Also the number of examples where t 2 and t 4 are deleted is 4 In the case of the attribute values a 11  a 12  a 13  a 21  a 22  and a 23  the supports deﬁned by Formula 3 are 0.25 0.5 0.25 0.5 0.25 and 0.25 respectively Therefore when the minimum support is 0.3 the patterns A 1  a 12 and A 2  a 21 are extracted as frequent patterns supp  p  f  p  N 3 Here N is the number of examples and f  p  is the number of examples including the pattern p  On the other hand we note individual attributes In the case of the attribute A 1  the data includes only a missing value in the example t 4  In the case of the attribute A 2  the data includes only a missing value in the example t 2  In addition in each case the number of examples where the missing value is deleted is 5 Therefore the supports for the attribute values a 11  a 12  and a 13 are 0.4 0.4 and 0.2 The supports for the attribute values a 21  a 22  and a 23 are 0.4 0.4 and 0.2 When the minimum support is 0.3 the patterns A 1  a 11 and A 1  a 12 are extracted as frequent patterns for the attribute A 1  and A 2  a 21 and A 2  a 22 are extracted as frequent patterns for the attribute A 2  The aforementioned examples show that the complete deletion of examples including missing values and the partial deletion of examples based on each attribute lead to different results The latter one uses the information discarded by the former one We can anticipate that the latter one discovers more valid patterns than the former one does Frequent patterns are usually composed of some items It is necessary to decide which examples are deleted from the attribute set corresponding to the items The attribute set is called the attribute pattern hereafter In the case that the number of attributes is small it is possible to decide which examples are deleted for all combinations of attributes in advance However the number of the combinations increases exponentially as the number of attributes increases In the case that the number of attributes is large it is not possible to decide the example subsets corresponding to all the combinations in advance Therefore it is necessary to decide which examples are deleted when the attribute pattern is given We note the case that an attribute pattern includes all the attributes The number of the remaining examples in the case is smaller than or equal to the numbers in the case of other attribute patterns This is because the attribute patterns based on all the attributes are a super subset of other attribute patterns Therefore if two supports are deﬁned by Formula 4 and Formula 5 the relationship supp char  p P  002 supp pos  p  is satisﬁed for a pattern p  In the following supp char and supp pos are called characteristic support and possible support respectively Here P is an attribute pattern P all is the attribute pattern composed of all attributes and n  is a function that calculates the number of examples not including missing values in the attribute pattern P  supp char  p P  f  p  n  P  4 
68 
68 


supp pos  p  f  p  n  P all  5 The characteristic support uses more examples than the possible support does in order to evaluate the support The characteristic support is a more valid criterion Thus this paper tries to discover patterns whose characteristic supports are larger than or equal to the minimum characteristic support The patterns are a kind of frequent patterns and are called characteristic patterns hereafter Also this paper calls the patterns whose possible supports are larger than or equal to the minimum characteristic support possible patterns If an attribute is added to an attribute pattern examples including new missing values may be added That is the value of the denominator in the characteristic support may decrease The monotonic property is not always satisﬁed in the case of the characteristic support For example we note the following example In the case of the attribute pattern  A 1 A 2   100 examples are remaining and 27 examples include the attribute value set  a 11 a 21   Also the former examples include 10 missing values in the attribute A 3 and the latter examples have the attribute value a 31 in the attribute A 3  Then in the case of the attribute pattern  A 1 A 2   the characteristic support in the pattern  A 1  a 11 A 2  a 21  is 0.27  27 100  In the case of the attribute pattern  A 1 A 2 A 3   the characteristic support in the pattern  A 1  a 11 A 2  a 21 A 3  a 31  is 0.3  27 90  The monotonic property is unsatisﬁed in this example On the other hand the possible support satisﬁes the monotonic property because the denominator in the possible support is xed The possible support of a pattern gives the upper bound of characteristic supports given by super patterns of the pattern Therefore if the possible support is smaller than the minimum characteristic support the characteristic supports of the super patterns are smaller than the minimum characteristic support That is the super patterns do not become characteristic patterns It is not necessary to expand the pattern whose possible support is smaller than the minimum characteristic support To the contrary if the possible support of the pattern is larger than or equal to the minimum characteristic support its supper patterns may become characteristic patterns It is necessary to keep the pattern even if the pattern is not extracted as a characteristic pattern In the following the pattern whose possible support is larger than or equal to the minimum characteristic support is called a possible pattern According to these discussions in the evaluation of the patterns it is necessary to evaluate the patterns by both the characteristic support and possible support That is if the characteristic support of a pattern is larger than or equal to the minimum characteristic support the pattern is extracted as a characteristic pattern Otherwise it is necessary to evaluate the possible support of the pattern If its possible support is larger than or equal to the minimum characteristic support the pattern is kept as the seed of the super patterns We can efﬁciently discover all characteristic patterns by the two-step evaluations C Generation of candidate patterns The discovery method of frequent patterns can discover frequent patterns from the tabular structured data by using the expression of the items as shown in Section II-B The expression requires the generation of items corresponding to each attribute value The number of items tends to be huge and the amount of calculation tends to be huge On the other hand the discovery method repeats the generation of candidate patterns and the calculation of their frequencies It is important to decrease the number of the candidate patterns We note the property of the tabular structured data In the data each attribute has at most an attribute value Each item set does not include items whose attributes are equal to each other It is not necessary for the discovery method to evaluate a candidate pattern such that attributes of items composing the pattern are equal to each other The discovery method can judge that the pattern is not a characteristic pattern without calculating its frequency Sakurai et al  proposed the a ttrib ute constraint based on the property of the tabular structured data in the sequential pattern discovery and proposed the discovery method incorporating the constraint Also Sakurai et al  v e riﬁed the effectiveness of the method by using medical examination data However the method judges whether items composing a candidate pattern have the same attribute when the candidate pattern is generated and it deletes the candidate pattern including the same attribute The method requires judging the attribute constraint even if the judgment can be performed much more speedily than the calculation of the frequency can Thus this paper proposes a method without judging the attribute constraint First this section explains the outline of the method The method generates attribute patterns by combining with attributes corresponding to items Also the method generates attribute value sets by combining with attribute values corresponding to attributes Here the combinations are performed for different attributes This two-step generation method can generate all candidate patterns composed of different attributes without judging the attribute constraint The attribute value set is called the attribute value pattern hereafter Next a more concrete method is explained in the following We can assume that the attribute and the attribute values are arranged in a criterion such as the alphabetic order without losing generality Thus we assume A i A j  a ik 1 a ik 2  and a ix 1 a jx 2 for i<j and k 1 k 2  The method can compose all attribute patterns including two attributes by combining the attribute A i with the other attribute A j  Figure 1 shows an example of the combinations In this gure the method generates the attribute patterns  A 1 A 2    A 1 A 3      A 1 A m    A 2 A 3    and  A m 025 1 A m  in order Also the method can compose all attribute patterns including three attributes by combining the attribute pattern  A i A p  with the other attribute pattern  A i A q   where i<p<q  The attribute patterns  A i A p  and  A i A q  have the common attribute A i  For example the method generates an attribute pattern 
69 
69 


 A 1 A 2 A 3  by combining  A 1 A 2  with  A 1 A 3   Similarly the method generates the attribute patterns  A 1 A 2 A 4      A 1 A 2 A m    A 2 A 3 A 4     and  A m 025 2 A m 025 1 A m  in order Fig 1 Generation of candidate patterns In general the method generates all attribute patterns including r attributes by combining two attribute patterns including  r  1 attributes These attribute patterns including  r  1 attributes include the common  r  2 attributes and the common attributes are arranged before remaining attributes Figure 2 shows an outline of the generation of an attribute pattern In this gure each circle shows an attribute and designs on the circle identify the kind of attributes Fig 2 Generation of an attribute pattern We note the generation of attribute value patterns The generation is based on processes similar to the aforementioned generation of attribute patterns That is the method generates all attribute value patterns including r attribute values by combining two attribute value patterns including  r  1 attribute values These attribute value patterns including  r  1 attribute values have the  r  2 common attribute values and the common attribute values are arranged before remaining attribute values For example the method generates the attribute value pattern  a 11 a 21  by combining the attribute value a 11 with the other attribute value a 21  Similarly the method generates the attribute value patterns  a 11 a 22      a 11 a 2 m 2    a 12 a 21    in order as shown in Figure 1 Also the method generates  a 11 a 21 a 31  by combining  a 11 a 21  with  a 11 a 31   It generates the attribute value patterns  a 11 a 21 a 31    a 11 a 21 a 32     a 11 a 21 a 3 m 3    a 11 a 22 a 31  in order Lastly we note the method that increases the number of items The method has two kinds of strategy The rst strategy is the width-based method and generates candidate patterns whose numbers of items are small in order The other strategy is the depth-based method and generates candidate patterns related to speciﬁc items or item sets in order In order to decide the strategy we note the attribute value patterns included in the same attribute pattern If the tabular structured data is scanned for the attribute pattern the frequencies of the attribute value patterns are calculated and the frequency of examples not including missing values for the attribute pattern is calculated simultaneously Also if possible patterns are given for all attribute patterns composed of the common attributes and a different attribute the candidate patterns are generated by combining two possible patterns without generating redundant candidate patterns Here the number of items composing the candidate patterns is equal to the number that adds 1 to the number of the possible patterns We can anticipate that the width-based method easily discovers all characteristic patterns On the other hand in the depth-based strategy if all characteristic patterns related to speciﬁc items or item sets are discovered the patterns can be discarded The strategy tends to require smaller memory space than the width-based method In the case of the tabular structured data the number of items tends to be huge and the number of candidate patterns tends to be huge In order to save the memory space it is reasonable to use the depth-based strategy to some extent Therefore the strategy used in this paper is a mixture of the widthbased strategy and the depth-based strategy First the strategy checks rst candidate patterns including attribute patterns A 1  A 2    and A m in order based on the width-based strategy Next the strategy checks higher candidate patterns related to the attribute patterns in order based on the depth-based strategy Lastly in the higher candidate patterns candidate patterns related to a speciﬁc attribute pattern are checked in order based on the width-based strategy That is the strategy checks candidate patterns including attribute patterns A 1  A 2    A m   A 1 A 2    A 1 A 3      A 1 A m    A 1 A 2 A 3      A 1 A 2 A m    in order In this section we do not pay attention to the division of the data Each attribute value can keep a corresponding subset of the data It is possible for the division to decrease the amount of calculation On the other hand the division requires additional memory space to store the subsets The division does not always lead to the decrease of the calculation time because of the swapping process of the space In future work we will try to verify the effectiveness of the division D Discovery method According to the discussion in subsection II-B and subsection II-C the discovery method of characteristic patterns is described as shown in Figure 3 The method inputs both the tabular structured data  DB  composed of N examples and the minimum characteristic support  MinChSp  It outputs all 
70 
70 


characteristic patterns First the method calculates the number  Mvl  of examples that do not include missing values by using calcM issingV l   Mvl is used to calculate possible supports The method discovers rst characteristic patterns whose numbers of items are 1 After that it discovers higher characteristic patterns whose numbers of items are larger than 1 In the discovery of the rst characteristic patterns the function createStruct  creates the structure that stores the information related to each attribute A i and the structure is referred to as St  The method stores the attribute A i as an attribute pattern to St.PtAry and stores each attribute value a ij to St.VlPtAry Here PtAry and VlPtAry are members of St Next the function calcF q  calculates frequencies of both a ij and the missing value of A i by referring to the row of A i in DB  This function stores the frequency of a ij to FqAry and stores the frequency of the missing value to mvl The method calculates the characteristic support of a ij by using the formula FqAry  j  N 025 mvl  If the characteristic support is larger than or equal to MinChSp  the function output  outputs the pattern  A i  a ij  corresponding to a ij as a characteristic pattern Otherwise the method calculates the possible support of a ij by using the formula FqAry  j  N 025 Mvl  Then if the possible support is larger than or equal to MinChSp  the pattern is kept to generate candidate patterns whose numbers of items are larger Otherwise the pattern is deleted from St.V lPtAry  The calculation of supports and the judgment are repeated for each attribute value pattern Lastly the function judgePt  checks whether the number of remaining attribute patterns is larger than or equal to 1 If at least one attribute pattern remains the function addQueue  stores the structure to Queue 1  Otherwise the structure is deleted Owing to these processes the method can output all rst characteristic patterns and can keep all possible patterns in order to generate higher candidate patterns In the discovery of the higher characteristic patterns the function pickQueue  picks up one of the structures from Queue i  Here the structures include the information related to attribute patterns composed of i attributes The picked-up structure is referred to as tSt 1  The method picks up other structures by referring to Queue i  The picked-up structure is referred to as tSt 2  The function createSt  creates the structure that stores the information related to attribute patterns composed of  i 1 attributes and the structure is referred to as St  The function genAtP t  generates an attribute pattern composed of  i 1 attributes by combining the attribute pattern of tSt 1 with the attribute pattern of tSt 2 This function stores the generated attribute pattern to St  We note that Queue i stores the structures related to attribute patterns such that each attribute pattern includes the  i  1 common attributes from the top of the pattern Therefore this function generates the pattern by adding the last attribute in the pattern of tSt 2 to the attribute pattern of tSt 1  Next the function genV lP t  generates attribute value patterns corresponding to the generated attribute pattern by combining the attribute value patterns of tSt 1 with the attribute value patterns of tSt 2  The generated attribute value patterns are composed of  i 1 attribute values They are stored to St  Here we note that this function picks up one of the attribute value patterns of tSt 1 and picks up all attribute value patterns of tSt 2 in order After that this function picks up the next attribute value pattern of tSt 1  It repeats the pick-up until all attribute value patterns of tSt 1 are picked up Owing to these processes this function can generate all attribute value patterns Next the function calcF q  calculates frequencies of both the generated attribute value patterns and the missing value of the generated attribute pattern by referring to rows of the generated attribute patterns in DB  This function stores the frequencies of the generated attribute patterns to FqAry and stores the frequency of the missing value to mvl  In a process similar to the discovery of rst characteristic patterns the method calculates characteristic supports and possible supports of the generated attribute patterns The method also outputs characteristic patterns and keeps possible patterns in St In addition if at least one attribute patterns remains St is stored to Queue i 1  Otherwise St is deleted The method starts the growth corresponding to the top structure of Queue i 1 when the growth corresponding to the top structure of Queue i terminates Therefore the method can investigate higher characteristic patterns in the order of A 1  A 2    and A m 025 1  We note the attribute A m is not processed This is because A m is the last attribute and higher characteristic patterns based on A m are still being investigated for other attributes Also we note the algorithm does not include the deletion process of discovered patterns If it is necessary to delete them the method requires administrating the link relations among higher attribute patterns in the attribute A i  The method can delete the discovered patterns in A i when the method starts the discovery of higher characteristic patterns in the attribute A i 1  III N UMERICAL EXPERIMENTS A Data This paper performs numerical experiments by using synthetic data The data is generated based on the algorithm as shown in Figure 4 That is the data is composed of examples whose number  trnum  is deﬁned by the user Each example is composed of attributes whose number  atnum suserdeﬁned Also each attribute is composed of attribute values whose number  atvnum  is user-deﬁned In addition missing values are inserted in the data based on the user-deﬁned missing rate  mrate  Here the missing rate is deﬁned by the formula mvnum trnum  atvnum  where mvnum is the number of missing values trnum  atnum  atvnum  and mrate are input to the algorithm and the algorithm outputs the tabular structured data as shown in Figure 5 In these experiments trnum is 1,000 atnum is 2 3 5 and 10 atvnum is 2 3 5 and 10 and mrate is 0.1 0.2 0.3 0.4 and 0.5 For each combination of trnum  atnum  atvnum  and mrate  10 example sets are generated based on the random numbers using different initial value 
71 
71 


Initialization A  002 m 1 A i  calcM issingV l  A  Mvl  Discovery of rst characteristic patterns For each attribute A i 003 A createStruct  St  St.AtP tAry  A i  St.V lPtAry  002  For each attribute value a ij 003 A i add a ij to St.V lPtAry  calcF q  St DB  FqAry  mvl  j 0 For each attribute value pattern VlPt j 003 St.V lPtAry csup  FqAry  j  N 025 mvl  If csup 004 M inChSp  Then output  St j  Else psup  FqAry  j  N 025 Mvl  If psup  M inChSp  Then delete VlPt j from St.V lPtAry  j  j 1 If judgeP t  St  true  Then addQueue  St  Queue 1  Else delStruct  St  Discovery of higher characteristic patterns i 1 while true   while  tSt 1 pickQueue  Queue i   NULL   For each attribute pattern tSt 2 003 Queue i createStruct  St  genAtP t  tSt 1 AtP tAry tSt 2 AtP tAry  St.AtP tAry  genV lP t  tSt 1 V lP tAry tSt 2 V lP tAry  St.V lPtAry  calcF q  St DB  FqAry  mvl  j 0 For each attribute value pattern VlPt j 003 St.V lPtAry csup  FqAry  j  N 025 mvl  If csup 004 M inChSp  Then output  St j  Else psup  FqAry  j  N 025 Mvl  If psup  M inChSp  Then delete VlPt j from St.V lPtAry  j  j 1 If judgeP t  St  true  Then addQueue  St  Queue i 1  Else delStruct  St  i  i 1  i  i  1 If i  0 Then break   end  Fig 3 A discovery method of characteristic patterns B Method This paper discovers characteristic patterns from generated example sets based on the proposed method Also it discovers frequent patterns based on a previous method That is the patterns are discovered from generated example sets where examples including missing values are excluded They correspond to characteristic patterns This paper uses 0.01 0.05 1 Read trnum  atnum  atvnum and mrate  2 Set trcnt to0andset atcnt to 0 3 If trcnt is larger than or equal to trnum  terminate this algorithm 4 Add trcnt to 1 5 If atcnt is larger than or equal to atnum gotostep10 6 Add atcnt to 1 7 Generate a random number in the range 0  1  8 If the random number is smaller than or equal to mrate  set a missing value to the attribute value corresponding to trcnt and atcnt  Otherwise generate another random number select a value from  1  2   atvnum  based on the random number with equal probability and set the value to the attribute value 9 Return to step 5 10 Set atcnt to 0 and return to step 3 Fig 4 A generation method of synthetic data Fig 5 An example of the synthetic data 0.1 and 0.2 as the minimum characteristic support and the minimum support  MinSp  Also it veriﬁes the effectiveness of the proposed method by evaluating the method from three viewpoints First the number of examples used in order to discover patterns is evaluated Second the difference of discovered patterns between the proposed method and the previous method is evaluated Third the number of redundantly stored possible patterns is evaluated C Results Figure 6 shows parts of the numerical experiments In each gure the horizontal axis shows the number of items In Figure 6\(a and Figure 6\(b the vertical axis shows the number of examples In Figure 6\(c Figure 6\(d Figure 6\(e and Figure 6\(f the vertical axis shows the number of patterns Figure 6\(a Figure 6\(c and Figure 6\(e show the result in the case that trnum 1,000 atnum 10 atvnum 2 mrate 0.1 and MinChSp  MinSp 0.01 Figure 6\(b Figure 6\(d and Figure 6\(f show the result in the case that trnum 1,000 atnum 10 atvnum 10 mrate 0.4 and MinChSp  MinSp 0.01 In addition Figure 6\(a and Figure 6\(b show the relationship between the number of examples that do not include missing values in the attribute patterns of discovered characteristic patterns and the number of items in the discovered patterns In these gures Proposed shows the results of the proposed method and Previous shows the results of the previous method Figure 6\(c and Figure 6\(d show the difference of both the discovered characteristic patterns and the discovered frequent patterns In these gures Common shows the 
72 
72 


a The number of evaluated examples the case t1000a10v2m0.1sup0.01 b The number of evaluated examples the case t1000a10v10m0.4sup0.01 c The difference of discovered patterns the case t1000a10v2m0.1sup0.01 d The difference of discovered patterns the case t1000a10v10m0.4sup0.01 e The number of characteristic patterns and possible patterns the case t1000a10v2m0.1sup0.01 f The number of characteristic patterns and possible patterns the case t1000a10v10m0.4sup0.01 Fig 6 Experimental results results in the case that both the proposed method and the previous method discover the patterns Proposed only shows the results in the case that the proposed method discovers them and the previous method does not discover them Previous only shows the results in the case that the proposed method does not discover them and the previous method discovers them Figure 6\(e and Figure 6\(f show the relationships of both the number of characteristic patterns and the number of possible patterns that do not include characteristic patterns In these gure Char shows the results in the case of the characteristic patterns and Pos shows the results in the case of the possible patterns D Discussions 1 Number of evaluated examples We note the results of Figure 6\(a and Figure 6\(b The results show that the previous method uses much smaller examples than the proposed one in order to discover characteristic patterns In particular in the case that the number of items is small and the rate of missing values is high this trend tends to be apparent The proposed method can discover the characteristic patterns based on many examples We can anticipate that the proposed method more validly discovers the patterns Therefore the proposed method is more efﬁcient than the previous ones 2 The difference of discovered patterns We note Figure 6\(c and Figure 6\(d In the case that the number of attributes is small the difference of the discovered patterns is slight This is because the variation of characteristic patterns is small On the other hand in the case that the number of attributes is large we can conﬁrm that the difference become huge The results show that the previous method may fail 
73 
73 


to discover important characteristic patterns Therefore the proposed method is particularly important in the case that the number of attributes is larger 3 Characteristic patterns and possible patterns We note the results of Figure 6\(e and Figure 6\(f The results show many possible patterns are discovered in the case that the number of attributes is large and the rate of missing values is high The proposed method uses the number of examples that do not include missing values in all attributes in order to calculate possible supports In this case many examples tend to include missing values in some attributes The number tends to be huge Therefore the possible supports tend to be evaluated as larger than the characteristic supports We think this is the reason many possible patterns are discovered If it is necessary to discover all characteristic patterns the proposed method needs to keep all possible supports However it is important to decrease the number of possible patterns because many possible patterns require much memory space The space may give large impacts to the calculation speed On the other hand as the number of attributes is large the possibility that characteristic patterns including all attributes are discovered tends to be small and the characteristic patterns tend to be composed of only parts of attributes So if we aim at the discovery of characteristic patterns whose numbers are smaller than or equal to the user-deﬁned number of attributes we may be able to estimate smaller possible supports For example we arrange attributes in descending order of the frequencies of examples including missing values and accumulate the frequencies in the order until the number of attributes arrives at the user-deﬁned maximum number of attributes In the case that the number of examples that include multiple missing values is small this method can appropriately estimate the number  n  P 002   of examples that do not include missing values in attribute patterns  P 002  Here P 002 is composed of attributes whose number is user-deﬁned maximum number On the other hand in the case that the number of the examples is large this method may not be able to estimate it appropriately This is because many examples may be doubly counted The number of examples that does not include the missing values in P 002 may be smaller than n  P all   Therefore it is necessary to apply other methods to evaluate the number in the latter case We may be able to use sampling methods of attribute patterns In future work we will try to consider estimation methods for a smaller number 4 Generality of the proposed method Real data sets include many missing values For example in the case of a questionnaire respondents do not always answer all the questions The unanswered questions become missing values Also in the case of medical eld doctors do not always perform all tests on all patients and ask them the same questions owing to the restrictions of time and cost The unperformed tests and the unanswered questions become missing values In addition parts of the collected data may be destroyed owing to human errors breakdown of machines and poor transmission environments The destroyed data becomes missing values On the other hand the proposed method deals with missing values without depending on the application tasks Therefore the method can be applied to many application tasks In this paper we showed only the experimental results based on the synthetic data However numerical experiments based on real medical data are performed and the results are similar to the results shown in this section In future work we are planning to consider whether the characteristic patterns have larger impact We believe the proposed method efﬁciently acquires characteristic patterns composed of items from the tabular structured data IV S UMMARY AND FUTURE WORK In this paper we proposed a method that discovers characteristic patterns from tabular structured data including missing values The method efﬁciently uses the information included in the data without deleting examples including missing values or completing missing values Also the method generates both attribute patterns and attribute value patterns step-wisely This paper applies the proposed method to synthetic numerical data and veriﬁes the effectiveness of the proposed method In future work we will try to apply the proposed method to many application elds and to verify the effectiveness of the method For example we are planning to apply the method to medical data nancial data and so on Also we will try to consider a method that estimates possible supports more appropriately in order to decrease the number of generated possible patterns Lastly we will try to expand the method to cover the sequential data including missing values R EFERENCES  R  A gra w al and R  S rikant Fast Algorithms for Mining Association Rules in Large Databases  Proc 20th Intl Conf on Very Large Data Bases 487-499 1994  J  H an J  P ei and Y  Y in Mining Frequent Patterns without Candidate Generation  ACM SIGMOD Intl Conf on Management of Data 1-12 2000  T  M orzy and M  Z akrze w icz Group Bitmap Index A Structure for Association Rules Retrieval  Proc 4th Intl Conf on Knowledge Discovery and Data Mining 284-288 1998  L  B  O thman a nd S B Y a hia Yet Another Approach for Completing Missing Values  Proc 4th Intl Conf on Concept Lattices and Their Applications 155-169 2006  J  R  Q uinlan Induction of Decision Trees  Machine learning 1 1 81166 1986  A  R agel Preprocessing of Missing Values Using Robust Association Rules  Proc 2nd European Sympo on Principles of Data Mining and Knowledge Discovery 414-422 1998  A  R agel Treatment of Missing Values for Association Rules  Proc 2nd Paciﬁc-Asia Conference on Research and Development in Knowledge Discovery and Data Mining 258-270 1998  S  S akurai Y  Kitahara and R  O rihara Discovery of Sequential Patterns Coinciding with Analysts Interests  J of Computers 3 7 1-8 2008  J  J Shen and M  T  Chen A Recycle Technique of Association Rule for Missing Value Completion  Proc 17th Intl Conf on Advanced Information Networking and Applications 526 2003  T  Shintani Mining Association Rules from Data with Missing Values by Database Partitioning and Merging  Proc 5th IEEE/ACIS Intl Conf on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering Software Architecture and Reuse 193-200 2006  M J Zaki S  P arthasarathy  M Ogihara and W  L i New Algorithms for Fast Discovery of Association Rules  Proc 3rd Intl Conf on Knowledge Discovery and Data Mining 283-286 1997 
74 
74 


meani n g u s i ng t h e C ohen d ze Threats t o ity concern f actors t hat can inﬂuence our obs erv a t i ons  A l t hough bot h a s s o ci at i o n r ul e d i s co v e r y an d G r a n g e r cau sality test can statistically in f e r c o changes b et w een  l es or t e mporal l y cons equent changes  as in th e case o f G r a n g e r th is w o u l d n o t allo w t o c laim an yt hi ng about caus e ef fect rel a t i ons hi ps about changes o ccurri ng on a  l e and o n t hos e h a v i n g a change-coupl i n g re l a t i o n w i t h i t  Threats t o ex t e r n a l v a l i d i t y concern t he general i zat i o n of our  ndi ngs  A l t hough w e performed our anal ys es on four di f ferent s ys t e ms  b el ongi ng t o di f ferent domai ns and de v e l oped w i t h di f ferent p rogrammi ng l a nguages  w e are aw a r e t h a t a f u r t h e r e m p i r i c a l v a l i d a t i o n o n a l a r g e r s e t o f sy st e m s w o u l d b e b e n e  c i a l t o b e t t e r su p p o r t o u r  n d i n g s R TED W K As s t a t e d b y B o h n e r a n d Ar n o l d  1 5  am a j o r g o a l o f impact analys is is to identify the s oftw ar e w or k p r oducts af f ect ed by pr opos ed c hang es  Mos t of t h e e xi s t i n g c hange i m pact anal ys i s t echni ques aim a t e x p l o itin g t h e p r esen ce o f d e p e n d e n c ies i n t h e so u r ce code i dent i  ed by means o f s t a t i c anal ys i s 2  dynami c 3 or s p eci  c t echni ques s uch a s s t a t i c and or dynami c s l i c i n g 16  S o me i m pact anal ys i s t echni ques c ope wi t h p r o b l e m s s p e c i  c o f p a r t i c u l a r k i n d s o f a r t i f a c t s  for e xampl e  U ML model s 17  T here i s a l ar ge corpus of s t udi es rel a t e d t o c hange i m pact anal ys i s  h o w e v er a compl e t e s u rv e y of t h em i s be yond t h e s cope of t h i s paper  As m e n t i o n e d i n t h e i n t r o d u c t i o n  o n e l i m i t a t i o n o f e x i s t in g im p a c t a n a ly s is te c h n iq u e s is th a t th e y w o r k a s s u m in g the p res ence o f d ependencies b etween artif acts  Alternati v e approaches e x i s t t o o v e rcome s uch a l i m i t a t i on S o me of 4 18  are b as ed on info rmation r etrie v al i e the y ex p l o i t t h e t ex t u a l c o n t e n t o f t h e a r t i f a c t s  a s s u m i n g t h a t ac h a n g e t o a s o f t w a r e a r t i f a c t w i l l i m p a c t o t h e r  t e x t u a l l y sim ilar a r tif acts Th e w eak n e ss i s t h a t t h e se a p p r o a c h e s mi g h t f a i l t o  n d p e r t i n e n t l i n k s w h e n t h e s i mi l a r i t y i s lo w—wh ile ar tif acts a r e  i n d eed r elated—or m ight nd fa l s e p o s i t i v e s w h e n u n r e l a t e d a r t i fa c t s a r e t e x t u a l l y s i m i l a r  Ot h e r a p p r o a c h e s t h a t d o n o t r e l y o n c o d e d e p e n d e n c i e s a r e bas e d o n e xpert j udgment a nd code i n s p ect i o n 19  ho w ev e r  s ev e r a l s t u d i e s h av e s h o w n t h a t e x p e r t p r e d i c t i o n s a r e frequently incorrect or at leas t b ias e d b y s ubjecti v enes s  20  and s ource code i n s p ect i o n can be prohi bi t i v e l y e xpens i v e 21  The  rs t s t udi es ai med a t i dent i fyi ng l ogi cal change coupl i ngs w e re performed by G a l l al r s t o n c h a n g e releas es of a t elecommunication s ys tem  22  a nd then on commit h is tories e x tracted from C VS logs 23   T o o v er co m e th e lim itatio n s o f th e p r e v i o u s ch an g e im p act analys is approaches  a nd abo v e all t o c omplement t he recommendat i ons t h at coul d b e p ro vi ded b y t radi t i onal c hange impact analys is approaches  t wo a p p r o a c h e s w e r e d e v e l o p e d in p a r a lle l b y tw o d if f e r e n t r e s e a r c h g r o u p s  n a m e ly Y in g et  5 a nd Zi mmermann et al 1 6  B o t h us e a s s oci a t i o n r u les d isco v e r y  a wellk n o wn d a tam in in g p r actice—th at we s u mmari zed i n S ect i o n II-B t o d et ermi ne s e t s of  l es th a t w e r e c h a n g e d to g e th e r f r e q u e n tly in th e p a s t f r o m th e change hi s t ory o f t he code bas e  T he hypot hes i s i s t hat t he change patterns i nferred b y m eans o f a s s o ciation r ules i.e l e s c o c h a n g i n g i n t h e s a m e c h a n g e s e t  c a n b e u s e d t o recommend pot ent i a l l y rel e v a nt s ource code t o a d e v el oper performi n g a change T he y found t h at i n man y cas es t h e precis i on in the p erformed pr ediction i s o ften abo v e 70 and i n s ome cas es higher t han 90 w hile the r ecall o ften lo w e r th a n 2 5   a n d in s o m e c a s e s b e lo w 1 0   In a p re vi ous paper 7 w e i n t roduced t h e i dea o f u s i ng th e m u lti v a r i ate tim e s er ies f o r p r ed ictin g t h e im p act o f ac h a n g e  T h i s p a p e r c o n t i n u e s t h ee a r l y w o r k p r e v i o u s l y pr e s e nt e d a s f ol l o w s   we p r e s e n t a n e m p i r i c a l e v a l u a t i o n  t h r o u g h c h a n g e s fro m fo u r s o ft w a re s y s t e m s  o f G ra n g e r c a u s a l i t y t e s t  its co m p ar iso n with asso ciatio n r u le d isco v e r y  a n d th e ove r l a p o f t h e i r r e s u l t s  T h e p r e v i o u s w o r k o n l y s h o w e d th e a p p licab ility o f th e a p p r o ach o n a s u b s y s tem o f t h e a 7  md  o m p o s e d o f a b o u t 3 0  l e s o n l y   to tr ain t h e m u lti v a r i ate tim e s er ies m o d e l i n a w a y t h a t pro v i d es t h e  s t rengt h of t h e c hange coupl i n g rel at i on we u s e  l e c h a n g e f r e q u e n c i e s  i n s t e a d o f B o o l e a n va r i a b l e s i n d i c a t i n g w h e t h e r o r n o t  l e s c h a n g e d   we d e  n e a h y b r i d a p p r o a c h t h a t c o m b i n e s r a n k i n g o f bot h a s s o ci at i o n r ul es and G ranger  C AND W K IN P S In recent y ears  As s o ciation r ule d is co v e ry 11  has b een su c c e ssf u l l y a p p l i e d t o p r e d i c t c h a n g e c o u p l i n g s a m o n g  l e s by mi ni ng dat a from s oft w are repos i t o ri es 1  5  Thi s paper p erforms a n e mpirical comparis on of as s o ciation r ule di s c o v e ry w i t h a t echni que bas e d o n m ul t i v a ri at e t i m e s eri e s an aly s is a n d sp eciﬁcally o n th e G r a n g e r cau sality test  8   Re s u l t s o f a n e m p i r i c a l s t u d y p e r f o r m e d o n c h a n g e d a t a ex t r a c t e d f r o m C V S r e p o s i t o r i e s o f f o u r d i f f e r e n t s o f t w a r e sy st e m s F r e e B S D i 3 8 6  M y l y n  S q u i d  a n d R h i n o  sh o w th at  i o v e r a ll asso ciatio n r u le d isco v e r y e x h ib it a h ig h e r p r ecisio n th an Gran g e r cau sality test w h ile th e r ecall o f Gr an g e r cau sality test is i n m o s t cases h ig h e r f o r Gr an g e r cau sality o r at least c o m p a r a b l e an d  ii th e n u m b e r o f tr u e r eco m m e n d a tio n s p r o v id ed b y Gr an g e r cau sality test is h ig h e r th a n f o r a s s o c ia tio n r u le s  a n d a b o v e a ll th e tw o te c h n iq u e s p r o v id e a s e t o f r e c o m m e n d a tio n s h a v in g a v e r y lo w in te r s e c tio n  The a bo v e res u l t s s ugges t t h e opport uni t y of combi n i n g th e tw o te c h n iq u e s  A h y b r id te c h n iq u e o b ta in e d b y c o m bi ni ng ranki ng s c ores pro v i d ed by as s o ci at i o n rul es and b y Gran g e r cau sality allo w t o o b t ain  i a F measu r e a n d a r ecall 7 http://w w w  s am ba o r g 


hi gher t han t he t w o t echni ques a l one a nd i i  a p reci s i on i n bet w een t h e t w o  In s ummary  t he performed s t udy s ugges t s th e p o te n tia l o f m u lti v a r ia te tim e s e r ie s a n a ly s is to s u g g e s t change coupl i ngs compl e ment ary t o t hos e p ro vi ded b y a s so c i a t i o n r u l e s a n d t h e a d v a n t a g e s o f c o m b i n i n g t h e t w o te c h n iq u e s  Wo r k i n p r o g r e s s a i m s a t  i  u s i n g e n h a n c e d w a y s o f co m b in in g t h e tw o t ech n i q u e s  ii f u r t h e r v alid atin g t h e combi n ed t echni ques t hrough more cas e s t udi es as w e l l as by in v e stig atin g h o w ch an g e s t en d t o b e p r o p a g a ted i n p r o jects ha ving a d if ferent or ganizati on and  iii better unders tanding th e n atu r e o f c h a n g e co u p lin g i n f er r e d b y G r a n g e r cau sality te s t a s o p p o s e d to th o s e in f e r r e d b y m in in g a s s o c ia tio n r u le s  R EF ER EN C ES 1 T  Z i m m e rm a n n  P  W e i s g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  i n E 0 4  P r o c e e d i n g s o f t h e 2 6 t h In t e r n a t i o n a l C o n f e r e n c e o n Sof t w ar e E ngi neeri n g 2 0 0 4  p p  5 6 3  5 7 2  2 R  S  A rn o l d a n d S  A  B o h n e r   Im p a c t a n a l y s i s t o w a rd s a frame w o rk fo r c o m p a riso n   i n Pr o c e e d i n g s o f t h e C o n f e r e n c e on Sof t w ar e M ai nt enance  I C SM 1993 Mont r  eal  Quebec Ca n a d a  S e p t e m b e r 1 9 9 3 1 9 9 3  p p  2 9 2  3 0 1  3 J  L a w a n d G  R o t h e rm e l   W h o l e p ro g ra m p a t h b a s e d d y nami c i mpact anal ysi s   i n Pr o c e e d i n g s o f t h e 2 5 t h I n t e r n a tio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  M a y 3 1 0  2 0 0 3  Po r t l a n d  O r e g o n  U S A I E E E C o m p u t e r S o c i e t y  2 0 0 3  p p  308–318  G  C anfora and L  C erul o Impact anal ysi s by mi ni ng sof t w a r e and c hange r e quest r e posi t o r i es  i n 11t h I E E E In t e r n a t i o n a l S y m p o s i u m o n S o f t w a r e M e t r i c s M E T R IC S 2005  1922 Sept em ber 2005 C om o I t al y I E E E C o m p u t e r So c i e t y  2 0 0 5  p  2 9  5 A  T  T  Y i n g  G  C  M u rp h y  R  N g  a n d M  C  C h u C a rro l l  P r ed i ct i n g s o u r ce co d e ch an g es b y m i n i n g r e v i s i o n h i s t o r y   IE E E T r a n s a c t i o n s o n S o f t w a r e E n g i n e e r i n g v o l  3 0  p p  5 7 4  586 S e p 2004 6 T  Z i m m e rm a n n  P  W e i  g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  IEEE Tr a n s  S o f t w a r e E n g  v o l 3 1 n o  6 p p  4 2 9  4 4 5  2 0 0 5  7 M  C eccarelli L Ceru lo  G C an fo ra a n d M  Di P e n t a  An ecl ect i c approach for c hange i m pact anal ysi s   i n Pr o c e e d i n g s of t h e A C M  I E E E 32r d I nt ernat i onal C onf er ence on Sof t w ar e En g i n e e r i n g  I C S E 1 0 1 0  N e w I d e a s a n d Em e r g i n g Re s u l t s N IE R  T r a c k  2 8 M a y 2 0 1 0  C a p e T o w n  S o u t h A f r i c a t o appear A C M P r e s s  2 0 1 0  ht t p    w w w  r cost  uni sanni o i t  md i p e n t a  p a p e r s  n i e r 2 0 1 0  p d f  8 C  W  J  G ra n g e r   In v e s t i g a t i n g c a u s a l re l a t i o n s b y e c o n o met r i c model s and cr o ssspect r al m et hods  a  vo l  3 7  n o  3  p p  4 2 4  4 3 8  1 9 6 9   N  D  M ukhopadhyay a nd S  Chatterjee Causality and pat h w a y s earch i n mi croarray t i me s eri e s e xperi ment   s v o l 2 3 n o  4 p p  4 4 2  4 4 9  2 0 0 7  1 0  A  H i n d l e  M  W  G o d fre y  a n d R  C  H o l t   M i n i n g re c u rre n t act i v i t i es  F o u r i er an al y s i s o f ch an g e e v en t s   i n ernatio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  I C S E 2 0 0 9  M a y 1624 2009 V ancouver  C anada C om pani on V ol um e  pp 295–298 1 R Ag ra w a l T  Imie lin sk i a n d A  N  S w a mi  M i n i n g a s soci at i o n r ul es bet w een set s of i t ems i n l ar g e d at abases  in Pr o c e e d i n g s o f t h e 1 9 9 3 A C M S I G M O D I n t e r n a t i o n a l Co n f e r e n c e o n M a n a g e m e n t o f D a t a  W a s h i n g t o n  D  C  M a y 1993 A C M P r e s s  1 9 9 3  p p  2 0 7  2 1 6  2 J  D  H a m i l t o n  Ti m e S e r i e s A n a l y s i s P r i n c e t o n U n i v e r s i t y Pr e s s  J a n u a r y 1 9 9 4  3 J H Le e   Co m b i n i n g mu ltip le e v id e n c e fro m d if fe re n t propert i es o f w ei ght i n g s chemes  i n Pr o c e e d i n g s o f t h e 1 8 t h annual i n t e rnat i onal A C M S I G I R conf er ence on R e sear c h and de vel opm ent i n i nf orm a t i o n r et ri e v al N e w Y o r k  N Y  U S A  AC M  1 9 9 5  p p  1 8 0  1 8 8  4 D  S h e s k i n  Ha n d b o o k o f P a r a me t r i c a n d N o n p a r a me t r i c St at i s t i c al P r ocedur es  f ourt h edi t i on C h a p m a n  A l l  2007 5 R  A rn o l d a n d S  B o h n e r  Sof t w ar e C hang e I m pact A nal ysi s  Wi l e y I E E E C o m p u t e r S o c i e t y  1 9 9 6   M Kamkar   An o v ervi e w and comparat i v e cl assi  cat i o n o f pr ogr am sl i c i n g t echni ques  J S y s t  S o f t w  v o l 3 1 n o  3  1995 7 L  C  B ri a n d  Y  L a b i c h e  L  O S u l l i v a n  a n d M  M  S  ow ka A u t o m a t e d i m p a c t a n a l y s i s o f U M L m o d e l s   f Syst em s and Sof t w ar e v o l  7 9  n o 3  p p  3 3 9  3 5 2  2 0 0 6  1 8  A  C h e n  E  C h o u  J  W o n g  A  Y  Y a o  Q  Z h a n g  S  Z h a n g  and A  M i c hai l  C V S S ear ch S ear chi n g t hr ough sour ce code usi n g C V S comment s  i n ICSM 01 P r oceedi ngs of 17t h IE E E In t e r n a t i o n a l C o n f e r e n c e o n S o f t w a r e M a i n t e n a n c e  364  M L i ndv al l a nd K S a ndahl   P r act i cal i m pl i cat i ons of t r ace Sof t w ar e—P r act i c e and E x peri ence v o l  2 6 n o 1 0  pp 1161–1180 O c t  1996 0     H o w w e l l d o e x p e ri e n c e d s o ft w a re d e v e l o p e rs p re d i c t soft w a re change J S y s t  S o f t w  v o l 4 3  n o 1  p p  1 9  2 7  1998 1 S L Pﬂe e g e r  Sof t w ar e E ngi neeri ng T h eory and P r act i c e  Up p e r S a d d l e R i v e r  NJ  P r e n t i c e Ha l l  1 9 9 8   H Gal l  K Haj ek and M  J azayeri  Det ect i o n o f l ogi cal coupl i n g b ased on pr oduct r el ease h i s t o r y   i n Pr o c e e d i n g s o f th e I n te r n a tio n a l C o n fe r e n c e o n S o ftw a r e M a in te n a n c e  I C S M 98 1 9 9 8 p p  1 9 0  1 9 7   H Gal l  M Jazayeri  and J  K raj e wski   CVS r el ease h i s t o ry dat a f o r d et ect i n g l ogi cal coupl i ngs  i n 6t h I nt ernat i onal Wo r k s h o p o n P r i n c i p l e s o f S o f t w a r e E v o l u t i o n  I W P S E 2 0 0 3   12 S ept e m b er 2003 H e l s i n ki  F i n l and I E E E C o m p u t e r So c i e t y  2 0 0 3  p p  1 3  2 3  


                        






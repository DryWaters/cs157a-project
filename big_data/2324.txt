Mining Fuzzy Similar Association Rules from Quantitative Data Shyue-Liang Wang Chun-Yin Kuo Department of Information Management I-Shou University Kaohsiung Taiwan R 0 C E-mail: slwang@isu edu tw Abstract Data mining of association rules'fiom items in transaction databases has been studied extensively in recent years In order to discover more practical rules domain knowledge such as taxonomies of items 9 and similarity among items I have been considered 
to produce generalized association rules and similar association rules respectively Howevec these algorithms deal with only transactions with binary values whereas transactions with quantitative values are more commonly seen in real-world applications This paper thus proposes a new data-mining algorithm for extracting fizzy knowledge j?om transactions stored as quantitative values The proposed algorithm integrates fizzy set concepts and the apriori mining algorithm to find fiq similar association rules in given transaction data sets where similarity relations are assumed among 
database items The rules discovered here thus promote coarser granularity of association rules and exhibit quantitative regularity under similarity relations 1 Introduction Data mining also known as knowledge discovery in databases, means a process of nontrivial extraction of implicit previously unknown and potential useful information from databases SI It has been recognized as a new area for database research and received considerable interests in recent years The kinds of knowledge discovered in databases come in many forms including association rules classification rules clustering 
rules sequential patterns and prediction among others It is most commonly seen in applications to induce association rules from transaction data The problem of mining association rules was introduced in ll Let I={i i2  i,J be a set of literals called items Given a set of transactions D where each transaction Tis a set of items such that TcI 0-7803-7461-4/02/$17.00 0 2002 IEEE 190 Tzung-Pei Hong Department of Electrical Engineering National University of Kaohsiung 
Kaohsiung, Taiwan R 0 C E-mail tphong@nuk.edu tw an association rule is an expression XaY where Xc I YcI and XnY An example of such a rule is that 90 of customers buy hamburgers also buy Coke The 90 here is called the confidence of the rule which means that 90 of transaction that contains X also contains Y The support of the rule is the percentage of transactions that contain both X and Y 
The problem of mining association rules is to find all rules that satisfy a user-specified minimum support and minimum confidence However direct application of association rule algorithm on transaction data might produce oversized amount of unwanted rules, not to mention the excessive amount of computation effort wasted Hence characteristics of transaction data domain knowledge and the objective of application should be considered in the mining process For example domain knowledge such as taxonomies of items and similarity among items Ill has been considered to produce generalized association 
rules and similar association rules respectively Recently the fizzy set theory 14 has been used more and more tkequently in intelligent systems because of its simplicity and similarity to human reasoning 7 Several fuzzy learning algorithms for inducing rules from given sets of data have been designed and used to good effect with specific domains 2][4][6 Strategies based on decision trees were proposed in  Hong et al. also proposed a fuzzy mining algorithm for managing quantitative data 5 However domain knowledge 
of items was not considered in their approach In fact, items in real-world applications may possess some kinds of similarities Mining fuzzy similar association rules may thus lead to the discovery of more general and important knowledge from data In this paper we focus on designing a sophisticated data-mining algorithm capable of dealing with mining fuzzy similar association rules from quantitative data The proposed algorithm integrates fuzzy set concepts and the apriori mining algorithm to find fuzzy similar 


association rules by modifying the apriori mining algorithm I J K L M N The rest of our paper is organized on follows The concept of similar association rules is reviewed in section 2 The proposed fuzzy similar association rules and its mining algorithm are described in section 3 A simple example is given in section 4 Conclusion and proposal of fhture work are given in section 5 I J KLMN 1 0.4 0.7 0.6 0.4 0.8 0.4 1 0.4 0.4 0.7 0.4 0.7 0.4 1 0.4 0.4 0.4 0.6 0.4 0.4 1 0.4 0.4 0.4 0.7 0.4 0.4 1 0.4 0.8 0.4 0.4 0.4 0.4 1 2 Review of similar association rules A B C D E F A Similarity relation 1 0.4 0.4 0.8 0.4 0.4 0.4 1 0.4 0.4  0.4 0.4 0.4 0.4 1 0.4 0.6 0.8 0.8 0.4 0.4 1 0.4 0.4 0.4 0.4 0.6 0.4 1 0.6 0.4 0.4 0.8 0.4 0.6 1 The concept of a similarity relation is essentially a generalization of the concept of an equivalence relation 13 It is usefhl for describing how similar two elements from the same domain are as the name implies For a given domain Z a similarity relation S is a mapping of every pair of elements in the domain onto the unit interval 0 11 More specifically Definition 1 A similarity relation S in domain Z is a binary relation in Z such that for any a b c E Z 1 S a a  1 2 S a b  S b a 3 S a c 2 max min S a b S\(b,c for all b E Z Examde 1 Assuming that a similarity relation S on the domain A is shown in Figure 1 The domain of A consists of six elements A B C D E F The grade of membership ps A D is 0.8 meaning that the similarity between the domain elements A and D is the degree of 0.8 A B C D E F B Similar association rules 3 The fuzzy similar association rule algorithm This section describes the proposed data mining algorithm based on the apriori algorithm l to discover fuzzy similar association rules fiom quantitative data A fuzzy similar association rule is an implication of the form X=F  Y=F2 where X L Z E Z and X I Z are subsets of different equivalence classes induced by a similarity level value a And FI F2 F3 are fuzzy sets representing linguistic terms The rule 191 


X=Fl Y=Fz holds in the transaction set D with confidence C if C of transaction in D that supports X=FJ\(Y=Fz also supports Z=F3 The rule X=F1 Y=Fz has support S if S of transaction in D SUPPOIQ X4'1 U\(Y=Fz U\(Z=Fj The problem of mining fuzzy similar association rules can be stated as follows Given a set of transactions D and a set of similarity relations on the transaction items the problem of mining fuzzy similar association rules is to find all fuzzy similar association rules that have support confidence and similarity greater than user-specified minimum support called min-sup minimum confidence called min-conj and minimum similarity \(called min-a Notation I il i2...iJ a set of literals representing items D TI Tz  TJ a set of quantitative transactions I  the j-th transaction I j s n SA  a similarity relation defined on a set of items n  partition of SA with respect to a similarity level aA AI  equivalence class in n that contains item h  the number of fuzzy regions for equivalence class A  ip  id ik 200A={ip  id 4  the I-th fuzzy region of AI va  the quantitative value of AI in lj Fi  the fiuzy set converted from v Ilk fJt   the membership value of Ti in region count  the summation of f j=1 to n max count  the maximum count value among countl  1=1 to hl max RI  the tiuzy region of AI with max  countl C  the set of candidate EC equivalence class sets with r L  the set of large EC sets with r equivalence classes equivalence classes The proposed mining algorithm first determines the partitions and equivalence classes for each similarity relation according to the user-specified minimum similarity level value min-a It then uses membership functions to transform each quantitative value into a fuzzy set in linguistic terms The algorithm then calculates the scalar cardinalities of all linguistic terms in the transaction data In turns the algorithm calculates the largest k-EC sets that have supports greater than min-sup It then generates fuzzy similar association rules from the largest k-EC sets that have confidence greater than min-con Detailvof the proposed mining algorithm are described below The fuzzy similar association rule algorih INPUT A set of transactions D={Tl T  TJ a set of similarity relations SA S  on item sets A B  etc a set of membership functions min-a min-sup min-con OUTPUT A set of fuzzy similar association rules STEP 1  For each given similarity relation SA calculate the partitionn and its equivalence classes A ikd where UA is the least a value in SA greater than or equal to min-a STEP 2 For each transaction lj group the items belonging to the same equivalence class into a set The amount for each set v  is the sum of item amounts in the set STEP3 Transform the quantitative value v of each transaction I into a fuzzy set F represented given membership functions STEP 4 Count the scalar cardinality of each fuzzy region n in each transaction count  f j=1 STEP 5 Find the maximum cardinality rnax countl  MAX\(countl  Let rnax count be the region with max count for item A  which will be used to represent the fuzzy characteristic of equivalence class AI in later mining processes I=1 STEP 6 Check whether the value max count of a region max  RI is larger than or equal to the predefined min-sup If the count of a region max RI is equal to or greater than min-sup put it in the large 1-EC LI STEP 7 Set 1 where r is the number of equivalence class sets kept in the current equivalence class sets It first joins L and L assuming that r-I EC's in the two STEP 8 Generate the candidate set Cr+I fiom L 192 


EC sets are the same and the other one is Merent It then keeps in Cr the EC sets which have all their sub-EC sets of r sets existing in L STEP 9 To each newly formed candidate r+l itemset s with items s sz  s,+J a Calculate the fuzzy value of s in each transaction T as fj  f/s A fjS2 A  A fjs 3 where fjsl is the membership value of T in region s If the minimum operator is used for the intersection then fjs  Min fjSl  r j=l b Count the scalar cardinality of s in the transaction as follow three units of A four units of B and seven units of K In addition we assume that there are two similarity relations defined on two sets of items One set of items contains A B  F and its similarity relation is given in Figure 1 The other set of items contains I J  N and its similarity relation is given in Figure 2 Also the fuzzy membership functions are assumed to be the same for all the items and are shown in Figure 3 In this example amounts are transformed into three fuzzy regions Low Middle and High Thus each item amount generates three fuzzy membership values according to the predefined membership functions The min-sup is set as 2 the min-conf is set as 0.7 and the min-a is set as 0.8 TABLE 1. A simple quantitative transaction database count  Cfjs i=l c If count is larger than or equal to the predefined min-sup puts in L STEP 10 IfL is null then do the next step; otherwise set e1 and go to STEP8 STEP 1 1  Establish the fuzzy similar association rules for all large q-itemset s containing items SI SZ  sq q 2 2 as follows a Construct all possible fuzzy similar s,A  As,_,As,+,A  As  s  w=l to q association rules b Calculate the confidence values of all fuzzy similar association rules using the formula 2 fjs j=l j=l STEP 12 Output the rules with confidence values larger than or equal to the predefined min-con After STEP 12 the rules discovered can act as the meta-knowledge for the given transactions 4 An example Itl this section we describe an example to demonstrate the proposed fuzzy similar association rule algorithm This is a simple example to show how the proposed algorithm can be used to discover fuzzy similar association rules fiom the quantitative transaction database shown in the Table 1 The data set includes 5 transactions Each transaction in table1 has a transaction ID and a set of items with quantities represented as item name item amount For example the first transaction contains Exarm.de 3 Given the quantitative transaction database in Tablel the similarity relations in figure1 and figure2 the fuzzy membership functions in figure3 and the min-a 0.8 min-sup=2 min-conf  0.7 the proposed fuzzy similar association rule algorithm finds the following two rules 1 CuF=Low a K=Middle with confidence 0.91 2 K=Middle a CuF=Low with confidence0.91 They can be interpreted as 1 IF a customer purchases low quantity of product C or F then he will purchase a middle quantity of product K with a confidence factor of 0.91 2 IF a customer purchases middle quantity of product K then he will purchase a low quantity of product C or F with a confidence factor of 0.91 These two rules can be regarded as meta-knowledge about the given transaction database 5 Conslusion In this work we will introduce a new type of association rule, called fuzzy similar association rule and present a fuzzy data mining algorithm to discover this type of rules fiom transaction databases with quantitative values The proposed rule is a kind of fuzzy rule in the sense that  1 similarity relations are permitted on transaction items and 2 quantitative values are represented as linguistic terms fuzzy sets Specifjmg similarities among items allows more flexible representation of association rules 193 


Fuzzy set representation of quantitative values provides coarser granularity of association rule therefore forming fewer numbers of rules The rules thus miningout exhibit quantitative regularity under similarity relations and can be used to provide suggestions under appropriate supervisions Although the proposed method works well in data mining for quantitative values it is just a beginning More work needs to be done on this topic Our method assumes the similarity relations and membership functions are known in advance In 6][10 we proposed some learning methods to automatically derive similarity relations and membership functions We will therefore attempt to dynamically adjust these relations and functions in the proposed fuzzy data-mining algorithm to avoid the bottle neck of knowledge acquisition Membership value Item amount Figure 3 The membership functions used in this example 6 Reference R Agrawal T Imielinksi and A Swami 223Mining association rules between sets of items in large database\224 Proc of the ACM SIGMOD Conference on Management of Data 1993,207-216 L M.de Campos and S Moral, \223Learning rules for a fuzzy inference model\224 Fuzzy Sets and Systems, vol P Clark and T Niblett 223The CN2 induction algorithm\224 Machine Learning vol 3 1989 A.Gonzalez 223A learning methodology in uncertain and imprecise environments\224 Intemational Journal of intelligent Systems vol 10 1995,57-371 T P Hong C.S Kuo and S.C Chi 223Mining association rules from quantitative data\224 Intelligent Data Analysis vol 3 1999,363-376 T P Hong and J B Chen 224Processing individual fuzzy attributes for fuzzy rule induction\224 Fuzzy Sets and Systems vol 112 No.l,2000 127-140 A Kandel, Fuzzy Expert Systmes, CRC Press, Boca G Piategsky-Shapiro 223Discovery analysis and presentation of strong rules\224 Knowledge Discovery in Databases WIT mess 1991,229-248 59,1993,247-257 261-283 Raton 1992,8-19 Association Rules\224 Proc of the VLDB conference Zurich, Switzerland, September 1995 S.L Wang J.S Tsai T.P Hong 223Discovering Functional Dependencies from Similarity-based Fuzzy Relational Databases\224 International Journal of Intelligent Data Analysis Vol 5 No.2 2001 S.L Wang C.Y Kuo T.P Hong 223Mining Similar Association Rules from Transaction Databases\224 proceedings of the 5\224 Intemational Conference on Knowledge-based Intelligent Information Engineering Systems September 2001, Osaka, Japan 486-489 C H Wang J F Liu T P Hong and S S Tseng 223A fuzzy inductive learning strategy for modular rules\224 Fuzzy Sets and Systems vol 103 No 1 1999 L.A Zadeh 223Similarity relations and fuzzy orderings\224 Inform Sci., vol 3 no.1 1971, 177-200 L.A Zadeh 223Fuzzy sets\224 Information and Control vol 8 no.3 1965,338-353 131-149 91-105 I 9 R Srikant R Agrawal 223Mining Generalized 194 


Proceedmgs of the First International Conference on Machme Learning and Cybernetics Beijing 4-5 November 2002 161 171 81 191 Guozhu Dong, Jiawei Han, Joyee Lam Jean Pei and Ke Wang Mining Multi-Dimensional Constrained Gradients in Data Cubes VLDB 2001 R.Ng L.V.S.Lakshmanan J.Han and A.Pang Exploratory mining and pruning optimizations of constraned association rules. ACM SIGMOD 1998 R.Agrawal T.Imielinski and ASwami Fast algorithms for mining association ruels. VLDB 1994 Jiawei Han, Jianyong Wang Guozhu Dong, Jian Pei Ke Wang CubeExplorer online exploration of data cube ACM SIGMOD 2002 1033 


4.1 Simulation model In the section we evaluate the performances of the three algorithms including BASIC 1121 Cumulate 12 and GMAR on a DELL PowerEdge 4400 Server with Intel" Xeon Processor and 756MB main memory running Windows 2000 server All the experimental data are generated randomly and stored on a local 30GB SCSI Disk Ultra 160 with a RAID controller The relative simulation parameters are shown in Table 1 To make our data representative, we generate two types of databases in the experiments i.e DENSE databases and SPARSE databases. Each item in the DENSE database is randomly generated from a pool P called potentially frequent itemsets with size 300 while each item in the SPARSE database is randomly generated from a pool N i.e the set of all the items\with size 1000 Since the items in the DENSE database are more clustered than those in the SPARSE database, larger frequent itemsets will probably be produced in the DENSE database for the same minimum support Besides we use the notations T for average number of items per transaction I for average number of items in a frequent itemset, and D for number of transactions. For example the experiment labeled with 7lOB.DIK represents the simulation environment with IO items on the average per transaction 3 items on the average in a frequent itemset, and 1000 transactions in total Table 1 Simulation parameters with default values ID INumber of transactions 1000-500,000 7 INumber ofthe items per transaction 15-15 P INumber of potentially frequent 1300  litemsets I I Number of the items in a frequent 12-5 4.2 Experimental results Experiment 1 In the experiment we explore the execution time of BASIC Cumulate and GMAR algorithms for the environment 7lO.L3,DIK under different minimum support and minimum confidence pairs as shown in Figure 9 In the figure, we find that our algorithm GMAR is almost faster 2-16 times than BASIC especially for larger minimum support and minimum confidence pairs whereas Cumulate is only faster 1.3-1.5 times than BASIC although R Srikant and R Agrawal claimed that Cumulate runs faster 2-5 times than BASIC 1121 In general the larger the minimum support and minimum confidence pair is the faster the execution time of the three algorithms becomes To be fair to all algorithms, we have added the extra time of generating original frequent itemsets and association rules for GMAR However the time is helow 1 of total execution time thus we do not show it in the figure h n  B a 3 i.m.26 i.ma 1.~1.3 i.mm 1.740.3 I.w Figure 9 Execution time for different pairs minimum support  Confidence Experiment 2 In the experiment we extend Experiment 1 by fixing the minimum support IS and observe their variations For the minimum support 1.5 all the algorithms except GMAR are not sensitive to the changes of the minimum confidences as shown in Figure IO The reason is that larger minimum confidences will make GMAR prune more irrelevant rules. Nevertheless, GMAR is still in the first rank D  2 4M cm 22 CUlIIUlStt  gm BASIC 8 Irn 0 0 0.26 0.28 0.3 0.32 0.34 0.3 minimum confidence Figure 10 Execution time for different minimum confidences Experiment 3 In the experiment, we explore the execution time of the three algorithms for the environment ZlO.I3.DxK i.e different numbers of transactions generated in the SPARSE database and in the DENSE database as shown in Figure Il.\(a and b respectively. Both cases have the same minimum confidence 0.3 However to get comparable number of frequent itemsets, we set a smaller minimum support 1 in the SPARSE case and a larger 233 


minimum support 2 in the DENSE case As expected GMAR is still the hest one among them in the SPARSE and DENSE case especially when there are a huge amount of transactions From the both cases we find that much more frequent itemsets are generated in the DENSE database than in SPARSE database so that BASIC and Cumulate are not practicable candidates there B Ixa 8 Imo 222ixa 80 0 Imo 3033 m m loo30 number of transactions Figure 11 a Execution time for different numbers of transactions in the SPARSE database cumh?t  6 loo30  rma 2230 lorn m 5m 7cw IwD3 number of transactions Figure 1 l.\(b Execution time for different numbers of transactions in the DENSE database 5 Conclusions In the paper we try to find the association rules between the items at different levels in the taxonomy tree under the assumption that original frequent itemsets and association rules have already been generated beforehand The primary challenge is how to make use of the original frequent itemsets and association rules to directly generate new generalized association rules rather than rescanning the database In the proposed algorithm GMAR we use join methods and pruning techniques to generate new generalized association rules Through several comprehensive experiments we find that the GMAR algorithm is much better than BASIC and Cumulate algorithms since it generates fewer candidate itemsets and furthermore prunes a large amount of irrelevant rules based on the minimum confidence 6 Acknowledgments This research was supported in part by the National Science Council Taiwan under contract NSC-90-22 13-E-224-026 7 References I R Agrawal T Imielinski and A Swami 223Mining Association Rules between Sets of Items in Large Databases,\224 Pmc ACM International Conference on Mananement of Data  1993 pp 207-216 121 R Anrawal and R Srikant 223Fast Alaorithms for Mmine Adsociation Rules,\224 Pmc 2Vh Internationaiconference on Ve Large Data Bases 1994 pp 487-499 131 Yong-Jian Fu 223Data Mining,\224 IEEE Potentials Yol 16 No 4 1997 pp 18-20 141 Jia-Wei Han and Yong-Jian Fu 223Mining Multiplelevel Association Rules in Large Databases,\224 IEEE Transactions on Knowledge and Data Engineering Yo 11 No 5 1999 pp 798-805 5 Iia-Wei Han and Micheline Kamber Data Mining Concepts and Techniques Morgan Kaufmann Publishers 2001 6 Iia-Wei Han lian Pei and Yi-Wen Yin 223Mining Frequent Patterns without Candidate Generation,\224 Pmc ACM International Conference on Management o Data 2000 pp 1-12 7 Mon-Fong Jim Shian-Shyong Tseng and Shan-Yi Lia 223Data Types Generalization for Data Mining Algorithms,\224 Pmc IEEE International Conference on stems Man and Cybernetics 1999 pp 928-933 8 Bing Liu Wynne Hsu and Yi-Ming Ma 223Minin Association Rules with Multiple Minimum Supports,\224 Pmc 5 ACM International Conference on Knowledne Discovery and B DataMining 1999 pp 337-341 191 J S Park M S Cben and P S Yu 223An Effective  H&h-based Algorithm for Mining Association Rules,\224 Pmc ACM Internotional Conjerence on Mamgement o Data 1995 pp 175-186 IO A Savasere E Omiecinski, and S Navathe 223An Efficient Algorithm for Mining Association Rules in Large Databases,\224 P 21\224 lnternationk Conference on Very La Data Bases 1995 pp 432-443 Ill Pradeep Shenoy layant Haritsa S Sudarshan Gaurav Bhalotia, Mayank Bawa and Devavrat Shah 223Turbo-charging Vertical Mining of Large Databases,\224 Pmc ACM International Conference on Management of Data 2000 pp 22-33 I21 R Srikant and R Agrawal 223Mining Generalized Association Rules,\224 Pme 21\224 International Conference on Very Large DataBases 1995 pp 407-419 I31 S Y Sung K Wag and L. Chua 223Data Mining in a Large Database Environment,\224 Pmc IEEE International Conference on Systems Man and Cybernetics 1996 pp 988-993 I41 H Toivonen 223Sampling Large Databases for Association Rules,\224 Pmc 2T\221 International Conference on Very Large Data Bases 1996 pp 134-145 I51 Ming-Cheng Tseng Wen-Yang Lin and Been-Chian Chien 223Maintenance of Generalized  Association Rules with Multiple Minimum Supports,\224 Pmc 9th IFSA World Congress and 20th NAFIPSInternational Conference 2001 pp 1294-1299 234 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



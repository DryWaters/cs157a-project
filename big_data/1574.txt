Cabinet: Managing Data Efficiently in the Global Federated \nFile System \nAvinash Kalyanaraman, Andrew Grimshaw nDepartment of Computer Science \nUniversity of Virginia \nCharlottesville, VA 22904 \n{ak3ka grimshaw}@virginia.edu \n \nAbstract—With ever expanding datasets, efficient data \nmanagement in grids becomes important. This paper describes \nCabinet which employs two techniques for efficiently managing \ndata in gridsa caching system and a new file staging approach \ncalled coordinated staging. The caching system is designed based \non the characteristics of grid applications. Coordinated staging is \nbased on the BitTorrent Protocol model and is specifically \ndesigned for High Throughput Computing \(HTC grids. In coordinated staging, each site that \nis assigned to execute an individual job of the HTC application ntreats other execution sites as potential replica-stores. In our \nevaluation, we show that coordinated staging lowered the \ndownload time of a file by 3.85x, and increased the throughput of \nthe download by 2.86x over the conventional approach of file \ntransfer from a single source. \nKeywords—grids; file staging; big data; distributed file systems \nI. INTRODUCTION \nScientific collaborations and the increasing computational nneeds of applications have warranted the development of grids \n[1]. The ability of grids to provide a larger resource pool than \nwhat is available at a single site has helped solve problems \npreviously believed to be intractable. On the other hand, the \ndata-size used by applications has been increasing. Seidel [2] \nclaims that the data generated each year is greater than the sum \nof the generated-data over all previous years Thus, managing \nsuch large amounts of data in computational grids becomes \nimportant. Researchers are interested in both analyzing this \ndata and harnessing the vast computational resources available \nvia the grid. The consequence is a situation where the data and \ncomputation are not collocated, warranting the need for \nefficient data management techniques. \nAt the same time, storage is becoming cheaper and the \namount of storage available for researchers at their campuses \nand supercomputing sites has been increasing. This storage \nspace can be used to cache and replicate input files. Caching \nand replication are two traditional techniques for efficient data \nmanagement in distributed systems. This work, Cabinet deals \nwith caching in the context of a computational grid. \nCommonly scientists' datasets are located at their \ninstitutions. Two techniques [3] exist for moving data to the \ncompute site \(referred henceforth as simply site ninput files [4] and on-demand input file access [3, 5, 6]. Pre-\nstaging moves all the input files required by a job to the site \nbefore the job starts running. Typically users have allocations \nindicating the amount of wall-clock time they can use at a site. \nIn this approach, no allocations are consumed during stage-in nOn-demand access recreates the “home filesystem” of the user \nat the site by forwarding read requests to the institutions. \nHowever, this method suffers a serious limitation. The \nexecution time of the application increases as it blocks during \nreads waiting for data to be fetched from "home". As users are \noften charged allocations from the time their job starts \nexecuting, this method consumes more allocations than pre-\nstaging. Since allocations are valuable entities obtained via a \nstrict peer-review process, it becomes natural for users to prefer \npre-staging. Consequently, Cabinet deals with the pre-staging \napproach and employs a new technique called coordinated \nstaging which makes pre-staging faster. \nThe work has been done in the context of the Global \nFederated File System \(GFFS  grids. GFFS provides an ability for \ncampuses, supercomputing centers, industrial centers etc to \noperate under a single, global path-based namespace without \nrequiring the data owners and application developers to change \nthe way they store and operate on the data. \nIn grids, the term resource denotes an implementation of a \nparticular service. Since the GFFS is a standards-based \nfilesystem, each resource can be understood as an nimplementation of a standard. For example, every file is a \nresource implementing the ByteIO standard [8] and every \ndirectory is a resource of the Resource Namespace Service [9] \nspecification. Being a wide-area distributed filesystem, the \nGFFS suffers from the limitations of the network. The first part \nof this work coordinated staging treats the GFFS from a \ncomputational grid's perspective. The second part of this work ncaching treats the GFFS from both a computational grid and \ndata grid's perspective. \nThe rest of this paper is organized as follows: Section II \nmotivates the problem, Section III describes a new file staging ntechnique called coordinated staging, Section IV describes the \ncaching system and its working, Section V presents the \nimplementation, Section VI shows the evaluation, Section VII \ndiscusses the related work and Section VIII summarizes the \nwork. \nII. MOTIVATION \nIn this section, we describe the need for caching and fast nfile staging. For the rest of this section, the following notations \nwill be used. Let J be a job submitted by user U. Let F = {F1, \nF2, ... , Fn} be the set of input files required by J, such that F  \nØ. Let J denote a reuse job. A reuse job is defined to be a job \nthat is submitted after J finishes execution. Let F be the set of \n2013 IEEE 9th International Conference on e-Science\n978-0-7695-5083-1/13 $25.00 © 2013 IEEE\nDOI 10.1109/eScience.2013.36\n124\ninput files required by J’, and F ? F’  Ø. Let U’ denote any \nuser except U. J 


can be understood to belong to U or U’, \nunless stated explicitly. \nA. The Need for Caching \nCaching is important in computational grids for two \nreasons: input files tend to be shared by jobs, and input files ntend to be reused across jobs. \n1 multiple individual tasks, uses a common input \nfile\(s ncomputing \(HTC  refer to a \nclass of applications which involves users running multiple \ncopies of their programs simultaneously with no \ncommunication between the individual tasks. In such cases, \nwe would not want each individual task to stage-in the same \ninput file. A single stage-in into the site must occur. An \nexample where the same input files get used repeatedly is \nparameter sweep applications. For e.g., Garzon [11] showed nthe effectiveness of caching for a protein docking application. \n2 reasons. In some \ncases, users learn input parameters from an initial set of runs. \nAlternatively, a user may modify his algorithm based on the \ninitial results. The subsequent “modified” program will use \nthe same set of input files and libraries. In other words, trial-\nand-error which is inevitable in scientific research results in \nreuse. At times, generating input files could be expensive, \nleading to unavoidable reuse. Reuse can also occur due to jobs \nfailing because of programming errors, scripting errors or \nexecution node failure. While these are use-cases of input file \nreuse from an individual user or his research group’s nperspective, some input files like public databases may be \ncommon across several research groups, creating a greater \npotential for reuse. \nStorage is cheap enough to not hinder the caching and \nreplication of input files that are shared and reused, instead of \ncopying them across the network many times. \nB. The Need for Fast File Staging \nDespite caching, it is still necessary for files to be staged-in \nquickly \(the first time so that jobs can begin execution. \nStaging may be necessary even during reuse. There are many \nreasons why the reuse-job J’ need not execute on the cached \nsite\(s sites of the initial run J by user U metascheduling algorithms need not always \nbe data-aware. For instance, they may take queuing delay and \nthe number of available processors into consideration. For \nexample, GridWay [14] schedules jobs onto resources using a \nuser-specified ranking model. Secondly, scheduling constraints \nmay prevent J’ from executing on the cached sites. For \nexample, the memory or processor requirements of J’ may not \nbe satisfiable by the cached site. Finally, J’ may belong to a \ndifferent user U’, who may not have allocations or permissions \nto run on the cached site\(s fast staging is needed so that jobs \ncan begin execution quickly. Moreover, we will also need a \nfast staging mechanism for those files which exist as a single \ncopy \(i.e those files which have not been cached or replicated nIn this paper, we present coordinated staging, a new \ntechnique for fast staging, specifically designed for HTC \napplications. In coordinated staging, each site assigned to \nexecute a sub-job of the HTC application treats the other sites \nas potential replica-stores. \nTo understand coordinated staging, let us first take a look at \na typical HTC job-submission in grids. The user submits an \nHTC application-description file to a metascheduler [15]. The \nmetascheduler parses this file and extracts the description of \neach individual task of the HTC job. \nThis description includes among other things, the list of \nfiles required to be staged into the site for successful execution \nof that \(individual individual to a site based on a scheduling algorithm. \nTypically, these jobs run at multiple sites primarily because nthere is a limit on the number of jobs a user can have in the \nlocal queuing system of a site at any given instant of time. In \nother words, even though the execution-service running at the \nsite may interface to a queuing system, the service cannot qsub \nan unbounded number of jobs on behalf of a user. For example, \nthe maximum number of jobs that may be queued by a user on \nTACC-Ranger is 50. \nAs Cabinet's data-management strategies are employed in \nthe context of the GFFS, coordinated staging is designed for \nthe common case of the input file stage URI being a GFFS \npath. The common way of staging files which are not cached or nreplicated is for each site to download them from the lone \ncopy. This lone copy which is explicitly created by the user \(as \nopposed to an implicit creation by caching or replication approach has a big disadvantage: \nall sites fetch only from the primary making it a potential \nbottleneck and this primary may not be “close” to the \ndownloading sites. The terms “close” and “far” refer to \nnetwork proximity and bandwidth. \nHowever, it may be possible that the sinks \(sites the source\(s   nbandwidth links. In such cases, we would want sites to \ndownload as much content as possible from one another, as \nthey are all downloading the same content. Coordinated \nstaging achieves this by making each site that downloads a file \nf treat other sites as potential replica-stores for f.  \nTo describe how each site 


treats other sites as potential \nreplica-stores, we use the following notation. Let J = {J1, J2, \n…, Jn} be an HTC application, where Ji  \(1in set of \nsites available to the metascheduler to schedule jobs on. The \nmetascheduler schedules each job Ji onto some site Sj \(1js execution. While scheduling Ji onto Sj, the \nmetascheduler also informs Sj about the set of sites who will nstage-in each file f, where f  Fi. The metascheduler ensures \nthat each site which stages-in f sees this same set of sites in the \nsame order. As we shall soon see, this order is critical to the \nworking of coordinated staging. \n125\nLet Sf  = { S1, S2, ... , Sk} be the set of sites that will be \ndownloading f. The goal of coordinated staging is to maximize \nthe traffic on faster peer links \(links providing faster download nrates each site s  Sf \nqueries f and obtains its size sz. This sz amount of contents is \nimplicitly partitioned among the Sf sites onto Sf disjoint chunks \nbased on the order provided by the metascheduler. For example \nif sz = 400GB and |Sf| = 4, then a vector of the form <\(S1, f, 0, \n100GB S2, f, 100GB, 100GB S3, f, 200GB 100GB S4, f, \n300GB, 100GB site, file, offset, size file starting at offset. This chunk, which each site is said \nto be "responsible for", is referred to as the primary chunk \(PC s algorithm, explained in Section \nIII-B. The site responsible for the PC is called its master. All \nnon-PCs of a master are referred to as secondary chunks \(SCs does \nnot matter, as long as they are arranged correctly at the sink. \nThe number of chunks for a file f equals the number of sites \ndownloading f. Having obtained the PC, each site has to \ndownload the remaining Sf|-1 SCs. Each site picks one SC at a \ntime and downloads it completely before moving to the next \none. As we are dealing with big datasets, and the duration of a \nchunk's download is non-trivial, each site following the same \norder of SCs could result in all of them attempting to read from \nthat chunk's master simultaneously nincarnation of the First Mile Problem. Since the order of the \ndownload of chunks do not matter, each site shuffles the order \nof the SCs by randomly picking a SC and downloading it to \ncompletion. Each SC is downloaded like the PC using the same \ndownload algorithm but by also including that SC's master as a npotential replica \(to explore previous \nchunk's download associated with f. We refer to this approach \nas unoptimistic coordinated staging unopt-CS no peers. \nA. Optimistic coordinated staging \nWe have also created an extension to unopt-CS called \noptimistic coordinated staging \(opt-CS site’s \npeer who can provide a better download rate than the chunk's \nmaster or primary, or replicas to have already downloaded that \nchunk of interest. Consequently, opt-CS extends unopt-CS \nwherein each SC is downloaded using the download algorithm \nby \(optimistically nmetascheduler as potential replicas.  An attempt to read from a \npotential replica that has not yet downloaded the required \ncontent will result in a fault being returned. Such a site will no \nlonger be considered as a potential replica for the download of \nthat chunk \(not the file nThe goal of our download algorithm is to reduce the time \ntaken by a sink to download a chunk that has been replicated. \nAn advantage of this algorithm is that it does not use any \nexplicit services for network monitoring or forecasting. Before \nexplaining the algorithm’s working, we first introduce the \nphases and the sub-phases of the algorithm: Explore \nPhase\(EP DP UP ISP and Heed Sub-Phase\(HSP ISP first step of EP and UP \n\(explained below replica without noting its perceived \nbandwidth. The goal here is to warm-up the disk or filesystem \ncaches at the source, so that comparisons can be made by \nreads in EP and UP with warmed-up reads of DP. \nHeed Sub-Phase HSP notes its perceived bandwidth. The connection and caches \nare warmed-up before this sub-phase is invoked nExplore Phase \(EP its perceived \nbandwidth. This phase starts with the ISP for warm-up \npurposes. ISP is followed by HSP, where the actual \nknowledge on perceived bandwidth is acquired. \nDownload Phase \(DP downloads \nfrom a replica identified to be the fastest via exploration or \nunchoke. This fastest replica is called the chief replica. This \nphase has two sub-parts. During the larger first sub-part, Dd \namount of data 


is downloaded from the chief replica without \nnoting the perceived bandwidth. It is different from the ISP in nthe following ways. While the goal of ISP is to warm-up, this \nsub-part is a consequence of that replica being the fastest. \nSecondly, Dd is much larger than Di of ISP. The second sub-\npart is HSP. The bandwidth perceived in HSP is used in UP. \nUnchoke Phase \(UP time-variant, each sink periodically selects a replica, \nand checks if it offers better bandwidth than the chief replica. \nThis phase starts with the ISP to warm-up the chosen replica. \nThe ISP is followed by the HSP where the bandwidth offered \nby this chosen replica is noted. If this bandwidth is greater \nthan the chief replica's bandwidth noted during its DP, then \nthe unchoked replica becomes the new chief replica. \n2 Methodology \n The inputs to the algorithm are: the starting byte offset to \ndownload, the last byte offset to read, an exploration set \n\(represented by En invoking application has no knowledge about the perceived \nbandwidth, and an explored set \(represented by Ed nthe set of sources about whom the \(invoking algorithm begins by first running EP on each replica \nof En. The replica offering the best bandwidth among those in \nEd and En becomes the chief replica. The remaining replicas \nare said to be choked. Next, the DP is run on the chief replica. \nAfter the DP is complete, the replica at the head of the choked \nlist is removed This replica is called the unchoked replica. UP \n126\nis run on this unchoked replica to see if it offers better \nbandwidth than the chief replica. If it does not, the DP is once \nagain run on the chief replica. If it does, then the chief replica \nis appended to the choked list, and the DP is run on this new \nchief replica This sequence of DP-UP-DP continues until the \nentire chunk is downloaded. \nC. Improving Single File-Transfer Speed via Parallel-TCP \nTo improve the download speed from a single replica, we \nemploy the proven technique of parallel TCP [18] in which \nmultiple TCP streams are used to download from the source to \nmitigate the underlying slowness of TCP.  On the other hand, \na common way for users to access files on the GFFS is via nFUSE [19]. Consequently, we also modified the GFFS-aware \nFUSE-driver to use parallel-TCP. \nIV. THE CACHING SYSTEM \n In this section, we explain the working of the caching \nsystem. Before looking at the working, we shall explain how \nthe execution-site is organized to perform caching. \nA. Compute-site Architecture \n A private working-directory is associated with each \nindividual job. This directory is wiped out when the job ncompletes. In existing implementations, the input files required \nby the job are staged into this directory Besides the working-\ndirectory, there is a cache directory which stores the cached \ninput files. This architecture is similar to the one used in the \nARC grid middleware [20]. We next explain how re-stage-in is nprevented during sharing and reuse. \nB. Sharing \nFor this prototype implementation, we assume that input nfiles are not modified by jobs during execution. This \nassumption is made because currently there is no standard way \n[15] of denoting such read-only input files. In order to detect \nsharing, the sites require a way to identify individual jobs of \nan HTC application. Consequently, the metascheduler \ngenerates a unique identifier for every HTC application. All \nindividual jobs of a given HTC application have the same nidentifier. If multiple individual jobs are scheduled onto the \nsame site, only one of the jobs will stage-in the shared input \nfile to its working directory. The remaining jobs will create \nhard-links to this location Creating links within the working \ndirectory of jobs of a single HTC application ensures that if \nany user incorrectly specifies his file to be read-only, then \nonly his jobs get affected. If a job requires a certain file f, but \nother jobs of the same HTC application \(at that site a link cannot be created. The \nstaging is then treated like a reuse \(explained below cache-miss. \nC. Reuse \nOne of the goals of the caching sub-system is to prevent \n"big" input files from being staged-in during reuse. In order to \nachieve this, whenever a site stages in an input file, it caches \nthat file. Only files with sizes greater than a certain caching \nthreshold are cached. Small files are not cached for two \nreasons - owing to their small size they can be quickly re-\nstaged during reuse. Moreover, even if individual jobs of an \nHTC application require the same file, a re-stage-in can be \nprevented \(as explained in Section IV-B cached files globally visible. This results in \nboth availability and performance benefits. \nAt the same time the bigger input files generally tend to \nbe read-only. This is because scientific datasets \(representative nof the "big" input files  sensors, telescopes etc, \nreleased to the public, and then become effectively immutable. \nTypically, a write corresponds to a completely new version of \nthe dataset being created. As a result, this globally visible ncached file is treated as a read-only replica \(R-only replica subject to access control version of the file being created, we do \nnot propagate changes on the primary or any non read-only \ncopy 


referred henceforth as read-write replica or RW-replica guarantee that \nthe new version will be used before being evicted, b files might get evicted, \nwhich could result in unnecessary restaging \(during reuse destroying the cached-copy on an update \nnotification results in simpler cache management. \nConsequently, the RW-replica notifies the R-only replicas of \nan update. The cached-copy destroys itself, when it receives \nthis invalidation message. The details of the working are \nexplained in Section IV-E. It is to be noted that the terms \ncached file and R-only replica mean the same. \nD. Write vs Update \nWe first define the terms write and update with respect to \na replica. A write on a read-write replica R means a user \nperformed an explicit write on that replica. An update on a \nread-write replica R means a user performed a write on some \nreplica R' \(R R and global visibility of cached files. \nE. Methodology \nOnce a decision has been made to cache an input file the \nsite first creates an empty cached-copy in the cache-directory. \nSince the cached copy will be globally visible, it is important \nto ensure that, if a replica is inaccessible to some user U, then \nthe cached copy should also be inaccessible to U. \nConsequently, the \(empty to notify it on any access control change, and \nthen sets its access control to that of the RW-replica. Next the \ncached copy subscribes to all RW-replicas of the file for both \nwrites and updates. It is necessary to subscribe to both writes \nand updates because the consistency model employed in \nGFFS is eventual consistency 22]. In our notification scheme, \nthe publisher stores the notification message in persistent \nstorage until it has been acknowledged \(by the subscriber nglobally visible for reads, and asynchronously downloads the \ncontents \(via coordinated staging to read a \n127\nsection of the file that has not yet been downloaded, results in \na fault being returned nSince storage is a finite entity, a replacement algorithm is \nassociated with caches. In our caching system when the \namount of storage used reaches a High Water Mark, files are \nevicted using a simple Least Recently Used algorithm until a \nLow Water Mark is reached. \nV. IMPLEMENTATION \nIn this section, we explain how the caching sub-system and \ncoordinated staging are implemented in GenesisII [23]. \nGenesisII, a web service standards-based grid middleware, is \nthe first realization of the GFFS. Since GenesisII and GFFS \nare both standards-based, we first overview a few standards \nthat helps understand the implementation better. \nA Standards \nWS-Addressing Endpoint references \(EPRs  service endpoints \n\(namely resources contains extra information \nabout the resource that can be used by clients as hints. \nWS-Naming [25] extends WS-Addressing by providing \nmeans for transparent failover, replication \(or caching EPRs cannot be compared, they cannot be \nused as a cache key. WS-Naming addresses this limitation by nproviding means to uniquely "name" a resource via an \nEndpoint Identifier \(EPI the \nMetadata of an EPR. For example, when a file \(ByteIO \nresource different EPRs but \nshare the same EPI. WS-Naming also states that associated \nwith each resource can be a resolver, which stores the EPR of \nthe primary and replicas of that resource. When queried with \nan EPI, the resolver returns an EPR from this set, thus \nproviding a way to achieve transparent failover. \nThe Basic Execution Service \(BES  nexecution sites. Depending on the implementation, a BES may \nexecute the job on a single computer, a cluster interfaced by a \nqueuing system, the cloud etc. \nB. Caching and Coordinated Staging Implementations nCoordinated staging treats each site as a potential replica-\nstore. Consequently, there needs to be a way for peers to \naddress and read from replicas in this replica-store, Hence, \neach BES resource incorporates within the Metadata of its \nEPR, the EPR of another service called the Fast Stager \nService \(FSS resolver by matching a \ngiven EPI with the set of EPRs in that replica-store, and \nreturns the EPR corresponding to the replica. How the FSS \nbuilds this set of EPRs is explained later. It is to be noted that nno access control check is performed by FSS. All \nauthentications are performed by the replicas themselves nWe next explain how each site acquires the FSS EPR of \nother sites. Complying with the BES standard, to create a job \non a BES, the metascheduler makes a Create Activity call on \nthat BES passing an Activity Document describing the job. \nInside the xsd:any element of the Activity Document, the \nmetascheduler inserts the peer knowledge - i.e for each file f \nrequired by the activity, the metascheduler inserts the FSS \nEPRs of those sites who will also stage-in f. The HTC \napplication identifier is also inserted within the xsd:any nelement. At the site, each individual job takes the help of the \nStager Manager and Download Manager for staging-in. \nThe Stager Manager\(SM or being staged-in 


job requires a file f that has \nalready been staged-in \(or is being staged-in application, then SM creates a hard-link to that \njob's working-directory location of f. Files which cannot be nlinked are sent to the Download Manager for download. \nThe Download Manager\(DM nperforms coordinated staging. In our current implementation, \nonly cacheable files undergo coordinated staging. In other \nwords, this means the “replica-store” of a site is actually its \ncache. The DM first downloads those files for which that site \nhas to behave like a peer in coordinated staging. This is done \nby looking at the Activity Document. Before downloading a \nfile f, the DM checks the cache using the f’s EPI as the cache-\nkey. On a cache-miss, the DM creates an empty ByteIO \nresource [8] \(corresponding to f and having the same EPI as f EPR with the local FSS, \nmaking f addressable by the peers. The DM partitions f into \nchunks equaling the number of FSS EPRs for f in the Activity \nDocument. The DM identifies its primary chunk by comparing \nthe EPI in the FSS EPR of the BES \(associated with the job it \nis downloading associated \nwith f in the Activity Document, and downloads it into the \ncache. Next, all the \(randomized secondary chunks of f are \ndownloaded using coordinated staging. In unopt-CS, the DM \nasks the FSS EPR associated with the chunk's master \(inferred \nfrom the Activity Document ncorresponding to the EPI of f. This EPR is treated as a replica \nwhile downloading that secondary chunk. In opt-CS, the DM \nasks the masters of all secondary chunks for their local ByteIO \nEPR corresponding to the EPI of f. These EPRs are treated as \nreplicas for each secondary chunk. After downloading a \ncacheable file completely, its EPR is registered with the \nresolver \(if one exists nfile is then copied from the cache to the working directory of \nthat job. \nVI. EVALUATION \nThe experimental setup consisted of eleven geographically \ndistributed sites. Table 1 describes the configuration of each nsite. Table 2 shows the average bandwidth perceived by each \nsite with every other site. \nIn coordinated staging, each site "chunkifies" the file to be \nstaged-in, and downloads chunks of the file in a random order nThis results in seeks and writes to arbitrary offsets. We first \nevaluate the overhead of writing to random offsets of an \nempty file. Figure 1 shows that the overhead of seeking is \nnegligible and the time taken to write at an arbitrary seek \noffset is nearly constant. This is because seeking generally  \n128\nExecution site Machine Type Cache filesystem type \nTexas Advanced Computing Center \(TACC NFS \nSan Diego Supercomputing Center - Sierra Red Hat Enterprise Server 5.8 ZFS mounted via NFS \nIndiana University – India Red Hat Enterprise Server 5.8 ext4 mounted via NFS \nUniversity of Virginia CS - Romulus Ubuntu 10.04 ext3 mounted via NFS \nUniversity of Virginia CSE - UVACSE Ubuntu 12.04 ext4 \nUniversity of Virginia University Datacenter - UDC Ubuntu 10.04 ext4 \nAmazon Small Instance UK Availability Zone 1a – UK1 Amazon Linux AMI ext3 \nAmazon Small Instance UK Availability Zone 1b – UK2 Amazon Linux AMI ext3 \nAmazon Small Instance UK Availability Zone 1c – UK3 Amazon Linux AMI ext3 \nAmazon Small Instance Japan Amazon Linux AMI ext3 \nAmazon Small Instance Singapore – S’pore Amazon Linux AMI ext3 \nTable 1 Experiment Pool \n          Sink nSource \nSierra Alamo India Romulus UDC Uvacse UK1 UK2 UK3 Japan S’pore \nSierra - 4.42 6.83 6.91 10.69 7.18 3.25 2.81 2.07 4.96 2.93 \nAlamo 8.53 - 8.10 6.93 8.26 6.82 4.19 3.79 3.26 3.30 2.24 \nIndia 9.01 5.20 - 7.49 17.10 7.56 4.93 4.82 4.47 3.15 2.40 \nRomulus 9.93 6.22 5.42 - 22.73 34.28 4.19 3.66 3.42 2.42 2.32 \nUDC 12.44 7.81 5.70 9.17 - 9.12 4.90 3.53 3.47 2.69 2.22 \nUVACSE 10.54 11.16 16.15 70.95 36.44 - 7.73 6.17 5.57 3.57 2.72 \nUK1 4.45 2.44 5.06 6.39 8.61 5.73 - 13.49 13.47 2.98 2.18 \nUK2 4.41 2.32 4.92 6.29 8.14 5.19 12.99 13.16 2.96 2.16 \nUK3 4.41 2.30 4.96 6.33 8.20 5.19 13.17 13.21 - 2.97 2.03 \nJapan 5.44 2.00 3.01 4.56 4.20 4.00 3.41 2.87 2.82 - 4.18 \nS’pore 2.80 1.88 2.38 3.45 3.22 3.25 2.80 2.27 2.25 4.99 - \nTable 2 Average Perceived Bandwidth between sites in MBPS \n \nParameter Value \nNumber of parallel TCP Streams 4 \nIgnore Sub-Phase Di 32MB \nHeed Sub-Phase Dh 64MB \nDownload Sub-Phase Dd 3GB - 64MB = \n2.94GB \nTable 3Parameters used in the experiment \ninvolves modifying only an in-memory variable which tracks \nthe byte-offset of the next read or write operation on the file. \nTypically, no storage is allocated for byte-offsets within the \nhole which is created while seeking beyond end-of-file with \nthree different sources were conducted. The three sources \nwere: Singapore \(site providing the lowest upload rate to other \nsites site providing moderate upload rate to other \nsites site providing the best upload rate to \nother sites as execution-sites. An HTC application consisting \nof ten sub-jobs was submitted to a metascheduler placed on nRomulus, a modest host at the University of Virginia. Each \nindividual job of the HTC application required a single shared \nfile to be staged-in. The source of this shared file was \nSingapore, Alamo or UVACSE depending on the experiment. \nThe size of this shared file was 3GB or 15GB. The \nmetascheduler was made to schedule exactly one individual \njob onto each execution site. Table 3 lists the parameters used \nfor the experiments 


n \nFig. 1 Time taken to seek and write \nFigure 2 shows the download time by the sites under all three \nstudied approaches \(normalized to the conventional approach \nof downloading from a single source that all \nthree approaches employed parallel-TCP. It was observed that \nwith Singapore and Alamo as sources every site benefitted \nunder both unopt-CS and opt-CS. With Singapore as source \nthe speed-up varied between 1.42 and 3.85, while with Alamo \nas source, the speed-up varied from 1.35 to 3.70. Speed-up \nwas achieved not only because of the availability of faster \npeers for download, but also due to lesser bandwidth \ncontention at the source. With a 3GB source at UVACSE, no \nsite except Romulus suffered a significant slowdown. With a n15GB source at UVACSE, all sites except Romulus and Alamo \nobtained a speed-up. A speed-up of upto 1.56 was achieved. \nTypically, the 15GB downloads obtain greater speed-up than \nthe 3GB ones. This is because a lesser percentage of the \noutcalls are spent on exploring, and the penalties of \noptimistically assuming a peer to have a file are less severe.  \n0\n50\n100\n150\n200\n250\nTi\nm\ne \nta\nke\nn \nin\n m\ns 0\n1G\n10G\n25G\n50G\n100G\n129\n \n \n \n n \n \n \n \n \nFig. 3 Comparison of the throughput of the three approaches \nMoreover, for the 3GB download under opt-CS, it is possible \nfor a site to not download a chunk from a closer peer even \nthough the peer may have already downloaded the chunk. This \nis because the chunk size is small enough to be covered by \nexecuting the Explore Phase on a small number of unexplored \nreplicas. Opt-CS was on average 1.17x faster than the unopt-\nCS because the former tries to increase the traffic flowing on \nthe faster links.  \nWe define the throughput of a download to be the ratio of \nthe total amount of data downloaded by all the sites to the time \ntaken for the last site to finish downloading the given \(shared ndownload under all three approaches, normalized to the \nconventional approach. Under opt-CS, the throughput of the \nsystem improved for all the cases. With the slower sources, \nboth opt-CS and unopt-CS caused an increase in throughput. \nUnopt-CS on the 3GB source at UVACSE resulted in a \nnegligible throughput decrease It is to be noted that sites \nwhich finish downloading earlier can be simultaneously \nexecuting the job \(using files from the working directory from the cache directory nSite Purge Policy \nTACC Lonestar 10 days \nTACC Ranger Deletion on full filesystem \nPSC Blacklight 7 days nPurdue Steele 90 days \nIU Quarry 60 days \nNCSA Forge 4 days for files >= 10GB, else 14 days \nNICS Kraken 30 days \nTable 4 Scratch space purge policy heterogeneity amongst a few \nXSEDE sites \nVII. RELATED WORK \nThe idea of using downloaders as uploaders has been used \nin peer-to-peer systems like in the BitTorrent protocol [26 nHowever, there exist differences between the two systems. \nFirstly, in our system, all the peers start downloading at \nalmostthe same time. Secondly, the churn-rate is very high in \npeer-to-peer systems while the peers in our environment are \nmore stable. The metascheduler performs the task of the \nTracker in BitTorrent by helping downloaders find each other. \nIn both systems, peers can become prospective seeders. \nBitTorrent uses a choking technique to prevent free-riding. \nThe metascheduler prevents free-riding to an extent by npreventing those BES' which do not incorporate the FSS EPR \nfrom obtaining peer knowledge. We assume that all peers are \ncooperating to achieve a common goal and assume no \nmalicious peers. \nThe state-of-the-art production grids [16, 27, 28] typically \nadvertise a manual approach for file transfer via scp or \nGridFTP 29]. Owing to storage quota constraints in the home \ndirectory at each site, users use a larger shared scratch space. \nThe heterogeneity in the scratch space purge policy of sites is n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nSi\ner\nra\nA\nla\nm\no\nIn\ndi\na\nR\nom\n'u\ns\nU\nD\nC\nU\nva\ncs\ne\nU\nK\n1\nU\nK\n2\nU\nK\n3\nJa\npa\nn\nConvent ional unopt-CS opt-CS\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nSi\ner\nra\nIn\ndi\na\nR\nom\n'u\ns\nU\nD\nC\nU\nva\ncs\ne\nU\nK\n1\nU\nK\n2\nU\nK\n3\nJa\npa\nn\nS'\npo\nre\nC onventional unopt-CS opt-CS\n0\n1\n2\n3\n4\nConventional unopt-CS opt-CS\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nSi\ner\nra\nA\nla\nm\no\nIn\ndi\na\nR\nom\n'u\ns\nU\nD\nC\nU\nva\ncs\ne\nU\nK\n1\nU\nK\n2\nU\nK\n3\nJa\npa\nn\nC onventional unopt-CS opt-CS\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nSi\ner\nra\nIn\ndi\na\nR\nom\n'u\ns\nU\nD\nC\nU\nva\ncs\ne\nU\nK\n1\nU\nK\n2\nU\nK\n3\nJa\npa\nn\nS'\npo\nre\nC onventional unopt-CS opt-CS\n0\n0.5\n1\n1.5\n2\n2.5\n3\nConventional unopt-CS opt-CS\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt\nConventional\nunopt-CS\nopt-CS\n\(a source \(b c normalized to the conventional approach for 3GB \nfile \(top bottom problems in this manual approach. The user \nmust not only remember if the correct version of his input files nis in the scratch space of a particular site, but also remember \nthe policies of each site. Table 4 shows the heterogeneity in \nscratch space purge policy among a few XSEDE sites. Such \nan approach defeats an important use-case of computational \ngrids - "the user must not think" and should just "submit and \nforget" [14]. \nOn the other hand, grid middlewares like GenesisII [23] \nand Globus [30] have components like BES [12] and WS-\nGRAM [13]. Some of these services support sharing of input \nfiles by jobs at a site. The shared files are 


deleted once the last \njob finishes. Consequently, reuse which is inevitable in \nscientific research is not addressed. \nARC [20] is a grid middleware with a cache for handling \nfile sharing and reuse. However the cached files are readable \nonly by jobs within the site. Cabinet has a globally visible \ncache resulting in both performance and availability benefits. \nGridFTP [29] is a file transfer mechanism which also uses nparallel-TCP for mitigating the inherent slowness of TCP. rftp \n[31] is a file-transfer tool implemented on GridFTP which \ndownloads from multiple replicas simultaneously. \nTypical staging techniques do not address the possibility of \ntreating other execution sites as possible replicas. To the best \nof our knowledge, this is the first system to employ such a \nstaging technique. In this paper, each site downloads from \nonly one peer at a time. But our work can be extended to \ndownload from multiple peers simultaneously, and we leave \nthat as a future work. \nVIII. CONCLUSION \nIn this paper, we described two techniques for efficiently \nmanaging data in the GFFS- a caching system and a new file \nstaging technique called coordinated staging. The caching \nsystem aims to achieve a “once is enough” file transfer goal \nby preventing re-staging during sharing and reuse of input \nfiles. The main contribution of this work is coordinated \nstaging which treats execution sites as possible replica-stores. \nTwo techniques to perform coordinated staging were \ndiscussed: an unoptimistic and an optimistic approach. \nCoordinated staging decreased the download time by upto \n3.85x, and increased the throughput by upto 2.86x over the \nconventional approach of file-transfer from a single source. \nAlso, the optimistic approach was on average 1.17x better \nthan the unoptimistic approach. \nACKNOWLDEGMENT \nThis material is based upon work supported in part by the \nNational Science Foundation under Grant No. 0910812 This \nwork used the Extreme Science and Engineering Discovery \nEnvironment \(XSEDE National \nScience Foundation grant number OCI-1053575. \n \n \nREFERENCES \n[1] A. Grimshaw et al. “An open grid services architecture primer,” Computer, vol. 42, \npp. 27–34, Feb. 2009. \n[2] E. Seidel, TeraGrid 2011 Keynote Address, 2011. \nhttps://www.xsede.org/wwwteragrid/archive/web/tg11/seidel-article.html. \n[3] P.-C. Chen, J.-B Chang, Y.-L. Su, and C.-K. Shieh, “Ondemand data co-allocation \nwith user-level cache for grids,” Concurr Comput.: Pract. Exper., vol. 22, pp. \n2488–2513, Dec. 2010. \n[4] G. Wasson and M. Humphrey, “HPC File Staging Profile 1.0,” tech. rep., Open \nGrid Forum, 2010 \n[5] J. Bent, A. Arpaci-Dusseau, R. Arpaci-Dusseau and M Livny, “Migratory file \nservices for scientific applications,” tech. rep., Univ. of Wisconsin, Madison, 2002 n[6] J. Bester, I. Foster, C. Kesselman, J. Tedesco, S. Tuecke, “GASS: A data \nmovement and access service for wide area computing systems,” 1999. \n[7] A. Grimshaw, M. Morgan and A. Kalyanaraman GFFS—The XSEDE Global nFederated File System. Parallel Processing Letters,23\(02  rep., Open Grid Forum, 2006. \n[9] M. Morgan, A. Grimshaw, and O. Tatebe, “RNS specification 1.1,” tech. rep nOpen Grid Forum, 2010. \n[10] M. Morgan and A. Grimshaw, Methods in Enzymology, ch. 8. Elseiver, 2009. \n[11 J. I. Garzon et al, “End-to-end cache system for grid computing: Design and \nefficiency analysis of a highthroughput bioinformatic docking application,” Int. J. \nHigh Perform. Comput. Appl., vol. 24, pp. 243–264 Aug. 2010. \n[12] I. Foster et al. “Basic execution service specification 1.0,” tech. rep., Open Grid \nForum 2008. \n[13] WS-GRAM: http://www.globus.org/toolkit/docs/4.0/execution/wsgram/. \n[14] E. Huedo, R. S. Montero and I. M. Llorente, “The GridWay framework for \nadaptive scheduling and execution on grids,” Scalable Computing: Practice and \nExperience, vol. 6, no. 3, 2005. \n[15] A. Anjomshoaa et al, “Job submission description language specification 1.0,” \ntech. rep., Open Grid Forum, 2005. \n[16] W. Gentzsch et al, “DEISA distributed european infrastructure for \nsupercomputing applications,” J. Grid Comput., vol. 9, no. 2, pp 259–277, 2011. \n[17] XSEDE. https://www.xsede.org/. \n[18] T. J. Hacker and B. D. Athey, “The end-to-end performance effects of parallel tcp \nsockets on a lossy wide-area network,” 2001. \n[19] Filesystem in Userspace. http://fuse.sourceforge.net/. \n[20] M. Ellert et al. “Advanced resource connector middleware for lightweight \ncomputational grids,” Future Gener. Comput. Syst., vol. 23, pp. 219–240, Feb. \n2007. \n[21] A Chervenak et al. “Giggle: a framework for constructing scalable replica location \nservices,” in Proceedings of the 2002 ACM/IEEE conference on Supercomputing, \npp. 1–17, IEEE Computer Society Press, 2002. \n[22] S. Valente and A. Grimshaw, “Replicated grid resources,” in Proceedings of the \n2011 IEEE/ACM 12th International Conference on Grid Computing, pp. 198–206, \nIEEE Computer Society, 2011. \n[23] GenesisII http://www.genesis2.virginia.edu/. \n[24] “Web Services Addressing http://www.w3.org/Submission/ws-addressing/. \n[25] A. Grimshaw, M. Morgan, and K. Sarnowska, “WS-naming location migration, \nreplication, and failure transparency support for web services,” Concurr. Comput nPract. Exper., vol. 21, pp. 1013–1028, June 2009. \n[26] B. Cohen, “Incentives build robustness in BitTorrent,” 2003. \n[27] TeraGrid. https://www.teragrid.org. \n[28] UK National Grid Service http://www.ngs.ac.uk/. \n[29] W. Allcock et al. “GridFTP: Protocol extensions to FTP for the Grid,” 2001. \n[30 I. Foster and C. Kesselman, “Globus: A metacomputing infrastructure toolkit,” Int. \nJ. of Supercomputer Appl 


vol. 11, pp. 115–128, 1996. \n[31] J. Feng and M. Humphrey, “Eliminating replica selection - using multiple replicas \nto accelerate data transfer on grids,” Parallel and Distributed Systems, International \nConference on, vol. 0, p. 359, 2004 \n \n \n131\n 


order to assess the benefit of\nthe whole architecture. The relative importance or weights\nfor the value aggregation rules must be known beforehand\nand are an input to the model.\nCost model\nThe goal of the cost model is to provide an estimate of the\nlifecycle cost of an architecture \(i.e., a set of constellations\nand ground stations particular differ-\nentiating between different contract modalities, \(procurement\nvs hosted payloads vs 100 commercial cost, operations cost, and\nprogram overhead. Some of these are further divided into\nnon-recurring and recurring costs, as illustrated in Fig. 3.\nPayload Cost—Payload cost is only incurred when the con-\ntract modality is procurement or hosted payloads. If a 100%\ncommercial approach is taken, payload cost is set to zero,\nas it is included in the service fee charged to NASA by the\nprovider. Payload cost is the sum of a non-recurring cost\nand a recurring cost. When these values are not provided by\nFigure 3. Lifecycle cost breakdown\nthe user, they are estimated using CERs that utilize payload\nmass m and number of channels n as independent variables.\nThe CERs are taken from the USCM8 model [23] and are\nprovided below. All values are in FY2010$k.\nCpayl,NR = 339m+ 5127n \(6 7 cost\nof fabricating a qualification unit and Cpayl,R is the cost of\nfabricating the first flight unit. The standard error of the\nestimate \(SEE SEE of Equation 7 inside\nthe domain 38-928kg is 28%. All SEEs are corrected for the\nnumber of degrees of freedom. Total cost for development\nand fabrication of N identical payloads is thus given by:\nCpayl = Cpayl,NR N\nbCpayl,R \(8 is only incurred when the contract\nmodality is procurement. If a 100% commercial approach\nor hosted payloads approach are taken, bus cost is set to zero,\nas it is included in the service fee charged to NASA by the\nprovider. Bus cost is the sum of a non-recurring cost and a\nrecurring cost. When these values are not provided by the\n10\nuser, they are estimated using CERs that utilize subsystem\nmass as the independent variable. The CERs are taken from\nthe USCM8 model [23] and are provided below. All values\nare in FY2010$k.\nCbus,NR = 110.2mdry \(9 10 is the devel-\nopment cost including the cost of fabricating a qualification\nunit and Cpayl,R is the cost of fabricating the first flight\nunit. The standard error of the estimate \(SEE 114-5127kg is 47%. The SEE of Equation\n10 inside the domain 288-7398kg is 21%. Total cost for\ndevelopment and fabrication of N identical buses is computed\nas illustrated in Equation 8, with a learning factor of 95%.\nNote that the computation of bus cost depends on the dry\nmass of the spacecraft. This can be provided by the user,\nor it can be estimated by the spacecraft design module, which\nis described later in this section.\nLaunch Cost—Launch cost is only incurred when the contract\nmodality is procurement. If a 100% commercial approach\nor hosted payloads approach are taken, launch cost is set to\nzero, as it is included in the service fee charged to NASA by\nthe provider. Launch cost is given by the sum of the costs of\nlaunching all constellations in the architecture. Computation\nof launch cost for a constellation is based on the assumption\nthat, given a constellation of P planes and S satellites per\nplane, P < NL < PS launches are necessary to launch\nthe constellation, i.e., at least one launch per plane \(in\nother words, satellite engines are not sized to do inclination\nchanges after injection by taking into account both\nperformance and geometrical considerations.\nIn particular, a database of launchers is available to each\nconstellation. This database is shown in Table 5. Note that\nthe data concerning performance is provided in terms of the\n3 coefficients of a quadratic function of the orbit altitude.\nIn other words, if the entry of the table for a certain orbit\ntype \(e.g., LEO polar  then the\nperformance at altitude h can be computed as :\nperf\(h 11 computed as follows:\nNL = max{NL,mass, NL,vol, NL,dim} \(12 required\ngiven the total spacecraft mass and the performance of the\nlaunch vehicle to the desired orbit NL,vol is the minimum\nnumber of launches required given the total spacecraft vol-\nume and the volume of the launch vehicle; NL,dim is the\nminimum number of launches required given the sum of the\nmaximum dimension of all spacecraft and the height of the\nlaunch vehicle:\nNL,mass = d\n?NS/C\ni=1 mwet,i\nperf\(lv, orbit 13 14 15 spacecraft in the constella-\ntion, mwet,i, voli, and dmaxi are the wet mass, volume,\nand maximum dimension respectively of spacecraft i, and\nperf\(lv, orbit the volume, and the height respectively of\nthe launch vehicle. Once the number of launches has been\ncomputed launch cost is simply given by the product of\nnumber of launches and launch cost.\nGround segment cost—Ground segment cost is the sum of a\nnon-recurring cost and a recurring cost. When these values\nare not provided by 


the user, they are estimated using CERs\nthat utilize location of the facility, the number of spacecraft,\nand spacecraft lifetime as independent variables. The CERs\nare taken from [23] and are provided below. All values are in\nFY2010$k.\nCground,R = Cground,NR + Cground,Rt\(yr loc n$\nm2\n m2 0.5\n$M\nS/C/yr\nNS/Ct\(yr 16 loc construction cost in different locations, A is\nthe floor area of the facility in m2, and t\(yr lifetime\nin years. The values of the adjustment factor are taken from\n[23].\nService fees— Service fees are only applicable for hosted\npayloads and 100% commercial approaches. In these cases,\nthey can replace payload bus, launch, or ground segment\ncost. Service fees for the hosted payloads approach are\ncomputed as a fix quantity \(10$M resources such as volume, mass, power, data rate, or a\ncombination thereof. Service fees for the 100 commercial\napproach are computed as a fixed quantity \($2k spacecraft design module can be by-\npassed by choosing to assign a commercially available bus\ninstead of designing a bus. While the standard bus approach is\ncloser to reality, the spacecraft design module provides more\ndistinction in lifecycle cost between different architectures,\nand therefore it is chosen as the primary operating mode of\nthe tool. The spacecraft design module is an iterative module\nthat provides a subsystem-level design of the spacecraft bus\nincluding a very rough configuration of the spacecraft from\nthe payload requirements.Assumptions concerning the differ-\nent sub-modules in the spacecraft design module namely the\nbus selection module and the four steps of the process shown\n11\nTable 5. Extract of launch vehicle database\nAtlas-V Delta-7920 Taurus-XL\nPayload GTO [104,0,0] [5 · 102,0,0] [0,0,0]\nPayload LEO polar [15 103,?4 · 10?2,0] [4 · 103,?1 · 10?2,7 · 10?5] [1.2 · 103,?4.4 · 10?2,0]\nDiameter \(m m 10.0 7.53 5.71\nCost \(FY2010$M detail in the rest of this section.\nElectrical power subsystem design— The Electrical Power\nSubsystem \(EPS designed based on a very rough power\nbudget. The mass of the EPS is given by:\nmEPS = mSA +mbatt +mother 17 the other\ncomponents. The solar array is designed to provide enough\npower at end-of-life, assuming a certain yearly degradation\n?\(%/yr W/kg W nPe\nTe\nXe\n+ Pd\nTd\nXd\nTd\nWBOL\(\nW\nm2\n m\n2 1 kg 18 Te\(s s Te,\nT \(s W W requirements during\ndaylight, Xd and Xe are the energetic efficiencies between\nthe solar array and the power bus \(through the batteries in\ncase of eclipse W/m2 technology, Id is an efficiency, ? is the Sun\nangle, WBOL\( Wm2 at\nBOL, and ASA\(m2 capacity\nassuming a certain specific energy ?e\(Wh/kg Wh kg 19 is the depth of discharge \(which depends on the\norbital parameters batteries\nto the load. In particular, the DOD is assumed to be 0.8 for\nGEO, 0.6 for dawn-dusk SSO, and 0.4 for all other orbits.\nThe mass of the rest of components \(regulators, converters,\nand wiring function of the power at be-\nginning of life PBOL and the spacecraft dry mass mdry as\nsuggested in 24]:\nmother = ?PBOL + ?mdry \(20 power, PBOL = WBOLASA is the power\navailable at BOL, ? accounts for wiring, and mdry is the\nspacecraft dry mass.\nDelta-V and propellant mass budgets— The design of the\nADCS and propulsion subsystems is based on a rough ?V\nbudget of the spacecraft, which consists of four components:\ninjection, drag compensation, ADCS, and deorbiting:\n?V = ?Vinj + ?Vdrag + ?VADCS + ?Vdeorbit \(21 is in-\njected into a transfer orbit that has the perigee at 150km and\nthe apogee at the final orbit altitude:\n12\nTable 6. ?V required to compensate drag for different\norbits\nOrbit ?Vdrag\(m/s/yr h < 500km 12\nLEO\(500km < h < 600km 600km < h < 1000km configuration ?VADCS\(m/s/yr rp, ra, r n1\nr\n? 1\nrp ra\n rp1, ra1, rp2, ra2, r rp2, ra2, r rp1, ra1, r RE + 150km, r, r, r, r 22 rp1, ra1, rp2, ra2, r orbit \(rp1, ra1 rp2, ra2 to compensate drag is strongly depen-\ndent on orbit altitude. The values shown in Table 6 were taken\nfrom 25]:\nThe ?VADCS required for ADCS depends on the ADCS\nconfiguration, as shown in Table 7. These values were\nadapted from [25].\nThe ?Vdeorbit is computed assuming that LEO spacecraft are\ndeorbited using atmospheric drag, and all other spacecraft\nare deorbited using solar radiation presure. For drag-based\ndeorbiting 


the?Vdeorbit is computed based on a change of\nsemimajor axis from the current circular orbit to an elliptical\norbit that has the perigee at 0km and the apogee at the orbit\naltitude:\n?Vdeorbit,drag = ?V \(r, r RE , r, r 23 semimajor axis from the\ncurrent circular orbit to an elliptical orbit that has the same\nperigee and a slightly higher apogee:\n?Vdeorbit,SRP = ?V \(r, r, r, r + ?h, r 24 are due to the GEO restricted zone, the\n35km are to allow for gravitational perturbations, and the\nremaining margin depends on the magnitude of the effect of\nsolar radiation pressure on the spacecraft \(the larger the ef-\nfect, the larger the margin the spacecraft.\nOnce the ?V has been calculated, it is possible to compute\nthe propellant mass required to satisfy this ?V budget. The\ntool assumes that ?Vinj is performed by the apogee kick\nmotor \(AKM other ?V are performed by the\nADCS subsystem. For each of these propulsion systems, the\npropellant mass can be computed using the rocket equation:\n?Vj = gIsp,j log\nmi\nmf\n\(25 which can be\ndifferent for the AKM and the ADCS subsystem, mi is the\ninitial mass with propellant and mf is the final mass without\nthe propellant.\nAttitude Determination and Control and Propulsion Subsys-\ntem—The mass of the ADCS is mostly given by the mass\nof the sensors and the mass of the actuators. The mass\nof the sensors is driven by the attitude knowledge accuracy\nrequirement acc \(Equation 26 satisfy by the momentum storage h required \(Equation 27 26 27 that acc can vary depending on the architecture, as the\npointing requirements of a high gain antenna, or an optical\npayload, are very different from those of a low gain antenna.\nConcerning the momentum storage h, it is assumed to be\nsized to counter the different disturbance torques produced by\natmospheric drag, gravity gradient, solar radiation pressure,\nor the Earth’s magnetic field. Expressions for these distur-\nbance torques were taken from [25].\nIn addition to sensors and actuators, the ADCS has additional\nmass that can be estimated as a fix fraction of the spacecraft\ndry mass:\nmADCS = 3msen + 4mact + 0.01mdry \(28 subsystem, the mass of the AKM\ncan be estimated from its propellant mass assuming a certain\nmass fraction:\nmAKM =\n\(1 29 structure subsystem\nSubsystem k\nThermal 0.0607\nAvionics 0.0983\nStructure 0.5462\nThermal, avionics, and structure subsystems—The thermal,\navionics, and structure subystems are designed using simple\nparametrics of the form msubsystem = kmpayload. The\nconstans k that are used for each subsystem are summarized\nin Table 8.\nThe mass of the launch adapter mLA = 0.01mdry is added\nto the mass of the spacecraft.\nUpdate spacecraft mass and dimensions—After the first iter-\nation, the dry and wet mass of the spacecraft are updated.\nDimensions are estimated assuming a perfect cube of 100\nkg/m3. The mass and dimensions of the solar panels are\ntaken into account to update the inertial properties of the\nspacecraft, as illustrated in Equation 30:\nLA = 1.5s+ 0.5\n?\nAa\n2\nIz = 0.01mdry\nIx = Iy = Iz + L\n2\naMa \(30 design algorithm is\niterative because several feedback loops appear in the N2\nmatrix showing the dependences between different modules\nin the algorithm. For instance, the mass of the ADCS depends\non the mass of the spacecraft, which obviously depends on the\nmass of the ADCS. Thus, a set of convergence criteria need\nto be defined. The convergence criteria used by the tool are\ndescribed in Equation 31:\n|mdry,i+1 ?mdry,i| < 10kg 31 the current status of the MIT archi-\ntecture study for the SCaN system. The study consists of a\nstakeholder analysis to identify the primary stakeholders and\ntheir needs, and the development of a computational tool to\nexplore the architectural tradespace.\nSeveral interviews have been conducted with experts at\nNASA to elicit the potential requirements on SCaN from\ndifferent user communities.\nThe major architectural decisions to be made by the SCaN\nprogram have been identified and encoded in a mathematical\nmodel. A computational tool has been developed that can\nautomatically enumerate and evaluate thousands of different\nSCaN architectures. This tool contains both a performance\nand a cost model.\nNext Steps\nThe next steps include calibration of the optical link budget\ncalculations, comparisons of the network scheduling calcula-\ntions with historical TDRSS load data, and validation of the\nspacecraft sizing algorithm with real TDRS data. Following\nthe completion of the stakeholder analysis, the tool will be\nbe used to explore the architectural tradespace and identify\na subset of preferred architectures worth studying in more\ndetail. These architectures could then be analyzed in NASA’s\nArchitecture Development Lab \(ADL NNX11AR70G.\nThe authors would also like to thank the Centre de Formacio\nInterdisciplina`ria Superior and the Cellex Foundation for\npartially funding this project.\nREFERENCES\n[1] S. Tsiao, Read you loud and clear! The story of NASA’s\nspaceflight tracking and data network. Washington\nDC: Library of Congress, 2007.\n[2] G. Maral Satellite Communication Systems: systems,\ntechniques and technology, 2009.\n[3] K. Y. Jo, “Satellite 


communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[4] E. Jennings and D. Heckman, “Architecture Modeling\nand Performance Characterization of Space Communi-\ncations and Navigation \( SCaN  R. Borgen, S. Nguyen, J. Segui, T. Stoe-\nnescu, S.-y. Wang, and S. Woo, “Space Communica-\ntions and Navigation SCaN Astronautics, no. August, pp. 1–11,\n2009.\n[6] E. Jennings and D. Heckman, “Performance Charac-\nterization of Space Communications and Navigation\n\(SCaN Mar. 2008.\n[7] J. Alonso and K. Fall, “A Linear Programming For-\nmulation of Flows over Time with Piecewise Constant\nCapacity and Transit Times piecewise constant capacity\nand transit times,” 2003.\n[8] B. L. Murphy High Resolution Satellite Communica-\ntion Simulation,” 2000.\n[9] M. Werner, A. Jahn, E. Lutz, and A Bottcher, “Analysis\nof System Parameters for LEO/ICO-Satellite Commu-\nnication Networks,” 1995.\n[10] T Weilkiens, Systems engineering with SysML/UML:\nmodeling, analysis, design. Heidelberg, Germany: The\nMorgan Kaufmann/OMG Press, 2006.\n[11] M. Rao, S. Ramakrishnan, and C. Dagli, “Modeling and\nSimulation of Net Centric System of Systems Using\nSystems Modeling Language and Colored Petri-nets :\nA Demonstration Using the Global Earth Observation\n14\nSystem of Systems,” Systems Engineering, vol. 11,\nno. 3, pp. 203–220, 2008.\n[12] B. H. Y Koo, W. L. Simmons, and E. F. Crawley, “Al-\ngebra of Systems: A Metalanguage for Model Synthesis\nand Evaluation,” IEEE Transactions on Systems, Man,\nand Cybernetics - Part A: Systems and Humans, vol. 39,\nno. 3 pp. 501–513, May 2009.\n[13] M. Ehrgott and X. Gandibleux, “A Survey and An-\nnotated Bibliography of Multiobjective Combinatorial\nOptimization,” OR Spectrum, vol. 22, no. 4, pp. 425–\n460, Nov. 2000.\n[14] D Selva, “Rule-based system architecting of Earth\nobservation satellite systems,” PhD dissertation Mas-\nsachusetts Institute of Technology, 2012.\n[15] D. Selva and E. F. Crawley, “VASSAR: Value Assess-\nment of System Architectures using Rules,” in Proceed-\nings of the 2013 IEEE Aerospace Conference, Big Sky,\nMontana 2013.\n[16] T. Sutherland, B. Cameron, and E. Crawley, “Program\ngoals for the nasa/noaa earth observation program de-\nrived from a stakeholder value network analysis,” 2012.\n[17] B. Cameron, E. Crawley, G. Loureiro and E. Reben-\ntisch, “Value flow mapping: Using networks to inform\nstakeholder analysis,” Acta Astronautica vol. 62, pp.\n324–333, 2008.\n[18] B. Cameron and Crawley, “Goals for space exploration\nbased on stakeholder network value considerations,”\nActa Astronautica, vol. 68, pp. 2088–2097, 2011.\n[19] D. Selva and E. F Crawley, “Integrated Assessment of\nPackaging Architectures in Earth Observing Programs,”\nin Proceedings of the 2011 IEEE Aerospace Confer-\nence, Big Sky, Montana, 2010.\n[20] O. P. Gupta and C. S. Fish, “Iridium NEXT: A Global\naccess for your sensor needs,” in Proceedings of the\n2010 American Geophysical Union Fall Meeting San\nFrancisco, CA, 2010.\n[21] T. Stoenescu and L. Clare, “Traffic Modeling for\nNASA’s Space Communications and Navigation\n\(SCaN  communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[23] H. Apgar, “Cost Estimating,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 11.\n[24] R. S. Bokulic, C. C. DeBoy, S. W. Enger, J. P. Schnei-\nder and J. K. McDermott, “Spacecraft Subsystems IV\nCommunications and Power,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 21.\n[25] P. Springmann and O. de Weck, “Parametric scaling\nmodel for nongeosynchronous communications satel-\nlites,” Journal of spacecraft and rockets, vol. 41, no. 3,\npp 472–477, 2004.\nBIOGRAPHY[\nMarc Sanchez is a senior student from\nUniversitat Politecnica de Catalunya\n\(Barcelona, Spain Telecommunications En-\ngineering. His is currently a Visiting\nStudent at the Space System Architecture\nGroup of MIT, focusing his interests in\nrule-based expert systems and how they\ncan be applied to space communications\nnetworks. Prior to his work at MIT, Marc has been a\nsoftware engineer at Sener Ingenieria y Sistemas involved in\nthe development of commercial software FORAN CAD/CAM.\nDr. Daniel Selva received a PhD in\nSpace Systems from MIT in 2012 and\nhe is currently a post-doctoral associate\nin the department of Aeronautics and\nAstronautics at MIT. His research inter-\nests focus on the application of multi-\ndisciplinary optimization and artificial\nintelligence techniques to space systems\nengineering and architecture, in partic-\nular in the context of Earth observa-\ntion missions. Prior to MIT, Daniel worked for four years\nin Kourou \(French Guiana in\noperations concerning the guidance, navigation and control\nsubsystem, and the avionics and ground systems Daniel has\na dual background in electrical engineering and aeronautical\nengineering, with degrees from Universitat Politecnica de\nCatalunya in Barcelona, Spain, and Supaero in Toulouse,\nFrance. He is a 2007 la Caixa fellow, and received the Nortel\nNetworks prize for academic excellence in 2002.\nDr. Bruce Cameron is a Lecturer\nin Engineering Systems at MIT and a\nconsultant on platform strategies. At\nMIT, Dr. Cameron ran the 


MIT Com-\nmonality study, a 16 firm investigation\nof platforming returns. Dr. Cameron’s\ncurrent clients include Fortune 500 firms\nin high tech, aerospace, transportation,\nand consumer goods. Prior to MIT,\nBruce worked as an engagement man-\nager at a management consultancy and as a system engineer\nat MDA Space Systems, and has built hardware currently in\norbit. Dr. Cameron received his undergraduate degree from\nthe University of Toronto, and graduate degrees from MIT.\nDr. Edward F. Crawley received an\nSc.D. in Aerospace Structures from MIT\nin 1981. His early research interests\ncentered on structural dynamics, aeroe-\nlasticity, and the development of actively\ncontrolled and intelligent structures. Re-\ncently, Dr. Crawleys research has fo-\ncused on the domain of the architecture\nand design of complex systems. From\n1996 to 2003 he served as the Depart-\nment Head of Aeronautics and Astronautics at MIT, leading\nthe strategic realignment of the department Dr. Crawley is a\nFellow of the AIAA and the Royal Aeronautical Society \(UK academies of engineering.\n15\nHe is the author of numerous journal publications in the\nAIAA Journal, the ASME Journal, the Journal of Composite\nMaterials, and Acta Astronautica. He received the NASA\nPublic Service Medal Recently, Prof Crawley was one of\nthe ten members of the presidential committee led by Norman\nAugustine to study the future of human spaceflight in the US.\nBernard D. Seery is the Assistant Di-\nrector for Advanced Concepts in the Of-\nfice of the Director at NASA’s Goddard\nSpace Flight Center \(GSFC include assisting the Deputy\nDirector for Science and Technology\nwith development of new mission and\nmeasurement concepts, strategic analy-\nsis, strategy development and investment\nresources prioritization Prior assign-\nments at NASA Headquarters included Deputy for Advanced\nPlanning and Director of the Advanced Planning and In-\ntegration Office \(APIO and Evaluation \(PA&E DAA and Physical Research \(OBPR Directorate, Code 600, at \(GSFC bachelors of science in physics, with emphasis in\nnuclear physics. He then attended the University of Ari-\nzona’s School of Optical Sciences, and obtained a masters\ndegree in Optical Sciences, specializing in nonlinear optical\napproaches to automated alignment and wavefront control\nof a large, electrically-pumped CO2 laser fusion driver. He\ncompleted all the course work for a PhD in Optical Sciences\nin 1979, with emphasis in laser physics and spectroscopy. He\nhas been a staff member in the Laser Fusion Division \(L-\n1 Alamos National Laboratories \(LANL working on innovative infrared laser auto-alignment\nsystems and infrared interferometry for target alignment for\nthe HELIOS 10 kilojoule, eight-beam carbon dioxide laser\nfusion system. In 1979 he joined TRW’s Space and Defense\norganization in Redondo Beach, CA and designed and de-\nveloped several high-power space lasers and sophisticated\nspacecraft electro-optics payloads. He received the TRW\nPrincipal Investigators award for 8 consecutive years.\nDr. Antonios A. Seas is a Study Man-\nager at the Advanced Concept and For-\nmulation Office ACFO Electro-Optics branch where\nhe focused on optical communications\nand the development of laser systems\nfor space applications. Prior to joining\nNASA in 2005 he spent several years in\nthe telecommunication industry developing long haul sub-\nmarine fiber optics systems, and as an Assistant Professor\nat the Bronx Community College. Antonios received his\nundergraduate and graduate degrees from the City College of\nNew York, and his doctoral degree from the Graduate Center\nof the City University of New York. He is also a certified\nProject Management Professional.\n16\n 


1483\nSUB-NYQUIST SAMPLING RATES\nMustafa Al-Ani, University of Westminster, United Kingdom; Bashar Ahmad, University of Cambridge, \nUnited Kingdom; Andrzej Tarczynski University of Westminster, United Kingdom\nTPa-8.10: OPPORTUNISTIC TRANSMITTER SELECTION FOR SELFLESS 1488\nOVERLAY COGNITIVE RADIOS\nMohammad Shaqfeh, Texas A&M University at Qatar, Qatar; Ammar Zafar, King Abdullah University \nof Science and Technology, Saudi Arabia Hussein Alnuweiri, Texas A&M University at Qatar, Qatar; \nMohamed-Slim Alouini, King Abdullah University of Science and Technology, Saudi Arabia\nTPa-8.11: A GAME THEORETIC POWER CONTROL FRAMEWORK FOR 1493\nSPECTRUM SHARING IN COMPETITIVE ENVIRONMENTS\nRaghed El-Bardan, Swastik Brahma, Pramod K. Varshney, Syracuse University, United States\nTPa-8.12: COGNITIVE RADIO TRANSMISSION STRATEGIES FOR PRIMARY ...........................................1498\nERASURE CHANNELS\nAhmed ElSamadouny, University of Texas at Dallas, United States; Mohammed Nafie, Ahmed Sultan, \nNile University Egypt\nTPa-8: RELAYS IN COMMUNICATIONS\nTPa-8.1: OPTIMIZED RECEIVER DESIGN FOR DECODE-AND-FORWARD 1535\nRELAYS USING HIERARCHICAL MODULATION\nTu Nguyen, Broadcom Corporation, United States; Pamela Cosman, Laurence Milstein, University of \nCalifornia, San Diego, United States\nTPa-8.2: OPTIMAL LINEAR-COMBINING RECEIVER FOR 1540\nDECODE-AND-FORWARD RELAYS USING SUPERPOSITION CODING\nTu Nguyen, Broadcom Corporation, United States; Laurence Milstein, University of California, San \nDiego, United States\nTPa-8.3: ALTERNATE RELAYING AND THE DEGREES OF FREEDOM OF 1545\nONE-WAY CELLULAR RELAY NETWORKS\nAya Salah, Amr El-Keyi Mohammed Nafie, Nile University, Egypt\nTPa-8.4: DISTRIBUTED AF BEAMFORMING RELAY NETWORKS UNDER 1550\nTRANSMIT POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon Edwin M. Sawan, Wichita State University, United States; Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nTPa-8.5: JOINT TRANSMIT DESIGN AND NODE SELECTION FOR 1555\nONE-WAY AND TWO-WAY UNTRUSTED RELAY CHANNELS\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.6: WIRELESS PHYSICAL LAYER SECURITY ENHANCEMENT WITH  ..............................................1560\nBUFFER-AIDED RELAYING\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.7: TRAINING SLOT ALLOCATION FOR MITIGATING ESTIMATION  ................................................1565\nERROR PROPAGATION IN A TWO-HOP RELAYING SYSTEM\nQian Gao, Gang Chen, Yingbo Hua, University of California, Riverside United States\nxxv\nTPa-8.8: TRANSMIT OUTAGE PRE-EQUALIZATION FOR 1570\nAMPLIFY-AND-FORWARD RELAY CHANNELS\nFernando Sanchez, Gerald Matz, Vienna University of Technology, Austria\nTPa-8: ADAPTIVE FILTERING\nTPa-8.1: A GRADIENT-CONTROLLED IMPROVED PROPORTIONATE 1505\nMULTI-DELAY FILTER\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nTPa-8.2: COMPLEX PROPORTIONATE-TYPE AFFINE PROJECTION  ...........................................................1510\nALGORITHMS\nKevin Wagner Naval Research Laboratory, United States; Miloš Doroslovacki, George Washington \nUniversity, United States\nTPa-8.3: RADAR WAVEFORM DESIGN IN ACTIVE COMMUNICATIONS 1515\nCHANNEL\nKevin Shepherd, Ric Romero, Naval Postgraduate School, United States\nTPa-8.4: THE LEAKY LEAST MEAN MIXED NORM ALGORITHM................................................................1520\nMohammed Abdul Nasar, Azzedine Zerguine, King Fahd University of Petroleum & Minerals, Saudi \nArabia\nTPa-8.5: A NEW VARIABLE STEP-SIZE ZERO-POINT ATTRACTING  ...........................................................1524\nPROJECTION ALGORITHM\nJianming Liu, Steven Grant, Missouri University of Science and Technology, United States\nTPa-8.6 RECURSIVE LEAST SQUARES FILTERING UNDER STOCHASTIC 1529\nCOMPUTATIONAL ERRORS\nChandrasekhar Radhakrishnan, Andrew Singer, University of Illinois at Urbana-Champaign, United \nStates\nTPa-8: CELLULAR AND HETEROGENEOUS NETWORKS\nTPa-8.1: DOWNLINK COVERAGE ANALYSIS OF N-TIER 1577\nHETEROGENEOUS CELLULAR NETWORKS BASED ON CLUSTERED STOCHASTIC \nGEOMETRY\nChunlin Chen, Robert Elliott, Witold Krzymien, University of Alberta / Telecommunications Research \nLaboratories, Canada\nTPa-8.2: SYSTEM-LEVEL PERFORMANCE OF THE MIMO-OFDM 1582\nDOWNLINK WITH DENSE SMALL CELL OVERLAYS\nThomas Wirth, Bernd Hofeld, Fraunhofer Heinrich Hertz Institute, Germany\nTPa-8.3: ADAPTIVE HARQ AND SCHEDULING FOR VIDEO OVER LTE......................................................1584\nAvi Rapaport, Weimin 


Liu, Liangping Ma, Gregory S. Sternberg, Ariela J. Zeira, Anantharaman \nBalasubramanian, InterDigital, United States\nTPa-8.4: NOVEL PARTIAL FEEDBACK SCHEMES AND THEIR EVALUATION 1589\nIN AN OFDMA SYSTEM WITH CDF BASED SCHEDULING\nAnh Nguyen University of California, San Diego, United States; Yichao Huang, Qualcomm \nTechnologies, Inc., United States Bhaskar D. Rao, University of California, San Diego, United States\nTPa-8.5: OPPORTUNISTIC THIRD-PARTY BACKHAUL FOR CELLULAR  ...................................................1594\nWIRELESS NETWORKS\nRussell Ford, Changkyu Kim, Sundeep Rangan, Polytechnic Institute of New York University, United \nStates\nTPa-8.6: PROACTIVE USER ASSOCIATION IN WIRELESS SMALL CELL  ...................................................1601\nNETWORKS VIA COLLABORATIVE FILTERING\nFrancesco Pantisano, Joint Research Center, Italy; Mehdi Bennis, University of Oulu Finland; Walid \nSaad, University of Miami, United States; Stefan Valentin, Bell Labs, Alcatel-Lucent, Germany nMérouane Debbah, Supélec, France; Alessio Zappone, Technische Universität Dresden, Germany\nTPa-8.7 INTERFERENCE ANALYSIS OF MULTI-HOP CELLULAR SENSOR 1606\nNETWORKS\nYeashfi Hasan, R. Michael Buehrer, Virginia Polytechnic Institute and State University, United States\nxxvi\nTPb-1: FULL-DUPLEX MIMO COMMUNICATIONS II\nTPb-1.1: DIVERSITY-MULTIPLEXING TRADEOFF ANALYSIS OF MIMO 1613\nRELAY NETWORKS WITH FULL-DUPLEX RELAYS\nQiang Xue University of Oulu, Finland; Anna Pantelidou, Renesas Mobile Europe, Finland; Behnaam \nAazhang, Rice University, United States\nTPb-1.2: ERGODIC MUTUAL INFORMATION OF FULL-DUPLEX MIMO 1618\nRADIOS WITH RESIDUAL SELF-INTERFERENCE\nAli Cagatay Cirik, University of California, Riverside, United States; Yue Rong, Curtin University, \nAustralia; Yingbo Hua, University of California, Riverside, United States\nTPb-1.3: FULL-DUPLEX IN LARGE-SCALE WIRELESS SYSTEMS 1623\nBei Yin, Michael Wu, Christoph Studer Joseph R. Cavallaro, Rice University, United States; Jorma \nLilleberg, Broadcom, United States\nTPb-1.4 FULL-DUPLEX COMMUNICATION VIA ADAPTIVE NULLING......................................................1628\nScott Johnston, Paul Fiore, Massachusetts Institute of Technology, United States\nTPb-1.5: WEIGHTED-SUM-RATE MAXIMIZATION FOR BI-DIRECTIONAL  ...............................................1632\nFULL-DUPLEX MIMO SYSTEMS\nAli Cagatay Cirik, University of California, Riverside, United States; Rui Wang, The Chinese nUniversity of Hong Kong, Hong Kong SAR of China; Yingbo Hua, University of California, Riverside, \nUnited States\nTPb-2: PHY PERFORMANCE ABSTRACTION TECHNIQUES\nTPb-2.1: STOCHASTIC DYNAMIC MODELS IN PHY ABSTRACTION 1639\nFrancesc Rey, Josep Sala-Alvarez, Technical University of Catalonia, Spain\nTPb-2.2: ON SCALABILITY, ROBUSTNESS AND ACCURACY OF PHYSICAL 1644\nLAYER ABSTRACTION FOR LARGE-SCALE SYSTEM LEVEL EVALUATIONS OF LTE \nNETWORKS\nFlorian Kaltenberger, Imran Latif, Raymond Knopp, Eurecom, France\nTPb-2.3: LINK ADAPTATION IN MIMO-OFDM WITH PRACTICAL 1649\nIMPAIRMENTS\nAlberto Rico-Alvarino University of Vigo, Spain; Robert W. Heath, Jr., University of Texas at Austin, \nUnited States\nTPb-2.4 DIGITAL PRE-DISTORTION OF RADIO FREQUENCY 1654\nFRONT-END IMPAIRMENTS IN THE DESIGN OF SPECTRALLY AGILE MULTICARRIER \nTRANSMISSION \nZhu Fu, Alexander Wyglinski, Worcester Polytechnic Institute United States\nTPb-2.5: SYSTEM-LEVEL INTERFACES AND PERFORMANCE EVALUATION 1659\nMETHODOLOGY FOR 5G PHYSICAL LAYER BASED ON NON-ORTHOGONAL nWAVEFORMS\nGerhard Wunder, Martin Kasparick, Fraunhofer Heinrich Hertz Institute, Germany; Stephan Ten \nBrink University of Stuttgart, Germany; Frank Schaich, Thorsten Wild, Yejian Chen, Bell Labs, \nAlcatel-Lucent Germany; Ivan Gaspar, Nicola Michailow, Gerhard Fettweis, Technische Universität \nDresden, Germany; Dimitri Ktenas, Nicolas Cassiau, Commissariat à l’énergie atomique et aux \nénergies alternatives, France; Marcin Dryjanski, Kamil Sorokosz, Slawomir Pietrzyk, IS-Wireless, \nPoland; Bertalan Eged, National Instruments Hungary\nTPb-3: LOW-DIMENSIONAL SIGNAL MODELS\nTPb-3.1: NEAREST SUBSPACE CLASSIFICATION WITH MISSING DATA 1667\nYuejie Chi, The Ohio State University, United States\nTPb-3.2: REFLECTIONS ON SAMPLING-FILTERS FOR COMPRESSIVE 1672\nSENSING AND FINITE-INNOVATIONS-RATE MODELS\nP. P Vaidyanathan, Srikanth Tenneti, California Institute of Technology, United States\nTPb-3.3: IDENTIFIABILITY BOUNDS FOR BILINEAR INVERSE 1677\nPROBLEMS\nSunav Choudhary, Urbashi Mitra, University of Southern California, United States\nTPb-3.4: LOAD FORECASTING VIA LOW RANK AND SPARSE 


MATRIX  ...................................................1682\nFACTORIZATION\nSeung-Jun Kim, Georgios B Giannakis, University of Minnesota, United States\nxxvii\nTPb-3.5: SEMI-BLIND SOURCE SEPARATION VIA SPARSE 1687\nREPRESENTATIONS AND ONLINE DICTIONARY LEARNING\nSirisha Rambhatla, Jarvis Haupt, University of Minnesota - Twin Cities, United States\nTPb-4: LOCATION-AWARE NETWORKING\nTPb-4.1: ROBUST LINK SCHEDULING WITH CHANNEL ESTIMATION 1695\nAND LOCATION INFORMATION\nSrikar Muppirisetty, Rocco Di Taranto, Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.2: SIMULTANEOUS ROUTING AND POWER ALLOCATION USING  .................................................1700\nLOCATION INFORMATION\nRocco Di Taranto Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.3: LOCATION AWARE TRAINING SCHEME FOR D2D NETWORKS ..................................................1705\nDaoud Burghal, Andreas F. Molisch, University of Southern California, United States\nTPb-4.4: A COOPERATIVE HIGH-ACCURACY LOCALIZATION ALGORITHM 1709\nFOR IMPROVED ROAD WORKERS’ SAFETY\nSankalp Dayal, Adam Mortazavi, Khanh H. Huynh, University of California, Santa Barbara, United \nStates; Ramez L. Gerges California Department of Transportation, United States; John J. Shynk, \nUniversity of California, Santa Barbara, United States\nTPb-4.5: REAL-TIME ENERGY STORAGE MANAGEMENT WITH 1714\nRENEWABLE ENERGY OF ARBITRARY GENERATION DYNAMICS\nTianyi Li, Min Dong, University of Ontario Institute of Technology, Canada\nTPb-5: ANALYSIS OF COMPLEX BIOLOGICAL SYSTEMS AND OMICS DATA II\nTPb-5.2: STATISTICAL VALIDATION OF PARAMETRIC APPROXIMATIONS TO 1721\nTHE MASTER EQUATION\nGarrett Jenkinson, John Goutsias, The Johns Hopkins University, United States\nTPb-5.4: A MESSAGE-PASSING ALGORITHM FOR HAPLOTYPE ASSEMBLY 1726\nZrinka Puljiz, Haris Vikalo, University of Texas at Austin United States\nTPb-6: TARGET TRACKING I\nTPb-6.1: TRACK STATE AUGMENTATION FOR ESTIMATION OF 1733\nPROBABILITY OF DETECTION IN MULTISTATIC SONAR DATA\nEvan Hanusa, David Krout, University of Washington, United States\nTPb-6.2: HYPOTHESIS STRUCTURE IN ENHANCED 1738\nMULTIPLE-HYPOTHESIS TRACKING\nStefano Coraluppi, Craig Carthel, Compunetix Inc., United States; Marco Guerriero, SAIRA/FAR nAMERICAS Inc., United States\nTPb-6.3: SPLINE PROBABILITY HYPOTHESIS DENSITY FILTER FOR 1743\nNONLINEAR MANEUVERING TARGET TRACKING\nRajiv Sithravel, Xin Chen, McMaster University, Canada; Mike McDonald, Defence Research and \nDevelopment Canada Canada; Thia Kirubarajan, McMaster University, Canada\nTPb-6.4: PERFORMANCE ANALYSIS OF THE CONVERTED RANGE RATE  ...............................................1751\nAND POSITION LINEAR KALMAN FILTER\nSteven Bordonaro Naval Undersea Research Center, United States; Peter Willett, Yaakov Bar-Shalom, \nUniversity of Connecticut United States\nTPb-6.5: MAP-PF MULTITARGET TRACKING WITH PROPAGATION 1756\nMODELING UNCERTAINTIES\nKristine Bell, Robert Zarnich, Metron, United States\nTPb-7: MACHINE LEARNING AND STATISTICAL SIGNAL PROCESSING II\nTPb-7.1 FORWARD/BACKWARD STATE AND MODEL PARAMETER 1763\nESTIMATION FOR CONTINUUM-STATE HIDDEN MARKOV MODELS \(CHMM States\nxxviii\nTPb-7.2: LOW-RANK KERNEL LEARNING FOR ELECTRICITY MARKET 1768\nINFERENCE\nVassilis Kekatos, Yu Zhang, Georgios B Giannakis, University of Minnesota, United States\nTPb-7.3: HIERARCHICAL CLUSTERING METHODS AND ALGORITHMS 1773\nFOR ASYMMETRIC NETWORKS\nGunnar Carlsson, Stanford University, United States; Facundo Mémoli, University of Adelaide, \nAustralia; Alejandro Ribeiro, Santiago Segarra, University of Pennsylvania, United States\nTPb-7.5: ACHIEVING COMPLETE LEARNING IN MULTI-ARMED BANDIT 1778\nPROBLEMS\nSattar Vakili, Qing Zhao, University of California, Davis, United States\nTPb-8: DESIGN AUTOMATION\nTPb-8.1: MPMAP: A HIGH LEVEL SYNTHESIS AND MAPPING TOOL FOR  ................................................1785\nMPSOCS\nAmr Hussien, Ahmed M. Eltawil University of California, Irvine, United States; Rahul Amin, Jim \nMartin, Clemson University, United States\nTPb-8.2: SOFTWARE TOOL FOR FPGA BASED MIMO RADAR APPLICATIONS 1792\nAmin Jarrah, Mohsin M. Jamali, University of Toledo, United States\nTPb-8.3: MULTI-CLOCK DOMAIN OPTIMIZATION FOR 1796\nRECONFIGURABLE ARCHITECTURES IN HIGH-LEVEL DATAFLOW APPLICATIONS\nSimone Casale-Brunet, Endri Bezati, Claudio Alberti, Marco 


Mattavelli, École Polytechnique Fédérale \nde Lausanne \(EPFL Milano, Italy; Jörn Janneck, Lund \nUniversity, Sweden\nTPb-8.4: ACTOR CLASSIFICATION USING ACTOR MACHINES 1801\nGustav Cedersjö, Jörn Janneck, Lund University, Sweden\nTPb-8.5: SYSTEMS DESIGN SPACE EXPLORATION BY SERIAL DATAFLOW 1805\nPROGRAM EXECUTIONS\nSimone Casale-Brunet, Marco Mattavelli Claudio Alberti, École Polytechnique Fédérale de Lausanne \n\(EPFL Sweden\nTPb-8.7: REAL-TIME RADAR SIGNAL PROCESSING ON MASSIVELY 1810\nPARALLEL PROCESSOR ARRAYS\nZain Ul-Abdin, Halmstad University, Sweden; Anders Åhlander, Saab AB, Sweden; Bertil Svensson, \nHalmstad University, Sweden\nTPb-8.8 ALGORITHM AND ARCHITECTURE CO-DESIGN OF MIXTURE  ..................................................1815\nOF GAUSSIAN \(MOG States; Robert Bushey, Analog Devices Inc., \nUnited States; Gunar Schirner Schirner, Northeastern University United States\nTPb-8: MULTIUSER MIMO SYSTEMS\nTPb-8.1: MULTI-USER MIMO SCHEDULING IN THE FOURTH 1855\nGENERATION CELLULAR UPLINK\nNarayan Prasad, NEC Laboratories America, Inc., United States; Honghai Zhang, Google, United \nStates; Hao Zhu University of Illinois at Urbana-Champaign, United States; Sampath Rangarajan, \nNEC Laboratories America Inc., United States\nTPb-8.2: OPTIMAL DOF REGION OF THE TWO-USER MISO-BC WITH 1860\nGENERAL ALTERNATING CSIT\nJinyuan Chen, Petros Elia Eurecom, France\nTPb-8.3: EXPLOITING SPATIAL SPECTRUM HOLES IN MULTIUSER 1865\nMIMO SYSTEMS\nFeeby Salib, Karim Seddik, American University in Cairo, Egypt\nTPb-8.4: DEGREES OF FREEDOM ACHIEVED USING SUBSPACE 1869\nALIGNMENT CHAINS FOR THREE-CELL NETWORKS\nGokul Sridharan, Wei Yu, University of Toronto, Canada\nTPb-8.5: INTERFERENCE ALIGNMENT FOR MISO BROADCAST  ...............................................................1875\nCHANNELS UNDER JAMMING ATTACKS\nSaiDhiraj Amuru, Ravi Tandon, R. Michael Buehrer, T. Charles Clancy, Virginia Tech, United States\nxxix\nTPb-8.6: PERFORMANCE STUDY OF MRC AND IRC WEIGHTS IN 1880\nLTE/LTE-A SYSTEMS WITH INTERFERENCE MANAGEMENT\nThomas Svantesson, ArrayComm, United States\nTPb-8.8: A SYSTEM-LEVEL STUDY ON MULTI-USER MIMO 1885\nTRANSMISSION FOR DENSE FDD NETWORKS\nLars Thiele, Martin Kurras, Kai Börner, Thomas Haustein, Fraunhofer HHI, Germany\nTPb-8.9 DIVERSITY-MULTIPLEXING TRADEOFF OF MIMO LINEAR 1890\nPRECODING\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nTPb-8: ELECTROPHYSIOLOGY AND BRAIN IMAGING\nTPb-8.1: JOINT COMPRESSION OF NEURAL ACTION POTENTIALS AND 1823\nLOCAL FIELD POTENTIALS\nSebastian Schmale, Benjamin Knoop, Janpeter Hoeffmann, Dagmar Peters-Drolshagen, Steffen Paul, \nUniversity of Bremen, Germany\nTPb-8.2 REDUCING THE EFFECT OF CORRELATED BRAIN SOURCES IN  ...............................................1828\nMEG USING A LINEARLY CONSTRAINED SPATIAL FILTER BASED ON MINIMUM \nNORM\nJosé Alfonso Sánchez De Lucio, David M Halliday, University of York, United Kingdom\nTPb-8.3: ONLINE BAYESIAN CHANGE POINT DETECTION ALGORITHMS 1833\nFOR SEGMENTATION OF EPILEPTIC ACTIVITY\nRakesh Malladi, Rice Unviersity, United States; Giridhar P Kalamangalam, University of Texas Health \nScience Center, United States Behnaam Aazhang, Rice Unviersity, United States\nTPb-8.4: SPIKING NEURAL NETWORKS BASED ON LIF WITH LATENCY 1838\nSIMULATION AND SYNCHRONIZATION EFFECTS\nGian Carlo Cardarilli, Alessandro Cristini, Marco Re, Mario Salerno, Gianluca Susi, University of \nRome Tor Vergata Italy\nTPb-8.5: TIME-FREQUENCY ANALYSIS OF BRAIN ELECTRICAL SIGNALS 1843\nFOR BEHAVIOUR RECOGNITION IN PATIENTS WITH PARKINSON’S DISEASE\nHuaiguang Jiang, Jun Jason Zhang, University of Denver, United States; Adam Hebb, Colorado nNeurological Institute, United States; Mohammad H. Mahoor, University of Denver, United States\nTPb-8.7: A MEASURE OF CONNECTIVITY IN THE PRESENCE OF 1848\nCROSSTALK\nSergul Aydore, Syed Ashrafulla Anand Joshi, Richard M Leahy, University of Southern California, \nUnited States\nWAa-1: MIMO INTERFERENCE MANAGEMENT\nWAa-1.1: DEGREES OF FREEDOM FOR THE CONSTANT MIMO 1897\nINTERFERENCE CHANNEL WITH COMP TRANSMISSION\nCraig Wilson, Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United 


States\nWAa-1.2: DYNAMIC INTERFERENCE MANAGEMENT 1902\nAly El Gamal Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United States\nWAa-1.3: A MUD/RATE SELECTION TOOL FOR COGNITIVE RADIOS IN  ..................................................1907\nPACKET BASED ASYNCHRONOUS GAUSSIAN MULTIPLE ACCESS CHANNELS\nPrabahan Basu, Rachel Learned, MIT Lincoln Laboratory, United States\nWAa-1.4: PRECODER DESIGN FOR FRACTIONAL INTERFERENCE 1912\nALIGNMENT\nHari Ram Balakrishnan, Giridhar K Indian Institute of Technology Madras, India\nWAa-2: OFDM\nWAa-2.1: MIMO-OFDM OUTAGE CHANNEL CAPACITY WITH PRACTICAL  .............................................1919\nIMPERFECT CSI\nMarko Kocic, MIT Lincoln Laboratory, United States; Nicholas Chang, Applied Communication \nSciences, United States; Matthew Ferreira MIT Lincoln Laboratory, United States\nxxx\nWAa-2.2: BIASED ESTIMATION OF SYMBOL TIMING OFFSET IN OFDM 1924\nSYSTEMS\nRohan Ramlall, University of California, Irvine United States\nWAa-2.3: A FACTOR-GRAPH APPROACH TO JOINT OFDM CHANNEL 1929\nESTIMATION AND DECODING IN IMPULSIVE NOISE CHANNELS\nMarcel Nassar, University of Texas at Austin, United States; Philip Schniter, The Ohio State University, \nUnited States; Brian Evans, University of Texas at Austin, United States\nWAa-2.4: WIDELY LINEAR DATA ESTIMATION FOR UNIQUE WORD  ........................................................1934\nOFDM\nMario Huemer, Alexander Onic, Christian Hofbauer, Stefan Trampitsch, Johannes Kepler University \nLinz Austria\nWAa-3: ADAPTIVE FILTERING\nWAa-3.1: A GRADIENT-CONTROLLED PROPORTIONATE TECHNIQUE FOR 1941\nACOUSTIC ECHO CANCELLATION\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nWAa-3.2: INTERFERENCE IDENTIFICATION IN CELLULAR NETWORKS  .................................................1946\nVIA ADAPTIVE PROJECTED SUBGRADIENT METHODS\nKonstantin Oltmann, Renato L. G. Cavalcante, Slawomir Stanczak, Martin Kasparick, Fraunhofer \nHeirinch Hertz Institute, Germany\nWAa-3.3: A RECONSIDERATION OF IMPROVED PNLMS ALGORITHM 1951\nFROM METRIC COMBINING VIEWPOINT\nOsamu Toda, Masahiro Yukawa, Keio University, Japan\nWAa-3.4: DETECTION PERFORMANCE OF MATCHED TRANSMIT 1956\nWAVEFORM FOR MOVING EXTENDED TARGETS\nRic Romero, Naval Postgraduate School, United States\nWAa-4: RELAYING AND COOPERATION\nWAa-4.1: TWO-WAY AMPLIFY-AND-FORWARD RELAY STRATEGIES  .......................................................1963\nUNDER RELAY POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon, Edwin M. Sawan, Wichita State University, United States Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nWAa-4.2: GAUSSIAN INTERFERING RELAY CHANNELS...............................................................................1968\nHieu T. Do, Tobias J. Oechtering, Mikael Skoglund, KTH Royal Institute of Technology, Sweden; Mai \nVu, Tufts University, United States\nWAa-4.3: THROUGHPUT IMPROVEMENTS FOR CELLULAR SYSTEMS 1973\nWITH DEVICE-TO-DEVICE COMMUNICATIONS\nPhuongBang Nguyen, Bhaskar D. Rao, University of California, San Diego, United States\nWAa-4.4: COOPERATIVE SIMULTANEOUS LOCALIZATION AND  ...............................................................1978\nSYNCHRONIZATION: A DISTRIBUTED HYBRID MESSAGE PASSING ALGORITHM\nBernhard Etzlinger, Johannes Kepler University, Austria; Florian Meyer, Vienna University of \nTechnology, Austria; Andreas Springer, Johannes Kepler University, Austria; Franz Hlawatsch, Vienna \nUniversity of Technology, Austria; Henk Wymeersch, Chalmers University of Technology Sweden\nWAa-5: IMAGE ANALYSIS AND PROCESSING\nWAa-5.1: MULTISCALE AM-FM IMAGE RECONSTRUCTIONS BASED ON 1985\nELASTIC NET REGRESSION AND GABOR FILTERBANKS\nIoannis Constantinou, University of Cyprus, Cyprus; Marios Pattichis, University of New Mexico, \nUnited States Constantinos Pattichis, University of Cyprus, Cyprus\nWAa-5.2: COLORIZATION BASED ON PIECEWISE AUTOREGRESSIVE 1990\nMODEL\nYasuhiro Nakajima, Takashi Ueno, Taichi Yoshida, Masaaki Ikehara, Keio University, Japan\nWAa-5.3: IMAGE DENOISING BY ADAPTIVE DIRECTIONAL 1995\nLIFTING-BASED DISCRETE WAVELET TRANSFORM AND QUANTIZATION\nNaoki Furuhashi, Azusa Oota, Taichi Yoshida, Masaaki Ikehara, Keio University Japan\nxxxi\nWAa-5.4: INTRODUCING DIVERSITY TO NORMALIZED CROSS 2000\nCORRELATION FOR DENSE IMAGE REGISTRATION\nNafise Barzigar, Aminmohammad Roozgard, Pramode Verma, Samuel Cheng, University of Oklahoma nUnited States\nWAa-6: MULTI-SENSOR SIGNAL PROCESSING\nWAa-6.1: WHY DOES DIRECT-MUSIC ON SPARSE-ARRAYS WORK 2007\nP. P Vaidyanathan, Piya Pal, California 


Institute of Technology, United States\nWAa-6.2: ASYMPTOTICALLY OPTIMAL TRUNCATED HYPOTHESIS TEST 2012\nFOR A LARGE SENSOR NETWORK DESCRIBED BY A MULTIVARIATE GAUSSIAN \nDISTRIBUTION\nJiangfan Zhang, Rick Blum, Lehigh University, United States\nWAa-6.3: A JOINT LOCALIZATION AND SYNCHRONIZATION TECHNIQUE  ............................................2017\nUSING TIME OF ARRIVAL AT MULTIPLE ANTENNA RECEIVERS\nSiamak Yousefi, Xiao-Wen Chang, Benoit Champagne, McGill University Canada\nWAa-6.4: REDUCING THE FRACTIONAL RANK OF INTERFERENCE WITH 2022\nSPACE-TIME-FREQUENCY ADAPTIVE BEAMFORMING\nShawn Kraut, Adam R. Margetts, MIT Lincoln Laboratory, United States; Daniel Bliss, Arizona State \nUniversity, United States\nWAa-7: COMMUNICATION SYSTEM DESIGN\nWAa-7.1: IMPLEMENTATION OF SELECTIVE PACKET DESTRUCTION ON 2029\nWIRELESS OPEN-ACCESS RESEARCH PLATFORM\nStephen Hughes Bosheng Zhou, Roger Woods, Queen’s University Belfast, United Kingdom; Alan \nMarshall, Unievrsity of Liverpool, United Kingdom\nWAa-7.2: EFFICIENT ERROR-AWARE POWER MANAGEMENT FOR 2034\nMEMORY DOMINATED OFDM SYSTEMS\nMuhammad S Khairy, Ahmed M. Eltawil, Fadi J. Kurdahi, University of California, Irvine, United \nStates; Amin Khajeh Intel labs, United States\nWAa-7.3: FPGA IMPLEMENTATION OF A MESSAGE-PASSING OFDM 2041\nRECEIVER FOR IMPULSIVE NOISE CHANNELS\nKarl Nieman, University of Texas at Austin, United States; Marcel Nassar, Samsung Information \nSystems America United States; Jing Lin, Brian Evans, University of Texas at Austin, United States\nWAa-7.4: MOBILE TRANSMITTER DIGITAL PREDISTORTION:  ...................................................................2046\nFEASIBILITY ANALYSIS, ALGORITHMS AND DESIGN EXPLORATION\nMahmoud Abdelaziz, Tampere University of Technology, Finland Amanullah Ghazi, University of \nOulu, Finland; Lauri Anttila, Tampere University of Technology, Finland; Jani Boutellier, University of \nOulu, Finland; Toni Lähteensuo, Tampere University of Technology, Finland; Xiaojia Lu, University of \nOulu, Finland; Joseph R. Cavallaro, Rice University, United States; Shuvra Bhattacharyya University \nof Maryland, United States; Markku Juntti, University of Oulu, Finland; Mikko Valkama, Tampere nUniversity of Technology, Finland\nWAb-1: MIMO PROCESSING\nWAb-1.1: MMSE RECEIVE FILTERING FOR PRECODED MIMO SYSTEMS .................................................2057\nAhmed Mehana, Samsung Electronics, Co., Ltd United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-1.2: COVERAGE IN DENSE MILLIMETER WAVE CELLULAR  ............................................................2062\nNETWORKS\nTianyang Bai, Robert W. Heath, Jr., The University of Texas at Austin, United States\nWAb-1.3: LINEAR PRECODING FOR MIMO WITH LDPC CODING AND  .....................................................2067\nREDUCED RECEIVER COMPLEXITY\nThomas Ketseoglou, California State University, Pomona, United States; Ender Ayanoglu, University nof California, Irvine, United States\nxxxii\nWAb-1.4: OPTIMAL PILOT BEAM PATTERN DESIGN FOR MASSIVE MIMO 2072\nSYSTEMS\nSong Noh, Michael D. Zoltowski, Purdue University United States; Youngchul Sung, Korea Advanced \nInstitute of Science and Technology, Republic of Korea; David J. Love, Purdue University, United \nStates\nWAb-2: ADVANCES IN CODING AND DECODING\nWAb-2.1: EFFICIENTLY ENCODABLE NON-BINARY GENERALIZED LDPC  .............................................2079\nCODES\nNicholas Chang Applied Communication Sciences, United States; Marko Kocic, MIT Lincoln \nLaboratory, United States\nWAb-2.2 PRACTICAL NON-BINARY RATELESS CODES FOR WIRELESS 2084\nCHANNELS\nDavid Romero, Massachusetts Institute of Technology, United States; Nicholas Chang, Applied \nCommunication Sciences, United States; Adam R. Margetts Massachusetts Institute of Technology, \nUnited States\nWAb-2.3: ON THE OPTIMALITY OF POLAR CODES FOR THE 2089\nDETERMINISTIC WIRETAP CHANNE\nAli Fakoorian, A. Lee Swindlehurst, University of California, Irvine, United States\nWAb-2.4: DELAY-OPTIMAL STREAMING CODES UNDER 2094\nSOURCE-CHANNEL RATE MISMATCH\nPratik Patil, Ahmed Badr, Ashish Khisti, University of Toronto, Canada; Wai-Tian Tan Hewlett-\nPackard Labs, United States\nWAb-3: DETECTION\nWAb-3.1: ASYNCHRONOUS SIGNAL DETECTION IN 2103\nFREQUENCY-SELECTIVE NON-GAUSSIAN CHANNELS\nSaiDhiraj Amuru, Daniel Jakubisin, R. Michael Buehrer, Virginia Tech, United States Claudio da \nSilva, Samsung Electronics, Co., Ltd., United States\nWAb-3.2: AN INFORMATION THEORETIC CHARACTERIZATION OF THE  ................................................2108\nCHANNEL SHORTENING RECEIVER\nFredrik Rusek, Ove Edfors, Lund University, Sweden\nWAb-3.3: ITERATIVE MMSE-SIC RECEIVER WITH LOW-COMPLEXITY  ...................................................2113\nSOFT SYMBOL AND RESIDUAL INTERFERENCE ESTIMATIONS\nGuosen Yue, Narayan Prasad, Sampath Rangarajan, NEC Laboratories America, Inc., United 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



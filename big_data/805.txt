 Condition Monitoring of Induction Motors Using Wavelet Based Analysis of Vibration Signals   Jeevanand S Abraham T. Mathew Department of Electrical Engineering Department of Electrical Engineering National Institute of Technol ogy, Calicut National Institu te of Technology, Calicut  Kerala, India. E-mail jeeva.cts@gmail.com Kerala, India  E-mail atm@nitc.ac.in    Abstract  Condition monitoring of machines has its roots in the human ECG analysis for detecting cardiac arrhythmias.  Condition  monitoring  in  industry  is desirable   for   increasing   machinery   availability reducing  consequential  damage,  and  improving  the operational  efficiency.  This is very significant in industries that use heavy duty machines for various processes.  A  monstrous  three-phase  AC  induction motor to drive a city water supply pump or very big high power motors used in mills, huge generators for generating power in hydel plants etc. depict a few of them.  Also, for  safety  and  economic  considerations there  is  a  need  to  monitor  the  behavior of motors working in critical production processes as well. This paper demonstrates how the condition of an induction motor can be monitored by the analysis of the acoustic signal that represents the non-stationary vibration data. The analysis has been done using various signal processing  algorithms  and  a  robust  fault detection scheme  has  been  developed  using  the PSD  \(Power Spectral Density\ concept in Wavelet Decomposition   1. Introduction  Induction  machines  are  the  primary  source  of mechanical  power  in  industries  due  to  their rugged construction,  high  reliability  and  better efficiencies Early warnings on the physical condition of machines are important for increasing machinery availability reducing consequential damage, and improving the operational efficiency. Even though electrical sensing with an emphasis on analyzing the motor stator current have  been  utilized  widely,  vibration-based  condition monitoring   has   attracted   the   attention   of   many researchers working in the area of induction machines and  has  gained  industrial  acceptance,  as  vibration analysis techniques are quite effective in assessing a machine’s  health is clai m e d t h at v i bration monitoring is the most reliable method of assessing the overall health of a rotor system 5]. Mos t  m e t h ods are to analyze the vibration signal in either timedomain or frequency-domain.   Frequency-domain analysis is more attractive because it can provide more detailed information about the status of the machine  Du e  to th e  av erag ing p r oblem s in clas s i c  FFT  analysis,  there is  a good  chance that the significant lines which correspond to certain faults may be hidden The  STFT  \(Short  Time  Fourier  Transform\  has  the shortcoming that it uses a sliding window of constant width,  which  causes resolution problems in  analysis 7   T h e va r i a b l e t i m e r e so l u t i o n gi ve n b y t h e W a ve l e t  Transform makes it a good choice for analysis of quasi-steady vibration signals. The power-distribution function  resulting  from  a  wavelet  transformation appears to be the optimal method to be applied to nonstationary signals to show  changes  in the amplitude and  distribution  of  the  harmonic h i s PS D  concept has been tested in stator current analysis of the motor by the Authors in ch o f t h e w o r k don e  till now has been to identify faults like stator short circuiting, bearing damages and the broken rotor bars Electrical faults, which can go unnoticed in running conditions,   like   the   Single   Phasing   faults   and mechanical faults like the Loose Foundation bolts of the machine is equally dangerous for the motor health If the size of the motor is huge, the loose foundation bolts, if went unnoticed can even cause the destruction of the building in which the motor is kept. Also, the impact of variable load cond itions along with the faults mentioned has not been  discussed till  now  and that opens  up  an  area  to  investigate  how  the  PSD parameters change with load, along with the faults and whether  these  faults  can  be  identified  using  them under various load conditions The reasons behind failures in rotating electrical machines have their origin in design, manufacturing 
2008 Second International Conference on Future Generation Communication and Networking Symposia 978-0-7695-3546-3/08 $25.00 © 2008 IEEE DOI 10.1109/FGCNS.2008.22 75 


tolerance, assembly, installation, working environment nature of load and schedule of maintenance.  The induction  motor,  like  any  other  rotating  electrical machine,  is  subjected  to  both  electromagnetic  and mechanical forces T h e de s i gn of  m o tor is s u ch t h at  the interaction between these forces under normal conditions leads to a stable operation with minimum noise and vibrations. When the fault takes place, the equilibrium  between  these  forces  is  lost,  leading  to further  enhancement  of  the  fault.  Experiments  were conducted  on  real  induction  motor  and  the  better classification  results  were  obtained  using  the  PSD concept in wavelet analysis  2. Experimental Setup  The experimental setup has been created in lab using a 10HP motor.  The Monitran \(MTN 1130  piezoelectric accelerometer ha s been used for fetching the vibration data.    The motor was loaded directly using dynamometers. The Yokogawa’s DL1620  was used as the data acquisition system. A digital filter \(0 10 kHz bandwidth\, was used to remove the unwanted noise and useless overtones. The motor current, speed load and the vibration data were measured.  Only vibrations are used for analytical purposes.  The sampling rate set for recording the data was 50 kHz. A high sampling rate is desired to avoid aliasing and thereby to preserve the integrity of the data. A high speed USB device has been used for transferring the data from the instrument    Table 1. Machine details      3. Proposed Approach  The essence of the Fourier transform of a waveform is to decompose or separate the waveform into a sum of sinusoids of different frequencies. In the transformation towards the frequency domain, time information is lost. When observing the Fourier transform of a signal, it is impossible to distinguish when a given event took place. This is a serious drawback for fault diagnosis because of the nature of signals to be analyzed, which are likely to contain time-varying frequencies. The Fourier and the STFT gives us the area in which more detailed processing is required. Therefore it is a tool which can be used to obtain only surface level information. The drawbacks of Fourier and STFT approach has lead to the widespread use of wavelets for processing the data Wavelet analysis can reveal aspects of data that other signal analysis techniques fail to spot, such as trends breakdown points, discontinuities in higher derivatives and self-similarity l s o f o r m a ny decades  scientists have wanted more appropriate functions than the trigonometrical sines and cosines, which have been the basis of Fourier analysis, to approximate choppy signals. By their definition, these functions are nonlocal \(and stretch out to infinity\. They therefore do a very poor job in approximating sharp spikes. But with the advent of Wavelet analysis, we can use approximating functions that are contained neatly in finite domains. Wavelets are well-suited for approximating data with sharp discontinuities [9 l l  similar observations on the properties of wavelets make it an Ideal tool for our analysis CWT \(Continuous Wavelet Transform\ is defined as follows         dt t t x W    1         1 The constant 1    is used for normalization purposes  is the time delay and  is the scale The DWT of a function x  t be expressed as                 0 0 0     j j k j j k j j t k d t k c t x   2 In this expansion, the first summation gives a function that is a low resolution or coarse approximation of x  t cale 0 j  For each increasing j in the second summation, a higher or finer resolution function is added, which adds increasing details. The choice of 0 j sets the coarsest scale, whose space is spanned by  t k j  0     These    wavelet    coefficients,    under    certain conditions,   can   completely  describe  the  original function,  and  in  a  way  similar  to  Fourier  series coefficients,  can  be  used  for  analysis,  description approximation, and filtering. If the scaling function is well behaved, then at a high scale, samples of the 
76 


signal are very close to the scaling coefficients  The Methodology adopted is given as 1\     Acquiring the Vibration signal or Data 2\nalyzing the signal using the classic Fourier analysis 3\Processing the data using the best tool available for non-stationary signals  The Wavelet 4\hoosing the proper wavelet for   analysis 5\   Calculating   the   PSD   of   the   wavelet  decompositions and finding out the proper  Indicator for Healthy or Faulty conditions  3.1. FFT Analysis  The FFT analysis of the data was performed by taking sets of 65536 samples of data, and averaging of FFT was done to remove unwanted noise and to make significant lines sharper. The FFT analysis is performed with a high frequency resolution of 0.76 Hz   Figure 1. Vibration data obtained for healthy condition    Figure 2. FFT for healthy condition  Figure 3. Vibration data obtained for single phasing    Figure 4. FFT for single phasing condition  The FFT analysis of the signature of the motor is shown in Figure 2 and Figure 4. From Figure 2 we can see that, there are no significant overtones pertaining to the machine signature after 10 kHz. Therefore, the data corresponding to the actual signature of the machine is in the range of \(0-10\Hz. Similar FFT’s were obtained for Loose Foundation bolts as well. For a 4pole, 50 Hz motor operating from 50 Hz and running at a speed of 1500 RPM, the following vibration frequency components will dominate under the Single Phasing condition: F1 = 1500/60 Hz; F2 = 2*50-\(50/3 Hz; F3 = 2*50 Hz; F4 = 2*50+\(50/3\ Hz; F5 = \(4*50    Table 2. Comparison of frequency magnitudes   Table 2 shows the dominance of frequency lines in most of the cases, as expected. Also, it is seen that, the loose foundation bolts condition is also showing a hike in the respective frequencies, especially at 200 Hz. But these cannot be taken as clear diagnostic information due to the averaging problems of FFT. Also, under the loaded conditions, these results were not found to follow  
77 


3.2. Wavelet Analysis of the Data  Two wavelets were selected for processing. To avoid overlapping between two adjacent frequency bands, a high-order mother wavelet that results in high order frequency filter should be used [8 h eref o r e Daubechies10 was selected as suggested by these authors. But, upon detailed investigation, it was found that the response of the wavelet was poor for lower order frequency bands. Similar results were obtained for other wavelets of Daubechies family like DB6. The data was downsampled by 2 before processing. After downsampling, 32768 data points were taken for further processing. Four such sets have been chosen for all investigations and comparisons. The PSD values did not show any significant changes in the lower frequency bands, where changes do occu 7 du e to electrical faults, when DB family was used. Also for the mechanical fault considered here, it was not found to be a suitable choice. Next, the Morlet wavelet was tested. This was also suggested by the authors for electrical faults [6 n d er n o l o a d co n d itio n  T h is  choice proved to be good one for fault detection under no-load and loaded conditions and also for the mechanical fault. An efficient Load Indicator was found using the proposed wavelet based PSD analysis Only analysis using the Morlet wavelet is discussed further  Table 3. Wavelet frequency bands for analysis   4. Experimental Results  The classic Fourier analysis has shown hikes in most of the respective frequency levels. Due to the shortcomings of this classic analysis in non-constant frequency signals, like vibrations, the wavelet based PSD analysis was done using the Morlet wavelet  Case 1: Normal condition with increasing Torque  The motor is run under balanced three phase voltage and vibration data is collected for normal conditions under no-load and then under different loads  Figure 5. Variation of PSD’s for various scaling factors for Morlet CWT under no- load  The Bar graph shown in Figure 5 indicates the  PSD values in for the no-load condition. There are  slight variations in the value of PSD in one scale itself. So, we are taking the average values, to take into account the variations that occur. It is seen that the Morlet wavelet has a good response to higher scales which was not there for the Daubechies family of wavelets, due to which the changes at these levels were not getting reflected. This makes Morlet a better choice for analysis   Figure 6. Variation of PSD’s for various scaling factors for Morlet CWT: heavy load  It can be seen from Figure 5 and Figure 6 that the PSD at scaling level six rises with load. From no-load to heavy load, this was found to show a linear rise in the value. The average PSD values were found to rise from 4.933349 J for no-load to 14.01358 J for the heavily loaded condition. Even though PSD values for other Scaling factors do change, only the level six scaling and the corresponding PSD could act as the load indicator under Healthy and Faulty Conditions Case 2: Single phasing condition and increasing Torque 
78 


 The electrical faults affect the lower order frequency ranges of the vibration data. Therefore, in the Single Phasing condition we expect a hike in the average PSD values in the higher scales. The fault was created by connecting a switch in one of the phases and opening it during motor running condition   Figure 7. Variation of PSD’s for various scaling factors for Morlet CWT under single phasing no-load  Figure 8. Variation of PSD’s for various  scaling factors for Morlet CWT under  single phasing Medium-load   From Figure 7 it is clear that, a noticeable hike in PSD is there in the 50.78125 - 25.3906 Hz range. The average energy value was found to be 103.01 J for the four sets of data, for no-load condition. For the loaded  condition the values of PSD for scaling factors four and five were found to be excellent indicators of the fault. The average value of PSD at fourth scaling factor varied from 26.58916 J to 44.89249 J from no-load to higher loaded conditions. It can be seen that in Figure 8, the PSD in fourth scaling factor has a notable rise under load with an average value of around 50 J. In Normal Condition it ranged from 18.66039 J to 25.87709 J only. PSD at the fifth scaling was found to increase with load, which was the reverse trend in case of healthy condition. Both of these with average PSD for ninth scaling factor \(For no-load\ were found to be excellent indicators of the fault for all conditions Case 3: Loose foundation bolts and increasing Torque  The Foundation Bolts of the machine were loosened. The machine was run under unloaded and loaded conditions, and the vibrations were fetched   Figure 9. Variation of PSD’s for  various scaling factors for Morlet CWT  under loose foundation \(light load  In Figure 9, the value of PSD for different scales in Light-load condition is shown. We can see that PSD for the fourth scaling factor has a high average value which is a good indicator for the fault. Same PSD was found to be a sufficient indicator of the fault for higher load conditions. Even though this fault indicator is good enough to detect the fault, it has an overlap with the Single Phasing condition, under light load \(below 10% load\. It may be noted that the PSD value corresponding to the sixth scaling factor was found to be a good load indicator in fault conditions as well   5. Conclusion  This paper presents the methods for the online detection of Induction motor faults based on wavelet based PSD analysis of the vibration data. The method is useful for effective online monitoring and diagnosis in industrial applications. The experiments performed and the results obtained show that wavelet based PSD analysis achieves good results in the field of fault diagnosis for every operating point of the induction motor The PSD method which has been experimented for faults like broken rotor bars and shorted stator 
79 


windings has proved to be a good indicator in case of other potential faults like Single Phasing and Loose Foundation bolts, under various load conditions. More investigation with no-load and variable load conditions may be done with different motors to make the results obtained more concrete  6. References  1  H. Su and K. T. Chong, “Induction machine condition monitoring using neural network modeling”, IEEE Transactions on Industrial Electronics, vol.  54, no.  1, pp 241-249, February   2007  2  J. S. Mitchell Introduction to Machinery Analysis and  Monitoring 2 nd ed. Tulsa, OK: Pennwell, 1993  3  R. A. Munoz and C. G. Nahmias, “Mechanical vibration of three-phase induction motors fed by non sinusoidal currents,” in Proc.  Int.  Power  Electron.  Congr pp.166172, 1994 4  F.Filippetti, G. Franceschini, C. Tassoni and P Vas Broken bar  detection  in  induction  machines  Proc  IEE-IAS Annu. Meeting Conf vol. 1, pp. 95-102 1994  5  C.  M.  Riley,  B.  K.  Lin,  T.  G. Habetler,  and  R.  R Schoen, “A method for sensorless on-line vibration monitoring of induction machines IEEE  Trans. Ind  Applicat vol. 34, pp. 1240-1245, Dec. 1998  6  Giovanni Betta  Consolatina Liguori, Alfredo Paolillo and  Antonio Pietrosanto, “A DSP-Based FFT-Analyzer  for the  fault  diagnosis  of  rotating  machine  based  on  vibration analysis IEEE     Transactions on I nstrumentation and Measurement vol.  51, no.  6, pp 1316-1322, Dec. 2002  7  G. K. Singh, Saleh Al Kazzaz Sa’ad Ahmed, “Vibration signal analysis using wavelet transform for isolation and identification of electrical faults in induction machine  Electric Power Systems Research vol. 68, pp. 119-136, 2004  8  Jordi Cusido, Luis Romeral, Juan A. Ortega, Javier A Rosero, Antonio Garcia Espinosa, “Fault detection in induction  machines  using  power  spectral  density  in  wavelet decomposition IEEE   Transactions   on  Industrial Electronics vol 55,  no. 2,  pp 633-643  February 2008  9  Amara Graps An Introduction to wavelets IEEE Computational science and Engineering pp. 50-55  Summer1995  10  Ali M.  Reza,  Spire  Lab,  UWM From Fourier Transform  to  Wavelet  Transform”,  WHITE PAPER  IEEE,pp. 3-17, October 27,1999         
80 


sequences into a finite state machine The controller of the machine can be defined for executing and monitoring the actions in the plan The transformation of plans into executable sequences is facilitated utilizing the distinction between abstract plans and concrete plans Abstract plans identify the actions and temporal structure of the plan without providing the details of how the sensor web resources are invoked to carry out the plan Concrete plans provide the details of accessing the resources and allow for the automation of the execution of the plans by a agent we called the web manager Future reports will describe the design and implementation of the web managers in detail REFERENCES 1 Michael Botts SensorML Standard for In-situ and Remote Sensors Proceedings of EOGEO-2004 College London London UK 2004 2 R Buyya D Abramson and J Giddy Nimrod/G:An Architecture of a Resource Management and Scheduling System in a Global Computational Grid HPC Asia 2000 Beijing China IEEE Computer Society Press Los Alamitos CA USA May 14-17 2000 3 INTEX-B Web site http://www.espo.nasa.gov/intex-b 4 C xml parser used in the Coordinator 5 Verma V Jonsson A Pasareanu C and latauro M Universal executive and plexil Engine and language for robust spacecraft control and operations In American Institute of Aeronautics and Astronautics Space 2006 Conference San Jose California 6 Nemani R Votava P Roads J White M Thornton P and Coughlan J Terrestrial observation and prediction system Integration of satellite and surface weather observations with ecosystem models In Proceedings of the 4th International Conference on Integrating GIS and Environmental Modeling GIS/EM4 Banff Canada 2000 BIOGRAPHY Dr Robert Morris is a senior researcher in Computer Science in the Exploration Technology Directorate Intelligent Systems Division at NASA Ames Research Center His primary professional goal is the application of advanced Al technology in planning scheduling and plan execution to the Investigator of a project for coordinating the activities of distributed remote sensor webs for observing the Earth His primary research interests include temporal constraint-based reasoning for automated planning and scheduling Dr Jennifer L Dungan is a research scientist with NASA's  1.1.1 ar Ames Research Center at Moffett Field CA Her expertise is in the use of physically calibrated measurements from remote sensing to predict biophysical variables using spatial statistical approaches She was one of the first to apply geostatistical techniques of stochastic interpolation to spatially complete remote sensing data for predicting vegetation amount She has contributed to the development of rigorous frameworks for scaling and uncertainty in remote sensing science She has had long experience with processing Landsat MSS and Thematic Mapper and many other EOS data types She serves on the editorial boards of Remote Sensing of Environment and the International Journal of Applied Earth Observation and Geoinformation Mr Petr Votava is a senior software engineer at NASA Ames Research Center and CSUMB He has been a software engineer on NASA's MODIS team for Ithe past 10 years His primary research interests include operating systems X distributed computing computer architecture and natural language processing Dr Lina Khatib is a research scientist at Perot Systems Government Services She is a member of the Planning and Scheduling Group Intelligent Systems Division at NASA ARC Her interests are in constraint reasoning and preferences heuristic search temporal reasoning intelligent planning and scheduling Her main goal is to put advances in Al into practice Among other projects she was the main developer of the Global Map Generator for USGS that optimizes selection of satellite images for complete earth coverage llll   next generation of NASA's exploration systems He is currently Principal 7 


  8 often have long run times. Depending on the temporal and spatial range of data requested, processing wall-clock times may range from minutes to weeks. The notion of a service call changes from a quick \223getting\224 of a data product, to an 223ordering\224 of a product. The normal synchronous aspect of the services must then be changed to an asynchronous model Job Management Additionally with long-running services, there will inevitably be overlapping processing times on the server Therefore given the finite computing resources available overloading the computational resources with simultaneous service requests should be avoided. We require the ability to define the appropriate level of computational resources to be utilized and want any remaining service requests to be queued until sufficient computing resources are available This then maximizes processo r utilization of each service request Distributed resource management \(DRM\stems can be leveraged to manage the distribution of workload to available compute resources Each Web Service request would map to a job request on the processing server. DRMs can monitor the current state of all resources and assign the jobs to the best-suited resources Rather than directly interfacing with one specific DRM implementation, we leveraged the Open Grid Forum\222s Distributed Resource Management Application \(DRMAA pronounced \223drama\224\API for job submission, monitoring control, and retrieval of resu lts Thi s l a nguage and vendor agnostic API frees us from language specific implementations, as well as vendor specific implementations of job management, and allows us to focus on the abstract representation of resource management This API is supported by several different vendors of job scheduling implementations, including Sun Grid Engine SGE and Torque.  Though bot h Torque and SGE fi t  our requirement of an open source scheduler, Torque is still based on an older PBS implementation and does not offer the scalability and Java bindings that SGE does Asynchronous Services By default, a Web Service call is a synchronous call where a request is sent from the client to the server and blocks until a response is available to be sent back to the client \(figure 6\ut for long running processing routines, it is impractical to hold a network connection and block until the service has completed. A scientist on the client side may not be able to wait for the response after a completed longrunning job. We want to enable complete network disconnects where the client may be potentially shut down Additionally, service calls where seamless data access is intrinsic would require the gene rated data to be downloaded as well before the service call unblocks and completes. The client user would have to wait for both processing and downloading times There have been extensions to existing web services-based standards to augment with asynchronous capabilities. WSNotification, a standards-base d approach to enable eventdriven capabilities to Web Se rvices using the publishsubscribe pattern. OASIS\222 Web Services Notification WSN\ses this notification pattern to allow subscribing to a Web Service\222s event information and be notified of such information. OGC\222s Web Pr ocessing Service \(WPS spatially referenced data have been augmented with  OGC\222s W e b Notification Service \(WNS\so provides messaged-based notifications between services. By using client-side modules, each web service client can receive notifications without resorting to polling. However, all of these approaches require a richer set of clients that may only be available in Web Service-rich language platforms such as Java. Our goal requires that our asynchronous solution work in more simpler and less rich platforms such as C and IDL What we desire is a simpler approach that minimizes clientside requirements of running any form of a messaging server. Preferably, the solution should be simple enough to work with clients that have a minimal capable of doing HTTP GET, such as a basic REST service call  Figure 6. Sequence diagram showing potentially long blocking calls for long processing times from Web Services Asynchronous Services using Web Services A more desirable model of behavior would be to use Asynchronous Web Services \(figure 7\he one synchronous blocking call is par titioned into smaller atomic Web Service calls. The Apache Axis2 project and Sun\222s JAX-WS Reference Implementation provide a set of asynchronous atomic calls that allow a service client to submit a service, check if it is done, and then get the results 


  9 when it is done. However, even this model does not fit the desired model of behavior  Figure 7. Sequence diagram showing the push and pull methods from Asynchronous Web Services  Asynchronous Web Services can use either a Synchronous or Asynchronous MEP \(Message Exchange Protocol transmitting and receiving protoc ol messages.  There are two methods supported for both synchronous and asynchronous MEP types:  polling and callback. Both support non-blocking client side behavior The polling method represents the \223pull\224 model of processing where the client determines when the response is received.  The callback method has the client passing a callback handler to the Web Service Endpoint. This callback is essentially an endpoint on the client side running in a separate thread that waits for the server to respond.  The callback method represents the \223push\224 model of processing where the server determin es the notification For polling-based asynchronous MEP, we find that the client still needs to be active while it polls. That is, a service submission would normally return a response object that is used to check if the job is done. That same response object is also used later to retrieve the results when available. For long duration processing times, the client must still maintain the same response object. Though the response object may in principle be marshalled out for longer persistence implementation-specific network connection reliance be prove to be impractical. The preferred approach would be to move the role of asynchronous waiting from the Web Services request/response objects down further to the job scheduler The remaining option would be to use normal synchronous Web Service calls, but cleanly se parate the different atomic operations into individual synchronous Web Service calls These individual calls consists of submitting a job canceling a job, getting the status of the job \(running cancelled, etc\ting the progress of the job \(console output, etc\and finally getting the results of the job \(figure 8\ Each synchronous call is then delegated to an underlying job manager for the actual service job management. Collectively, the client is provided with an asynchronous service model For particularly long running service jobs, we find that users also want to see progress of the processing activity. In addition to getting the status of the job state \(such as queued, running, done, cancelled\so provide the capability to see progressive real-time output form the processing job. Our service endpoint manages a console buffer of a processing job\222s STDOUT/STDERR. When a Web Service call to get the progress of a particular job is invoked, the current buffer contents of the progress is returned and then flushed from the server-side buffer. This enables clients to build GUI applications on top of this asynchronous service and see the real-time console output of the server-side processing on their client GUI window Additionally, the console refresh rate, determined by the client, can be adjusted to an appropriate rate for that client\222s usage. Other approaches are possible including publishing the progress to a custom Atom feed. But here, the console content is only handled and retrieved when the client needs it  Figure 8. Sequence diagram showing atomic synchronous calls that implement job management capabilities of a service  Though callbacks \(registerable handlers\ally the preferred paradigm over polling, this client example demonstrates the utility of keeping it simple. We require maintaining a set of lightweight Web Service clients across multiple platforms. Not all platforms and Web Service APIs support asynchronous Web Services. For true callbacks 


  10 implementations would also require the clients to run Web Service endpoints of their own This asynchronous service model that is composed of synchronous atomic Web Service calls can also be used at varying levels of complexity as desired by the client user For the novice, the service \223submit-isDone-get\224 sequence can be encapsulated into one simple function call. For the intermediate user, the same aggregated function call can also provide real-time notifications \(Observer design pattern\job currently running on the server. For the advance user network disconnects and client shutdown after a service job has been submitted can be achieved. The unique job id that is returned upon service submission can be stored for persistence enabling users to submit a product request from laptop, shutdown their laptop, and restartup at later time to retrieve the generated products Using AXIS2 and JAX-WS for the various client-side implementations introduces an extra dependency for users of some clients and therefore is less preferable. We also want to maximize ease-of-use for the user where we lessen the burden of installation, set up, and library dependencies Whenever possible, we used the \223vanilla\224 SOAP implementation that is intr insically available for each platform to keep the client footprints small Another intended use of our services is to be orchestratable by Web Services-enabled workflow engines. The callback approach to asynchronous Web Services is currently not as interoperable as standard synchronous Web Services However, current Web Service workflow engines can be set up to operate with standard Web Services that have the atomic actions exposed as multiple synchronous Web Service calls that poll for when a job request is done before continuing Data Delivery Once processing has completed, the service response is returned to the user. In th e Earth science domain, these results typically are generated data products that may be large in size. Given that the SOAP approach to Web Service uses XML as the underlying content being transferred transferring binary data in the SOAP message would not be efficient for large binary data sizes. Large binary file data support in XML currently still exhibits technical and performance issues. Approaches ex ist to encode binary data in various encoding schemes such as MIME and base64 More recently, there have b een new W3C recommendations for handling large binary data transfers such as XML-binary Optimized Packaging \(XOP Transmission Optimization Mechanism \(MTOM and Resource Representation SOAP Header Bl  However these new extensions may not be supported or compatible with all the client platforms that we need to support \(such as Matlab, IDL, and Python We settled on an approach that is compatible across the major client platforms. Rather then forcing data to be encoded in any scheme in SOAP, we simply allow the binary data to be transferred efficiently in standard http/https. When a Web Service job has completed, the generated product data files are placed in a unique URLaccessible location, and these UR Ls are sent back in the service response. The clients are then responsible for downloading the product files from the URLs A side benefit of this approach is observed when orchestrating our services fro m workflows. The URL results from one workflow operator are passed onto the next operator, which then is responsible for pulling the data from the given URLs. This method allows each operator to control the rate of accessing th e previous operator\222s data results OPeNDAP Another mechanism we support for data access is Data Access Protocol  \(DAP\ore specifically, we leverage the  for requesting and transporting data that is generated by the services. OPeNDAP also enables remote subsetting of data using constraint expressions, and the translation of data from one format to another. HDF5 data has been recently shown to work well over OPeNDAP using the Hy  The OPeNDAP protocol in recent years has become more widely used and accepted in the Earth Science community The Earth System Grid \(ESG on Environment and Water \(CREW\two large Earth science data centers using OPeNDAP for data access Date Time Handling For time handling, leveraging the Java GregorianCalendar simplifies handling timezones, time ranges, as well as correct leap years.  The bus iness logic model layer fully leverages the GregorianCalendar model to allow us to support manipulating multiple time granules, from seconds to years, and of any duration for each time granule. There is also a related XMLGregorianCalendar that we leverage for representation of W3C XML Schema 1.0 date/time datatypes across the Web Services For averaging, given a particular start and end time in GregorianCalendar format, along with an integer time duration amount, the model is able to determine the correct time ranges \(i.e. number of averaged files\d partitions the work accordingly for the av eraging engine \(in this case the engine is IDL\anCalendar individual time elements are retrieved and passed on to the engine for 


  11 processing, and the result is a list of files that propagates up to the server side layer For subsetting, latitude and longitude values are handled at the model layer, and translated \(when necessary correct coordinate values for the underlying engine.  Also to reduce the number of parameters a user would need to provide, we support user inputs of date/time string using the ISO 8601 format, the International Standard for the representation of dates and tim For exam pl e t h e input string \2232008-10-31T12:00:00Z\224, would be converted into a GregorianCalendar inst ance representing that exact date/time for the model layer Using the combination of GregorianCalendar and the ISO 8601 standard allows us to easily handle timezone-aware and timezone-na\357ve inputs. Internally to our \223business logic\224 model layer, all date/times are timezone-aware and set to the UTC timezone to match most of the instrument data conventions. But if the user provides a timezone-na\357ve date/time, that is with no timezone specified, then we promote it to UTC standard time. We also support user input in any timezone here we leverage the GregorianCalendar to convert any timezone to the UTC internal representation This simplifies science studies where users simply provide the local time at the area of interest to query data for  7  C LIENT I MPLEMENTATION FOR A NALYSIS E NVIRONMENTS  We implemented client-side modules to adapt to the major working environments favored by most scientists: \(1 4\thon, \(5\/C++, and \(6 Fortran90. Unlike other approaches that force the scientists to leave their familiar working environment to access data our services tool set brings the data access and manipulation back into their working envi ronments. Whenever possible we also aimed to develop the ability to automatically download and construct the native data objects in each respectively environment. This eliminates the need for the end user to worry about data file downloads, local file management, and loading them into in-memory data arrays for manipulation. A consistent experience is given to the user, both across the different tools and across the different platforms, with common interfaces and usage conventions This form of seamless integration directly facilitates the transparent access and manipula tion of heterogeneous data as called for by NASA\222s ACCESS NRA goals Java The Java client was designed to be an importable jar library from any user Java application. Since the Web Service endpoint server was already written with Sun\222s JAX-WS Reference Implementation, we also chose the same for the Java client implementation. This maximizes interoperability since both client and server utilize the same library. The client contains high-level methods for calling the Web Service and automatically downloading the custom-created files, allowing the entire process of service querying and downloading data to be contained in a single method call Lower level methods are also exposed in the service allowing the user more fine-grain control over the data flow and interface with the Web Services Matlab Mathwork\222s Matlab is a popular working environment used by scientists to perform science analysis. The 2008 release of Matlab has built-in support fo r Web Services with autocode-generation from WSDL URLs. It leverages the Java integration that Mathworks has already worked into Matlab We leveraged this built-in capability to develop Matlab modules that access the same server-side Web Services for Level 2 and Level 3 data access and manipulation Our Matlab service client consists of a number of .m files file extension for Matlab custom code\and requires no Java package dependencies beyond the JVM native to the Matlab environment.  Built-in SOAP functions help to create, send, and parse the SOAP message, which is used to communicate with our remotely hosted Web Services For automatic data file downloads, classes and methods standard with Java version 1.5 \(standard with Matlab 7.6 were used to access and download the files via http.  The resulting client allows all of the Web Services and downloading functionality to be transparent to a user Matlab supports the construction and handling of full Java data objects and the invocation of Java class methods directly form within Matlab. We made use of built-in functions that served as the bridge between a Matlab script and a SOAP service call \(createSoapMessage.m callSoapService.m, and parseSoapResponse.m\. These built-in SOAP functions in Matlab constrained us to passing a narrow range of Matlab data types due an incomplete set of Matlab datatype to W3C SOAP datatypes. Particularly the date-time and arrays of strings must be manually handled as more primitive types Two methods of datetime passing were settled upon.  One relies simply upon passing a tuple representation of datetime\227a number for the year, and others for the month, day hour, minute, and second.  While such a method worked well \(converting simple numerical data types\t was seen to be cumbersome and made for far less readable code to have to use six parameters to specify a single datetime.  We turned then using short char acter strings to represent datetimes, following the ISO 8601 standard.  Data type conversion of character strings between Matlab and XML is similarly easy as numerical types, and made for very concise and readable function calls 


  12 Passing arrays of strings required a retreat from any kind of array-like data structure.  Instead, a single, long string was created from an array of strings in Matlab, separated by a distinct delimiter \(a \223,\224 in this case\s single long string is passed through the service interface to the endpoint server, which then parses the string back into a list format before continuing on with the rest of the call sequence IDL ITT\222s IDL is another powerful visualization and analysis tool popular with the Earth science analysis community  Unl i k e M a t l a b, IDL \(as of versi on 7.0 have any built-in Web Services support. IDL can be made to speak the Web Services languages via an IDL-Java bridge delegating the Web Services capability to a linked Java library.  This does allow calling the Web Services, but there were some issues encountered along the way First, the IDL-Java bridge connectivity required some setup and handling by the end user. Environment variables and jar classpaths must be properly configured. While this is easily resolve with an installer, there was a strong desire to minimize the IDL client foot print to where there are no dependencies. We wanted to provide an IDL client code that could be dropped into a directory somewhere and should \223just work\224 Second, there are some known issues working with objects in IDL. We encountered memory errors during execution which appeared to be a memory leak in the IDL-Java bridge there was previously a known memory leak that had been patched\also ex tra overhead when interfacing between IDL and Java where data is converted from Java objects to IDL types Our current effort is focused on building a \223poor man\222s\224 SOAP as part of our IDL client that will allow us to directly call and interface with the Web Services, without having to go through Java.  We plan to utilize IDL\222s built-in simple http support to send manually constructed SOAP messages Though this approach forgoes the robustness of the JAXWS implementation, it will however provide a pure IDL client to our end users with no external dependencies Python The Python scripting environment has become a popular working environment for fast prototyping and exploratory science processing. Among all of the clients here, the Python Web Services client is the most trivial. We leveraged the suds package, a lightweight SOAP client for consuming Web Services in Pyt Though ot her open-source Python Web Service packages exist \(such as ZSI\we have found suds to be the most easy to use and more dynamic in nature. Suds does not require class code generation and can read WSDLs at runtime to dynamically construct a proxy object with an interface representing the WSDL C/C We want any C/C++ client to be able to interact with the server-side Web Services of Level 2 and Level 3 data generation. By using the using the popular open-source gSOAP Toolkit for SOAP Web Services package  client-side modules can interact with the data generation services developed on the server-side. gSOAP also includes facilities to autogenerate C/C++ RPC code from our published WSDL definition files of the Web Service on the server. We have also found that gSOAP has a good selfcontained XML bindings facility Fortran Fortran90 modules can be made capable of remotely accessing and the Level 2 and Level 3 data. Though Fortran has no built-in libraries to perform Web Services, we leveraged our C/C++ Web Service API via gSOAP to do the work. Fortran can call an 223externed\224 C Web Service API and pass back the relevant data into the Fortran environment. This would enable Fortran to fully delegate the Web Services operations to the C/C++ implementation 8  NEWS  L EVEL 2  P RODUCTS  With the availability of the software infrastructure supporting server-side processing, and seamless client-side data query and access, downstream data products can now be generated from the source merged NEWS Level 2 data Averaged One of the most common wa ys to summarize the large amount of data is to calculate the averages of data within a given temporal and spatial boundary. For example, it is very useful for scientists to make daily, weekly, monthly averages of some parameters in a regular latitude-longitudepressure grid, make a global map of the average, and analyze any global patterns and trends. In order to facilitate the needs, we developed an averaging Web Service to generate averaged data products that a user can customize The input arguments for the averaging Web Service are the time range, time granule, and a list of parameter names to produce averaged products with. The time range specifies the start and end time to access the NEWS data from. The time granule specifies the aver aging time period. The list of parameter names specifies the choice of parameters that are requested to make averaged products Subsetted Subsetting a data set is a fundamental way to access specific data from a large collection of data. We developed a usercustomizable subsetting Web Service that supports three general subsetting conditions 1  Spatial condition \(latitude, longitude, vertical range 


  13 2  Temporal condition \(e.g. from 2002-05 to 2002-07 3  Parameter selection \(e.g. te mperature and atmospheric water vapor only The combination of these three conditions allows a user to subset data in time, location, and parameter space 9  NEWS  L EVEL 3  P RODUCTS  Many of these quantities in NEWS L2 product interact through fundamental physical processes \(e.g. temperature affects cloudiness, and also the converse\ Consequently the observations should be treated as statistically separate variables, though traditiona l methods of summarizing satellite data do just that. We applied statistical clustering methods to a multiple-parameter set of observations from the A-Train instruments over the multi-year record. The resulting Level 3 quantitative summaries are made accessible through our serv ice-oriented tool Level 3Q Level 3Q data sets are statistical summaries of underlying Level 2 data. Like traditional Level 3 products they are 223gridded\224 in the sense that they provide a summary of Level 2 data belonging to space-time grid cells. These cells are typically defined as one or fi ve degree spatial regions over a time period of one or eight days, or one calendar month Unlike traditional Level 3 products, the Level 3Q \(L3Q grid cell summaries provide nonparametric multivariate estimates of the joint probability distributions of multiple geophysical parameters. Distribution estimates are derived from the underlying Level 2 data using informationtheoretic principles that balance the quality of the estimate against the amount of data reduction achieved  Figure 9. Raw and summarized data for one grid cell Raw data belonging to that grid cell can be listed in a data table with one row for each of N data points and one column for each variable \(here, two alternate representation: a scatter plot. In both cases each data point has weight 1. On the right are two representations of the compressed summary. The data table has K<<N rows and two extra columns showing cluster count and distortion. Counts are shown in the corresponding scatter plot by the bar heights  Data reduction replaces a larg e number of individual data points with a smaller number of representative data points and associated weights and quality measures. Figure 9 illustrates the basic concept. The idea is to treat a set of coincident measurement of different geophysical parameters for the same footprint as a multivariate vector, and collect all such vectors belonging to a given spatial-temporal grid cell as a set of points in high-dimensional data space. These data are partitioned into disjoi nt groups, called clusters, and we report the following statistic s for each: i\the centroid which is the representative, ii\he number or proportion of original data points assigned to it, and iii\the average squared distance between member data points and the centroid. This latter quantity is also called the cluster distortion The method that assigns data points to clusters is an adaptation of a signal-processing algorithm called Entropyconstrained Vector Quantizati EC VQ i s si m i l a r t o  the well-known K-means clusteri  Kmeans finds an assignment of raw data points to K clusters that minimize distortion. ECVQ finds an assignment that minimizes a quantity based partly on distortion, but also on the entropy of the probability distribution defined by the clustering. Entropy is a measure of information-theoretic complexity, and it is also well known that greater complexity is required to achieve lower distorti  ECVQ was originally proposed as a way of estimating this trade-off. The algorithm may find fewer than K groups as it attempts to balance the competing goals of fidelity to the original data and parsimony of representation.  This produces the smallest, or more properly, the least complex output data set that achieves a given level of fidelity to the original data. Our version of ECVQ is adapted in a number of ways for use as a massive data set reduction tool. These are described in detail in  and 26  W e  have al so previously employed our version of ECVQ to produce monthly summaries of Atmospheric Infrared Sounder data  The algorithm\222s output is best thought of as an estimate of the multivariate distribution of the data in a given space-time grid box. The original data have a distribution that puts probability  N on each multivariate data point, where N is the number of data points. ECVQ coarsens this distribution by collecting similar points into clusters, representing them by cluster centroids, and assigning probabilities N k k where N k is the number of point assigned to the k th cluster. In addition we also report the within-cluster mean squared error distortion\, which is a measure of the quality of the cluster representative as a stand-in for the original data assigned to it 1 N to cluster  


  14 10  A NALYSIS R ESULTS  AIRS, AMSR-E, MODIS and CLOUDSAT data have been merged into a dataset by the NEWS effort, and a framework of Web Services for averaging, subsetting and statistical analysis have been developed. Collectively it facilitates the data access and analysis of hydr ological processes. Here we present an example usage of instrument intercomparison Comparing Data Products Prior to Merging A necessary step in creating a formal merged data product is intercomparison of component data sets.  This ensures that the mutual random and systematic differences between the two data sets are quantified.  This approach does not provide information about absolute bias, which can be obtained only from comparisons with unbiased standard data sets.  For example, wate r vapor and temperature biases are typically constrained through comparisons with in situ observations as from radiosonde.  Such comparisons are usually the responsibility of the data provides, so the analyses described below assume some knowledge of satellite measurement biases An example of comparing component data sets is presented here with a single atmospheric state variable, in this case observed by AIRS \(Atmos pheric Infrared Sounder AMSR-E \(Advanced Microwave Scanning Radiometer for EOS\For this example five variables \(AIRS Total Water column, AMSR-E total water column, AIRS cloud fraction AIRS total water error estimate, AMSR-E liquid water path stemming from two different instruments \(AIRS and AMSR-E\pared and correlated The Atmospheric InfraRed Sounder \(AIRS\he Advanced Microwave Scanning Radiometer \(AMSR-E\are two instruments aboard the AQUA spacecraft. AMSR-E estimates water vapor over water surfaces and AIRS estimates water vapor over ocean and land. A map of the daily average of terrestrial water vapor column is shown in figure 10. This figure maps th e AIRS estimate of average total \(column\er vapor in mm during March 2003 at a spatial resolution of 1 degree in latitude and longitude  Figure 10. Map of averaged AIRS Total column water vapor for 2003-03   Figure 11. Scatter plot of monthly AIRS and AMSR-E column water vapor. AIRS and AMSR-E water vapor agree very well on the co incident locations  A similar a subset of AMSR-E water vapor over the ocean was prepared with our services and merged with the AIRS dataset at the same spatial and temporal resolutions. A scatter plot of the values estimated with AMSR-E is compared to the collocated va lue of AIRS in figure 11 Figure 11 also shows a red line to mark the location where all points should fall if the AIRS and AMSR-E estimates were the same. The figure shows a tendency by AMSR-E to estimate higher total water vapor than AIRS. However there are locations where AIRS does show higher values. A map of the averaged differences \(AIRS-AMSR-E\15 selected monthly means between the years 2003--2006 is shown in figure 12 This map highlights locations where each instrument tends to overe stimate compared with the other. Blue tones identify regions where AIRS estimates are larger than AMSR-E and shades of brown locate the regions where the opposite is true 


  15  Figure 12. Map of average differences over 15 months between AIRS and AMSR-R water vapor  Figure 12 highlights regions th at are characterized by different hydrological regimes. AIRS overestimates coincide with regions where cold western boundary currents cause frequent cold marine stratocumuli. AMSR-E tends to estimate higher total water vapor in regions characterized by warm sea surface temperatures and frequent convective activity. This result is consistent with previous comparisons    Figure 13. AIRS Total Cloud Fraction sum for 2003-03 Sum over all pressure levels AIRS is an IR measurement that cannot estimate water vapor in regions overcast with optically thick clouds. This property introduces a bias that depends on the cloud fraction. Figure 13 shows an estimate of the cloud fraction using a surrogate for cloud fraction over several AIRS pressure levels. It adds up the cloud fraction at the different levels \(because there may be overlaps, the sum over all pressure levels can be larger than one between the areas with large cloud fraction sums and large AMSR-E overestimates with respect to AIRS and vice versa, areas with the smallest cloud fraction sums coincide with the areas with large AIRS water vapor estimates A proxy for the "thickness" of the clouds in the overcast regions is the liquid water content of such clouds. The advantage of this proxy over others is that it also conveys information about the physical and hydrological characteristics of the scenes co rrelated with the differences Figure 14 shows a PDF of the differences as a function of AIRS water vapor and AMSR-E cloud liquid water path. A black contour line marks the change of sign in the differences. It shows that AIRS estimates higher total water vapor at low liquid water paths with a characteristic quasilinear increase between 5--20 mm. AMSR-E estimates larger total water vapor at 1 x 1 degree regions where the liquid water path is high. The pattern of the differences raises questions about why does AMSR-E estimates differ so quickly from AIRS at low water vapor contents and low liquid water paths  Figure 14. AIRS-AMSR-E differences \(in mm function of AIRS total water and AMSR-E cloud liquid water for the month 2003-03  


  16  Figure 15. AIRS-AMSRE differences as a function of AIRS error estimate over one day  AIRS has an error estimate of the total water vapor value that it calculates. The diffe rences between AIRS and AMSR-E are shown as a function of this estimate in figure 15 and very little correlation is found 11  R ELEVANT W ORK  Merged A-Train Level 2 Data A merged product that preserves the relationship of observed atmospheric water properties facilitates the hydrological studies by enabling scientists to get directly at the model data without worrying about the logistics of finding, collecting, and coordinating the measured quantities from different instruments. Previously there did not exist a capability to discover and access data from the A-Train\222s multiple instruments as merged multi-parameter data sets Enabling Orchestratable Service Workflows Our distributed service-oriented approach of loosely coupled services also enable s a higher level of reusability and orchestration with other services. Increasing numbers of workflow engines are already supporting Web Services as components/operators, which can then be orchestrated together into higher-level meta/virtual services SciFlo, a Scientific Dataflow Execution Environment, is a workflow engine that already supports assembling reusable SOAP Services, native execu tables, local command-line scripts, and codes into a distributed computing flow \(a graph of operators\8 SciFlo can u tilize o u r g en eric SOAP services as part of a larger coordinated data flow The Taverna Workbench is a free software tool for designing and executing workflows. Like SciFlo, it can orchestrate SOAP-based Web Services as components within a workflow. Taverna provides a visual editor to construct and edit the sequence of services in the workflow We have found that Taverna can dynamically introspect a given WSDL and construct the workflow component interface representing it Giovanni Giovanni, an acronym for the Goddard Earth Sciences Data and Information Services Cent er, or GES DISC, Interactive Online Visualization and Analys is Infrastructure, is a webbased tool to help visualize Earth science data  It  provides a simple and intuitive way to visualize, analyze and access vast amounts of Eart h science remote sensing data without having to download the data. Similar to the services developed here, it addresses the difficulties of traditional data acquisition and analysis methods by moving the complexity to the server-side Giovanni provides multiple in terface instances based on instrument and measurement ty pes. For example, the \223ATrain Along CloudSat Track Inst ance\224 can provide plots of vertical profiles of clouds, temperature, humidity, cloud and aerosol classification across the multiple instruments of the A-Train A distinction between Givanni\222s A-Train data and the data set in this paper is that we are using a formal merged product of the A-Train. We leverage the NEWS effort that is based on error- and resolution-weighted mean of the input data sets, with associated uncertainty estimates. This provides a formal model of the collective A-Train observations rather than the collection of the individual instrument measurements Each of Giovanni\222s multiple interface instances provides a very simple and easy to use web interface. However, we recognized that sometimes scientists want more than the simple interfaces. Some scien tists may want to process Level 3 products using their own trusted code, or may want to perform variations of their own plots. With Giovanni, the individual scientist wanting more custom advanced capabilities must depend on the Giovanni development team Giovanni is based on the web portal paradigm where users visit a web page and use web tools to find and visualize data. Similar to Giovanni, our client APIs also make data acquisition more seamless. However, our services are based on the different paradigm were the power and flexibility of data analysis and processing are shifted back into the scientists own familiar computing environments. We realize that scientists generally want to perform \223exploratory computing\224 where they can sere ndipitously analyze the data using their own familiar and trusted code 


  17 Giovanni 2 was inherently synchronous where processing was bounded to a single http session. Long service running times still require the user to hold the same http session Similar to our asynchronous Web Service we discussed, the upcoming Giovanni 3 will be supporting asynchronous sessions. They will be using a RSS feed to monitor the service request. Version 3 will also be based on a servicesoriented architecture, wher e Giovanni services can be offered as a standard SOAP Web Services. This is similar to our approach, as well as SciFlo\222s services 12  C ONCLUSIONS  To achieve the science research goal of investigating longterm and global-scale trends in climate, water and energy cycle, and weather variability, we enhanced and improved on existing algorithms to work with distributed and heterogeneous data and information systems infrastructure By developing a service-oriented architecture for discovering, accessing, and mani pulating of NEWS merged A-Train data sets, we can strengthen the interconnectedness and reusability of these services across broader range of Earth science investigations The merged NEWS Level 2 data is a formal model containing the voluminous data from the AIRS, AMSR-E MLS, MODIS, and CloudSat instruments. Previously scientists wanting to perform long-term and global-scale studies encompassing simultaneous measured quantities would quickly face a data acce ss hurdle of first finding the data, then manually downloading them, and finally merging the data into a cohesive model\227before starting their analysis. Additionally the voluminous nature of the data particularly because of the MODIS data\each scientist potentially downloading the same data resulting in redundancy of reprocessing on the client sides. Our paradigm pushes more of the commonly repeated processing onto the server side. Moreover, this avoids repeated downloading of the same data among the science users. We can deliver customi zed averaged, subsetted, and summarized data of the merged A-Train observations to the scientists for them to immediately begin their analysis work We recognized that scientists also often want to perform 223exploratory computing\224 where they can freely explore the aspects of the data and run serendipitous exploration in their own familiar environment. We developed client-side distributed APIs in popular analysis environments such as Matlab, IDL, and Python. Our APIs hide the complexity of Web Services and allow the service capabilities to be embedded in the scientists own computing environments By purposely avoiding the \223web portal\224 paradigm and providing the suite of platform specific APIs in each of these language platforms, we enable the scientists to remain within their own familiar environments to select, process and download the data seamlessly into their environment for their own further analysis. Alternative methods involving web portals force the scientists to leave the environment and manually interact with the web portal to search and download the data We can examine not only long-term changes in amplitude of a single variable but also those among multiple variables Our L3Q clustering method was specifically designed to preserve information about the covariability of multiple observations, such as those from the A-Train.  Weather and climate variability is characterized by changes among atmospheric observables, but those changes have been limited by a lack of observations and analytical techniques We are not aware of any multi-parameter analyses to date The full potential of the A-Train climate record will not be realized until the multi-parameter climatology is understood. The work presented is one method of approaching this difficult problem Our service tool addresses several objectives of the NASA Earth science data community including 1\mprove interoperability to facilitate the transparent access and manipulation of heterogeneous and distributed data by science users, 2\ransition and deploy existing Earth science research analysis tools and software using a 223Service Oriented Architecture\224 \(SOA\ to enhance their reuse potential for other science domains and improve overall awareness and access of these tools by a broad community, 3\ increase users\222 ability to customize their discovery, access, deliv ery, manipulation, and preferred format of data and information 12  F UTURE W ORK  On-demand Level 3T Summaries from Level 3Q We plan to develop services for creating custom summaries of the L3Q data into more refined Level 3T summaries L3T\create their own custom Level 3 products on demand from L3Q. The custom Level 3 products are the transformation of L3Q data based on user-specific objectives such as regression and correlation analyses. The cust om production will generate not only the transformed data but also the statistical estimation of the accuracy of the summarized data based on the distribution of L3Q and the quality of L3Q Delegating the Temporal-Spatial Data Querying Currently, our processing layer utilizes existing and legacy processing code that was developed in IDL, Matlab, and C++. Though the original intent was to be able to adapt existing code and wrap as a service, this meant maintaining its original form of accessing the source data for processing Small modifications were made to enable these codes to quickly access the data based on file path and file naming schemes. However, we want to decouple the file accessibility and processing roles 


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



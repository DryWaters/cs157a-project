Mining Approximate Dependencies Using Partitions on Similarity-relation-based Fuzzy Databases Shyue-liang Wang*, Jenn-Shing Tsai and Been-Chian Chien Department of Information Management I-Shou University, Taiwan slwang@csaSOO.isu.edu.tw Institute of Information Engineering I-Shou University, Taiwan m873202m~cbc ABSTRACT In this work we present a data mining technique for determining approximate dependencies in similarity-relation-based fuzzy databases Similarity-relation-based fuzzy data model is most suitable for describing analogical data over discrete domains 
in addition to fuzzy-set-based fuzzy data models Approximate dependency is an extension of functional dependency such that equality of tuples is extended and replaced with the notion of equivalence class The approximate dependency we define here can capture more real-world integrity constraints then most existing functional dependencies on fuzzy databases A level wise mining technique is adopted here for the search of all possible nontrivial minimal approximate dependencies based on equivalence classes of attribute values An algorithm based on Huhtala 5 is presented here whereas other approximate types 
of functional dependencies introduce only conceptual viewpoints Keyword data mining approximate dependency similarity relation, fuzzy database 1 INTRODUCTION Data mining also referred to as knowledge discovery on databases is the nontrivial extraction of implicit previously unknown and potentially useful information from data 4 It is the search for relationships and patterns that exist in large databases but are hidden among the vast amount of data Association rules classification rules discrimination rules characteristic rules, functional dependencies, and clusterings are some of the relationships and patterns typically searched Mining of functional and approximate dependencies from relations has 
been identified as an important database analysis technique Functional dependencies are relationships between attributes of a relation a functional dependency states that the value of an attribute is uniquely determined by the values of some other attributes The discovery of functional dependencies from relations has received considerable interests An approximate dependency can be considered as a functional dependency that almost holds It describes approximate 0-7803-5731-0/99$10.00 01999 IEEE V-871 relationships between attributes 
of a relation in databases Many mechanisms for incorporating approximate relationships have been proposed previously: the fuzzy functional dependency framework of Raju and Majumdar 9 the probabilistic dependency framework of Haux and Eckert 5 and cluster dependency framework of Saharia and Barron lo etc However current mining techniques of determining functional and approximate dependencies are based on crisp databases Although various forms of approximate dependency on fuzzy databases have been proposed their emphases are on the conceptual viewpoints, and no algorithms are given In this work we present an approach for finding approximate dependencies from databases that contain similarity-relation 
based fuzzy data A similarity relation is a generalization of an equivalence relation such that reflexiveness, symmetry, and max min transitivity is satisfied In addition to fuzzy-set-based fuzzy databases similarity-relation-based fuzzy data model has been proposed by Buckles and Petry 3 as an important tool for storing fuzzy information in database technology It is also recognized as a model that is most suitable for describing analogical data over discrete domain 8 When a similarity relation is defined on 
an attribute domain, its attribute values can be partitioned into equivalence classes with respect to a specified level value Attribute values in an equivalence class are similar to each other to the degree of the given level value The approximate dependency in our fuzzy database is defined as a functional dependency based on equivalence classes of attribute values If attribute A is approximately dependent on attributes in X it means that each equivalence class in A is functionally dependent on an equivalence class 
in X For each attribute with a corresponding level value, the tuples in database are partitioned into a set of equivalence classes The use of partitions on the tuples makes the discovery of approximate dependencies easy and efficient as tuple-wise computation is reduced to equivalence-class-wise manipulation Our algorithm is based on the level-wise algorithm that has been used in many data mining applications 6,7 It starts from dependencies with a small left-hand side and works towards larger dependencies until the minima1 dependencies 


that hold are found Sec SW Eng Acct Sys Eng Salesman Dn Eng The rest of our paper is organized as follows Section 2 reviews the basic concept of partitions and approximate dependencies on fuzzy databases based on similarity relations Section 3 describes the searching algorithm of finding the approximate dependencies based on Huhtala etc Finally a discussion is given at the end of paper Sec Sw Acct Sys Sales Dn 1 0.6 0.7 0.6 0.5 0.6 0.6 1 0.6 0.8 0.5 0.8 0.7 0.6 1 0.6 0.5 0.6 0.6 0.8 0.6 1 0.5 0.8 0.5 0.5 0.5 0.5 1 0.5 0.6 0.8 0.6 0.8 0.5 1 Eng Eng man Eng 2 PARTITIONS AND APPROXIMATE DEPENDENCIES ON FUZZY DATABASES 37 40 45 47 50 53 55 Fuzzy relational databases to accommodate incomplete imprecise or uncertain information have been studied extensively in recent years l-3,113 To represent fuzzy information in the data model two basic approaches can be classified model through similarity relations or proximity relations 3 and model through possibility distribution   Similarity relation-based fuzzy database has been recognized as a model that is most suitable for describing analogical data over discrete domains In the following we review the basic concept of the model 1 0.9 7 0.7 0.5 0.5 0.5 For each attribute domain D a similarity relation s is defined over its domain elements s  D x D  0 11 A similarity relation is a generalization of an equivalence relation in that if a b c E D then s is reflexive s\(a a  1 symmetric s\(a b  s\(b a transitive s\(a c 2 max[min\(s\(a, b\s\(b, c for all b E D A similarity-relation-based fuzzy relational is defined as a set of relations consists of tuples Let ti represent the i-th tuples of a relation R it has the form til ti2  tirn where t is defined on the domain set Dj 1 IjSm Unlike the ordinary relational database, two simple but important extensions are defined The first extension is that the tuple component tu selected from Dj is not constrained to be singleton, instead c Dj and t  0 Allowing tuple component tij to be a subset of the domain Dj means that fuzzy information can be represented If t consists of a single element it represents the most precise information; whereas if t is the domain D. itself it corresponds to the fuzziest information This leads to the definition 3 1J tij 221J U 221J J DEFINITlON A fuzzy database relation R is a subset of the set cross product aD1 xZD2 x  xzDm D D D where 2 J  2 J  0  2 J represents the power set of Dj The second extension of the fuzzy relational database is that, for each domain set D of a relation a similarity relation S is defined over the set elements J Sj  Dj x Dj   0 1 1 The similarity relation introduces different degrees of similarity to the elements in and this is another mechanism for the representation of 223fuzziness\224 in this fuzzy relational data model A simple illustration of the fuzzy database relation is shown in the Table 1 below representing the JOB EXPERIENCE and SALARY of eight EMPLOYEES The similarity relations for domain attributes JOB EXPERIENCE and SALARY are shown in Fig 1 EMP JOB IEXP SALARY 1 Salesman 3 37K 2 IDesign Engineer I10 140 3 ISystem Engineer 15 145K I 4 Software Engineer 15 45K 5 1 Accountant I12 147 I I 6 1 Accountant 15 150 J 7 I Secretary 110 I53 8 lsecretary 115 l55K Table 1 A Fuzzy Database Relation 137 40 45 47 50 53 55 Fig 1 0.9 0.7 0.7 0.5 0.5 0.5 1 0.7 0.7 0.5 0.5 0.5 0.7 1 0.9 0.5 0.5 0.5 0.7 0.9 1 0.5 0.5 0.5 0.5 0.5 0.5 1 0.9 0.9 0.5 0.5 0.5 0.9 1 0.9 0.5 0.5 0.5 0.9 0.9 1 Similarity relations for attribute domains SALARY V 872 


An approximate dependency over a relation schema r is expressed as X  A where X Informally, an approximate dependency X  A holds if all tuples that agree on X approximately also agree on A approximately Formally the dependency holds or is valid in a given relation R over r if for all pairs of tuples t and tl E R we have: if t   t  for all DJ E X then tt];4  tl];\221  where tl represents the equivalence class of tuple t, with respect to an attribute DJ with level value a r and A E r a a1 I DI 1 DI We explain the notations as follows Two tuples ti and tl are equivalent with respect to an attribute Dj for a given level value aj if tij and tlj belong to the same equivalence class of Dj The equivalence classes of Dj are determined by the level value aj and defined by the similarity relation For example for attribute JOB with level value 0.8 the equivalence classes are Secretary Accountant Software Engineering System Engineering Design Engineering and Salesman It means that Software Engineering System Engineering and Design Engineering are similar to each other with value higher or equal to 0.8 and they are in the same equivalence class of attribute JOB We denote it by Software Engineering wa System Engineering or System Engineering ma Design Engineering\where a  0.8 Tuples 2  3 and 4 in Table 1 therefore belong to the same equivalence class in terms of attribute JOB In general an attribute Dj partitions the tuples of a relation into a set of equivalence classes We denote the equivalence class of a tuple ti E R with respect to an attribute Dj with level value aj by  i.e The set aI rD  t I\224 I t E RI of equivalence classes is a partition of R under DJ with level value a That is XE is a collection of disjoint sets \(equivalence classes of tuples, such that each set has values belonging to an equivalence class in DJ and the union of the sets equals the relation R The rank 1x1 of a partition is the number of equivalence classes in x\222 Example 1 Consider the relation in Table 1 Attribute JOB with attribute value 0.8 has equivalence classes Secretary Accountant Software Engineering System Engineering Design Engineering and Salesman For salesman it forms an equivalence class of tuple 1 For Software Engineering, System Engineering, Design Engineering it forms an equivalence class of tuple 2,3,4 The partition with respect to JOB is X,,08  I 2,3,4}, {5,6 7,s The partition with respect to EXPERIENCE is   1,3,4,6 0.9 2,5,7 8 The partition with respect to SALARY is XaL 0.8  1,2 3,4,5\{6,7,8 The concept of partition refinement gives almost directly approximate dependencies A partition x is a refinement of another partition x\222 if every equivalence class in x is a subset of some equivalence class of x\222 We have the following lemma 61 Lemma 1 An approximate dependency X  A holds if and only if xX refines x{A Example 2 Continuing example 1 to find out whether the approximate dependency JOB  SALARY holds we can compare the partitions ZJoB and XExp and check whether ZJoB refines XExp Since equivalence class 2,3,4 of ZJOB is not contained in any equivalence class of ZEm the approximate dependency JOB  SALARY does not hold However approximate dependency JOB EXPERIENCE  SALARY holds, since ZJoB,Exp   11 21 3,4 51 61 7 8 is arefinement of ZSAL  1,2 3,4,5 6,7,8 0.8 0.9 0.8 0.9 0.8  0.9 0.8,0.9 0.9 There is an even simpler test for determining the approximate dependency X  A If xx refines x then adding A to X does not increase any equivalence classes of xx, thus xxu A equals xX Therefore we have the following lemma 6 Lemma 2 An approximate dependency X  A holds if and Only if IbXI  bX U A 3 SEARCHING ALGORITHM An approximate dependency X  A is minimal \(in R if A is not approximately dependent on any proper subset of X i.e if Y  A does not hold in R for any Y c X The dependency X  A is trivial if A E X Our task is to find the following given a relation R find all minimal non-trivial approximate dependencies that hold in R To find all minimal non-trivial dependencies X  A we search through the space of all possible non-trivial dependencies and test the validity and minimality of each dependency The validity test means testing Inx  Inx U A  as described in lemma 2 which requires computing the partitions Minimality test reduces the number of dependencies we have to consider For example if we find X  A holds, then Z  A is not minimal for any proper superset Z of X The collection of all possible left-hand sides of dependencies is the collection of all attribute sets They constitute a set containment lattice such as in Figure 2 6,7 The level-wise algorithm starts the search from the singleton sets, and work its way through the lattice level by level until the minimal hold are found During this level-wise search false dependencies are eliminated as early as possible with some pruning techniques V 873 


0 partitions with respect to two subsets of X different subsets of size 1x1-1 will do In fact any two A B D AB fic AD BC BD CD ABC ABD ACD BCD ABCD Fig 2 The set containment lattice for A,B,C,D} representing the search space of all possible left-hand sides The possible right-hand sides consist of single attribute that can be obtained with a single bread-first or level-wise pass through the lattice In addition, there is a one-to-one correspondence between the edges of the lattice and the non-trivial dependencies the edge between sets X and Xw{A} is viewed as a non-trivial dependency X  A The efficiency of the level-wise algorithm is based on reducing the computation of each level by using results from previous levels We do not need to compute the partitions from scratch for every set of attributes In fact the partitions of the next level in the lattice can be obtained as a product of two earlier partitions in the previous level The product of two partitions n\221 and n\223  denoted n  n  is the least refined partition  0 thatrefines both n and K Lemma 3 For all X Y E r Zx  Ky  nXvY Example 3 Continuing from Example 1 the partitions with respect to JOB EXPERIENCE SALARY are njiB  I 2,3,4 5,6 7,8 ngp  1,3,4,6 2,5,7 811 0.9 0.8.0.9  Tw  l 2 3,4,5 6 respectively Partition ZJoB,m 11 21, {3,4 51 61 71 8 is the least refinement of nJoB and nExp  Partition nJoi,sAL  I 2 3,4 5 6 is the least refinement of nJOB and 0.8 0.9 0.8 0.9 0.8 0.9 0.9 0.9  ZaL Partition nExp:wL 11 2 3,4 51 6 71 0.9 0.9  8 is the least refinement of EEXp and Xw For partitions nx 1x1 2 2 they are computed as a product of When the algorithm is processing a set X it will test dependencies of the form X\\\(A  A where A E X This allows validity testing based on Lemma 2 since both zX and x\\\(A have already been computed To test minimality of X\\{A  A we need to know whether W{A  A holds for some proper subset Y of X The information is stored in the set C\222\(X of right-hand side candidates of X 6 where C\222\(X   A E r 1 for all B E X, X  A,B  B does not hold To find all valid minimal non-trivial dependencies we search the set containment lattice in a level-wise manner A level L is the collection of attribute sets of size e such that the sets in L can potentially be used to construct dependencies based on the considerations of previous sections We start with Ll  A I A E r and compute Lz from L1 and L3 from Lz and so on According to these information we obtain the following algorithm derived from Huhtala 6 where the pruning and next level generations procedures can be found Algorithm: level-wise search of dependencies 1 Lo 0 2 C\222\(0 r 3 LI DJaJ I DJaJ Er 1 I j I m 4 e  1 5 whileL,#0 6 COMPUTE-PARTITION\(L 7 COMPUTE-DEPENDENCIES\(L 8 PRUNE\(L 9 Lt+l  GENERATE-NEXT-LEVEL\(L io e:=e I 4 DISCUSSION We have presented an approach for finding approximate dependencies from fuzzy relational databases based on similarity relations The similarity-relation-based fuzzy data model has been recognized as a model that is most suitable for analogical data over discrete domains Approximate dependencies considered here is defined as a functional dependency based on equivalence classes of attribute values instead of equality of attribute values The mining algorithm is based on level-wise search of Mannila The determination of approximate dependency is an extension of Huhtala\222s approach which discovers functional dependency on crisp data The concept of approximate dependency can be further extended to other types of fuzzy data models and will widen applications in the areas of database management reverse engineering and query optimization 5 REFERENCE l M Anvari and G.F Rose 223Fuzzy relational databases\224 in Bezdek Ed Analysis of Fuzzy Information Vol I1 V 874 


CRC Press, Boca Raton, FL 1987 P Bosc and 0 Pivert 223Fuzzy querying in conventional databases\224 In Fuzzy Logic for the Management of Uncertainty, Zadeh L and Kacprzyk, J. Eds, John Wiley New York 1992 645-671 B.P Buckles and F.E Petry 223A fuzzy representation of data for relational databases\224, Fuzzy Sets and Systems 7 W.J Frawley G Piatesky-Shapiro and C.J Matheus 223Knowledge Discovery in Databases An Overview\224 Knowledge Discovery in Databases G Piateskey-Shapiro and W.J Frawley, eds, pp 1-27 AAAI/MIT Press 1991 R Haux and U Eckert 223Nondeterministic dependencies in relations an extension of the concept of functional dependency\224 Information Systems IO 2 1985 139 148 Y Huhtala J Karkkainen P Porkka and H Toivonen 221\221Efficient discovery of functional and approximate dependencies using partitions\224 Proceedings of IEEE International Conference on Data Engineering 1998, 392 410 H Mannila and H Toivonen 223Levelwise search and borders of theories in knowledge discovery\224, Data Mining and Knowledge Discovery 1 3 1997,241-258 J.M Medina M.A Vila J.C Cubero and 0 Pons 223Towards the implementation of a generalized fuzzy relational database model\224 Fuzzy Sets and Systems 75 K.V.S.V.N Raju and A.K Majumdar, \223Fuzzy functional dependencies and lossless join decomposition of fuzzy relational database systems\224 ACM Transactions on Database Systems 13 2 1988, 129-166 A.N Saharia T.M Barron 223Approximate dependencies in database systems\224, Decision Support Systems 13 1995 335-347 L.A Zadeh 223Similarity relations and fuzzy orderings\224 Info. Sci vol3 no 1 Mar 1971, 177-200 1982,213-226 1995,273-289 V 875 


6  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Genetic programming \(GP  The dream  Stop writing programs  Instead, go and catch them  Take a herd of variants on a program  Let them fight it out for a while  Go fetch  GP= mutation of program structure  Special form of GA \(genetic algorithms 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 Genetic Algorithms \(GA Current Population 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1  Init ialize Populat i on New Population 2  E v a l u a te F i tn e s s 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 3 Elit ism 1 0 1 1 1 0 1 1 1 1 1 1 0 1 4. S e l e c t Parents 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 5. Cr o s s ov e r 1 0 0 1 1 0 0 1 0 1 0 1 1 1 6 Muta te 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


7  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 GA Selection Rank population is sorted according to objective values Elitism fittest carry over to next generation Roulette fitness increases chances of selection Stochastic Universal Sampling equal opportunity for all 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 GA Crossover  Single point crossover  \(One random crossover point 11001010101010101101 11001010 110011001101 10011001110011001101 10011001 101010101101  Two point crossover  \(Two random crossover points 11001010101010101101 11001 001110011 101101 10011001110011001101 10011 010101010 001101  Uniform crossover \(Probabilistic bit selection 11001010101010101101 11 0 0 1 0 01 10 0 0 11 101 1 01 10011001110011001101 10 0 1 1 0 10 11 1 0 10 001 1 01 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


8  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 GA Mutation Mutation Randomly flip bits Why Mutate Promotes diversity in the next generation Approaches  Order changing: Swap 2 bits from a chromosome 1001 1 0011100110 0 1101                     1001 0 0011100110 1 1101  Adding/Subtracting: Slight changes to real # encoding 1.12 3.65 3.86 4.31 5.21\              \(1.12 3.65 3.73 4.23 5.21 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 X Genetic Programming focus on the algorithm 3 + X\ \(Z Y X MOD Y\ \(X + 4\ / 2  3 X  Z Y  X MOD  Y 2 X + 4\ / \(Z Y X MOD Y\ 3 / 2 N e w    E x p r e s s i o n s 4  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


9  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Recommended settings  DeJong90  Population size: 50  Number of generations 1,000  Crossover type: typically two point  Crossover rate: 60  Mutation type: bit flip  Mutation rate: 0.001 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: software effort prediction [Burgess Least squares regression vs NN vs GA Converge consistently NN > GP Accuracy GP > NN Readability 225 NN=0;  GP builds big theories using all available knowledge chunks Ease of configuration 225LSR= easy 225 NN = much expertise needed 225 A = some expertise needed Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


10  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Decision tree learning recursive diversity reduction  Given examples with a mix of classes  Find a \223Description\224  Which, if applied\205  205Makes parts of the mix more uniform If circle2, then \223-\224 If circle1, then \223+\224           X Z    2 1 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Decision tree learning  Diversity=0= all examples in 1 class  Diversity = maximum = all classes equally represented  Best \223splitter\224 decreases diversity the most  Many measures of diversity in the literature  Simpson diversity index: biologists  1repeatRate: cryptographers  Gini index: econometricians: as used in CART iman8  Entropy: information theorists: as used in C4.5 Quinlan92  to find more complex descriptions           X Z    3 2 1 If circle2 Then If circle3 then \223+\224 else   \223-\224 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 



Proceedings of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 MOBILE-AGENT-BASED DISTRIBUTED AND INCREMENTAL  TECHNIQUES FOR ASSOCIATION RULES YUN-LAN WANG ZENG-ZHI LI, HAI-PING ZHU Institute of Computer Architecture and Networks Xi'an Jiaotong University, Xi'an 7 10049, China E-MAIL: wangyunlan@263.net Abstract The ever-growing size of data being stored in today's information systems inevitably leads to the distributed database architectures Moreover many databases are 
distributed in nature It is important to devise efficient methods for distributed data mining It is well known that distributed database has an intrinsic data skew property So it is desirable to mine the global rules for the global business decisions and the local rules for the local business decision In this paper a mobile-agent-based distributed knowledge discovery architecture has been proposed for data mining in the distributed heterogeneous database systems. Based on this architecture a flexible and efficient mobile-agent-based 
distributed algorithm for association rules IDMA is presented that can mine the global and local large itemsets at the same time Furthermore when mining the local large itemsets an incremental algorithm IAA is employed, which utilizes a heuristic selective scan technique to reduce the number of database scans required and to keep the size of the candidate itemset sets from increasing exponential The performance of IDMA is studied The results show that the algorithm IDMA is valid and has superior performance Keywords 
Incremental mining; Mobile Agent KDD Data mining; Association Rule Distributed mining 1 Introduction The importance of data mining is growing at rapid pace recently Analysis of past transaction data can provide very valuable information on  customer behavior and business decisions Many databases are distributed in nature For example the departments of many organizations and companies are scattered across a country or all over the world so the huge number of transaction records are likely to be store at different sites It's inevitably leads to distributed database architecture At the same time 
the transactions in the distributed database may be changed time to time Consequently the research of distributed and incremental algorithm architectures and systems for mining distributed information sources is very important and challenging 0-7803-7865-2/03/$17.00 02003 IEEE Of the various data mining problems mining of association rules is an important one. The problem has been studied substantially with many interested and efficient data mining algorithms reported. Apriori I runs a number of iterations and in each iteration scans the database once to obtain the large itemsets of the same size DHP 2 is the improvement 
of Apriori in which the hash technique is adopted. FP-tree  proposes a novel frequent pattern tree structure and develops an efficient FP-tree based mining method, which only needs to scan the database once and is efficient for small database All of the algorithms above are not considered the problem of the refresh of the database FUP2  is an incremental maintaining technique for association rules when the new transactions are added to the database and the obsolete ones are deleted from it FUP2 tends to suffer from the inherent problem of need multiple scans of database Algorithm Count distribution \(CD 
5 which is the adaptation of Apriori algorithm has been proposed for the parallel mining environment The PDM 6 algorithm tries to parallelism the DHP algorithm FPM 7 adopts the count distribution approach and has incorporated two powerful candidate pruning techniques, distributed pruning and global pruning But all of CD PDM and FPM tend to suffer from the following inherent problems 1 Only the global large itemsets can be mined. The information of the local large itemsets on each site cannot be provided So it may not provided support for local business decision 2 The information in the 
previous mining cannot be used to reduce the cost of current mining since they are not incremental algorithm Mobile agents are intelligent programs that can migrate on computer networks The concept of having mobile agents carrying out tasks is creating a new paradigm for network-enabled distributed computing Mobile agents make it very much easier to design implement and maintain distributed systems Mobile agents can reduce network traffic, provide an effective means of overcoming network latency, and help us to construct more robust and fault-tolerant systems IBM's Aglets Workbench system 9 provides an applet-like programming model for mobile 266 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 agents The contribution of this paper is as follows 1 The architecture of the mobile-agent-based distributed knowledge discovery system has been proposed for data mining in the distributed heterogeneous database systems which is implemented based on Aglet The architecture consists of a knowledge discovery management system JSDMS and some knowledge discovery sub-systems sub-KDS KDMS is located in the management system of the distributed database system. The sub-KDS is located in each site of the distributed database 2 Based on the architecture of the distributed knowledge discovery system a flexible and efficient mobile-agent-based distributed algorithm IDMA for association rules is presented in which the global association rules and all the local association can be mined at the same time The thinking in IDMA is that one mobile agent is dispatched by the KDMS to each sub-KDS to mining all the local large itemsets According to the relations between the local and the global large itemsets most global large itemsets can be ascertained. If some itemsets cannot be decided they are global large or not the counter mobile agents can be dispatched to relative sites to get the support count So all the global frequent itemsets can be mined The remainder of the paper is organized as follows The architecture of the distributed knowledge discovery system is discussed in section 2 The mobile-agent-based distributed algorithm is proposed in section 3 The performance study of the distributed algorithm IDMA is reported in section 4 The conclusions are presented in section 5 2 The Architecture of the Mobile-Agent-Based Distributed Knowledge Discovery System The architecture of the distributed knowledge discovery system which is based on mobile agent is illustrated in fig 1 The system includes the distributed knowledge discovery management system \(KDMS\and the knowledge discovery sub-system sub-KDS the structures of KDMS and sub-KDS are as follows I I II MPM mining process manage MACC mobile agent control centre GKB global knowledge base LKB local knowledge base DMMA data mining mobile agent PMA data pre-processing mobile agent MAE mobile agent environment CMA counter mobile agent MAEE mobile agent execution environment Figure 1 The architecture of the mobile-agent-based distributed knowledge discovery system 2.1 The Structure of KDMS of this module is as follows 1 Dispatches the mobile agent to each sub-KDS and mining the local knowledge integrates the local knowledge to get the global knowledge 2 Analyzes the data in the data warehouse by the means of Mining Process Manager: This is the core module of the distributed knowledge discovery system The function 267 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 QLAM Data Warehouse: The history data is stored in the data warehouse The databases in the different sites of the distributed information system are often heterogeneous The data warehouse techniques should be adopted to transfer the data to uniform format so the data can be organized and accessed efficiently QLAM OLAM is the combine of OLAP and data mining Data warehouse provides the platform for OLAP and data mining The data in the multi-dimension data warehouse can be analyzed and mined The operating of slice scan drill and rotate can be processed Global Knowledge Base: The knowledge in the global knowledge base includes the knowledge mined from the global data warehouse and the knowledge, which is mined from all the sub-KDS by the mobile agents and integrated by the mining process manager Mobile Agent Control Center MACC MACC is the framework within which the mobile agent activities in the distributed data mining system take place MACC is responsible for generating/activating/assembling the agents required for the data mining process The different agent types and their tasks are briefly discussed below Data mining mobile agent DMMA This agent can be dispatched to sub-KDS to mine the local large itemsets 2 Data pre-process mobile agent PDA which be dispatched to sub-KDS to pre-process the data in the local database and collect the data to the data warehouse Counter mobile agent CMA The task of this agent is to be dispatched to the sub-KDS and scan the local database to get the support count of some itemsets 1 3 2.2 The Structure of sub-KDS Local database The local real time information is stored in the local database which can be queried by the local supervisor and at the same time can be mined by the mobile agent dispatched by the supervisor Local knowledge database the knowledge discovered by the mobile agent is return to the KDMS at the same time it is saved in the local knowledge base which can provide references to the local supervisor Mobile agent execution environment \(MAEE The KDMS dispatches the mobile agent to the sub-KDS so the mobile agent execution environment has to be installed in the sub-KDS In this paper Aglet is used as the mobile agent platform 3 The Mobile-Agent-Based Distributed Algorithm for Association Rules 3.1 The Important Property in Distributed Mining for Association Rules Let D be a partitioned database located at n sitesS1,S2  S The database partitions at these sites are D',D On  Let D be the local database at site Si and U D  D  D nDJ I for i j  We useX  Xiup to denote the support count in D and D respectively Let ID1 be the number of transactions in global database D and lDil be the number of transactions in local database D  Definition 1 Xis global large, if Xsup 2 s  ID  Definition 2 Xis local large in site Si  if X:up 2 s  ID I  Lemma 1 If itemset X is global large there exists a site Si 1 5 i I n  such that X and all its subsets are locally large at site S  Lemma 2 If the set of the global large itemsets is GL the set of the local large itemsets at site Si is LL  then GL c a i=l Lemma 3 For an itemset X if the set of sites at which Xis large noted as Xfie  the set of sites at which Xis not large noted as  It is  clear that Xfie-s Xunfie-s  SI Sn I and Xfie-s n Xunfie-s Q  The following results hold 1 The possible minimal support count of X is denoted as Xmin-sup 7 Xmin-sup 2 C~iup  s'ex,m 2 The possible maximal support count of X is denoted as Lemma 4 If Xmin-sup 2 s*IDI then X is global large itemset Lemma 5 If Xmax-sup  s  ID1  then X cannot be global large itemset 3.2 The Thinking in Distributed Algorithm IDMA and Its Procedure The thinking in the mobile-agent-based distributed 268 


Proceedings of the Second International Conference on M algorithm for association rules IDMA is that the KDMS dispatches the mobile agent DMMA to each site The mobile agents move to the sub-KDS and execute the mission of data mining The local large itemsets can be got so the local association rules can be obtained and the local knowledge base can be refreshed The set of local large itemsets and their support counts led back to the KDMS by the mobile agents When all the mobile agents come back to KDMS the possible minimum and maximum support counts of the potential global large itemsets can be got according to lemma 3. According to lemma 4 and lemma 5 most of the itemsets in the set uLL can be judged whether they are global large or not The itemsets that cannot be judged are added to the set of agenda itemsets The counter mobile agent CMA is dispatched to the related sites to get the support counts of the itemsets that are in the set of agenda itemsets When these mobile agents come back to KDMS all the global large itemsets can be got n 1=1 Procedure IDMAO incremental algorithm IAA 2 1 MACC creates DMMA according to the MACC dispatches the mobile agent to each The mobile agent distributed and parallel mines the local large itemsets at each sites LL is the set of local large itemsets at site S  The mobile agent comes back to KDMS with the set of local large items and its support count 4 The set of global candidate itemsets Sub-KDS 3  GC=ULL ache Learning and Cybernetics Wan 2-5 November 2003 18 19 20 21 end for 22 fori  1 ton 23 24 end for 25 for each X E uAi 26 if Xsup 2s*IDI GL=GLu{X 27 End for else if Xmax-sup 2 s*IDI for i  1 to n if x e LL A  A u{x  if A f I  CMA is dispatched to Si to scan D once and get the support counts of the itemsets in Ai  n i=l 3.3 The Incremental Algorithm IAA for the Local Large Itemsets The algorithm that is employed to derive the local large itemsets is IAA  101 The feature of IAA is as follows Firstly The selective scan technique is adopted to determine frequent itemsets in batch so as to reduce the number of database scans required and to avoid the size of the candidate set becomes huge too quickly. Secondly IAA is an incremental algorithm for maintaining the frequent itemsets in the cases of insertion, deletion and modification of the transactions in the database. It takes advantage of the previous mining result to cut down the cost of finding the new rules in a frequently updated database Lastly the useful relations between the previous frequent itemsets with respect to the origin database and the new frequent itemsets with respect to the updated database have been studied they are used to prune the candidate itemsets for i  1 to n lln is the number of sites A  I efficiently when scanning the added and deleted portions of the database 4 Performance Study of IDMA I A is the set of agenda itemsets at end for for each itemset X E GC Xmax-sup  0  Xmin-sup  0  for i  1 to n if x E LL Xmax-sup  Xmax-sup  XLp  Xmin-sup  Xmin-sup  X:up  else x  x  s  ID'I  end for if x s*IDI GL=GLu\(X To assess the performance of the algorithm IDMA we performed several experiments on a cluster of computers of 2.0 GHz and 526 MB of memory The simulation program was coded in C The methods used to generate synthetic data are the same as the technique introduced in 7 The notation of the database is in the form Dx.Ty.Iz.Sr where x is the number of transactions in each site, y is the mean size of the transactions z is the average size of the potentially large itemsets and Y is data skewness. The number of sites is denoted as n And the minimum support threshold is noted as minsup For the aim of simplicity we assume that the number of deleted and added transactions on each site is 10% of the transactions on the site in the previous mining 1  269 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Xi'an 2-5 November 2003 4.1 The Performance of the Mobile Agent decreases On the contrary the execution time of IDMA increases slightly as the data skew-ness increase However IDMA is faster than FDM about 0.6 to 2.8 times The time cost for mobile agent serialized, the time for the transmission of mobile agent on the network and the time for the mobile agent de-serialized would affect the performance of the data mining system So it is important to test the time performance of mobile agent It can be seen from table 1 that the time consumed by mobile agent is in millisecond degree. Compared to the time consumed by the data-mining algorithm it can be ignored So it will not depress the performance of the data mining system Table 1 The Performance of Mobile Agent  The time for mobile agent serialized I 12.8ms I 15.0ms The time for mobile agent transmission in the network 3.9ms The time for mobile agent installed by java class loader 4.2 The Relative Performance of IDMA and FPM The mobile-agent-based distributed knowledge discovery system is a Java based system The way to accelerate the data mining processing is through use of native C/C methods and including the data mining algorithm IAA, which was coded in C as a dynamic link library through Java's JNI  111 We have compared the time performance between IDMA and FPM 4 J 815 1 1.5 2 2.5 3 Minimum Support Threshold  Figure2 The relative performance with respect to different minimum support threshold The first experiment is conducted to examine the relative performance for the same databases on different minimum support threshold The result is reported in Fig.2 It can be seen that IDMA is faster than FDM about 0.8 to 1.9 times. Where the number of sites is 4 Figure.3 studied the relative performance with respect to varied data skew-ness. Due to the global pruning as the data skew-ness increase the response time of FPM DlOOK.T5.14.S n=4 minsup=l.O IIIII lI11 IIIII IIIII Skewness S Figure3 The relative performance with respect to different data skewness T300Wn.D5.14.S0.8 n minsup=l O 1 I I I I I I I 2 3 4 5 6 Number of Sites Figure.4 The execution time with respect to the number of sites D300Wn.T5.14.S0.5 n minsup=l.O Number of Sites Figure.5. Execution time speedup i 270 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 In the speedup experiment we use the database D300k/n.T5.14.S0.5 which has medium database skew-ness as the base-database to performance the speedup experiments The number of sites is 1 to 6 The support threshold is 1.0%. The results are shown in Fig.4 and FigureS It can be seen clearly that IDMA almost achieves the ideal liner speedup 03 T5 14 SO 5 n=5 minsup=l 0 1200 i nnn c FPM c IDMA 200 400 600 800 1000 Numer of Transactions on Each Site K Figure 6 Scale-up experiment In the scale-up experiments, the number of processors involved is fixed to 4 The number of transactions on each site is varied from 50K to 1000K The results are shown in Figure.6 It is shown that the execution time of IDMA and FPM increase linearly as the number of transactions increases. It is also shown that IDMA is faster than FPM about 1.5 times. This shows that IDMA is scalable and can work well with very large databases 5 Conclusions In this paper the mobile-agent-based distributed knowledge discovery architecture has been proposed for data mining in the distributed heterogeneous database systems Based on the architecture of the distributed knowledge discovery a flexible and efficient distributed algorithm IDMA for association rules is presented which can mine all the global large itemsets and all the local large itemsets at the same time A novel incremental algorithm for the association rules is employed to mine the local large itemsets The performance of IDMA is studied The results show that the algorithm IDMA is valid and has superior performance References R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases Proc of ACM SIGMOD 1993 pp J.S Park M S Chen and P S Yu Using a Hash-Based Method with Transaction Trimming For Mining association Rules IEEE transactions on knowledge and data engineering 9\(5 81 3-825, 1997 Jiawei Han Jian Pei and Yiwen Yin Mining Frequent Patterns without Candidate Generation 2000 ACM SIGMOD Intl Conference on Management of Data D W Cheung S.D Lee and Benjamin Kao A General Incremental Technique for Maintaining Discovered Association Rules Proceedings of the Fifth International Conference on Database Systems for Advanced Applications, 1997, pp 185-194 R Agrawal and J.C Shafer Parallel Mining of Association Rules Design Implementation and Experience IEEE Transactions on Knowledge and Data Eng 8\(6 962-969 December 1996 T Shintani and M. Kitsuregawa, Hash Based Parallel Algorithms for Mining Association Rules Proc 4th Int\222l Conf Parallel and Distributed information Systems, IEEE Computer Soc Press Los California David W Cheung and Yongqiao Xiao Effect of Data Skewness in Parallel Mining of Association Rules Proc Pacific-Asia Conf Knowledge Discovery and Data Mining Lecture Notes in Computer Science Vol.1394 New York SpringerVerlag 1998 pp Joseph Kiniry, Daniel Zimmerman, A Hands-on Look at Java Mobile Agents, IEEE Internet Computer, 1997 Lange D B Java Aglet Application Programming Interface \(J-APPI\IBM Tokyo Research Laboratory 1997 http://www.trl.ibm.co.jp/aglets 207-216 pp 1-12 1996 pp 19-30 48--60 1 \(4 21-30 lo Yunlan Wang Zengzhi Li Jun Xue Yinliang Zhao A Novel Incremental Algorithm for Mining Frequent Itemsets 2002 International Symposium on Distributed Computing and Application to Business Engineering and Science, 2002, pp.60-64 ll Calvin Austin and Monica Pawlan Chapter 5 JNI Technology Advanced Programming for the Java Platform 2001 pp. 207-230  Acknowledgments Supported by the National Natural Science Foundation of China under Grant No.60173066 271 


most known classifiers ARC-BC suppc2036 6=90 rm-scdbcov BEP I initial set of NleS I manual tuned set of rules  I I I micm-avg 1 84.14 I M.62 mscmavg 1 63.55 74.41 Table 5 Micro-average PrecisionlRecall breakeven point for ten most populated Reuters categories  manual tuning of the classifier mances improved as presented in Table 5 A comparison between the pruning methods is given in Table 7 By applying the pruning methods the accuracy of the classifier is not improved However the reduction in number of rules represents a step further in manually or au tomatically tuning of the system 5 Conclusion and Future Work This paper introduced a new technique for text catego rization It employs the use of association rules Our study provides evidence that association rule mining can he used for the construction of fast and effective classifiers for auto matic text categorization We have presented an association rule-based algorithm for building the classifier ARC-BC that considers categories one at a time The algorithm as sume a transaction-based model for the mining documenl I suppon 11 training I testing 1 IOW 11 18 I 3 15 I1 9 I 2 Table 6 Training and testing time in sec onds with respect to the support threshold for Reuters-21570 dataset set The experimental results show that the association rule based classifier performs well and its effectiveness is com parable to most well-known text classifiers. One major ad vantage of the association rule-based classifier is its rela tively fast training time Moreover the rules generated are understandable and can easily be manually updated or ad justed if necessary The maintenance of the classifier is straight forward In the case of ARC-BC when new doc uments are presented for retraining only the concerned cat egories are adjusted and the rules could be incrementally updated The introduction of the dominance factor 6 allowed multi-class categorization However other feature selection techniques such as latent semantic analysis could improve the results by giving an insight on the discriminative fea ture among classes We are working on reducing the num ber of features thus better discrimination among classes is expected Currently the discovered rules consider the pres ence of terms in documents to categorize We are studying possibilities to take into account the absence of terms in the classification rules as well Table 4 PrecisionlRecall-breakeven point on ten most populated Reuters categories for ARC-BC and 25 


I BEP II ARC-BC with 6  50 and rupp=15 1 IO D Lewis Niive bayes at forty The independence assump tion in information retrieval In 10th European Conference on Machine Learning ECML-98 pages 4-15 1998 I I H Li and K Yamanishi Text classification using esc-based stochastic decision lists In Xrh ACM Inremarional Confer ence on Informarion and Knowledge Management\(C1KM 99 pages I22 130 Kansas City.USA 1999 I21 W Li I Han and 1 Pei CMAR Accurate and efficient c!assi!kation based on multiple class-association rules In IEEE Inrernarional Conference on Dara Mining ICDM'OIA San Jose California November 29-Dwmber 2 2001 I31 B Liu W Hsu and Y Ma Integrating classification and as sociation rule mining In ACMlnr Coni on Knowledge Dis covery and Dara Mining SIGKDD'9XA pages 8046 New York City NY August 1998 I41 1 Moulinier and J.4 Ganascia Applying an existing machine learning algorithm to text Categorization In S.Wemter E.Riloff and GScheler editors Connecfionisl srarisrica1,and symbolic approaches 10 learning for naru ral language processing Springer Verlag, Heidelberg Ger many 1996 Lecture Notes for Computer Science series number IMO I51 The reuters-21578 text categorization test collection http://www.research.att.co1nl~lewis/reuters2 1578.html I61 M Ruiz and P Srinivasan Neural networks for text catego rization In 22nd ACM SIGIR nlernariOMl Conference on Informarion Rerrieval pages 281-282 Berkeley CA USA August 1999 I71 F Sebastiani Machine learning in automated text cate gorization Technical Report IEI-B4-31-1999 Consiglio Nazionale delle Ricerche Pisa. Italy 1999 I81 C M Tan Y F Wang and C D Lee The use of bigrams to enhance text categorization Jour nal of Information Processing and Management 2002 http://www.cs.ucsb.edu yfwang/paperdig&m.pif I91 University of California irvine knowledge discovery in databases archive http://kdd.ics.uci.edd 20 Y Yang An evaluation of statistical approaches to text cat egorization Technical Report CMU-CS-97-127 Camegie mellon University, April 1997 211 Y.Yang and X.Liu A re-examination of text categorization methods In 22nd ACM Inremarional Conference on Re search and Developmenr in Informarion Retrieval SIGIR 99 pages 42-49 Berkeley.US, 1999 22 0 R Zaiane and M.-L. Antonie Classifying text documents by associating terms with text categories In Thirreenrh Aus tralasian Darabase Conference ADC'OZ pages 215-222 Melbourne Australia lanuan 2002  11 wlo pruning I rn-s I rn-s  db-cov 11 3072rules I 383rules I 127rules I IC II R99 I R42 I 76 6 I micro-avg 11 81.8 I 68.2 I 7 I 4 macro-avg 11 78.24 I 64.40 I 58.53 Table 7 PrecisionIRecall-breakeven point for ten most populated Reuters categories with different pruning methods References I R. Agrawal T Imielinski and A Swami Mining associa tion rules between sets of items in large databases In Proc 1993 ACM-SIGMOD Inr Conf Management of Dara pages 207-216 Washington, D.C., May 1993 Z M:L Antonie 0 R. Zaiane and A Coman Application of data mining techniques for medical image classification In Second lnrernarional ACM SIGKDD Workshop on Mul rimedia Dara Mining pages 94-101 San Francisco USA August 2001 131 C. Apte F Damerau and S Weiss Automated learning of decision rules for text categorization ACM Tronsnction on Informarion Sysrems 12\(3 1994 4 R Bekkerman R El-Yaniv N Tishby and Y Winter On feature distributional clustering for text categorization In Proceedings of SIGIR-01 24rh ACM lnrernarional Con ference on Research and Development in Informarion Re rrieval pages 146-153 New Orleans US 2001 5 W Cohen and H Hirsch Joins that generalize text clas sification using whirl In 4th lnrernnrional Conference on Knowledge Discovery and Data Mining SigKDD'98 pages 169-173 New York City,USA 1998 6 W Cohen and Y Singer. Context-sensitive learning methods for text categorization ACM Transactions on Informarion Sysrems 17\(2\-173 1999 7 J Han 1 Pei, and Y Yin Mining frequent patterns without candidate generation In ACM-SIGMOD Dallas. 2000 SI D A Hull Improving text retrieval for the routing problem using latent semantic indexing In 17rh ACM lnrernarional Conference on Research ad Development in Information Rerrievnl SIGIR-94 pages 282-289 1994 9 T Joachims Text categorization with support vector ma chines learning with many relevant features In 10th Euro pean Conference on Machine Learning ECML-98 pages 137-142 1998 26 


FIGURE 5 Execution time and rules returned versus minimum coverage for the various algorithms FIGURE 6 Execution time of dense_0002 as minconf is varied for both data-sets. Minimum coverage is fixed at 5% on pums and 1% on connect-4 FIGURE 7 Maximum confidence rule mined from each data-set for a given level of minimum coverage   1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution time \(sec Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution Time \(sec Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 1e+07 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    0 500 1000 1500 2000 2500 3000 3500 20 25 30 35 40 45 50 55 60 65 Execution time \(sec minconf pums  connect-4  1 10 100 1000 10000 100000 1e+06 20 25 30 35 40 45 50 55 60 65 Number of Rules minconf pums  connect-4    0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 Highest Rule Confidence Minimum Coverage pums  connect-4 


8.2  Effects of minimum confidence The next experiment \(Figure 6\ws the effect of varying minconf while fixing minimp and minsup to very low values. With connect-4, we used a minimum coverage of 1%, and with pums, a minimum coverage of 5%. Minimp was set to .0002 with both data-sets. As can be extrapolated from the previous figures, the number of rules meeting these weak minimp and minsup constraints would be enormous As a result, with these constraints alone, Dense-Miner exceeds the available memory of our machine The efficiency of Dense-Miner when minimum confidence is specified shows that it is effectively exploiting the confidence constraint to prune the set of rules explored. We were unable to use lower settings of minconf than those plotted because of the large number of rules. As minconf is increased beyond the point at which fewer than 100,000 rules are returned, the run-time of Dense-Miner rapidly falls to around 500 seconds on both data-sets 8.3  Summary of experimental findings These experiments demonstrate that Dense-Miner, in contrast to approaches based on finding frequent itemsets achieves good performance on highly dense data even when the input constraints are set conservatively. Minsup can be set low \(which is necessary to find high confidence rules as can minimp and minconf \(if it is set at all\This characteristic of our algorithm is important for the end-user who may not know how to set these parameters properly. Low default values can be automatically specified by the system so that all potentially useful rules are produced. Refinements of the default settings can then be made by the user to tailor this result. In general, the execution time required by Dense-Miner correlates strongly with the number of rules that satisfy all of the specified constraints 9.     Conclusions We have shown how Dense-Miner exploits rule constraints to efficiently mine consequent-constrained rules from large and dense data-sets, even at low supports. Unlike previous approaches, Dense-Miner exploits constraints such as minimum confidence \(or alternatively, minimum lift or conviction\ and a new constraint called minimum improvement during the mining phase. The minimum improvement constraint prunes any rule that does not offer a significant predictive advantage over its proper sub-rules. This increases efficiency of the algorithm, but more importantly it presents the user with a concise set of predictive rules that are easy to comprehend because every condition of each rule strongly contributes to its predictive ability The primary contribution of Dense-Miner with respect to its implementation is its search-space pruning strategy which consists of the three critical components: \(1\functions that allow the algorithm to flexibly compute bounds on confidence, improvement, and support of any rule derivable from a given node in the search tree; \(2\proaches for reusing support information gathered during previous database passes within these functions to allow pruning of nodes before they are processed; and \(3\ item-ordering heuristic that ensures there are plenty of pruning opportunities. In principle, these ideas can be retargeted to exploit other constraints in place of or in addition to those already described We lastly described a rule post-processor that DenseMiner uses to fully enforce the minimum improvement constraint. This post-processor is useful on its own for determining the improvement value of every rule in an arbitrary set of rules, as well as associating with each rule its proper sub-rule with the highest confidence. Improvement can then be used to rank the rules, and the sub-rules used to potentially simplify, generalize, and improve the predictive ability of the original rule set References 1 w a l  R.; Im ie lin ski  T   a n d S w a m i, A. 1 9 9 3   M i n i ng As so ciations between Sets of Items in Massive Databases. In Proc of the 1993 ACM-SIGMOD Int\222l Conf. on Management of Data 207-216 2 raw a l R.; M a n n ila, H Sri k an t  R T o i v o n en  H.; an d  Verkamo, A. I. 1996. Fast Discovery of Association Rules. In Advances in Knowledge Discovery and Data Mining AAAI Press, 307-328 3 K Ma ng a n a r is S a n d Sri k a n t, R 19 97  P a rtia l Cl a ssif i cation using Association Rules. In Proc. of the 3rd Int'l Conference on Knowledge Discovery in Databases and Data Mining 115-118 4 a rd o  R. J 1 9 9 8  Ef f i c i en tly Min i n g  Lo n g  P a ttern s fro m  Databases. In Proc. of the 1998 ACM-SIGMOD Int\222l Conf. on Management of Data 85-93 5  Mi c h ae l J. A a n d  Lin o f f G  S 1 9 9 7  Data Mining Techniques for Marketing, Sales and Customer Support John Wiley & Sons, Inc 6 Bri n, S  M o t w a n i, R.; Ullm a n J.; a n d  Tsu r S. 19 9 7 Dyn a m i c  Itemset Counting and Implication Rules for Market Basket Data. In Proc. of the 1997 ACM-SIGMOD Int\222l Conf. on the Management of Data 255-264 7 h e n  W   W   1 9 9 5 F a st Ef fecti v e Ru le In d u ctio n   In  Proc. of the 12th Int\222l Conf. on Machine Learning 115-123 8 In tern atio n a l Bu sin e s s Mac h in e s   1 9 9 6  IBM Intelligent Miner User\222s Guide Version 1, Release 1 9 m e t tin e n M   Ma nn ila  P  Ro nk a i ne n  P   a n d V e rk a m o  A  I. 1994. Finding Interesting Rules from Large Sets of Discovered Association Rules. In Proc. of the Third Int\222l Conf. on Information and Knowledge Management 401-407 10  Ng   R  T    L a k s hm ana n   V   S    Ha n  J   an d P a ng A  1 9 9 8   Exploratory Mining and Pruning Optimizations of Constrained Association Rules. In Proc of the 1998 ACM-SIGMOD Int\222l Conf. on the Management of Data 13-24 11 Ry mo n  R 1 9 9 2   Search  t h ro u g h Sy s t e m atic S e t En u m era tion. In Proc. of Third Int\222l Conf. on Principles of Knowledge Representation and Reasoning 539-550 1  Sha f e r  J  A g r a w a l R   an d Me ht a M 19 98  SPR I N T   A  Scalable Parallel Classifier for Data-Mining. In Proc. of the 22nd Conf. on Very Large Data-Bases 544-555 13  S m y t he P  and  Go od man   R  M 19 92 An I n f o r m at i o n Th eo retic Approach to Rule Induction from Databases IEEE Transactions on Knowledge and Data Engineering 4\(4\:301316 14  S r i k a n t   R    V u  Q an d Ag r a w a l  R  19 97 M i ni ng  A ssoc i a tion Rules with Item Constraints. In Proc. of the Third Int'l Conf. on Knowledge Discovery in Databases and Data Mining 67-73 15 W e bb, G. I 1 9 9 5 OP U S An Ef f i c i e n t Adm i ssible Algo rit h m for Unordered Search. In Journal of Artificial Intelligence Research 3:431-465 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



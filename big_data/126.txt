Ef\002cient Mining for Association Rules with Relational Database Systems Karthick Rajamani Dept of Elec and Comp Engg Rice University karthick@rice.edu Alan Cox Dept of Computer Science Rice University alc@rice.edu Bala Iyer IBM Santa Teresa Labs balaiyer@us.ibm.com Atul Chadha IBM Santa Teresa Labs achadha@us.ibm.com Abstract With the tremendous growth of large-scale data repositories a need for integrating the exploratory techniques of data mining with the capabilities of relational systems to ef\002ciently handle large volumes of data has now risen In this paper we look at the performance of the most prevalent association rule mining algorithm Apriori with IBM's DB2 Universal Database system We show that a multi-column MC data model is preferable over the commonly used single column SC data model for association rule mining We obtain factors of 4.8 to 6 improvement in performance for the MC data model over commercial implementations for the SC data model We provide a new relational operator called Combinations  for ef\002cient SQL implementation of Apriori in the database engine this results in trivial parallelizability reliability and portability for the mining application Keywords Database mining association rule mining operator for association 1 Introduction There is an increasing usage of relational database systems by organizations to store vast amounts of data The compelling need to extract useful information from this data has led to wide-spread adoption of data mining techniques In addition to being the storage system for the mining data relational data base systems provide highly reliable large-volume data handling capability ef\002cient query indexing and parallelization facilities and widening portability across a multitude of system architectures All these have made the integration of data mining tasks with the database system an attractive proposition The integration of mining applications and database systems however requires appropriate data organization some modi\002cations/enhancements in the database system and either changes in or entirely new mining techniques The problem of association rule mining was introduced initially for market basket data analysis 1  T h e s i m p le and easily understandable nature of these rules has led to widespread adoption of this technique in data analysis In this paper we study the issues involved in integrating association rule mining with the database system In our study of association rule mining we 002nd that the physical data model used for the mined data has a signi\002cant impact on performance The single-column SC data model is a common physical data model used in marketbasket analysis However it does not yield suf\002cient performance for association rule mining We propose an alternate physical data model for association rule mining called multi-column MC that can considerably improve its performance in the database We use an object-relational extension to the database system called user-de\002ned function UDF to 002nd association rules in MC data We compare the performances of a commercial implementation of the Apriori association rule mining algorithm for the SC model with our own UDF prototype of Apriori for the MC data model Our experimental results indicate that the MC model's performance is up to 6 times better than the SC model's When data resides in a RDBMS using SQL to work with the data increases the reliability and portability of an application In the case of RDBMS supporting parallelizable queries the SQL implementation can be easily parallelized when written with due care Further improvements in performance can also be obtained through improvements in performance of the related querying facilities We provide an SQL implementation for association rule mining of data in the MC model We de\002ne the semantics for a new relational operator Combinations  which can be effectively used for a very ef\002cient SQL implementation of the Apriori algorithm for association rule mining We implement a 


prototype of the operator using new object-relational extensions of the DB2-UDB d a t a b a s e s ys t e m  O u r e xpe ri ments indicate that the performance of this implementation is comparable to that of a more complicated implementation of the Apriori algorithm that was designed for good performance A more detailed account of our work can be obtained from our technical report 17 In summary we make two main contributions to the task of discovering association rules in databases i We identify the physical data model that is most suitable for association rule mining based on the access pattern of the application ii We provide an ef\002cient SQL implementation for association rule mining using a new relational operator We provide a prototype using object-relational extensions of DB2 to implement the operator The SQL implementation enables an easily parallelizable and portable approach to association rule mining The rest of the paper is organized as follows Section 2 presents the Apriori algorithm for association rule mining Section 3 presents the SC and MC data models for association data In section 4 we give a brief overview of our method for handling the MC data model and the results of our experiments with both the data models In section 5 we provide our SQL implementation for association rule mining with the MC data model We show how our operator Combinations  can be used along with other common SQL querying facilities to implement the Apriori algorithm In section 6 we present some of the related work and present our conclusions in section 7 2 Background on Association Rule mining This section is based largely on the description of association rule mining given by Agrawal et al 1 3  L e t I  f I 1 I 2   I n g be the domain of literals called items  A record called a transaction contains a set of items I 1 I 2   I k 032 I  The input to the association rule mining algorithm is a set of transactions T Wecallanysetofitems I 1 I 2   I m 032 I collectively an itemset An association rule is a relation of the form A   B in T  where A B are itemsets and A  B    A is the antecedent of the rule and B is the consequent of the rule An itemset has a measure of statistical signi\002cance associated with it called support  Support for an itemset Xin T  support\(X  is the number of transactions in T containing X For a rule A   B  the associated support is support A  B  A support fraction is the ratio of the support value to the total number of transactions The strength of a rule is given by another measure called con\002dence  The con\002dence of A   B is the ratio support A  B   support\(A  The problem of association rule mining is to generate all rules that have support and con\002dence greater than some user-speci\002ed thresholds Itemsets that have support greater than the user-speci\002ed support are called large itemsets For a large itemset S if A 032 S and support\(S  support\(A 025 con\002dence threshold then A   S 000 A is an association rule The problem of association rule mining is thus broken down into two tasks a The task of determining all large itemsets This stage is split into two parts a candidate-generation phase aset of itemsets called candidate itemsets are chosen this set is chosen such that it contains all potential large itemsets b large-itemset generation phase the support for the candidates are counted those with support greater than or equal to the user-speci\002ed minimum support qualify to become large  b The task of determining the rules with enough con\002dence from the large itemsets Once the large itemsets are determined generating the rules is a straightforward task and is not very time consuming The bulk of the time and memory requirement is for identifying the large itemsets and their support values The Apriori algorithm proposed by Agrawal and Srikant  provides an ef\002cient method for generating association rules It obtains its ef\002ciency by using potentially smaller candidate sets when counting the support for itemsets to identify large itemsets It uses the fact that for a given support all the subsets of a large itemset need to be large itemsets themselves For example if the set A,B,C is a large itemset i.e it has at least the minimum support then all of its subsets A B C A,B B,C and A,C also have at least the required minimum support Apriori makes multiple passes over the input data to determine all the association rules Let L I denote the set of large itemsets of size I and let C I denote the set of candidate itemsets of size I  Before making the I th pass Apriori generates C I using L I 000 1  Its candidate-generation process ensures that all subsets of size I-1 of C I are all members of the set L I 000 1 Inthe I th pass it then counts the support for all the itemsets in C I  At the end of the pass all itemsets in C I with a support greater than or equal to the minimum support form the large itemset L I  Figures 1 and 2 provide the pseudocode for the Apriori algorithm In both the 002gures the subset\(s N function gives all the subsets of size N in the set s This method of pruning the C I set using L I 000 1 results in a much more ef\002cient support-counting phase for Apriori when compared to the earlier algorithms In addition the usage of a hash-tree data structure for storing the candidates provides a very ef\002cient support-counting process largeitemset generation phase As originally proposed the Apriori algorithm uses its own data structures for measuring the support and does not 


L 1  f large 1-itemsets g  for k  2 L k 000 1 6    k   C k  Generate candidates L k 000 1   forall records t 2 D C t  C k T subset\(t k forall candidates c 2 C t c:count   L k  f c 2 C k j c:count 025 support g Answ er   k L k  Figure 1 Apriori Algorithm insert into C k select p.item 1  p.item 2  p.item k-1  q.item k-1 from L k 000 1 p L k 000 1 q where p.item 1  q.item 1  p.item k-2  q.item k-2 p.item k-1  q.item k-1  forall itemsets c 2 C k forall s 2 subset\(c k-1 if s 62 L k 000 1  then delete c from C k  Figure 2 Generate candidates L k 000 1  use any SQL queries in its implementation 3 Physical Data Models for Association Inspite of signi\002cant research efforts on association rule mining techniques there has been no clear speci\002cation for a physical data model for the input data Consider the example of a retail sales data Here the record is a single sale transaction  where the association is between the items sold in the transaction The data is quite often organized in a schema of the form Transaction id Item hereafter referred to as SC model This schema would result in one entry for every item sold in the transaction With the Transaction id Item schema the Transaction id value would be repeated for every item bought in that transaction The SC data model would be useful for performing conventional relational queries against items bought in transactions Some of the early work in association rule mining 11 p ropos e t he us e o f s uc h r e l a t i ona l que ri e s for d i s covering association rules and work with this data model However later work  h a v e s ho w n s i gni 002 c a n t p e rfor mance improvement by using Apriori-based algorithms that did not use relational queries in their implementation But to the best of our knowledge no change in the data model was proposed Even commercial offerings of the these better algorithms have stayed with the SC model For the purpose of association rule mining we propose a data model of the form Transaction id Item1 Item2  ItemC We will refer to this as the multiple-column MC model In this model the column Item i contains the i th item of that particular transaction The domain of every Item i column is the entire set of items If C is the average number of non-null items in a row in the MC model of the input data the SC model requires C-1 times more rows albeit shorter ones to be read in for every pass over the table Figure 3 provides an example to illustrate the different representations with SC and MC In a sense the MC model provides a horizontal representation of the data while the SC model provides a vertical representation of the data SC model MC model TID Item TID Item1 Item2 Item3 1 Apple 1 Apple Coke Bread 1 Coke 2 Bread Apple 1 Bread 3 Carrot Mango Coconut 2 Bread 2 Apple 3 Carrot 3 Mango 3 Coconut Figure 3 Example illustrating the SC and MC data models 3.1 Analysis of Data\255Access Costs We use a simpli\002ed table-scan cost model to illustrate the bene\002t of the MC model Consider a table with R transactions  each one involving C number of items on the average For the CPU costs for accessing the i nput data table let t R denote the time associated with a row access for concurrency control page-\002x etc Let t C denote the CPU time required for a single column access Then the CPU costs associated with both the models are cpu cost MC  t R 003 R  t C 003 R 003 C cpu cost SC  t R 003 R 003 C  t C 003 R 003 C The cost difference comes out to  cpu cost SC 000 cpu cost MC  R 003 t R 003  C 000 1 Thus we see that the cpu-cost difference increases as the number of rows in the table increases and also as the average number of items in a transaction grows The I/O cost is proportional to the volume of data scanned for each model Let S h be the size of the header associated with each row in the database table S i be the number of bytes per item and S t denote the size of the transaction id In the case of the MC model since the items are already grouped by transaction id into each row the transaction ids need not be scanned However for the SC model since the grouping by transaction id has to be done 


their values also need to be scanned in The volume of data scanned for both the models are v ol MC  R 003  S h  C 003 S i  v ol SC  R 003 C 003  S h  S i  S t  The volume difference comes out to  v ol SC 000 v ol MC  R 003  S h 003  C 000 1  S t 003 C  Here we see that the I/O-cost difference also increases with increase in the number of rows and also with an increase in the average number of items in a transaction In the above models we ignored the cost for handling the null entries in the MC model If we consider t n as the cpu cost for processing a null item and N as the total number of columns in the MC model we get the condition t R t n  N  C 000 1 for SC to have a higher cpu cost Similarly if we consider S n to be the size of the null indicator for the I/O cost of SC to be greater than the I/O cost of MC we get the condition  S h 003  C 000 1  S t 003 C  S n 003 N  For reasonable values of N relative to C these conditions would hold for most databases An additional cost for the SC model arises because of the gr ouping on transaction id that is required to obtain all the items sold in a transaction together This is eliminated in the MC model because of the implicit grouping provided by having all such items in a single row 3.2 Other Aspects Regarding additional storage for storing the null entries in the MC data model most commercial database systems provide facilities for ef\002cient compression of data For short records lot of nulls a good compression mechanism would easily reduce the extra storage for the nulls all identical 002elds so good compressibility to just a marginal increase Iyer and Wilhite 14 p r o v id e a c o m p r e h e n s i v e a n a ly s i s o f various data compression options and discuss them in the context of IBM's DB2 database management system In addition to minimizing storage costs compression could even speed up the mining process by trading off higher I/O latencies with lower compression/uncompression overheads for very large datasets A key advantage of the SC model is the extensibility of the domain of items after the initial table has been created This is retained in our MC model as no column for the items has any speci\002c association with a particular item Column Item i is just a place-holder for the i th item in a particular transaction in the SC model the Item column is the place-holder for any of the items in a transaction Thus any addition to the domain of items does not need to alter the schema for the MC table in any way The limit of the number of columns in the table places a corres ponding limit on the maximum number of items that can be part of one record However as can be seen in 002gure 4 only an extremely low number of transactions are truncated because of this These should probably have been treated as outliers anyway The MC model is limited in the nature of relational queries over the items Data analysis where neither the grouping of items of same transaction nor the ef\002ciency of obtaining all the data in the table are relevant could still require the SC model However when the primary application has a grouping requirement like that of association rule mining or needs to do complete scans of the input table the potential performance bene\002t justi\002es the usage of the MC model The performance bene\002ts are even greater when repeated runs of such an application are required for data analysis such as is often the case with association rule mining It is also our experience that many real-life datasets are found in the MC data model But they get converted to the SC model at signi\002cant conversion costs for storage and computation because the underlying assumption for the implementation of the mining algorithm is that of the SC data model By pointing out that better performance can be obtained with the MC data model we would hopefully discourage such practice 4 Implementation and Results for MC Data Model In our study we compare the performance of two implementations for association rule mining using the Apriori algorithm We use the highly optimized implementation of Apriori for the SC model from IBM's Intelligent Miner IM Data Mining Suite 13  F or t h e M C m ode l  w e us e one of DB2's object-relational extensions c a l l e d t he us e r de\002ned function UDF A UDF provides an application the means to perform computation on retrieved records inside the database system Similar facilities are available on other commercial database systems like Informix's Illustra or Oracle v8 In our implementation we pass every row of data from the MC table to the UDF function All the computations and generation of rules is done by the code inside the UDF UDFsinDB2,canberunintwomodes,either fenced or unfenced  In the unfenced mode they share the database's address space avoiding the overhead of switching from the database's address space to the application's address space when data is passed from the database to the application In the fenced mode UDFs run in the application's address space which is distinct from the database's Agrawal and Shim 2 h a v e s h o w n t h e b en e\002 t o f e x ecu t i n g U D F s i n t h e unfenced mode We chose to conduct our experiments with UDFs running in the fenced mode to provide the same environment for our implementation as for the Intelligent Miner IM implementation of Apriori where all computations are performed in the application's address space We also performed tests with a UDF implementation for 


the SC data model But its performance was upto a factor of 2-3 times slower than the highly optimized IM implementation Hence we decided to use IM's implementation as representative of the SC model The data structures and the computation modules are quite similar for both the IM and UDF implementations The only difference lies in the extraction of data from the database IM obtains the data from a table with data in the SC model and the UDF from a table in the MC model Our experiments were conducted on an IBM PowerStation 590 that has a 66Mhz Power2 processor with 512MB memory with a 1.07GB Serial-link disk drive We used DB2 v2.1 as our RDBMS Our mining data was drawn from the daily sales data of a large chain of grocery stores in Canada the data collected over a seven month period The original data was stored in a format similar to that of the MC data model but had other attributes per item in each transaction We use just the items sold in each transaction as our input The data has an average of 12 items per sale So the SC model has about 12 times the number of rows in the MC model Our UDF implementation for the MC model supported a maximum of 60 items per transaction the input data under both SC and MC models were identical Figure 4 gives the distribution for the number of items per transaction From it we see that there are only a negligible number of transactions that have more than 60 items per transaction We ran our experiments for a minimum support of 0.5 varying the total number of transactions from 100K-400K Figure 5 shows the time curves for IM and the UDF implementations The ratio of the association time for IM to the UDF association time varies between 4.8 to 6 This factor signi\002cant even for single runs becomes very important when repeated association runs need to be performed over the input data with varying support and con\002dence Data mining techniques in general and association rule mining in particular are typically applied to the data sets repeatedly with varying parameters Thus any improvement in the execution time of a single run of the application has a much bigger effect in the overall performance gains for that application The results clearly indicate the superiority of the MC model over the SC model for database tables used as input for association rule mining 5 SQL implementation for Association For implementing Apriori in SQL over data in the MC data model we propose a new relational operator Combinations  Combinations is a speci\002c form of the generic Powerset operator it produces all subsets of the powerset of a speci\002ed size Hence it is a natural addition for any system supporting set operations such as an RDBMS Combinations takes a set of items S and a number I as input and returns the different combinations of size I from S as rows in a new relation The items in a row i.e the items in each combination are in lexicographic order The resulting table has I columns and j S j C I rows Formally C ombinations  S I  S all X I  where X I  f i 1 i 2   i I g  i j 2 S 1 024 j 024 I  and i 1 i 2   i I  For example for an input set S  f A,B,C,D g and I  2 the output of operator Combinations would be ff A,B g  f A,C g  f A,D g  f B,C g  f B,D g  f C,D gg  For use with the MC model the Combinations operator takes as its input set the elements in the row of a table unlike traditional SQL operators that take a column of a table as their input set The operator performs the required subset function that is used in both the large-itemset and candidate-itemset generation phases of the Apriori algorithm 002gures 1 and 2 For an input table Data with N columns the SQL statements using Combinations for generating large itemsets of size I and candidate itemsets of size I are given in 002gures 6 and 7 Every row in L I contains a large itemset of size I The 002rst I columns contain the items of the itemset and the last column contains the support value Every row in C I contains one candidate itemset of size I  with each column containing one item Once all the large itemsets are generated the rules can be generated from them quite easily We can again easily use the Combinations operator to generate the rules using SQL queries We implement the Combinations operator using UDB's object-relational extension Table-Function 7 18 L i ke a UDF the table-function is a user-de\002ned method that can be used in SQL queries But the table-function returns a table to the query invoking it and is used in the FROM clause of an SQL query This extension provides a highly 003exible table construction utility to be used along with SQL Performance In the large-itemset generation phase using Combinations on all the items in a transaction would generate too many unwanted combinations those not found in the candidate itemsets To reduce such combinations we add a new clause to the operator in  Filter   The operator is now modi\002ed to emit combinations of only those items in the input set which are also present in set  Filter   C I is used as the  Filter  set for generating L I  Incorporating this clause into our table-function was done easily by passing the small hash table containing the items in C I as a binary-large-object BLOB argument to the table function There is yet another optimization that can improve the performance of the SQL approach using Combinations We found that during the large itemset generation phase the output of the table function for Combinations is created 


  0 2000 4000 6000 8000 10000 12000 14000 16000 18000 0 20 40 60 80 100 120 140 160 180 Number of transactions Number of items/transaction cdistrout Figure 4 Distribution for Number of Items/Transaction   0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 5500 100000 150000 200000 250000 300000 350000 400000 Time \(in seconds Number of transactions IM  UDF Figure 5 Execution time for IM and UDF implementations insert into L I select C.item1  C.itemI c ount from Data d C I C join Combinations d.item1 d.itemN I as g on C.item1  g.item1 and  and C.itemI  g.itemI group by C.item1 C.item2  C.itemI having count 025 support Figure 6 SQL for generating large item\255 sets insert into C I select l1.item 1  l1.item 2  l1.item I-1  l2.item I-1 from L I 000 1 l1 L I 000 1 l2 where l1.item 1  l2.item 1 and  l1.item I-2  l2.item I-2 and l1.item I-1  l2.item I-1 and  select count from L I 000 1 join Combinations l1.item 1  l1.item I-1  l2.item I-1  I-1 I Figure 7 SQL for generating candidate itemsets 


as a temporary table in the database and then joined with the candidates table If this temporary table is not generated but the counts for the candidate sets directly incremented by using hash-grouping with the entries in the candidates table as the keys performance would be signi\002cantly enhanced However this involves modi\002cations to the RDBMS optimizer for queries involving table functions Since this was beyond our control in the existing set up this optimization was not performed We ran our experiments for the SQL implementation with DB2-UDB beta version that provides the Table Function extension installed on an SP2 node with 256 MB memory Our execution times for the SQL implementation were between 2 to 6 times that of the UDF implementation of the Apriori algorithm This performance is comparable to the best commercial SC implementation for the algorithm that we could 002nd the association rule mining tool in Intelligent Miner When the memory requirements for the UDF approach are met by the system it provides the best uniprocessor performance This is because of the usage of the complex hash-tree structure that provides for ef\002cient scanning of the tuples for candidate itemsets in the UDF approach In the SQL implementation simple database operations join and group by are used for the same purpose these use data structures not as ef\002cient as the hash-tree for this task However by relying on the database system for providing the bulk of the storage requirements memory/disk and database operations for its performance the SQL approach is much more scalable and portable In addition to it the queries can be trivially parallelized in an SMP MPP or even a cluster of SMPs environment 6 Related Work Many researchers have proposed new operators to support data mining DMQL p ropos e s ope ra t o rs for m i n i n g characteristic rules classi\002cation rules association rules etc Meo et al.[16 ha d p ropos e d a S Q L l i k e ope ra t o r f or generalized association rule mining The M-SQL 12 l a nguage has a special operator Mine to generate and query propositional rules Tsur et al 21 ge ne ra liz e t he ide a of Apriori-pruning to a concept called query 003ocks and show how it can be used in general-purpose mining systems and in conventional query optimizers These proposals focus on the general querying semantics and interface for mining as opposed to our focus on providing a speci\002c ef\002cient SQLbased implementation of mining for database systems Lakshmanan et al 15 a nd G y s s e ns e t a l   8  ha v e proposed extensions to SQL that work on non-column data in a relational table However their extensions differ from ours as they are proposed for inter-operability in multi-database systems and not for providing the 003exibility and functionality required by data mining applications Agrawal and Shim s ho w t he be ne 002 t of us i n g U D F s for the development of applications tightly coupled with the database engine Houtsma and Swami 11 p ropos e d SETM anSQL based algorithm for association rule mining Their algorithm uses simple database operations sorting and mergescan joins However their joins are more expensive as they are against the input data table and they do not have an ef\002cient candidate set pruning such as Apriori More recently Sarawagi et al 19 co mp ar e m an y a l t e r natives for implementing association rule mining with relational database systems They also examine a Horizontal data model which is comparable to our MC data model However they work under the assumption that the original data can be found only in the SC data model and so incorporate an additional factor for conversion in their cost analysis Sarawagi et al and Zaki et al 22 co n s i d er Vertical or tid-list transformations to the data to achieve good performance In this transformation they build for each item a list of the ids of the transactions tid-list in which the item occurs The support count for each itemset is then obtained by merging the tid-lists of the items in that itemset They 002nd this approach to have very good performance when the number of candidate itemsets is not large but expensive in terms of storage requirements for doing the transformation In the context of providing ef\002cient I/O access for decision-tree and Bayes classi\002ers the Monet mainmemory database system 10 us e s t h e D e c o m pos e d Storage Model 6 to v e r tic a lly f r a g m e n t a ll r e la tio n s in to Binary Association Tables BAT This signi\002cantly reduces the I/O costs associated with the attribute-oriented accesses required for obtaining attribute-class correlation counts at various stages of the classi\002cation algorithms The SPRINT 20 c l a s s i 002 e r a dopt s a s i m i l a r v e r t i c a l fra gm e n t a tion by creating an attribute-list for each attribute containing just the attribute values class labels and the record ids from the original multi-attribute table This again provides signi\002cant I/O reduction in the execution of the decisiontree based algorithm used in SPRINT 7 Conclusions We have shown that the physical layout of data plays an important part in the performance of the association rule mining problem Our results show that the MC representation is the better physical data model compared to the SC model We have also provided the Combinations operator that is necessary for performing a SQL-query-based implementation of Apriori over the MC data Our experiments with a prototype implementation of this operator using the UDB's table functions show good uniprocessor performance We also indicate how we can obtain still bet 


ter performance for the SQL implementation through query optimization The SQL implementation provides a convenient method for using the optimization and parallelization capabilities in the database system for the bene\002t of the application It also provides a scalable implementation not memory bound for the algorithm Our work indicates that mining using the database engine is a feasible proposition However it requires careful attention to the data model and access pattern and suitable extensions to the relational database system to provide the new functionality objectrelational extensions such as UDFs and Table Functions required by data mining applications References 1 R  A g r a w a l  T  I m i e lin s k i a n d A  S w a m i  M in in g A s s o c i ation Rules between Sets of Items in Large Databases In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data  pages 207\226216 May 1993 2 R  A gr a w al and K  S hi m  D e v e l opi ng t i ght l y c oupl ed dat a mining applications on a relational database system In Proceedings of the 2nd International Conference on Knowledge Discovery in Databases and Data Mining  August 1996 3 R  A gr a w al and R  S r i kant  F ast A l gor i t h m s f o r M i n i n g A ssociation Rules In Proceedings of the 20th International Conference on Very Large Databases  September 1994 4 P  B oncz W  Q u ak a nd M  L K e r s t e n M onet a nd its Geographical Extensions a Novel Approach to HighPerformance GIS Processing In Proceedings of the 5th International Conference on Extending Database Technology  March 1996 5 D  C h a m b e r lin  Using the New DB2 IBM's ObjectRelational Database System  Morgan Kaufmann 1996 6 G  C o p e la n d a n d S  K h o s h a 002 a n  A D e c o m p o s itio n S to ra g e Model In Proceedings of the 1985 ACM SIGMOD International Conference on Management of Data  May 1985 7 D B 2 U n i v er sal D at abase  U D B   http//www.software.ibm.com/data/db2 Web Document 8 M  G yssens L  L akshm a nan and I  S ubr am ani a n T a bl es as a Paradigm for Querying and Restructuring In Proceedings of the 1996 ACM Symposium on Principles of Database Systems  June 1996 9 J  H an Y  F u K  K oper s ki  W  W ang and O  Z ai ane A Data Mining Query Language for Relational Databases In Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data  May 1996  M  H o l s hei m er and M  L  K er st en A r c hi t ect ur al Suppor t for Data Mining In International Workshop on Knowledge Discovery in Databases Sea ttle  1994  M  H out sm a a nd A  Sw am i  Set or i e nt ed M i ni ng of A ssociation Rules Technical Report RJ 9567 IBM Almaden Research Center October 1993  T  I m i e l i n ski  A  V i r m ani  and A  A bdul ghani  A ppl i cat i o n Programming Interface and Query Language for Database Mining In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining  August 1996  I n t e r n at i onal B usi n ess M achi n es IBM Intelligent Miner User's guide  Version 1 Release 1 SH12-6213-00 ed ition July 1996  B  R  I y er and D  W i l h i t e  D at a C om pr essi on Suppor t i n Databases In Proceedings of the 20th International Conference on Very Large Databases  September 1994  L Lakshm anan F  S adr i  a nd I  Subr am ani a n Schem a SQ L A Language for Interoperab ility in Relational Multidatabase Systems In Proceedings of the 22nd International Conference on Very Large Databases  1996  R  M e o G  Psai l a  a nd S C e r i  A N e w S Q L l i k e O per a t o r for Mining Association Rules In Proceedings of the 22nd International Conference on Very Large Databases  1996  K  R a j a m a ni  B  I yer  and A  C hadha U si ng D B 2 s O bj ect Relational Extensions for Mining Association Rules Technical Report TR 03,690 Santa Teresa Laboratory IBM Corporation September 1997  B  R e i n w a l d and H  P i r ahesh SQ L O pen H et er ogeneous Data Access In Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data  June 1998  S Sar a w a gi  S  T hom as a nd R  A g r a w a l  I n t e gr at i n g A ssociation Rule Mining with Relational Database Systems Alternatives and Implications In Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data  June 1998  J Shaf er  R  A gr a w al  a nd M  M e ht a SPR I N T  A S cal abl e Parallel Classi\002er for Data Mining In Proceedings of the 22nd International Conference on Very Large Databases  September 1996  D  Tsur  J  D  U l l m an S  A bi t e boul  C  C l i f t on R  M o t w ani  S Nestorov and A Rosenthal Query 003ocks a Generalization of Association-rule Mining In Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data  June 1998  M  Zaki  S  P ar t h asar at hy  W  L i  and M  O gi har a  N e w A l gorithms for Fast Discovery of Association Rules In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining  August 1997 


a Computing view b query graph t f ivot method Figure 5 pivot method query graphs re\337ecting the produced columns of the select clause contributes with a value of pc 004 8 to the overall cost resulting in 14 004 pc 6 004 pt  5.2 Comparing different Methods The cost of computing the nearest neighbour using the t method may be split into the computation of the cost for the view de\336nition to perform the t of the prototype information and the core select statement using the t view As already mentioned the pt 212 1 ary join of the prototype table is easily optimized by the existence of an index of the prototype ID In this case each join partner has the size of 1 004 1 d  yielding pt 004 1 d  as the overall cost computing the view without any return operator The query itself joins the view with the PConformations table Reading the result of the view corresponds to one single tuple with pt 004 1  d  columns The access of the PConformations table has the size of pc 004 1  d   The outer query adds to the overall costs with reading the result of the inner query  pc 004 1  d  004  pt 1  and accessing the Prototypes table  pt 004 1  d   The return operator 336nally consumes a data stream of cardinality pc with d 3 attributes The cost of discretization using the self-join method can be computed in three steps The 336rst step considers the computation of the view P rototypeAssignment which requires the access to the two tables P roteinConf ormation  pc 004 1  d   and P rototypes  pt 004 1  d   The resulting data stream which has to be read for further processing yields due to the semantics of the Cartesian product to  pc 004 pt  004 1  d 2  The second step addresses the inner query consuming exactly the size of the view and producing a data stream of pc 004 2 for only two columns The outer query reads the result of the inner query and the result of the view   pc 004 pt  004 3  d   At last the return operator has costs the size of the join operator yielding pc 004  d 3  In a similar y the cost for the minpos  method can be computed Instead of the join with the P rototypeAssigment view in the outer query the P roteinConf ormation table with a cost of pc 004  d 1 a Computing view b query graph PrototypeAssignment of self join method Figure 6 self-join method query graphs Figure 7 cost reduction scenario is referenced Additionally the view must be executed only once further reducing the cution costs Table 1 summarizes the partial and total cost for all different methods computing the prototype for each amino acid residue Since this tabular and formular-based representation does not give any hint about the best strategy 336gure 7 gives a scenario with four different dimensions i.e d 1  4  7  10  and 5000 amino acid residues The scenario shows the resulting performance gain of the pivot method compared to minpos  and selfjoin method with 25 100 1000 and 2500 prototypes Within the proposed cost model the t method yields a slightly lower total cost than the minpos  method because the pt 212 1 ary selfjoin is considered extremely cheap r due to the dependency of the total cost from the number of prototypes the t method can not be considered a feasible solution for real applications with a reasonable high number of prototypes Compared to the self-join method the minpos  method yields a substantial cost reduction 6 Summary and Conclusion This paper introduces the problem of 336nding frequent substructures in protein data sets The analysis process is split into two parts The 336rst step consists in 336nding the Proceedings of the 15th International Conference on Sci entific and Statistical Database Management \(SSDBM\22203 1099-3371/03 $17.00 \251 2003 IEEE  


 t method view execution pt 001 1  d   f database operations inner query pt 001 1  d  pc 001 1  d   pt 1 joins outer query pc 001 1  d  001  pt 1 pt 001 1  d  pc 001  d 3 total cost pt 001 3  5 d  pc 001 5  3 d  pc 001 pt 001 1  d  self-join method view execution 2 001  pc 001 1  d  pt 001 1  d   f database operations inner query  pc 001 pt  001 3  d  1 join outer query pc 001 2 pc 001 pt  001 3  d  pc 001 3  d  2 cross product total cost pt 001 2  2 d  pc 001 7  3 d  pc 001 pt 001 6  2 d  1 group by minpos method view execution pc 001 1  d  pt 001 1  d   f database operations inner query  pc 001 pt  001 3  d  1 join outer query pc 001 2 pc 001 1  d  pc 001 3  d  1 cross product total cost pt 001 1  d  pc 001 7  3 d   pc 001 pt  001 3  d  1 group by Table 1 Cost comparison of the different methods nearest prototype in the multi-dimensional dihedral angle space To accomplish this task the data sets are brought into a relational schema and a method is proposed to compute the minimal distance considering the wrap-around effect in the angle space Three different methods to 336nd an associated prototype inside the database systems are compared A minimal SQL extension  minpos  maxpos  function results in much more ef\336cient query execution plans The second step of generating frequent item sets to detect frequent substructures within the amino acid sequences requires substantial SQL extension A ew operator as a new member of the OLAP grouping function operators is introduced This operator is a generic tool and may be ploited by a huge set of data mining applications To summarize a database system used to ef\336ciently analyse huge data volumes requires additional support from the technology  The required extension range from minimal UDFs like our proposed minpos  maxpos functions to more complex operators like our proposed grouping combinations operator f and only if the database community provides this kind of functionality the acceptance of database systems in the biotechnology community will increase in the near future References  R Agra w al T  Imielinski and A N Sw ami Mining association rules between sets of items in large databases In Proceedings of the International Conference on Management of Data  pages 207\320216 ACM Press 1993  S Bohl M Dink elack er  J  Griese and S Schrader  Highly adaptable amino acid side chain rotamer library in pdb coordinates In Workshop in Computational Biology at the Plant Biochemistry Department of the Albert-Ludwigs-Universitt Freiburg Germany  2002  M Bo wer  F  Cohen and R Dunbrack Homology modeling with a backbone-dependent rotamer library J Mol Biol  267:1268\3201282 1997  R Chandrasekaran and G Ramachandran Studies on the conformation of amino acids xi analysis of the observed side group conformations in proteins Int J Pept Prot Res  2:223\320233 1970  R Dunbrack and F  Cohen Bayesian statistical analysis of protein side-chain rotamer preferences Protein Sci  6:1661\320 1681 1997  J Gray  A  Bosw orth A Layman and H Pirahesh Data cube A relational aggregation operator generalizing groupby cross-tab and sub-total In Proceedings of the Twelfth International Conference on Data Engineering  pages 152\320 159 IEEE Computer Society 1996  A Hinneb ur g M Fischer  and F  Bahner  Finding frequent substructures in 3d-protein databases In Workshop on Bioinformatics at the 19th International Conference on Data Engineering  IEEE Computer Society 2003  M James and A Sielecki Structure and re\336nement of penicillo-pepsin at 1.8 a resolution J Mol Biol  125:299\320 361 1983  J K usze wski A Gronenborn and G Clore Impro ving the quality of nmr and crystallographic protein structures by means of conformational database potential derived from structure databases Protein Sci  5:1067\3201080 1996  S C Lo v ell J M W ord J S Richardson and D C Richardson The penultimate rotamer library Proteins Struct Funct Genet  40:389\320408 2000  M MCGre gor  S  Islam and M Sternber g Analysis of the relationship between side-chain conformation and secondary structure in globular proteins J Mol Biol  198:295\320310 1987  R Srikant and R Agra w al Mining generalized association rules In VLDB\32595 Proceedings of 21th International Conference on Very Large Data Bases Switzerland  pages 407\320 419 Morgan Kaufmann 1995  M J Zaki Ef 336cient enumeration of frequent sequences In Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management Bethesda Maryland USA November 3-7 1998  pages 68\32075 ACM 1998  M Zhang B Kao C L Y ip and D  W L Cheung Ffs an i/o-ef\336cient algorithm for mining frequent sequences In Knowledge Discovery and Data Mining PAKDD 2001 5th Paci\336c-Asia Conference Hong Kong China April 16-18 2001 Proceedings  volume 2035 of Lecture Notes in Computer Science  pages 294\320305 Springer 2001 Proceedings of the 15th International Conference on Sci entific and Statistical Database Management \(SSDBM\22203 1099-3371/03 $17.00 \251 2003 IEEE  


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



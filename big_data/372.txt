Web Search with Personalization and Knowledge  George T. Wang, F. Xie Dept. of Electrical and Computer Engineering University of California, Irvine F. Tsunoda, H. Maezawa Hitachi Software Engineering Co. Ltd. Japan  Akira K. Onoma Computer and Information Sciences Hosei University, Japan    Abstract  Although many search engines provide relevantly good search results to the user, they do not consider personal domain-specific preferences in their searching or ranking 
algorithms. In an intranet environment we could collect the background information about the users such as their expertise. If we can accumulate, categorize and personalize web usage information, it can be used to help the user search web pages efficiently and effectively. Data analysis and mining can further facilitate web searching in an intelligent way. This paper describes Internet Search Advisor \(ISA\, a personalized, knowledge-driven search system that helps the user find the informative web sites. The ISA supports multi-dimensional data analysis and data mining based on association rules and sequential patterns  1. Introduction  The Internet has impacted almost every aspect of our 
society. The number of web sites and web pages has grown rapidly so that it is almost impossible for a user to locate unknown web sites rapidly and accurately without search engines or web directories. Most of the search engines employ their own algorithms to provide relevant web sites given a set of input keywords. They are also scalable so that a user can select a specific search domain What a meta-searching engine does is to send input keywords to multiple search engines, collect outputs from them, format outputs and generate final results to the user In general, search engines decide the web page 
veral factors. These factors are nse that they do not consider personal preferences. In other words, given input keywords, the search output is identical to every user. On the other hand if we collect information of each user, for example, his expertise, experience and web usages we can provide better search results. To our knowledge little approach has been done on this subject In the following, Section 2 summarizes work related to ribes the Internet Search Advisor \(ISA\ that we have developed to support personalized web search. ISA consists of the Process Module, Parser Module, Data Analysis Module, and Data 
Mining Module. The paper is concluded in Section 4  2. Related Work  Due to the explosive growth of web pages it is impossible for web users to locate web sites or web pages of interest without a web search engine or web directory Usually a search engine crawls all websites periodically and builds an index structure for a full-text database. Web directories classify the selected web sites by subjects. It is common that a portal provides both a search engine and a web directory The Internet or an intranet can be considered as a distributed database with the following characteristics 
001\002 Distributed: Web pages are distributed across multiple web servers 001\002 Volatile: Web masters continue to update, add and delete web pages 001\002 Unstructured: Web contents include HTML pages, text her document files which are semi-structured or unstructured 001\002 Large: A web search engine needs efficient methods for crawling, indexing, storage, and query processing The Internet or an intranet can be modeled as a directed graph G:\(V, E here V 
is a set of vertices pages\d E is a set of edges \(hyperlinks\ample Figure 1 shows the graph model of an example web site If we remove the back-links a graph becomes a tree i.e., a connected, acyclic and undirected graph. These back-links can be used as an important factor to decide the page ranks o r i n s t an ce, i f  a w e b pag e  x has more back links pointing to it than page y the rank of x should be higher than that of y  To construct a search engine several steps are needed these include building a crawler, constructing page ranks 
Referen plain s h o w to crawl web pages efficiently. Referen c ribes th e structure of Google which is one of the most popular web search engines. There are many commercial search engines available right now and most of them have the generic architecture as shown in Figur Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


   A dmissions A lumni Home Libraries Students 205\205 205\205  205\205 205\205  205\205   Figure 1. The graph model of an example web site   Interface Users Query engine Index Indexer Crawler Web page description Web   Figure 2. Architecture of a generic search engine   A crawler is a software agent that visits different web sites, downloads the web pages, parses the web pages and stores the parsed information into a database. It starts with an entry URL and extracts a set of URLs from the download pages recursively in a breadth-first or depth-first manner. With breadth-first search, the crawler visits all the nodes at level n before visiting any nodes at level n+1 On the other hand, with depth-first search, the crawler follows a path until it cannot go deeper and it returns recursively. Reference addresses the problem of ordering the URLs for crawling and it concludes that a good ordering strategy enables the crawler to collect \223more important\224 pages when the buffer size is limited An inverted index data structure can be employed to store the words extracted from the downloaded pages. It usually consists of a list of keywords, each having a set of pointers to the pages in which the keyword appears Consequently, given a keyword, this data structure can be used to locate those pages that contain the keyword Some \223stopwords\224 \(e.g., articles, prepositions, etc.\ are not searchable and should not be included in the index structure Given a set of keywords \(or a query\, the query engine retrieves the web pages \(\223output\224 pages\ in which all the keywords are included. The ranking algorithm that decides in what order the output pages are displayed is the key factor to decide the quality of the search engine. The ranking algorithm usually considers several factors including the proximity of the keywords to 223rank\224 the output pages [12   The importance of data analysis can be understood if large amounts of data can be stored over the time. Data analysis tools provide summarization, understanding and organization over a data set. On-line analytical process OLAP\ was first introduced by h ere are s e v e ral Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


differences between OLAP and on-line transaction process \(OLTP\. For instance, OLTP is transactionoriented, application-oriented and simple queryoriented. On the other hand, OLAP is analysis-oriented subject-oriented and complex query-oriented. Reference  i d es a det a i l e d com p ari s on bet w een  OL A P  an d OLTP systems Most OLAP tools employ a multidimensional data model, which views data in the form of a data cube Reference es s e v e ral m e t h ods of  multidimensional aggregations for ROLAP servers Referen plain s th e u s e of  a data cu be as  a relational aggregation operator. A data cube models an n dimensional data set with a set of dimensions and facts. A fact table usually stores the subjects, and dimensions are the different perspectives of the facts The core of multidimensional data analysis aggregates the facts with a set of dimensions. A \223star\224 schema is often used to model a multidimensional data analysis With the availability of user access patterns, data mining can be applied to extract rules that relate input keywords, users, and visited URLs. In particular association rules [3  4  can b e id entif ied to co r r e late different dimensions, and sequential patterns   be used to derive search patterns of given users or a set of keywords  3. Internet Search Advisor  Today, most search engines are not personalized the output pages and their ranks are the same to every user However, there are many situations that personalization can significantly facilitate web search if we can consider user profiles and their web usage histories. As a simple example, seniors of Computer Science are usually more familiar with Java than freshmen. If a freshman student wants to obtain some information about Java she/he can first consult the \223hot list\224 \(i.e., a list of URLs that have been visited most frequently over a time period\for 223Java\224 from the seniors. Thus the knowledge of one group of users can play a role in guiding the other users to reach useful URLs sooner When a user visits the web sites his web usages information can be collected. We have developed the Internet Search Advisor \(ISA\ to accumulate the information about users\222 activities in a way transparent to the user. For instance, when a user downloads several web pages that are related to \223Java Programming\224, the ISA stores the web usage information. Later on whenever the user needs to go to web sites related to 223Java Programming\224 she/he can be directed to these sites on the \223hot list\224. By applying data analysis functions, the user can post more useful queries such as 223Which URLs were visited for input keyword \221Java Programming\222 in the last month?\224 The ISA is designed to work on top of any existing search engines \(currently Google and Alta Vista\o determine the \223hot lists\224 we consider several factors such as number of clicks, duration of each visit and user evaluations of a specific set of users As shown in Figure 3, ISA largely consists of four components: the Parser Module, the Process Module the Analysis Module, and the Mining Module  3.1 Parser Module  The Parser Module connects a user to a target search engine, passes the input keyword\(s\ to the search engine\(s\nloads the web pages, reformats the output pages, and passes the output pages to the user Each target search engine has its corresponding parser The parser can be implemented using the Common Object Model \(COM\ramming expertise to accomplish a client and server relationship in the Windows environment  3.2 Process Module  The Deliverer Process takes an input query from the user through the web browser and passes the keywords to the corresponding parser. It receives the formatted output pages from the Parser Module and generates the hot URL lists. The Bookkeeper Process is responsible for updating the database to track users\222 behaviors after the Deliverer Process generates the search output. The Reporter Process generates the hot URL lists based on a classification of users Figure 4 shows a snapshot of ISA given the input keyword \223UCI\224. The leftmost column displays the reformatted Google output and the middle column shows 1\the user\222s rank for UCI related pages, and \(2 recommendation rank for these pages from all users by adding up the visiting counts. The rightmost column allows the user to select the preferred pages of other users. Therefore we can utilize other users\222 preferences if their expertise is known   Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


  User Interface  Process module Parser module Deliverer Bookkeeper Reporter 205 Database Google A lta Vista Google Parser Alta Vista Parser A nalyzer Miner Analysis and mining modules 205    Figure 3. Architecture of ISA    Figure 4. A snapshot of ISA given the input keyword \223UCI\224  Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


3.3 Data Analysis Module  Once historical data are accumulated we can post queries. Some example queries include 001\002 Which keywords were demanded the most in the last two months 001\002 Who have used the following keywords the most in the last two months 001\002 Which web sites were visited the most in the last three months In general a data warehouse should be separated from the operational database. However, in this project we have used the same database for both purposes. We can easily separate these two when the size of the database increases Four dimensions of facts are of interest: users \(IP addresses\, keywords, URLs, and time. The measures are also user, keywords and URLs  3.3.1 Multidimensional Data Model  Considering the schema shown in Figure 5 we can create three types of 3-dimensional cubes. Note that the time-dimension is implied and it is not explicitly shown in Figure 5. Figure 6 shows the user interface for the data analysis module and its output. We can post three types of queries based on three dimensions  Q1 Which URLs were visited the most \(given a keyword\ in the last two months \(by a user A1 A list of URLs  Q2 Which keywords were demanded the most \(given a URL\ from January 2001 to May 2002 \(by a user A2 A list of keywords Q3 Who was the most frequent visitor, given a keyword, on a URL in the last three months A3 A list of users   Using the multidimensional data structure we can offer a \223recommendation\224 function and a \223similar keyword\224 function. The recommendation function is similar to the global URL hot list in that given a set of keywords, ISA recommends a list of URLs based on the number of visits It also provides a list of similar keywords for a set of keywords given. For example if a user searches for \223java design\224, ISA would provide the keywords related to the URLs corresponding to \223java design\224  3.4 Data Mining  Once ISA is operational the database size will keep increasing. It is likely that we can discover some interesting rules or correlations hidden in the large data set from the ISA database. In the ISA environment there are two kinds of knowledge to be mined: association rules and sequential patterns  3.4.1 Mining Association Rules from ISA Database  Using the association rule algorithm we can derive rules like: \223Which URLs are likely to be visited for a specific keyword?\224 and \223Which keywords are likely to be used on a specific URL?\224 The association rule approach can find some correlations from a large data set [3   Basically there are two steps involved to derive an association rule from a data set: \(1\ find frequent items and \(2\e the association rules from the frequent items We have employed the DHP \(Direct Hashing and Pruning\ algorithm [13 in the Data M i ner  T h is algo r ithm  utilizes hash techniques to accelerate the generation of frequent item sets We have also made some modifications on the original DHP algorithm to make it more efficient. The original DHP algorithm makes several scans on the transactional data. During each scan, new frequent item sets are discovered and some items in the transactional data are pruned if they will not be in any frequent item sets during the next scan. The original DHP algorithm counts the number of occurrences of an item set twice, one to count if that item set is frequent or not, and one to check whether any item in the transactional data can be deleted However, we propose that one count is eno ugh. In fact during the first count, we will already find out the items that will not appear in frequent item sets in future scans Before the starting of the k-th scan of the algorithm, we have already generated k-1 item sets. During the k-th scan we generate the candidate frequent k item sets by selectively combining two frequent k-1 item sets into one k item set using the a priori rules. Here we also employ a hash technique to discover quickly whether all the k-1 item subsets of a candidate k item set are frequent. If not we can delete this candidate k item set since it cannot be a frequent set. After then the remaining candidate k item sets will be inserted into a hash table, where they are counted to satisfy the minimum support. As shown in Figure 7, assuming a database size of 10,000 transactions the time consumed by the improved DHP algorithm decreases rapidly as we increase the minimum supporting percentage  3.4.2 Mining Sequential Patterns from the ISA Database  Whenever a client uses ISA the transaction time is recorded into the database. Using the database we can obtain some knowledge about how and when different web sites were visited. In other words, we can extract some sequential patterns based on the access information Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


 Figure 5. The ISA database schema    Figure 6. User interface for the ISA data analysis tool   Time vs. Support Percentage \(on mining 10,000 transactions 0 100 200 300 400 500 0123456 Support Percentage Time \(s   Figure 7. Sample output of the ISA data analysis tool      Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


For example assuming the data in Table 1 and the minimum support s is 2, we can extract the sequential pattern 23->38->49, i.e. users often tend to visit 23, then 38, followed by 49  t  User ID URL 1 5 23 49 1 <5 38 1 5 45 49 2 <23 2 <19 38 2 23 47 49   Extracting sequential patterns typically needs much more computational power than finding association rules The sequential discovery techniques we use involve 4 phases 001\002 Phase 1 finds the frequent item sets from the data sequences. This is almost identical to finding association rules. However, each item set is only counted once for every user. Therefore, although item 5 appears 3 times for user 1, it is only counted as appearing once 001\002 Phase 2 enumerates all the frequent items sets 1: <23 2: <38 3: <49 4: <23 49 001\002 Phase 3 transforms the original data sequences by replacing the items with the enumerated item sets  Table 2.  Transformed data  User ID URL 1 1 3 4 1 2 1 3 2 1 2 2 2 1 3 4  001\002 Phase 4 finds the frequent patterns in the transformed data by the counting algorithm similar to DHP. We can obtain the frequent sequential patterns that satisfy the minimum support. In this case, the sequences <1 2> <1 3> <2 3> <1 2 3> appear twice so they are all frequent sequences  We can employ a lexical tree to count the frequent sequential patterns efficiently during phase 4. Figure 8 shows the paths of the lexical tree. Figure 9 shows the quential pattern search algorithm along with the support percentage and the execution ansaction database  4. Conclusions  We have introduced the Internet Search Advisor ISA\, a personalized, knowledge-driven search system that helps the user to find web information based on individual preferences. To our knowledge, no existing search engines provide such personalized search results We have also implemented a data miner to extract association rules and sequential patterns based on an improved DHP algorithm that reduces the cost of the trim process. Finally we have introduced a data structure, called lexical tree, to find sequential patterns efficiently In the future, we need to develop an efficient sequential pattern data-mining algorithm that avoids generating all the candidate sets. We also need an efficient similarity-matching algorithm to find the similar URLs related to a specific keyword  References  1  R  A g arw a l   C  A g arw a l an d V  P r asad  A T r ee P r o j ect i o n  Algorithm for Generation of Frequent Item Sets Journal of Parallel and Distributed Computing pp. 350-371, 2001  2 S  Ag a r wa l  R  Ag r a wa l   P  M   D e s h p a n d e   A Gu p t a   J  F   Naughton, R.Ramakrishnan, and S. Sarawagi. On the computation of multidimensional aggregates In Proc. 1996 Int. Conf. Very Large Data Bases \(VLDB\22296 pp. 506 \226 521 Bombay, India, Sept. 1996  3  R. A g ra w a l, T  Im ie linsk i, a nd A  Sw a m i. Mining  association rules between sets of items in large databases Proc. of the ACM SIGMOD Conference on Management of Data pp. 207-216, Washington, D.C., May 1993  4 R. A g ra w a l a nd R. Srik a n t. Fa st a l g o rithm s f o r m i ning  association rules Proc. of the VLDB Conference Santiago Chile, September 1994  5  R A g ra w a l a nd R. Srik a n t. Mining Se que ntia l P a tte rns  Proc. of the 11 th Int\222l Conference on Data Engineering  Taipei, Taiwan, March 1995  6  Ri card o Baeza-Yat e s an d Bert h i er Ri b e i r o Net o  M o d e rn  Information Retrieval, Addison Wesley, New York, 1999  7 Ch ia-Hu i Ch an g an d Ch in g Ch i Hsu   En ab lin g  Co n cep tBased Relevance Feedback for Information Retrieval on the Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


WWW IEEE Transactions on Knowledge and Data Engineering vol. 11, no. 4, pp. 595 609 1999  8 S. C h a udhur i a nd U  D a y a l. A n ov e r v i e w  of  da ta  warehousing and OLAP technology. ACM SIGMOD Record 26:65-74, 1997  9  J ung hoo C ho, H e c t or G a r c ia M olina  L a w r e n c e P a g e  Efficient Crawling Through URL Ordering The Seventh International WWW Conference \(WWW98 Brisbane Australia, April 14-19, 1998    E F C odd S. B  C odd, a nd C  T  Sa lle y  B e y ond decision support Computer World 27, July 1993   J  G r a y S. C h a u dhur i, A  B o s w or th A   L a y m a n  D   Reicahrt, M. Venkatral, F. Pellow, and H. Pirahesh. Data Cube: A relational aggregation operator generalizing groupby, cross-tab and sub-totols Data Mining and Knowledge Discovery 1:29-54, 1997  12  L a w r en ce P a ge S e rgey Bri n  T h e A n at o m y o f a S earch  Engine The Seventh Internati onal WWW Conference WWW98 Brisbane, Australia, April 14-19, 1998  13 J S  P a rk M  S  Ch en  an d P  S  Yu  A n  ef f ect i v e h a sh based algorithm for mining association rules SIGMOD \22295  pp. 175-186    Root 1 2 3 4 2 3 3 3  Figure 8. A lexical tree  Time vs. Support Percentage 0 100 200 300 400 500 02468 Support Percentage Tim e  s    Figure 9. Time \(seconds\ vs. support percentage for the sequential pattern algorithm  Proceedings of the IEEE Fourth International Symposium on Multimedia Software Engineering \(MSE\22202 2002114351/02 $17.00 \251 2002 IEEE  


 A A A A A A A A B B B B B B B A B A B A B A B AB A B A A A A B B B A B A B A A B B B B A B A B A B A B A B A B A disjoint B A inside B A contains B A equals B A meets B A covered by B A covers B A overlaps B A B A B A B A B A B AB Figure 4 Topology and resolution increase with minimum bounding circles 64Mb of main memory Since the Apriori algorithm uses the number of transactions as support and we wanted to compare our algorithm with Apriori we have implemented MaxOccur and the na\250 021ve with transaction based support MaxOccur1 The second version of MaxOccur MaxOccur2 used the object-based support as presented in Algorithm 3.1 Table 9 shows the average execution times for the four algorithms with different image set sizes and 033 0 0  05 for Apriori 223Na\250 021ve\224 and MaxOccur1 and 0  0035 for MaxOccur2 The results are graphically illustrated in Figure 5 Clearly MaxOccur scales well with both versions treating one thousand images in 1.3 seconds on average regardless of the size of the data set The running time for 002ltering the frequent item-sets with 033 0  the maximum support threshold line 16 of Algorithm 3.1 is negligible since it is done in main memory once the frequent item-sets are determined Moreover the calculation of the total number of items line 4 of Algorithm 3.1 is done during the 002rst scan of the data set and has limited repercussion on the algorithms execution time The major difference between Apriori and MaxOccur is in ascertaining the candidate item-sets and counting their repeated occurrences in the images Obviously MaxOccur discovers more frequent item-sets The na\250 021ve algorithm also 002nds the same frequent item-sets but is visibly capable of less performance in execution time The left graphic in Figure 6 shows the average number of frequent item-sets discovered with the three algorithms Apriori found on average 109 different frequent k-item-sets while MaxOccur1 and Na\250 021ve found 148 on the same data sets and MaxOccur2 found 145 on average The discrepancy between MaxOccur1 and MaxOccur2 is basically due to the different de\002nition of support The price we pay in performance loss with MaxOccur is gained by more frequent item-sets and thus more potentially useful association rules with recurrent items discovered ofimages Apriori Na\250 021ve MaxOccur1 MaxOccur2 10K 6.43 70.91 13.62 13.68 25K 15.66 176.69 32.35 34.11 50K 30.54 359.38 66.07 67.44 75K 44.93 514.33 97.27 101.23 100K 60.75 716.01 130.12 137.81 Table 9 Average execution times in seconds with different number of images 0 100 200 300 400 500 600 700 800 10K 25K 50K 75K 100K Apriori MaxOccur1 MaxOccur2 Na\357ve time images Figure 5 Scale up of the algorithms 6 Discussion and conclusion We have introduced in this paper multimedia association rules based on image content and spatial relationships between visual features in images using coarse to 002ne resolution approach and we have demonstrated the preservation and changes in topological features during resolution re\002nement We have put forth a Progressive Resolution Re\002nement approach for mining visual media at different resolution levels and have presented two algorithms for the discovery of content-based multimedia association rules These rules would be meaningful only in a homogeneous image collection a collection of semantically similar images or received from the same source channel Many improvements could still be added to the multimedia mining process to speed up the discovery or to re\002ne or generalize the discovered results 017 One major enhancement in the performance of the multimedia association rule discovery algorithms is the addition of some restrictions on the rules to be discovered Such restrictions could be given in a metarule form Meta-rule guided mining consists of dis#ofimages 033 0 0  25 0  20 0  15 0  10 0  05 10K 1.43 2.20 2.70 5.06 13.51 25K 2.80 4.78 6.31 11.20 32.35 50K 6.27 9.28 11.59 22.74 66.07 75K 8.24 13.57 17.69 33.94 97.27 100K 11.32 17.63 23.13 46.74 130.12 Table 10 Average execution time in seconds of MaxOccur with different thresholds 


 0 20 40 60 80 100 120 140 160 MaxOccur2 MaxOccur1 Na\357ve Apriori Apriori MaxOccur1 MaxOccur2 Na\357ve F k  Figure 6 Frequent item\255sets found by the dif\255 ferent algorithms covering rules that not only are frequent and con\002dent but also comply with the meta-rule template For example with a meta-rule such as 223 H-Next-to X Y   Colour x red  Overlap Y Z   P  Y Z  224 one need only to 002nd frequent 3-item-sets of the form f HNext-to\(red Y  Overlap Y 003  P  Y 003  g where Y is an attribute value and P a visual descriptor or spatial relationship predicate Obviously such a 002lter would greatly reduce the complexity of the search problem A method for exploiting meta-rules for mining multilevel association rules is given in  017 We have approximated an object in an image to a locale which is an area with a consistent visual feature such as colour Objects in images and videos are obviously more complex In a recent paper 9 re gions and their signatures are used as objects in a similarity retrieval system A computationally ef\002cient way to identify distinct objects in images is however still to be proposed Automatically identifying real objects and using spatial relationships between real objects would reduce the number of rules discovered and make them more signi\002cant for some multimedia applications 017 Object recognition or identi\002cation in image processing and computer vision is a very active research 002eld Accurately identifying an object in a video for example as being an object in itself is a very dif\002cult task We believe that data mining techniques can help in this perspective Multimedia association rules with spatial relationships using the motion vector of locales as a conditional 002lter can be used to discover whether locales moving together in a video sequence are part of the same object with a high con\002dence 017 There are many application domains where multimedia association rules could be applied and should be tested such as global weather analysis and weather forecast medical imaging solar surface activity understanding etc We are investigating the application with Magnetic Resonance Imaging MRI to discover associations between lesioned structures in the brain or between lesions and pathological characteristics Further development and experiments with mining multimedia data will be reported in the future References 1 R  A gr a w al and R  S r i kant  F ast a l gor i t h ms f o r m i n i n g a ssociation rules In Proc VLDB  pages 487\226499 1994 2 M  J  E genhof er  Spatial Query Languages  PhD thesis University of Maine 1989 3 M  J  E genhof er and J  S har ma T opol ogi cal r e l a t i ons between regions in r 2 and z 2 In Advances in Spatial Databases SSD'93  Singapore 1993 4 U  M  F ayyad S  G  D j or go vski  a nd N  W e i r  A ut omat i n g the analysis and cataloging of sky surveys In U Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy editors Advances in Knowledge Discovery and Data Mining  pages 471\226493 AAAI/MIT Press 1996 5 Y  F u a n d J Han  M e ta-ru le-g u i d e d m in in g o f a sso ciatio n rules in relational databases In Proc 1st Int Workshop Integration of Knowledge Discovery with Deductive and ObjectOriented Databases  pages 39\22646 Singapore Dec 1995 6 J  H an an d Y  F u  Disco v e ry o f mu ltip le-le v el asso ciatio n r u l es from large databases In Proc VLDB  pages 420\226431 1995 7 Z  N  L i  O R Z a 250 021ane and Z Tauber Illumination invariance and object model in content-based image and video retrieval Journal of Visual Communication and Image Representation  10\(3\:219\226244 September 1999 8 R  M iller a n d Y  Y a n g  Asso ciatio n r u l es o v e r i n t erv a l d ata In Proc ACM-SIGMOD  pages 452\226461 Tucson 1997 9 A  N atse v  R Rasto g i  a n d K Sh im W ALR U S A s imilar ity retrieval algorithm for image databases In Proc ACMSIGMOD  pages 395\226406 Philadelphia 1999  R Ng L  V  S  L akshmanan J  H an a nd A Pang E x ploratory mining and pruning optimizations of constrained associations rules In Proc ACM-SIGMOD  Seattle 1998 11 R Srik an t a n d R Ag ra w a l M i n i n g q u a n titati v e asso ciatio n rules in large relational tables In Proc ACM-SIGMOD  pages 1\22612 Montreal 1996  P  S t ol or z H  N a kamur a  E  M esr obi an R  M unt z E  S h ek J Santos J Yi K Ng S Chien C Mechoso and J Farrara Fast spatio-temporal data mining of large geophysical datasets In Proc Int Conf on KDD  pages 300\226305 1995  O  R  Z a 250 021ane Resource and Knowledge Discovery from the Internet and Multimedia Repositories  PhD thesis School of Computing Science Simon Fraser University March 1999  O  R  Z a 250 021ane,J.Han,Z.-N.Li,J.Y.Chiang,andS.Chee MultiMediaMiner A system prototype for multimedia data mining In Proc ACM-SIGMOD  Seattle 1998  O  R  Z a 250 021ane J Han Z.-N Li and J Hou Mining multimedia data In CASCON'98 Meeting of Minds  Toronto 1998 


18001  balancing mechanism which requires further investi gation 4.5 Speedup Figure 12 shows the speedup ratio for pass 2 vary ing the number of processors used, 16 32 48 and 64 where the curve is normalized with the 16 processor execution time The minimum support value was set to 0.4 4.5 0.5 1 1 0 I 10 20 30 40 50 60 70 number of mxessors Figure 12 Speedup curve NPA HPA and HPA-ELD attain much higher lin earity than SPA HPA-ELD an extension of HPA for extremely large itemset decomposition further in creases the linearity HPA-ELD attains satisfactory speed up ratio This algorithm just focuses on the item distribution of the transaction file and picks up the extremely frequently occurring items Transferring such items could result in network hot spots HPA-ELD tries not to send such items but to process them locally. Such a small mod ification to the original HPA algorithm could improve the linearity substantially 4.6 Effect of increasing transaction Figure 13 shows the effect of increasing transac tion database sue as the number of transactions is increased from 256,000 to 2 million transactions We used the data set t15.14 The behavior of the results does not change with increased database size The minimum support value was set to 0.4 The num ber of processors is kept at 16 As shown each of the parallel algorithms attains linearity 5 Summary and related work In this paper we proposed four parallel algorithms for mining association rules A summary of the four database size Sizeup 0 I 0 500 loo0 1500 uxw amount of transaction thousands Figure 13 Sizeup curve algorithms is shown in Table 5 In NPA the candi date itemsets are just copied amongst all the proces sors Each processor works on the entire candidate itemsets NPA requires no data transfer when the supports are counted However in the case where the entire candidate itemsets do not fit within the mem ory of a single processor the candidate itemsets are divided and the supports are counted by scanning the transaction database repeatedly Thus Disk 1/0 cost of NPA is high PDM, proposed in 6 is the same as NPA which copies the candidate itemsets among all the processors Disk 1/0 for PDM should be also high The remaining three algorithms SPA HPA and HPA-ELD partition the candidate itemsets over the memory space of all the processors Because it better exploits the total system's memory, disk 1/0 cost is low SPA arbitrarily partitions the candidate itemsets equally among the processors Since each processor broadcasts its local transaction data to all other pro cessors the communication cost is high HPA and HPA-ELD partition the candidate itemsets using a hash function which eliminates the need for transac tion data broadcasting and can reduce the comparison workload significantly HPA-ELD detects frequently occurring itemsets and handles them separately which can reduce the influence of the workload skew 6 Conclusions Since mining association rules requires several scans of the transaction file its computational requirements are too large for a single processor to have a reasonable response time This motivates our research In this paper we proposed four different parallel algorithms for mining association rules on a shared nothing parallel machine and examined their viabil 29 


Table 5 characteristics of algorithms ity through implementation on a 64 node parallel ma chine the Fujitsu AP1000DDV If a single processor can hold all the candidate item sets parallelization is straightforward It is just suf ficient to partition the transaction over the proces sors and for each processor to process the allocated transaction data in parallel We named this algo rithm NPA However when we try to do large scale data mining against a very large transaction file the candidate itemsets become too large to fit within the main memory of a single processor In addition to the size of a transaction file a small minimum support also increases the size of the candidate itemsets As we decrease the minimum support computation time grows rapidly but in many cases we can discover more interesting association rules SPA HPA and HPA-ELD not only partition the transaction file but partition the candidate itemsets among all the processors We implemented these al gorithms on a shard-nothing parallel machine Per formance evaluations show that the best algorithm HPA-ELD attains good linearity on speedup by fully utilizing all the available memory space which is also effective for skew handling At present we are doing the parallelization of mining generalized association rules described in 9 which includes the taxonomy is-a hierarchy Each item belongs to its own class hierarchy In such mining associations between the higher class and the lower class are also examined Thus the candidate itemset space becomes much larger and its computation time also takes even longer than the naive single level association mining Parallel pro cessing is essential for such heavy mining processing Acknowledgments This research is partially supported as a priority research program by ministry of education We would like to thank the F\221ujitsu Parallel Computing Research Center for allowing us to use their APlOOODDV sys tems References l R.Agrawal T.Imielinski and ASwami 223Min ing Association Rules between Sets of Items in Large Databases\224 In Proc of the 1993 ACM SIGMOD International Conference on Manage ment of Data pp207-216 May 1993 2 R.Agrawal and RSrikant 223Fast Algorithms for Mining Association Rules\224 In Proc of the 20th International Conference on Very Large Data Bases pp.487-499 September 1994 3 J.S.Park M.-S.Chen and P.S.Yu 223An Effec tive Hash-Based Algorithm for Mining Associ ation Rules\224 In Proc of the 1995 ACM SIG MOD International Conference on the Manage ment of Data SIGMOD Record Vo1.24 pp.175 186 June 1995 4 H.Mannila H.Toivonen and A.I.Verkamo 223Ef ficient Algorithms for Discovering Association Rules\224 In KDD-94:AAAI Workshop on Knowl edge Discovery in Databases pp.181-192 July 1994 5 A.Savasere, E.Omiecinski and S.Navathe 223An Effective Algorithm for Mining Association Rules in Large Databases\224 In Proc of the 21th International Conference on Very Large Data Bases pp.432-444 September 1995 6 J.S.Park M.-S.Chen and P.S.Yu 223Efficient Parallel Data Mining for Association Rules\224 In Proc of the 4th International Conference on In formation and Knowledge Management pp.31 36 November 1995 7 T.Shintani and M.Kitsuregawa 223Considera tion on Parallelization of Database Mining\224 In Institute of Electronics Information and Com munication Engineering Japan SIG CPS Y95 88 Technical Report Vo1.95 No.47 pp.57-62 December 1995 8 T.Shimizu T.Horie and H.Ishihata 223Perfor mance Evaluation of the APlOOO Effects of message handling broadcast and barrier syn chronization on benchmark performance-\224  In S WO PP 22292 9.2 ARC 95 Information Processing Society of Japan Vo1.92 No.64 1992 9 R.Srikant and R.Agrawal 223Mining Generalized Association Rules\224 In Proc of the 21th Inter national Conference on Very Large Data Bases pp.407-419 September 1995 30 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



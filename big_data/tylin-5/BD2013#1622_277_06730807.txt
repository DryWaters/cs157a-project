Overcoming Limitations of Off-the-shelf Priority\nSchedulers in Dynamic Environments\nFeng Yan1, Shannon Hughes1, Alma Riska2, and Evgenia Smirni1\n1College of William and Mary, Williamsburg, VA, USA fyan,srhughes,esmirni@cs.wm.edu\n2EMC Corporation, Cambridge, MA, USA, alma.riska@emc.com\nAbstract—It is common nowadays to architect and design\nscaled-out systems with off-the-shelf computing components op-\nerated and managed by off-the-shelf open-source tools. While\nweb services represent the critical set of services offered at scale,\nbig data analytics is emerging as a preferred service to be co-\nlocated with cloud web services at a lower priority raising the\nneed for off-the-shelf priority scheduling. In this paper we report\non the perils of Linux priority scheduling tools when used to\ndifferentiate between such complex services. We demonstrate that\nsimple priority scheduling utilities such as nice and ionice\ncan result in dramatically erratic behavior We provide a remedy\nby proposing an autonomic priority scheduling algorithm that\nadjusts its execution parameters based on on-line measurements\nof the current resource usage of critical applications Detailed\nexperimentation with a user-space prototype of the algorithm on\na Linux system using popular benchmarks such as SPEC and\nTPC-W illustrate the robustness and versatility of the proposed\ntechnique, as it provides consistency to the expected performance\nof a high-priority application when running simultaneously with\nmultiple low priority jobs.\nI. INTRODUCTION\nComputer systems composed of off-the-shelf hardware\nrunning open-source operating systems are evolving to support\nemerging web applications and big data analytics at a large\nscale. The goal, exempli?ed by the Open Compute initiative,\nwhich was started by Facebook but has been widely adopted\nby the larger tech community, is to keep down the cost of\nvery large systems, data computation, and overall web ser-\nvices. While traditional computer systems, particularly those\nsupporting enterprise applications, have included sophisticated\n\(and often proprietary scheduling\nmodules, the industry is increasingly turning to commodity\nhardware and un-modi?ed software to accomplish large-scale\nservices and computation.\nThis trend offers a challenge. Such systems are expected to\nrun a wide array of web applications alongside signi?cant sup-\nport applications ensuring data redundancy and computation to\ndeliver individualized services to customers. For example, in a\nsystem with tens to hundreds of nodes supporting a web store,\nthere may be background processes that would need to analyze\nthe logs collected during the operation of the system, to\ngenerate preferences of the web store users, or even to analyze\nfailures and generate failure detection, isolation, and handling\nrules that are critical in ensuring resilience at scale [1]. In\norder to enable systems of the scale proposed in [2], the\nsystem architecture would follow the shared-nothing model [3]\nwhere individual servers \(or nodes distributed system while exchanging messages with other\nparticipating servers \(or nodes servers are\nexpected to be off-the-shelf hardware running general-purpose\noperating systems such as Linux, yet still provide enterprise-\ngrade computing services.\nIn such systems, the focus is on the ability to locate\nimportant but relatively time-insensitive tasks alongside user-\nfacing applications where demand uctuates semi-randomly\nand short response time is critical to meeting service level\nagreements and maintaining user engagement. This problem,\ni.e., prioritizing systems work, is often solved via scheduling\npolicies at the kernel [4], [5] or at the application level [6],\n[7], [8], [9]. In Linux, the most popular commodity operating\nsystem, priority scheduling is achieved through nice and\nionice. Though these are static prioritization tools, dynamic\namount of CPU and memory resources can be allocated to a\ngiven process via renice.\nUsing the web-driven TPC-W benchmark [10], [11] as\na representative foreground application, we experiment with\na number of background tasks from the SPEC benchmark\nsuite [12] and also our own microbenchmark. We ?nd that\nnice is at best erratic in its ability to isolate the performance\nof the high priority, time-sensitive application from the low\npriority time-insensitive background work in the system We\nalso explore the effect of adding ionice prioritization to the\nbackground processes, which helps background jobs that re-\nquire signi?cant memory resources, but can seriously damage\neffectiveness in CPU-intensive cases.\nTo address the limitations of off-the-shelf prioritization\ntools like nice and ionice, we develop smart, a portable\ntool which runs in user-space and observes the behavior of the\nforeground task in order to calculate reasonable parameters\nfor suspending and resuming background work. Extensive\nexperimentation shows that smart effectively utilizes system\nresources by scheduling background jobs only when these\nresources are lightly utilized by high priority processes. Ad-\nditionally, smart better isolates the foreground performance\nthan nice or nice plus ionice, as well as doing so\nmore consistently than either of those off-the-shelf options.\nThus, smart can be seen as a more intelligent tool that can\neffectively differentiate the level of service received by high\nand low priority processes, independent of the complexity of\ncompeting workloads.\nThe rest of the paper is organized as follows. In Sec-\ntion II, we provide results from characterizing the behavior\nof nice under several scenarios. Section III develops a new\nprioritization scheme 


which determines when and for how long\nto schedule the low priority processes according to the CPU\nutilization in the system. The new framework is evaluated via\nextended experiments in Section IV. We conclude the paper\nand summarize future work in Section VI.\n2013 IEEE 21st International Symposium on Modelling, Analysis Simulation of Computer and Telecommunication Systems\n1526-7539/13 $26.00 © 2013 IEEE\nDOI 10.1109/MASCOTS.2013.72\n505\nII. BACKGROUND AND MOTIVATION\nProprietary systems often have their own scheduling algo-\nrithms that allow them to maintain performance of user work-\nload while other lower priority jobs are running in the back-\nground. The available off-the-shelf tools for priority scheduling\nin any Unix-based system are nice, which prioritizes access\nto the CPU resource, and ionice, which prioritizes access\nto the disk resource. While different distributions of Unix\nhave different implementations of nice and ionice they\noperate similarly: when enabled, they allow users to adjust the\nexecution priority of processes.\nA process that is invoked via nice can have a scheduling\npriority between -20 \(the highest priority the lowest\npriority is set to zero or\nthe process is invoked without the nice command then the\nprocess is run with the default i.e., normal process, i.e., the higher the priority the larger\nthe chunk of CPU time the process gets. The exact relation\nbetween the nice parameter and the amount of CPU time\ndedicated to a process are implementation dependent and vary\nbetween Unix/Linux distributions. The mechanism is generally\nsimple to use and depends on ne-grained CPU consumption.\nSimilarly, ionice allows ranking the priority of a process\nfrom 0 to 3, where 3 is meant to designate a process that should\nbe given IO resources only when the IO system is otherwise\nidle. A user may select to invoke both nice and ionice. In\nour experiments, we combine nice 19 with ionice 3 to\ngive the lowest priority setting for both resources, which we\nlabel “allnice”.\nIndependent of which resource the nice or ionice\ntool try to prioritize, they differentiate concurrent jobs by\ngiving them a different time share on the resource. The time\nshare depends on the total demands of all concurrent jobs,\nirrespective of their priority. Consequently, higher priority jobs\nreceive their proportional share of the available resource rather\nthan their own absolute demand. Thus, differentiating via\nnice or ionice, which operates at the kernel-level and in\n?ne-grain time scales, may result in ?uctuating performance\nfor higher priority jobs especially if their resource demands\n?uctuate across time or high demands in multiple resources.\nIsolating the performance of high priority jobs under such\nconditions becomes challenging.\nTo illustrate the ineffectiveness of nice and ionice\nin preserving performance of high priority processes, we\nmeasure the slowdown of a high priority workload \(“fore-\nground background workloads are selected from\nthe SPEC benchmark suite [12], see Section IV-A for a\ndetailed description of the experimental setup. The foreground\nbenchmark is scheduled using the default priority in the OS\nscheduler i.e., corresponding to the value 0 of the nice\npriority parameter with\nnice with parameters ranging from 0 to 19 and also “allnice”,\ni.e., with the lowest CPU and IO priority The execution time\nof the foreground job is our target performance measure.\nWe show two scenarios in Figure 1 i.e., one where allnice\nworks as expected \(left graph right graph both graphs, the x-axis illus-\ntrates the “amount” of the background work that is executed\n 0\n 1000\n 2000\n 3000\n 4000\n 5000\n 6000\n0 2 4\nTi\nm\ne \nto\n F\nin\nis\nh \nO\nne\n It\ner\nat\nio\nn \n\(m\ns libquantum\nbaseline\nnice: 19\nnice: 10\nnice: 0\nnice: -20\nallnice\n 0\n 500\n 1000\n 1500\n 2000\n 2500\n 3000\n 3500\n 4000\n0 2 4\nTi\nm\ne \nto\n F\nin\nis\nh \nO\nne\n It\ner\nat\nio\nn \n\(m\ns 19\nnice: 10\nnice: 0\nnice: -20\nallnice\nFig. 1. Foreground performance with 2 and 4 background jobs \(all jobs are\nSPEC benchmarks no nice, baseline case i.e., nice 19 and ionice 3 job, i.e., no background, 2,\nand 4 concurrent background instances. In the left graph, SPEC\nhmmer is the foreground job and SPEC libquantum is the\nbackground one. In this experiment, nice and ionice are\neffective in isolating the performance of the foreground work-\nload independent of the amount of background work in the\nsystem. Speci?cally, the baseline case \(where the background\njob is scheduled without nice same foreground\nperformance as when the background job is scheduled with\nnice 0, as expected. Experiments where libquantum is\nscheduled with nice 10 and nice 19 maintain the perfor-\nmance of hmmer at the same level as without any background\njob. When libquantum is scheduled with priority -20, then\nindeed its priority is higher than that of hmmer and as a result\nhmmer suffers from signi?cant performance slowdown.\nThe right graph of Figure 1 shows a very different behavior.\nHere, the performance trends of the foreground job become\nclearly unpredictable and does not follow the relative priority\nset by nice. In some cases any priority parameter even -\n20 see the second bar\nfrom right in the graph with 4 bzip2 as 


background jobs delays.\nThe results in Figure 1 corroborate that nice does not\nisolate performance of high priority jobs in the presence of\nmemory and IO demands from the background jobs. The\nproblem persists even with the added boost of ionice. A\nstraightforward approach to remedy this problem is to limit\nthe impact of background jobs on foreground performance\nby slowing down the background jobs in periods of CPU\ncontention only, by suspending their execution periodically\nduring those times.\nTo give a ?rst proof-of-concept that intelligent suspending\nof the background will work, we conduct a controlled experi-\nment where the foreground workload is TPC-W [10], a web-\nservice benchmark that has signi?cant variability across time\nin its CPU and memory demands 13] and background work\nconsists of 2 and 8 simultaneous executions of hmmer from the\nSPEC suite. In these experiments, we deliberately control the\ndemands of TPC-W on the various resources by changing the\nnumber of its emulated browsers such that we know a priori\nwhen TPC-W’s resource demands are high or low. Figure 2\nplots the CDH \(Cumulative Distribution Histogram 2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 2hmmer\nNOBG\nbaseline\nnice\nallnice\nsuspend\n 0\n 100\n 200\n 300\n 400\n 500\n 600\nNO-BG\nbaseline\nnice allnice\nsuspend\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns hmmer\n 0\n 5\n 10\n 15\n 20\n 25\n 30\n 35\n 40\nNO-BG\nbaseline\nnice allnice\nsuspend\nBG\n: u\ntili\nza\ntio\nn n\(%\n 1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 8hmmer\nNOBG\nbaseline\nnice\nallnice\nsuspend\n 0\n 500\n 1000\n 1500\n 2000\n 2500\nNO-BG\nbaseline\nnice allnice\nsuspend\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns hmmer\n 0\n 10\n 20\n 30\n 40\n 50\n 60\nNO-BG\nbaseline\nnice allnice\nsuspend\nBG\n: u\ntili\nza\ntio\nn n\(%\n periodic suspending of the background jobs according to a prior known foreground behavior.\nW’s transaction response time, the overall average response\ntime of the TPC-W transactions, and the CPU share that is\nallocated to the background job. We report on four different\nways of handling the background work: 1 invoking it with the\ndefault OS priority, \(i.e., without nice or ionice, this is the\nbaseline case invoking it using nice 19 \(the lowest CPU\npriority; we label this “nice ionice 3 \(the lowest CPU and IO priority; we label this\n”allnice job in\nperiods of high CPU utilization \(which are known a priori; we\nlabel this “suspend the TPC-W response time\nwith no background job is also reported. We observe that nice\nis very ineffective for both experiments \(see the two rows of\ngraphs in Figure 2, the top representing a light background\nworkload of 2 hmmers and the bottom representing a heavy\nbackground workload of 8 hmmers performance compared to nice but suspend is steadily\na better option. Remarkably, it improves TPC-W’s performance\nwhile not starving the background job, see the rightmost col-\numn of background utilization graphs. These results motivate\nus to develop a smart scheduler that can remedy the pitfalls of\nnice and ionice while also being lightweight and easy to\nuse.\nIII. METHODOLOGY\nParameter Description\nUTILuser FG CPU util during the last Monitoring Window\nUTILnoBG long term average FG CPU util, run in isolation\nUTILwBG long term average FG CPU util, run with BG\nBWnoBG Bursty Window size of FG CPU util, run in isolation\nBWwBG Bursty Window size of FG CPU util, run with BG\nBGstatus BG status, active or suspend\nTABLE I. SUMMARY OF THE PARAMETERS IN ALGORITHM.\nAs discussed in Section II, when CPU increases and there\nis contention among processes to utilize the resource, nice\nscales down the share of all processes according to their\npriorities In a system where low priority jobs are treated as\nbest-effort processes rather than requiring steady but limited\nresources, the performance of high priority jobs can be signif-\nicantly improved by allowing the background jobs to utilize\nthe CPU only during periods when the high priority processes\nare not requesting a large portion of the resource.\nAs clari?cation, we illustrate how the foreground work-\nload, TPC-W, uses the CPU across time, see Figure 4. The\nCPU utilization and corresponding TPC-W response times\nare shown across time. In the top graph, TPC-W executes in\nisolation, i.e., there is no background work other than system\nprocesses. We can see that there are lulls, when TPC-W is not\ndemanding much CPU time, these periods correspond to low\nTPC-W response times. These are the time periods where it\nwould be most bene?cial to schedule the background work.\nIn the second graph, we see the behavior of TPC-W with 2\nsimultaneous executions of hmmer, the graph corresponds to\nthe default priorities, i.e., the baseline experiment. Here, we\nsee the dramatic effect of uncontrolled executions of hmmer\non TPC-W’s response time. In addition, the change trends of\nCPU utilization and response times suggests that monitoring\nthe CPU utilization is a good choice for our purpose.\nOur proposed algorithm, smart, aspires to schedule back-\nground/lower priority jobs only during 


low-demand time peri-\nods when the background jobs are not going to damage the\nresponsiveness of the high priority jobs. When foreground\njobs have high CPU demands, smart chooses to suspend the\nbackground jobs rather than allow the built-in scheduler to\nscale back all running processes to ?t the available resources.\nThe smart scheduling algorithm observes the behavior of\nthe foreground process to determine what level of CPU demand\nconstitutes “high” activity for that process and how long the\nperiods of high activity last. This allows smart to determine\nwhen to suspend the low priority processes and for how long to\nkeep them suspended before checking the foreground demand\nagain. The main premise of this scheduling algorithm is that\nthe foreground job is expected to be an interactive application,\nhaving periodic bursts of demand punctuated by periods of\nlow usage. Furthermore, we take response time to be the best\nmeasure of the foreground’s performance, due to the interactive\n507\nnature of the application. By scheduling background work\nduring the lulls in foreground activity and suspending them\nduring the peaks, we can protect the responsiveness of the\nforeground job while serving background work at the most\nopportune times.\nThe algorithm monitors the foreground job both while it\nruns alone and while it runs with the background work. From\nthe data collected smart “learns” the stochastic characteris-\ntics of the foreground resource demands. Speci?cally smart\nmonitors the CPU utilization at 10 second intervals and at\nthe end of the observation period categorizes each interval\nas being either of high utilization or low utilization, based\non the average observed utilization during the period. Finally,\nsmart uses the collected information to determine the average\nwindow length of consecutive high utilization intervals, which\nwe term Bursty Window \(BW length.\nWhen smart is in active scheduling mode, it continues\nto monitor the foreground process at 10 second intervals as\nlong as the background jobs are running. When an interval\nof higher than average utilization is detected, the background\nprocesses are suspended for a BW amount of time. After\nBW time elapses, smart checks the foreground utilization\nagain and resumes the background processes only if CPU\nutilization is below the average value. Otherwise, smart\nkeeps the background jobs suspended for another BW period.\nThe scheduling decisions made by smart are based on the\nappropriate average utilization and BW lengths for the current\nsystem state.\n1. if system in characterization state do\ncollect utilization information to calculate\nUTILnoBG UTILwBG, BWnoBG and BWwBG.\n2. if system in scheduling state do\na. if BGstatus = suspend\ni. if UTILuser UTILnoBG\nresume BG work\nBGstatus = active\nwait Monitoring Window\nii. else if UTILuser >= UTILnoBG\nwait BWnoBG\niii.go to Step 2.a\nb. else if BGstatus = active\ni. if UTILuser < UTILwBG\nwait Monitoring Window\nii else if UTILuser >= UTILwBG\nsuspend BG work\nBGstatus = suspend\nwait BWwBG\niii.go to Step 2.a\n3. if detect system change events \(e.g., new application\nadded, system upgrade, system failure, etc The algorithm of smart scheduling.\nA summary of the main parameters used in smart is given\nin Table I. All parameters labeled as noBG correspond to\nmeasurements with no active background jobs, while wBG\ncorresponds to measurements with active background work.\nThe algorithm itself is given in Figure 3. We emphasize that\nthe CPU utilization patterns may change over the time and\nkeep on updating the scheduling parameters can re?ect these\nchanges, as described in the Step 3 in the algorithm, such\nupdate can be event driven or periodical.\nFinally, the monitoring and suspending/resuming tools re-\nquired by the algorithm are handy in the Linux system, so\nthe algorithm is lightweight and can be implemented and\ndeployed in the user space easily please see experiment setup\nfor more details about the prototype we implemented. By\nusing the system tools the overhead of the algorithm is almost\nnegligible.\nIV. EXPERIMENTAL EVALUATION\nIn this section, we evaluate our proposed scheduling algo-\nrithm. First we give an overview of the experimental setup and\nthen we outline and discuss our results.\nA. Experimental Setup\nAll experiments presented in this paper are conducted on\na Dell Precision WorkStation with Intel Pentium Dual Core\n2.4GHz processor, 1GB memory, Seagate 7.2K SATA hard\ndrives, running openSUSE 11.4 \(64 bit TPC-W benchmark.\nAs background, we use benchmarks from the SPEC CPU2006\nsuite and our own microbenchmark.\nTPC-W is a web server and database performance bench-\nmark. The Java implementation that we use in this paper is\ndeveloped from the distribution by the University of Wisconsin\n- Madison[14]. We use tomcat as the web server and mysql\nas the database server. TPC-W provides a large number of pa-\nrameters. We use the browsing mix with 50 emulated browsers\nand 100000 items in the database. TPC-W is a challenging\nworkload for our purposes here because it is characterized by\ncontinuous variability in its resource demands across time [11],\nas also shown in Figure 4.\nSPEC CPU2006 is an industry-standard CPU-intensive\nbenchmark suite [12]. SPEC CPU2006 is composed from a\nseries of real-world applications designed to stress CPU and\nmemory usage. The ?ve workloads from SPEC we use here are\nthe following: bzip2 performs compression, decompression,\nand checking against the original at several compression scales\nfor sample input The SPEC version of the bzip2 algorithm\nprevents any IO beyond the initial read of the input so as\nto make 


this benchmark CPU and memory intensive with\nvery little IO activity. gcc performs optimized compilation\nof a large sample program, with a slight alteration to the gcc\nalgorithm to force more memory usage than would be typical\nof the real-world gcc compiler. hmmer performs searching and\nranking of sequence matches in a database, simulating gene\nsequence matching. libquantum simulates factorization as\nit would be performed on a quantum computer. povray is a\nray-tracer that simulates the way rays of light travel in a scene.\nFor a fair comparison, when the SPEC benchmark is used as\nbackground workload, we repeat its execution so that it ends\nat the same time with TPC-W.\nWe also wrote our own microbenchmark to run as back-\nground work. Most importantly this allows us to get precise\nmetrics for the behavior of the background task under smart\nand the comparison methods. Additionally, the microbench-\nmark allows us to experiment with a broader range of CPU,\nmemory, and IO demands from the background task. In the\nresults reported here, the microbenchmark steadily consumed\napproximately 25% of the system’s total CPU resource and\n508\n 0\n 20\n 40\n 60\n 80\n 100\n 0  500  1000 1500  2000  2500  3000  3500\n 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 140000\nCP\nU \nUt\nil n m\ns second FG TPC-W, no BG 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 140000\nCP\nU \nUt\nil \(\n m\ns Time \(second FG: TPC-W, BG: 2 hmmer Util\nResponse Time\nFig. 4. TPC-W utilization and response time across time without background work and under 2 hmmer bookmarks as background work.\n20% of memory capacity 1. This is accomplished simply by\nperforming multiplications in a tight loop which is embedded\nin a larger loop containing array initialization and ?le writes.\nB. Implementation\nIn order to provide a simple and easily portable im-\nplementation, our monitoring and scheduling algorithms are\nimplemented entirely in user space, making use of the readily\navailable Linux commands \(e.g., pidstat and kill into three main categories: foreground \(TPC-W-related SPEC-related or microbenchmark different from what is generally seen\nin scheduling algorithms in the literature, where measurements\nand decisions are made at the microsecond level. The long\nintervals are actually a bene?t to our method, since we are\nperforming a predictive analysis of trends. Th monitoring\ninterval here 10 seconds for the purpose of balancing overhead\nand accuracy.\nTo control the execution of the background work, we use\nthe STOP and CONT signals and pass them to process by\nthe kill command to “pause” and “resume” the background\ntask execution The process is suspended by being starved\nof resources, but because it is not actually killed, it can be\nimmediately resumed from where it is paused.\nC. Results\nTo thoroughly evaluate the performance of smart we\nrun TPC-W as the foreground task with a variety of SPEC\nbenchmarks and our own microbenchmark as background\ntasks. In Figures 6, 7, and 8, we report key performance\nmetrics from each experiment in order to compare the smart\nalgorithm to four existing possibilities. As an upper bound, we\ntake the case where TPC-W runs alone with no background\ntasks. As a lower bound, the “baseline” case is where TPC-\nW and the background tasks run together with no attempt to\ncontrol their behavior. We also include two competitors to the\nsmart algorithm: the case where the background task runs\n1we also experiment with different CPU, memory and IO demands set-\ntings for the microbenchmark, but due to the interest of space and similar\nobservations, we only show one case here as an example.\nunder lowest nice priority and the “‘allnice” case, where the\nbackground runs with both lowest nice priority and lowest\nionice priority.\nTo evaluate the performance of the foreground tasks, we\nfocus on the CDH of the TPC-W response times, which is\nthe best measure of perceived responsiveness for an interactive\napplication. The horizontal axis shows response time lengths in\nmilliseconds, while the vertical axis shows probability. Thus, if\nthe curve intersects the point \(500, 0.80 the observed response times were 500 ms or less in that\nexperiment. So, the more quickly the curve rises initially and\nthe more tightly it makes the knee bend toward the asymptote\nof 1, the better the foreground performance the users perceive.\nFirst, we conduct experiments to show the importance\nof “when” to initiate the suspension of background work.\nIn this experiment, we also report results with a periodic\nsuspension of the background job \(labeled “suspend the\nforeground workload demands, i.e., the experiment is not the\nsame as in Figure 2 where perfect future workload knowledge\nwas assumed. Figure 5 illustrates than when compared to\nthe periodic suspension, which is completely oblivious of\nthe variability in resource demands of the foreground work,\nsmart improves response time for the foreground task without\nfurther reducing the CPU time given to the background task.\nIndeed, in the 2 hmmer case, smart actually increases the\nresources given to the background \(see the utilization graphs 


over the periodic\nsleep strategy.\nObservation 1: The smart implementation improves fore-\nground performance and sometimes also background perfor-\nmance better than periodically throttling the background tasks.\nWe show the results of TPC-W run with our microbench-\nmark as background in Figure 6. We can see that smart is\nable to signi?cantly improve the response time for TPC-W,\ne.g., up to 60% less compared to nice, while at a relatively\nlow expense of slowing down the background task, as can be\nseen in the BG iterations and BG utilization graphs in the\nthird and fourth rows. Furthermore, the smart algorithm is\nless susceptible to degrading the foreground response time in\nthe presence of a larger number of background processes than\nthe other methods.\n509\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time ms 500\n 600\nNO-BG\nbaseline\nnice allnice\nsuspend\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Time Comparison \n FG: TPCW, BG: 2 hmmer\n 0\n 5\n 10\n 15\n 20\n 25\n 30\nNO-BG\nbaseline\nnice allnice\nsuspend\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n hmmer\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms Comparison - 8hmmer\nNOBG\nbaseline\nnice\nallnice\nsuspend\nsmart\n 0\n 500\n 1000\n 1500\n 2000\n 2500\nNO-BG\nbaseline\nnice allnice\nsuspend\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Comparison \n FG: TPCW, BG: 8 hmmer\n 0\n 5\n 10\n 15\n 20\n 25\n 30\n 35\n 40\nNO-BG\nbaseline\nnice allnice\nsuspend\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n hmmer\nFig. 5. Performance comparison between suspend, smart and other methods.\nObservation 2: The smart implementation is a signi?cant\nimprovement over off-the-shelf methods, especially in cases of\nmemory contention.\nFor the rest of our experiments, we report only the\nutilization given to the background task because the SPEC\nbenchmarks take too long to complete to be able to use the\nnumber of iterations as a useful metric. As expected and shown\nin the microbenchmark results in Figure 6, the amount of\nutilization given to the background task closely aligns with\nthe number of complete iterations.\nFigure 7 shows results for two instances of SPEC back-\nground tasks running with TPC-W. It is easy to see that for\nthe gcc and bzip2 background cases, the smart algorithm\nbends the response time CDH very close to the ideal case of no\nbackground work, signi?cantly improving this key metric over\nthe result achieved by nice, which actually performs worse\nthan the expected lower bound baseline case, or “allnice”,\nwhich does little better than the lower bound. We note that\nsmart makes this dramatic improvement in the foreground\nresponse time while giving the background task approximately\nthe same, admittedly small, CPU share as “allnice”.\nIn the case of povray as shown in Figure 7, smart\nstill improves the response time of the foreground, but not as\ndramatically. Compared to the gcc and bzip2 cases, there\nis simply less room for improvement between the lower and\nupper bounds. This is because povray is a CPU-intensive\nbenchmark with relatively less IO and memory activities,\nwhich plays to the strengths of the built-in schedulers. It is\nworth noting, however, that smart also gives a small boost to\nthe background performance while improving the foreground\nperformance.\nObservation 3: The smart implementation has the poten-\ntial to produce a win/win situation, where both the foreground\nand background performance bene?t over the built-in priority\nmethods.\nIn Figure 8, we report analogous results for experiments\nwith 8 instances of the background task running. These results\nshow a much bigger spread between the upper and lower\nbounds for all three cases, more like the 2 bzip2 case. This\nis because as multiple instances run together, the lower IO and\nmemory usage of the povray benchmark add up and start to\nbecome an issue. As the graphs show, the smart algorithm\nperforms solidly well in all three cases, in contrast to nice,\nwhich falls near the baseline in all cases, and “allnice”, which\nconsistently lies below smart Additionally, we note that in\nthese cases smart is able to achieve its stronger protection of\nthe foreground without penalizing the background more than\n“allnice”.\nRealistically, no systems administrator would attempt to\nrun this level of background demand on a server whose\nresponse time mattered. However, smart clearly handles\nthis kind of poor judgment better than the built-in priority\nmechanisms do.\nObservation 4: The smart implementation is robust in the\nface of unreasonably heavy amounts of attempted background\nwork.\nFinally, we examine the behavior of the smart algorithm\nacross time in the graphs shown in Figure 9. Here, the top\ngraph shows the lighter background load of 2 hmmer instances\nand the bottom graph shows the heavier 8 hmmer load We\ncan see that length of suspend periods has increased when\nthe background load is heavier and that this is providing the\nnecessary extra protection to the foreground task.\nObservation 5: The smart implementation correctly\nlearns the behavior of the foreground task and permits the\nbackground tasks to run in a complementary manner.\nTo further evaluate and improve smart, we plan to experi-\nment with less regular background work, especially less regular\nmemory and IO access patterns. We also plan to work with\nmultiple targets that can also provide throughput or completion\ndeadline protection for background work. There may be 


more\ncomplex workload that can not be well-served by smart’s\nreliance on the average CPU utilization of the foreground task\nas the key threshold for scheduling decisions. In that case, we\n510\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms micro\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500 2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms micro\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500 2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms micro\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 500\n 1000\n 1500\n 2000\n 2500\n 3000\n 3500\n 4000\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Comparison \n FG: TPCW, BG: 2 micro\n 0\n 1000\n 2000\n 3000\n 4000\n 5000\n 6000\n 7000\n 8000\n 9000\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Comparison \n FG: TPCW, BG: 4 micro\n 0\n 2000\n 4000\n 6000\n 8000\n 10000\n 12000\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Comparison \n FG: TPCW, BG: 8 micro\n 0\n 2e+08\n 4e+08\n 6e+08\n 8e+08\n 1e+09\n 1.2e+09\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n: i\nte\nra\ntio\nns\nMethods\nAverage BG Iterations Comparison \n FG TPCW, BG: 2 micro\n 0\n 1e+08\n 2e+08\n 3e+08\n 4e+08\n 5e+08\n 6e+08\n 7e+08\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n i\nte\nra\ntio\nns\nMethods\nAverage BG Iterations Comparison \n FG: TPCW, BG: 4 micro\n 0\n 5e+07\n 1e+08\n 1.5e+08\n 2e+08\n 2.5e+08\n 3e+08\n 3.5e+08\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n: i\nte\nra\ntio\nns\nMethods\nAverage BG Iterations Comparison \n FG: TPCW, BG: 8 micro\n 0\n 5\n 10\n 15\n 20\n 25\n 30\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n FG: TPCW, BG: 2 micro\n 0\n 5\n 10\n 15\n 20\n 25\n 30\n 35\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n: u\ntili\nza\ntio\nn n\(%\n 45\nNO-BG\nbaseline\nnice19\nallnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n FG: TPCW, BG: 8 micro\nFig. 6. Performance results for microbenchmark as background.\nplan to add more scheduling parameters by capturing more\nsophisticated statistical information to make our scheduling\nframework even more intelligent and robust.\nV. RELATED WORK\nIn this paper we have presented an implemented approach\nto protect the response time of a high-priority task which\nhas bursty behavior that cannot be matched to a predictable\nschedule but nevertheless can be statistically characterized in\nsome useful ways. This is quite different from traditional\nwork on real-time scheduling disciplines, which is heavily\nfocused on strictly or semi-strictly predictable periodic tasks,\nsuch as media players, and which generally require kernel\nmodi?cation, changes to application code in order to take\nadvantage of the system, and keeping track of speci?c deadline\ninformation for every task [6], [7], [8].\nWe also differ from works such as [4], which look to\nprovide kernel support for differentiating Quality of Service\nfor individual customers. We are focused on preventing back-\nground tasks on the server from interfering with any response-\ntime-sensitive tasks rather than on separating tasks requiring\ndifferent QoS. Indeed, our course-grained predictive approach\nto background task management could be combined with QoS\ndifferentiation schemes by using different thresholds to protect\nhigher QoS processes more than lower.\nRecent scheduling research has often focused on the partic-\nular problems of scheduling jobs on multicore machines and\ncomputing clusters [15], [16]. When priority schedulers are\nconsidered, it is generally with the intention of improving their\nfairness or maintaining fairness when adapting a scheduler\nto more complex circumstances [16], [17]. The individual\ncharacteristics of particular tasks are often taken into account\nfor scheduling purposes, for instance to save energy during\nperiods of low utilization [18] or to spread out intensive tasks\nto prevent thermal damage to a machine [19]. In some cases the\nnon-linear interaction of different co-located jobs is taken into\n511\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500 1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 2povray\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500 2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms Comparison - 2bzip2\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 100\n 200\n 300\n 400\n 500\n 600\n 700\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns povray\n 100\n 1000\n 10000\n 100000\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns FG Response Time Comparison \n FG: TPCW, BG: 2 gcc\n 100\n 1000\n 10000\n 100000\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns 0\n 5\n 10\n 15\n 20\n 25\n 30\nNO-BG\nbaseline\nnice allnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n Utilization Comparison \n FG: TPCW, BG: 2 povray\n 0\n 2\n 4\n 6\n 8\n 10\n 12\n 14\n 16\n 18\n 20\nNO-BG\nbaseline\nnice 


allnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n 2\n 4\n 6\n 8\n 10\n 12\nNO-BG\nbaseline\nnice allnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n Comparison \n FG: TPCW, BG: 2 bzip2\nFig. 7. Performance results for 2 SPEC benchmarks as background tasks.\naccount [20]. In this work, we look to use as much of the spare\ncapacity as possible for time-insensitive background tasks, as\nin the case of a server handling the continuous and bursty\nworkload of foreground user traf?c while also intending to\nperform replication, integrity checking, data analysis, or other\nwork [21], [22].\nVirtual machines can also be used to isolate high priority\ntasks [5]. However, this approach requires signi?cant overhead\nto manage, monitor, and adjust resource allocation to the\ndifferent virtual machines. Our approach is less expensive,\nsimpler to use, and does not require the deployment of any\nadditional software.\nPriority-based schedulers are wide-spread and intuitive, but\nit is well-known that they cannot strongly protect a high-\npriority foreground task, especially in the case of numerous\nbackground tasks, because they never starve the background\ntasks [23], [24]. We have found that under certain circum-\nstances, the behavior of Linux nice can be quite unpre-\ndictable, sometimes with worse foreground performance when\nbackground processes are given the lowest nice priority than\nwhen nice is not used at all.\nThere are a variety of approaches to address this problem\nin the literature, though differing in both approach and ultimate\ngoals from our own. Cucinotta et. al. focus on meeting accept-\nable throughput for ”soft real-time” applications, speci?cally\nmedia streaming, which has a range of acceptable frame rates\nfrom ideal to tolerable for brief periods [25]. To do this, they\ntake a signal processing approach to characterize the activ-\nity periodicity behavior of the blackbox legacy applications\nthey are attempting to control, and use the results to budget\nresources for each application. Their implementation requires\nkernel modi?cation and does not explicitly stop low priority\nbackground tasks in order to better protect foreground tasks,\nas ours does. Meehean et. al. propose a very ?exible system\nwhich requires kernel modi?cation and demonstrate a scenario\nsimilar to ours [26].\nOther researchers have focused on the progress rate of\napplications to determine appropriate resource sharing between\nthem [27], [28]. Ferguson et. al. describe a weighted fair-\nsharing system that uses the progress rate to effectively bal-\nance between jobs with speci?c deadlines of varying impor-\ntance [28]. Douceur and Bolosky share our goal more clearly,\nidentifying very low priority tasks that should not be allowed\nto impact the foreground task [27]. To determine whether\nthe background task should be run or temporarily stopped,\nthey monitor the progress rate of the background applications,\nassuming that when the progress rate falls below a particular\nthreshold, it must be because of foreground process contention\nfor shared resources. The background tasks are then stopped\nfor a window of time, then tried again Inspired by the TCP\ncongestion control mechanism, the sleep window increases\nexponentially as resource contention is repeatedly observed.\nThese approaches work well, but require a way to monitor the\nprogress rate of background applications, by the application\nthemselves reporting an application-speci?c measure during\nexecution or by a test run paired with detailed information\n512\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000 1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 8povray\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500 2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0  500  1000  1500  2000\nPr\nob\nab\nilit\ny\nResponse Time \(ms Comparison - 8bzip2\nNOBG\nbaseline\nnice\nallnice\nsmart\n 0\n 500\n 1000\n 1500\n 2000\n 2500\n 3000\n 3500\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns n FG: TPCW, BG: 8 povray\n 100\n 1000\n 10000\n 100000\n 1e+06\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns 1e+06\nNO-BG\nbaseline\nnice allnice\nsmart\nFG\n: A\nve\nra\nge\n R\nT \n\(m\ns Comparison \n FG: TPCW, BG: 8 bzip2\n 0\n 5\n 10\n 15\n 20\n 25\n 30\n 35\n 40\n 45\nNO-BG\nbaseline\nnice allnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n 0\n 2\n 4\n 6\n 8\n 10\n 12\nNO-BG\nbaseline\nnice allnice\nsmart\nBG\n: u\ntili\nza\ntio\nn \n\(%\n Utilization Comparison \n FG: TPCW, BG: 8 gcc\n 0\n 2\n 4\n 6\n 8\n 10\n 12\n 14\nNO-BG\nbaseline\nnice allnice\nsmart\nBG\n u\ntili\nza\ntio\nn \n\(%\n results for 8 SPEC benchmarks as background tasks.\n 0\n 10\n 20\n 30\n 40\n 50\n 60\n 70\n 80\n 0  500  1000  1500 2000  2500  3000  3500\nsuspend\nactive\nFG\n C\nPU\n U\ntil \n\(%\n second Utilization and BG Status Overtime Plot \(FG: TPC-W, BG: 2 hmmer, smart 40\n 50\n 60\n 70\n 80\n 0  500  1000  1500  2000  2500  3000  3500\nsuspend\nactive\nFG\n C\nPU\n U\ntil \n\(%\n S\nta\ntu\ns\nRunning Time \(second FG: TPC-W, BG: 8 hmmer smart 


algorithm.\nabout the job.\nAlso closely related to our work, Abe et. al. consider\ndistributed computing projects like SETI@home, which allow\nindividuals to donate computing time to scienti?c calculations\nwhen their computer is otherwise idle [23]. Similar to our\nwork, Abe et. al. ?nd built-in priority scheduling insuf?cient\nto protect foreground performance and choose to turn off\nbackground processing when the system detects resource con-\ntention with foreground processes. Similar to systems focused\non background task progress rate mentioned above, Abe et.\nal. monitor the background process to detect this contention\nand apply an exponential back off to reduce the impact on\nthe foreground. Instead of attempting to measure the progress\nof the background tasks, however, they monitor the share of\nresources given to the background process. If the share drops,\nthey assume that the foreground processes are now demand-\ning more resources and could bene?t from the background\ndropping altogether. In contrast, we focus on the behavior of\nthe foreground task, looking for the best periods in which to\nperform background work. We also include a learning phase,\nin which we characterize the statistical distribution of the fore-\n513\nground traf?c’s busy periods to determine the optimal periods\nto suspend the background job execution. This additionally\nallows our monitoring intervals to be much longer than most\nof other approaches, which reduces the overhead of smart\nand allows it to function entirely in the user space without\nspecial kernel modi?cation.\nTo sum up, smart scheduling differs from all the above\nwork in that it does not require changing the kernel or depend\non complex software. It does not require making changes to\nthe foreground application or its processes, it can be even\ndeployed without interrupting the current services. Therefore,\nit is lightweight, portable and ?exible.\nVI CONCLUSIONS\nScheduling high-priority jobs together with low-priority\nones in off-the-shelf systems using nice and ionice, a\nstandard non-proprietary software that is available with any\nUnix-based distribution, can be erratic, often resulting in severe\nperformance inconsistencies, especially when the resource\nconsumption of the high priority job is not constant across\ntime and when all jobs compete for more resources than just\nthe CPU. To remedy this, we present smart, a new algorithm\nfor improving the performance inconsistencies of nice and\nionice, which bases its operation on restricting the resource\nconsumption of background tasks when necessary, such that\nservice differentiation across jobs with different priorities is\nconsistent. smart is based on online monitoring of the CPU\nconsumption of the foreground job and on observing differ-\nences between the average CPU utilization of the high-priority\njob versus the utilization observed within a short time window.\nBased on these differences, best-effort jobs are suspended and\nrestarted.\nsmart is effective for high-priority workloads that are\nresource-hungry with a periodic or bursty pattern, but some-\ntimes at the detriment of the low priority jobs, i.e., the\nthroughput or completion times of low priority jobs is not part\nof the algorithm. Our on-going work focuses on addressing\nthis by providing multiple targets in terms of different perfor-\nmance metrics \(e.g., throughput versus response times versus\ncompletion deadlines different jobs \(e.g., both high and\nlow priority ones will be developed by capturing and taking advantage\nof more sophisticated statistical information.\nACKNOWLEDGMENTS\nThis work has been supported by NSF grants CCF-0937925\nand CCF-1218758.\nREFERENCES\n[1] A. Rabkin and R. Katz, “Chukwa: a system for reliable large-scale\nlog collection in Proceedings of the 24th international conference\non Large installation system administration, ser. LISA’10 Berkeley,\nCA, USA: USENIX Association, 2010, pp. 1–15. [Online Available:\nhttp://dl.acm.org/citation.cfm?id=1924976.1924994\n[2] “The open compute project http://www.opencompute.org/, 2011.\n[3] M. Stonebraker, “The case for shared nothing,” IEEE Database Eng.\nBull., vol. 9, no. 1, pp. 4–9, 1986.\n[4] R. Zhang, T. Abdelzaher, and J. Stankovic, “Kernel support for open\nqos-aware computing,” in Real-Time and Embedded Technology and\nApplications Symposium, 2003. Proceedings The 9th IEEE, 2003, pp.\n96–105.\n[5] P. Padala, K.-Y. Hou, K. G. Shin, X. Zhu, M. Uysal, Z. Wang,\nS. Singhal and A. Merchant, “Automated control of multiple virtualized\nresources,” in EuroSys, 2009, pp. 13–26.\n[6] L Sha, T. F. Abdelzaher, K.-E. rzn, A. Cervin, T. P. Baker, A. Burns,\nG. C. Buttazzo, M. Caccamo, J. P Lehoczky, and A. K. Mok, “Real\ntime scheduling theory: A historical perspective.” 2004, pp. 101–155.\n[7] J Nieh and M. S. Lam, “A smart scheduler for multimedia applications.”\n2003, pp. 117–163.\n[8] C. W. Mercer, S Savage, and H. Tokuda, “Processor capacity reserves:\nOperating system support for multimedia applications.” in ICMCS,\n1994, pp. 90–99.\n[9] J. Hwang and T. Wood, “Adaptive dynamic priority scheduling for\nvirtual desktop infrastructures,” in IWQoS, 2012, pp. 1–9.\n[10] “TPC-W,” http://www.tpc.org/tpcw/.\n[11] E. Cecchet, A. Ch, S Elnikety, J. Marguerite, and W. Zwaenepoel, “A\ncomparison of software architectures for e-business applications,” In\nProc. of 4th Middleware Conference, Rio de, Tech. Rep., 2002.\n[12] J. L. Henning, “Spec cpu2006 benchmark descriptions,” SIGARCH\nComput. Archit. News, vol. 34, no. 4, pp. 1–17, Sep. 2006 Online].\nAvailable: http://doi.acm.org/10.1145/1186736.1186737\n[13] Q. Wang, Y. Kanemasa, M. Kawaba, and C 


Pu, “When average\nis not average: large response time ?uctuations in n-tier systems,”\nin Proceedings of the 9th international conference on Autonomic\ncomputing, ser. ICAC ’12. New York, NY, USA: ACM, 2012, pp. 33–\n42 Online]. Available: http://doi.acm.org/10.1145/2371536.2371544\n[14] T. Bezenek, T. Cain, R. Dickson, T. Heil M. Martin, C. McCurdy,\nR. Rajwar, E. Weglarz, C. Zilles, and M. Lipasti, “Java tpc-w imple-\nmentation distribution,” http://pharm/ece.wisc.edu/tpcw.shtml, 2011.\n[15] M. Isard, V. Prabhakaran, J. Currey, U Wieder, K. Talwar, A. Goldberg,\nand A. Goldberg, “Quincy: fair scheduling for distributed computing\nclusters in SOSP, 2009, pp. 261–276.\n[16] M. Zaharia, D. Borthakur, J. S. Sarma, K. Elmeleegy, S. Shenker,\nI. Stoica and I. Stoica, “Delay scheduling: a simple technique for\nachieving locality and fairness in cluster scheduling.” in EuroSys, 2010,\npp. 265–278.\n[17] C. Krasic, M. Saubhasik, A. Sinha, A. Goel, and A. Goel Fair and\ntimely scheduling via cooperative polling.” in EuroSys, 2009, pp. 103–\n116.\n[18] E. Thereska, A Donnelly, D. Narayanan, and D. Narayanan, “Sierra:\npractical power-proportionality for data center storage in EuroSys,\n2011, pp. 169–182.\n[19] A. K. Coskun, R. D. Strong, D. M. Tullsen, T. S. Rosing, and\nT. S. Rosing Evaluating the impact of job scheduling and power\nmanagement on processor lifetime for chip multiprocessors in SIG-\nMETRICS/Performance, 2009, pp. 169–180.\n[20] S.-H. Lim, J.-S. Huh, Y. Kim, G. M. Shipman, C. R. Das and C. R.\nDas, “D-factor: a quantitative model of application slow-down in multi-\nresource shared systems.” in SIGMETRICS, 2012, pp. 271–282.\n[21] N. Mi, A. Riska, X. Li, E. Smirni, and E. Riedel, “Restrained utilization\nof idleness for transparent scheduling of background tasks,” in Proceed-\nings of the Eleventh International Joint Conference on Measurement and\nModeling of Computer Systems, SIGMETRICS/Performance, 2009 pp.\n205–216.\n[22] F. Yan, A. Riska, and E. Smirni, “Fast eventual consistency with\nperformance guarantees for distributed storage,” in ICDCS Workshops,\n2012, pp. 23–28.\n[23] Y. Abe, H. Yamada, K. Kono, and K. Kono Enforcing appropriate\nprocess execution for exploiting idle resources from outside operating\nsystems.” in EuroSys, 2008, pp. 27–40.\n[24] L. Eggert and J. D. Touch, “Idletime scheduling with preemption\nintervals,” in SOSP, 2005, pp. 249–262.\n[25] T. Cucinotta, F. Checconi, L. Abeni, L. Palopoli, and L. Palopoli, “Self-\ntuning schedulers for legacy real-time applications.” in EuroSys, 2010,\npp. 55–68.\n[26] J. Meehean, A Arpaci-Dusseau, R. Arpaci-Dusseau, and\nM. Livny, “CPU Futures: Scheduler support for application\nmanagement of cpu contention,” Technical Report at:\nhttp://research.cs.wisc.edu/techreports/2010/TR1684.pdf, 2011.\n[27] J R. Douceur, W. J. Bolosky, and W. J. Bolosky, “Progress-based\nregulation of low-importance processes.” in SOSP, 1999, pp. 247–260.\n[28] A. D. Ferguson, P. Bodk, S. Kandula, E. Boutin, R. Fonseca, and\nR. Fonseca Jockey: guaranteed job latency in data parallel clusters.”\nin EuroSys, 2012, pp. 99–112.\n514\n 


Meteosat, and \nthen worked on Cluster, Huygens and XMM-Newton.   \nBefore joining ESA he was employed in the aerospace \nindustry in France, where he developed embedded \nsoftware systems. He graduated as an engineer in the \nEcole Centrale de Paris, and later obtained a master's \ndegree in Space Engineering. \n \n 


the?Vdeorbit is computed based on a change of\nsemimajor axis from the current circular orbit to an elliptical\norbit that has the perigee at 0km and the apogee at the orbit\naltitude:\n?Vdeorbit,drag = ?V \(r, r RE , r, r 23 semimajor axis from the\ncurrent circular orbit to an elliptical orbit that has the same\nperigee and a slightly higher apogee:\n?Vdeorbit,SRP = ?V \(r, r, r, r + ?h, r 24 are due to the GEO restricted zone, the\n35km are to allow for gravitational perturbations, and the\nremaining margin depends on the magnitude of the effect of\nsolar radiation pressure on the spacecraft \(the larger the ef-\nfect, the larger the margin the spacecraft.\nOnce the ?V has been calculated, it is possible to compute\nthe propellant mass required to satisfy this ?V budget. The\ntool assumes that ?Vinj is performed by the apogee kick\nmotor \(AKM other ?V are performed by the\nADCS subsystem. For each of these propulsion systems, the\npropellant mass can be computed using the rocket equation:\n?Vj = gIsp,j log\nmi\nmf\n\(25 which can be\ndifferent for the AKM and the ADCS subsystem, mi is the\ninitial mass with propellant and mf is the final mass without\nthe propellant.\nAttitude Determination and Control and Propulsion Subsys-\ntem—The mass of the ADCS is mostly given by the mass\nof the sensors and the mass of the actuators. The mass\nof the sensors is driven by the attitude knowledge accuracy\nrequirement acc \(Equation 26 satisfy by the momentum storage h required \(Equation 27 26 27 that acc can vary depending on the architecture, as the\npointing requirements of a high gain antenna, or an optical\npayload, are very different from those of a low gain antenna.\nConcerning the momentum storage h, it is assumed to be\nsized to counter the different disturbance torques produced by\natmospheric drag, gravity gradient, solar radiation pressure,\nor the Earth’s magnetic field. Expressions for these distur-\nbance torques were taken from [25].\nIn addition to sensors and actuators, the ADCS has additional\nmass that can be estimated as a fix fraction of the spacecraft\ndry mass:\nmADCS = 3msen + 4mact + 0.01mdry \(28 subsystem, the mass of the AKM\ncan be estimated from its propellant mass assuming a certain\nmass fraction:\nmAKM =\n\(1 29 structure subsystem\nSubsystem k\nThermal 0.0607\nAvionics 0.0983\nStructure 0.5462\nThermal, avionics, and structure subsystems—The thermal,\navionics, and structure subystems are designed using simple\nparametrics of the form msubsystem = kmpayload. The\nconstans k that are used for each subsystem are summarized\nin Table 8.\nThe mass of the launch adapter mLA = 0.01mdry is added\nto the mass of the spacecraft.\nUpdate spacecraft mass and dimensions—After the first iter-\nation, the dry and wet mass of the spacecraft are updated.\nDimensions are estimated assuming a perfect cube of 100\nkg/m3. The mass and dimensions of the solar panels are\ntaken into account to update the inertial properties of the\nspacecraft, as illustrated in Equation 30:\nLA = 1.5s+ 0.5\n?\nAa\n2\nIz = 0.01mdry\nIx = Iy = Iz + L\n2\naMa \(30 design algorithm is\niterative because several feedback loops appear in the N2\nmatrix showing the dependences between different modules\nin the algorithm. For instance, the mass of the ADCS depends\non the mass of the spacecraft, which obviously depends on the\nmass of the ADCS. Thus, a set of convergence criteria need\nto be defined. The convergence criteria used by the tool are\ndescribed in Equation 31:\n|mdry,i+1 ?mdry,i| < 10kg 31 the current status of the MIT archi-\ntecture study for the SCaN system. The study consists of a\nstakeholder analysis to identify the primary stakeholders and\ntheir needs, and the development of a computational tool to\nexplore the architectural tradespace.\nSeveral interviews have been conducted with experts at\nNASA to elicit the potential requirements on SCaN from\ndifferent user communities.\nThe major architectural decisions to be made by the SCaN\nprogram have been identified and encoded in a mathematical\nmodel. A computational tool has been developed that can\nautomatically enumerate and evaluate thousands of different\nSCaN architectures. This tool contains both a performance\nand a cost model.\nNext Steps\nThe next steps include calibration of the optical link budget\ncalculations, comparisons of the network scheduling calcula-\ntions with historical TDRSS load data, and validation of the\nspacecraft sizing algorithm with real TDRS data. Following\nthe completion of the stakeholder analysis, the tool will be\nbe used to explore the architectural tradespace and identify\na subset of preferred architectures worth studying in more\ndetail. These architectures could then be analyzed in NASA’s\nArchitecture Development Lab \(ADL NNX11AR70G.\nThe authors would also like to thank the Centre de Formacio\nInterdisciplina`ria Superior and the Cellex Foundation for\npartially funding this project.\nREFERENCES\n[1] S. Tsiao, Read you loud and clear! The story of NASA’s\nspaceflight tracking and data network. Washington\nDC: Library of Congress, 2007.\n[2] G. Maral Satellite Communication Systems: systems,\ntechniques and technology, 2009.\n[3] K. Y. Jo, “Satellite 


communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[4] E. Jennings and D. Heckman, “Architecture Modeling\nand Performance Characterization of Space Communi-\ncations and Navigation \( SCaN  R. Borgen, S. Nguyen, J. Segui, T. Stoe-\nnescu, S.-y. Wang, and S. Woo, “Space Communica-\ntions and Navigation SCaN Astronautics, no. August, pp. 1–11,\n2009.\n[6] E. Jennings and D. Heckman, “Performance Charac-\nterization of Space Communications and Navigation\n\(SCaN Mar. 2008.\n[7] J. Alonso and K. Fall, “A Linear Programming For-\nmulation of Flows over Time with Piecewise Constant\nCapacity and Transit Times piecewise constant capacity\nand transit times,” 2003.\n[8] B. L. Murphy High Resolution Satellite Communica-\ntion Simulation,” 2000.\n[9] M. Werner, A. Jahn, E. Lutz, and A Bottcher, “Analysis\nof System Parameters for LEO/ICO-Satellite Commu-\nnication Networks,” 1995.\n[10] T Weilkiens, Systems engineering with SysML/UML:\nmodeling, analysis, design. Heidelberg, Germany: The\nMorgan Kaufmann/OMG Press, 2006.\n[11] M. Rao, S. Ramakrishnan, and C. Dagli, “Modeling and\nSimulation of Net Centric System of Systems Using\nSystems Modeling Language and Colored Petri-nets :\nA Demonstration Using the Global Earth Observation\n14\nSystem of Systems,” Systems Engineering, vol. 11,\nno. 3, pp. 203–220, 2008.\n[12] B. H. Y Koo, W. L. Simmons, and E. F. Crawley, “Al-\ngebra of Systems: A Metalanguage for Model Synthesis\nand Evaluation,” IEEE Transactions on Systems, Man,\nand Cybernetics - Part A: Systems and Humans, vol. 39,\nno. 3 pp. 501–513, May 2009.\n[13] M. Ehrgott and X. Gandibleux, “A Survey and An-\nnotated Bibliography of Multiobjective Combinatorial\nOptimization,” OR Spectrum, vol. 22, no. 4, pp. 425–\n460, Nov. 2000.\n[14] D Selva, “Rule-based system architecting of Earth\nobservation satellite systems,” PhD dissertation Mas-\nsachusetts Institute of Technology, 2012.\n[15] D. Selva and E. F. Crawley, “VASSAR: Value Assess-\nment of System Architectures using Rules,” in Proceed-\nings of the 2013 IEEE Aerospace Conference, Big Sky,\nMontana 2013.\n[16] T. Sutherland, B. Cameron, and E. Crawley, “Program\ngoals for the nasa/noaa earth observation program de-\nrived from a stakeholder value network analysis,” 2012.\n[17] B. Cameron, E. Crawley, G. Loureiro and E. Reben-\ntisch, “Value flow mapping: Using networks to inform\nstakeholder analysis,” Acta Astronautica vol. 62, pp.\n324–333, 2008.\n[18] B. Cameron and Crawley, “Goals for space exploration\nbased on stakeholder network value considerations,”\nActa Astronautica, vol. 68, pp. 2088–2097, 2011.\n[19] D. Selva and E. F Crawley, “Integrated Assessment of\nPackaging Architectures in Earth Observing Programs,”\nin Proceedings of the 2011 IEEE Aerospace Confer-\nence, Big Sky, Montana, 2010.\n[20] O. P. Gupta and C. S. Fish, “Iridium NEXT: A Global\naccess for your sensor needs,” in Proceedings of the\n2010 American Geophysical Union Fall Meeting San\nFrancisco, CA, 2010.\n[21] T. Stoenescu and L. Clare, “Traffic Modeling for\nNASA’s Space Communications and Navigation\n\(SCaN  communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[23] H. Apgar, “Cost Estimating,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 11.\n[24] R. S. Bokulic, C. C. DeBoy, S. W. Enger, J. P. Schnei-\nder and J. K. McDermott, “Spacecraft Subsystems IV\nCommunications and Power,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 21.\n[25] P. Springmann and O. de Weck, “Parametric scaling\nmodel for nongeosynchronous communications satel-\nlites,” Journal of spacecraft and rockets, vol. 41, no. 3,\npp 472–477, 2004.\nBIOGRAPHY[\nMarc Sanchez is a senior student from\nUniversitat Politecnica de Catalunya\n\(Barcelona, Spain Telecommunications En-\ngineering. His is currently a Visiting\nStudent at the Space System Architecture\nGroup of MIT, focusing his interests in\nrule-based expert systems and how they\ncan be applied to space communications\nnetworks. Prior to his work at MIT, Marc has been a\nsoftware engineer at Sener Ingenieria y Sistemas involved in\nthe development of commercial software FORAN CAD/CAM.\nDr. Daniel Selva received a PhD in\nSpace Systems from MIT in 2012 and\nhe is currently a post-doctoral associate\nin the department of Aeronautics and\nAstronautics at MIT. His research inter-\nests focus on the application of multi-\ndisciplinary optimization and artificial\nintelligence techniques to space systems\nengineering and architecture, in partic-\nular in the context of Earth observa-\ntion missions. Prior to MIT, Daniel worked for four years\nin Kourou \(French Guiana in\noperations concerning the guidance, navigation and control\nsubsystem, and the avionics and ground systems Daniel has\na dual background in electrical engineering and aeronautical\nengineering, with degrees from Universitat Politecnica de\nCatalunya in Barcelona, Spain, and Supaero in Toulouse,\nFrance. He is a 2007 la Caixa fellow, and received the Nortel\nNetworks prize for academic excellence in 2002.\nDr. Bruce Cameron is a Lecturer\nin Engineering Systems at MIT and a\nconsultant on platform strategies. At\nMIT, Dr. Cameron ran the 


MIT Com-\nmonality study, a 16 firm investigation\nof platforming returns. Dr. Cameron’s\ncurrent clients include Fortune 500 firms\nin high tech, aerospace, transportation,\nand consumer goods. Prior to MIT,\nBruce worked as an engagement man-\nager at a management consultancy and as a system engineer\nat MDA Space Systems, and has built hardware currently in\norbit. Dr. Cameron received his undergraduate degree from\nthe University of Toronto, and graduate degrees from MIT.\nDr. Edward F. Crawley received an\nSc.D. in Aerospace Structures from MIT\nin 1981. His early research interests\ncentered on structural dynamics, aeroe-\nlasticity, and the development of actively\ncontrolled and intelligent structures. Re-\ncently, Dr. Crawleys research has fo-\ncused on the domain of the architecture\nand design of complex systems. From\n1996 to 2003 he served as the Depart-\nment Head of Aeronautics and Astronautics at MIT, leading\nthe strategic realignment of the department Dr. Crawley is a\nFellow of the AIAA and the Royal Aeronautical Society \(UK academies of engineering.\n15\nHe is the author of numerous journal publications in the\nAIAA Journal, the ASME Journal, the Journal of Composite\nMaterials, and Acta Astronautica. He received the NASA\nPublic Service Medal Recently, Prof Crawley was one of\nthe ten members of the presidential committee led by Norman\nAugustine to study the future of human spaceflight in the US.\nBernard D. Seery is the Assistant Di-\nrector for Advanced Concepts in the Of-\nfice of the Director at NASA’s Goddard\nSpace Flight Center \(GSFC include assisting the Deputy\nDirector for Science and Technology\nwith development of new mission and\nmeasurement concepts, strategic analy-\nsis, strategy development and investment\nresources prioritization Prior assign-\nments at NASA Headquarters included Deputy for Advanced\nPlanning and Director of the Advanced Planning and In-\ntegration Office \(APIO and Evaluation \(PA&E DAA and Physical Research \(OBPR Directorate, Code 600, at \(GSFC bachelors of science in physics, with emphasis in\nnuclear physics. He then attended the University of Ari-\nzona’s School of Optical Sciences, and obtained a masters\ndegree in Optical Sciences, specializing in nonlinear optical\napproaches to automated alignment and wavefront control\nof a large, electrically-pumped CO2 laser fusion driver. He\ncompleted all the course work for a PhD in Optical Sciences\nin 1979, with emphasis in laser physics and spectroscopy. He\nhas been a staff member in the Laser Fusion Division \(L-\n1 Alamos National Laboratories \(LANL working on innovative infrared laser auto-alignment\nsystems and infrared interferometry for target alignment for\nthe HELIOS 10 kilojoule, eight-beam carbon dioxide laser\nfusion system. In 1979 he joined TRW’s Space and Defense\norganization in Redondo Beach, CA and designed and de-\nveloped several high-power space lasers and sophisticated\nspacecraft electro-optics payloads. He received the TRW\nPrincipal Investigators award for 8 consecutive years.\nDr. Antonios A. Seas is a Study Man-\nager at the Advanced Concept and For-\nmulation Office ACFO Electro-Optics branch where\nhe focused on optical communications\nand the development of laser systems\nfor space applications. Prior to joining\nNASA in 2005 he spent several years in\nthe telecommunication industry developing long haul sub-\nmarine fiber optics systems, and as an Assistant Professor\nat the Bronx Community College. Antonios received his\nundergraduate and graduate degrees from the City College of\nNew York, and his doctoral degree from the Graduate Center\nof the City University of New York. He is also a certified\nProject Management Professional.\n16\n 


1483\nSUB-NYQUIST SAMPLING RATES\nMustafa Al-Ani, University of Westminster, United Kingdom; Bashar Ahmad, University of Cambridge, \nUnited Kingdom; Andrzej Tarczynski University of Westminster, United Kingdom\nTPa-8.10: OPPORTUNISTIC TRANSMITTER SELECTION FOR SELFLESS 1488\nOVERLAY COGNITIVE RADIOS\nMohammad Shaqfeh, Texas A&M University at Qatar, Qatar; Ammar Zafar, King Abdullah University \nof Science and Technology, Saudi Arabia Hussein Alnuweiri, Texas A&M University at Qatar, Qatar; \nMohamed-Slim Alouini, King Abdullah University of Science and Technology, Saudi Arabia\nTPa-8.11: A GAME THEORETIC POWER CONTROL FRAMEWORK FOR 1493\nSPECTRUM SHARING IN COMPETITIVE ENVIRONMENTS\nRaghed El-Bardan, Swastik Brahma, Pramod K. Varshney, Syracuse University, United States\nTPa-8.12: COGNITIVE RADIO TRANSMISSION STRATEGIES FOR PRIMARY ...........................................1498\nERASURE CHANNELS\nAhmed ElSamadouny, University of Texas at Dallas, United States; Mohammed Nafie, Ahmed Sultan, \nNile University Egypt\nTPa-8: RELAYS IN COMMUNICATIONS\nTPa-8.1: OPTIMIZED RECEIVER DESIGN FOR DECODE-AND-FORWARD 1535\nRELAYS USING HIERARCHICAL MODULATION\nTu Nguyen, Broadcom Corporation, United States; Pamela Cosman, Laurence Milstein, University of \nCalifornia, San Diego, United States\nTPa-8.2: OPTIMAL LINEAR-COMBINING RECEIVER FOR 1540\nDECODE-AND-FORWARD RELAYS USING SUPERPOSITION CODING\nTu Nguyen, Broadcom Corporation, United States; Laurence Milstein, University of California, San \nDiego, United States\nTPa-8.3: ALTERNATE RELAYING AND THE DEGREES OF FREEDOM OF 1545\nONE-WAY CELLULAR RELAY NETWORKS\nAya Salah, Amr El-Keyi Mohammed Nafie, Nile University, Egypt\nTPa-8.4: DISTRIBUTED AF BEAMFORMING RELAY NETWORKS UNDER 1550\nTRANSMIT POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon Edwin M. Sawan, Wichita State University, United States; Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nTPa-8.5: JOINT TRANSMIT DESIGN AND NODE SELECTION FOR 1555\nONE-WAY AND TWO-WAY UNTRUSTED RELAY CHANNELS\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.6: WIRELESS PHYSICAL LAYER SECURITY ENHANCEMENT WITH  ..............................................1560\nBUFFER-AIDED RELAYING\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.7: TRAINING SLOT ALLOCATION FOR MITIGATING ESTIMATION  ................................................1565\nERROR PROPAGATION IN A TWO-HOP RELAYING SYSTEM\nQian Gao, Gang Chen, Yingbo Hua, University of California, Riverside United States\nxxv\nTPa-8.8: TRANSMIT OUTAGE PRE-EQUALIZATION FOR 1570\nAMPLIFY-AND-FORWARD RELAY CHANNELS\nFernando Sanchez, Gerald Matz, Vienna University of Technology, Austria\nTPa-8: ADAPTIVE FILTERING\nTPa-8.1: A GRADIENT-CONTROLLED IMPROVED PROPORTIONATE 1505\nMULTI-DELAY FILTER\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nTPa-8.2: COMPLEX PROPORTIONATE-TYPE AFFINE PROJECTION  ...........................................................1510\nALGORITHMS\nKevin Wagner Naval Research Laboratory, United States; Miloš Doroslovacki, George Washington \nUniversity, United States\nTPa-8.3: RADAR WAVEFORM DESIGN IN ACTIVE COMMUNICATIONS 1515\nCHANNEL\nKevin Shepherd, Ric Romero, Naval Postgraduate School, United States\nTPa-8.4: THE LEAKY LEAST MEAN MIXED NORM ALGORITHM................................................................1520\nMohammed Abdul Nasar, Azzedine Zerguine, King Fahd University of Petroleum & Minerals, Saudi \nArabia\nTPa-8.5: A NEW VARIABLE STEP-SIZE ZERO-POINT ATTRACTING  ...........................................................1524\nPROJECTION ALGORITHM\nJianming Liu, Steven Grant, Missouri University of Science and Technology, United States\nTPa-8.6 RECURSIVE LEAST SQUARES FILTERING UNDER STOCHASTIC 1529\nCOMPUTATIONAL ERRORS\nChandrasekhar Radhakrishnan, Andrew Singer, University of Illinois at Urbana-Champaign, United \nStates\nTPa-8: CELLULAR AND HETEROGENEOUS NETWORKS\nTPa-8.1: DOWNLINK COVERAGE ANALYSIS OF N-TIER 1577\nHETEROGENEOUS CELLULAR NETWORKS BASED ON CLUSTERED STOCHASTIC \nGEOMETRY\nChunlin Chen, Robert Elliott, Witold Krzymien, University of Alberta / Telecommunications Research \nLaboratories, Canada\nTPa-8.2: SYSTEM-LEVEL PERFORMANCE OF THE MIMO-OFDM 1582\nDOWNLINK WITH DENSE SMALL CELL OVERLAYS\nThomas Wirth, Bernd Hofeld, Fraunhofer Heinrich Hertz Institute, Germany\nTPa-8.3: ADAPTIVE HARQ AND SCHEDULING FOR VIDEO OVER LTE......................................................1584\nAvi Rapaport, Weimin 


Liu, Liangping Ma, Gregory S. Sternberg, Ariela J. Zeira, Anantharaman \nBalasubramanian, InterDigital, United States\nTPa-8.4: NOVEL PARTIAL FEEDBACK SCHEMES AND THEIR EVALUATION 1589\nIN AN OFDMA SYSTEM WITH CDF BASED SCHEDULING\nAnh Nguyen University of California, San Diego, United States; Yichao Huang, Qualcomm \nTechnologies, Inc., United States Bhaskar D. Rao, University of California, San Diego, United States\nTPa-8.5: OPPORTUNISTIC THIRD-PARTY BACKHAUL FOR CELLULAR  ...................................................1594\nWIRELESS NETWORKS\nRussell Ford, Changkyu Kim, Sundeep Rangan, Polytechnic Institute of New York University, United \nStates\nTPa-8.6: PROACTIVE USER ASSOCIATION IN WIRELESS SMALL CELL  ...................................................1601\nNETWORKS VIA COLLABORATIVE FILTERING\nFrancesco Pantisano, Joint Research Center, Italy; Mehdi Bennis, University of Oulu Finland; Walid \nSaad, University of Miami, United States; Stefan Valentin, Bell Labs, Alcatel-Lucent, Germany nMérouane Debbah, Supélec, France; Alessio Zappone, Technische Universität Dresden, Germany\nTPa-8.7 INTERFERENCE ANALYSIS OF MULTI-HOP CELLULAR SENSOR 1606\nNETWORKS\nYeashfi Hasan, R. Michael Buehrer, Virginia Polytechnic Institute and State University, United States\nxxvi\nTPb-1: FULL-DUPLEX MIMO COMMUNICATIONS II\nTPb-1.1: DIVERSITY-MULTIPLEXING TRADEOFF ANALYSIS OF MIMO 1613\nRELAY NETWORKS WITH FULL-DUPLEX RELAYS\nQiang Xue University of Oulu, Finland; Anna Pantelidou, Renesas Mobile Europe, Finland; Behnaam \nAazhang, Rice University, United States\nTPb-1.2: ERGODIC MUTUAL INFORMATION OF FULL-DUPLEX MIMO 1618\nRADIOS WITH RESIDUAL SELF-INTERFERENCE\nAli Cagatay Cirik, University of California, Riverside, United States; Yue Rong, Curtin University, \nAustralia; Yingbo Hua, University of California, Riverside, United States\nTPb-1.3: FULL-DUPLEX IN LARGE-SCALE WIRELESS SYSTEMS 1623\nBei Yin, Michael Wu, Christoph Studer Joseph R. Cavallaro, Rice University, United States; Jorma \nLilleberg, Broadcom, United States\nTPb-1.4 FULL-DUPLEX COMMUNICATION VIA ADAPTIVE NULLING......................................................1628\nScott Johnston, Paul Fiore, Massachusetts Institute of Technology, United States\nTPb-1.5: WEIGHTED-SUM-RATE MAXIMIZATION FOR BI-DIRECTIONAL  ...............................................1632\nFULL-DUPLEX MIMO SYSTEMS\nAli Cagatay Cirik, University of California, Riverside, United States; Rui Wang, The Chinese nUniversity of Hong Kong, Hong Kong SAR of China; Yingbo Hua, University of California, Riverside, \nUnited States\nTPb-2: PHY PERFORMANCE ABSTRACTION TECHNIQUES\nTPb-2.1: STOCHASTIC DYNAMIC MODELS IN PHY ABSTRACTION 1639\nFrancesc Rey, Josep Sala-Alvarez, Technical University of Catalonia, Spain\nTPb-2.2: ON SCALABILITY, ROBUSTNESS AND ACCURACY OF PHYSICAL 1644\nLAYER ABSTRACTION FOR LARGE-SCALE SYSTEM LEVEL EVALUATIONS OF LTE \nNETWORKS\nFlorian Kaltenberger, Imran Latif, Raymond Knopp, Eurecom, France\nTPb-2.3: LINK ADAPTATION IN MIMO-OFDM WITH PRACTICAL 1649\nIMPAIRMENTS\nAlberto Rico-Alvarino University of Vigo, Spain; Robert W. Heath, Jr., University of Texas at Austin, \nUnited States\nTPb-2.4 DIGITAL PRE-DISTORTION OF RADIO FREQUENCY 1654\nFRONT-END IMPAIRMENTS IN THE DESIGN OF SPECTRALLY AGILE MULTICARRIER \nTRANSMISSION \nZhu Fu, Alexander Wyglinski, Worcester Polytechnic Institute United States\nTPb-2.5: SYSTEM-LEVEL INTERFACES AND PERFORMANCE EVALUATION 1659\nMETHODOLOGY FOR 5G PHYSICAL LAYER BASED ON NON-ORTHOGONAL nWAVEFORMS\nGerhard Wunder, Martin Kasparick, Fraunhofer Heinrich Hertz Institute, Germany; Stephan Ten \nBrink University of Stuttgart, Germany; Frank Schaich, Thorsten Wild, Yejian Chen, Bell Labs, \nAlcatel-Lucent Germany; Ivan Gaspar, Nicola Michailow, Gerhard Fettweis, Technische Universität \nDresden, Germany; Dimitri Ktenas, Nicolas Cassiau, Commissariat à l’énergie atomique et aux \nénergies alternatives, France; Marcin Dryjanski, Kamil Sorokosz, Slawomir Pietrzyk, IS-Wireless, \nPoland; Bertalan Eged, National Instruments Hungary\nTPb-3: LOW-DIMENSIONAL SIGNAL MODELS\nTPb-3.1: NEAREST SUBSPACE CLASSIFICATION WITH MISSING DATA 1667\nYuejie Chi, The Ohio State University, United States\nTPb-3.2: REFLECTIONS ON SAMPLING-FILTERS FOR COMPRESSIVE 1672\nSENSING AND FINITE-INNOVATIONS-RATE MODELS\nP. P Vaidyanathan, Srikanth Tenneti, California Institute of Technology, United States\nTPb-3.3: IDENTIFIABILITY BOUNDS FOR BILINEAR INVERSE 1677\nPROBLEMS\nSunav Choudhary, Urbashi Mitra, University of Southern California, United States\nTPb-3.4: LOAD FORECASTING VIA LOW RANK AND SPARSE 


MATRIX  ...................................................1682\nFACTORIZATION\nSeung-Jun Kim, Georgios B Giannakis, University of Minnesota, United States\nxxvii\nTPb-3.5: SEMI-BLIND SOURCE SEPARATION VIA SPARSE 1687\nREPRESENTATIONS AND ONLINE DICTIONARY LEARNING\nSirisha Rambhatla, Jarvis Haupt, University of Minnesota - Twin Cities, United States\nTPb-4: LOCATION-AWARE NETWORKING\nTPb-4.1: ROBUST LINK SCHEDULING WITH CHANNEL ESTIMATION 1695\nAND LOCATION INFORMATION\nSrikar Muppirisetty, Rocco Di Taranto, Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.2: SIMULTANEOUS ROUTING AND POWER ALLOCATION USING  .................................................1700\nLOCATION INFORMATION\nRocco Di Taranto Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.3: LOCATION AWARE TRAINING SCHEME FOR D2D NETWORKS ..................................................1705\nDaoud Burghal, Andreas F. Molisch, University of Southern California, United States\nTPb-4.4: A COOPERATIVE HIGH-ACCURACY LOCALIZATION ALGORITHM 1709\nFOR IMPROVED ROAD WORKERS’ SAFETY\nSankalp Dayal, Adam Mortazavi, Khanh H. Huynh, University of California, Santa Barbara, United \nStates; Ramez L. Gerges California Department of Transportation, United States; John J. Shynk, \nUniversity of California, Santa Barbara, United States\nTPb-4.5: REAL-TIME ENERGY STORAGE MANAGEMENT WITH 1714\nRENEWABLE ENERGY OF ARBITRARY GENERATION DYNAMICS\nTianyi Li, Min Dong, University of Ontario Institute of Technology, Canada\nTPb-5: ANALYSIS OF COMPLEX BIOLOGICAL SYSTEMS AND OMICS DATA II\nTPb-5.2: STATISTICAL VALIDATION OF PARAMETRIC APPROXIMATIONS TO 1721\nTHE MASTER EQUATION\nGarrett Jenkinson, John Goutsias, The Johns Hopkins University, United States\nTPb-5.4: A MESSAGE-PASSING ALGORITHM FOR HAPLOTYPE ASSEMBLY 1726\nZrinka Puljiz, Haris Vikalo, University of Texas at Austin United States\nTPb-6: TARGET TRACKING I\nTPb-6.1: TRACK STATE AUGMENTATION FOR ESTIMATION OF 1733\nPROBABILITY OF DETECTION IN MULTISTATIC SONAR DATA\nEvan Hanusa, David Krout, University of Washington, United States\nTPb-6.2: HYPOTHESIS STRUCTURE IN ENHANCED 1738\nMULTIPLE-HYPOTHESIS TRACKING\nStefano Coraluppi, Craig Carthel, Compunetix Inc., United States; Marco Guerriero, SAIRA/FAR nAMERICAS Inc., United States\nTPb-6.3: SPLINE PROBABILITY HYPOTHESIS DENSITY FILTER FOR 1743\nNONLINEAR MANEUVERING TARGET TRACKING\nRajiv Sithravel, Xin Chen, McMaster University, Canada; Mike McDonald, Defence Research and \nDevelopment Canada Canada; Thia Kirubarajan, McMaster University, Canada\nTPb-6.4: PERFORMANCE ANALYSIS OF THE CONVERTED RANGE RATE  ...............................................1751\nAND POSITION LINEAR KALMAN FILTER\nSteven Bordonaro Naval Undersea Research Center, United States; Peter Willett, Yaakov Bar-Shalom, \nUniversity of Connecticut United States\nTPb-6.5: MAP-PF MULTITARGET TRACKING WITH PROPAGATION 1756\nMODELING UNCERTAINTIES\nKristine Bell, Robert Zarnich, Metron, United States\nTPb-7: MACHINE LEARNING AND STATISTICAL SIGNAL PROCESSING II\nTPb-7.1 FORWARD/BACKWARD STATE AND MODEL PARAMETER 1763\nESTIMATION FOR CONTINUUM-STATE HIDDEN MARKOV MODELS \(CHMM States\nxxviii\nTPb-7.2: LOW-RANK KERNEL LEARNING FOR ELECTRICITY MARKET 1768\nINFERENCE\nVassilis Kekatos, Yu Zhang, Georgios B Giannakis, University of Minnesota, United States\nTPb-7.3: HIERARCHICAL CLUSTERING METHODS AND ALGORITHMS 1773\nFOR ASYMMETRIC NETWORKS\nGunnar Carlsson, Stanford University, United States; Facundo Mémoli, University of Adelaide, \nAustralia; Alejandro Ribeiro, Santiago Segarra, University of Pennsylvania, United States\nTPb-7.5: ACHIEVING COMPLETE LEARNING IN MULTI-ARMED BANDIT 1778\nPROBLEMS\nSattar Vakili, Qing Zhao, University of California, Davis, United States\nTPb-8: DESIGN AUTOMATION\nTPb-8.1: MPMAP: A HIGH LEVEL SYNTHESIS AND MAPPING TOOL FOR  ................................................1785\nMPSOCS\nAmr Hussien, Ahmed M. Eltawil University of California, Irvine, United States; Rahul Amin, Jim \nMartin, Clemson University, United States\nTPb-8.2: SOFTWARE TOOL FOR FPGA BASED MIMO RADAR APPLICATIONS 1792\nAmin Jarrah, Mohsin M. Jamali, University of Toledo, United States\nTPb-8.3: MULTI-CLOCK DOMAIN OPTIMIZATION FOR 1796\nRECONFIGURABLE ARCHITECTURES IN HIGH-LEVEL DATAFLOW APPLICATIONS\nSimone Casale-Brunet, Endri Bezati, Claudio Alberti, Marco 


Mattavelli, École Polytechnique Fédérale \nde Lausanne \(EPFL Milano, Italy; Jörn Janneck, Lund \nUniversity, Sweden\nTPb-8.4: ACTOR CLASSIFICATION USING ACTOR MACHINES 1801\nGustav Cedersjö, Jörn Janneck, Lund University, Sweden\nTPb-8.5: SYSTEMS DESIGN SPACE EXPLORATION BY SERIAL DATAFLOW 1805\nPROGRAM EXECUTIONS\nSimone Casale-Brunet, Marco Mattavelli Claudio Alberti, École Polytechnique Fédérale de Lausanne \n\(EPFL Sweden\nTPb-8.7: REAL-TIME RADAR SIGNAL PROCESSING ON MASSIVELY 1810\nPARALLEL PROCESSOR ARRAYS\nZain Ul-Abdin, Halmstad University, Sweden; Anders Åhlander, Saab AB, Sweden; Bertil Svensson, \nHalmstad University, Sweden\nTPb-8.8 ALGORITHM AND ARCHITECTURE CO-DESIGN OF MIXTURE  ..................................................1815\nOF GAUSSIAN \(MOG States; Robert Bushey, Analog Devices Inc., \nUnited States; Gunar Schirner Schirner, Northeastern University United States\nTPb-8: MULTIUSER MIMO SYSTEMS\nTPb-8.1: MULTI-USER MIMO SCHEDULING IN THE FOURTH 1855\nGENERATION CELLULAR UPLINK\nNarayan Prasad, NEC Laboratories America, Inc., United States; Honghai Zhang, Google, United \nStates; Hao Zhu University of Illinois at Urbana-Champaign, United States; Sampath Rangarajan, \nNEC Laboratories America Inc., United States\nTPb-8.2: OPTIMAL DOF REGION OF THE TWO-USER MISO-BC WITH 1860\nGENERAL ALTERNATING CSIT\nJinyuan Chen, Petros Elia Eurecom, France\nTPb-8.3: EXPLOITING SPATIAL SPECTRUM HOLES IN MULTIUSER 1865\nMIMO SYSTEMS\nFeeby Salib, Karim Seddik, American University in Cairo, Egypt\nTPb-8.4: DEGREES OF FREEDOM ACHIEVED USING SUBSPACE 1869\nALIGNMENT CHAINS FOR THREE-CELL NETWORKS\nGokul Sridharan, Wei Yu, University of Toronto, Canada\nTPb-8.5: INTERFERENCE ALIGNMENT FOR MISO BROADCAST  ...............................................................1875\nCHANNELS UNDER JAMMING ATTACKS\nSaiDhiraj Amuru, Ravi Tandon, R. Michael Buehrer, T. Charles Clancy, Virginia Tech, United States\nxxix\nTPb-8.6: PERFORMANCE STUDY OF MRC AND IRC WEIGHTS IN 1880\nLTE/LTE-A SYSTEMS WITH INTERFERENCE MANAGEMENT\nThomas Svantesson, ArrayComm, United States\nTPb-8.8: A SYSTEM-LEVEL STUDY ON MULTI-USER MIMO 1885\nTRANSMISSION FOR DENSE FDD NETWORKS\nLars Thiele, Martin Kurras, Kai Börner, Thomas Haustein, Fraunhofer HHI, Germany\nTPb-8.9 DIVERSITY-MULTIPLEXING TRADEOFF OF MIMO LINEAR 1890\nPRECODING\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nTPb-8: ELECTROPHYSIOLOGY AND BRAIN IMAGING\nTPb-8.1: JOINT COMPRESSION OF NEURAL ACTION POTENTIALS AND 1823\nLOCAL FIELD POTENTIALS\nSebastian Schmale, Benjamin Knoop, Janpeter Hoeffmann, Dagmar Peters-Drolshagen, Steffen Paul, \nUniversity of Bremen, Germany\nTPb-8.2 REDUCING THE EFFECT OF CORRELATED BRAIN SOURCES IN  ...............................................1828\nMEG USING A LINEARLY CONSTRAINED SPATIAL FILTER BASED ON MINIMUM \nNORM\nJosé Alfonso Sánchez De Lucio, David M Halliday, University of York, United Kingdom\nTPb-8.3: ONLINE BAYESIAN CHANGE POINT DETECTION ALGORITHMS 1833\nFOR SEGMENTATION OF EPILEPTIC ACTIVITY\nRakesh Malladi, Rice Unviersity, United States; Giridhar P Kalamangalam, University of Texas Health \nScience Center, United States Behnaam Aazhang, Rice Unviersity, United States\nTPb-8.4: SPIKING NEURAL NETWORKS BASED ON LIF WITH LATENCY 1838\nSIMULATION AND SYNCHRONIZATION EFFECTS\nGian Carlo Cardarilli, Alessandro Cristini, Marco Re, Mario Salerno, Gianluca Susi, University of \nRome Tor Vergata Italy\nTPb-8.5: TIME-FREQUENCY ANALYSIS OF BRAIN ELECTRICAL SIGNALS 1843\nFOR BEHAVIOUR RECOGNITION IN PATIENTS WITH PARKINSON’S DISEASE\nHuaiguang Jiang, Jun Jason Zhang, University of Denver, United States; Adam Hebb, Colorado nNeurological Institute, United States; Mohammad H. Mahoor, University of Denver, United States\nTPb-8.7: A MEASURE OF CONNECTIVITY IN THE PRESENCE OF 1848\nCROSSTALK\nSergul Aydore, Syed Ashrafulla Anand Joshi, Richard M Leahy, University of Southern California, \nUnited States\nWAa-1: MIMO INTERFERENCE MANAGEMENT\nWAa-1.1: DEGREES OF FREEDOM FOR THE CONSTANT MIMO 1897\nINTERFERENCE CHANNEL WITH COMP TRANSMISSION\nCraig Wilson, Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United 


States\nWAa-1.2: DYNAMIC INTERFERENCE MANAGEMENT 1902\nAly El Gamal Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United States\nWAa-1.3: A MUD/RATE SELECTION TOOL FOR COGNITIVE RADIOS IN  ..................................................1907\nPACKET BASED ASYNCHRONOUS GAUSSIAN MULTIPLE ACCESS CHANNELS\nPrabahan Basu, Rachel Learned, MIT Lincoln Laboratory, United States\nWAa-1.4: PRECODER DESIGN FOR FRACTIONAL INTERFERENCE 1912\nALIGNMENT\nHari Ram Balakrishnan, Giridhar K Indian Institute of Technology Madras, India\nWAa-2: OFDM\nWAa-2.1: MIMO-OFDM OUTAGE CHANNEL CAPACITY WITH PRACTICAL  .............................................1919\nIMPERFECT CSI\nMarko Kocic, MIT Lincoln Laboratory, United States; Nicholas Chang, Applied Communication \nSciences, United States; Matthew Ferreira MIT Lincoln Laboratory, United States\nxxx\nWAa-2.2: BIASED ESTIMATION OF SYMBOL TIMING OFFSET IN OFDM 1924\nSYSTEMS\nRohan Ramlall, University of California, Irvine United States\nWAa-2.3: A FACTOR-GRAPH APPROACH TO JOINT OFDM CHANNEL 1929\nESTIMATION AND DECODING IN IMPULSIVE NOISE CHANNELS\nMarcel Nassar, University of Texas at Austin, United States; Philip Schniter, The Ohio State University, \nUnited States; Brian Evans, University of Texas at Austin, United States\nWAa-2.4: WIDELY LINEAR DATA ESTIMATION FOR UNIQUE WORD  ........................................................1934\nOFDM\nMario Huemer, Alexander Onic, Christian Hofbauer, Stefan Trampitsch, Johannes Kepler University \nLinz Austria\nWAa-3: ADAPTIVE FILTERING\nWAa-3.1: A GRADIENT-CONTROLLED PROPORTIONATE TECHNIQUE FOR 1941\nACOUSTIC ECHO CANCELLATION\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nWAa-3.2: INTERFERENCE IDENTIFICATION IN CELLULAR NETWORKS  .................................................1946\nVIA ADAPTIVE PROJECTED SUBGRADIENT METHODS\nKonstantin Oltmann, Renato L. G. Cavalcante, Slawomir Stanczak, Martin Kasparick, Fraunhofer \nHeirinch Hertz Institute, Germany\nWAa-3.3: A RECONSIDERATION OF IMPROVED PNLMS ALGORITHM 1951\nFROM METRIC COMBINING VIEWPOINT\nOsamu Toda, Masahiro Yukawa, Keio University, Japan\nWAa-3.4: DETECTION PERFORMANCE OF MATCHED TRANSMIT 1956\nWAVEFORM FOR MOVING EXTENDED TARGETS\nRic Romero, Naval Postgraduate School, United States\nWAa-4: RELAYING AND COOPERATION\nWAa-4.1: TWO-WAY AMPLIFY-AND-FORWARD RELAY STRATEGIES  .......................................................1963\nUNDER RELAY POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon, Edwin M. Sawan, Wichita State University, United States Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nWAa-4.2: GAUSSIAN INTERFERING RELAY CHANNELS...............................................................................1968\nHieu T. Do, Tobias J. Oechtering, Mikael Skoglund, KTH Royal Institute of Technology, Sweden; Mai \nVu, Tufts University, United States\nWAa-4.3: THROUGHPUT IMPROVEMENTS FOR CELLULAR SYSTEMS 1973\nWITH DEVICE-TO-DEVICE COMMUNICATIONS\nPhuongBang Nguyen, Bhaskar D. Rao, University of California, San Diego, United States\nWAa-4.4: COOPERATIVE SIMULTANEOUS LOCALIZATION AND  ...............................................................1978\nSYNCHRONIZATION: A DISTRIBUTED HYBRID MESSAGE PASSING ALGORITHM\nBernhard Etzlinger, Johannes Kepler University, Austria; Florian Meyer, Vienna University of \nTechnology, Austria; Andreas Springer, Johannes Kepler University, Austria; Franz Hlawatsch, Vienna \nUniversity of Technology, Austria; Henk Wymeersch, Chalmers University of Technology Sweden\nWAa-5: IMAGE ANALYSIS AND PROCESSING\nWAa-5.1: MULTISCALE AM-FM IMAGE RECONSTRUCTIONS BASED ON 1985\nELASTIC NET REGRESSION AND GABOR FILTERBANKS\nIoannis Constantinou, University of Cyprus, Cyprus; Marios Pattichis, University of New Mexico, \nUnited States Constantinos Pattichis, University of Cyprus, Cyprus\nWAa-5.2: COLORIZATION BASED ON PIECEWISE AUTOREGRESSIVE 1990\nMODEL\nYasuhiro Nakajima, Takashi Ueno, Taichi Yoshida, Masaaki Ikehara, Keio University, Japan\nWAa-5.3: IMAGE DENOISING BY ADAPTIVE DIRECTIONAL 1995\nLIFTING-BASED DISCRETE WAVELET TRANSFORM AND QUANTIZATION\nNaoki Furuhashi, Azusa Oota, Taichi Yoshida, Masaaki Ikehara, Keio University Japan\nxxxi\nWAa-5.4: INTRODUCING DIVERSITY TO NORMALIZED CROSS 2000\nCORRELATION FOR DENSE IMAGE REGISTRATION\nNafise Barzigar, Aminmohammad Roozgard, Pramode Verma, Samuel Cheng, University of Oklahoma nUnited States\nWAa-6: MULTI-SENSOR SIGNAL PROCESSING\nWAa-6.1: WHY DOES DIRECT-MUSIC ON SPARSE-ARRAYS WORK 2007\nP. P Vaidyanathan, Piya Pal, California 


Institute of Technology, United States\nWAa-6.2: ASYMPTOTICALLY OPTIMAL TRUNCATED HYPOTHESIS TEST 2012\nFOR A LARGE SENSOR NETWORK DESCRIBED BY A MULTIVARIATE GAUSSIAN \nDISTRIBUTION\nJiangfan Zhang, Rick Blum, Lehigh University, United States\nWAa-6.3: A JOINT LOCALIZATION AND SYNCHRONIZATION TECHNIQUE  ............................................2017\nUSING TIME OF ARRIVAL AT MULTIPLE ANTENNA RECEIVERS\nSiamak Yousefi, Xiao-Wen Chang, Benoit Champagne, McGill University Canada\nWAa-6.4: REDUCING THE FRACTIONAL RANK OF INTERFERENCE WITH 2022\nSPACE-TIME-FREQUENCY ADAPTIVE BEAMFORMING\nShawn Kraut, Adam R. Margetts, MIT Lincoln Laboratory, United States; Daniel Bliss, Arizona State \nUniversity, United States\nWAa-7: COMMUNICATION SYSTEM DESIGN\nWAa-7.1: IMPLEMENTATION OF SELECTIVE PACKET DESTRUCTION ON 2029\nWIRELESS OPEN-ACCESS RESEARCH PLATFORM\nStephen Hughes Bosheng Zhou, Roger Woods, Queen’s University Belfast, United Kingdom; Alan \nMarshall, Unievrsity of Liverpool, United Kingdom\nWAa-7.2: EFFICIENT ERROR-AWARE POWER MANAGEMENT FOR 2034\nMEMORY DOMINATED OFDM SYSTEMS\nMuhammad S Khairy, Ahmed M. Eltawil, Fadi J. Kurdahi, University of California, Irvine, United \nStates; Amin Khajeh Intel labs, United States\nWAa-7.3: FPGA IMPLEMENTATION OF A MESSAGE-PASSING OFDM 2041\nRECEIVER FOR IMPULSIVE NOISE CHANNELS\nKarl Nieman, University of Texas at Austin, United States; Marcel Nassar, Samsung Information \nSystems America United States; Jing Lin, Brian Evans, University of Texas at Austin, United States\nWAa-7.4: MOBILE TRANSMITTER DIGITAL PREDISTORTION:  ...................................................................2046\nFEASIBILITY ANALYSIS, ALGORITHMS AND DESIGN EXPLORATION\nMahmoud Abdelaziz, Tampere University of Technology, Finland Amanullah Ghazi, University of \nOulu, Finland; Lauri Anttila, Tampere University of Technology, Finland; Jani Boutellier, University of \nOulu, Finland; Toni Lähteensuo, Tampere University of Technology, Finland; Xiaojia Lu, University of \nOulu, Finland; Joseph R. Cavallaro, Rice University, United States; Shuvra Bhattacharyya University \nof Maryland, United States; Markku Juntti, University of Oulu, Finland; Mikko Valkama, Tampere nUniversity of Technology, Finland\nWAb-1: MIMO PROCESSING\nWAb-1.1: MMSE RECEIVE FILTERING FOR PRECODED MIMO SYSTEMS .................................................2057\nAhmed Mehana, Samsung Electronics, Co., Ltd United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-1.2: COVERAGE IN DENSE MILLIMETER WAVE CELLULAR  ............................................................2062\nNETWORKS\nTianyang Bai, Robert W. Heath, Jr., The University of Texas at Austin, United States\nWAb-1.3: LINEAR PRECODING FOR MIMO WITH LDPC CODING AND  .....................................................2067\nREDUCED RECEIVER COMPLEXITY\nThomas Ketseoglou, California State University, Pomona, United States; Ender Ayanoglu, University nof California, Irvine, United States\nxxxii\nWAb-1.4: OPTIMAL PILOT BEAM PATTERN DESIGN FOR MASSIVE MIMO 2072\nSYSTEMS\nSong Noh, Michael D. Zoltowski, Purdue University United States; Youngchul Sung, Korea Advanced \nInstitute of Science and Technology, Republic of Korea; David J. Love, Purdue University, United \nStates\nWAb-2: ADVANCES IN CODING AND DECODING\nWAb-2.1: EFFICIENTLY ENCODABLE NON-BINARY GENERALIZED LDPC  .............................................2079\nCODES\nNicholas Chang Applied Communication Sciences, United States; Marko Kocic, MIT Lincoln \nLaboratory, United States\nWAb-2.2 PRACTICAL NON-BINARY RATELESS CODES FOR WIRELESS 2084\nCHANNELS\nDavid Romero, Massachusetts Institute of Technology, United States; Nicholas Chang, Applied \nCommunication Sciences, United States; Adam R. Margetts Massachusetts Institute of Technology, \nUnited States\nWAb-2.3: ON THE OPTIMALITY OF POLAR CODES FOR THE 2089\nDETERMINISTIC WIRETAP CHANNE\nAli Fakoorian, A. Lee Swindlehurst, University of California, Irvine, United States\nWAb-2.4: DELAY-OPTIMAL STREAMING CODES UNDER 2094\nSOURCE-CHANNEL RATE MISMATCH\nPratik Patil, Ahmed Badr, Ashish Khisti, University of Toronto, Canada; Wai-Tian Tan Hewlett-\nPackard Labs, United States\nWAb-3: DETECTION\nWAb-3.1: ASYNCHRONOUS SIGNAL DETECTION IN 2103\nFREQUENCY-SELECTIVE NON-GAUSSIAN CHANNELS\nSaiDhiraj Amuru, Daniel Jakubisin, R. Michael Buehrer, Virginia Tech, United States Claudio da \nSilva, Samsung Electronics, Co., Ltd., United States\nWAb-3.2: AN INFORMATION THEORETIC CHARACTERIZATION OF THE  ................................................2108\nCHANNEL SHORTENING RECEIVER\nFredrik Rusek, Ove Edfors, Lund University, Sweden\nWAb-3.3: ITERATIVE MMSE-SIC RECEIVER WITH LOW-COMPLEXITY  ...................................................2113\nSOFT SYMBOL AND RESIDUAL INTERFERENCE ESTIMATIONS\nGuosen Yue, Narayan Prasad, Sampath Rangarajan, NEC Laboratories America, Inc., United 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



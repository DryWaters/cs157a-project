Cache Topology Aware Mapping of Stream Processing Applications onto CMPs\nFang Zheng1, Chitra Venkatramani2 Rohit Wagle2, and Karsten Schwan1\n1College of Computing, Georgia Institute of Technology, Atlanta Georgia\n2IBM T. J. Watson Research Center, Yorktown Heights, New York\nAbstract—Data Stream Processing is an important class\nof data intensive applications in the “Big Data” era. Chip\nMulti-Processors \(CMPs standard hosting platforms\nin modern data centers. Gaining high performance for stream\nprocessing applications on CMPs is therefore of great interest.\nSince the performance of stream processing applications largely\ndepends on their effective use of the complex cache structure\npresent on CMPs, this paper proposes the StreamMap ap-\nproach for tuning streaming applications’ use of cache. Our\nmajor idea is to map application threads to CPU cores to facil-\nitate data sharing AND mitigate memory resource contention\namong threads in a holistic manner. Applying StreamMap to\nthe IBM’s System S middleware leads to improvements of up to\n1.8× in the performance of realistic applications over standard\nLinux OS scheduler on three different CMP platforms.\nKeywords-Data Stream Processing; Cache Topology; Thread\nMapping; IBM Infosphere Streams\nI INTRODUCTION\nData Stream Processing is an important class of data\nintensive applications in the “Big Data era. Providing real-\ntime data analytics capabilities to extract insights from\nlive data streams, it has been applied to many application\ndomains, including ?nance & trading, image processing,\nnetwork intrusion detection, and environmental monitoring.\nAn important question to ask about stream processing\napplications is their performance on common hardware\nplatforms like the modern chip multiprocessors \(CMPs entire spectrum of portable devices\nto high end server systems. Today’s multicore architectures\nare equipped with complex cache hierarchies. On one hand,\nmulti-level caches are used to alleviate the two-order-of\nmagnitude gap in speed between CPU and DRAM, mak-\ning maximizing cache utilization a signi?cant factor for\napplication performance. On the other hand, cores share\ncertain memory resources with each other including last\nlevel cache, hardware prefetch unit, front side bus and\nmemory controller. While sharing those resources between\ncores can be constructive for data sharing \(e.g., to facilitate\ndata reuse in shared cache and reduce cache coherency\ntraf?c resources [18]. Therefore, judiciously\nmanaging application’s interaction with cache structure is of\ngreat importance to achieve high performance on CMPs.\nThis paper argues that thread-to-core mapping is an\neffective way to control how a stream processing appli-\ncation interact with CMP’s caches. This is because how\napplication threads are placed onto cores largely determines\nhow memory resources are shared between threads. This,\nin turn, impacts not only the ef?ciency of data messaging\nand sharing between threads, but also the intensiveness of\nresource contention between threads for their private state\ndata. In fact, our experiments show up to 3× difference in\nperformance between different thread-to-core mappings for\nsome streaming applications.\nUnfortunately, current operating systems are largely igno-\nrant of data sharing and con?icts in resource demands among\napplication threads, and assign threads to cores based on core\nidleness often resulting in sub-optimal and highly varying\napplication performance. Although there has been previous\nwork on mapping applications onto CMPs [14, 24, 34], their\neffectiveness for stream processing applications is not well\nunderstood. Besides, most existing solutions do not consider\ndata sharing and resource contention relationships between\nthreads in a holistic manner and fall short for streaming\napplications with complicated inter-thread relationships.\nThis paper proposes StreamMap, an approach that makes\nstreaming applications cache topology aware to obtain high\nperformance on CMP architectures StreamMap assigns ap-\nplication threads to cores so that \(i respected while \(ii collect relevant information about threads’ cache\nbehavior and derives high-quality thread-to-core mappings.\nThe mapping is enforced when launching the application\nonto target machine for production run StreamMap is trans-\nparent to user programs and operates at user level without\nmodi?cations to operating systems or hardware.\nThis paper makes the following contributions:\n1 characterizes the cache\nbehavior of streaming applications and quanti?es the impact\nof cache topology on streaming application performance.\nFindings include that \(1 sensitive to CMP’s cache topology, \(2 quite diverse and resource contention between\noperators can cause severe performance loss, and \(3 Linux OS thread scheduler fails to schedule applica-\ntions in ways that ef?ciently use CMP memory hierarchies.\n2 Distributed Computing Systems\n1063-6927/13 $26.00 © 2013 IEEE\nDOI 10.1109/ICDCS.2013.13\n552\nholistic mapping policy which improves data reuse for better\ncache utilization and reduces negative resource contention.\nIts user-level implementation facilitates its adoption by the\nstream processing middleware.\n3 


experimental evaluation. The approach is\nimplemented within IBM’s System S middleware and is\nevaluated with two real-world applications in the ?nancial\nand scienti?c domains, respectively. Performance evalua-\ntions on three different Intel architectures show consistent,\nup to 1.8× performance improvements for cache topology\naware mapping versus unaware techniques.\nThe remainder of the paper is organized as follows.\nSection II presents background information on the System S\nmiddleware and CMP cache topology. Section III motivates\nour work by demonstrating the signi?cance of a CMP’s\ncache topology to the performance of streaming applications.\nSection IV describes details about the cache topology aware\nmapping techniques. Section V shows the performance\nimprovements of two realistic applications brought by the\nStreamMap approach. Section VI reviews related work, and\nSection VII concludes the paper.\nII. BACKGROUND\nA. IBM System S Middleware\nOur work is based on System S [9] \(commercialized as\nIBM Infosphere Streams industry-leading\nmiddleware enabling high throughput, low latency stream\nprocessing. As shown in Figure 1, it provides a program-\nming language, a compilation framework, and an execution\nruntime to implement and run streaming application in a\ndistributed environment. The Streams Processing Language\n\(SPL declarative language supporting\nthe operator-stream programming model. Operators can be\nprimitive ones supported by System S, reused from existing\ntoolkits, or implemented by programmers on their own in\nC++ and/or Java. With SPL, operators are composed into a\ndata?ow graph by de?ning the streams that connect them.\nStreams carry a continuous stream of tuples with ?xed\nschema. The SPL compiler compiles the SPL source code\nto generate C++ code, which is then compiled by native\ncompilers to generate deployable binary executables The\nSystem S runtime provides the execution environment for\nstreaming applications and handles job scheduling monitor-\ning, and fault-tolerance.\nSystem S provides language support for multi-threading\nan SPL program Programmers can specify an input port of\nan operator as a “Threaded Port”, for which the System S\nruntime will create a thread to handle the incoming tuples\nfrom that port and execute the subgraph of operators rooted\nfrom that input. In the sample program shown in Figure 1,\nthe operator FinalData has its input port con?gured as a\nThreaded Port. The SPL compiler will accordingly introduce\na separate thread to handle incoming tuples from this input\nand drive the execution downstream.\nSPL program \nSPL \nCompiler \nExecutable \nSystem S Runtime nSource \nFinalData \nSink \nThread A \nThread B \nQueue \nFunction Call \n \nnamespace sample; \n \ncomposite Main { \n type \n    RecT = int32 v1, list<int32>[32] v2; \n \n  graph \n    stream<RecT>  Source = Beacon logic state: mutable int32 i = 0; \n        param iterations : 100u; \n        output Source : v1 = i++; \n n    stream<RecT> FinalData = Functor\(Source FinalData: v1 = i++; \n        config threadedPort : queue\(Source, Sys.Wait, 10  Custom\(FinalData v1 Middleware.\nC0 \nL1 \(32KB 32KB 4MB 32KB 32KB 4MB Hub \nMemory \(4GB a Xeon X5355 2.66GHz 32KB 32KB 4MB nC3 \nL1 \(32KB 32KB 4MB 8GB 32KB 32KB 4MB nC6 \nL1 \(32KB 32KB 4MB b Xeon E5320 1.86GHz 32KB 32KB 32KB 32KB 256KB 256KB 256KB 256KB 4MB 6GB 32KB 32KB nL1 \(32KB 32KB 256KB 256KB 256KB 256KB 4MB 6GB c Xeon E5506 2.13GHz multi-core platform, Threaded Ports\nand in-memory queues provide the necessary mechanism\nto multi-thread SPL programs and exploit various forms of\nparallelism inherent in the programs. There are additional\nways to introduce threads, however. One common case is\nthat each source operator \(those that does not have an input\nport example, in Figure 1,\nthere is one thread to drive the execution from operator\nFirstSource to downstream operators until it encounters a\nthreaded port. Other places where additional threads are\ncreated and participate in the execution of stream graphs\ninclude threads associated with time-based windows and\nthose introduced by the underlying transport layer.\nWhile inter-thread communication is made explicit at the\nSPL level through the Threaded Port language construct,\nactual data movement is instantiated through an in-memory\n563\nSource \nOperator \nSink \nSource \nOperator \nSink \nThread A Thread B \nSource \nOperator \nSink nSource \nOperator \nSink \nSource Thread A \nThread B \nThread A Thread B \n\(a b c Thread Relationships.\nqueue between producer and consumer threads. The queue is\na FIFO, lock-free, circular buffer, with various optimizations\nto reduce cache coherency traf?c \(for more details of the\nqueue implementation, we refer readers to [12 CMPs or simply multi-cores 


are also becoming per-\nvasive in personal and mobile computing environments.\nModern CMPs typically feature deep and complex memory\nhierarchies. Figure 2 shows the cache topology of three\nmachines equipped with different Intel Xeon processors.\nThe ?rst \(Figure 2\(a single socket. Each core has its own L1\ndata and instruction cache, and each pair of cores share one\nL2 cache All four cores share the Front Side Bus \(FSB known as UMA, i.e., Uniform Memory Access Figure 2\(b processors. In each socket, each core has its own\nL1 cache and shares L2 cache with another core. All 8-\ncores share the FSB and memory controller and have access\nto DRAM in a UMA fashion. Different from the former\ntwo machines, the third machine \(see Figure 2\(c Non-Uniform Memory Access are two quad-core processors, each with its own local\non-chip memory controller. Accessing data in local memory\nbanks is faster than accessing data in remote memory banks.\nIII. CHALLENGES IN MAPPING STREAMING\nAPPLICATIONS ONTO CMPS\nThis section uses experimental measurements to establish\nthe fact that on multicore platforms, thread-to-core mappings\ncan have a signi?cant impact on streaming application\nperformance, motivating the need for carefully determining\nits best thread-to-core mapping.\nA Multi-threaded Streaming Applications\nThere are various forms of parallelism inherent in the\noperator graphs of streaming applications, typically resulting\nin a partitioning of operators among threads and a temporal\nscheduling of how operators are run within each thread.\nAs mentioned in Section II, with System S such paral-\nlelization is expressed with Threaded Ports introduced into\nthe proper locations in the stream graph. This results in\nthe runtime creation of threads that each execute a group\n0 \n500 \n1000 \n1500 \n2000 n2500 \n3000 \n16\n \n24\n \n40\n \n72\n \n13\n6 \n26\n4 \n52\n0 \n10\n32\n \n20\n56\n \n41\n04\n \n82\n00\n \n16\n39\n2 \n32\n77\n6 nM\nB\n/S\nec\n \nTuple Size \(Bytes n16\n \n24\n \n40\n \n72\n \n13\n6 \n26\n4 \n52\n0 \n10\n32\n \n20\n56\n \n41\n04\n \n82\n00\n \n16\n39\n2 \n32\n77\n6 \nM\nB\n/S\nec\n \nTuple Size \(Bytes a b c n1000 \n2000 \n3000 \n4000 \n5000 \n16\n \n24\n \n40\n \n72\n \n13\n6 \n26\n4 \n52\n0 \n10\n32\n \n20\n56\n \n41\n04\n \n82\n00\n \n16\n39\n2 n32\n77\n6 \nM\nB\n/S\nec\n \nTuple Size \(Bytes Communication Performance.\nof operators in a per-tuple, depth-?rst manner. Threads\nwithin the same streaming program may have three possible\nrelationships with each other, as shown in Figure 3.\nIndependent: threads progress independently from each\nother, without communicating or sharing any common op-\nerator, as shown in Figure 3 \(a b associated with the\nThread Port and the consumer thread directly operates on\ntuples in the queue.\nOperator-Sharing: two threads share one or multiple\noperators, as shown in Figure 3 \(c synchronize through\na mutex lock to execute the shared operator\(s application is multi-\nthreaded by programmers or with automated mechanisms\nlike graph partitioning-based operator fusion [15]. Given\nsuch an application, our goal is to determine the thread-to-\ncore mapping that maximizes overall application throughput.\nB. Inter-Thread Data Movement\nData movement performance between producer and con-\nsumer threads in CMPs is sensitive to the relative distance\nof source and destination cores along the cache topology.\nConsider a pair of threads shown in Figure 3 \(b Figure 2\(a e.g., on core 0 and\n1 consumer thread may directly read the data from\nthe L2 cache; on the other hand, if the two threads are on\ntwo cores that are ’far away’ from each other \(e.g., core 0\nand core 2 will\ncause invalidation of copies in the other L2 cache, and the\nconsumer thread will experience L2 cache misses and wait\nfor data to be moved through cache coherency protocol.\nWe demonstrate this fact with a sender-receiver bench-\nmark that measures data movement throughout via a queue\nassociated with Thread Port Figure 4 shows up to a 3\ntimes throughput difference between sharing vs. not sharing\nLast Level Cache. This suggests that threads with producer-\nconsumer relationship can bene?t from sharing cache. It\nalso shows that the OS scheduler does not respect the data\nmovement between threads and leads to performance loss.\nC. Shared Resource Contention\nWhen running a multi-threaded streaming application on a\nCMP, threads share certain resources in the CMP’s memory\nhierarchy, including the last-level cache, prefetching hard-\nware, the Front Side Bus \(FSB L2\nCACHE WITH THE RIGHT THREAD \(NORMALIZED TO THE LEFT\nTHREAD’S SOLO-RUN TUPLE CONSUMPTION RATE 99.9% 100.4%\nFunctor 100.4% 100.4% 100.2% 98.0% 100.6%\nAggregator 99.9% 99.9% 103.5% 112.8% 114.7%\nSort 100.2 99.4% 148.8% 192.9% 205.8%\nHashJoin 100.1% 100.2% 122.6% 134.4% 136.6%\nTable II\nTUPLE CONSUMPTION RATE OF THE LEFT THREAD WHEN NOT\nSHARING L2 CACHE WITH THE RIGHT THREAD \(NORMALIZED TO THE\nLEFT THREAD’S SOLO-RUN TUPLE 


CONSUMPTION RATE 99.8%\nFunctor 97.9% 100.5% 97.5% 97.5% 100.8%\nAggregator 100.0% 100.0% 100.0% 101.3% 104.3%\nSort 96.3% 96.4 95.0% 100.0% 103.4%\nHashJoin 96.7% 97.3% 99.00% 99.7% 102.1%\n\(as shown in Figure 2 sharing can\nbe constructive for data movement between producer and\nconsumer threads, it can also cause destructive contention\non shared resources demanded by multiple threads and slow\ndown overall performance This is particularly the case for\nthreads with Independent relationship \(Figure 3 \(a not share data with each other, each thread’s\naccesses to its own working set compete for resources cache\nspace, memory bandwidth, etc benchmark\nprogram structured as Figure 3 \(a The two opera-\ntors in the middle of the chains are chosen among ?ve\ncommonly-used operators: Filter, Functor Sort, Aggregator\nand Hash Join, in order of their working set size. There\nare 5 × 5 combinations. We run the benchmark on the 4-\ncore UMA machine \(Figure 2\(a share L2 cache or use\nseparate L2 caches. Under each of the two thread-to-core\nmappings, we measure the tuple consumption rate of the left\nthread and normalize the rate to the rate when the left thread\nruns in solo and the right thread does not exist. When the\ntwo threads share L2 cache, they contend for shared cache\nspace resulting in performance degradation. The larger the\nworking sets, the worse the performance \(e.g., the left thread\nexecuting Sort operator is slowed down by 105.8% when\nthe right thread executing Hash Join, as shown in Table I and the left\nthread experiences no more than 4.4% slowdown compared\nto running solo \(shown in Table II benchmark results imply that threads with contending\ndemands on memory resources should be mapped far away\nfrom each other in cache topology to reduce contention on\nshared resources in the memory hierarchy.\n0 \n50 n100 \n150 \n200 \n250 \n300 \n4-core UMA 8-core UMA 8-core NUMA \nPe\nrc\nen\nta\nge\n \(%\n nDiff. Last Level Cache \nNot Pin \nFigure 5. Runtime of Operator Sharing Benchmark \(Normalized to the\nSharing Last Level Cache Case they synchronize with each other to execute\nthe shared operators, as shown in Figure 3 \(c shared operator\(s threads\nwith shared operators may bene?t from sharing cache since\none thread’s access to the lock and shared operators loads\ndata into cache which can then be re-used by other threads.\nWe run a benchmark to show how sharing operators may\naffect application performance. The benchmark measures\nthe time of two threads synchronizing on a shared barrier\noperator 10 million times. The benchmark is run on three\nmachines, each with three different thread-to-core mappings:\nsharing Last Level Cache \(LLC thread scheduling. Figure 5 shows that on all\nthree CMPs, sharing LLC between threads improves barrier\nperformance by up to 2.2× over forcing threads use separate\nLLC. The mapping by OS scheduler \(“Not Pin” in Figure 5 Challenges\nBenchmark results indicate that when running multi-\nthreaded streaming applications on CMPs, the thread-to-core\nmapping can signi?cantly affect application performance\ndue to: \(1 2 3 benchmark performance by up\nto 3× over the default OS scheduler.\nHowever, complexities exist in determining the thread-to-\ncore mapping that leads to the optimal application perfor-\nmance. Real-world streaming applications may have a large\nnumber of threads that exhibit sophisticated relationships.\nFigure 6 shows a three-thread streaming program in which\nThreads 1 and 2 share an operator and both move data to\nThread 3 through a queue. Each thread’s data working set\nconsists of \(1 including state data of operators\nonly executed by this thread and tuples passed between\nprivate operators 2 including the state\ndata of operators shared with other threads and tuples passed\nthrough queues result, obtaining the optimal mapping\nrequires non-trivial knowledge of threads’ cache behavior\nand intelligently considering how mapping would impact all\nthreads’ accesses to their private and shared data e.g., assess\n585\n  Op2 \n  Op1 \n  Op5 \nS1 \nS2 \nS5 \n  Op4 \n  Op3 S3 \nS4 \n  Op6 S6 \n  Op7 S7 \nQueue \nThread 1 Thread 2 \nThread 3 \nS1 S2 S5 \nS3 S4 S5 \nS6 S7 \nThread 1 Working Set \nThread 2 Working Set \nThread 3 Working Set \nFigure 6. Cache Behavior of Streaming Programs.\nwhether the bene?t of data sharing between two threads\noutweighs their contention for accessing private data Overview\nMotivated by the potential performance gains and com-\nplexity of thread mappings, we implement StreamMap as\nan of?ine optimization step in the System S compilation\nprocess to decide and enforce thread mapping onto a target\nmulticore platform. As shown in Figure 7, StreamMap\nis an optional step in application compilation and build\nprocess. StreamMap takes as inputs a description of the\ntarget machine and the 


executable ?le generated by the SPL\ncompiler. Depending on the mapping algorithm used, it may\nperform one or multiple trial runs of the executable on target\nmachine and record various information. StreamMap then\ninvokes the thread mapping algorithm to calculate the best\nthread-to-core mapping. The mapping is enforced during\napplication initialization by setting threads’ CPU af?nity.\nStreamMap has the following advantages:\n\(1 Generality. It targets arbitrary SPL-programmed\nstreaming applications for multicore nodes and does not\nrequire knowledge about operators’ internal implementation.\n\(2 homogeneous CMPs.\nIts user-level implementation makes it easy to change its\nmapping methods and its realization for different OSes.\n\(3 minimal programmer involvement.\nAlthough StreamMap is currently implemented with Sys-\ntem S middleware, the techniques are applicable to any\nstream processing applications.\nB. Thread Mapping Algorithms\nA good thread-to-core mapping for a streaming appli-\ncation should place intensively communicating and data\nsharing threads close to each other, and meanwhile isolate\nthreads with con?icting demands on resources. Below we\ndescribe four thread mapping algorithms.\n1 inputs the set of threads within the streaming\napplication and the core ids of the target machine. It runs\nthe application on the target machine with all possible\nthread-to-core mapping combinations, and after completion,\nchooses the mapping with highest application throughput.\nSPL \nCompiler StreamMap \nL2 \nC\n0 \nL1 \nC\n1 nL1 \nL2 \nC\n2 \nL1 \nC\n3 \nL1 \nJob \nLaunch \nExecutable \nT1-C0 \nT2-C2 \nT3-C3 \nT4-C1 L2 \nC\n0 \nL1 \nC\n1 \nL1 \nL2 \nC\n2 nL1 \nC\n3 \nL1 \nTarget Machine \nMapping File Production Run \nSPL \nSource \nFigure 7. Optimization Work?ow of StreamMap.\nThe algorithm also takes advantage of the symmetry of cache\ntopology to eliminate obviously redundant mappings. Ex-\nhaustive Search is guaranteed to ?nd the optimal thread-to-\ncore mapping, and does not require any additional pro?ling\ninformation about the application or target machine. This\nalgorithm, however suffers from its poor scalability with\nnumbers of threads and CPU cores.\n2 TreeMatch: The\n“TreeMatch” algorithm [14] aims to minimize data move-\nment cost for mapping a group of MPI processes onto a CMP\nmachine. It takes as input the machine’s cache topology and\nan inter-process communication matrix. The cache topology\nis modeled as a tree with cores as leaves. The inter-process\ncommunication matrix describes the data transfer volumes\nbetween each pair of MPI processes TreeMatch incremen-\ntally divides processes into non-overlapping groups whose\nsizes are equal to the arity of each level of the topology\ntree, starting from the leaf level and up to the root. At each\nlevel, the grouping uses a greedy heuristic that minimizes\ninter-group communication volume. After process groupings\nat all levels of the cache topology tree are determined, the\nmapping of processes to cores can be identi?ed.\nFor System S applications, since inter-thread communica-\ntions are explicitly speci?ed at the SPL level \(via Threaded\nPorts also has pro?ling\nsupport to record the total data volumes passing through\nThreaded Ports, based on which the inter-thread communi-\ncation matrix can be constructed. Greedy partitioning is then\napplied to determine the thread mapping.\n3 shown in Fig-\nure 8 both inter-thread\ncommunication and operator sharing can be viewed as\ndata sharing between threads TreeMatch-S quanti?es these\ntwo relationships with a uniform metric that measures the\n’intensity’ of data sharing. This intensity depends on: \(i shared operators’ internal states, and \(ii behavior.\nThe metric is obtained with the DynamoRIO/Umbra tool,\nwhich measures threads’ cache access at cache line level.\nDynamoRIO [1] uses dynamic instrumentation of binary\nexecutables to obtain various program characteristics at\ninstruction granularity. Umbra [31] adds a set of plug-ins\nto DynamoRIO for tracking program’s memory references.\nWe measure thread cache behavior using Umbra’s cache\n596\nC\n0 \nL1  \nL2 \nC\n1 \nL1 nC\n2 \nL1 \nL2 \nC\n3 \nL1 \nop1 \nop2 op3 op4 \nop6 op5 \nThread 0 \nThread 1 \nThread  2 Thread  3 \n{{T0, T2}, {T1 T3}}\nT0 T1 T2 T3 \nT0   0 140 150 140 \nT1 140   0   0   0  \nT2 150   0   0   0 \nT3 140   0   0   0 \nT0 T1 T2 T3 nT0   0 1000 1200 1200 \nT1 1000   0   0   0  \nT2 1200   0   0 2000 \nT3 1200   0 2000   0 \n{{T0, T1}, {T2 T3}}\nTreeMatch Result: \nThread Communication Matrix \nThread Correlation Matrix \nTreeMatch: \nCommunication nProfiling \nCache Topology Tree Target Machine \nSPL Program \nTreeMatch-S Result: \nC0 C1 C2 C3 \nTreeMatch-S nBinary  \nInstrumentation \nFigure 8. Illustration of TreeMatch and TreeMatch-S Algorithms.\nline ownership tracking capability [32]. During program\nexecution, Umbra assigns an ownership bitmap in shadow\nmemory for each application-accessed cache line. Each bit in\nthe bitmap represents one thread, and setting a bit to 1 means\nthe corresponding thread owns a copy of that cache line in its\nprivate cache. Umbra dynamically inserts instructions before\nevery memory access instruction to maintain the ownership\nbitmaps. When a thread reads a 


cache line, it installs a\ncopy of that cache line in its private cache; accordingly,\nthe instructions inserted by Umbra set thread’s bit in that\ncache line’s ownership bitmap. If a thread updates a cache\nline, it invalidates all other threads’ copies of that cache\nline; Umbra-inserted instructions accordingly set the writing\nthread’s bit and clear all other bits in the bitmap.\nWith cache line ownership tracking, thread sharing inten-\nsity is measured as follows. \(1 an array of counters for each\nthread to record its interaction intensity with other threads.\n\(2 reads a cache line of which it does not\nown a copy \(a cache miss exclusively own \(a cache invalidation line\nis increased by 1. \(3 counters.\nThis matrix records the sharing intensity between thread\nwhich uniformly captures both inter-thread communication\nand operator sharing relationships. TreeMatch-S uses this\nthread correlation matrix and applies thread grouping and\nmapping in the same way as TreeMatch.\n4 TreeMatch-\nS considers shared resource contention between threads. The\nHolistic Mapping algorithm takes into account both sharing\nAND contention intensity between threads and strikes a\nbalance between them to determine an appropriate mapping.\nTo mitigate contention on shared memory resources \(e.g.,\nlast level cache, FSB need to quantify each thread’s\ndemand on those resources and distribute those demands\nin a balanced way Previous work [34, 26] suggests that\nthe Last Level Cache Miss Rate \(measured as number of\nlast level cache misses per thousand instructions the LLC miss rate not only indirectly measures\na thread’s working set size \(in terms of how much of\nits working set cannot ?t into last level cache Side\nBus. We adopt this approach and obtain each thread’s LLC\nmiss rate values as follows. We ?rst apply TreeMatch-S to\nget an initial thread mapping. We then run the application\non the target machine with this mapping and measure the\nrelevant hardware performance counter events. We use the\nLikwid tool [2] to collect performance counter values and\ncalculate the LLC miss rate for each thread.\nWith the generated measurements the Holistic Mapping\nmethod groups threads in accordance with the cache topol-\nogy tree. It treats the grouping of threads at each level\nas a graph partitioning problem. Each thread is assigned a\nweight that is its LLC miss rate, and each pair of threads is\nassigned a weight that represents the data sharing intensity\nobtained with the TreeMatch-S measurements. The goal of\ngraph partitioning is to reduce cross-group data sharing and\nin addition, to maintain a reasonable balance of aggregate\nLLC miss rate values among thread groups. Partitioning is\nperformed with the SCOTCH graph partitioning tool [3].\n5 Details:\nNUMA Effect: When running on a NUMA machine, each\nthread initialize its operators AFTER binding to target cores\nso that its data is placed in local NUMA domain.\nMeasurement Cost. Obtaining a machine’s cache con-\n?guration is a one-time cost. For any application/machine\ncombination, Exhaustive Search requires a complete run.\nFor TreeMatch, information about inter-thread communica-\ntion can be measured once and used across machines. For\nTreeMatch-S, data sharing intensity needs to be measured\nonce for any given cache line size. Holistic Mapping needs\nto obtain the same data sharing intensity information as\nTreeMatch-S; it must additionally collect hardware perfor-\nmance counter values with one run on target machine.\nSensitivity to Input Data. All four algorithms make map-\nping decisions based on pro?ling information using sample\ninput data. If threads’ runtime behavior diverges dramatically\nfrom the pro?ling runs, the of?ine mapping generated by\nthose algorithms may lead to unsatisfactory performance.\nOne possible solution to this problem is to continuously\nmonitor and adjust thread mappings at runtime. Since most\nstreaming applications with which we have worked have\nsteady behavior \(the same observation is made for StreamIt\napplications [28 topic for future work.\nV. PERFORMANCE EVALUATION\nWe apply StreamMap to two real-world streaming appli-\ncations VWAP and LOIS Enterprise Linux Server release 5.8. The diversity of\nmachines’ cache structures helps assessing the effectiveness\nof StreamMap across different CMP platforms.\nFor comparison, we also measure the application perfor-\nmance achieved without StreamMap, i.e., we run application\n6057\nFunctor \nAggregator \nFunctor \nJoin nFile Sink \nFunctor Functor \nAggregator \nFunctor \nJoin \nFile Sink \nFunctor Functor \nAggregator \nFunctor \nJoin nFile Sink \nFunctor Functor \nAggregator \nFunctor \nJoin \nFile Sink \nFunctor \nSplit \nSource Thread \nWorker Thread 1 Worker Thread 2 \nFunctor Functor \nSplit Split \nFunctor \nFunctor \nFunctor \nFunctor \nFigure 9. VWAP Application.\nFileSource \nCustom \nFunctor Functor \nFileSink \nFunctor \nFunctor Aggregator \nAggregator Functor nFunctor \nBarrier \nFunctor \nBarrier \nFunctor \nFileSink \nThread 1 \nThread 3 \nThread 2 \nThread 4 \nFunctor nFigure 10. LOIS Application.\nW2 \nW1 \nS \nW3 \nC\nom\nm\nun\nic\nat\nio\nn \nVo\nlu\nm\ne \nInter-Thread Communication \nS W1 W2 W3 \n1.0 \n0.0 \nD\nat\na \nSh\nar\nin\ng \nIn\nte\nns\nity\n \nW2 \nW1 \nS \nW3 \nInter-Thread Correlation \nW1 W2 W3 S \n1.0 


n0.0 \nL2 \nL1 L1  \nL2  \nL1 L1 \nL2 \nC\n1 \nL1 \nC\n5 \nL2 \nC\n6 \nL1 \nC\n7 \nL1 \nL2 \nL1 \nC\n2 \nL1  \nL2  \nC\n3 \nL1 \nC\n4 \nL1 L1 \nL2 \nL1 \nC\n7 \nL1 \nS W W W \nS W W \nBest Mapping \nWorst Mapping \nL1 \nW \nL2 \nL1 \nC\nom\nm\nun\nic\nat\nio\nn nVo\nlu\nm\ne \nFigure 11. Thread Mapping of VWAP.\n0 \n0.2 \n0.4 \n0.6 \n0.8 \n1 \n1.2 \n1.4 \n1.6 \n1.8 \n1 2 3 4 nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic n0 \n0.2 \n0.4 \n0.6 \n0.8 \n1 \n1.2 \n1.4 \n1.6 \n1.8 \n1 2 3 4 5 6 7 8 \nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic \n\(a b c n0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n1 2 3 4 5 6 7 8 \nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best nWorst TreeMatch \nTreeMatch-S Holistic \nFigure 12. Throughput of VWAP with Small Sliding Window \(Normalized to the Throughput of Single-Threaded VWAP with Default OS Scheduler OS scheduler de-\ncide the core on which each thread runs. On a typical Linux\nOS, the scheduler schedules threads based on core idleness\nand may migrate threads across cores during execution.\nA. VWAP Application Performance\nThe VWAP application ingests ?nancial ticket streams\ncontaining trade and quota data from a stock exchange and\ndetects bargains from the data. As shown in Figure 9, input\ndata streams ?ow into VWAP via a source operator. A split\noperator uses a hash function to route each tuple to one of\nthe downstream branches Each branch has an aggregator\noperator to maintain a running average of trades and a join\noperator with a sliding window where each new quota tuple\nwill be matched with trades to determine bargains. There is\none source thread executing the subgraph from the source to\nthe split operator. Each downstream branch is executed by a\nworker thread. The source thread passes data to each worker\nthread via a separate Threaded Port queue Worker threads\ndo not communicate or share operator with each other.\nWe run VWAP with two different con?gurations: the ?rst\n\(referred to as “Small Window second \(referred to as “Large Window dataset consisting of a day of traces. We use\na subset of this sample dataset for StreamMap to quickly\ncalculate of?ine thread mappings and use the whole dataset\nto measure resulting application performance.\nFigure 12 shows the normalized throughput of VWAP\nwith “Small Window” con?guration. We make three ob-\nservations from the results. First, the maximum difference\n0 \n5 \n10 \n15 \n20 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn nBins \nSource Thread \nL1 Cache L2 Cache \n0 \n1 \n2 \n3 \n4 \n5 \n6 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn 1 \nL1 Cache L2 Cache \n0 \n1 \n2 \n3 \n4 \n5 \n6 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn n0 \n1 \n2 \n3 \n4 \n5 \n6 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn Reuse Distance of VWAP with 4 Threads.\nbetween the best and worst performing mappings is 27%\non 4-Core UMA 43% on 8-Core UMA, and 68% on 8-\nCore NUMA. On both 8-Core UMA and 8-Core NUMA\nmachines, the differences are the most evident with 3, 4 and\n5 threads. Figure 11 shows the inter-thread communication\nand correlation matrices for VWAP with 4 threads. Both ma-\ntrices reveal that the source thread has balanced data sharing\nrelationships with each of the three worker threads, which\nis expected from VWAP’s data?ow structure Figure 11 also\nshows the best and worst performing mappings on 8-Core\nUMA. Placing intensively communicating threads close to\neach other is bene?cial to application performance. As\nVWAP scales beyond 6 threads, the performance differences\nof different mappings diminish. This is due to the symmetry\nof machines’ cache topologies and the balanced data and\nwork distribution among worker threads in VWAP.\nSecond, TreeMatch TreeMatch-S, and Holistic Mapping\nall generate the best thread mapping in all cases. Since\nthreads in VWAP do not share operators, thread correlation\nmatrix only re?ects inter-thread communication intensity\n\(Figure 11 based on which TreeMatch-S derives the same\nmappings as TreeMatch. We further measure threads’ cache\n6158\n\(a 4-Core UMA \(b c nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic n0 \n0.2 \n0.4 \n0.6 \n0.8 \n1 \n1.2 \n1.4 \n1.6 \n1 2 3 4 \nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic \n0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \n1 2 3 4 5 6 7 8 nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic nFigure 14. Throughput of VWAP with Large Sliding Window \(Normalized to the Throughput of Single-Threaded VWAP with Default OS Scheduler We use Reuse Distance [33] to\nmeasure cache locality: when a thread access a cache line,\nthis access’ Reuse Distance is the number of distinct cache\nlines referenced between current access and the previous\naccess to that cache line; a cache line access with a long\nreuse distance has a high probability of being a cache 


miss.\nFigure 13 shows the reuse distance histograms of VWAP\nwith 4 threads.We see that all 4 threads has good temporal\nlocality since the majority of cache line accesses can ?t\ninto L1 cache. We also measure the working set size \(the\nnumber of distinct cache lines touched that the working set size of\nthe Source thread is 465 cache lines, and that of each Worker\nthreads is 9 or 10 cache lines. Due to the small working set\nsizes, contention on last level cache and FSB is not severe\namong VWAP threads. Therefore, Holistic Mapping has the\nsame results as TreeMatch and TreeMatch-S.\nThird, Figure 12 shows that the mappings by the default\nLinux OS scheduler is close to the worst cases for most\ntests. This is because the Linux scheduler tends to spread\nthreads across the system, and this hurts the performance of\nVWAP which is communication dominant.\nInterestingly, the performance of VWAP with “Large\nWindow” con?guration shown in Figure 14 achieves better performance \(up\nto 7 sliding windows have large working sets,\nso the contention on shared cache and memory bandwidth\noutweighs inter-thread communication. As a result, both\nTreeMatch and TreeMatch-S generate sub-optimal mappings\ndue to failure to consider resource contention. Holistic\nMapping, however, still ?nds the best mapping. This clearly\nshows the importance of holistically considering both data\nsharing and resource contention for thread mapping.\nB. LOIS Application Performance\nThe LOIS application detects outliers in radio data from\nouter space The version of LOIS used in this paper reads\nfrom a disk ?le containing a sample dataset collected from\na Scandinavian radiotelescope in Europe. Figure 10 shows\na 4-thread setup of LOIS. Thread 1 calculates point-wise\ncoordinates for each input data record which are consumed\nby Thread 2. Thread 2 and 3 maintains aggregate statistics on\ntwo sliding windows of past records. Thread 2 produces data\nto feed into Thread 3, and also synchronizes with Thread\n3 on a shared Barrier operator. Thread 4 receives from\nThread 2 and 3 the upper and lower bounds of coordinates\nderived from the sliding windows, and ?nds all outliers in\nthe incoming data record. 5-thread and 6-thread versions of\nLOIS are constructed by further introducing Threaded Ports\nto split the work of Thread 3 and 4.\nFigure 15 shows the performance of LOIS. Both\nTreeMatch-S and Holistic Mapping are able to ?nd the best-\nperforming thread mapping in all cases which outperforms\nthe worst mapping and the default OS mapping by up to\n2.4 and 1.8 times, respectively. TreeMatch, on the other\nhand, sometimes gives sub-optimal mappings. To explain\nthe difference between TreeMatch and TreeMatch-S, we\nlook at the inter-thread communication matrix and thread\ncorrelation matrix for LOIS with 4 threads. Figure 16 shows\nthat thread correlation measurements capture data sharing\nbetween threads \(especially between Thread 2 and 3 due\nto their sharing of operators using\ninter-thread communication volumes.\nHolistic Mapping achieves the same best mapping as\nTreeMatch-S for LOIS. This is because resource contention\nis not severe among threads in LOIS. Figure 17 shows the\nreuse distance histograms of 4 LOIS threads. Although the\nLOIS threads show worse temporal locality than VWAP\n\(since the histograms are more scattered towards larger dis-\ntances t into\nL2 cache. Therefore, the bene?t brought by placing thread\nwith intensive data sharing close to each other outweighs\nthe penalty of resource contention.\nIn terms of cost, Exhaustive Search has poor scalability.\nFor example, enumerating all possible mappings of 6-thread\nLOIS on 8-Core UMA machine takes 600 pro?ling runs even\nafter eliminating redundant mappings based on symmetry\nof cache topology. TreeMatch needs one pro?ling run with\nSystem S runtime’s communication pro?ling facility, but the\npro?ling overhead is negligible. TreeMatch-S needs one run\nwith binary instrumentation which can slow down VWAP\nand LOIS by up to 8×. Holistic Mapping requires two pro?l-\ning runs: the ?rst run is the same as TreeMatch-S with binary\ninstrumentation enabled, and the second one is with low-\noverhead hardware performance counter monitoring enabled.\n6259\n\(a b c nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic n0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \n1 2 3 4 5 6 \nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic \n0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n1 2 3 4 5 6 \nN\nor\nm\nal\niz\ned\n T\nhr\nou\ngh\npu\nt \nNumber of Threads \nOS Default Best \nWorst TreeMatch \nTreeMatch-S Holistic \nFigure 15 Throughput of LOIS \(Normalized to the Throughput of Single-Threaded LOIS with Default OS Scheduler nSh\nar\nin\ng \nIn\nte\nns\nity\n \nT1 T2 T3 T4 \nC\nom\nm\nun\nic\nat\nio\nn \nVo\nlu\nm\ne \nInter-Thread Communication Inter-Thread Correlation \nT3 \nT2 \nT1 \nT4 \nT3 \nT2 \nT1 \nT4 \nT1 T2 T3 T4 \n1.0 1.0 \n0.0 0.0 \nL2 \nL1 L1  \nL2  \nL1 L1 \n1 3 2 4 \nMapping by TreeMatch Mapping by TreeMatch-S \nL2 \nL1 L1  \nL2  \nL1 L1 \n1 2 4 3 \nFigure 16. Thread Mapping of LOIS with 4 Threads on 4-Core UMA.\nC. Major Observations from Experimental Results\n\(1 to 2.4x difference between the best and\nworst thread mappings. The difference is more evident when\nthere is more asymmetry in application structure and/or\ncache topology. Since streaming applications with compli-\ncated 


data?ows and parallelisms are emerging and current\nand next generation of CMPs by major vendors are adopting\ndeep and complex cache structures, cache topology aware\nmapping will show growing importance in the future.\n\(2 sometimes\nconstitutes the worst case \(especially for applications whose\nperformance is dominated by inter-thread data sharing Linux OS scheduler.\n\(3 constructive data sharing and\ndestructive resource contention between threads. This is\ndemonstrated by our Holistic Mapping algorithm which\nalways ?nds the best mappings.\nVI. RELATED WORK\nA. Mapping Multi-Threaded Programs on CMPs\nCommunication and Sharing Aware Mapping. The prob-\nlem of mapping a multi-process or multi-threaded program\nto a set of underlying resources to minimize program execu-\ntion time is NP-hard [8 Various heuristics have been pro-\nposed with the objective of minimizing communication cost,\nsuch as graph partitioning [5] and graph matching [19]. [24]\nimplements a OS-level scheduler which places intensively-\ninteracting threads close to each other. As shown in this\npaper, arranging data movement based on cache topology\nalone does not capture all important trade-offs and may lead\nto sub-optimal overall performance.\nContention Aware Mapping. [18] shows that contention\non shared memory resources can severely degrade applica-\n0 \n3 \n6 \n9 \n12 \n15 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn n12 \n15 \nC\nol\nd 0 1 2 3 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn 4 5 6 7 8 9 10\n \n11\n \n12\n \n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn n13\n \n14\n \n15\n \n16\n \n17\n \n>1\n8 \n# \nof\n C\nac\nhe\n L\nin\ne \nA\ncc\nes\nse\ns \n\(U\nin\nit:\n M\nill\nio\nn nL1 Cache L2 Cache \nFigure 17. Memory Reuse Distance of LOIS.\ntion performance on CMPs. Hardware [21] and OS level [17]\ncache partitioning, user level thread scheduling [34], and\ncompiler-time transformation [22, 25 are proposed to mit-\nigate resource contention among processes and/or threads.\nHowever, they only work for independent threads or pro-\ncesses with no communication or sharing relationships.\nHolistic Mapping. [26 exploits thread mapping for op-\ntimizing multi-threaded datacenter applications on CMPs.\nHowever, the mapping policies in [26] either use exhaustive\nsearch or require a new algorithm for each type of cache\ntopology. Our new contributions include an in-depth study\nof streaming application’s cache behavior and a holistic\nmapping algorithm which is more general and scalable.\nB. Optimizing Streaming Applications on CMPs\nAlgorithmic Optimization of Streaming Algorithms. Exam-\nples include join [27, 11], aggregation [6], sorting [10 and\nfrequency counting [7]. Operators in a streaming program\nmay interact with each other in complicated ways and\nsuch complexity is manifested at thread level at runtime.\nManaging such complicated interaction is beyond the scope\nof tuning individual operators, so orchastration provided by\nStreamMap is necessary to coordinate threads’ execution.\nBesides, StreamMap does not require knowledge of opera-\ntors’ internal implementation, and uses pro?ling information\ncollected at middleware level to make mapping decisions.\nTherefore, StreamMap is orthogonal and complementary to\ncode tuning of individual streaming operators.\nCompile-Time Scheduling and Mapping of Streaming Pro-\ngrams on CMPs. Pioneered by StreamIt [13], work has\nbeen done in optimizing static scheduling of streaming\nprograms on multicores [16, 29, 30]. Those work apply\ncompiler analysis and code transformation to exploit various\nparallelism in program to balance computation load among\nthreads. Since most of those work target Cell B.E. architec-\n630\nture which has explicitly managed memory hierarchy, they\ncommonly try to hide data movement cost by overlapping\ncommunication with computation in the execution schedule.\nIn comparison, StreamMap targets cache topologies seen in\nx86 CMP architecture which impose distinct challenges such\nas contention on shared resources, and it works at thread\nlevel without heroic compiler analysis.\nCache-Aware Optimization of Streaming Programs. [23]\nproposed three techniques to optimize StreamIt programs\non a uniprocessor: execution scaling, buffer manager, and\nregister replacement. [20] extends execution scaling to multi-\ncore. Both work assumes synchronous data ?ow model to\ncalculate static steady state schedule, and [20] does not\nconsider thread mapping to reduce contention or thread\nsynchronization cost 4] theoretically shows that cache-\nef?cient scheduling of streaming programs on a uniprocessor\ncan be modeled as a partitioning problem and some special\ncases can be solved in polynomial time. Our work targets\nmulti-core processors, uses mapping algorithms different\nfrom the one proposed in [4], implements those algorithms\ninside System S middleware, and evaluates them with real-\nworld applications on representative architectures.\nVII CONCLUSIONS AND FUTURE WORK\nThis paper demonstrates that CMP’s cache topology can\nhave a signi?cant impact on the performance of multi-\nthreaded streaming applications. Our StreamMap approach\nautomatically places threads 


to cores to control the data\nsharing and resource contention between threads, and can\nimprove real-world streaming applications’ performance by\nup to 1.8 times over the default Linux OS scheduler.\nFuture directions of this research are twofold. We plan to\nstudy how to use StreamMap to provide feedback informa-\ntion to System S’ compiler to optimize operator fusion. We\nalso plan to apply StreamMap to a wider range of streaming\napplications, e.g., dynamic graph analysis.\nREFERENCES\n[1] Dynamorio: Dynamic instrumentation tool platform.\nhttp://www.dynamorio.org, October 2012.\n[2] Likwid: Lightweight performance tools.\nhttp://code.google.com/p/likwid, October 2012.\n[3] Scotch: Static mapping, graph, mesh and hypergraph partitioning.\nhttp://www.labri.fr/perso/pelegrin/scotch/, October 2012.\n[4] K. Agrawal, J. T. Fineman, J Krage, C. E. Leiserson, and S. Toledo.\nCache-conscious scheduling of streaming applications. In Proc. of\nSPAA 12, 2012.\n[5] H. Chen, W. Chen, J. Huang, B. Robert, and H. Kuhn. Mpipp: an\nautomatic pro?le-guided parallel process placement toolset for smp\nclusters and multiclusters. In Proc. of ICS ’06, 2006.\n[6] J. Cieslewicz and K. A. Ross. Adaptive aggregation on chip multi-\nprocessors. In Proc. of VLDB ’07, 2007.\n[7] S. Das, S. Antony D. Agrawal, and A. El Abbadi. Thread cooperation\nin multicore architectures for frequency counting over multiple data\nstreams. Proc. VLDB Endow., 2\(1  Alves, J. Schneider,\nP. Navaux, and H.-U. Heiss. Evaluating thread placement based on\nmemory access patterns for multi-core processors. In Proc. of HPCC\n’10, 2010.\n[9] B. Gedik, H. Andrade, K.-L. Wu, P. S. Yu, and M Doo. Spade: the\nsystem s declarative stream processing engine. In Proc. of SIGMOD\nConference, 2008.\n[10] B Gedik, R. R. Bordawekar, and P. S. Yu. Cellsort: high performance\nsorting on the cell processor. In Proc. of VLDB ’07, 2007.\n[11] B. Gedik, R. R. Bordawekar, and P. S. Yu. Celljoin: a parallel stream\njoin operator for the cell processor. The VLDB Journal, 18\(2  Vachharajani. Fastforward for\nef?cient pipeline parallelism: a cache-optimized concurrent lock-free\nqueue. In Proc. of PPoPP ’08, 2008.\n[13] M. I. Gordon, W. Thies, and S. Amarasinghe. Exploiting coarse-\ngrained task data, and pipeline parallelism in stream programs. In\nProc. of ASPLOS ’06, 2006.\n[14] E. Jeannot and G Mercier. Near-optimal placement of mpi processes\non hierarchical numa architectures. In Proc. of Euro-Par ’10 2010.\n[15] R. Khandekar, K. Hildrum, S. Parekh, D. Rajan, J. Wolf, K.-L. Wu,\nH. Andrade, and B. Gedik. Cola optimizing stream processing\napplications via graph partitioning. In Proc. of Middleware ’09, 2009.\n[16] M Kudlur and S. Mahlke. Orchestrating the execution of stream\nprograms on multicore platforms. In PLDI ’08 2008.\n[17] J. Lin, Q. Lu, X. Ding, Z. Zhang, X. Zhang, and P. Sadayappan.\nGaining insights into multicore cache partitioning: Bridging the gap\nbetween simulation and real systems. In Proc. of HPCA ’08, 2008.\n[18] J Mars, L. Tang, and M. L. Soffa. Directly characterizing cross core\ninterference through contention synthesis In Proc. of HiPEAC ’11,\n2011.\n[19] E. H. Molina da Cruz, M. A. Zanata Alves, A. Carissimi, P. O. A.\nNavaux, C P. Ribeiro, and J.-F. Mehaut. Using memory access traces\nto map threads and data on hierarchical multi-core platforms. In Proc.\nof IPDPSW ’11, 2011.\n[20] A. Moonen, M. Bekooij, R. van den Berg, and J. van Meerbergen.\nCache aware mapping of streaming applications on a multiprocessor\nsystem-on-chip. In Proc. of DATE 08, 2008.\n[21] M. K. Qureshi and Y. N. Patt. Utility-based cache partitioning: A low-\noverhead high-performance, runtime mechanism to partition shared\ncaches. In Proc. of MICRO 39, 2006.\n[22] A. Sandberg D. Eklo¨v, and E. Hagersten. Reducing cache pollution\nthrough detection and elimination of non-temporal memory accesses.\nIn Proc. of SC ’10, 2010.\n[23] J. Sermulins, W. Thies, R. M. Rabbah, and S. P. Amarasinghe Cache\naware optimization of stream programs. In Proc. of LCTES, 2005.\n[24] D. Tam, R. Azimi, and M. Stumm Thread clustering: sharing-aware\nscheduling on smp-cmp-smt multiprocessors. In Proc. of EuroSys 07,\n2007.\n[25] L. Tang, J. Mars, and M. L. Soffa. Compiling for niceness: mitigating\ncontention for qos in warehouse scale computers. In Proc. of CGO\n’12, 2012.\n[26] L. Tang, J. Mars, N. Vachharajani, R. Hundt, and M L. Soffa.\nThe impact of memory subsystem resource sharing on datacenter\napplications. In Proc. of ISCA ’11 2011.\n[27] J. Teubner and R. Mueller. How soccer players would do stream joins.\nIn Proc. of SIGMOD ’11 2011.\n[28] W. Thies and S. Amarasinghe. An empirical characterization of stream\nprograms and its implications for language and compiler design. In\nPACT ’10, 2010.\n[29] A. Udupa, R. Govindarajan, and M. J Thazhuthaveetil. Software\npipelined execution of stream programs on gpus. In CGO ’09, 2009.\n[30] Z. Wang and M. F. O’Boyle. Partitioning streaming parallelism for\nmulti-cores: a machine learning based approach. In PACT 10, 2010.\n[31] Q. Zhao, D. Bruening, and S. Amarasinghe. Umbra: ef?cient and\nscalable memory shadowing. In Proc. of CGO ’10, 2010.\n[32] Q. Zhao, D. Koh, S. Raza, D. Bruening, and W.-F. Wong. Dynamic\ncache contention detection in multi-threaded applications. In Proc. of\nVEE ’11, 2011.\n[33] Y. Zhong, X. Shen, and C. Ding Program locality analysis using\nreuse distance. ACM Trans. Program. Lang. Syst., 31\(6  Zhuravlev, S. Blagodurov, and A. Fedorova. Addressing shared\nresource contention in multicore processors via scheduling. In Proc.\nof ASPLOS ’10, 2010.\n641\n 





brought together the Neu-\nroprosthesis Group \(NPG Also in 2003, Dr. Peng \nlead the creation of the Interagency Modeling and Analysis Group \(IMAG consists of program \nofficers from ten federal agencies of the U.S. government and Canada www.imagwiki.org/mediawiki of biological systems MSM Consortium of investigators \(started in \n2006 intelligent tools and reusable models, and \nintegrating these approaches in engineering systems and multiscale physiological problems. \n \n \nJose C. Principe \n \nPRESENTATION TITLE:  Tensor Product Kernels for  \nMultiscale Neural Decoding and Control \n \nAbstract: This talk will present a tensor product kernel that combines at the same time \nlocal field potentials \(LFPs multiscale neural activity. We will explain how to construct multiscale kernels \nthat map jointly the neural data to a functional space, and will illustrate its application in \nthe development of online controllers for electrical stimulation in sensorimotor brain machine interfaces.  \n \n Biographical Sketch: Jose C. Principe M’83-SM’90-F’00 Engineering at the University of Florida where he teaches advanced \nsignal processing, machine learning and artificial neural networks \(ANNs University of Florida Computational NeuroEngineering Labora-\ntory \(CNEL of interest is processing of time varying signals with \nadaptive neural models. The CNEL Lab has been studying signal and pattern recognition principles based \non information theoretic criteria \(entropy and mutual information Networks of \nthe IEEE Signal Processing Society, Past-President of the International Neural Network Society and Past-\nEditor in Chief of the IEEE Transactions on Biomedical Engineering. He is a member of the Advisory Board \nof the University of Florida Brain Institute.  Dr. Principe has more than 500 publications.  He directed 78 \nPhD dissertations and 65 Master theses.  He wrote in 2000 an interactive electronic book entitled Neural \nand Adaptive Systems” published by John Wiley and Sons and more recently co-authored several books on n“Brain Machine Interface Engineering” Morgan and Claypool, “Information Theoretic Learning”, Springer,  \nand Kernel Adaptive Filtering”, Wiley. \n \n \nPaul Sajda  \n \nPRESENTATION TITLE:  Neurally and Ocularly Informed Graph-Based  \nModels for Searching 3D Environments \n \nAbstract: As we move through an environment, we are constantly making assessments, \njudgments, and decisions about the things we encounter. Some are acted upon immedi-\nately, but many more become mental notes or fleeting impressions -- our implicit "label-\ning" of the world. In this talk I will describe our work using physiological correlates of this labeling to con-\nstruct a hybrid brain-computer interface \(hBCI record electroencephalographic \(EEG part of a 3D virtual city under free-viewing conditions. Using machine learning, we integrate \nthe neural and ocular signals evoked by the objects they encounter to infer which ones are of subjective inter-\nest. These inferred labels are propagated through a large computer vision graph of objects in the city, using nsemi-supervised learning to identify other, unseen objects that are visually similar to those that are labelled. \nFinally, the system plots an efficient route so that subjects visit similar objects of interest. We show that by \nexploiting the subjects' implicit labeling, the median search precision is increased from 25% to 97%, and the \nmedian subject need only travel 40% of the distance to see 84% of the objects of interest. We also find that \nthe neural and ocular signals contribute in a complementary fashion to the classifiers inference of subjects' \nimplicit labeling. In summary, we show that neural and ocular signals reflecting subjective assessment of ob-\njects in a 3D environment can be used to inform a graph-based learning model of that environment, resulting \nin an hBCI system that improves navigation and information delivery specific to the user's interests. \n \nBiographical Sketch: Paul Sajda is Professor of Biomedical Engineering, Electrical Engineering and Radiol-\nogy at Columbia University and Director of the Laboratory for Intelligent Imaging and Neural Computing \n\(LIINC modeling and \nmachine learning applied to image understanding. Prior to Columbia he was Head of The Adaptive Image \nand Signal Processing Group at the David Sarnoff Research Center in Princeton, NJ. He received his B.S in \nElectrical Engineering from MIT and his M.S. and PhD in Bioengineering from the University of Pennsyl-\nvania. He is a recipient of the NSF CAREER Award, the Sarnoff Technical Achievement Award, and is a nFellow of the IEEE and the American Institute of Medical and Biological Engineering \(AIMBE Editor-in-Chief for the IEEE Transactions in Neural Systems and Rehabilitation Engineering and a \n member of the IEEE Technical Committee on Neuroengineering. He has been involved in several technol-\nogy start-ups and 


is a co-Founder and Chairman of the Board of Neuromatters, LLC., a neurotechnology \nresearch and development company. \n \n \nJustin C. Sanchez  \n \nMODERATOR: Symposium #2 - Brain-Machine Interface   \nand \nPanel #1 Funding and Trends in Neuroengineering  \n \nBiographical Sketch: Justin C. Sanchez joined DSO as a program manager in 2013. At \nDARPA, Dr. Sanchez will explore neurotechnology, brain science and systems neuro-\nbiology. Before coming to DARPA, Dr. Sanchez was an Associate Professor of Biomedical Engineering and nNeuroscience at the University of Miami, and a faculty member of the Miami Project to Cure Paralysis. He ndirected the Neuroprosthetics Research Group, where he oversaw development of neural-interface medical ntreatments and neurotechnology for treating paralysis and stroke, and for deep brain stimulation for nmovement disorders, Tourette’s syndrome and Obsessive-Compulsive Disorder. \n \nDr. Sanchez has developed new methods for signal analysis and processing techniques for studying the un-\nknown aspects of neural coding and functional neurophysiology. His experience covers in vivo electro-\nphysiology for brain-machine interface design in animals and humans where he studied the activity of \nsingle neurons, local field potentials and electrocorticogram in the cerebral cortex and from deep brain \nstructures of the motor and limbic system. \n nHe is an elected member of the Administrative Committee of the IEEE Engineering in Medicine and Biology nSociety. He has published more than 75 peer-reviewed papers, holds seven patents in neuroprosthetic de-\nsign and authored a book on the design of brain-machine interfaces. He has served as a reviewer for the \nNIH Neurotechnology Study Section, DoD’s Spinal Cord Injury Research Program and the Wellcome \nTrust, and as an associate editor of multiple journals of biomedical engineering and neurophysiology. \n \nDr. Sanchez holds Doctor of Philosophy and Master of Engineering degrees in Biomedical Engineering, and \na Bachelor of Science degree in Engineering Science, all from the University of Florida. \n \n \nSteven J. Schiff \n \nPRESENTATION TITLE:  Towards Model-Based Control in Neural Engineering \n \nAbstract: Since the 1950s, we have developed mature theories of modern control the-\nory and computational neuroscience with little interaction between these disciplines. \nWith the advent of computationally efficient nonlinear Kalman filtering techniques n\(developed in robotics and weather prediction increasingly accurate reconstruction of dynamics in a variety \nnormal and disease states in the brain, the prospects for synergistic interaction between these fields are \nnow strong. I will show recent examples of the use of nonlinear control theory for the assimilation and con-\ntrol of single neuron and network dynamics, a control framework for Parkinson’s disease, and the potential \nfor unification in control of spreading depression and seizures. Lastly, I will discuss why the subtle and \ndeep intersection of symmetry, in brains and models, is important to take into account in this transdisci-\nplinary fusion of computational models of the computational brain with real time control.  \n Biographical Sketch: Steven J. Schiff, Brush Chair Professor of Engineering and Director of the Penn State \nCenter for Neural Engineering, is a faculty member in the Departments of Neurosurgery, Engineering Sci-\nence and Mechanics, and Physics. A Pediatric Neurosurgeon with particular interests in Epilepsy, Hydro-\ncephalus, Sustainable Health Engineering and Global Health, he holds a PhD in Physiology, and an MD, \nfrom Duke University School of Medicine. His book on Neural Control Engineering, was published by the \nMIT Press in 2012. Dr. Schiff has been listed in the Consumer’s Research Council of America’s guides to top \nphysicians and surgeons, and is a Fellow of the American Physical Society the American College of Sur-\ngeons, and the American Association for the Advancement of Science. \n \n \nNitish V. Thakor  \n \nPRESENTATION TITLE:  Translating Revolutionary Prosthesis to  \nPractical Prosthesis \n \nAbstract The Revolutionary Prosthesis Program by DARPA helped launch a revolu-\ntion in prosthetics technology and means for controlling the advanced dexterous \nlimbs, up with to 22 degrees of freedom.  That has necessitated the challenge of con-\ntrolling the limb with such superior dexterity.  I will introduce methods for dexterous nprosthesis control, from myoelectric to cortical \(EEG, Electrocorticogram, neural \nspike, local field potential incorporating multimodal sensors, such as camera and video tracking, may lead to more functional \nand practical prosthesis control. Emerging challenge now is to make the revolutionary prosthetics, practi-\ncal affordable and available for amputees today. I will present our affofdable prosthetic limb solution de-\nveloped with funding from the NIH Small Business Innovations Research \(SBIR hybrid solution, such as using RFID, for dexterous hand function. \n \nBiographical Sketch: Nitish V. Thakor F’1994 Institute for Neurotechnology \(SINAPSE in Chief \(EIC from 2005-2011 and presently the EIC of Medical and Biological Engineer-\ning and Computing. Dr. Thakor is a recipient of a Research Career Development Award from NIH a Presiden-\ntial Young Investigator Award from the 


NSF and is a Fellow of the AIMBE IEEE Founding Fellow of BMES \nand Fellow of IFMBE.  He is a recipient of the award of Technical Excellence in Neuroengineering from IEEE \nEngineering in Medicine and Biology Society Distinguished Alumnus Award from Indian Institute of Technol-\nogy Bombay India and a Centennial Medal from the University of Wisconsin School of Engineering. \n \n \nBruce Wheeler \n \nPRESENTATION TITLE:  Welcome Remarks \n nBiographical Sketch: Bruce Wheeler’s research interests lie in the application of elec-\ntrical engineering methodologies to neuroscience. His work influenced the develop-\nment of neural spike sorting technologies demonstrated that microelectrode array \nrecording from brain slices was possible and productive, and has been a leader in the \ndevelopment of lithography to control cells, especially neurons, in culture. This work \naims at basic science understanding of the behavior of small populations of neurons, in hopes of creating \nbetter insight into the functioning of the brain. Bruce Wheeler moved to the University of Florida in 2008, \nafter 28 years at the University of Illinois, mostly in the ECE Dept. He founded the Bioengineering Depart-\n ment at Illinois and served as acting department chair at both Illinois and Florida.  He currently serves as nPresident of the IEEE Engineering in Medicine and Biology Society, the world¹s largest bioengineering soci-\nety, and was Editor in Chief of the IEEE Transactions on Biomedical Engineering. He is a Fellow of the nIEEE, AIMBE and BMES.  \n \n \nJohn A. White \n \nPRESENTATION TITLE:  Are Our Cellular Models Fundamentally Wrong? \n \nAbstract: The Hodgkin-Huxley model, arguably the greatest success story in the history \nof computational neuroscience, is the predecessor of thousands of existing cellular models \nthat span a significant range of levels of detail. Here, using electrophysiological, dynamic-\nclamp, and computational techniques, we demonstrate that many of the “gold standard” \nsingle-cell models, used by thousands of laboratories, fail to account correctly for the responses of well-studied \nexcitatory neurons to noise.  In particular, the input-output gain of entorhinal stellate cells and neocortical py-\nramidal cells is substantially less sensitive to noise than predicted by the models.  The major source of the dis-\ncrepancy is that the models fit measured peri-threshold voltage dynamics poorly.  Because noise is ubiquitous \nand prominent in the brain, and because neuronal gain is crucial for understanding a wide range of response nproperties at the cellular and network levels, we argue that this is an issue of fundamental importance. \n nBiographical Sketch:  John A. White is the Executive Director of the Brain Institute and a USTAR Professor nof Bioengineering and Neuroscience at the University of Utah.  White received B.S. in Biomedical Engineering nfrom Louisiana Tech University and his PhD in Biomedical Engineering from Johns Hopkins University.  \nWhite's research focuses on the mechanistic bases of normal and abnormal neural activity and information \nprocessing His approach blends technology development, electrophysiology, computational modeling, and \nimaging. The goal is to develop new treatments for memory disorders and epilepsy, based on novel applica-\ntions of electronic technology and methods of analysis from applied mathematics and engineering.  White has \npublished over 70 peer-reviewed papers.  As principal or co-principal investigator, he has raised over $50M in \ngrant funding from the government and private sources. He is a Fellow of the American Institute for Biologi-\ncal and Medical Engineering and a Fellow of the Biomedical Engineering Society. \n \n \nGreg Worrell \n \nPRESENTATION TITLE Electrophysiological Biomarkers of  \nHuman Epileptogenic Brain \n \nAbstract: Epilepsy is a common neurological disorder affecting over 50 million people \nworldwide. Despite spending as little as 0.01% of their lives having seizures, people \nwith epilepsy take antiepileptic drugs \(AEDs ex-\nperience significant AED related side effects, and approximately 1/3 continue to have seizures. Mapping the \nbrain networks generating seizures is critical for successful epilepsy surgery, therapeutic brain stimulation, \nand seizure forecasting. In focal epilepsy the spontaneous, evoked, and induced brain activity is disrupted \nover a wide range of spatiotemporal scales. Multiscale electrophysiology recordings have uncovered a range \nof electrophysiological biomarkers, measurable interictal \(between seizures normal and \npathological tissue that show promise for spatiotemporal mapping of epileptogenic brain. In this talk we \nreview two potential applications of these multiscale biomarkers, epilepsy surgery and seizure forecasting.  \n \n Biographical Sketch:  Greg Worrell, MD, PhD is Chair of Clinical Neurophysiology, Director of Mayo Sys-\ntems Electrophysiology Laboratory \(MSEL prac-\ntice and research are focused on the evaluation and care of patients with medically resistant epilepsy nThrough MSEL he is currently pursuing the integration of large-scale neurophysiology, computing, and im-\naging for biomarker discovery. Ongoing clinical trials are investigating brain mapping, therapeutic brain nstimulation, and seizure forecasting.  \n \nDr. Worrell received his PhD in Physics from Case Western Reserve University and MD from University of \nTexas Medical Branch. He completed his Neurology training at Mayo Clinic. He is a member of the Ameri-\ncan Academy of Neurology, American Neurological Association, American Epilepsy Society, and IEEE. \n \n \nKaiming Ye  \n \nPanel #1: Funding and Trends in Neuroengineering  \n 


nBiographical Sketch:  Kaiming Ye is Professor and Department Chair of Bioengineer-\ning at State University of New York, Binghamton. He also serves as Program Director \nof Biomedical Engineering Program at National Science Foundation \(NSF imaging and \nvaccine development.  He is best known for his creative works in directing differentia-\ntion of human pluripotent stem cells into clinically relevant cell lineages under 3D environments and his \nwork in engineering fluorescence nanosensors for continuous glucose monitoring. He serves as Program \nEvaluator for Accreditation Board for Engineering and Technology \(ABET and co-chaired a number of international conferences and has been invited to deliver \nkeynote/plenary speech in numerous international and national conferences. He has published more than \n60 peer-reviewed papers and a book on human embryonic stem cells and a patent on glucose sensor. He \nserves as Executive Editor, Associate Editor, and member of Editorial Boards of 13 journals.  \n 


Reinhartz-Berger, and A. Sturm, “OPCAT-\na bimodal CASE tool for object-process based system\ndevelopment,” in 5th International Conference on En-\nterprise Information Systems \(ICEIS 2003  Olsen, R. Haagmans, T. J. Sabaka, A. Kuvshinov,\nS. Maus, M. E. Purucker, M. Rother, V. Lesur, and\nM. Mandea The Swarm End-to-End mission simulator\nstudy : A demonstration of separating the various con-\ntributions to Earths magnetic field using synthetic data,”\nEarth, Planets, and Space, vol. 58, pp. 359–370, 2006.\n[10] R. M Atlas, “Observing System Simulation Exper-\niments: methodology, examples and limitations,” in\nProceedings of the WMO Workshop on the Impact of\nvarious observing systems on Numerical Weather Pre-\ndiction, Geneva Switzerland, 1997.\n[11] M. Adler, R. C. Moeller, C. S. Borden, W. D. Smythe,\nR. F. Shotwell, B. F. Cole, T. R Spilker, N. J.\nStrange, A. E. Petropoulos, D. Chattopadhyay, J. Ervin,\nE. Deems, P. Tsou, and J. Spencer Rapid Mission\nArchitecture Trade Study of Enceladus Mission Con-\ncepts,” in Proceedings of the 2011 IEEE Aerospace\nConference, Big Sky, Montana, 2011.\n[12] J. Hauser and D. Clausing, “The house of quality,”\nHarvard Business Review, no. May-June 1998, 1988.\n[13] T. L. Saaty, “Decision Making With the Analytic Hier-\narchy Process,” International Journal of Services Sci-\nences, vol. 1, no. 1, pp. 83–98, 2008.\n[14] A. M. Ross, D. E Hastings, J. M. Warmkessel, and\nN. P. Diller, “Multi-attribute Tradespace Exploration as\nFront End for Effective Space System Design,” Journal\nof Spacecraft and Rockets, vol. 41, no. 1, 2004.\n[15] W. L. Baumol On the social rate of discount,” The\nAmerican Economic Review, vol. 58, no. 4, pp. 788–\n802, 1968.\n[16] M. K Macauley, “The value of information : Measuring\nthe contribution of space-derived earth science data to\nresource management,” Journal of Environmental Eco-\nnomics and Management, vol. 22, pp. 274–282, 2006.\n[17 S. Jamieson, “Likert scales: how to \(ab Dec.\n2004.\n[18] R. C. Mitchell and R. T. Carson, Using Surveys to\nValue Public Goods: The Contingent Valuation Method,\nS. Aller, Ed. Washington DC: Library of Congress,\n1989.\n[19] O. C. Brown, P. Eremenko, and P. D Collopy, “Value-\nCentric Design Methodologies for Fractionated Space-\ncraft: Progress Summary from Phase 1 of the DARPA\nSystem F6 Program,” AIAA SPACE 2009 Conference &\nExposition, 2009.\n[20] a. Stoffelen, G. J Marseille, F. Bouttier, D. Vasiljevic,\nS. de Haan, and C. Cardinali, “ADM-Aeolus Doppler\nwind lidar Observing System Simulation Experiment,”\nQuarterly Journal of the Royal Meteorological Society,\nvol. 132, no. 619, pp 1927–1947, Jul. 2006.\n[21] A. Newell and H. A. Simon, Human Problem Solving.\nEnglewood Cliffs, NJ: Prentice Hall, 1972.\n[22] R. Lindsay, B. G. Buchanan, and E. A. Feigenbaum,\n“DENDRAL: A Case Study of the First Expert System\nfor Scientific Hypothesis Formation,” Artificial Intelli-\ngence, vol. 61, no. 2, pp. 209–261, Jun 1993.\n[23] B. G. Buchanan and E. H. Shortliffe, Rule-based Ex-\npert Systems: the MYCIN experiments of the Stanford\nHeuristic Programming Project. Addison-Wesley,\n1984.\n[24] P. Hart, R. Duda, and M. Einaudi PROSPECTORA\ncomputer-based consultation system for mineral explo-\nration,” Mathematical Geology, no. November 1977,\n1978.\n[25] J. McDermott, “R1: A Rule-Based Configurer of Com-\nputer Systems,” Artificial lntell., 19 39, vol. 19, no. 1,\npp. 39–88, Sep. 1982.\n[26] K. J. Healey, “Artificial Intelligence Research and Ap-\nplications at the NASA Johnson Space Center,” AI\nMagazine, vol. 7, no. 3, pp. 146–152, 1986.\n[27] C Forgy, “Rete: A fast algorithm for the many pat-\ntern/many object pattern match problem,” Artificial in-\ntelligence, vol. 19, no. 3597, pp. 17–37, 1982.\n[28] L. A. Zadeh, “Fuzzy Sets,” Information and Control,\nvol. 8, no. 3, pp. 338–353, Jan. 1965.\n[29] C. Haskins, “INCOSE Systems engineering handbook -\nA guide for system life cycle processes and activities,”\nSystems Engineering, 2006.\n[30] N. Das, D. Entekhabi and E. Njoku, “An Algorithm for\nMerging SMAP Radiometer and Radar Data for High-\nResolution Soil-Moisture Retrieval,” IEEE Transactions\non Geoscience and Remote Sensing, vol. 49, no. 99, pp.\n1–9, 2011.\n[31] A. Messac and A. Ismail-Yahaya, “Multiobjective ro-\nbust design using physical programming,” Structural\nand Multidisciplinary Optimization, vol. 23, no. 5, pp.\n357–371, Jun. 2002.\n20\n[32] B. Cameron, “Value flow mapping: Using networks\nto inform stakeholder analysis,” Acta Astronautica,\nvol. 62, no. 4-5, pp. 324–333 Feb. 2008.\n[33] R. Yager, “On ordered weighted averaging aggregation\noperators in multicriteria decision making,” Systems ,\nMan and Cybernetics, IEEE Transactions on, no. 1, pp.\n183–190, 1988.\n[34] J. Fortin, D Dubois, and H. Fargier, “Gradual Num-\nbers and Their Application to Fuzzy Interval Analysis,”\nIEEE Transactions on Fuzzy Systems, vol. 16, no. 2, pp.\n388–402, Apr. 2008.\n[35] H. Apgar, “Cost Estimating,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 11.\n[36] Chalmers University of Technology, “Use of P-band\nSAR for forest biomass and soil moisture retrieval,”\nEuropean Space Agency, Tech Rep., 2004.\n[37] D. Selva, “Rule-based system architecting of Earth\nobservation satellite systems,” PhD dissertation, Mas-\nsachusetts Institute of Technology, 2012.\n[38] H. H. Agahi, G. Ball, and G. Fox, “NICM Schedule &\nCost Rules of Thumb,” in AIAA Space Conference 2009,\nno. September, Pasadena, CA, 2009, pp 6512–6512.\nBIOGRAPHY[\nDaniel Selva received a PhD in Space\nSystems from MIT in 2012 and he is\ncurrently a post-doctoral associate in\nthe department of Aeronautics and As-\ntronautics at MIT. His research inter-\nests 


focus on the application of multi-\ndisciplinary optimization and artificial\nintelligence techniques to space systems\nengineering and architecture, in partic-\nular in the context of Earth observa-\ntion missions. Prior to MIT, Daniel worked for four years\nin Kourou \(French Guiana particular, he worked as a specialist in\noperations concerning the guidance, navigation and control\nsubsystem and the avionics and ground systems. Daniel has\na dual background in electrical engineering and aeronautical\nengineering, with degrees from Universitat Politecnica de\nCatalunya in Barcelona, Spain, and Supaero in Toulouse,\nFrance. He is a 2007 la Caixa fellow, and received the Nortel\nNetworks prize for academic excellence in 2002.\nEdward F. Crawley received an Sc.D. in\nAerospace Structures from MIT in 1981.\nHis early research interests centered on\nstructural dynamics, aeroelasticity, and\nthe development of actively controlled\nand intelligent structures. Recently, Dr.\nCrawley’s research has focused on the\ndomain of the architecture and design of\ncomplex systems. From 1996 to 2003\nhe served as the Department Head of\nAeronautics and Astronautics at MIT, leading the strategic\nrealignment of the department. Dr. Crawley is a Fellow of\nthe AIAA and the Royal Aeronautical Society \(UK is the\nauthor of numerous journal publications in the AIAA Journal,\nthe ASME Journal, the Journal of Composite Materials, and\nActa Astronautica. He received the NASA Public Service\nMedal. Recently, Prof Crawley was one of the ten members of\nthe presidential committee led by Norman Augustine to study\nthe future of human spaceflight in the US.\n21\n 


Mars program. It would be designed for low mass, lowpower and low temperature operation. The S-band antenna would be a smaller, simpler version of the antenna that flew on Deep Impact. Other antenna options would be available The UHF antennas have been flown on previous Mars lander/rover missions. There would be other alternatives for the S-band antenna and the UHF transceiver on the hub could use a larger power amplifier to talk to an orbiting asset as a backup to the S-band radio  Risk  The highest risk items for telecom would be the single string design for each element and six year design lifetime. However, the S-band radio has flight heritage. The UHF radios would be a new design but do not require new technology. They would be an engineering development 8. SYSTEM SUMMARY Mass Equipment List Table 5 shows a summary of the mass and power for each of the subsystems for the remote instrument units. The mass of one remote unit without the specified instrument is 26.6 kg with contingency specified at the subsystem level based on heritage. Table 6 shows a summary of mass and power by subsystem for the hub. The mass of the hub with contingency is 44.9 kg. Table 7 shows a mass summary for the entire package with appropriate contingencies added per the JPL  s Flight Project Practices and Design Principles Design Principles. The package totals 218.2 kg which includes four remote units, five instruments, one hub, and the carrier container\(s Table 5. Mass and power summary for remote units Remote Unit Mass CBE Contingency Total Power Power 14.3 kg 30% 18.5 kg 0.180 W 2 W Night /Day Thermal 2.0 kg 29% 2.5 kg 0 W Telecom UHF 0.2 24% 0.3 kg 2 W 40 W CDS 0.7 kg 30% 0.9 kg 1 W \(1/60th per hour 3 W Structure 3.4 kg 30% 4.4 kg 0 W Total x 1 unit 20.6 kg 29% 26.6 kg Diplexer S-Band Downconverter STDN command data to S/C CDS Pr oc es so r S-Band Exciter 9 dBi S-Band LGA UHF Downconverter Small UHF transceiver command data to S/C CDS 


to S/C CDS Pr oc es so r UHF PA UHF Monopole Command data to C&amp;DH Command dat  to C&amp;DH  Figure 7  Telecom block diagram for the S-band \(top bottom  units would be located on the hub while the remote units only contain a UHF system 15 9. OPERATIONAL SCENARIOS Daytime Operations During the day, the remote units and hub would be fully operational. The remote units would collect data from their instruments as specified by the science team and store it in the controller memory. Table 8 shows the data volume expected from each instrument. After 24 hours have passed the UHF telecom system on the hub is used to poll each of the remote units separately at the designated interval for the stored data. The hub then transmits the data direct-to-Earth using the S-band radio. This requires a maximum of eight hours at 50 kbps each day using the DSN 34 m antennas However, data rates as high as 120 kbps may be achieved reducing the downlink time. The hub has enough memory margin to accumulate data from all the instruments for three Earth days before it must downlink the data Nighttime Operations During nighttime operations, data collection at the remote units would be taking place. The magnetometer and seismometer collect data continuously. However, the seismometer operates at a reduced mode where the sampling rate is reduced to one-half of the daytime rate which has been deemed more than adequate by the science team. The remaining instruments collect data at various intervals that would be conducive to the science team  s current requirements. Telecom events would not be scheduled during the lunar night. The data accumulates in the controller memory over 16 Earth days \(~14 days at an equatorial location would be considered a worse case so two days have been added to be conservative data volume summary for each instrument during a 16 Earth day lunar night. When the sun comes up and the hub and remote units have sufficient power to run the telecom systems the hub polls each remote unit separately at a designated interval similar to operations during the day. The data would then be transmitted to Earth gradually over the next few days using the S-band radio Table 7. Mass summary for total package Unit Mass Contingency Mass + contingency 4 Remote Units 82.4 kg 29% 106.4 kg Hub 35.2 kg 27% 44.9 kg Instruments including cabling 17.3 kg 30% 22.5 kg Carrier Container\(s Total with heritage contingency 153.1 kg 29% 197.5 kg  System contingency  21.4 kg 14 Total Package  43% 218.9 kg Table 8. Instrument data volumes received at the hub over one Earth day in daylight operations Science Instrument Compressed Data Volume Received at Hub 


Volume Received at Hub Mb Seismometer 236 Magnetometer 58 Heat Flow Probe 2 Seismic Sounder 700 Instrument &amp; Hub Engineering Data 6 Total 1002 Hub Memory 5000 Margin 80  Table 6. Mass and power summary for hub Hub/Base Unit Mass CBE Contingency Total Power Power 14.3 kg 30% 18.5 kg 0.180 W 2 W Night /Day Thermal 13.4 kg 28% 17.2 kg 0 W Telecom UHF Telecom S-band 3.4 15% 3.9 kg 2 W 40 W CDS 0.7 kg 30% 0.9 kg 1 W \(1/60th per hour W \(day Structure 3.4 kg 30% 4.4 kg 0 W Total x 1 unit 35.2 kg 27% 44.9 kg 2.38 W avg at night  16 10. SUMMARY AND CONCLUSIONS The ALGEP modular design builds upon lessons learned from Apollo era ALSEP package and technology advances since that time. ALGEP meets the requirements of long lifetime survival while maintaining continuous operation of its instruments during the lunar night which can last up to 16 days at equatorial regions on the Moon. The package would be powered using solar arrays and batteries alone not requiring nuclear sources to supply power or maintain thermal control. This concept is feasible due to its lowpower operational mode at night The modular design and packaging scheme provides flexibility in deployment across all regions of the Moon including the farside pending the availability of an orbital communications asset. The relatively light ALGEP package could be accommodated on astronaut activity support vehicles, providing a method to distribute the packages across the Moon, ultimately gaining a Moon-wide understanding of lunar geophysical properties ACKNOWLEDGEMENTS This work was supported by the NASA Lunar Sortie Science Opportunities Program The work described in this publication was carried out at the Jet Propulsion Laboratory, California Institute of Technology under a contract with the National Aeronautics and Space Administration References herein to any specific commercial product process or service by trade name, trademark, manufacturer 


or otherwise does not constitute or imply its endorsement by the United States Government or the Jet Propulsion Laboratory, California Institute of Technology REFERENCES 1] NRC  Scientific Context for Exploration of the Moon   Washington D.C.: The Nat. Academies Press, 2007 2] Apollo 11 Prelim. Sci. Rept., NASA SP-214, 1969 3] Apollo 12 Prelim. Sci. Rept., NASA SP-235, 1970 4] Apollo 14 Prelim. Sci. Rept., NASA SP-272, 1971 5] Apollo 15 Prelim. Sci. Rept., NASA SP-289, 1972 6] Apollo 16 Prelim. Sci. Rept., NASA SP-315, 1972 7] Apollo 17 Prelim. Sci. Rept., NASA SP-330, 1973 8] ALSEP Termination Report, NASA RP-1036, 1979 9] NRC  New Frontiers in the Solar System: an Integrated Exploration Strategy  Decadal Survey D.C.: The Nat. Academies Press, 2003 10] International Lunar Network Science Definition Team Final Report, 2009 BIOGRAPHY Melissa Jones is a member of the technical staff in the Planetary and Lunar Mission Concepts Group at the Jet Propulsion Laboratory.  Current work includes development of small Lunar lander concepts and instrument packages to deploy on the Moon,  Report Manager for the Titan Saturn System Mission Outer Planets Flagship Mission study, and staffing various concept studies as a systems engineer on Team X, JPL  s mission design team.  Melissa graduated from Loras College with a B.S. in Chemistry and a Ph.D. in Space and Planetary Science from the University of Arkansas  Linda Herrell has a BA in math/computer science/languages \(University of Texas fluids and heat transfer \(City College of New York addition to analytical work in computer science and thermal and structural analysis, she has worked as both a payload \(instrument Earth orbiting \(Hubble Space Telescope, Earth Observing System \(EOS Cassini as Proposal Manager for several NASA science missions She currently serves as the Program Architect for NASA's New Millennium Program    Table 9. Instrument data volumes generated at the hub after 16 Earth day lunar night Science Instrument Compressed Data Volume Received at Hub Mb Seismometer 1980 Magnetometer 920 Heat Flow Probe 5 Seismic Sounder 0 Instrument &amp; Hub Engineering Data 72 Total 2977 Hub Memory 5000 Margin 40  17 Bruce Banerdt has been a research geophysicist at the California Institute of Technology's Jet Propulsion Laboratory since 1977, where he does research in planetary geophysics and instrument development for flight projects. He has been on science teams for numerous planetary missions 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



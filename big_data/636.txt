1-4244-2577-8/08/$20.00 ©2008 IEEE Hepatocellular Carcinoma Angiogenesis Assessment Role of Ultrasound and Mathematical Modelling   Ofelia Mosteanu 1 Teodora Atena Pop 1 Paula Raica 2 Monica Lupsor 1 Mihai Socaciu 1 Liviu Miclea 2 Radu Badea 1  1  Iuliu Hatieganu University of Medicine and Pharmacy Cluj-Napoca ofeliamosteanu@gmail.com  2 Technical University of Cluj-Napoca paula.raica@aut.utcluj.ro    Abstract  Hepatocellular carcinoma is one of the five most common cancers worldwide. Experimental and clinical data indicate that in human hepatocellular carcinoma \(HCC\mor progression is associated with angiogenesis and that an increase in 
microvascular density is associated with a poor prognosis Ultrasound is an attractive modality for imaging angiogenesis because of the ease with which it can be repeated without exposing the patient to any risk. The ready repeatability of ultrasound is proving useful in following tumour response to conventional and novel antitumour drugs The tumour growth and its treatment response are the subjects of present interest which concerns the oncologic community worldwide. Cancer research has undergone radical changes in the past few years. The next big step will be to implement mathematical modeling approaches to interrogate the enormous amount of data being produced and extract useful answers In summary, this paper illustrates how mathematical models 
mighty be used to investigate promising US techniques for an in vivo, non-invasive, globally quantification of tumour’s morphological and functional changes I.  I NTRODUCTION Hepatocellular carcinoma is one of the five most common cancers worldwide, with a particularly high prevalence in Asian countries due to endemic hepatitis B virus infection [1   The incidence of HCC is also rising in Western countries as a result of increasing hepatitis C virus infection. More than 80 of patients with HCC have associated cirrhosis and impaired liver function, making treatment of HCC more difficult than many other cancers. The tumour growth and its treatment response are the subjects of present interest which concerns the 
oncologic community worldwide. Cancer research has undergone radical changes in the past few years. An important and hot trend of the research in this field is represented by the study of the cancer on models that simulate reality. Since the '80s there was a consensus in biomedical community that the biological systems are too complex to be used with accuracy by mathematical models. There was the same opinion about mathematical correlation of cancer which has a chaotically and unpredictable evolution. The distrust for biomathematics left biomedical science back to other sciences, biomedical achieving only immature experimental observations II.  Angiogenesis in hepatocellular carcinoma There are two types of microvascular structures in the liver 
large vessels, such as portal and central venules and hepatic arterioles, lined with continuous endothelial cells, and fenestrated sinusoids lined with discontinuous sinusoidal endothelial cells \(SEC\. The adult liver is highly vascularized Malignant liver tumours grow in an uncontrolled fashion with the propensity to spread into the surrounding tissues. Both these critical features are closely dependent from the tumour vascular networ  A s pa s s i v e di ff us i o n a l o n e w o ul d l i m i t  the passage of nutrients and the removal of waste products to few millimetres of tissue, the development of neoformed vessels is essential for the tumour growth. In liver tumors capillaries are formed and sinusoid fenestration is lost. Stellate cells 
are regarded as liver-resident pericytes. They may contribute to angiogenesis through mechanisms different from those attributed to pericytes and become activated. Fibrillar extracellular matrix accumulates and hepatocytes lose microvilli. The result is a distorted sinusoidal structure characterized by capillarization and formation of neovessels. Vascular proliferation is stimulated by a large number of angiogenesis factors and many of these have been recently identifed as peptides and cytokines The ability of tumoural cells to produce such substances was frstly reported in 1971 by Folkman et al  w h o s ubs e que n t l y  proposed that, in small tumours, the development of neovascularization identifies the shift from the dormant pre-vascular phase to the growing and spreading phase. Unlike the dual 
supply of the normal hepatic parenchyma provided by vessels arising from the systemic arterial circulation and the portal venous circulation, an advanced hepatocellular carcinoma HCC\ is abundantly supplied by systemic arteries alone. This abundancy facilitates the angiographic diagnosis of malignancy and differentiates non-neoplastic or preneoplastic conditions such as liver cirrhosis, hepatocellular adenoma, focal nodular hyperplasia and adenomatous hyperplasia. Tumoural vascularization shows some peculiar biological and morphological features. Firstly, it is not self-limited and tends to grow indefinitely according to the biological behavior of the tumour. Secondly, it develops as a complex, chaotic network at the growing edge of the tumour with irregular and winding branches pene 
trating the nodule with a radial shape. The number of vessels within the tumour is often, but not always, increased, so that hypervascularity is a common feature. The vessels are primitive, thin-walled, with paucity or absence of smooth muscular layer, frequently formed by incomplete  endothelial cells layer and connective tissue alone, sometimes directly lined by tumour cells. Anastomoses between adjacent arteries and veins mainly at the periphery of the nodule, are frequently observed 4  H C C p r o g r e s s e s  f r o m a s m a l l  w e lld i f f e r e n ti ate d tu mo r  


with no developed blood vessels to a larger and moderately or poorly differentiated form with a characteristic hypervascularity during dedifferentiation process III.  Angiogenesis imaging – ultrasound By insonating tissues where blood is flowing, and then processing the received signal, a non-invasive assessment of blood velocity can be made. In particular, when a transmitted ultrasonic wave is backscattered by moving red cells, the reflected signal displays a change in frequency which is described by the Doppler equation fD=2fV\(cos c where fD is the Doppler shift frequency, f the emitted ultrasonic frequency, V is the speed of blood cells, a the angle between the directions of the ultrasonic beam and blood cell motion, and c is the speed of ultrasound in tissue. Due to a fortuitous accident, when the US frequencies usually employed in diagnostic imaging \(2.5±10 MHz\ are backscattered by blood cells moving along human circulation, the Doppler frequency falls in the audible acoustic field, so that we can actually listen to blood flowing in the vessels Ultrasound \(US\ is an accessible, non-invasive and relatively inexpensive technique, ideal for longitudinal, in vivo, investigations involving a large number of subjects [5 U s i n g t h e pr e sently available US instruments, the Doppler signal can be represented by different sophisticated modalities, including duplex, colour and power Doppler Colour Doppler US is able to detect tumour neovascularity and the model of the tumour vascularization \(Fig 1 and 2\. This is important because there is a strong correlation between the index of flow resistance and histological features of aggressiveness [6   US imaging allows the location of the sample volume into the vessel in duplex Doppler, to obtain the Doppler frequency spectral trace, which reflects the velocity distribution of blood cells across the diameter of the vessel over successive cardiac cycles. The parameters peak frequency, spectral broadening and resistive index \(RI\ derived from the spectral analysis provide information on blood flow velocity, turbulence and vascular impedance, respectively, and may be useful to characterize flow patterns observed in the different tumours Colour Doppler displays a map of vascular spaces in a selected portion of the real-time US scan, with the advantage of rapidly assessing the presence and direction of blood flow and the spatial distribution of vessels, the latter being helpful in the mapping of tumoural angioarchitecture \(Fig 3 and 4 Power Doppler displays the integrated amplitude of the Doppler signal, and it is inherently more sensitive than conventional colour Doppler in displaying presence of flow in very small vessels [7  in c r ea s i n g th e d e p i cti o n o f  b o t h b e n i g n  an d  malignant liver lesions vascularization [8   The relative limitation of power Doppler is that it does not provide any information regarding flow direction, velocity and turbulence. Despite the advancement of technology, there are some limits on performance of Doppler US, particularly in the evaluation of deeply located lesions, such as tumours of the posterior segments of the liver, of low velocity flows and of very small vessels \(as it occurs in tumoural vasculature US contrast agents have been developed in the attempt to overcome these limits, and there are now several agents which are in use or under investigation for enhancing liver vascular imaging   Fig 1. A- Grey scale: Liver hyperechoic tumoural mass in segment 6, well-delimitated from the liver parenchima through a transonic halo.  B and C – Tumoural vascularisation is predominantly peripheral, with an anarchical disposition, origi 


nated from a lot of vascular pedicles \(Colour Doppler and Bflow, respectively   Fig 2  A- Grey scale: tumoural mass, encefaloid, homogeneous, hyperechoic, developed on a liver with inhomogeneous structure and irregular contour.  B and C – Tumoural angioarchitectural modell : increased, anarchical vascularisation, originated from a lot of vascular pedicles \(Colour Doppler and Power Doppler, respectively  Quantitative analysis of the raising vascular signal after contrast-enhanced administration and kinetic vascular studies allow the differentiation benign/ malignant tumours with similar results to contrast-enhanced CT [9  th e m e a s u r e o f t h e a n g i ogenesis extent by the type of the tumour, the metastasis potential of the lesion and the efficacy of the treatment   Fig 3. Hypervascular HCC \(gray scale US, power Doppler 3D reconstruction and pulse inversion imaging  Using contrast-enhanced agents US is more sensitive in angiogenesis detection and depicts vascularity on the scarring tissue for diagnosing the local relapse [10,11,12  T h e  m e chanism of action of microbubbles is related to its main acoustic property: to be many times more reflective than blood, thus improving the amplitude of Doppler signals up to 20±25 dB. In experimental studies microbubbles have been able to detect flow velocities of 2 cm/s or less in a phantom tube of 200 mm in diameter [14,15  H o w e v e r  th i s v e l o ci t y i s l a r g el y  o v er th e upper limit of human capillary flow \(0.03±0.08 cm/s\ [1  whose assessment remains  therefore unfeasible with the presently available technology   Figure 4  HCC- intratumoural vascularization at Doppler US  Pulse inversion imaging and harmonic techniques with contrast-enhanced agents raise the accuracy of angiogenesis evaluation [17  I n te r m it te n t U S allo w s to in d i r e c tly as s e s c a p ill a r y  


blood flow and to quantify functional parameters of the tumour vascularization. Recently has been developed intermittent contrast-enhanced US which is able to quantify tumour neovascularization [18    All these studies show that there is a huge interest in the development of new US techniques to detect tumour angiogenesis. A non-invasive imaging technique that could identify tumour blood flow would represent a valuable method for depiction the functional tumour status and therapy response. The progress in oncological treatment involves new strategies tumour angiogenesis inhibitors. US would have an important role in following-up the therapeutic response. The change of tumour vascularization has more accuracy than tumour growth because of its irregular form IV.  Mathematical modelling of angiogenesis Mathematical modelling of various aspects of tumour angiogenesis is important both for the understanding of the process and for the development of intelligent diagnosis and prognosis systems, but it has some difficulties. The number of parameters that can be determined and have informational content is very large, and the processes involved are not fully known or understood. The difficulty to reliably forecast the risk of cancer metastasis for individual patients stems from the fact that cancer is the result of a complex interplay between numerous factors, namely: cellular parameters–altered rates of cell proliferation, apoptosis, migration, adhesion, metabolism and mutation and microenvironmental parameters–extracellular matrix ECM\ composition, angiogenesis, inflammation and proteases Tumour-induced angiogenesis provides the crucial link between the avascular phase of solid tumour growth and the more harmful vascular phase, wherein the tumour invades the surrounding host tissue and blood system [19  H o w e ve r  t h e s e  apparently insidious features of tumour-induced angiogenesis are now being used to combat cancer growth and the clinical importance of angiogenesis as a prognostic tool is now wellrecognised [20  A n ti a n g i o g en es i s s t r a t e g i es ar e al s o b e i n g  developed as a potentially powerful, non-invasive weapon against the spread of cancer [21   Over the last decade, many mathematical models of tumor growth, both temporal and spatio-temporal, have appeared in the research literature. The results of numerical simulations provided successfully the structure and morphology of capillary networks and have been also used to examine some control strategies by therapeutical intervention. Partial differential equation modelling was first applied in tumour-induced angiogenesis by Balding and McElwain n d de v e l o pe d by Ch a p lain and Sleeman [23  w h o s t u d i ed th e co n cen tr at i o n p r o f i l e s  of the tumour angiogenic factors \(TAF Much of the experimental data that exist on the growth kinetics of avascular tumors have been integrated into mathematical models using various growth laws such as Gompertzian growth, logistic growth and exponential growth, to name a few More recent studies have shown that the pattern of cap illaries depends on the interaction between the TAF profiles and local gradients of extracellular matrix components [24 I n ad d i t i o n  to continuous and deterministic models, discrete, stochastic models have also been considered [25 M o d e li n g o f th e v ital  process of tumor-induced angiogenesis and capillary network formation has also been undertaken. A discrete modelling approach used the theory of random walk. The chemotactic response of the endothelial cells to TAF and the haptotactic response to the extracellular matrix are modelled through functions which assign directional probabilities for the movement of endothelial cells [26  D e te r m i n is t i c  r e ac tio n d i f f u s i o n e q u a tions have been used to model the spatial spread of tumors both at an early stage in its growth and at the later invasive stage Typical solutions observed in all these models appear as invading traveling waves of cancer cells. The studies developed so far could only track the movement of the endothelial cells and estimated where they migrate and how fast they do this. Some of these  models have studied the tumour growth before it becomes invasive or during the early stages of invasion [27  o t h ers analyze the stages in tumour development [28  S e v e r a l models are based on the spheroid model or other related models to analyze the dynamics of antibody-drug therapy. These models consider the diffusion of an antibodydrug into the tumour mass followed by the binding of the antibody to the tumour cell, and subsequent internalization of the antibody-drug complex. However, these models study the dynamics of an individual tumour without considering the effect of other tumours growing simultaneously in the body, i.e. the dynamics of the process as a whole is not considered. Therefore, although these models may be mathematically valid, they are difficult to test experimentally and, consequently, of limited impact. The potential impact of the mathematical modeling of angiogenesis is the possibility for the data to be applied for other tumours the improvement of the diagnosis and  monitorization in a fieldwith high morbidity and mortality, the reduction of the medical care expenses V.  Conclusions Mathematical models might be used to investigate promising US techniques for an in vivo, non-invasive, globally quantification of tumour’s morphological and functional changes Because of the complex cancer physiopathology the cancer research needs a multidisciplinary and complex aproach with a central role for computational models. These models will allows us to understand the impact of the spacial and temporal model of angiogenesis on efficacy of cancer therapy. The algoritms of these processes might apply in experimental and clinical research \(the treatment’s results prediction\ and virtual trials for pharmaceutical industry Vascular imaging makes it possible to quantify the number and spacing of blood vessels, measure blood flow and vascular permeability, and analyze changes in blood vessel walls. Imaging methods also have potential utility in assessing the efficacy of angiogenesis inhibitors used in the treatment of cancer  The potential broad applicability of the US techniques makes it possible to explore the range of the morphological variability of vasculature that can be produced in nature, thus increasing its diagnostic importance in cancer research   


R EFERENCES  1  El-Serag HB, Davila JA, Petersen NJ, et al. The continuing increase in the incidence of hepatocellular carcinoma in the United States: An update Ann Intern Med 2003;139:817–23 2  Schor AM, Schor SL. Tumor angiogenesis J Pathol 1983;141:385±413 3  Folkman J. Tumor angiogenesis Adv Cancer Res 1985;43:175±202 4  Roncalli M, Roz E, Coggi G, Di Rocco MG, Bossi P, Minola E, et al The vascular profile of regenerative and dysplastic nodules of the cirrhotic liver: implication for diagnosis and classification Hepatology  1999;30:1174±1178 5  K.J. Niermann, A.C. Fleischer, E.F. Donnelly et al. “Sonographic depiction of changes of tumor vascularity in response to various therapies”, Ultrasound Q 2005;21:61-67 6  J.M. Rubin, “Flow quantification”, Eur Radiol 1999;9 :S368-371 7  Rubin JM, Bude RO, Carson PL, Bree RL, Adler RS. Power Doppler US: a potentially useful alternative to mean frequency-based color Doppler sonography. Radiology 1994;190:853±856 8  Imamura M, Shiratori Y, Shiina S, Sato S, Obi S, Okudaira T, et al Power Doppler sonography for hepatocellular carcinoma: factors affecting the power Doppler signals of the tumors. Liver 1998;18:427±433 9  T. Albrecht, J. Hohmann, “Ultrasound contrast agents” Radiologe 2003;43:793-804   Wang Z, Tang J, An L, Wang W, Luo Y, Li J, Xu J  Contrast-enhanced ultrasonography for assessment of tumor vascularity in hepatocellular carcinoma.J Ultrasound Med. 2007;26:757-62   S ftoiu A, Ciurea T, Bani M, Georgescu C, Com nescu V, Rogoveanu I, Gorunescu F, Georgescu I. Immunohistochemical assessment of angiogenesis in primary hepatocellular carcinoma.Rom J Gastroenterol. 2004 Mar;13\(1\:3-8   D Cosgrove. Angiogenesis imaging – ultrasound. Br. J. Radiol., December 1, 2003; 76\(suppl_1\: S43 - S49   Tanaka S, Arii S  Current status and perspective of antiangiogenic therapy for cancer: hepatocellular carcinoma. Int J Clin Oncol. 2006;11:82-9   M.J. Blomley, P.S. Sidhu, D.O. Cosgrove et al. “Do different types of liver lesions differ in their uptake of the microbubble contrast agent SH U 508A in the late liver phase? Early experience”, Radiology 2001;220:661-667   Hindle AJ, Perkins AC. A perfusion phantom for the evaluation of ultrasound contrast agents. Ultrasound Med Biol 1994;20:309±314 16  Bollinger A, Putti P, Barras JP, Trachsler H, Siegenthaler W. Red blood cells velocity in nailfold capillaries of men, measured by a television microscopic technique. Microvasc Res 1974;7:61±72 17  A. Hochmuth, M. Fleck, P. Hauff, et al. ”First experiences in using a new ultrasound mode and ultrasound contrast agent in the diagnosis of blunt renal trauma: a feasibility study in an animal model Invest  Radiol  2000; 35:205-211 18  M. Krix, F. Kiessling, S. Vosseler et al. “Sensitive noninvasive monitoring of tumor perfusion during antiangiogenic therapy by intermittent bolus-contrast power Doppler sonography”, Cancer Research 2003; 63 8264-8270 19  M.A. Chaplain, A.R. Anderson, “Mathematical modelling, simulation and prediction of tumour-induced angiogenesis” Invasion Metastasis 1996;16:222-234 20  G. Gasparini, A.L. Harris, “Clinical importance of the determination of tumor angiogenesis in breast carcinoma: much more than a new prognostic tool” J Clin Oncol. 1995;13:765-782 21  A.L. Harris, “Antiangiogenesis for cancer therapy”, Lancet 1997;349:SII13-5 22  D. Balding, D.L. McElwain, “A mathematical model of tumour-induced capillary growth”, J Theor Biol 1985;114:53-73 23  M.A. Chaplain, B.D. Sleeman, “A mathematical model for the production and secretion of tumour angiogenesis factor in tumours”,  Math Appl Med Biol 1990;7:93-108 24  M.J. Holmes, B.D. Sleeman, “A mathematical model of tumour angiogenesis incorporating cellular traction and viscoelastic effects”, J Theor Biol  2000;202:95-112 25  M.J. Plank, B.D. Sleeman, “A reinforced random walk model of tumour angiogenesis and anti-angiogenic strategies” Math Appl Med Biol 2003;20:135-181 26  C.J. Mode, B.D. Sleeman, “An algorithmic synthesis of the deterministic and stochastic paradigms via computer intensive methods” Math Biosci 2002;180:115-126 27  P.R. Colville-Nash, D.A. Willoughby, “Growth factors in angiogenesis:current interest and therapeutic potential”,  Molecular Medicine Today 1997, 3:14-23 28  D. Fukumura, R. Xavier, T. Sugiura et al. Tumor induction of VEGF promoter activity in stromal cells”, Cell 1998, 94:715-725  


event itself but this destabilizing effect has been found to be a lesser problem than the static geometric interferences and is generally treated separately The Phoenix solar arrays deploy in two stages where the center of each array is first swung away from the lander body and into position and then the array panels are deployed by sweeping out a 3600 arc around the center point The two stages of solar array deployment are illustrated in Figure 5 The driving feature of the deployment is the bottom corner of the array which is visible in the lower right of Figure 5\(d This corner sweeps out a circular arc that is below the instrument deck and at the full 1.8 m diameter of the array The result is that any rocks that either interfere directly with the path of the solar array or elevate the footpads sufficiently to cause the ground to interfere can result in partial deployment of one or both of the solar arrays An example of the solar array deployment envelope interference with a hemispherical rock is illustrated in Figure 6 In order to assess the static geometric risk a series of 1-km2 simulated rock fields are first generated in Matlab using the Golombek 1 exponential model It is important to note that the risk to the lander is also a strong function of the rock height to diameter ratio due to the exponentially larger number of smaller rocks For the purpose of this analysis the rocks are again assumed to be hemispherical with a height to diameter ratio h/d  0.5 which has proven to be a good approximation of the surface and orbital observations of Martian rocks The lander is then randomly placed in these rock fields and checked for contact first contact with three lander feet is detected and the lander is reoriented accordingly and second the solar array and lander body volumes are checked for interferences to both the rocks and 0.16 0.14 0.12 l 111111 l 1 1 l 0.12 0.1  0.08 0.06 0.04 0.02 0 0 0.05 0.1 0.15 k=CFA the surface which is assumed to be locally flat Each different rock density field is analyzed in Matlab with 10,000 landing events and the results are then fit with a polynomial to give a risk curve as a function of the cumulative fractional area CFA covered by rocks The results are shown in Figure 7 for CFA's up to 300O 6 RISK ASSESSMENT RESULTS A summary and comparison of the Phoenix landing risk assessment for static and dynamic events is provided in Table 1 The data presented includes three different rock field densities or CFA's of 5\260O 10 and 15 As noted in the subtext of Table 1 the data are presented in a hierarchal sense such that any case that failed for multiple reasons is removed from the pool of remaining cases so that they are not counted more than once For instance if a landing fails due to an instability caused by a rock under a footpad it would not also be included in the failure to deploy a solar array category In examining the data presented in Figure 7 and in Table 1 it is evident that the landing risk increases markedly with increasing rock coverage It is also clear from Table 1 that the dominant component of the total tipover  rock interference risk comes from the rock interference component which typically makes up about 900o of the total risk to the lander For this reason much of the landing site selection effort has been focused on finding areas of low rock density and the metric for success is taken as the rock interference success/failure probability with the understanding that this represents the majority of the total risk 1663E-02  BDMYPY Poly BDMYPY 0.2 0.25 0.3 0.35 Figure 7 Probability of failure due to contact with a rock as a function of CFA where all contacts with the body BD or the Y/+Y solar arrays MYPY are included 6 


Table 1 Summary of static and dynamic landing risks for 1000 independent landings Item Rock Abundance 5 10 15  Unstable Landing Surface Slope 260-\260\260 0.00 0.00 Unstable Landing Rock Under Pad 0.10 0.80 1.20 Tipo6ve CAses J 10 MM 260 1 2O Rock Impacts Lander Enclosure 0.50 2.40 4.20 Ground Inhibits One Array Deploy 0.10 0.20 0.60 Rocks Inhibit One Array Deploy 0.40 4.00 8.90 Rocks Inhibit Both Array Deploy 0.00 0.00 0.00 Rock Inteferlence J 1.00 616O 13J0 ITAI Tipover Rock Interferee I 10%j1 74%1 1C490 Marginal Stability Ratio 0%&<20 0.10 0.10 0.10 Leg Stroke  85 of Crushable Limit 0.00 0.00 0.00 Load Limiter Deform  85 of Limit 0.10 0.10 0.00 Tilt to North  16 deg 0.30 0.40 0.90 Tilt to to Surface  16 deg 0.00 0.20 0.60 Stessing\247 Cases 0M50 MMO 1ASO Note Failure tvDes in hierarcha order if case meets multiole criteria and is counted in anv row above it is not counted a;aain 7 CONCLUSIONS The Phoenix lander has been modeled in both a dynamic and static sense in order to assess the level of risk to the lander for a given landing site surface composition It has been found that while there is a potential for the lander to tip over during touchdown the primary component of risk actually occurs due to the possibility that the lander will land on or near a rock large enough to either damage critical components of the lander body or to prevent one or more of its solar arrays from deploying A number of stressing cases were also identified through the static and dynamic analysis that result in reduced system margins and could possibly limit the mission science if conditions were unfavorable However overall the probability of success for Phoenix is very high and the team is looking forward to landing day on May 25 2008 8 ACKNOWLEDGMENTS The author wishes to acknowledge the hard work and dedication of the Lockheed Martin team that was instrumental in developing and performing many of the dynamic analyses reported in this paper and provided a number of the figures In particular the contributions of John Bruce and Tim Gasparrini were invaluable and were very much appreciated Special thanks also to everyone on the Phoenix team for their tireless efforts in putting it all together and making it work If it was easy then everyone would do it REFERENCES 1 Matthew P Golombek et al Rock size-frequency distributions on Mars and implications for Mars Exploration Rover landing safety and operations J Geophysical Research 108\(E12 Dec 25 2003 pp ROV27-1-23 BIOGRAPHY Douglas Adams is a senior member of the engineering staff in the Spacecraft Structures and Dynamics Group at NASA's Jet Propulsion Laboratory in Pasadena California He joined JPL after receiving his Ph.D in Aeronautics and Astronautics from Purdue University in May of 2001 His background includes work in structures structural dynamics mechanics of materials fracture mechanics composite materials as well as spacecraft attitude dynamics and control During his tenure at JPL he has worked on numerous programs including the Mars Exploration Rovers MER Terrestrial Planet Finder TPF MARSIS SHARAD Hydros and Aquarius In his most recent experience he worked as the Entry Descent and Landing EDL Mechanical Systems Engineer for the Phoenix spacecraft currently en route to Mars and he is presently engaged as the Mars Science Laboratory MSL Parachute Cognizant Engineer 7 


from the FPGA via UDP packets over a direct gigabit Ethern et connection to a PC running a Matlab acquisition program All seemed to work 002ne until we either decreased the decimation thus increasing the data rate over Ethernet or ran long acquisition sessions The ADC input was a sine wave coming from a function generator Looking at the data collected with Matlab we could see that points were being dropped from the sine wave that we fed into the ADC Checking the data rate over Ethernet with a packet sniffer it was observed that the peak rate was only 100 Mbps even though the bandwidth of the connection was 1Gbps But even at decimation rates that could be handled with a 100 Mbps throughput data points were being dropped sooner or later in the acquisition The reason for the lower-than-expected throughput is most likely a combination of the overhead of packetizing the data into UDP packets and computing checksums and the underlying implementation of the IP stack that we used in our system We relied on lwIP Lightweight TCP/IP Stack distributed by Xilinx and designed by Adam Dunkels Swedish Institute of Computer Science to pro vide the dri v ers necessary for UDP communication However as suggested by many user forums it may not run at its full potential on the embedded processor in Xilinx FPGAs Furthermore the receiving PC running a Matlab acquisition program can also be slowing down the communication causing the input rate into the AD7760 controller core FIFO to exceed the output rate Due to the issues experienced on longer acquisition runs using UDP over Ethernet to facilitate FPGA data of\003oad we decided to record a 002xed amount of digitized data directly to a compact 003ash card connected to the development board This method has the bene\002t of easing the load on the CPU as all it needs to do is read the AD7760 controller core FIFO and store that data into external RAM When a speci\002ed amount of data is present in external RAM the CPU stops data acquisition and writes the collected samples to the compact 003ash card Of course the drawback is that we no longer have a 223real-time\224 data acquisition system Furthermore the Xilinx drivers provided for accessing the compact 003ash card are very slow in writing data to a FAT 002lesystem Nevertheless with this method clean and long data captures became possible Synchronization was the last crucial point to check For an FTS synchronization between the signal beam and a reference channel are absolutely critical in order to obtain meaningful data To check for good synchronization in our dualchannel system we simply plotted the data acquired from both channels which comes from the same function generator against each other in order to observe a 1:1 ratio If the signals are not synchronized we would see various patterns or missing points in an otherwise diagonal line passing through the origin 5 M K IV D ATA A CQUISITION To ensure that the AD7760 meets all the requirements of the FTIR data acquisition we have recorded solar interferograms with an existing instrument the JPL MkIV spectrometer designed for stratospheric balloon observations of sunset and sunrise The MkIV optical laboratory includes a coelostat that brings sunlight to the spectrometer for ground-based tests and measurements This allowed us to perform an end-to-end test of our recording system including full veri\002cation of the synchronization between the two ADC channels one for the reference laser and one for the IR signal beam In our lab setup shown in Figure 8\(a we have connected the data acquisition system to the MkIV spectrometer Our FPGA development board Xilinx ML507 has enough I/O to accommodate collecting data from two AD7760 evaluation boards As shown in Figure 8\(b we connect these boards to the output of InSb and reference laser channels Control of the data acquisition process is administered via an RS232 link to a lab computer a acquisition system with the JPL MkIV spectrometer b chain setup showing FPGA and AD7760 boards F igure 8  MkIV data acquisition An interferometer produces an output in the form of a DC term plus AC modulation the signal never goes negative since the lowest possible value is that of total darkness at zero volts It is important to avoid AC coupling and preserve the DC term because the low frequency variations of this DC 8 


term can be used to mitigate the effect of source brightness 003 uctuations Ho we v er  unless special care is tak en this would effectively result in the loss of one bit of ADC precision since no negative numbers would ever be recorded In the case of MkIV the noon-time IR DC term is 0.5 V with a peak AC value of 0.85 V The circuit of Figure 9 maps the MkIV values to the input range of 2.5 V to 2.5 V of the AD7760 With this level-shifting circuit total darkness will be at the negative limit of the ADC the noon-time DC term will be close to 0 volts and the peak interferogram value will use about 2/3 of the positive ADC range This allows us to use most of the dynamic range of the ADC while avoiding any risk of clipping The data-handling software can easily shift the signal back to its all-positive range by adding 2 23 to the recorded values This circuit also provides a differential input and generates the differential outputs needed by the AD7760 this con\002guration has the advantage of being insensitive to common-mode noise G=5 G=1 G=1 2.5 V   Vout VoutVin  Figure 9   Differential ampli\002er for MkIV IR signal beam Figure 10 shows the interferogram centerburst at the zeropath difference ZPD where light from the two interferometer arms interfere constructively at all wavelengths This run was recorded near solar noon and the DC term is correctly mapped to approximately zero ADC count DN digital number The minimum and maximum peaks use about 65 of the dynamic range of the ADC which is 2 23  8  388  608  6e+06 4e+06 2e+06 0 2e+06 4e+06 6e+06 150000 151000 152000 153000 154000 155000 156000 157000 158000 ADC output \(DN Point Index Figure 10   Interferogram centerburst showing ZPD at solar noon We have recorded four spectra with the AD7760 system two near local noon and two in the afternoon A small section of these spectra is shown in Figure 11 The sharp feature in the center of the plot is due to absorption by HF which is of anthropogenic origin 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 4038 4038.5 4039 4039.5 4040 Arbitrary units Wavenumber \(cm-1 HF Figure 11  Four spectra recorded by our V5FXT/AD7760 system The top two traces are consecutive runs near solar noon The bottom two traces taken in mid-afternoon The interferogram sampling frequency was 40 kHz and the reference laser was at 10 kHz resulting in 4 points per laser fringe oversampling factor of 2 Each scan took about 95 seconds to record and 3.8 M points were saved for each channel laser and IR The re-sampling step converted the IR data from the time domain to the path difference domain This includes a digital 002lter which allowed us to decimate the data down to 940 k points The maximum path difference was 57 cm providing a spectral resolution of 0.01 cm 000 1  Simultaneously with the AD7760 the internal MkIV signal chains recorded interferograms by sampling the IR channels on the zero crossings of the reference laser This is the standard method used previously for all MkIV 002eld campaigns this produces data which are already in the path difference domain Because of the external sampling trigger the zero crossing method requires elaborate auto-ranging ADC modules which have fewer bits of precision than delta-sigma ADCs the MkIV instrument uses 18-bit modules Furthermore these modules are hard to adapt to the higher speeds required for satellite instruments Figure 12 compares the data recorded simultaneously by the two systems For this Figure we have averaged the two scans taken at solar noon The signal-to-noise ratio of the AD7760 runs is about 260 which is higher than the MkIV S/N of about 200 We expect to get even better results from the AD7760 when it is properly packaged inside the interferometer enclosure The HF absorption feature provides a stringent test of the system because it is very narrow and it is located near the highfrequency end of the spectrum where the sampling quality is 9 


most critical As can be seen in Figure 12 there are no lines hape distortions and white noise dominates the difference between the AD7760 and the standard MkIV spectra 1 0 1 2 3 4 5 4038 4038.5 4039 4039.5 4040 Arbitrary units Wavenumber \(cm-1 AD7760 MkIV diff10 HF Figure 12   Comparison of AD7760 and MkIV spectra The blue trace is the difference multiplied by 10 6 C ONCLUSIONS AND F UTURE W ORK This research task now in its third year has brought FTIR spectrometry on hybrid-FPGAs closer to becoming applicable on proposed NASA missions This past year we have demonstrated signi\002cant performance gains by porting our designs to the Virtex-5 FXT FPGA which is on the path to a radiation hardened by design implementation Additionally we have demonstrated successful integration with an analog frontend AD7760 in a MATMOS-relevant environment using the MkIV interferometer to capture real solar spectra and producing interferograms that have a high signal-to-noise ratio The next step is designing a printed circuit board hosting the AD7760 in order to move away from using the EVALAD7760 board which has signi\002cant errors Additionally there is still much work left in streamlining our data acquisition architecture eventually including the FTIR processing in the same system that captures the solar spectra The goal is to capture and process data in real time as it is provided by the instrument A high priority is also redesigning the time-consuming re-sampling portion of FTIR processing This would involve moving this step partially into the hardware and taking advantage of embedded bock-RAM cells in the FPGA A second embedded processor will likely also be invoked in our future work in order to divide the data processing tasks and further reduce execution time A CKNOWLEDGMENTS We would like to thank Jess Landeros for his considerable technical assistance The research described in this paper was carried out at the Jet Propulsion Laboratory California Institute of Technology under a contract with the National Aeronautics and Space Administration R EFERENCES  D L Bekk er  M Luk o wiak M Shaaban J.-F  L Blavier and P J Pingree 223A Hybrid-FPGA System for On-Board Data Processing Targeting the MATMOS FTIR Instrument,\224 Aerospace Conference 2008 IEEE  pp 1\22615 March 2008  J J F ab ula 223Xilinx Programs Re vie w  224 in The First Workshop on Fault-Tolerant Spaceborne Computing Employing New Technologies  Sandia National Laboratories Albuquerque NM May 2008  G C T oon 223The JPL MkIV interferometer  224 Optics and Photonics News  vol 2 pp 19\22621 1991  P  J Pingree J.-F  L Bla vier  G C T oon and D L Bekker 223An FPGA/SoC Approach to On-Board Data Processing Enabling New Mars Science with Smart Payloads,\224 Aerospace Conference 2007 IEEE  pp 1\226 12 March 2007  J W  Brault 223Ne w approach to high-precision Fourier transform spectrometer d esign,\224 Applied Optics  vol 35 no 16 pp 2891\2262896 1996  J C Brasunas and G M Cushman 223Uniform timesampling Fourier transform spectroscopy,\224 Applied Optics  vol 36 no 10 pp 2206\2262210 1997  S I Feldman D M Gay  M W  Maimone and N L Schryer 223A Fortran-to-C Converter,\224 AT&T Bell Laboratories Murray Hill NJ Computing Science Technical Report 149 1995  D L Bekk er  223Hardw are and Softw are Optimization of Fourier Transform Infrared Spectrometry on HybridFPGAs,\224 Master's thesis Rochester Institute of Technology August 2007  223IBM Po werPC Embedded Processor Performance Libraries,\224 IBM Microelectronics Division Hopewell Junction NY Technical Report 2003  C Abramson D Isaacs and A Ansari 223Embedded Processing Innovations with Virtex-5 FXT Devices,\224 Xcell Journal  vol Q2 pp 8\22613 2008 11 Virtex-5 APU Floating Point Unit v1.0  Xilinx Inc San Jose CA May 2008 12 AD7760 2.5 MSPS 24-Bit 100 dB Sigma-Delta ADC with On-Chip Buffer  Analog Devices Norwood MA August 2006 13 Evaluation Board for AD7760/AD7762/AD7763 using Black\002n ADSP-BF537 EZ-KIT Lite  Analog Devices Norwood MA August 2006  A Dunk els 223The l wIP TCP/IP stack 224 http://www.sics.se/\230 adam/lwip/documentation.html Swedish Institute of Computer Science 2004  G K eppel-Aleks G C T oon P  O W ennber g and N M Deutscher 223Reducing the impact of source brightness 003uctuations on spectra obtained by Fourier10 


transform spectrometry,\224 A pplied Optics  vol 46 no 21 pp 4774\2264779 2007 B IOGRAPHY Dmitriy Bekker r eceived his M.S and B.S degrees in Computer Engineering from Rochester Institute of Technology in 2007 He has been at JPL as a summer student in 2006 and now is a full time employee since February 2008 in the Instrument Software and Science Data Systems section His areas of interest include FPGAs embedded systems digital signal processing and system architecture He has co-op and work experience at Draper Laboratory NASA Dryden Flight Research Center Syracuse Research Corporation and Brookhaven National Laboratory He is a member of IEEE Dr Jean-Francois Blavier 002 rst joined the JPL-MkIV Team in August 1985 as a contractor from Ball Aerospace He participated in the MkIV campaigns in McMurdo Antarctica ground-based and from Punta Arenas Chile NASA DC8 In late 1987 he started graduate work with Profs Delbouille and Dubois at the University of Li 036 ege Belgium His research tasks included installing the Fourier transform spectrometers at the International Scienti\002c Station of the Jungfraujoch Switzerland for atmospheric measurements and at the Institute of Astrophysics in Li 036 ege for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engineer and participated in all the MkIV campaigns since then one DC-8 campaign 20 balloon campaigns Dr J.-F Blavier obtained his Ph.D in Physics from the University of Li 036 ege in July 1998 Dr Geoffrey Toon  after receiving his B.A degree in Physics at Oxford University in 1978 obtained a D Phil in Atmospheric Physics in 1984 also from Oxford University He then came to JPL as an NRC post-doctoral Researcher and worked on the assembly and testing of the JPL MkIV interferometer and on analysis of ATMOS Spacelab-3 data Since becoming a JPL employee in 1986 he has worked almost exclusively on the MkIV project becoming the Principal Investigator in 1988 This work has earned seven NASA Achievement Awards and has resulted in more than 100 peer-reviewed journal articles Dr Christian Servais 002 rst joined the Institute of Astrophysics at the University of Li 036 ege in 1982 designing a digital 002lter for a prototype Fourier transform infrared spectrometer installed at the high altitude international scienti\002c station of the Jungfraujoch Switzerland In April 1984 he moved to the chemistry department of the University of Li 036 ege and developed time-of-\003ight and Photoion-Photoelectron coincidence experiments for his PhD thesis that he obtained in September 1994 He then returned to the Institute of Astrophysics were he has been since overseeing all experimental developments at the Laboratory of Atmospheric and Solar Physics located at the Jungfraujoch He is now specially involved in the design of improved Fourier transform spectrometer acquisition chains and remotely controlled hardware adapted to harsh environmental conditions 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 



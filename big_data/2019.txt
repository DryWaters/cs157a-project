Discovering Relational Patterns across Multiple Databases Xingquan Zhu"3 and Xindong Wu2 Dept of Computer Science  Eng Florida Atlantic University Boca Raton FL 33431 USA 2Dept of Computer Science University of Vermont Burlington VT 05405 USA 3Graduate University Chinese Academy of Sciences Beijing 100080 China xgzhu@cse.fau.edu xwu@cs.uvm.edu Relational patterns across multiple databases can reveal special The problem of finding global patterns is surely important in pattern relationships hidden inside data collections Existing reality as it reveals knowledge which is unavailable from each research in data mining has made significant efforts in single database point of view There is however another discovering different types of patterns from single or multiple problem involved in pattern mining from multiple databases databases but how to find patterns that have a higher support 
in discovering relational patterns and their relationships across database A than in database B with a given support threshold UX is databases Taking a retail store with two branches A and B as an still an open problem We propose in this paper DRAMA a example if a store manager were organizing data from these two systematic framework for Discovering Relational patterns Across branches for intelligent analysis he/she may easily raise concerns Multiple dAtabases More specifically given a series of data like 1 what are the frequent patterns in both A and B i.e A  collections we try to discover patterns from different databases ux  B  ux where Ux is the threshold 
in finding frequent with patterns relationships satisfying the user specified patterns and A  ux means that a pattern's support value in constraints Our method seeks to build a Hybrid Frequent Pattern database A should be no less than the value u 2 what are the tree HFP-tree from multiple databases and mine patterns from frequent patterns which appear more often in A than in B i.e A  the HFP-tree by integrating users constraints into the pattern B  u and 3 what are the patterns whose support differences in mining process these two stores are no less than the value a i.e IA-BI 2 a There are possibly many other concerns in this regard but unfortunately 1 Introduction no systematic solution has been proposed to address this issue in an effective way such that the 
discovered relational patterns can Many real-world applications involve the collection and 
management  multiple databases.Examplesincludemarke be used to support efficient and effective data and knowledge management of multiple databases Examples include market magent basket transaction data from different branches of a whole sale management store data collections of a particular branch in different time In reality when users are exposed to the data collected from periods census data of different states in a particular year and multiple sources it is a natural sense to refer to a contrast study data of a certain state in different years For years knowledge for knowledge and pattern discovery Examples include national discovery and data mining also referred to as KDD 1-2 has census data analysis 
network intrusion detection and molecular been proven to be an effective tool to search for novel and genetic data analysis We list here two motivating examples actionable patterns and relationships that exist in the data When Example 1 Considering a data expert who is interested in patterns take the form of association rules existing research in studying residents of north eastern states of America i.e the so the area has made significant efforts in discovering patterns called New England area including the states of Connecticut frequent itemsets closed patterns or sequential patterns from CT Maine ME Massachusettes MA New Hampshire NH different types of data environments with solutions roughly fall Rhode Island RI and Vermont VT this expert may be also into the following three categories 1 
finding patterns from a interested in finding the similarity/differences between residents single large volume database 2 finding patterns from multiple in this area and the residents on the West Coast say California databases and 3 finding patterns from continuous data streams CA For these purposes the following queries are likely to be The essential goal is to enhance mining algorithms such that they raised by the expert can scale up well to large volumes of centralized distributed or continuous data Query 1 Finding patterns that are frequent with a support level of c  in all of the New England states but significantly infrequent To find patterns from multiple databases a common concern is to with support level of  in California i.e CT ux  ME ux  discover knowledge which 
does not exist unless one unifies all MA x  NH x  RI x  VT o  CA  P data collections into a single view For this purpose existing Query 2 Finding patters that are frequent with a support level of research has been mainly targeted to discovering global patterns in the New England area w r t all states i.e with assistance of a local data mining process Collective data t\(CTinMeMNew England a w l s mining 3 is one of the most representative efforts in the area CT+ME+MA+NH+RI+VT  u with the objective of unambiguous local analysis that can be used Query 3 Finding patterns that 
are frequent with 
a support level of as a building 
block for generating the correct global results A 
a in all New England States but with their supports declining common practice is to conduct data mining on each single from northern to southern states i.e ME  NH VT  MA  database and then forward promising meta patterns to a central CT RI  ux place for analysis 4 Example 2 Recent development in microbiology and ___________________________________bioinformatics has made it possible to extract gene expression  This data for molecular genetic analysis One of the most import Thsresearch has been supported by the US National Science apiain st s uhgn xrsindt o eei Foundation NSF under Grant No CCF-05 14819 and the National diesprfln,orxa l,thmlcurcnerlsiiain Science Foundation of China NSFC under Grant No.60674 109 dsaepoilg o xml,temlclrcne lsllao 1 4244-0803-2/07/$20.00 251C2007 IEEE 726 


5 In order to detect signature patterns for Leukemia say Acute one has to list all the candidates if he/she does intend to do so Myeloid Leukemia AML and Acute Lymphoblastic Leukemia Therefore PPM will concurrently mine patterns from all other ALL a microbiologist can split the underling data into four parts CT ME  and VT and then pass on the patterns to CA to datasets with D1 containing gene expression data of normal verify whether they satisfy CA  P tissues D2 containing data of AML tissues D3 containing all ALL tissues and D4 containing all other cancer tissues Queries of the Both SPV and PPM rely on the results discovered from a single following types can then be used to capture the signature patterns database for pattern verification where the mining process for cancer classification candidate generation and pruning at each single site does not consider the existence of other databases at all unless the Query 1 Finding the patterns thatare frequen wt a sut patters were forwarded to other databases for verification As level of i t in either of the cancer datasets D2 D3 or D4 but are we will discuss later this single database based framework will significantly infrequent in D1 i.e D2 D3 D4    D1  forbid both SPV and PPM from answering some complex queries f3 However this disadvantage can be overcome by CPM which Query 2 Finding the patterns that are frequent with a support unifies all databases in the query into one view for candidate level of x in all cancer datasets but with support in Leukemia generation and verification The theme of CPM is to generate tissues higher than other cancers tissues i.e D2 D3  D4   length candidates from each single database with all candidates forwarded to a central place for candidate justification such that There are many other applications aside from the above two only candidates satisfying certain conditions are redispatched to examples that users will have to deal with data from different each database for the next round of pattern growing length-/+i sources In addition it is often the case that users know some This procedure repeats until no more candidates can be further basic features of these data collections such as the date and time generated each database was collected or the region or entity each database All the three methods above can somewhat fulfill the goal of may represent What remains unclear is the relationship of the finding relational patterns across multiple databases although not patterns hidden across multiple data collections As a result the necessarily for all types of queries For example SPV and PPM needs of comparing patterns from different datasets and cannot possibly answer Query 2 in Example 1 Because a patter understanding their relationships are emerging For example the satisfying CTHMEMA HANH-RI-VT  u can take any support store managers may want to find gradually increasing shopping value in each single database For example if a patten's support patterns of their customers in a certain period of time or a  microbiologist may want to find patterns of the diseases along an wa 0 in CT ME MA If n I u nV,i ol tl evolving order For these purposes discovering relational satisfy the query To find such patterns SPV and PPM have to evoling rder Forthes puroses disoverng rlatinal list all possible candidates by setting each database's threshold patterns across multiple databases can be a very important part of v all tossich isatesn\(by ginfeachbdatabase's theshold the KDD process Although well motivated the solution to this value to 0 which is technically infeasible In fact the most end however requires an efficient mechanism for complex serious disadvantage of all these three methods lies in the fact quering and mining on multiple databases that they are all Apriori-based where pattern generation and database rescanning for verification will significantly reduce their 2 Simple Solutions and Challenges speed in finding relational patterns It is commonly recognized that database rescanning for pattern verification could be very In a naive sense the problem of discovering relational patterns time consuming especially when the underlying data volumes across multiple databases can be solved by three simple solutons are large Therefore we need a fundamentally different design 1 Sequential Pattern Verification SPV 2 Parallel Pattern which should take the following concerns into consideration in Mining PPM and 3 Collaborative Pattern Mining CPM discovering relational patterns SPV starts pattern mining from a seed database which can be a 1 Being able to unify all databases in the query to fulfill the subset of a database in the query and then passes on the pattern discovery process In other words conducting discovered patterns to the second database for verification Such pattern mining from a single database without considering a sequential process repeats until patterns have been verified by all other databases is not an option for us all the databases involved in the query For example to answer Query 1 in Example 1 SPV may start from the CT database to 2 Being able to meet all queries listed in the above two find frequent patterns then pass on patterns to database ME to examples In Section 4 we will formally define our find patterns frequent in both CT and ME Any patterns which do problem and queries which should also be addressed by not satisfy the query will be pruned out immediately This our solutions process repeats until all the databases in the query have verified 3 Being able to scale well to large data volumes and can be the pattern easily extended to discover other types of relational Instead of verifying patterns in a sequential way PPM patterns other than frequent itemsets concurrently discovers patterns from each single database and In this paper we take the above concerns into consideration and then forwards all frequent patterns from each single database point of view to a central place to find the ones which satisfy the proposeea brid atte HFP base sution Our method seeks to build a single HFP-tree for each query where query constraints For example to answer Query 1 in Example 1 ptengerioadvrfctonufyheneligdtbss PPM concurrently discovers patterns from each single database t pe ptepuigpoes xeietlcmaiosfo CT ME  and VT and then checks whether a pattern satisfies bt ytei n elwrddtbsswl eosrt htti the query or not One should be aware that it is technically faeokcnsgiiatyehnetesedi idn infeasible to find patterns which satisfy CA fD by using database relational patterns where the improvement canl be as much as CA only because no deterministic pruning rules will hold and over 100 times better than simple solutions 1 4244-0803-2/07/$20.00 251C2007 IEEE 727 


3 Related Work of such a query must explicitly specify one single database and its corresponding threshold value Their method however cannot The problem of handling data from multiple databases is a answer a complex query like Queries 2 and 3 in Example 1 and nontrivial task in reality and it often raises concerns like how to therefore its applicability is limited in reality compare or unify different parts of data to achieve a common goal Domains of applications include classification 6 frequent Table 1 Two toy datasets D1 and D2 itemset mining 7-8 clustering 9 and OLAP 27 For example Database D1 Database D2 Yin et al 6 have previously proposed a CrossMiner for Trans ID IItems Trans ID Tttems classification from multiple databases The problem of 1 a b d 1 c f g association rule mining from distributed databases has also been 2 la b d 2 a b d g well studied 10-14 where count distribution data distribution 3 a b c d 3 a b c and candidate distribution are three basic mechanisms for 4 la c d g 4 la b d 4_ la c ed  g____4 la __b __d effective mining from multiple databases 14 However among 5 lb d f 5 la c all these research activities the focus has typically been on 6 la b d g 6 le c d mining a single database whether it is distributed or centralized 7 le f d 7 a c d f gi with the objective of unifying patterns discovered from each 8 la b c e g _ single database into new knowledge and patterns In comparison 4 Problem Definition our research focuses on finding patterns and their relationships across multiple databases A pattern P discussed in this paper takes the form as an itemset When the underlying data involve multiple distributed i.e a set of items which satisfy the user specified constraint\(s centralized sources one of the most important tasks is to assess The support of the pattern P in database D denoted by Sup P the similarity between the datasets such that the structural represents the ratio between the number of appearances of P in D information among the databases can be provided for analysis and the total transaction number in D Unless specified otherwise such as clustering 15 and 16 have previously addressed the we always use this ratio to denote a pattern's support problem of database similarity assessment by comparing association rules from each component database e.g how many The users constraints specify the patterns they intend to discover of those rules are identical and what are the numbers of instances from the database For example a user can specify D  a to covered by those identical rules In comparison we are interested indicate that he/she is intending to find patterns from database D in finding patterns across multiple databases with all qualified patterns support larger than the given threshold Tr A user can specify multiple databases in their constraints for The importance of finding differences between databases has example A  B  a which indicates a pattern with its support been noticed by many researchers in the area 17-20 with the values in A and B both larger than u and in addition a pattern's main focus on exploring differences between two databases at a support in A should be larger than its support in B In this paper time Webb et al 18 proposed a rule based method to explore a wepdefine thollogtw types ofpreltinshIp tors anfr contrast    se betwee tw daaae.J ta 0 aepooe we define the following two types of relationship factors and four contrast set between two databases Ji et al 20 have proposed operators to describe a user's constraints methods to explore minimal distinguishing subsequence patterns between two datasets where the patterns take the form of Relationship factors frequent in database A but significantly less frequent in  X2 oa\(X a indicates thatXis no less than a Xis larger database B i.e A  u B  f All those methods are than a interested in finding differences in terms of data items or  X  a  X a indicates that Xis no larger than a Xis less patterns between two datasets but cannot support the complex than a queries we mentioned in Example 1 in Operators The research in database queries has made significant efforts in  X  Y indicates the operation of summing up the support supporting data mining operations 21-23 with extensions of the values in both Xand Y database query languages to support mining tasks but most of  X Y indicates the operation of subtracting the support in Y these efforts focus on a single database with relatively simple from the support in X query conditions Among them the most relevant work related to  X  Y\(X Y  indicates the operation of X and Y Xor Y this research is the complex mining optimization system  Il indicates the absolute support value in X proposed by Jin and Agrawal 22 They presented an SQL-based mechanism from querying frequent patterns across multiple Notice that  directly sums up support values from participant databases with the objective of optimizing the users queries to databases The results from this operator do not reveal patterns find qualified patterns There are however essential differences support values from the union of the participant databases This between their work and what we will propose here 1 The operator is helpful when a data manager intends to find the efforts in 22 only focus on the problem of enumerating different average support of the patterns from multiple databases query plans and choosing the one with the least cost The pattern A user's query is simply the user's constraints taking the form of mining methods they adopted are actually the simple solutions as a combination of the above relationship factors and operators in we discussed in Section 2 Instead of optizing queres our  findng relaIonal patterns across multiple databases More research Will propose a data mining framework in supporting usrs qure to fin reaioa patens 2 Beas oh specifically a query should involve at least one database and one limitations of their pattern mining framework relying on each relationship factor say A  ut A query may also involve single database the solution in 22 can only answer simple multiple relationship factors and multiple operators which is queries like A  u1l   B  260\(2  C  8 i.e each element often the case in reality such as the query ME  NH VT  1 4244-0803-2/07/$20.00 251C2007 IEEE 728 


MA  CT RI  ux in Example 1 A pattem which satisfies the  a 1:0 It is obvious that z has no child so we build user's query is called a relational pattern Due to the limitation of another node z1 b 1 0 and set this node as the child of H It the pattern mining process a user's query cannot take an arbitary means that itemset ab has appeared once in D1 but 0 time in D2 form as he/she wishes instead we confine that a query must Finally we move to the third item d in T We find d is not a involve at least one relationship factor  or  with a numerical 1 threshold value immediately following this factor A query which child of the recently built node z so we build another new node complies with this confinement is called a valid query For 2 d 1:0 and set it as the child of zl Again it means that example A  B  C is not a valid query and however A  B itemset abd has appeared once in D1 but still 0 time in D2 For  C  ux is The reason we define a valid query is because any other transactions in D1 or D2 we will repeat the same without a specific threshold u it is technically infeasible to find procedure Take the third transaction in D2 T72 a b c as an all patterns satisfying A 2 B 2 Cf.3 example We first check whether Root has any child node named The procedure of discovering relational patterns across multiple a and since we have previously constructed such a node we databases is an interactive process where a user provides a query know for sure that it does exist Denoting this node by x we will and the system finds all patterns satisfying the query in an increase x's frequency count for database D2 by step 1 then we effective way In this paper we only deal with the problem of check whether x has any child node named b i.e the second item pattern discovery We assume that users queries and the of T  We increase the frequent count for D2 by step 1 if such a underlying databases are immediately available The problems of 3 effective/efficient user interactions and data privacy/security are node indeed exists otherwise we simply add a new member b not of our concern at this stage 0:1  as the child node of x We recursively repeat the above procedure until we finish the last item in T 2 The constructed 5 Hybrid Frequent Pattern Tree Construction HFP-tree for D1 and D2 is shown in Figure 1 The frequent pattern tree FP-tree 7 is a well-known data To speed up the tree transversal a header table is built for all structure in mining frequent itemsets The merits of the FP-tree items ever listed in the HFP-tree As shown in Figure 1 for a lie in the fact that it stores the set of frequent items of each clearer presentation we only list the header table for items a c e transaction in a compact structure which can avoid repeatedly and g For each item say g its list records all the locations scanning the original database during the mining process In this where g has ever appeared in the HFP-tree The purpose of the section we proposes a solution to have multiple databases joined header table is to facilitate the access of the item sets ending with together to build a single Hybrid Frequent Pattern tree HFP-tree the same item letter For example in Figure 1 if we want to find which will be used to discover relational patterns at a later stage the set ending with pattern letter c we may simply go through all Different from the traditional FP-tree which works on a single records of c's header list and at each location tracking upwards database the purpose of an HFP-tree is to find the set of frequent to the Root will produce an item set associated with item c In itemsets from transactions in all databases For this purpose Figure 2 we have listed detailed information of building an HFPchanges and extensions have been made accordingly As one of tree from multiple databases But before we go any further we'd the major changes each node of the HFP-tree takes the following like to solve a particular issue raised by multiple databases form x Y Y2  Yn where x is the name of the item stored at       Header Table HEP-Tree the current node denoted by item name and yl Y2,.,Yn are the header Tabl numbers of times that a particular itemset has appeared in databases D1 D2  D respectively Take D1 and D2 in Table 1 a 0 1-------3 as our example databases Assuming they are joining together to b-a 6 C construct an HFP-tree each node in the tree will take the form of b4---c 1 f-1 x Y1:Y2 withy1 and y2 denoting the numbers of times that the d d 1:0 Q f 0 c 0:1 itemset with items starting from the Root and ending at the e c 2 d2d1 f:0 10 1d1d current node x has appeared in databases D1 and D2 respectively f  If D1 and D2 are joining together to build a tree they must agree g e 1 0 d 1 0 with in advance the order of the items listed in the tree Here we assume D1 and D2 agreed to list their items according to the 1 0 alphabetic order we will discuss the generation of this list in Section 5.1 We also discard any threshold value at this stage Figure 1 Example of constructed HFP-tree forD1 and D2 in and therefore all items will be added into the HFP-tree Given a Table 1 transaction in D1 say Trans 1 T1l a b d where items have 5.1 Joint Ranking List been sorted according to the alphabetic order the HFP-tree In the above example we assume that all parts participating in construction will start from the first item a and check whether the HFP-tree construction use the same predefined item list the any child node of the Root has the same item_name Since we alphabetic order of the items In reality the order of the list plays know the HFP-tree is empty at this stage a is not a child of Root an important role to build a compact HFP-tree Take a dataset As a result we construct a new child node z a 1 1:0 for Root containing four transactions d c d b c d and a b c d which specifies that a iS a child of Root with a appearing once in as an example A frequent pattern tree built by using the items D1 and zero time in D2 After that we move to the second item b alphabetic order i.e a b c and d will have 10 interior nodes in T1  and check whether b is a child of the recently built node K excluding the Root On the other hand if items were previously ranked in the descending order of its frequency i.e d c b and a 1 4244-0803-2/07/$20.00 251C2007 IEEE 729 


the corresponding FP-tree will have 4 interior nodes only which j 1 M S-S R is about 60 of tree size reduction Reducing the tree size will R Z R 2 eventually lead to dramatic time saving in building the pattern M m S tree To solve the problem the original FP-tree algorithm 7 5.2 HFP-tree Construction scans the database beforehand to produce the ranking list and then use this list to build the FP-tree Figure 2 lists the algorithm details in building an HFP-tree from multiple databases D1,-.DM We assume here that each database When several databases join together to build an HFP-tree a Di comes with a minimal support threshold in determining its simple solution is to use a predefined item list to build the HFPfrequent items In the next section we will explain the details on tree This however will significantly deteriorate the system how to parse a user s query to generate such threshold values performances because any list without taking item frequency into consideration will lead to an inferior solution and eventually 6 Discovering Relational Patterns Using HFPraise the cost in tree construction For this purpose we propose a rank-join based ranking mechanism Tree Given M databases D1 D2  DM for HFP-tree construction 6.1 User Query Decomposition assume I I2  and IN are the union of the items in the databases As we have discussed in Section 4 a user's query may involve For any database Di we scan it and rank all items in Di in a multiple relationship factors and operators When submitting descending order of their frequency Denoting Rj the ranking such a complex query to the data mining model it is often the order of item Ij in database Di with the first item in the list case that not all parts of the query comply with the down closure denoted by 1 then Eq 1 will represent the average ranking property i.e the subset of a frequent itemset may also be order of each item Ij The final ranking list for all items is frequent For example the  and  relationship factors constrg R j 2,..N in an ascending order normally do not comply with the down closure property It is constructed by ranking R  j=1,2 N in an ascending order obvious that even if a pattern iB say abc does not satisfy B  where items with the least average ranking are listed at the top  but its superset say abcd may still comply with B  3 i  I M Therefore the mining process must preprocess a user's query and M Yi=1 1 explicitly decompose it into a set of subqueries which do comply The above mechanism joins the ranks of each item in all with the down closure property such that the mining model can databases together to produce the final ranking By doing so we use these subqueries to facilitate the candidate pruning process assume that databases are equally weighted and the rank in all For this purpose we list five properties here and will use these databases plays an equal role in deciding an item's final ranking properties to decompose each query before it is submitted to the In reality the size number of transactions of the databases data mining model All decomposed subquieries which comply involved in the query may vary significantly where a database with the down closure property are placed into a Down Closure containing more transactions should carry more weight in DC subset and meanwhile the original query is still kept to deciding the final ranking of a particular item For this purpose check a pattern's validity at the final stage we revise Eq 1 by taking the size of each database into Property 6.1.1 If a subquery has a single database and a consideration Assume Si is the number of transactions in Di then threshold value x listed on the left and right side of the S=Sl\261S2\261..\261Sm denotes the total number of transactions The relationship factor 2 or  respectively then this subquery weighted average ranking order is then represented in Eq 2 complies with the down closure property Input Databases D1  DM and their minimal support thresholds a am This property is based directly on the Apriori rule in frequent Output Hybrid Frequent Pattern tree HFP-tree itemset mining If a pattern P's support in a database is less than 1 Initialize an empty HFP-tree with node Root only a given threshold cc then any supersets of P the patterns growing 2 Scan each database Dl,...,DM once and calculate the ranking order of each from P will also have their support less than ux Therefore if a iteml b.,IN in each single database items with their support less than the query involves multiple databases factors 2 or  and a corresponding         qer involvesd mutil datbaes facors">"ort nd corresponding threshold are eliminated single threshold value U we may decompose this query into a set 3 Use Eq 2 to produce a joint ranking list L of subqueries with each single database and the threshold value uX 4 For each transaction 7k in Di sort items in Tk according to the list L Denote listed on the left and right sides of the factor For example the sorted Tk by tk with items in Tk denoted by I,..h query A  B  C  a can be decomposed into three subqueries 5 eRoot K A  cc  B u  and C u  and placed into the DC set It is 6 For all children x of z obvious that if a pattern P violates any one of these three a If x.item_name  I_.item_name increase the corresponding subqueries there is no way for P as well as P's any supersets to frequency count by step 1 the one corresponding to Di be a qualified pattern It is worth noting that subqueries in the DC i L x K K 1 Repeat step 5 until K=K set are merely for pattern pruning purposes and one should not b If no child of zhas item name I item name create a new node y use them to replace the original query The original query will   K  still be used to verify the patterns at the final stage as we will withy.item name IT.item name Initializey's frequency to zero discuss in the next subsection except for Dd which is set to l1 i Inserty as z child Property 6.1.2 If a subquery has the sum  of multiple ii z K K\2611  Repeat step 5 until K=K databases and a threshold value a listed on the left and right side 7 Repeat step 4 for all databases D1 DM then return the constructed HFP-tree of factor 2 or  respectively then this subquery complies with the down closure property Figure 2 Hybrid Frequent Pattern tree construction 1-4244-0803-2/07/$20.00 251C2007 IEEE 730 


For example a subquery like A+B+C  a complies with the 6.2 Relational Pattern Discovery Using HFP-tree down closure property and can be directly put into the DC set The proof of this property is trivial Given a pattern P and any of The construction of the HFP-tree ensures that the set of frequent its subpatterns Q assuming P's and Q s supports in A B and C itemsets for transactions in all databases can be enclosed into a are subpattemP3sn Q assuming Q's resp y it isupobs thAt Q  C compact tree structure but this does not automatically produce are PI P2 P3D an DJf D2\261D\2613De c 2iv then it is obvious that the relational patterns to meet our needs In this subsection we PI 2 3 3 V]'2P3 t introduce the HFP-tree based mining process in discovering Q1+Q2+Q3  P1+P2+P3  a Therefore the property is true relational patterns Figure 4 gives the pseudo code of the mining This property states that if a subquery sums up multiple databases t ogP g process which mainly consists of two procedures HFP-mining and is followed by factors 2 or  and a threshold value a and HFP-growth In the main procedure HFP-mining an input then it should be placed into the DC set for pattern pruning query Q is first decomposed into a set of subqueries DC Then Property 6.1.3 If a subquery has the support difference of two the system recursively calls HFP-growth to discover relational databases say A-B and a threshold value ux listed on the left patterns from the HFP-tree where the DC set is used to prune out and right side of factors 2 or  respectively then this unnecessary candidates on the fly and the query Q is used at the subquery can be further transformed into a subquery like A   final stage to assert the validity of the patterns which still complies with the down closure property Given an HFP-tree built from the multiple databases the HFPIt is obvious that if A-B  a then A  B+a Since a pattern's growth first checks each node ai in the header table of the tree support in a daabascanotbnegtivesoehaeA xBecause the header table has recorded the locations where ai has support in a database cannot be negative so we have A  a ever appeared in the tree we can start from each of ai's locations Property 6.1.4 If a subquery has the absolute support difference lij and track upwards towards the Root which will produce a of two databases say IA-BI and a threshold value cc listed on the hybrid prefix path HPPij for ai w.r.t to the current location 1 left and the right side of factors 2 or  respectively then this Figure 3 pictorially demonstrates the concept of a hybrid prefix query can be transformed into a subquery like A  a B a path for item g of the HFP-tree in Figure 1 for simplicity we which still complies with the down closure property only show branches involving g In Figure 3 g's header table has recorded six denoted by 6 digital numbers from 1 to 6 For It is obvious that if IA-BI 2 a then we have A B  a or A B each location say location 1 tracking from g upwards towards  u which lead to the inequations A  B+-x or B  A+a i.e the Root will produce a set ecba We replace the support of A  a B a For any pattern P if its supports in A and B each item in the set by the current support of g and it will are both less than u there is no way for P's superset to have a produce a path e 1:0 c 1:0 b 1:0 a 1:0 which is called a higher support than ux Therefore it still complies with the down hybrid prefix path HPP for g It is understandable that an HPP closure property records items and their frequencies w.r.t to each database which co-occur with g and have a higher rank than g in the list L Property 6.1.5 A subquery involves relationship factors  or Parsing all the HPPs of g should be able to produce frequent  will most likely not comply with the down closure property itemsets associated with g The HFP-growth will start from the and therefore cannot be placed into the DC set item with the lowest rank for pattern growth For this purpose With the above five properties we can decompose most complex for any item in the hybrid prefix paths of g we sum up its queries into a set of subquries which comply with the down frequencies w.r.t to each database from all locations which closure property and use the DC set to support efficient pattern will directly indicate whether this item is frequently associated pruning For example Query 3 in Example 1 ME  NH VT with g or not For example the other five hybrid prefix paths in  MA  CT RI  ux can be decomposed into a set of Figure 3 are d 1:1 b 1:1 a 1:1 f 0:1 dI 0:1 c 0:1 a subqueries like ME  u NH VT  u MA  u and CT RI  0:1 d 1:0 c 1:0 a 1:0 fI 1:0 d 1:0 a 1:0 and fI 0:1 u which will be used to check all candidates during the pattern c 0:1  The total frequencies of items in g's hybrid prefix path growing process are Freqg={a 4:2 b 2:1 c 2:2 d 3:2 e 1:0 f 1:2 Dividing all the frequency values by the total number of HEP-tree MetaHFP-treehfgg transactions in each database Dp=8 and D2=7 will produce the Root Root support values of each item Supg a 0 5:0.29 b 0.25 0.14 c 0.25:0.29 d 0.38:0.29 e 0.13:0 f 0.13:0.29 Given a query Ahybridprefix a 6c 0:1Q{D  D2  0.25 the query decomposition process will path of g 21 d 21 X>produce a DC set like DC={\(D1  0.25 AND D2  0.25 b 4:3 c 1:2 d 1:0 f 0:1Comparing all items support values in Supg with the DC set will d 1   CHexplicitly indicate that any of the following items b 0.25:0.14 1 d2 2 td i Figure3\(b e 0.13:0 and f 0.13:0.29 cannot form an itemset with g to 6 satisfy the query Q Therefore we can prune out those 1:L f 0:1 1:0 jj  MetaHFP-tree hfggd unqualified items directly with filtered HPPs of g denoted by c 7t   m   1:0 a 1:0 d I1:1 a 1:1 d 0:1 c 0:1 a 0:1 d 1:0,c  2-l  5 R 1:0 a 1:0 d 1:0 a 1:0 and c 0:1   After that we take V3 2 0:1 each filtered HPP as a meta-transaction and build a Meta HFP1 a 3:2 tree for g as shown in Figure 3 b Figure 3 a The hybrid prefix paths of g Figure 3 c The meta HFP-tree for T={gd AtaysgeifamaHFtre hsmoehnoept we will have to recursively call the HFP-growth procedure to Figure 3 A running example of hybrid prefix paths and a meta check each node in the header table of hfpii and build a meta HFP-tree for item g HFP-tree for the node The mining process recursively calls the 1-4244-0803-2/07/$20.00 251C2007 IEEE 731 


built from M databases ranking list L and the original query Q ctais Output Rational-pattem set RP on average It  S understandable that the runtime of the systems Poutput Rat-ional-patter ret Q will crucially rely on the underlying queries For an objective Procedure HFP-Mining HFP-tree Q assessment we define five queries as shown in Table 3 and will 1 Down Closure Set DC Query-Decomposition Q demonstrate the average system runtime performances in 2 RP-0,T*-0 answering these queries 3 HFP-growth HFP-tree T T uff the supports of P are the minimal Query Query constraints support we comparing pattern P's support Psup with the original query Q It is generate four synthetic databases with different sizes as shown in obvious that the supports of P={g 4:3 d 13:2 a 13:2 are Table 2 The explanations of the database description can be Psup=O{.38:0.28 which satisfy Q-{D1  D2  0.25 then found in 8 In short T10.l6.D300k.N1000.L1000 means a pattern P is eventually appended to the relational-pattern set RP database with 300,000 transactions and 1000 items where each transaction contains 10 items and each pattern contains 6 items Input an HFP-tree hfp RP DC Q L Procedure HFP-growth hfp T RP DC Q L Table 2 Synthetic database characteristics For HFP-growth procedure until the meta HFP-tree eventually 7 Experimental Evaluation contains one path only In Figure 3\(b because the meta HFPtree of g hfpg contains more than one path we will recursively In this section we report experimental evaluations and a call the HFP-growth to build a meta HFP-tree for each of the comparative study with two simple solution based relationalnodes in hfpg i.e item d For this purpose HFP-growth will pattern discovery mechanisms Our test datasets are collected push the current item g into a base set T g4:3 which records from two sources 1 synthetic databases generated by using the frequent items so far and conduct recursive pattern growth IBM Quest data generator 8][24 and 2 the IPUMS Integrated Public Use Microdata Series 2000 USA census micro-data with The recursive HFP-growth process will eventually lead to a meta 1 sampling rate 25 All experiments are performed on a 2.0 HFP-tree containing one or zero path At this stage there is no GHz Pentium PC machine with 512MB main memory All the need to grow patterns any further instead we can directly programs are written in C with the integration of an STL-like produce patterns by enumerating all the combinations of the C tree class 26 to fulfill the tree construction and access nodes in the tree and appending any of the combinations to the Although it is possible for DRAMA to reuse a previously underlying base set T to generate a pattern P as indicated on line constructed HFP-tree to answer multiple queries for fairness in e of the HFP-growth procedure Figure 4 Meanwhile P's comparison DRAMA will initiate HFP-tree construction and final supports are the minimal support of all involved items w.r.t HFP-mining for each query In the following tables and figures to each database Ie p min pp min UP2 where unless specified otherwise the runtime always means the total k=lk1.,K k=l,..K  execution time i.e the tree construction plus the mining time SUPP[k means the support value of the jh item in P w.r.t to For a comparative study we implement two simple solutions SPV and CPM as we have discussed in Section 2 While SPV database Di and K iS the number of items in P For example seunilymnsadvrfespten'rmec aaae Figure 3 c shows a one path actually one node meta HFP-tree CPMewill gener andie s from each database  D3 D4 buit fr bse et t 3,d 1:21 the header table of hfp in inverse order of the ranking list L a Si Apeningthi ony  a f Else Q24 D1.2\(D2 D3  D4.</J i HFP-growth hfpi T RP DC Q L 5 lD1-D2 2\(D3 D4.c2  Figure 4 Relational-pattern mining using HFP-tree 1-4244-0803-2/07/$20.00 251C2007 IEEE 732 contains a single path PS i For each combination denoted by i of the nodes in the path PS Table 3 Query plan descrpton 1 Generate pattern P based on items in Sii and ranking list L e If hfpi values of the node in i7 w.r.t each database T5p=Jlmin$z/I3[k min][f]},,where SH9t means the support D 1D22 D3 a k=l QK k=l,..,K 2  D1 D2 a D3+D4  value of the h item inP w.r.t to database Dl and Kis the number of items in P 2 Check whether P complies with the query Q if it does RP  RP u P Dl D2 for au ii Si Si u HPPU D3 Tl0.I6.DlOOk.NlOOO.L1000 c Prune items in Si based on the down closure rule in the DC set D4 Tl 0.16.D5Ok.N I000.L1000 d Build a hybrid prefix path HPPJ Build a meta HFP-tree hfpi 0 T*Tu ni The supports of T are the minimal support values of all the Database Database description nodes in T\(w.r.t each database D1 Tl0.16.D300k.NO000.L1000 b For each of ni's location au in the header table of hfp D2 T I 0.16.D200k.Nl 000.L1000 i each node ni in the remaining nde CPM will generate candidates from each component database built for base set T={g 4:3 du3 2 ppending th o node and refer to the collaborative mining process for candidate to the current base set Twill produce a pattern P=T u a 3 3:2 pruning For SPV we use FP-tree instead of the Apriori The final supports of P are the minimal support value of the item algorithm to mine patterns from the first database Because CPM in P which is 3:2 i.e Psup=O{.38:0.28 As we have analyzed needs candidates generated at each single database for in Section 6.1 the DC set is not equivalent to the original query collaboativemng,nerappl athetaditionale daprioia ori but rather for pattern pruning purposes only Therefore a pattern on each database The runtime of CPMis the pattern mining time P which is generated by using the down closure rule in the DC of the databases with the largest time expense plus the time for set does not necessarily comply with the original query Q A collaborative mining and pattern verification validity check must be conducted to assert whether P indeed complies with the query Q or not This can be easily achieved by Because real-world databases can vary significantly in size 


7.1 HFP-tree Construction Results consequently grow faster in finding frequent patterns as shown in Figure 6\(c In Section 5.1 we have proposed a joint ranking list which ranks items from different databases for HFP-tree construction We Since the joint ranking list unifies the ranking order of each item report in this section the performance of this ranking mechanism from different databases one may argue that why we don't just in facilitating tree construction and pattern growth processes We treat all items as they were from one single database e.g apply Q in Table 3 on the synthetic databases and use both the D=DJ+D2+D3 and then rank the items according to their total joint ranking list and the fixed ranking list to build HFP-trees frequencies with infrequent items in each database removed We report the results in Figure 6 where Figure 6\(a denotes the beforehand just like the traditional FP-tree method does comparison of the HFP-tree construction time Figure 6\(b However such a global ranking list reviews items as they come represents the comparison of the total number of HFP-tree from a single database without considering their frequencies in interior nodes and Figure 6\(c reports the comparison of the each single database which may produce a list inferior to the one HFP-growth time In all figures the x-axis denotes the support from the joint ranking list For example if the frequencies of threshold a in Ql and the y-axis denotes the results of different items a b c in D1 and D2 are 3000 1000 900 and 100 measures The meaning of each curve in Figure 6 is explained in 2000 1000 respectively The global ranking list will sum up Figure 5 each item's frequency and produce the list L=abc on the other hand the joint ranking list will produce the list L=bac As shown in Figure 6\(a the proposed joint ranking list can Considering that the most possible frequent itemsets in D1 and D2 dramatically reduce the time in building an HFP-tree from are bc instead ac or ab the joint ranking list may lead to multiple databases where the lower the support threshold a the better results in reality Figure 6\(a also reports the HFP-tree more significant the improvement can be observed When wa=2 construction time of the global ranking list which further it will cost the fixed ranking list and joint ranking list about 98 supports our analysis The HFP-growth on the tree built from the seconds and 60 seconds respectively to build the HFP-tree on global ranking list also needs more time than the one built from the other hand when ux becomes significantly low say 0.01 the joint ranking list and we therefore omit the results from this the cost of the joint ranking list increases to about 98.5 seconds mechanism in Figures 6\(b and 6\(c which is about 3.5 times less than the time of the fixed ranking list 364.8 seconds A low ux value will have most items in the 7.2 Query Runtime Comparison database become frequent and therefore be added into the HFPFigure 7 reports a detailed runtime performance comparison tree This can be very time consuming if the inserting process between DRAMA and two simple solutions SPV and CPM on does not take item frequency information into consideration Q in Table 3 where the x-axis denotes the support threshold because each item needs to check with the existing HFP-tree to value ux and the y-axis represents the system runtime in seconds find whether the current path already contains this item or not For a detailed comparison we also list the actual value of each The more the frequent items the fatter the HFP-tree and the method in the figure When the threshold value is relatively small more time is going to be spent on this process On the other hand say 0.05 or 0.01 the runtimes of SPV and CPMare extremely a ranking order which unifies the item frequency information large which makes no sense for comparison the empty cells from all databases can significantly reduce the time in inserting each transaction into the HFP-tree because each item a will have Overall DRAMA linearly responds to the threshold value uX and less search space in verifying whether the current node of the does an excellent job in answering the query Ql When the value HFP-tree already contains a or not In addition since the joint of ox is larger than 1.5 we notice that DRAMA is inferior to ranking list has items sorted by their frequencies before they were both SPV and CPM A further study shows that for large ux values inserted into the HFP-tree it will have a better chance compared the time for HFP-tree construction becomes significant to the fixed ranking list to force items in a frequent itemset to follow a single path and consequently reduce the size of the constructed HFP-tree As shown in Figure 6\(b the interior node Joint ranking list Fixed ranking list Global ranking list number of the HFP-tree built from the joint ranking list is about _ 1 to 10 less than the tree built from the fixed ranking list Because of the HFP-tree quality improvement more compact Figure 5 The meanings of curves in Figure 6 and less interior nodes the HFP-growth process will 2913270 12663270 51 I 3 300_ U1 co 260o 6 220 1 21632706 18 L 19132706 0 U-LL0 A714 __________ 1663270 100 1413270 1 6011376 0.01 0.05 0.1 0.5 1 1.5 2 0.01 0.05 0.1 0.5 1 1.5 2 0.01 0.05 0.1 0.5 1 1.5 2 Support Threshold  Support Threshold  Support Threshold  a HFP-tree construction time b  of HFP-tree interior nodes c HFP-growth time Figure 6 HFP-tree construction comparisons on Query 1 in Table 2 a the HFP-tree construction time b the total number of HFP-tree interior nodes and c the HFP-growth time 1-4244-0803-2/07/$20.00 251C2007 IEEE 733 Z 24132701 


compared to the time for HFP-growth For example when of DRAMA consistently and significantly better than CPM for all lo=1.5 DRAMA spends about 68 seconds on building the the queries HFP-tree however it only costs about 9 seconds for the HFPgrowth to mine the patterns At this support value level SPV SPy CPM applies an FP-tree based algorithm on D1 which outputs only 96 100000 p atterns for D2 to veri fy S o the performance of SP Vat wx=1 5  i s really just the runtime of the FP-tree mining on D On the other 10000 hand when the threshold value decreases the patterns generated from D1 can significantly increase which leads to a huge runtime expense for D2 to verify these patterns notice that database 100 scanning for pattern verification can be very expensive especially for large databases For example when a=0 10 DI 10 00    will generate about eighty thousand patterns which need to be a 0.01 verified by D2 among which about ten thousands patterns will DRAMA 131.6 122.6 116.4 106.9 96.1 77 67.3 further need to be verified by D3 As shown in Figure 7 the sPv 15787 10233 759 169 72 24 sequential verification mechanism of SPV needs more than ten CPM 29192 1064 245 89 29 thousand seconds to check all those patterns For DRAMA SupportThreshold  although the tree construction at this level a=0.1 costs about 96 seconds the integrated pattern pruning mechanism will Figure 7 Query runtime comparison on Q in Table 3 significantly reduce the HFP-growth time to about 20 seconds only So in total DRAMA can answer Q in about 106 seconds Table 4 Query runtime comparison on Q2 Q3 Q4 and Q5 in which is a huge improvement compared to SPV Table 3 a-0.5 F0.01 Although our analysis in Section 2 suggests that Collaborative Algorithm Q2 Q3 Q4 Qs Parallel Mining CPM may possibly outperform SPV because of DRAMA 157.1 135.6 129.5 147.7 the underlying collaborative mining process in candidate pruning CPM 3172 1125 1094 2957 The results in Figure 7 indicate that this is not the case Because CPM needs multiple databases to forward their candidates to a central place for collaborative mining by pruning unqualified 7.3 Case Study on a Real-world Dataset candidates we can only apply Apriori on each single database To further assess the system erformance of our roposed effort So the system performance of CPMis crucially bounded by the y pe p p on real-world datasets we download the US 2000 census micropoor performance of Apriori based algorithms When the support data from the IPUMS 26 which provides census information value a is large say 2 the performance of Apriori and FP-tree about the US residents individuals and households We use 1 is almost identical since not many items can be frequent sample of the year 2000 census data with forty seven attributes However for small x values the situation can be totally different Those attributes cover age household/personal income education For example when a=0.1 about 680 items in D1 are frequent race citizenship poverty and family relationship etc Because which produces more than 230 thousand length-2 patterns from many attributes contain multiple attribute values and some D1 although collaborative pattern pruning can somewhat remove attributes are numerical we further discretize each continuous some candidates it still leaves a large number of candidates for attribute and extend the total attribute to 587 distinct items We D1 to evaluate This huge burden significantly slows down the intentionally collect the data from four states California New performance of CPM and makes it almost unbearable in York Florida and Vermont corresponding to datasets CA NY answering many queries However being worse than SPV does FL and VT Depending on the number of populations in each not necessarily mean CPM is useless As we have analyzed in state the size of the dataset varies from 6000 Vermont to over Section 2 some queries like Q2 in Table 3 cannot be answered by 330,000 records California SPV because no mining from a single database can produce answers for Q2 For such situations CPMbecomes useful Table 5 reports a runtime performance comparison among To answer a qeylk 2weneamDRAMA CPM and SPV with dataset settings Dp=CA D2=NY To answer a query lke Q2 we need a minng process which iS D3=VT and D4=FL and two sets of support threshold values able to unify multiple databases into one view Both DRAMA Because SPV is not able to answer Q2 and Q5 its results in the and CPM can possibly attain this by using their collaborative corresponding cells are set to N/A Because census data are not mining and pattern pruning process where only patterns with randomly generated like the synthetic data item frequencies are their support satisfying D1  D2  ut or D3hD4  u are kept not random with many items frequencies significantly higher for further actions For DRAMA instead of prefiltering any than others So the support threshold values a and 8 we choose single infrequent items before the HFP-tree construction we will are relative high But even so we can see that DRAMA4 build an HFP-tree by using all items in the transactions and then consistently outperforms both SPV and CPM with a significant let HFP-growth prune out the candidates on the fly This runtime improvement The results in Table 5 indicate that mechanism turns out to be very efficient in reality as the HFPdifferent from the synthetic data CPM actually has a much better tree construction in this case spends only 105 seconds which is performance than SPV in answering some queries In fact when about 7 seconds more than ou=0.010  As shown in Table 4 a40 and fr50  although it will cost FP-tree mining about 5 where the value of Ut is fixed to 0.50 the run time performance seconds to mine patterns from D1 there are over ten thousand of DRAMA is much better than CPM in answering Q2 Table 4 patterns generated from D1 with the longest pattern containing 13 has further listed a runtime comparison between DRAMA and items All these patterns need to be verified by D2 which CPM in answering other queries in Table 3 with the performance increases the runtime significantly On the other hand at the 1-4244-0803-2/07/$20.00 251C2007 IEEE 734 


J Li Efficient mining of emerging patterns paper we have presented DRAMA Discovery Relational patterns on Data Mining 2005 that DRAMA pushes such rule sets into the mining process to 21 C Bucila J Gehrke D Kifer  W Whote Dualminer a dualspeed up the pattern growing DRAMA has demonstrated a pruning algorithm for itemsets with constraint Proc of ACM significant runtime improvement in finding relational patterns SIGKDD Conference 2002 from both synthetic and real-world databases where the 22 R Jin  G Agrawal A systematic approach for optimizing dicvrn trnd an difrecs Po.fththACSGKD Across Multiple dAtabases to solve the problem in an effective 1999 way The theme of DRAMA is to unify multiple databases to 20 X Ji J Bailey  G Dong Mining minimal distinguishing build a Hybrid Frequent Pattern tree and further decompose the subsequence patterns with gap constraints Proc of International user's query into a rule set with the down closure property After Conference Proc of ICDE 2006 performances of DRAMA can be more than 100 times better than 23 D Tsur J D Ullman S Abitboul C Clifton R Motwani  S simple methods Nestorov Query flocks A generalization of association-rule mining performances of emrha 0iebtcomplex mining tasks on multiple databases same threshold level there are about eighty frequent items in D1 References which produces about thirty two hundred length-2 candidates for CPM Meanwhile the collaborative pattern pruning from 1 U Fayyad G Piatetsky-Shapiro P Smyth  R Uthurusamy multiple databases will have those unnecessary candidates pruned Advances in Knowledge Discovery and Data Mining AAAI/MIT out on the fly So CPM can receive better performances than SPV Press 1996 2 J Han  M Kamber Data mining Concepts and techniques on the census data Morgan Kaufmann 2001 Our experimental study on the census data also brings some 3 H Kargupta B H Park D Hershberger and E Johnson interesting findings For example one rule we discovered states Collective data mining A new perspective toward distributed data interesting finngF emPLe one re tae mining in Advances in Distributed and Parallel Knowledge that the relational pattern P={"Resident is not one of the Discovery Cambridge MA MIT/AAAI Press 1999 following races African American Asian or Pacific Islander  4 X Wu  S Zhang Synthesizing High-Frequency Rules from Grandchildren do not live in this house exists with Different Data Sources IEEE Transactions on Knowledge and Data relationship VT 75.0  NY 63.2  CA 61.2  60 Engineering 15\(2003 2 353-367 where the value in the brackets indicates the actual support value 5 T Golub et al Molecular classification of cancer class discovery of the pattern in the given dataset This pattern may possibly and class prediction by gene expression monitoring Science imply that from California to New York to Vermont general US vol.286 Oct 1999 Proc ofACMSIGMOD Threshold Algorithm Q Q2 Q3 Q4 Q5 1996 cr--25 DRAMA 25.3 37.4 24.3 21.3 39.6 10 R Agrawal and J C Shafer Parallel Mining of Association Rules R-10\260 CPM 679 931 866 784 901 IEEE Proc of ACM-SIGMOD Conference 1998  Discovering contrasts and complex relationships among Prc fC-IMD ofrne 98 24 IBM Quest live separately with 6 Data Engineering Vol 8 SPV 3123 N/A 3201 3194 N/A P Yu Crossminer Efficient classification Proc ofICDMConference 2003 A contrast study is a common means of data analysis in 13 E Han G Karypis  V Kumar Scalable parallel data mining for discovering useful patterns from the data A real-world association rules Proc ofACMSIGMOD 1997 application often involves data collected from different sources 14 D Cheung V Ng A Fu  Y Fu Efficient mining of association where data managers or consumers often know simple dataset rules in distributed databases IEEE Trans on Knowledge and Data relationships e.g when and where the data in each dataset were Engineering vol 8 1996 collected or which entity each dataset corresponds to However 15 S Parthasarathy and M Ogihara Exploiting Dataset Similarity for collected or whlch entty each dataset corresponds to H ow e Distributed Mining Proc of 3rd Workshop on High Performance they are usually not aware of the relational patterns across Data Mining 2000 multiple databases which are often the driving force and the key 16 T Li M Ogihara  S Zhu Association-based similarity testing in understanding the detailed data correlations Although the and its applications Intelligent Data Analysis 7\(3 2003 users can rely on some simple solutions to find such relational 17 S Bay  M Pazzani Detecting group differences Mining Contrast patterns the runtime performances of these methods turn out to sets Data Mining andKnowledge Discovery 5\(3 2001 be unbearable in reality due to the possibly large data volumes 18 G Webb S Butler  D Newlands On detecting differences and the complex relationships among users constraints In this between groups Proc of the 9th ACMSIGKDD Conference 2003 paper w a p e d A[19 G Dong  Data Mining Project Quest synthetic data generation collections of data is a challenging and important task in data code http://www.cs.umbc.edu/-cgiannel/assoc gen.html mining To solve the problem DRAMA has focused on frequent 25 Integrated Public Use Microdata Series itemset mining But the framework proposed here is able to be http://www.ipums.umn.edu/usa/index.html extended to handle other relational patterns as well such as 26 tree.hh an STL-like C tree class constrained frequent itemsets closed frequent patterns and htp/wwaimgd/pea/re sequential patterns 27 B Chen L Chen Y Lin R Ramakrislnan Prediction Cubles Proc Of the 31st VLDB Conference 2005 1-4244-0803-2/07/$20.00 251C2007 IEEE 735 X Yin J Han  tend to itemsets in distributed and dynamic databases Transactions on Knowledge and No 6 December 1996 pp 962-969 cr-40 DRAMA 18.1 30.9 17.8 17.6 33.2 11 A Manjhi V Shkapenyuk K Dhamdhere  C Olston Finding CPM 347 492 362 273 419 recently frequent items in distributed data streams Proc of ICDE SPV 1192 N/A 1049 901 N/A 2005 12 M Otey A Veloso C Wang S Parthasarathy  W Meira 8 Conclusions Mining frequent across residents American Indian or White tend to live separately with multiple database relations Proc of ICDE 2004 their children and grand children which is more likely a 7 J Han J Pei  Y Yin Mining frequent patterns without traditional American family style So from CA to NY to VT this candidates generation Proc ofACMSIGMOD 2000 culture is likely more preserved 8 R Agrawal  R Srikant Fast algorithms for mining association rules Proc of VLDB 1994 Table 5 Query runtime comparison on IPUMS census data 9 T Zhang R Ramakrishnan  M Linvy BIRCH An efficient data clustering method for very large databases residents American Indian N"ite 



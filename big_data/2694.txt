Novel Vertical Mining On Diffsets Structure Wootipong Consue 1 and Werasak Kurutach 2 1 Department of Computer Engineering 2 Department of Information Technology Mahanakorn University Of Technology 51 Cheum-Sampan Rd., Bangkok, THAILAND e-mails: {B2923014, werasak}@mut.ac.th Abstract  Mining frequent patterns on the vertical data structures usually shows impro vements of performance over the classical hor izontal structure. This is because the vertical data structure supp orts fast frequen cy counting via intersection operations on transaction identifiers 
Recently, Diffsets [2   a vertical dat a representation, has been introduced for the sake of the size of memory required to store intermediate tids in the mining process. In this paper, we will present a new vertical mining algorithm on the Diffset structure called Fast Diffsets Vertical Mining \(FDVM\. Primarily, FDVM uses the concept of pattern growth on the Diffset structure, and we will show that FDVM outperforms previous methods in mining the complete set of frequent patterns.  Our experimental results indicate that significant performance improvement can be gained especially for large databases, over previously proposed vertical and horizontal mining algorithms 
1. Introduction  Mining frequent itemsets or frequent patterns been studied extensively in the research area of data mining. Particularly, it has played an important role in mining association rules [3,12 correlations [6], causality  se que ntial patterns 4   epi sodes 1 4   multidimensional patterns [11,13  m a x-patterns  1 0  partial periodic erging patterns 7], and m a n y  other important data mining tasks  Most of the previous work s on mining associations are based on the traditional horizontal transactional database format [3,8,12,13,15,16   a variant of Apriori-like 
approach [1  H o we ve r, a num b er of vertical m i ning algorithms have been propos ed recently for mining  h e ve rtical format, each ite m is associated with its corresponding tidset, the set of all transactions \(or tids\s that item. Mining algorithms on the vertical format have shown to be very effective and usually outperfor m horizontal approaches This advantage stems from the fact that frequent patterns can be counted via tidset intersections, instead of using complex internal data struct ures \(Candidate generation and counting occur in a single step\mining approaches take advantages on no distinction of candidate 
generation and support counting phases  a vertical da ta representation that only keeps track of the difference in the tids of a candidate pattern from its generating frequent patterns. It drastically cut down the size of memory required to store intermediate results. The initial database stored in the diffset format, instead of the tidset, can also reduce the total database size  In this paper, we present a novel vertical mining algorithm called FDVM, which can mine a complete set of frequent patterns on Diffset structure. FDVM utilizes a pattern growth strategy for efficiently enumerating all complete sets of frequent patterns. This algorithm recursively generates all subsets from 1-itemset condition 
patterns without compu ting the support va lues of all their subsets and, also, there are no candidate generation procedure and no complex data structures such as hash trees. It can be instantiated using either the traditional vertical tidset or the diffset structure. We will show that our new algorithm combined with diffset can outperform both dEclat [2 and Vipe r 1 7   The remaining of the paper is organized as follows Section 2 introduces the concept of diffset structure and its construction method. Section 3 proposes a new frequent pattern-mining algorithm, called Fast Diffset Vertical Mining \(or FDVM, for short\the Diffset structure 
Section 4 presents the result of our experimentation comparing the performance of our approach with others\220 Section 5 summarizes our work and discusses future research issues 2. Diffset Structure: Design and Construction Let I  a 1  a 2 203 a m be a set of items, and DB  T 1  T 2 203 T n be a transaction database, where 
T i  i 000\217 1, \203 n  ains a set of items in I In addition, an index i is a unique iden tifier \(called tid\a transaction T i The support or occurrence frequency  Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


an itemset \(or a pattern X denoted by 000V  X is the number of transactions in DB that contain X An itemset X is called a frequent itemset or a frequent pattern support is no less than a predefined minimum support threshold  000  To illustrate the concept of Diffset structure, it is assumed that DB 1, 2, 3, 4, 5}, as shown in Table 1, be an example of a transaction database, and I  A  B  C  D  E be a set of five different items in the database. Figure 1 depicts a common data format that has been used often in mining associations. In this traditional horizontal approach, each transaction has a tid along with the itemset comprising the transaction. In contrast, the vertical format maintains for each item its tidset, the set of all tids where the item occurs TID Item Bought 1 A,T,W 2 C,D,W 3 A,C,T,W 4 A,C,D,W 5 A,C,D,T,W 6 C,D,T Table 1: A transaction database  The Diffset structure is based on the concept of vertical database format. It avoids storing the entire tidset of each item by keeping track of only the differences in the tids between the tidset of each item and the whole tidset \(the set of all tids\nces in tids are stored in what has been called the diffset When we set a minimum support to the Diffset structure, an item a i whose corresponding tidset has th e cardinality more than  100 000 DBDB 000\020 must be cut off. Figure 2\(a Diffset structure with 000 50%. In Figure 2\(b structure is sorted by the support in an ascending order and, hence, it has a better chance that more postfix can be shared Horizontal Structure    1 A T W   2 C D W   3 A C T W  4 A C D W  5 A C D T W 6 C D T   Vertical Structure A C D T W 1 2 2 1 1 3 3 4 3 2 4 4 5 5 3 5 5 6 6 4 6 5  Figure 1: Common Data Formats DiffSet Structure A C D T W 2 1 1 2 6 6 3 4 a A D T C W 2 1 2 1 6 6 3 4   b Figure 2.  Diffset Data Format Figure 3: Compute Support on Diffset Figure 3 shows the different regions for the tidset and diffsets of item a and b Let t  a denote the tidset of an element a Also, the diffset of an element a is denoted by d a d defined by d a  t  a\220 U 000\020 t  a diffset of an itemset ab 1 defined by d ab  t  a  000\020 t  b  t  b\220  000\020 t  a\220 We can compute the support of an itemset ab on diffset structure by evaluating the cardinality of  000 Area shown in Figure 3. Thus, the support of itemset ab is 000V ab  000_ t\(a 000\210 t\(b 000_  000_\000V a 000_\000\020\000_ d\(ab 000_ where 000V a  000_ t\(a 000_  000_ U 000_\000\020\000_ d\(a 000_ 1 The symbol of set, e.g a, b}, has been ignored where there is no confusion could arise a b Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


Example 1 Based on the example database in Table 1 and its diffset that arises in Figure 2, we will illustrate how to evaluate the support of itemsets and, then, determine whether the itemsets are frequent patterns. It is assumed that the support th  to 3. Now, let\220s examine a 2-itemset AD first. We found that d\(AD t D\220 000\020 t A\220\= {1, 3}, and the support of item A is 000V A\sequently, the support of AD is 000V AD 000V A 000\020 d\(AD\| = 4 000\020 2 = 2. According to the definition, itemset AD is not a frequent pattern.  If we evaluate a 3-itemset ATW, we will obtain that |d\(ATW  000\207 0, and 000V AT 000V ATW 000\020 0 = 3 which leads to a conclusion th at ATW is a frequent pattern 3. FDVM \(Fast Diffset Vertical Mining  In this section, we will introduce how to carry out mining of a complete set of frequent patterns on Diffset structure. In addition, we will show some important properties of Diffset structure that can facilitate the frequent pattern mining. Basically, the search space for enumeration of the complete set of frequent patterns is given by the power set 000\013\000\f I 0005 which is exponential 000\013 000\f m 2 in  Im 000 the number of items  Primarily, our FDVM algorithm can be separated into two main parts. The first one is to find the long patterns and the other is to generate all patterns from the long patterns. In the first part, we will evaluate the supports of a 220s conditional patterns 2 to find the long pattern \(if 000 000V 000t xt long pattern. After that, hidden patterns can be generated by combining the elements of the long patterns with the same a 220s condition and, then testing those patterns for the co ndition of hidden patterns In the second part of the algorithm, we will generate all subitemset from the long patterns and the next long patterns of each condition without computing the supports by following Algorithm 2 \( \hich is based on the concept of Lemma 3.1. Then, we can combine the hidden patterns and all subitemset together to get the complete set of frequent patterns Algorithm 1. <FDVM  Step 1:  Find frequent items using the vertical data format  Step 2: Convert data into the vertical diffset format and, then, sort the items by their supports in an ascending order  Step 3: Find the long pattern and the low support of each X\220s condition by using Procedure Condition 2 a 220s conditional patterns mean s patterns which have a as the prefix  Step 4: Find the long pa ttern based on the next long pattern of each condition by using Procedure Condition  Step 5: Generate hidden itemsets from all combinations of the elements in all long patterns with the same a 220s condition and, then, ignore some patterns if they satisfy either of the 2 criteria   5.1 if the patterns has already tested in Step 3 and Step 4   5.2 if the patterns con sists of items in their low supports  Step 6: Test the remaining hidden itemsets whether they are frequent patterns or not  Step 7: Generate all subitemset from each long pattern by Procedure Extract  Step 8: Combine the results from Step 6 and Step 7 to receive the complete set of frequent patterns Procedure Condition  itemsX    000I 000 \000 RXTemp   Computer support fo rward in X\220s Condition   for j position\(X\n items to items    j XTempTemp 000\211\000    Test long pattern with j X  if supmin_ 000t TempSupport then  TempR 000  else RTemp 000   Test next long pattern if supmin_ 000t j XXSupport then   j XNextNext 000\211\000 else   j XLowLow 000\211\000     RLongLong 000\211\000  Lemma 3.1 Fragment growth  Let X be a frequent itemset in DB, B be X\220s conditional pattern base, and a be an itemset in B. Th en, the support of X 000\211 a in DB is equivalent to the support of a in B Corollary 3.1 Pattern Growth  Let X be a frequent itemset in DB, B be X\220s conditional pattern base, and a be an itemset in B. Then, X 000\211 a and only a is frequent in B Algorithm 2 Input  T \(long pattern with X\220s condition Output CS \(The set of frequent patterns L  length of long pattern with X\220s condition Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


SI i   Subitem of long pattern at i position Y ij  i-itemset number j in Complete set of frequent Patterns Procedure  TExtract  1 SITemp 000 set X\220condition to 1-itemset for i = 1 to  TL 000 expand 1 to L itemset   expand \(i-1\mset to i-itemset    for all 000>\000 TempY ji 000\217 000\020 1 with itemseti 000\020\000\020 1   find complete i-itemset for k=position \(i-1\f ji Y 1 000\020 to L     1 kji SIYTempTemp 000\211\000\211\000 000\020    TempCSCS 000\211\000  Example 2 Let us examine the mining process based on the Diffset structure in Figure 2 b. We collect all long patterns and next long patterns with a i condition  Let\220s start with A\220s conditional pattern base. We try to extend itemset A by adding item D to it and obtain 000V AD 2 which is less than 000 Thus, we keep item D in Low_Sup. Next, we try to extend itemset A by adding item T and have 000V AT\3 which is equal to 000 Therefore item T can be added to itemset A. Next, we try to extend itemset AT by adding item C and have 000V ATC\ which is less than 000 Thus, item C can\220t be added to itemset AT To find a next long pattern, we compute 000V AC support between item A and C not less than 000 Thus, save C itemset in to the next long pattern itemset . Last we try to extends itemset AT by adding item W and compute 000V ATW\= 3, that equals 000 Thus, itemsets ATW and C are the long pattern and the next long pattern in A\220s conditional pattern base, respectively  Now, let\220s consider D\220s conditional pattern base. We try to extend itemset D by addi ng item T to it and compute 000V DT\2 which is less than 000 Thus, we save item T to the Low_Sup. Next, itemset D is extended by adding item C and compute 000V DC\which is more than 000 That means we can add item C to D. Then, item W is added to itemset DC and compute 000V DCW\ 3 which equals 000  Thus, we can add item W to DC. Therefore, itemset DCW is the long pattern in D\220s conditional pattern base  Then, let\220s examine T\220s conditional pattern base. We try to extends itemset T by adding item C to it and compute 000V TC\3 which is greater than 000 Thus, we can add item C to itemset T. Next, item W is added to itemset TC and compute 000V TCW\ich is less than 000 To find a next long pattern, we compute 000V TW\ = 3 which is more than 000 Thus, we save item W into the next long pattern itemset. We obtain that itemsets TC and W are the long pattern and the next long pattern in T\220s condition pattern base, respectively  Now, let\220s move to C\220s conditional pattern base. We can find both long pattern and next long pattern in a similar manner to the abov e. As a result, CW is the long pattern in C\220s conditional pattern base. Similarly, W is the long pattern in the conditional pattern base of W  Next, we have to find long pattern from the next long patterns which are {C} and {W The result is that the respective long patterns with A\220s and T\220s conditions are AC and TW  Next, we find hidden patterns. Previously, we receive ATW and AC as A\220s conditional long patterns. Thus, we can combine their elements and have itemsets {ATC AWC} and {ATWC}. Then, based on Criteria 5.1 in Algorithm 1, we can ignore ATC} and {ATWC}. In the same manner, for T\220s conditional long patterns, we can generate hidden pattern {TCW} and ignore it by same criteria. Then, only itemset {AWC} remain to be testified for the condition of frequent pattern. According to its support 000V AWC\3, AWC is a frequent pattern. Next we have to extract subpattern from the long patterns \(see Example 3 Example 3 We will extract all subitemsets from each a 220s conditional long patterns found in Example 2 by using Algorithm 2. With A\220s co nditional long pattern {ATW we can extract all the patterns {A, AT, AW, ATW}. With D\220s conditional long pattern {DCW}, we have {D, DC DW, DCW}. After extracting all sub itemsets from all long patterns and combining them together, we will obtain the frequent patterns {A, AT, AW, ATW, D, DC, DW, DCW T, TC, C, CW, W, AC, TW}. Then, we can combine those frequent patterns with the hidden pattern {ACW} in order to receive the complete set of frequent pattern 4. Experimental Results  In this section, we will present performance comparisons of three algorithms  e nts were performed on a 933 MHz Pentium PC with 256 MB of Memory, running on Windows2000 Server. All the programs were written in C#. The dataset, so-called PUMSB dataset, chosen for testing the performances of the algorithms is publicly available from the website http://ftp2.census.gov/census_1990 Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


We will report the experim ental results on two datasets. The first one, denoted as 1 D is the PUMSB dataset containing census data with 7,117 items. In this dataset, the average  size of maximal potential frequent itemsets is 74, while the number of transactions in the dataset is 49,046. The second data set, denoted as 2 D is the PUMSB* dataset which is drived from PUMSB by removing items with the support of 80% or more from the 7,117 items. The average size of maximal potential frequent itemsets is reduced to 50, while the number of transactions in the dataset is still 49,046. There are numerous frequent itemsets in both data sets, as the support threshold goes down. There are pretty long frequent itemset as well as a large number of short frequent itemsets in them. They contain abundant mixtures of short and long frequent itemsets 4.1 Comparison of FDVM and Viper The scalability of FDVM and Viper   threshold decreases from 100 to 60% on pumsb dataset and decreases from 50 to 5% on pumsb* dataset is shown in Figure 4. It can be seen that FDVM\220s scalability is much better than Viper. This is because as the support threshold goes down, the number as well as the length of frequent itemsets increases dramatically. The candidate sets that Viper must handle become extremely large  0 50 100 150 200 250 300 25 30 35 40 43 45 50 60 70 80 90 95 Support threshold Runtime  sec  D2 FDVM D2 Viper D1 FDVM D1 Viper Figure 4. Scalability with support thresholds  Figure 5 depicts the run time per itemset of FDVM. It shows that FDVM has good scalability with the reduction of the minimum support threshold. Although the number of frequent itemsets grows exponentially, the run time of FDVM increases in a much more conservative way. Also Figure 5 indicates that as the support threshold goes down the run time per itemset decreases dramatically. This is why the FDVM can achieve good scalability with the support threshold 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 25 30 35 40 43 45 50 60 70 80 90 95 Support threshold  Runtime  i temset  sec  D2 runtime itemset D1 runtime itemset Figure 5. Run time of FDVM per itemset versus support threshold  The data set 2 D has been used to test the scalability with the number of transactions. The support threshold is set to 25%, and the results are presented in Figure 6 0 100 200 300 400 500 600 700 800 900 1000 1000 2000 3000 4000 5000 6000 7117 Number of transactions Runtime  sec  FDVM Viper Figure 6. Scalability with numbers of transactions  In Figure 6, it is obvious that both algorithms show linear scalability with the nu mber of transactions from 1,000 to 7,117. However, FDVM is much more scalable than Viper. As the number of transactions grows up, the difference between the two methods becomes larger and larger. Overall, FDVM is about an order of magnitude faster than Viper in large databases, and this gap grows wider when the minimum support threshold reduces Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


4.2 Comparison of FDVM and dEclat  dEclat is an efficient algorithm proposed by Zaki and Gouda h e basic i d ea of dEclat is com pose d  of computing diffsets for all distinct pairs of itemsets and checking the suppo rt of the itemsets  According to our experimen tal results, both algorithms are efficient in mining frequent patterns. However, a closer study shows that FDVM is better than dEclat when support threshold is low and the database is quite large  0 50 100 150 200 250 300 25 30 35 40 43 45 50 60 70 80 90 95 Support threshold Runtime sec FDVM dEclat FDVM dElat Figure 7: Scalability with thresholds  As shown in Figure 7, both FDVM and dEclat have good performance when the support threshold is simply low, but FDVM is still better. As shown in Figure 8, in which the support threshold is set to 25% on 2 D both FDVM and dEclat have linear scalability with the number of transactions, but FDVM is more scalable 0 50 100 150 200 250 300 1000 2000 3000 4000 5000 6000 7117 Number of transactions R u nti m e  s ec  FDVM dEclat Figure 8: Scalability with numbers of transactions  Major costs occurring in dEclat algorithm are computation of diffsets for all di stinct pairs of itemsets and checking of the sup ports of the itemsets. Particularly, in a database with a large number of frequent items, the computation cost becomes quite large. In contrast, FDVM uses only the notion of the subitemset generation. This is a main reason why FDVM has distinct advantages when the support threshold is low and when the number of transactions is large 5. Conclusions  We have proposed a novel vertical data-mining algorithm, called FDVM, that can mine a complete set of frequent patterns on a diffset structure. Our approach has been shown to be an efficient mining algorithm for large databases  In fact, FDVM has more advantages than other methods in several ways. Firstly, in contrast to dEclat algorithm ge nerates a subitemset with X 220s condition pattern without computing and checking the support of the subitemset. Secondly, the size of memory required in mining will be drastically cut down from the diffsets structure  In this work, we have implemented the FDVM algorithm and investigated its performance in comparison with several frequent pattern-m ining algorithms in large databases. Our performance study has shown that the algorithm mines both short and long patterns in large databases more efficiently th an previous methods did References  R. Agarwal, H. Mannila, R Srikant,H. To ivon en and A Inkeri Verkamo, Fast Discovery of Association Rules, In Advances in Knowledge Discovery and Data Mining Fayyad U. M., Piatesky-Shapiro G., Smyth P. and Uthurusamy R., Editors, page 307-328, AAAI Press, Menlo Park, CA 1996  M. J Zaki and K. Gouda, Fast v e rtical mining using diffsets Technical Report 01-1, Rensselaer Polytechnic Institute USA, 2001  R. Agrawal an d R.Srikant, Fast algorithms for mining  association rules, In VLDB\22094, pp.487-499  R.Agrawal and R.Srikant, Mi n i ng sequential patterns, In ICDE\22095, pp.3-14  B. Dunkel and  N. Soparkar Data org anization  and access for efficient data mining, In ICDE\22099, March 1999  S. Brin, R. Motwani,and, C Silverstein, Beyond market basket:Generalizing association rules to correlations, In SIGMOD\22097, pp.265-276  J. Han and M. Kamber, Da ta Mining: Concepts and  Techniques, Morgan Kaufmann Publishers, San Francisco CA, 2001 Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


 J. Ha n, J. Pei and Y  Yi n Mining f r e que nt patterns without candidate generation In ACM SIGMOD\22000 May 2000 9 J. Han, J. Pei and Y. Yin, Mining partial periodicity using frequent pattern trees, CS Technical Report 9910, Simon Fraser University, July 1999  R. J. B a y a rdo Efficien tly mining long p a tterns from databases, In ACM SIGMOD\22098, pp.85-93  M. Kamber, J. Ha n and J. Y. Chiang. Metaruleguided mining of multi-dimemsional association rules using data cubes,  In KDD\22097,  pp.207-210  M. Klemettin en, H. Mannila, P. Ronkainen H. Toivonen and A.I Verkamo, Finding interesting rules from large sets of discovered association rules, In CIKM\22094, pp.401-408  B. Lent, A.Swami and J.Widom Clustering association rules, In ICDE\22097, pp. 220-231  H. Mannil, H Toivonen and A. I. Verkamo, Discover y of  frequent episodes in event sequences, Data Mining and Knowledge Discovery 1, 259-289, 1997  R. Ng., L. V. S. Lakshmanan, J. Han and A. Pang  Exploratory mining and pruning optimizations of constrained association rules, In SIGMOD\22098, pp. 13-24  J. S. Park, M. S. Chen a nd P.S. Yu, An e ffective hash-based algorithm for mining association rules, In SIGMOD\22095 pp.175-186  P. Shenoy  J. R Haritsa, S. Sudarshan, G. Bhalotia, M Bawa and D. Shah. Turbo-charging vertical mining of large databases, In ACM SIGMOD\22000, May 2000  A. Savasere, E. Om iecinski an d S. Navath e An effici ent  algorithm for mining association rules in la rge databases, In VLDB\22095, pp.432-443  C. Silverstein, S. Brin, R. Motwani and J. Ullm an, Scalab le  techniques for mining causal structures. In VLDB\22098 pp.594-605  M. J. Z a ki Scalab le algori th m s for association mining IEEE Transactions on Knowledge and Data Engineering 12\(3\-June 2000  M. J. Zaki an d C. -J. Hsiao, CHARM: An efficient algorithm for closed association rule mining, Computer Science Dept., Rensseaer Polytechnic Institute, October 1999 Proceedings of the IEEE/WIC International Conf erence on Intelligent Agent Technology \(IAT\22203 0-7695-1931-8/03 $ 17.00 \251 2003 IEEE 


3 3.5 fixed-style adap-style Er 4 S1 White burst the transient signal s1 is white and Gaus40 02~45\260\260 10 rn 0 sian with zero mean S2 Single exponentially-decaying sinusoid 30 60 20 X 4050 f S2\(i Ce f cos\(27f i/foq5 33 20  0   260 30   for i I l  M with the phase  randomly chosen from   20   0 2 7 and the frequency f randomly generated in the range 10   10       1 Js 4 1\260 10 1 0 0 0 0.75 0.7~~~~~~~~~~~~~~~~~~~~~~0 0.9 0.85 00 0 0 0 000 ogpq 0 0 0 1 02 1 03 legt le 1 1h02 1033 3 Exponentially-enveloped white burst transient length transient length Figure 9 Exponential case The right plot gives compariS3 i efS si i 34 son of the bias and thresholds used in the new adaptive Page procedure to those of the fixed-style Page scheme tailored to for i 1   M each specific transient length In all cases T 10l6 The agS4 Narrowband burst S4 iS created by passing white gregate SNR SL corresponding to the bias used in the fixed Gaussian noise through a narrowband filter whose bandwidth Page schme is pltted in he left igure.1S 0.3wr and whose center frequency iS chosen randomly 8 10\26065 _F 0~~~~~~~~~~~~~~~~~~~0 bL where bL denotes the bias for the fixed-style comparison only Page designed for length L 4 SIMULATION STUDY Again considering the fixed-style Page scheme first based The purpose of this section is to study the performance of the on the thresholds h's calculated by the FFT approach we above designed adaptive Page test regardless of the transient find from figure 8 that the behavior of the Page test designed signal's form strength and location The signal model is for particular transient lengths L does not provide constant detectability and thus modification according to our adaptive Ho x  w 31 Page procedure is desirable Therefore b and h\(L are ob tained according to 23 and 21 The corresponding fixed H1 x\(n  s\(n n men  n  n  nd bias b and variable threshold h\(L are plotted and compared s\(n  w\(m nS  n  mS  Td to those used in the fixed-style Page tests in figure 9 The 32 performance of the adaptive Page procedure is given in figure 10 and a gratifying detection improvement is observed in which x denotes the observation vector w is white Gausespecially for shorter transient lengths sian noise with zero mean and unit variance the vector s is the transient signal of interest The transients are of short du-1 ration M compared with the observation length N In our 60r 7 r 1.5 simulations we always use N  128 M  30 fs  16  2  and A  0.5 unless stated otherwise The transients are as 2.5 50   2.5  follows 50 10\260 1021o2 100 t analysis fixed-style envelope sient lengh0 0 simulation fixed-styld te envelope betwen7flse0larm0is  l6 Te udatetake theform Pagetestoptiize  anansiena adap style simulation adap style Page 0.4 designed for L200 loo 101 0 2 10 oo 101102103 transient length transient length Figure 8 Detect"ab"ility of exponential transients using fixedFigure 10 Performance of the adaptive Page scheme in style Page procedures designed for various but specific tranExponential transient problem The Pd envelope from the sient length L In all cases Pd 0.8 and the average time normal fixed-style Page procedure and the performance of the between false alarms is T 106  The update takes the form Page test optimized for transient length L=200 are shown for g\(x x 


2 35 04 T 2 0.4 0.2 0.2 provides the best performance over a wide range of transients 10 15 20 25 10 15 20 Unlike the Page detector the transient duration M is required here and Tmax does indeed show some sensitivity as regards c d this parameter as illustrated in figure 11 for transient signal 7  sl Similar relationship between Tmax and M is observed for 0.8 0.8 other types of transients 0.2 0.75 0 Cl 10 15 20 25 10 15 20 0.7  a aggregate Certainly this is not an exhaustive menu of transients but a for v is 2.5 when information about M is completely unavailwide range is covered able In fact several new power-law detectors were developed in 19 for instance we have We apply the adaptive Page detector designed in section 3 the Gaussian shift-in-variance case to the above transient's T a _da Page 0.6 Tma 0.6 Mf-1+i 0.6 l0.6 0.8 0.4 0.4 0.2 X X XN 37 detection The b and h\(L derived according to 21 is 12\(N Z\(Xi  X+\261 3 used in this adaptive detector where Pd  8 T  106 and t N  128 The assumptions on which the adaptive Page proSimilarly by combining 3 contiguous FFT bins we can write cedure is built are those of Si the detector is weakly suited Tf 3 It was found that for most practical transient signals Tf 2 to S3 and would seem to bear little affection for either S2 or and Tf 3 were preferable to Tpl S4 a b To illustrate the performance of our adaptive Page detector we compare it to other detectors In 18 it was found that 0.8  0.8 Nuttall's maximum detector 14 SNR dB aggregate SNR dB 0.65  Figure 12 Detection performances of the adaptive Page scheme The transient duration is M  30 samples different oT 0.6  panels refer to different transient signals with a transient signal sl b transient signal 82 c transient signal 83 and 0.55  d signal 84 0.5  We plot Pd versus the aggregate SNR in figure 12 in which Pf a  10-4 It is noted that the adaptive Page procedure 0.45 provides very close performance to that of the maximum detector in all four situations which is best in all cases as 0.4 0 20 40 60 M 80 100 120 in 18 This is exciting as we recall that M is tuned in the maximum detector and that our adaptive Page test reFigure 11 Detection performances of Tmax vs Al for quires no such prior information It is additionally noted that transient signal sl The true transient duration is M  30 qursnschpirnfmao.Itsadtoalyoedht transient  sina  Th tretasetduaini.l 3 the adaptive Page procedure provides performance superior samples and the aggregate SNR is 18dB The dash-dotted line indicates the best performance of Tmax when true M to even the improved power-law detector Tf12 in most cases is chosen The dotted line indicates the performance of the with the exception of S2 in which the transient is highly naradaptive Page scheme rowband Nuttall's Tmax looks for an increase in empirical variance as 5 SUMMARY does our Page processor In  1 8 it was found that another detector due to Nuttall works particularly well for narrowband The standard Page test is designed to detect a change in distritransient signals this based on the power-law statistic 15 bution amongst a conditionally independent observation pool defined as but works nicely at detecting even transient changes provided N they are of known character The standard Page update has Tp1 N 5 i 36 implicit a fixed negative bias and a detection is recorded i upon passage by this update of a fixed threshold these the In 36 v is an adjustable exponent and the Xi  are bias and threshold are determined by the ambient and tranmagnitude-squared FFT bins corresponding to the observasient distributional models fO and fil Specifically when fO tions x It has been found that the best compromise value and fi are close the bias is light and threshold high and 9 1 0 T with v=2.5 0.4 Tmax max S 


when fo and fi are distinct the Page test uses heavy bias and quence of Random Variables Biometrika Vol 57 No low threshold 1 pp 1-17 1970 6 B Broder and S Schwartz Quickest Detection ProceNotionally a transient signal that is long-and-quiet and one dures and Transient Signal Detection ONR Technical that is short-and-loud ought to have approximately the same Res and Transier 1990 detectability However these two engender very different Report 2 November 1990 Page tests and unfortunately the test designed for one can 7 D Casasent J-S Smokelin A Ye Wavelet and Gabor work quite poorly for the other Consequently in this paper Transforms for Detection Optical Engineering Vol an adaptive Page processor has been developed it uses a con31 No 9 pp 1893-1898 September 1992 stant bias but has a threshold that adaptively changes with the 8 S Del Marco and J Weiss M-band Wavepacket-Based number of samples since the most recent reset Transient Signal Detector Using a Translation-Invariant Wavelet Transform Optical Engineering Vol 33 No The new detector has been studied extensively in the Gaus7 pp 2175-2182 July 1994 sian shift-in-mean and shift-in-variance and also in the expo[9 T Dyson Topics in Nonlinear Filtering and Detecnential shift-in-scale cases It works very well and essentially tion PhD Thesis Princeton University Princeton NJ traces the envelope of performance achievable with the best 1986 Page processor tuned to each transient length the proposal is reasonable but ad-hoc but apparently we hardly could do 10 B Friedlander B Porat Performance Analysis of better Transient Detectors Based on a Class of Linear Data Transforms IEEE Transactions on Information TheTransient detection is interesting because one does not know ory Vol 38 No 2 pp 665-673 March 1992 in advance the sort of transient signal one has to look for it 11 C Han P Willett and D Abraham Some Methods could be narrowband or not it could have a sharp attack or it to Evaluate the Performance of Page's Test as used to could increase slowly and disappear abruptly Many transient Detect Transient Signals IEEE Transactions on Signal detectors are tuned to one type of transient and comparatively Processing pp 2112-2127 August 1999 blind to others What tends to unite transient signals of prac[12 G Lorden Procedures for Reacting to a Change in Distical interest however is that they are an organized agglomtribution Annals o Mathematical Statistics vol 42 eration of energy into contiguous or nearby time samples 1897-1908 1971 Now assuming a unit-normal ambient a transient detector pp 1 that assumes nothing but this local scale-change and one that 13 G Moustakides Optimal Stopping Times for Detectis reasonably insensitive to other characteristics such as specing Changes in Distributions Annals of Statistics vol trum is that based on the Page structure for Gaussian shift14 pp 1379-87 1986 in-variance The adaptive Page test developed here is also 14 A Nuttall Detection Capability of linear-And-Power insensitive to transient length it has here been tested for a Processor for Random Burst Signals of Unknown Locavariety of transient signals for which it is not on the surface tion NUWC-NPT Tech Rep 10,822 August 1997 well-suited and its performance has been found remarkably N o-Law Progood 15 A Nuttall Detection Performance of Power-LwPo good.a cessors for Random Signals of Unknown Location REFERENCES Structure Extent and Strength NUWC-NPT Technical Report 10,751 September 1994 1 D Abraham Asymptotically Optimal Bias for a Gen[16 E Page Continuous Inspection Schemes Biometrika eral Nonlinearity in Page's Test IEEE Transactions vol 41 pp 100115 1954 on Aerospace and Electronic Systems pp 1-8 January 17 B Porat and B Friedlander Performance Analysis of 1996 a Class of Transient Detection Algorithms-A Unified 2 M Basseville and I Nikiforov Detection of Abrupt Framework IEEE Transactions on Signal Processing Changes Theory and Application Englewood Cliffs Vol 40 No 10 pp 2536-2546 October 1992 NJ Prentice Hall 1993 18 Z Wang and P Willett A Performance Study of Some 3 A Shiryaev On Optimum Methods in Quickest DetecTransient Detectors IEEE Transactions on Signal Protion Problems Theory Prob Appl Vol 8 No 1 pp cessing Vol 48-9 pp 2682-2686 September 2000 22-46 1963 19 Z Wang and P Willett All-Purpose and Plug-In 4 M Basseville Edge Detection Using Sequential MethPower-Law Detectors for Transient Signals IEEE ods for Change in Level-Part  Sequential Detection Transactions on Signal Processing November 2001 Of Change in Mean IEEE Transactions on Acoustic 20 P Willett and B Chen A New Sequential Detector Speech and Signal Processing Vol ASSP-29 No 1 for Short Duration Signals Proceedings of ICASSPFeb 1981 98 Seattle WA May 1998 5 D Hinkley Inference About the Change-Point in a Se[21 P Willett and Y Bar-Shalom Track Testing for Single 10 


Targets in Clutter Proceedings of the SPIE Aerosense Now using the above procedure we can calculate hL for tranConference on Signal Processing for Small Targets sient duration L L  1  N given T and thus the timeApril 2000 varying threshold h\(L via 21 and also the performance in terms of Pd of the Page and our adaptive Page tests APPENDIX 2 EVALUATE PERFORMANCE OF ADAPTIVE 1 THE FFT APPROACH TO EVALUATE PAGE TEST PERFORMANCE OF FIXED-STYLE PAGE TEST For the transient change problem modeled as in 10 the runlength metrics 5 and 1 are of less interest than they would be for the permanent change problem Further and perhaps more important given their context in this paper these approximations do not apply at all in the case of a time-varying Uration A Page update Thus given the update rule and the average time-between-false alarms T we employ the FFT approach introduced in 11 to obtain the requisite threshold h that satisfies it and then to get the detection performance Pd Interested readers please refer to 11 for detail since here only a j l brief description is given AYvvfj Consider Page's test as an iterated sequential test ST with 7 n sample ihdex n    sbti-Sb lower and upper thresholds 0 and h Each individual ST is defined as an update rule Figure 13 Illustration of a Page implementation 20 with Z Z.i  g\(x non-zero initial point The change starts at point nm indicated by the dotted line and a decision rule as in 20 The procedure to calculate the probability of detection for the Thus the pdf of Zn is adaptive Page scheme is complicated by the fact that the Page bn Z  fn\(Z  fg Z 38 statistic be non-zero at the start point of a change Figure 13 shows such an example where the transient change begins at where fg is the pdf of the update g\(xn fn-i denotes the point nm and the threshold index i  5 at the start point nm pdf of Zn given that the test has continued to time n and due to the non-zero initialization Since the threshold index  denotes convolution the convolution can be made both i plays an important role in the adaptive scheme a non-zero accurate and quick via a fast Fourier transform FFT Then initialization could result in a different detection decision It we compute is thus necessary to calculate detection probabilities for difOn Z ferent threshold index i corresponding to the start point nm fn\(z f h n  0  z  h 39 Overall under the H1 hypothesis we have JO fn z dz 00 as a direct normalization In a straightforward manner under Pd\(nd S p\(i nd i 42 the Ho hypothesis one can express T as i=l F Eo  F1 N 40 where nd is the transient length and i is the threshold index T n=Z P1\(n corresponding to the start point nd According to the definiwhere Ei N is the expected number of samples to a decision tion the pmf p\(i is decided by the characteristics of the test for hypothesis Hi and pi n Pr\(ST ends at n and decides Hl Ho Under the H hypothesis assuming the standard situation we p\(i Pon i 1 Ho 43 have E 0 Pon nm Ho ndl1 Pd nd 5 Pr detect k resets 41 where Pon n l Ho Pr ST will continue to time-step n I I Ho k=o Under the Ho hypothesis assuming fo z  d\(z with the where nd is the transient length6 update g  we can calculate the pdf fr,\(z H0 according to 39 and thus calculate Pon nm Ho0 correspondingly 61n 11 it was noted that the probability of detection is increased both by latent detections caused by diffusive threshold-crossings after a transient's For each index i to calculate the corresponding Pd md i in end and also by a non-zero CUSUM value at the inception of a transient  Both of these can be accounted for via the direct FFT approach and for 42 we need to study stopping probabilities both for the case details we invite the reader to examine 11 fo Z f&i-1\(Z Ho and for fo z 5\(z  For the case that 11 


fo z fi 1 z Ho we consider a decision rule Z Jane Wang Z Jane Wang received the BSc degree from Tsinghua Univer[h\(n+i-1 stopanddecideH sity China in 1996 and the MS and ZC  h[\(n  i1 c ntine dtest 44 PhD degrees from the University of Con 0 h\(m  i 1 continue test necticut in 2000 and 2002 respectively oc 0 stop and decide Ho all in electrical engineering She spent two years as Research Associate of ElecAd b d ts d rtrical and Computer Engineering DeAnd based on this decision rule 44 we compute the imporpartment and Institute for Systems Research at the Univertant quantities sity of Maryland She is now an Assistant Professor in the Department of Electrical and Computer Engineering at the pO\(m  Pr\(ST ends at n and decides Ho University of British Columbia Her present research interests are in the broad areas of statistical signal processing p n  Pr ST ends at n and decides Hi r4 in Pr\(ST ends at in and decides H1 information security and wireless communications Respectively for the case that fo z  d\(z we consider a decision rule Peter Willett Peter Willett is a Profesh c s and decide H sor of Electrical and Computer EngiZne 0,h cstop 1 neering at the University of ConnectiZn E 1 0,h\(n continue test 45 _ cut Previously he was at the University oo 0 stop and decide Ho of Toronto from which he received his BASc in 1982 and at Princeton University from which he received his PhD in and compute the corresponding quantities p\260\(n and po n 1 H h w e mrt Now using p n and p n and pog\(n and po n we can  E 18.Hha rte,mogterop Now,'using a a  ics about the processing of signals from volumetric arrays calculate Pd nd i as in 41 and finally calculate the overall decentralized detection information theory CDMA learPd nd in 42 It is worth to mention that for theoretical d  ing from data target tracking and transient detection He analysis we use the infinite as the upper bound of i in 42 is a Fellow of the IEEE and is a member of the IEEE Sighowever we use a finite reasonable upper bound in practical nal Processing Society's SAM technical committee He is an calculation For instance in the Gaussian shift-in-mean appliassociate editor both for IEEE Transactions on Aerospace cations we plot p\(i vs i in figure 14 From this figure it is and Electronic Systems and for IEEE Transactions on Sysclear that p\(i decays quickly with the increase of i therefore tems Man and Cyberetics He is a track organizer for it is reasonable to consider the truncated pmf Similar obserRemote Sensing at the IEEE Aerospace Conference 2001vations could be found for the Gaussian shift-in-variance and 2003 and was co-chair of the Diagnostics Prognosis and the Exponential cases System Health Management SPIE Conference in Orlando He also served as Program Co-Chairfor the 2003 IEEE Systems 02 Man  Cybernetics Conference in Washington DC 0.18 0.16  0.14 0.12 a 0.1 0.08 0.06 0.04 0.02 100 101 102 103 Figure 14 The pmf p\(i in the Gaussian shift-in-mean case 12 


Database 1 proc 2 procs 4 procs 8 procs T5.I2.D100K 20 17 12 10 T10.I4.D100K 96 70 51 39 T15.I4.D100K 236 168 111 78 T20.I6.D100K 513 360 238 166 T10.I6.D400K 372 261 165 105 T10.I6.D800K 637 435 267 163 T10.I6.D1600K 1272 860 529 307 Table 3 Naive Parallelization of Apriori seconds   0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2    0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD : With Reading Time Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2  Figure 4 CCPD Speed-up a without reading time b with reading time 13 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


Reading  f Total Time Database Time P 000 1 P 000 2 P 000 4 P 000 8 P 000 12 T5.I2.D100K 9.1s 39.9 43.8 52.6 56.8 59.0 T10.I4.D100K 13.7s 15.6 22.2 29.3 36.6 39.8 T15.I4.D100K 18.9s 8.9 14.0 21.6 29.2 32.8 T20.I6.D100K 24.1s 4.9 8.1 12.8 18.6 22.4 T10.I6.D400K 55.2s 16.8 24.7 36.4 48.0 53.8 T10.I6.D800K 109.0s 19.0 29.8 43.0 56.0 62.9 T10.I6.D1600K 222.0s 19.4 28.6 44.9 59.4 66.4 Table 4 Database Reading Time in section 4 320 computation balancing hash tree balancing and short-circuited subset checking The 336gure on the left presents the speed-up without taking the initial database reading time into account We observe that as the number of transactions increase we get increasing speed-up with a speed-up of more than 8 n 2 processors for the largest database T10.I6.D1600K with 1.6 million transactions r if we were to account for the database reading time then we get speed-up of only 4 n 2 processors The lack of linear speedup can be attributed to false and true sharing for the heap nodes when updating the subset counts and to some extent during the heap generation phase Furthermore since variable length transactions are allowed and the data is distributed along transaction boundaries the workload is not be uniformly balanced Other factors like s contention and i/o contention further reduce the speedup Table 4 shows the total time spent reading the database and the percentage of total time this constitutes on different number of processors The results indicate that on 12 processors up to 60 of the time can be spent just on I/O This suggest a great need for parallel I/O techniques for effective parallelization of data mining applications since by its very nature data mining algorithms must operate on large amounts of data 5.3 Computation and Hash Tree Balancing Figure 5 shows the improvement in the performance obtained by applying the computation balancing optimization discussed in section 3.1.2 and the hash tree balancing optimization described in section 4.1 The 336gure shows the  improvement r a run on the same number of processors without any optimizations see Table 3 Results are presented for different databases and on different number of processors We 336rst consider only the computation balancing optimization COMP using the multiple equivalence classes algorithm As expected this doesn\325t improve the execution time for the uni-processor case as there is nothing to balance r it is very effective on multiple processors We get an improvement of around 20 on 8 processors The second column for all processors shows the bene\336t of just balancing the hash tree TREE using our bitonic hashing the unoptimized version uses the simple mod d hash function Hash tree balancing by itself is an extremely effective optimization It s the performance by about 30 n n uni-processors On smaller databases and 8 processors r t s not as 14 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



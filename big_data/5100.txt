133 Market-Basket Problem Solved With Depth First Multi-Level Apriori Mining Algorithm Mirela Pater and Daniela E. Popescu Department of Computer Science Faculty of Electric Engineering and Information Technology, University of Oradea University Str. no.1, Oradea, Romania Phone: +40 \(0\259 408-250 E-Mail mirelap@uoradea.ro  depoepscu@uoradea.ro   AbstractThe problem of deriving association rules from data was first formulated in [9 a n d i s c a l l e d  th e  m a r k e t b a s k e t  problemé. This paper presents an efficient version of APRIORI algorithm for mining multi-level association rules in large databases to solve market-basket problem. Our algorithm named DEPTH FIRST MULTI-LEVEL APRIORI \(DFMLA uses the benefits of multi-leveled databases, by using the information gained by studying items from one concept level for the study of the items from the following concept levels  Keywords  data mining, support constrains, knowledge discovery in databases, multi-level databases, multi-level association rules mining  I. INTRODUCTION Data Mining refers to extracting or çminingé knowledge from large amount of data. Data mining is the nontrivial extraction of implicit, previously unknown, and potentially useful information from data as shows Dunham in [5 an d  Frawley  et al. in [6 T h r ough t h e ext r action  o f  knowled g e in  databases, large databases serve as rich, reliable sources for knowledge retrieval and verification, and the discovered knowledge can be applied to information management decision making, process control and many other applications The aim of data mining is the discovery of patterns within data stored in databases. Mining for association rules is a data mining method that lends itself to formulating conditional statements such as çif customers buy product x  then they also buy product y Therefore, data mining has been considered as one of the most important and challenge research areas. Some researchers like Strikant  and Agrawal, in [9  an d Ra j kuma r  et al. in [1 f o und t h at f o r m a n y  a p p l i cations it  i s  d i fficult  to  find strong and interesting associations among data items at the primitive levels of abstraction due to the sparsity of data However, many strong associations discovered at rather high concept levels are common sense knowledge. Therefore, a mining system with the capabilities to mine association rules at multiple levels of abstraction and traverse easily among different abstraction spaces is more desirable like Han  et al in [8  and R a jkum ar  et al. in [10  indic a te II. ASSOCIATION RULES MINING  Association rule discovery has emerged as an important problem in knowledge discovery and data mining. The association mining task consists of identifying the frequent itemsets, and then forming conditional implication rules among them Finding frequent itemsets is one of the most investigated fields of data mining The problem was first resented in [1  T h e  subse q uent paper of Agrawal, [2  i s c o n s ide r ed  as on e of th e mos t  important contributions to the subject. Its main algorithm APRIORI, not only influenced the association rule mining community, but it affected other data mining fields as well Association rule and frequent itemset mining became an ideally researched area, and hence faster and faster algorithms have been presented. Numerous of them are APRIORI based algorithms or APRIORI modifications We theoretically and experimentally analyze APRIORI which is the most established algorithm for frequent itemset mining One of the most well-studied problems in data mining is mining for association rules in market basket data Association rules, whose significance is measured via support and confidence, are intended to identify rules of the type, "A customer purchasing item A often also purchases item B Since the introduction of association rules, many algorithms have been developed to perform the computationally very intensive task of association rule mining. During recent years there has been the tendency in research to concentrate on developing algorithms for specialized tasks, e.g. for mining optimized rules or incrementally updating rule sets. Here we return to the classic" problem, namely the efficient generation of all association rules that exist in a given set of transactions with respect to minimum support and minimum confidence We try to solve the market basket problem using association rules mining algorith ms. In this paper we discuss the depth first [8  i m pl e m e n t a t i on of  A PRIORI 1 o n e  o f  t h e  fastest known data mining algorithms to find all frequent itemsets in a large database, i.e., all sets that are contained in at least minsup transactions from the original database. Here 978-1-4244-5056-5/09/$26.00 ©2009 IEEE 


134 SOFA 2009  3 rd International Workshop on Soft Computing Applications   29 July Ö 1 August    Szeged \(Hungary\ad \(Romania minsup is a threshold value given in advance. There exist many implementations of A PRIORI 6, 11   III. PROBLEM STATEMENT  Frequent itemset mining came from efforts to discover useful patterns in customersê transaction databases. A customersê transaction database is a sequence of transactions T _t 1 tn_ ere each transaction is an itemset ti  I\. An itemset with k elements is called a k itemset. In the rest of the paper we make the \(realistic\sumption that the items are from an ordered set, and transactions are stored as sorted itemsets. The support of an itemset X in T, denoted as supp T X is the number of those transactions that contain X  i.e supp T X  tj  X  tj An itemset is frequent if its support is greater than a support threshold, originally denoted by min supp The frequent itemset mining problem is to find all frequent itemset in a given transaction database The first, and maybe the most important solution for finding frequent itemsets, is the APRIORI algorithm [2  Later faster and more sophisticated algorithms have been suggested, most of them being modifications of APRIORI Therefore if we improve the APRIORI algorithm then we improve a whole family of algorithms. We assume that the reader is familiar with APRIORI [2  and  w e turn ou r  attention to its central data structure A typical example of association rule mining is market based analysis presented by Dunham [5   Th i s pr o c e s s  analyzes customer buying habits by finding association between the different items that customers place in their market basketé. The discovery of such association can help retailers develop marketing strategies by gaining insight into witch items of frequently purchased together by customers We assume every 1-itemset to be frequent; this can be effected by the first step of the algorithms we are looking at which might be considered as preprocessing A çdatabase queryé is defined as a question of the form Does customer _ buy product _?é \(or çDoes transaction  has item _?é\, posed to the original database. Note that we have __ database queries in the çpreprocessingé phase in which the supports of the 1-itemsets are computed and ordered: every field of the database is inspected once The number of database queries for DFMLA  equals  For instance, if customers buyi ng milk, how likely are they to also buy bread on the same trip to super market? Such information can lead to increased sale by helping retailers do selective marketing and plan there self space. For example placing milk and bread with in close proximity may further encourage the sale of these items together within visit to the store Let I= {I 1 I m   be a set of attributes called items. A subset X   I is called an itemset. A k-itemset is an itemset that contains k items Let the database  D= {T 1 T n  be a multi-set of transactions where each transaction T i I † { 1, É , n is an itemset [3  A tr an sa c t i o n  T contains an itemset X if X   T Each itemset has a certain statistical significance called support or frequency The support of an itemset X is the fraction of transactions in the database D containing itemset X i.e              D T X D T X S    2  An association rule is an implication X --> Y where X   I  Y   I and X Y   X is called the antecedent and Y  is called the consequent of the rule. The rule X --> Y holds with confidence C if C is the fraction of transactions containing X that also contain Y i.e         X S Y X S Y X C  3  The confidence denotes a ruleês strength. A confidence threshold C min is used to exclude rules that are not strong enough to be interesting. Accordingly, there is a support threshold S min that excludes all rules whose number of transactions containing the union of the antecedent and the consequent is below a certa in amount. Itemsets with minimum support are called frequent or large  itemsets The two kinds of thresholds must not be confused. The support threshold is defined over itemsets. When applied to association rules, it describes the minimum percentage of transactions containing all items that appear in the rule. The confidence threshold specifies the minimum probability for a consequent to be true if the antecedent is true. A confidence of nearly 100% characterizes only very stringent rules  IV  MULTI-LEVEL ASSOCIATION RULES   Based on the concept hierarchy and some existing algorithms for mining single-level association rules, a group of efficient algorithms for mining multilevel association rules are proposed by Han  et al. [7   8   and R a jkum ar  et al. [10  We assume that the database contains 1  an item data set which contains the description of each item in I in the form of A i description, where A i is the productês code 2  a transaction data set T T 1 T n which consists of a set of transactions T i A p A q   in the format of  \(TID, A i Where  TID is  a  transaction identifier and Ai is an item from the item data set Rajkumar  et al. [10 sh o w t h at  in m u lti-l e v e l d a ta ba s e s u s e hierarchy-information encoded transaction table instead of the original transaction table. This is useful when we are interested in only a portion of the transaction database such as food, instead of all the items. This way we can first collect the relevant set of data and then work repeatedly on the task 


135 Mirela Pater, Daniela E. Popescu    Market-Basket Problem Solved With Depth First Multi-Level Apriori Mining Algorithm relevant set. Thus in the transaction table each item is encoded as a sequence of digits Example The item Pepsi Cola is encoded as ç0201 according to the table 1 below. The first digit è0ê represents Foodé at the first level, the 2 nd digit represents çDrinksé in the 2 nd level, 3 rd digit is çColaé in the 3 rd level and, the 4 th  digit ç1é represents product ç1 in the çColaé category. The information required to create such a database is either implicit Pepsi Colaé is obviously part of the çcolaé category which is part of the çdrinksé category, etc., or it is provided by the user. Some information, like price or brand can be used to transform items into categories. For example White Bread can become a category which contains ç1$ White Breadé or çDorbobé White Bread  Table 1.Item codes and descriptions              The problem of finding association rules can be stated as follows. Given a set I of items, a database D of itemsets, a support threshold S min and a confidence threshold C min find all association rules X --> Y in D that have support X  Y   S min and confidence C\( X,Y   C min   Fig.1 Hierarchy-based multi-level database   We generally are not interested in all implications but only those that are important. Here importance usually is measured by two features called support and confidence  The support of an item \(or set of items\is the percentage of transactions in which that item \(or items\occurs. The confidence or strength for an association rule X -> Y is the ratio of the number of transactions that contains X U Y to the number of transactions that contain X In the multilevel database the item data set will be entered like in the table 1. This table also contains category codes and a description for each code \(category or item\ich is only needed for the final display. Itemês quantity, price, brand or other information should be present but are not considered in this paper  Table 2.Transactions components  Transaction Products T1 Bread White, Milk 1.5%, Coca Cola, Prigat T2 Bread White, Milk 1,5%, Milk 2%, Prigat T3 Milk 2%, Coca Cola T4 Milk 2%, Pepsi Cola T5 Bread Wheat, Coca Cola, Milk 2%, Prigat  Table 3.Transactions data set                  From the tables 1 and 2 we can deduce that the transactions are represented in table 3 Multi-level rules are rules in which the concepts or constants may be at multiple conceptual levels in conceptual hierarchies The problem is to discover the rules at multiple conceptual levels, i.e. multiple-level rules. Most rule discovery methods find primitive levels which only involve concepts at the primitive level. In multi-level databases this methods are extended by finding rules at different levels as opposed to rules at one specific level Thus, we have the ability to focus our attention on discovering informative rules between categories, or even between an item and a category, not just rules between items The support, the confidence and other mining rules can be used in new ways in a multilevel database For example the support of a category is the percentage of transactions in which that category occurs. Support for the Milk category   100 100  5 5 100         S\(Milk    trans n r Total products Milk with tranz Nr  Code Description 0 Food 00 Bread 01 Milk 02 Drinks 000 White \(Bread 001 Wheat \(Bread 010 1,5% \(Milk 011 2% \(Milk 020 Cola 021 Prigat 0200 Coca \(Cola 0201 Pepsi \(Cola Transaction Item Code T1 000 T1 010 T1 0200 T1 021 T2 000 T2 010 T2 011 T2 021 T3 011 T3 0200 T4 011 T4 0201 T5 001 T5 0200 T5 011 T5 021 


136 SOFA 2009  3 rd International Workshop on Soft Computing Applications   29 July Ö 1 August    Szeged \(Hungary\ad \(Romania One has to consider that the support of a category may not be the sum of the supports for the descendants. However, the support for a category canêt be lower than the support for one of its descendants For example, because a customer may have bought more than one item from the same category \(see transaction T2 milk 1.5% and milk 2%\ in the same transaction, the support for the çmilk category is counted only once, and itês smaller by 1\ than the sum of the supports of these items If a category doesnêt have minimum support then its descendants wonêt meet minimum support either. This is because the support for a category is lower or equal to the sum of the supports for its descendants and itês obvious that if the sum of sup1 and s2 is lower than min_sup than neither s1 nor s2 can be bigger than min_sup   Fig.2 Rule Inheritance   IV  DEPTH FIRST MULTI-LEVEL APRIORI ALGORITHM \(DFMLA  Description This is an improvement of the Apriori algorithm presented by Agrawal  and Strikant [2 i n  w i tc h  there are generally not interested in all implications but only those that are important like Han  and Fu demonstrated [8   Here importance is measured by support  The algorithm is for multi-level databases which gives us the advantage of using a progressive deepening method that is developed by extending the Apriori algorithm for mining single-level association rules in [8  T h e m e thod first finds  frequent data items at the topmost level and then progressively deepens the mining process into their frequent descendants at lower concept levels At first, this algorithm views the database as single-level which contains only itemsets from the first concept level. It uses the original Apriori algorithm to find association rules between these itemsets \(which, in our example, are categories Each time we find a new rule between 2 itemsets \(f g we test it for importance \(by support and confidence\ If it doesnêt pass the importance threshold then there wonêt be association rules between their descendents However if it does pass the importance tests, it means that there may be rules between their descendants. We take all the descendants of these itemsets from the next concept level and try to find a rule f2 g2 \(where f2 and g2 are subsets of f, g from the previous concept level\f we find a rule we immediately continue at next concept level in the same way until we donêt find interesting rules Implementation In implementation, this algorithm is like the Apriori algorithm for single-level databases presented in 2  T h e onl y  difference i s t h at afte r th e i m portance t e sts  i f  the rule between the 2 itemsets passes, it does the steps described in the following recursive function  function CheckDescendants\(k, lvl, f, g  for \(f2=1; f2<nr.of.itemsets.descented.from.f.on.lvl+1 f2 for \(g2=1 g2<nr.of.itemsets.descented.from.g.on.lvl+1; g2 if \(f2 g2 rule is interesting   Add.Itemset\(f2,g2\ L[k, lvl+1   CheckDescented\( k, lvl+1, f2, g2\;   //if f2 and g2 exist   Where  k Ö nr of items from a k-itemset  f,g are the itemsets from the f g rule  lvl Ö level where f,g are found  This function must be called before trying to find another rule at the same level \(lvl\ because we need to know exactly which subsets \(f and g\ were used in this rule Because f2 and g2 are derivations of the f and g subsets the transactions \(T\(k,lvl+1\in which they are found are actually some \(or all\ of the transactions in which f and g are found \(T\(k,lvl Thus, when the çCheckDescendants\(\é function is called we can send it a selection \(or just the IDs\of transactions from T\(k,lvl\The function wonêt have to scan the entire database to check for importance, it will just scan the selection of transactions. In fact, as we progress deeper, from on concept level \(lvl\ to the one following it \(lvl+1\the number of transactions should be smaller and smaller and scanning will be faster and faster In implementation, to obtain T\(k,lvl+1\we filter, from the previous transaction selection, only the transactions which contain items common to the f and g itemsets  V  PERFORMANCE STUDY & COMPARISONS  These algorithms donêt try to find rules between all subsets from the k-itemsets \(k>1\ remained after the prune step, [8 f i nd r u le s b e t w ee n de r i v a t i on s  o f t h e s u bs e t s  from the rules that were previously found to be interesting For example, if they find a rule at the first concept level, a rule between categories, they go deeper and try to find which subcategories that rule apply to If a rule doesnêt pass the importance threshold, then there wonêt be important rules between subcategories at the following concept levels To make this advantage more noticeable, we will compare the first algorithm to a similar multi-level Apriori algorithm described in [7  Th i s a l go r i t h m us e s  th e c a n d i d a te  g e n e r a t i on  algorithm in Apriori on each concept level. When it finishes with one level it moves on to the next level. We can say that this is a width-first algorithm and that the algorithms presented in this paper are depth-first 


137 Mirela Pater, Daniela E. Popescu    Market-Basket Problem Solved With Depth First Multi-Level Apriori Mining Algorithm On the database presented in the following example DFMLA algorithm will test the importance of the rules 1 2 1.1 2.1, 1.1.1 2.1.1, 1 3 and 2 3. Rule 1 3 and 2 3 wonêt pass the importance test and thus, the DFMLA algorithm wonêt test rules 1.1 3.1, 1.1 3.2, 2.1 3.1 etc contrary to the other algorithm which will eventually test the rules when it gets to the respective level    Fig.3.Multi-level Apriori vs. DFMLA. Performance comparison  An important disadvantage that DFMLA algorithm has is its memory usage. In a database with many concept levels when we get to the last level, TIDs for each previous level will be retained The studies were made on a multi-level database, created as presented at section 4. The database had 45000 database entries, 7500 transactions, each one having no more than 15 items; 750 distinct items which were encoded on 10 concept levels The experiments were conducted at a Pentium-IV machine with 512 MB memory at 2.8 GHz, running Red Hat Linux 7.3. The program was implemented in Java  VI  CONCLUSIONS  The scope of data-mining has been broadened by the study on the mining on multiple-level rules. The mining of multiple level rules can provide more information for the users and enhance the flexibility and power of data-mining systems This algorithm finds new rules by using the knowledge gained from previously found rules. If a rule fails at the first concept level many rules from the following concept levels wonêt be studied and thus,  the more concept levels a database has, the faster it will be to get results compared to other algorithms Storing the database in the primary memory is no longer a problem. On the other hand, storing the candidates causes trouble in situations, where a dense database is considered with a small support threshold. This is the case for any algorithm using candidates. Therefore, it would be desirable to look for a method which stores candidates in secondary memory. This is an obvious topic for future research Our conclusion is that DFMLA is a simple practical, straight forward and fast algorithm for finding all frequent itemsets  REFERENCES  1 Ag ra w a l  R   I m i e l i n s k i  T  a n d  S w a m i A    M i n in g  association rules between sets of items in large databases In Proc. of the ACM SIGMOD Conference on Management of Data pages 207Ö216, 1993 2 A g r a wa l  R   an d S t r i k a n t R    F as t a l g o r i t h m s  f o r m i n i n g  association rules In Proc. 1994 Int. Conf. Very Large Data Bases VLDBê95\ Santiago, Chile, 487-499, 1994 3  A g r a w a l  R and S t ri ka nt R   M ining seq u ential p a tt er ns   In Proc. 1995 Int. Conf. Data Engineering 3-14, Taipei Taiwan, 1995 4 ra wa l  R   M an n i l a  H   S r i k a n t R   T o i v o n e n H   a n d Verkamo A.I., çFast discovery of association rules In Advances in Knowledge Discovery and Data Mining pages 307Ö328, 1996 5 Dunh a m M H Data  M i nin g  Intr od uctor y a n d A d v a nc e d  Topics Prentice Hall, Pearson Education, Inc, Upper Saddle River, New Jersey, 2003  6  F r aw le y W.J  Pia t eet sk y S h ap i r o G   a n d M a th e u s  C  J  Knowledge discovery in databases: An overview   In G Piateetsky-Shapiro and W.J.Frawley, eds. Knowledge Discovery in Databases, 1-27, AAAI/MIT Press, 1991  7 Han J  an d Fu Y    Discove r y  of m u l t i p l e le v el association rules from large databases In Proc. 1995 Int Conf. Very Large Data Bases VLDBê95\ Zurich Switzerland, 420-431, 1995 8  Han J and F u Y M in ing Mu ltipl e le v e l  A s so cia t i on Rules in Large Databases IEEE Transactions on Knowledge and Data Engineering Vol.11, No.5, 1999 9 Ha n Y  F  Jiaw ei   D i s cov e r y  of mu ltipl e le v el  association rules from large databases In Proc. of the 21st International Conference on Very Large Databases \(VLDB Zurich, Switzerland, 1995 1 u hta l a Y  Kinen J    P o r k ka P    a nd Toivonen  H   Efficient discovery of functional and approximate dependencies using partitions.é. In ICDE pages 392Ö401 1998 1  H u h t al a Y  K a r k k a i n en  J Po r k ka P., an d  H   To iv o n en  TANE: çAn efficient algorithm for discovering functional and approximate dependencies The Computer Journal  42\(2\100Ö111, 1999 1  K n uth D  E   The Art o f  C o mp ut er P r og r a mmin g  V o l  3.é. Addison-Wesley, 1968 13 M a n n ila H  To iv o n e n H  an d V e r k am A  I    Discovering frequent episodes in sequences.é. In Proceedings of the First International Conference on Knowledge Discovery and Data Mining pages 210Ö215 AAAI Press, 1995 14 O z de n B   Ra ma s w a m y  S    a n d S i l b er s c ha tz A    C y c l i c  association rules.é.  In ICDE pages 412Ö421, 1998 [1  P a rk J. S., Chen M.-S., Yu and P. S., éAn effective hash based algorithm for mining association rulesé. In M. J. Carey and D. A. Schneider, editors Proceedings of the 1995 


138 SOFA 2009  3 rd International Workshop on Soft Computing Applications   29 July Ö 1 August    Szeged \(Hungary\ad \(Romania ACMSIGMOD International Conference on Management of Data pages 175Ö186, San Jose, California, 22Ö25, 1995 15  Par k  J. S   C h e n  M  S  an d  Y u P S  A n ef f ect i v e  h a s h  based algorithm for mining association rules.é In M. J. Carey and D. A. Schneider, editors Proceedings of the 1995 ACMSIGMOD International Conference on Management of Data pages 175Ö186, San Jose, California, 22Ö25 1995 1 R a jk u m ar N  Kar t hik M  R and Sivanandam S.N., çFast Algorithm for Mining Multilevel Association Rules IEEE Web Technology and Data Mining 687-692,   TENCON 2003 1 S a ras e re A O m i ecinsky  E an d  N a v a the S An  efficient algorithm for mining association rules in large databases In Proc. 21st Internatio nal Conference on Very Large Databases \(VLDB Zurich, Switzerland, Also Gatech Technical Report No. GIT-CC-95-04, 1995 1 t rik a n t R  and Ag ra w a l R M i n in g  g e ne r a liz e d  association rules In Proc. 1995 Int. Conf. Very Large Data Bases VLDBê95\ Zurich, Switzerland, 1995 19 R S r ik ant and R Ag raw a l M inin g  s e quent ial  p a tt er ns   Generalizations and performance improvements.é Technical report, IBM Almaden Research Center, San Jose, California 1995 20  To i v onen H S a m pling la r g e dat a bas e s  f o r asso ciati o n  rules In The VLDB Journal pages 134Ö145, 1996 2  Th o m a s S    B o da g a l a  S   A l s a bt i K    an d Ra n k a S   A n  efficient algorithm for the incremental updation of association rules in large databases. In Knowledge Discovery and Data Mining pages 263Ö266, 1997                             


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






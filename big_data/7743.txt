Disjunctive Combined Causal Rules Mining Manal Alharbi Computer Science and Engineering Department University of Connecticut Storrs, CT 06269-4155 manal.alharbi@uconn.edu Sanguthevar Rajasekaran Computer Science and Engineering Department University of Connecticut Storrs, CT 06269-4155 rajasek@enger.uconn.edu   Abstract Causal discovery is a well-studied problem due to an urgent need for systems that predict, explain, and make proper and necessary decisions in many domains including epidemiology, biology, medicine, economics, physics, and social sciences. Existing techniques such as learning Bayesian networks \(BNs\nd Randomized controlled trials \(RCTs\are expensive and time consuming. In addition, they only find single cause rules from certain data. There are numerous important applications wherein we have to generate disjunctive causal rules from uncertain data. In this paper we propose an algorithm called DCCRUD that employs frequent itemsets mining algorithms to discover disjunctive combined causal rules from uncertain data. To the best of our knowledge ours is the first paper to address this important problem. Discovering causal rules where targets are disjunctions of variables might be equally important. DCCRUD applies to uncertain databases We evaluate the performance of the proposed algorithms on real datasets Index Terms Data mining, Algorithms, Frequent itemsets Disjunctive rules mining, Causality, partial association, causal rule, Uncertain databases I  I NTRODUCTION  While traditional association rules mining algorithms identify the relationships among variables in general, the aim of causal discovery is to identify profound relationships such as “a change of antecedent is the cause for a change in the consequent”. Association rules mining uses the well-known support–confidence framework which does not necessarily signify causation [1 Fo r ex am ple th e  support–confidence framework can show that milk and eggs in the same basket are related but cannot indicate that buying eggs was caused by buying the milk. Causal relationships discovery is widely used in the prediction processes where the prediction of causes have been used to prevent harmful consequences [2  T h e  importance of discovering causal relationships can be felt in many areas, such as economics, physical, behavioral, medical biological, and social sciences. Thus, significant advances in exhibiting and finding causal rules have been made in many areas. One of the most powerful tools for causal discovery is the Randomized controlled trial \(RCT\ [5  RC T is a n  experimental approach, and th e main challenge in this approach is the difficulty of conducting experiments because of ethical concerns or cost issues [4 Causal  disc ov e r y  w ith  observational data is an alternative solution when the experimental approaches are infeasible. Due to a rapid expansion of observational data, researchers have focused on attempts to reduce costs and help in decision making by predicting vital indicators that prevent harmful consequences 4   In s p it e of a d v a n c es m a de in f i n d in g  cau s al  ru les exis tin g  methods are unable to handle big datasets. Several variations of causal discovery with observational data have been investigated in the literature. Most of the previous works were based on statistics [6-24   T h e m ain cha llen g e in th es e  approaches on observational data is that statistical correlations discovered from observational data may not really form a causal relationship [4    A  Causal Discovery Most of the existing studies [6-17 m ain ly f o cus on  inferring causal relationships in observational data using a directed acyclic graph  Bayesian networks\ or undirected probabilistic graphical models \(Markov networks\. It is known that Bayesian networks based formulations are NP-hard and therefore algorithms based on these are only applied on low dimensional data sets [17   C o n s train t bas e d app r oach es h a ve  been used as optimization methods as they do not search for a complete Bayesian network [18-22  Un f o rtu n ate ly th ey h a ve  two problems [3, 4  th ey on ly disc ov e r sin g le c a uses  and th e y  fail to discover causal relationships on non-fixed structures Integrating partial association tests along with association rules mining is a solution that has been introduced by [3, 4 and 21   T h ese s o lu ti on s lin k c a usality w ith c o n tin u ity  w h ere  the association between two variables is not affected by other variables. For example, it is reasonable to conclude that change of gender is the cause for salary differences, if there is always salary differences between male/female workers whatever the circumstances are \(e.g., different ages, domains and different qualifications\. In this case, the association between being female and receiving low salaries holds [4   The CR-PA algorithm [3 h a s b e en  pr o p o se d t o  dis c o v e r  causal relationships with both a single cause variable, and multiple cause variables B  Finding Frequent Patterns from Uncertain Data Association rules mining [30 is a w ell s tu die d p r ob lem  where the input is a database    consisting of  transactions Each is a subset of the set of all items An implication of the from  is said to be an association rule, where    and  An association rule has to satisfy two conditions to be of interest  The  support of the rule has to be at least minsup The s upport is  defined as the fraction of transactions that contain both X and Y  The confidence of the rule has to be at least user-defined threshold namely minconf The confidence is defined as the number of transactions in which both X and Y occur divided by the number of transactions in which X occurs  Unlike certain data where items in transactions are definite in terms of their occurrence in the data. In an uncertain database, we don’t know for sure which items belong to the transaction. We only know a probability for each possible item that this item belongs to the transaction [25-29  L et    be the set of all items of an uncertain dataset 2015 IEEE International Symposium on Signal Processing and Information Technology \(ISSPIT 40 


UDB that contains a set of transactions    Let be the probability that the transaction contains the item x, for any item x   The expected support of an itemset X can be defined as follows    A rule will be of interest if the expected support of the corresponding itemset  is at least   C  Disjunctive Association Rules Mining In several real life applications, rules in which both the antecedent and the consequent co nsist of disjunctions of items might be equally important. The problem of generating disjunctive rules has been introduced in the literature in the context of certain data [30, 31  In ou r p r evi o u s  w o rk 3 3    w e  introduced disjunctive rules from uncertain data for the first time and presented an algorithm called DRMUD In our DRMUD algorithm, we defined a k-disjunctive rule as      When item a occurs with enough support and confidence, one or more of the items   are also expected to occur. We defined the rule     to be interesting, if each of the rules   has enough minimum support. This is because when the rule  has enough support, then obviously the rule   also will have enough support whatever the support of the rule  is When the rule  does not have enough support, then the rule   may not be interesting even if the rule has sufficient support. To identify in teresting rules, we introduced two support thresholds minsup1 and minsup2 Here minsup1 is the minimum support that each of the rules  for 1  j   k-1 should have, and minsup2 is the minimum expected support that is required between the item a and the set of items    for the rule to be interesting DRMUD algorithm consists of two ph ases. In phase1, we mine pairs of items that have at least a minimum expected support  minsup1 In phase2, we use these pairs to generate kdisjunctive rules that satisfy the minimum expected support  minsup2  In this paper, we propose a novel approach that adopts some of the strategies from previous works on association rules mining [21  and  pa rti a l  ass o cia ti on  ru les min i n g 3  t o  discover causal relationships in observational data. Our new algorithm DCCRUD aims to discover disjunctive combined causal rules from uncertain. Our target consists of kdisjunctive variables, where k is the length of the rule and it is chosen by the user. Since previous works have shown that the vertical layout representation of a dataset helped to speed up the process of generating the candidate rules \(see e.g. [35    DCCRUD algorithm also uses vertical layout II  RELATED W ORKS  In this section, we introduce the statistical definition of correlation between two variables, and present the concepts for inferring causality from partial associations A  Support-Confidence Association Vs. Correlations Traditional support-confidence associations use downward closure property to reduce the search space Downward closure property deletes any superset of an infrequent itemset  In re a l i t y suppo rt c o n fi d e nce framework might be misleading since it ignores the negative correlations [3  T h e w ellk now n  Chi-square statistic test is widely used for testing the correlation.  Two items are said to be correlated or dependent when its Chi-square value is higher than a significance threshold  Unlike the traditional support-confidence associations that take advantage of downward closure property, correlation using Chi-square statistic test is upward closed in the itemset lattice. Upward closure property is a property of dependence correlation\ that states that if an itemset A is dependent, then its superset will be also dependent. Thus, the search space will be reduced since adding items to a correlated itemset A will not cancel the correlation [3  T h e  Chi-square statistic test is easy to calculate. However, it has two major limitations: first the expected values in all the cells in the contingency table must have a value greater than one; second, the expected values in at least 80% of the cells in the contingency table must be greater than 5. Brin, et al. [3 s o lv e d th is  pr o b lem by u s in g  the support-confidence  framework as an additional pruning condition for finding correlation rules. Zhou, et al. also used the support-confidence framework as an additional pruning condition for finding correlation rules [3  Th ey als o  u s e d  combined contingency tables for more than two variables instead of using multi-way contingency tables. Suppose we have three dichotomous variables gender \(female or male disease one \(having Rett syndrome or not\nd disease two having Alport syndrome or not\n the contingency table entries for cells like being female and having Alport  syndrome, and being male and having Rett syndrome will be close to zero, as it is very unlikely to be female and having Alport syndrome and being male and having Rett syndrome In the process of Causal discovery, we are more concerned with the positive outcomes of dichotomous variables. For instance, physicians are more interested in smoking subjects more than non-smoking subjects [3  Con s i d e r in g al l th e c ell s  with values close to zero will introduce many redundancies and subsequently unreliable results. Zhou, et al. [3 c all e d  any  association identified with a positive outcomes Chi-square value that is higher than a significance threshold as positive association. If the Chi-square value is less than a significance threshold then this will form a zero association B  Rules discovery using partial association tests As mentioned in the previous section, positive association plays an important role in identifying a Causal relation However, it is not easy to signify causality from correlations without human intervention [3   P a rti a l ass o ciat i o n t e st  2 3   24 is  a p o w e r f u l st atist i c a l  to ol th a t can  be u s e d t o t e st  conditional independence of random variables when a controlled experiment is impossible. It tests the association between two random variables I and J when a third random variable C is present. When the association between I and J does not hold, given the different combinations of C we refer to this as zero partial association. Zero partial association means, either C is a common cause of both I and J   or I causes C which causes J but there is no direct Causal relation between I and J 2  Brich  in 2 4  pr ov e d  th at  Mantel-Haenszel test 23  is an o p tim al m eth o d  f o r t e stin g a pa rt ial  ass o cia ti on  t e st  against the other methods. It excludes the non-causal relationships, and only the potential causal relationships are 41 


included. Thus, it is suitable for testing the partial association of Causal discovery [3  To t e st th e pa rtial ass o ciatio n   where x and y are two dichotomous random variables, and  we use the following equation        If the partial association is greater than a significance threshold then the association between  holds \(non-zero partial association\, and  is a Causal rule [3  N o t e th at th e  number of possible combinations of    where is the total number of variables. The worst memory usage and run time for conducting the partial test could thus be large. For instance, with  3 variables there are eight 2 2 possible contingency tables for the partial test. However instead of testing all the combinations, we only consider the items that come in the same transaction with or Those rows or columns in the contingency table with zero values are not considered [2  Z h ou  et  a l   3 h a ve p r op os ed th e CR PA algorithm for discovering causal rules in observational data The basic idea of the CR-PA algorithm is to identify positive associations using association rules mining as we have mentioned earlier. These positive associations are considered as causal hypotheses rules. Then, they employed the partial association tests on these association rules to exclude nonpersistent associations III  PROPOSED M ETHODS  In this section, we first present our proposed algorithm namely the DCCRUD algorithm for discovering disjunctive causal rules \(both single and combined\ from uncertain data Then, we discuss its time complexity Here are the components of the DCCRUD algorithm  Positive association: we use Chi-square statistic test to signify the positive association between two random variables  Cause effect relation: to test whether the positive association between two random variables is persistent or not, we use the well-known Mantel-Haenszel test   Combined casual rules: we use the F k-1 F 1 method to merge attributes in ascending order of variable IDs in order to generate combined rules from the zero associations sorted in ZA   Disjunctive causal rules: we use the same assumption as in our previous work on disjunctive rules mining DRMUD algorithm [3   w h ere ea ch cau s al pa ir i e     must have a  for 1  j   k-1 and the rule    must have a   where   A  Disjunctive Combined Causal Rules from Uncertain Data \(DCCRUD\ Algorithm                                                                                                             Phase 5: Generate the k-disjunctive combined causal rules                    Note is the value that each of the rules  for 1  j   k-1 should have to be a causal rule, and  is the value that is required between the item a and the set of items    for the rule to be interesting causal rule   stores the result of the partial test for each   B  Complexity Analysis Phase 1 the first step takes  time, where is the average number of  in a record, and is the number of records. Each  is allocated a bucket indexed with the same id as the  In a single scan through the database we can figure out for all 1-Varaibles. The second step takes time for only a single scan through the set of all 1variables is done The time complexity for this phase is    In phase 2 the algorithm generates frequent pairs using  method by merging a 1-frequent variables with a 1frequent variables in ascending order of item IDs to generate 2-frequent variables, and this can be done in linear time. Also 42 


DCCRUD counts the expected support for a new 2-variable itemset by making intersection between record lists. Due to ordering of the records this intersection can be done in time that is linear in the total length of the two lists Phase 2 takes     to find out positive and zero associated pairs using the  method    Where  number of variables and average size of each variable list In phase 3 DCCRUD creates the 2×2 contingency tables for each positive association pair with all combinations of all variables that are already associated with   and calculate the partial association test, using MantelHaenszel partial association test  To generate combined rules from the zero associations, in phase 4, we adopt the same strategy as in [3  T h e ru le   can be combined if both and have a zero association. This will reduce the search space since we will exclude all the positive associations from further combining. Based on observations in [3  if th e  ru l e  is an association rule but it fails in the partial test to be a causal rule, this means, the association between and is either interrupted by other variables, or the other variables are a common cause of both and Clearly, there is no direct causal relation between  and  Thus, it is improbable that combining another variable with the LHS will lead to a direct association. Moreover, any superset of a causal rule is co nsidered as a redundant rule, and doesn’t give any new information [3, 34   Th is w ill r e du ce  th e  search space since once a causal rule is discovered we will not generate any superset of this rule.  Also, the regular frequent association itemsets serve as pruning conditions that reduce the search space and time  Phase 3 and Phase 4 a re the most crucial in the algorithm because these phases are iterated. Phase 3, and phase 4 take time     In phase 5  following the same assumptions as in our proposed algorithm on disjunctive rule mining \(DRMUD 33   g i v e n a chi s q u a r e  cal c ulati on f o r tw o cau s a l  ru les i  e     the rule   must have a   and each rule  must have a   for 1  j   k-1  where In Phase 5, while considering the set S    if there is any j \(1 j k-1 such that   t j    then the set S is not considered  Phase 5 takes time     where is the size of the rule. Note that q q as   0,1 IV  EXPERIMENTAL  RESULTS We show the results of DRMUD algorithm [3 n de r th e  vertical format, and we show the comparison between our proposed algorithm and the algorithm in [3 o r s i n g le t a rg e t  under certain database A  Horizontal Vs. Vertical DRMUD algorithm In our previous work  w e  i n t r od uce d d i s j unct i v e r u l e  mining under uncertain database DRMUD algorithm Subsequently [3 w e sh ow ed th a t th e v e rt ic al a p p r oa c h  outperforms the horizontal approach in mining weighted frequent patterns for the case of conjunctions. Since the DRMUD algorithm was in horizontal format, and our proposed  algorithm is based on the idea of DRMUD  algorithm but under vertical format, we compare DRMUD in the two formats For the sake of comparison, we have used the same setting that we have used for the DRMUD algorithm. Both algorithms have been implemented and compiled using Microsoft’s Visual Studio C++ 2013, and run on an Intel\(R\ Core\(TM\ i7 3.40GHz PC with 8GB Main memory, operating on Microsoft Windows 7. We also have used the same dense dataset with 40,000 transactions, associated with 994 different items that we used for testing the performance of DRMUD in horizontal format. We have also run our vertical algorithm with the same values of k and configuration parameters: minsup1, and minsup2 that we used in horizontal format. Figure 1 shows a comparison between the vertical and horizontal versions of DRMUD in terms of run times, where the runtimes differ by the parameters specified by the users   Fig. 1. Comparisons between Horizontal and Vertical for DRMUD algorithms under 40k transactions associated with 994 different items B  CCRCD algorithm vs the CR-PA algorithm To the best of our knowledge, we are the first ones to introduce disjunctive causal rules from uncertain data, where our target consists of k-disjunctive variables \(where is the length of the rule and it is chosen by the user\. We have developed the algorithm CCRCD  for discovering combined causal rules from certain data. Both the CCRCD  algorithm and the CR-PA algorithm [3 dis c o v e re d th e sam e  cau s a l  ru les   We have used two datasets. Dataset1 is downloaded from [36   This dataset has also been used in [4  f o r dis c ov er in g  c a usa l  rules using PC 38  HITON-PC  n d CR-PA 3  algorithms  with eight attribute variables and one target variable, within 100k records. Dataset 2 has been generated using the software tool Tetrad [37 th at al low s th e c o n s t r u cti on  of a graphical model for inferring causal reasoning. It consists of 29 attribute variables and one target variable within 856 records. Table 5 shows the results for both CR-PA and CCRCD algorithms under dataset 1 and minimum support=0.05, and p-value= 0.05 \(95%\ Note that in the original data the names for the attributes were \(A, B, C, D, E F, G, H\, and the target na me was \(Z\e changed the attribute names to the values {1, 2…, 8}, and the target to the value {9  0 200 400 minsup1=0.007 minsup2=0.01 minsup1=0.0075 minsup2=0.015 minsup1=0.009 minsup2=0.02 Time in Seconds k=2 DRMUD Horizontal DRMUD Vertical 0 500 1000 minsup1=0.007 minsup2=0.01 minsup1=0.0075 minsup2=0.015 minsup1=0.009 minsup2=0.02 Time in Seconds k=3 DRMUD Horizontal DRMUD Vertical 43 


Table 6 shows the results for both CR-PA and CCRCD  algorithms under dataset 2 with minimum support=0.01, and p-value= 0.05 \(95%\ Here the attributes names are {1, 2 29},  and the target name is {30 Table 7 shows the results for both CR-PA and CCRCD  algorithms under dataset 2 with minimum support=0.01, and p-value= 0.1 \(90 Table 5: Dataset 1 Causal Rules  under p=0.05, min. support=0.05 CR-PA CCRCD B Z  2 9  C Z  3 9  F Z  6 9   Table 6: Dataset 2 Causal Rules  under p=0.05, min. support=0.01 Causal rule CR-PA CCRCD 3 30   6 30   22 30   23 30   27 30   29 30   11 28 30    Table 7: Dataset 2 Causal Rules  under p=0.1, min. support=0.01 Causal rule CR-PA CCRCD 2 30   3 30   6 30   15 30   22 30   23 30   27 30   29 30   9 17 30   11 28 30   C  DCCRUD algorithm  Since there is no existing algorithm for generating disjunctive combined causal rules from uncertain data, we have combined our method DRMUD algorithm [33 w ith  CR-PA algorithm a n d pr opo s e d t h e DCCRUD algorithm to mine disjunctive combined causal rules from data without uncertainty   DCCRUD  is implemented and compiled using Java Following is the execution environment  Intel\(R\ore\(TM\ i7 3.40GHz PC  8GB Main memory  Operating System is Microsoft Windows 7 For testing the performance of DCCRUD  over uncertain databases, we have used the following procedure We generated two datasets using [3 a ta s e t  1 co nsi s t s  of 5142 records with 20 attribute variables and five target variables, and dataset 2 consists of 26380 records with 40 attribute variables and ten target variables For each dataset, we have run our algorithms with different size of the rules and w and different configuration parameters of minimum expected support \(0.001, and 0.0009 and p1 value: 0.1 \(90%\, along with p2 value: 0.05 \(95 and p1 value” 0.025 \(97.5%\ p2 value: 0.01 \(99%\ble 8 shows the results of disjunctive single and combined Causal rules under p1-value= =0.025, p2-value 0.01  minimum support=0.001 with rule maximum size k=2  Table 8: Dataset 2 Disjunctive single and combined Causal Rules DCCRUD 5   13  23  6    24  14  21  7   19  23  8   4    10  21  3 16  21  12  22  17  22    Figure 2 shows the performance of our proposed algorithm. Note that the runtimes can vary based on other parameters provided by the users. Figure 3 shows the scale-up of the attributes. The run time increases as the number of attributes increases. Also, the run time decreases as the minimum support increases as is shown in figure 4 V  CONCLUSIONS Causal discovery is a well-known problem that also has been addressed using association rules mining under certain data. In our prior work [33 w e  w e re t h e  f i rs t to  in t r o d u c e  disjunctive rules mining from uncertain data. In this paper we have introduced and studied the problem of mining disjunctive combined causal from uncertain data. To the best of our knowledge we are the first ones to introduce this problem. We have proposed the DCCRUD algorithm to tackle this problem Our algorithm DCCRUD  works under vertical layout. We have presented theoretical and experimental results for the proposed method   Fig. 2. Performance of DCCRUD algorithm    0 0.1 0.2 0.3 0.4 minSup=0.001 minSup=0.0009 minSup=0.001 minSup=0.0009 Running Time \(seconds k=2 p1=0.1, p2=0.05 p1=0.025, p2=0.01 a\5142 Records, 20 attributes and 5 targets 0 0.5 minSup=0.001 minSup=0.0009 minSup=0.001 minSup=0.0009 Running Time \(seconds k=2 p1=0.1, p2=0.05 p1=0.025, p2=0.01 b\, 40 attributes and 10 targets k vs. time 0 0.5 p1=0.025 p2=0.01 p1=0.1 p2=0.05 p1=0.025 p2=0.01 p1=0.1 p2=0.05 Running Time \(seconds c\e-up of attributes, K=2 20 Attrib., 5 Targ 40 Attrib., 10 Targ minSup=0.001 minSup=0.0009 44 


 Fig. 3. Scale-up of attributes    Fig4. Run time Vs.  minimum support REFERENCES 1  L. Jiuyong, L. ThucDuy, L. Lin, L. Jixue, J. Zhou,S. Bingyu, "Mining Causal Association Rules", 2013 IEEE 13th International Conference on Data Mining Workshops \(ICDMW\- TX, USA - Dec. 7, 2013 to Dec. 10, 2013 2  J. Bowes, E. Neufeld, J. E. Greer,J. Cooke, "A Comparison of Association Rule Discovery and Bayesian Network Causal Inference Algorithms to Discover Relationships in Discrete Data", in Discrete Data, Proceedings of the Thirteenth Canadian Artificial Intelligence Conference -AI'2000 3  J. Zhou , L. Jiuyong,  L. Lin, L. Jixue, L. ThucDuy, S. Bingyu, W Rujing, " Discovery of Causal Rules Using Partial Association ", Data Mining \(ICDM\, 2012 IEEE 12th International Conference on 10-13 Dec. 2012 4  L. Jiuyong,  L. Lin, L. ThucDuy, "Practical Approaches to Causal Relationship Exploration", Springer International Publishing, 2015 SpringerBriefs in Electrical and Computer Engineering 5  TC. Chalmers, H. Smith, B. Blackburn, B. Silverman, B. Schroeder, D Reitman, A. Ambroz , "A method for assessing the quality of a randomized control trial". Controlled Clinical Trials 1981 6  I. Good, “A theory of causality,” British Journal for the Philosophy of Science 9, pp. 307–310, 1959 7  H. Reichenbach, “The principle of causality and the possibility of its empirical confirmation,”  Routledge and Kegan Paul, London, 1923 8  P. Suppes, “A probabilistic theory of causality,” North-Holland Amsterdam, 1970 9  G. Grahne, L. Lakshmanan, and X. Wang, "Efficient mining of constrained correlated sets," In Proc. 2000 Int. Conf. Data Engineering ICDE-00\, San Diego, CA, pp. 512-521, 2000   J. Pearl, and T. S. Verma, “A theory of inferred causation,” in Knowledge Representation and Reasoning: Proceedings of the Second International Conference, 1991, pp. 441–452   D. Heckerman, “A Bayesian approach to learning causal networks,” in UAI, 1995, pp. 285–295   D. Heckerman, “Bayesian networks for data mining”, Data Mining and Knowledge Discovery 1, pp. 79–119, 1997   S. Nadkarni and P. P. Shenoy, “A Bayesian network approach to making inferences in causal maps,” European Journal of Operational Research 128\(3\, pp. 479–498, 2001   J. Pearl, “From Bayesian network to causal networks,” in Bayesian Networks and Probabilistic Reasoning, pp. 1–31, 1994   M. R. Waldmann and L. Martignon, “A Bayesian network model of causal learning,” in Proceedings of the Twentieth Annual Conference of the Cognitive Science Society, 1998, pp. 1102–1107   J. Pearl, "Causality: Models, Reasoning, and Inference," Cambridge University Press, 2000   D. M. Chickering, D. Heckerman, and C. Meek, “Large-sample learning of Bayesian networks is NP-hard”, JMLR 5, 1287–1330, 2004   C. F. Aliferis, A. Statnikov, I. Tsamardinos, S. Mani, X. D Koutsoukos, “Local causal and Markov blanket induction for causal discovery and feature selection for classification Part I: Algorithms and empirical evaluation,” JMLR 11,pp. 171–234, 2010   S. Mani, G. F. Cooper, P. Spirtes, “A theoretical study of y structures for causal discovery,” in UAI, 2006, AUAI Press   J. P. Pellet, “Using Markov blankets for causal structure learning JMLR 9, pp. 1295–1342, 2008   C. Silverstein, S. Brin, R. Motwani, J. Ullman, “Scalable techniques for mining causal structures,” Data Mining and Knowledge Discovery 4 pp. 163–192, 2000   G. F. Cooper, “A simple constraint-based algorithm for efficiently mining observational databases for causal relationships,” Data Mining and Knowledge Discovery 1, pp. 203–224, 1997   N. Mantel and W. Haenszel, “Statistical aspects of the analysis of data from the retrospective analysis of disease”, Journal of the National Cancer Institute, Vol. 22, No. 4, pp. 719-748,1959   M. W. Birch, “The Detection of Partial Association, I: The 2×2 Case Journal of the Royal Statistical Society, Vol. 26, No. 2, pp. 313-324 1964   A. Motro, P. Smets, “Uncertainty Management in Information Systems”, ISBN 978-1-4615-6245-0, 1997   C. C. Aggarwal, and P. S. Yu, “A survey of uncertain data algorithms and applications”, IEEE Transactions on Knowledge and Data Eng 21\(5\: pp.609–623, 2009   T. Bernecker, H.-P. Kriegel, M. Renz, F. Verhein, and A. Z¨ufle Probabilistic frequent itemset mining in uncertain databases”, KDD pp.119–128, 2009   C. K. Chui, B. Kao, and E. Hung, "Mining frequent itemsets from uncertain data", The Pacific-Asia Conference on Knowledge Discovery and Data Mining \(PAKDD\, pp.47–58, 2007   C. K.-S. Leung, M. A. F. Mateo, and D. A. Brajczuk, "A tree-based approach for frequent pattern mining from uncertain data", PAKDD pp. 653–661, 2008   R. Agrawal, T. Imielinski, and A. N. Swami, “Mining association rules between sets of items in large databases”, Proceedings of ACM SIGMOD International Conference on Management of Data, ACM Press, Washington DC, pp.207-216, May 1993   A. A. Nanavati, K. P. Chitrapura, S. Joshi, and R. Krishnapuram Mining generalised disjunctive association rules”, CIKM, ACM, pp 482–489, 2001   M. C. Sampaio, Fernando H. B. Cardoso, Gilson P. dos Santos Jr.,Lile Hattori, “Mining Disjunctive Association Rules”, 15 aug. 2008   M. Alharbi, P. Periaswamy, S. Rajasekaran,"Disjunctive rules mining from uncertain databases", Computers and Communication \(ISCC 2014 IEEE Symposium on 23-26 June 2014   S. Brin, R. Motwani, C. Silverstein, “Beyond market baskets Generalizing association rules to correlations,” In: Proceedings ACM SIGMOD International Conference on Management of Data, Tucson Arizona, USA, May 13-15, pp.265–276. ACM, New York – 1997   M. Alharbi, S. Pathak S. Rajasekaran,"Frequent Itemsets Mining on Weighted Uncertain Data", Signal Processing and Information Technology \(ISSPIT\, 2014 IEEE Symposium on 15-17 December 2014   http://nugget.unisa.edu.au/Causalbook   http://www.phil.cmu.edu/tetrad   M. Kalisch P. B¨uehlmann and M. H. Maathuis. Variable selection for high-dimensional linear models: partially faithful distributions and the PC-simple algorithm. Biometrika,  7:261–278,2010   C. F. Aliferis, A. Statnikov, I. Tsamardinos, S. Mani, and X. D Koutsoukos. Local causal and Markov blanket induction for causal discovery and feature selection for classification Part I: Algorithms and empirical evaluation. Journal of Machine Learning Research 11:171–234,2010   0 0.5 p1=0.025 p2=0.01 p1=0.1 p2=0.05 p1=0.025 p2=0.01 p1=0.1 p2=0.05 Running Time \(seconds d\e-up of attributes, K=3 20 Attrib., 5 Targ 40 Attrib., 10 Targ minSup=0.001 minSup=0.0009  0.2 0.3 0.33 0.39 0.001 0.0009 Running Time \(seconds e\me Vs. min. support, K=2, p-values p1=0.1, p2=0.05  20 Attrib., 5 Targ  40 Attrib., 10 Targ   0.28 0.32 0.37 0.41 0.001 0.0009 Running Time \(seconds f\Run time Vs. min. support,K=3, p-values p1=0.1, p2=0.05  20 Attrib., 5 Targ  40 Attrib., 10 Targ 45 


Retail is a sparse dataset  consists of product sales data from retail stores Each transaction in the Retai dataset represents purchase information from one consumer at a time The details of the datasets are presented in gure 6 The programming language used to implement all the three algorithms is java and run in 3.3 GHz Intel processor 4 Gbyte memory and Windows 7 32bit OS Figs 7…9 show results of runtime experiments regarding the real and synthetic datasets shown in gure 6 In these gures we can observe that IHT-growth outperforms the others in all of the cases IHT-growth uses the proposed header tree structure to store the 1-frequent items instead of the older header table to minimize access times to search items As a result its advantages have a positive effect on reducing runtime in whole experiments Especially in the case of Retail dataset the difference of runtime between our algorithm and the others is much more than the other datasets  In all experiments FP-growth shows the worst performance Note that IHT-growth method can be used with any fptree mining to improve its ef“ciency We suggested here two methods to implement the new algorithm If we dont know the number of items in advance the First method is suggested In this experiments we used the second method By using the second method we can create a more ef“cient BSHTree because all the items with highest frequency will be appeared on the top of the BSHTree By using this method the run time can be improved by minimizing the searching time of items while sorting out the transactions VI CONCLUSION This study proposes an ef“cient transaction processing method during the transaction scanning time By applying the ef“cient binary search tree the mining time drastically reduced The new transaction sorting method is also improves the performance of mining The experimental results show that our algorithm outperforms the fp-growth and IFP-growth two well known and widely used algorithms Here we used a BSHTree after the rst scan to store the items with support count While using the BSHTree we used the actual names of items as keys This method can be applied to improve the mining process with any frequent itemset mining algorithm which is using a header table R EFERENCES  Jia wei H an Jian Pei and Y iwen Y in Mining Frequent P atterns without CandidateGeneration,SIGMOD 00 Proceedings of the 2000 ACM SIGMOD international conference on Management of data.Pages 1-12  Gw angb umPyun a Unil Y u n a  K eun Ho Ryu  E f cient frequent pattern mining based on Linear Pre“x tree Knowledge-Based Systems 55 2014 125…139  Y uh-JiuanTsay a T ain-Jung Hsu a Jing-Rung Y ub,FIUT  A n e w method for mining frequent itemsets,Information Sciences 179 2009 1724 1737  K e-Chung Lin I-En Liao  Zhi-Sheng Chen An impro v e d frequent pattern growth method for mining association rules Expert Systems with Applications 38 2011 5154…5161  F an-Chen Tseng An adapti v e approach to mining frequent itemsets ef“ciently Expert Systems with Applications 39 2012 13166…13172  R Agra w al T  Imielinski A.N Sw ami Mining association rules between sets of items in large databases in Proceedings of the ACMSIGMOD Conference on Management of Data pages 1993 pp 207…216  R Agra w al R Srikant F ast Algorithms for Mining Association Rules very Large Data Bases\(VLDB 1994 487499  Xiaobing Liu K u n Zhai W itold Pedrycz An impro v e d association rules mining method,Expert Systems with Applications 39 2012 13621374  Qiao yongwei,Y ang Hui Dong T ingjian,Research On QAR Data Mining Method Based On Improved Association Rule,Physics Procedia 24 2012 1514-1519  T  Hu S.Y  Sung H Xiong Q Fu Disco v ery of maximum length frequent itemsets Information Sciences 178 1 2008 69-87  G Lee U Y un K Ryu Sliding windo w based weighted maximal frequent pattern mining over data streams Expert Systems with Applications 41 2 2014 694-708  S.K T anbeer  C.F  Ahmed B.S Jeong Y  Lee Ef cient single-pass frequent pattern mining using a pre“x-tree Information Sciences 179 5 2008 559583  V S Tseng C.W  W u B.E Shie P S Y u  UP-Gro wth an ef cient algorithm for high utility itemset mining Knowledge Discovery and Data mining KDD 2010 253-262  T  W u  Y  Chen J han Re-e xamination of interestingness measures in pattern mining a uni“ed framework Data Mining and Knowledge Discovery DMKD 21 3 2010 371-397  J Han H Cheng D Xin X Y an Frequent pattern mining current status and future directions Data Mining and Knowledge Discovery DMKD 15 1 2007 55-86  Zaki Mohammed J Naren Ramakrishnan and Lizhuang Zhao Mining frequent boolean expressions application to gene expression and regulatory modeling International Journal of Knowledge Discovery in Bioinformatics IJKDB 1.3 2010 68-96 1084 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 


375 6  R. Meo, G. Psaila, & S. Ceri 223A new SQL-like operator for mining association rules,\224 in Proceedings of the 22 nd International Conference on Very Large Data Bases Conference \(VLDB\2221996  Bombay, India, September 1996, pp. 122-133 7  H. C. Tjioe, & D. Taniar, \223Mining association rules in data warehouses,\224 International Journal of Data Warehousing and Mining vol. 1, no. 3, 2005, pp. 28-62 8  T. Imielinski, L. Khachiyan, & A. Abdulghani, \223Cubegrades generalizing association rules,\224 Data Mining and Knowledge Discovery vol. 6, issue 3, 2002, pp. 219-257 9  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223Enhanced mining of associati on rules from data cubes,\224 in Proceedings of the 9 th ACM International Workshop on Data Warehousing and OLAP \(DOLAP\2222006 Arlington, VA, 2006 pp. 11-18 10  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223OLEMAR: an online environment for mining association rules in multidimensional data,\224 Data Mining and Knowledge Discovery Technologies vol. 2, 2007, pp. 1-36 11  M. T. Fisun, G. V. Gorban, \223Research and implementation syntactic algorithms create OLAP-cubes,\224 Transactions of Kherson National University no. 2\(38\, 2010, pp. 110-117. \(in Ukrainian 12  M. T. Fisun, G. V. Gorban, \223Models and methods of construction of OLAP systems for object-ori ented databases,\224 Information Technology and Computer System s, no. 1 \(209\, 2014, pp. 41-45 in Russian 13  G. V. Gorban, \223Application of B*-trees for creating and calculating of OLAP-cubes using combinatorial algorithm,\224 Technological Audit of Production and Reserves no. 5/4 \(13 2013, pp. 10-12. \(in Ukrainian  


paying a price of a slightly worse ratio for subsets Taken together the price of having more subsets is preferred because subsets contain only items actually in the assembly while superset and overlap patterns also contain unrelated items The 002rst and second row of 002gure 8 correspond to the instance and the pattern-based approach for graded synchrony The third corresponds to the instance-based approach for binary synchrony Comparing the diagrams for unrelated patterns our graded method detects all injected patterns 050\002rst and second rows\051 while the binary method also produces unrelated pattern In 050Borgelt et al 2015\051 it is demonstrated that the instance-based approach yields slightly better results than the pattern approach However this approach does not consider the precision of synchrony Surprisingly using only the pattern-based approach with a graded notion of synchrony yields a better ratio for overlap and superset patterns 7 CONCLUSIONS In this paper we presented a method to detect frequent synchronous patterns in event sequences using a graded notion of synchrony for mining patterns in the presence of imprecise synchrony of events constituting occurrences and selective participation 050incomplete occurrences\051 Our method adapts methods presented in the literature to tackle selective participation using binary synchrony especially the instancebased approach which looks at instances of patterns to improve the detection by removing instances that are likely chance events checking the precision of synchrony of these instances We demonstrate in our experiments that using a graded notion of synchrony for support computation helps to simplify the detection of selective participation because a pattern-based approach yields better results or at least equally good results as an instance-based approach This is a considerable advantage since identifying the individual pattern instances is costly and thus it is desirable to avoid it ACKNOWLEDGMENTS The work presented in this paper was partially supported by the Spanish Ministry for Economy and Competitiveness 050MINECO Grant TIN2012-31372\051 and by the Principality of Asturias through the 2013-2017 Science Technology and Innovation Plan 050Programa Asturias CT1405206\051 and the European Union through FEDER funds REFERENCES Abeles M 0501982\051 Role of the cortical neuron Integrator or coincidence detector Israel Journal of Medical Sciences  18\0501\051:83\22692 Borgelt C 0502012\051 Frequent item set mining In Wiley Interdisciplinary Reviews 050WIREs\051 Data Mining and Knowledge Discovery  pages 437\226456 050 J Wiley  Sons Chichester United Kingdom 2 Borgelt C Braune C and Loewe K 0502015\051 Mining frequent parallel episodes with selective participation In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  Gijon Spain Atlantis Press Borgelt C and Picado-Muino D 0502013\051 Finding frequent synchronous events in parallel point processes In Proc 12th Int Symposium on Intelligent Data Analysis 050IDA 2013 London UK\051  pages 116\226126 Berlin/Heidelberg Germany Springer-Verlag Dudoit S and van der Laan M J 0502008\051 Multiple Testing Procedures with Application to Genomics  Springer New York USA Ezennaya-G 264 omez S and Borgelt C 0502015\051 Mining frequent synchronous patterns with a graded notion of synchrony In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  pages 1338\2261345 Gijon Spain Atlantis Press ISBN 050on-line\051 978-94-62520-77-6 Hebb D O 0501949\051 The Organization of Behavior  J Wiley  Sons New York NY USA Kernighan W and Ritchie D 0501978\051 The C Programming Language  Prentice Hall K 250 onig P Engel A K and Singer W 0501996\051 Integrator or coincidence detector the role of the cortical neuron revisited Trends in Neurosciences  19\0504\051:130\226137 Louis S Borgelt C and Gr 250 un S 0502010\051 Generation and selection of surrogate methods for correlation analysis In Gr 250 un S and Rotter S editors Analysis of Parallel Spike Trains  pages 359\226382 Springer-Verlag Berlin Germany Mannila H Toivonen H and Verkamo A 0501997\051 Discovery of frequent episodes in event sequences In Data Mining and Knowledge Discovery  pages 259\226 289 Springer New York NY USA 1\0503\051 Picado-Muino D and Borgelt C 0502014\051 Frequent itemset mining for sequential data Synchrony in neuronal spike trains Intelligent Data Analysis  18\0506\051:997\226 1012 Picado-Muino D Borgelt C Berger D Gerstein G L and Gr 250 un S 0502013\051 Finding neural assemblies with frequent item set mining Frontiers in Neuroinformatics  7 Picado-Muino D Castro-Le 264 on I and Borgelt C 0502012\051 Fuzzy frequent pattern mining in spike trains In Proc 11th Int Symposium on Intelligent Data Analysis 050IDA 2012 Helsinki Finland\051  pages 289\226300 Berlin/Heidelberg Germany Springer-Verlag 


Rossum G V 0501993\051 Python for unix/c programmers copyright 1993 guido van rossum 1 In Proc of the NLUUG najaarsconferentie Dutch UNIX users group  Torre E Picado-Muino D Denker M Borgelt C and Gr 250 un S 0502013\051 Statistical evaluation of synchronous spike patterns extracted by frequent item set mining Frontiers in Computational Neuroscience  7 Tsourakakis C Bonchi F Gionis A Gullo F and Tsiarli M 0502013\051 Denser than the densest subgraph Extracting optimal quasi-cliques with quality guarantees In Proc 19th ACM SIGMOD Int Conf on Knowledge Discovery and Data Mining 050KDD 2013 Chicago IL\051  pages 104\226112 New York NY USA ACM Press Zaki M J Parthasarathy S Ogihara M and Li W 0501997\051 New algorithms for fast discovery of association rules In Proc 3rd Int Conf on Knowledge Discovery and Data Mining 050KDD 1997 Newport Beach CA\051  pages 283\226296 Menlo Park CA USA AAAI Press 



AN INVESTIGATION OF NEURAL NETWORKS I System Description Richard J McDuff Patrick K Simpson David Gunning FOR F-16 FAULT DIAGNOSIS We will report results of our ongoing research exploring the use of artificial neural networks ANNs for F16 flight line diagnostics ANN\222S are based upon the methods of in formation processing that might be used in neural circuitry rather than those of a conventional computer A 
significant aspect of neural networks is their ability to develop associ ations simply from examples ANN\222S hold the promise of solving difficult logistics problems such as multiple fault diagnosis prognostication changing configurations and en vironments and inaccurate diagnosis attributable to incom plete and/or flawed rules We tested three representative ANN\222S to see which type worked best for our problem We chose back propagation BPN and counterpropaga tion CPN because they are considered to be two of the more promising pattern matching paradigms The binary adaptive resonance theory 
I ART1 was picked because it leams faster than CPN or BPN and has on-line adaption i.e does not have to be totally retrained every time a new pattern is discovered On-line adaption is a powerful at tribute allowing new associations to be immediately incor porated into the knowledge base on the flight line or wher ever needed This paper explains the advantages and drawbacks to each network tested and describes how we trained them using historical flight line data 
Of the three ANN\222S examined ART1 proved to be the most appropriate and was able to produce multiple symptom to multiple fault diagnoses 1 INTRODUCTION There are several problems that plague existing military diagnostic systems Multiple fault diagnostics  one symptom leads to several faults many symptoms lead to one fault or many symptoms lead to many faults  is currently being performed with systems that are brittle and slow Because of the need for time-critical flight-line re 
sponse available symptom data is either misinterpreted or unused  often leading to the incorrect removal of a sys tem\222s component Every new weapon system must devel op its own diagnostic system resulting in slowly devel oped and costly systems Lastly when a weapon system goes through a configuration change, a costly process of di 351 2  0?0-035i 1 1     _   agnostic system development for the new configuration be comes 
necessary to keep the diagnostic system up to date We are examining the use of neural networks l as a potential method of solving these maintenance and di agnostics problems We have approached diagnostics from a pattern matching perspective in that we have con structed an input pattern from symptoms and matched that symptom pattern to an appropriate output pattern that cor responds to the fault that occurred An operational sketch of this approach is shown in Figure 1 INPUT PATTERN SYMPTOM I1111 
I t rttt OUTPUT CLASS FAULT FIGURE 1 An illustration of the neural network approach to diagnostics Input pattem symptoms are passed to a two-layer feedback neural network that determines whick class the input belongs within Once the input class is determined the outputs \(faults as saciated with that class are displayed The most sophisticated neural network pattar classifiers Adaptive Resonance Theory networks will automatically add new 
classe when they are needed After an extensive comparative analysis of several key neural network paradigms we have developed a neu ral network-based diagnostics systeh that addresses each of the previously stated problems This system is tar geted for eventual integration with the Air Force Human Resources Lab\222s Model-based Diagnostic Aiding System MDAS These preliminary results hold the potential promise for a generic weapon system diagnostic tool for any arbitrary weapon platform produced by any branch of the service i.e MlA1 F-16 ATF, ATA, SSN-21 etc 


Our efforts sought to answer eight key questions 1 How should the mining data for the networks be prepared 2 What is the most accurate way of representing the data 3 Which neural networks are most appropriate for 4 What is the proper hardware to use 5 How well did the chosen network perform 6 How can we maximize the speed of this network 7 What is the optimal user interface design 8 How can we provide multiple fault output probabili ties that elnulate an MDAS probability table out these problems and put 2 DATA ACOUISITION PREPARATION AND REPRESENTATION 2.1 DATA ACQUISITION The database used for training the neural networks is contained in the F-16 Tactical Interim CAMS And RE MIS Reporting System TICARRS 2 This database was acquired from the initial flight-line debriefing and the corrective actions taken Each database entry contains in formation for each discrepancy symptom-fault pair The TICARRS database was transformed into a neural net work training set that consisted of binary-valued symp tom-diagnosis pairs The TICARRS database we received was not com plete and contained many incorrectly entered discrepan cies In addition many database entries did not contain a sufficient symptom description, often omitting important in formation such as the state of the plane at fault time and any intermediate tests that were conducted that led to a successful diagnosis Because of this poor set of data it became imperative that the neural network was able to learn and classify symptoms with inherently noisy and missing information 2.2 DATA PREPARATION Although the TICARRS database has problems it is the only source of actual F-16 symptom-diagnosis data and a good representation of what can be expected from any modem weapon system A large portion of the time spent on this project was dedicated to data preparation We created a neural network training set by filtering through the TICARRS database and correcting or discard ing unsuitable entries From the TICARRS database we chose three key fields to represent the symptoms 1 MFL  Maintenance Fault List codes 2 FRC -Fault Reporting Codes; and 3 WD  When Discovered codes A combination of these three fields is used as the input symptoms for the neural network The MFL code is the only symptom acquired directly from the plane The FRC code when recorded out to the sixth digit, can represent a specific pilot complaint and is therefore useful symptom information. Sometimes, however, the FRC code is derived from the MFL code and is therefore redundant The WD code is not a formal" symptom but is associated with the problem being diagnosed, therefore it is used The remain ing fault information, such as the air force base the aircraft serial number, etc was not used because of the data anal ysis time constraints although in a fielded system it might be beneficial Also from the TICARRS database we chose two key fields to represent the fault that occurred 1 WUC -Work Unit Code; and 2 AT  Action Taken AT\code A four digit WUC specifies which Line Replaceable Unit LRU was involved, and a five digit WUC indicates which Shop Replaceable Unit SRU was involved The AT code signifies what type of action was taken on the unit repre sented by the WUC The narratives in both the discrepan cy symptom and action taken fault\portions of each re port sometimes contain useful information but since these are not formally or consistently encoded they are not used A complete description of the symptom and fault codes found in the TICARRS database is found in Table 1 We acquired six months of fire control system data and prepared it for neural network training From an initial set of 5,182 TICARRS entries only 1,662 usable entries were found to be usable We divided the usable discrepan cies i.e the historical data into two groups the training set  a group of all but the last three weeks of database entries 1464 entries and a test set  the last three weeks of database entries 198 entries Although each of the database entries is usable each entry is not necessari ly accurate In many instances the repair listed in the da tabase was not what actually fixed the problem Fortu 352 


MFL  uarias of ha leaas followed by he numbers There are 24 possible thm letter combinmions used in our system and so the vecta has 24 doff bits for them There PIC a maximum of 341 three Lgit numbers and so the vector has 341 doff bits for each There are cosily a thwsand MFL codes Example MFL FCR 003 FRC  consists of 8 digits of which we use only the middle 4 The middle four digits am sist of 8 number pair and tbm two reparate digits There are 100 possible two digit number wmbinmims for the pair and so the veaor has 100 possible odoff bits There are 27 on/off bits e41 fa the two separm leaa or mo digits Thae are over a thou sand FRC coded psiblr Emmwlr FE 9463AFM WD  amsirta of 8 single digit which M cithcr be 8 lmcr or a number There are 36 pos Example WD D WUC  consists of a 5 or 6 digit number separated into a 2 digit number followed by 3 dig iu which M eitha be 8 later or a number The 2 digit number and the 3 single digits we each aorrd 81 is m the output vecta sible leaas or digits and so there arc 36 doff bits for the WD ExamDlr WC 74AKB AT  amsina of 8 single digit which M cib bc 8 letter or a number and was smed as Em AT R is in the output veaa TABLE 1 DESCRIPTION OF TICARRS DATABASE ENTRIES nately this was not a problem our neural network ap proach is able to handle such noise inherently 2.3 DATA REPRESENTATION 2.3.1 Choosing a Representation Scheme One of the primary difficulties with choosing a neu ral network pattern recognition approach to diagnostics is data representation Because neural networks expect fixed length patterns i.e vectors to be presented during training and use a considerable amount of careful thought and planning is required to develop input symptom and output \(fault\representations Three representation schemes were examined for our data 1 variable-unit representations 2 intermedi ate-unit representations and 3 value-unit representa tions The first scheme variable-unit representation represents each symptom or action taken by a single neu ral network processing element or vector component whose value is the symptom code Using this scheme a processing element PE in a neural network\222s input layer represents all MFL numbers lOOO and its value would represent the MFL\222s ordinality As an example the MFL number 312 would be represented by a PE value of 312 An advantage to this representation is that it eliminates the need for an extensive analysis of the data to find all possible inputs and outputs This representation also re quires a smaller input and output vector dimensionality which will speed up the compute time for each pattern pre sentation Conversely such a representation creates a more difficult mapping because the low dimensional pat tern space is often linearly inseparable The more nonlin ear the mapping, the more difficult it is to acquire an accu numbers and/or letten that are transfamed into a binuy repnrentation amenable to nw ral networks The resulting input represmution is a 555 element vhr of binary values rate mapping It is felt that this data representation would require a highly nonlinear mapping leading to extensive training time Hence this method was not pursued any further The third representation scheme value-unit repre sentation assigns every possible input or output a sepa rate PE This method would produce the least difficult map ping because the high dimensional pattern space is the closest to being linearly separable This representation however would have unacceptably slow computation times because the vectors are so large In addition such an approach would require enumeration of all possible in puts or outputs, a task beyond the scope of this effort. Be cause of the computation and data analysis requirements of this approach, encoding it is infeasible for our purposes The second representation scheme intermediate unit representation represents the symptoms and actions taken with an encoding somewhere between the first and third schemes We chose this method for the input be cause it represents a compromise between exhaustive da ta analysis and extensive computation time The mapping is assumed to be linearly inseparable yet computationally achievable within the projects time constraints 2.3.2 Input and Output Representations Figure 2 shows how we represented the symptom input as a 555-element binary-valued vector Because the input representation is well understood and static, .the transformation from data base entry to binary vector was the only preprocessing necessary The fault output representation was more diffi cult Because both single and multiple faults can be asso ciated with the same symptom input the output repre sentation has to maintain a running set of statistics that describe the likelihood of each possible fault given a partic ular input In addition, the number of faults is not known apriori hence it is necessary to develop a dynamic output representation that can grow with the number of faults be ing encoded in the network To handle each of these issue 


y1\222 y2\222  Jk\222 r I YP  OUTPUT PATTERN CLASSES we encoded the output data in a dynamically sized 3 di mensional array that tabulates all faults that occur Fig ure 3 illustrates what information is stored with each pat tern class processing element h the network and Figure 4 shows the overall picture of the input and output represen tation with the neural network Class k Statistics Tal number of murrencen of this class 4 List of faults associated with this class Fault name Fault name Number of occLencen Number of ohmences x Fault 223k occman~s k Qnk 3 NEURAL NETWORK IMPLEMENTATION 3.1 WHICH NEURAL NETWORK IS BEST Choosing the proper neural network is essential to the success of this experiment To determine which net work is best suited to perform our pattern classification task requires a complete enumeration of the qualities de sired in the overall system These qualities include ability to immediately classify symptoms ability to handle noisy and incomplete data ability to not favor heavily occumng symptoms ability to recognize novel symptoms ability to immediately incorporate new symptoms ability to develop new symptom classes over rarely occurring symptoms and Originally we had intended to use the backpropagation 4 network but quickly realized that its inability to detect suf ficiently novel symptoms and its inability to immediately incorporate new symptom information were too limiting for its use Another neural paradigm that we considered was the Learning Vector Quantization network 5 and its counterpropagation extension 6 Although these net works do provide an ability to determine the novelty of a symptom they suffered from an inability to immediately in corporate new symptoms and are not useful in this applica Figure 4 The overall view of the neural network representation scheme for diagnostics Ihe TICARRS data base envy is transformed into a 555-element input that represents hat symptom During both leaming and operation the symptom is classified and each class has a set of dynamically changing statistics as well as a list of all the faults associ ated with the class tion What was needed was a network that would allow new patterns to be immediately incorporated i.e on-line learning and could distinguish between novel and known patterns The answer is the binary adaptive resonance theory network \(ART1 7 3.2 BINARY ADAPTIVE RESONANCE THEORY ART11 The binary adaptive resonance theory ART1 ANS  introduced by Carpenter and Grossberg  is a two layer nearest-neighbor classifier that stores an ar bitrary number of binary spatial patterns Ak  akl  a kn  k  1 2  m using a fast-learning version of the competitive learning law ARTl learns on-line operates in discrete or continuous time and has the topology shown in Figure 5 where the n FX PES correspond to Ak\222s com ponents and the p Fy PES each represent a pattern class The connections from the FX PES to each Fy PES w 1J form reference vectors For example the connections from the FX PES to the Fy PE b J form the reference weight vec tor W J  wlj w2j  w nJ   The connections from the Fy PES to the Fx PES form the pattern vectors For example the pattem vector attached to the jfh Fy PE is V  v J 11\222 vj2  Vjn Although ARTl is principally a two layer architec ture it is also transparently framed within two sub systems  the attentional subsystem and the orienting 354  


  kl kn a Figure 5 Topology of the binary adaptive resonance theory ARTI neural network There are inter-layer feedback connections w and vji between the FX and Fy PES that facilitaw a resonation upon proper match between ended patterns V  vjl vj __ Y  and input pattems Ak  akl a __ ah The FX PES accept inputs from the environment and the Fy PES each represent a pattern class During operation the Fy PES employ an invisible on-center/off-surmund competition that is used U choose the proper class for the presenred input These lateral interactions are shown in the figure as shaded selfexciting  and neighbor-inhibiting  connections to emphasize this point To keep the presentation uncluttered all connections are not shown there is ac tually a connection from each FX PE to each Fy PE and vice-versa a shaded negative lateral connection from each Fu PE to every other Fy PE and a shaded positive recur rent connection from every Fy PE to itself subsystem The attentional subsystem only allows the Fx PES to be engaged when an input pattern is present The orienting subsystem removes Fy PES from the set of allowable winners when an insufficient memory-input match occurs  an operation termed short-term memory STM reset These subsystems are implemented as in herent operations during pattern processing In essence ARTl conducts a serial search through the encoded patterns associated with each class trying to find a sufficiently close match with the input pattern If no class exists a new class is made The test for a sufficient match between the top-down feedback pattern and the bottom-up input pattern is called hypothesis testing An operational overview is provided in Appendix One and the equations are provided in Appendix Two 3.3 PROBABILITY POST-PROCESSING By tracking the number of occurrences of each class in the ARTl network see Figure 3 and by tracking the number of occurrences of each fault that occurred within each class we are able to provide a frequency-based prob ability measure for each fault within a given class In addi tion as the diagnostic system is used and the number of fault occurrences increases the statistics become more re liable As an example assume that we are operating the system and we have just classified a symptom as belong ing to class 123  y123 The hypothetical statistics asso ciated with 123 are shown in Figure 6 This class has only three faults associated with it 1 FCC FAILED 2 INS NEEDS SERVICE r Y 1 Yt  Y1*3 9 Y OUTPUT PATTERN CLASSES and 3 INS FAILED The to  Class 123 Statlstics otal uumher of occurrences of this class 43 List of faults associated with this class Fault Fault FCC FAILED Fault Fault INS NEEDS SERVICE Fault Fault INS FAILED Number of occurrences 17 Number of occurrences 12 Number of occurrences 35 Tigure 6 An example of how the output class statistics are used to provide probahilit nformation concerning which fault is associated with each symptom The statistics show hat this class has occurred 43 times Of the 43 occurrences of this class 17 times fault I ccurred 12 times fault 2 occurred and 35 times fault 3 occurred Using this information he probabilities of each fault being associated with the given symptom are 39.5 28.6 md 81.4 respectively number of times that this class has occurred is 43 Each of the three faults occurred 17 12 and 35 times respec tively To calculate the probability of each fault simply requires dividing the number of occurrences for each indi vidual fault by the total number of occurrences of the class For example the probability that fault 1 is associ ated with the symptom is 17/43  0.395 or 39.5 4 CONCLUSION We have developed an extension of ARTl that is used to implement an on-line learning multiple-fault di agnostic system that improves its performance with use ARTl was found to be the most appropriate neural network for this application because it is able to quickly incorporate new pattems it can inherently handle noisy and missing data and it provides immediate responses Also with the addition of the output pattern statistics we can overcome database ambiguities  a very difficult problem in classical AI systems ARTl is targeted for eventual use in diagnostic systems such as the Air Force Human Resources Lab's Model-based Diagnostic Aiding System MDAS The potential for this system is not strictly limited to this system Because of the flexibility in construction and use this system is easily applied to any weapon plat form as a generic diagnostic engine When addressing the issue of flexibility it is important to remember that neural networks can easily fuze data from several sen sors  an ominous task for most diagnostic systems 


Information fusion comes easily because the network learns to map input vectors to pattern classes irrespec tive of the actual information contained within the input data As an example acoustic stress information and in frared images could be combined as inputs to a heli-rotor diagnostics system In this paper we have described the system that has been implemented to perform fault diagnosis of F-16 fighters on the flight line In part I1 of this paper 8 we will discuss the results of our simulation experiments with actual TICARRS data and we will outline some areas of fu ture exploration ACKNOWLEDGMENTS We would like to thank J Harold McBeth and William Bertch for their insightful comments and helpful critiques of this work This work was supported by Air Force Human Resources Lab  Combat Logistics Branch contract number F33615-87-GO15 MIS-DD Program Dave Gunning  POC REFERENCES  11 Simpson P Artificial Neural Svstems Foundations Paradims ADDlications and Imdementations Pergamon Press Elmsford NY expected late 1989 release 2 TICARRS User\222s Manual Organizational and Interme diate Levels Volume I and 11 Air Force Logistics Com mand LOCflLPO Wright Patterson Air Force Base OH 45433  Walters D Response mapping functions tion and analysis of connectionist representations ceedinm of the IEEE First International Conference on Neural Networks Volume 111 pp 75-86 SOS Press San Diego CA 1987 Classifica  Werbos P Beyond Regression New tools for predic tion and analysis in the behavioral sciences Harvard Uni versity Ph.D Thesis 1974  Kohonen T Self-Organization and Associative Mem m Springer-Verlag: Berlin 1984 6 Hecht-Nielsen R Counterpropagation networks  geedines of the IEEE First International Conference on Neural Networks Volume II pp 19-32, 1987 7 Carpenter G and Grossberg S A massively parallel architecture for a self-organizing neural pattern recognition machine ComDuter Vision GraDhics and Image Under standing, 37, 54-115, 1987  McDuff R  Simpson P 1989 An investigation of neural networks for F-16 fault diagnosis 11 Simulation ex periments in preparation 1 General Dynamics Electronics Division P.O Box 85310 MZ 7202-K San Diego CA 92138  Air Force Human Resources Labs Combat Logistics Branch, Wright-Patterson Am OH 45433 356  


I Resent an qut pam     h to the Fx PES where Fx  xl  xn Aaivity at the Fx lays   t    La is denotcd by darkened PES t t FY FX 2 Each Fx PE acuvauon a sends a signal through its long-term memory LTM connections wi to evq Fy PE bJ This flow of acuvation is holed by the darkened regions flowng from Fx to Fy t   L t t  t 3 Each Fy PE unnpctcs with the others using compuitive intaactions until only one Fy PE remains active This operation in essene amounu to finding the reference vecm W that most closely matches the input paw AL This activity is denoted by thc darkened Fy PES   ta 4 wmg Fy PE say yJ sends a topdoam s~pl through IIS LTM ConnectlONI vJi back to FX and possibly ueates a new sa of Fx PE acuvauolls llus acuvity is repcsentcd by the darkened region FY FX t k1 w L t t g from Y 5 Themput Al   h IS canpared wth the topdoam  Fy to  5 arlted by the g FB PE and the difference Hmmg d~stana is measured bctwcm Ak and X Thc FX activity is repnsented by the darkened PES and the comparison oprauon is denoted by the box FX MPUT-ToP-DOWN CoMP*RISoN k1 ti h I If the duYerence between X and Ak exceeds a p&m"ed value the FY FX vigilance parameto then the wmmg Fy PE does not represent the poper class for Ak and it is removed from the sa of allowable Fy mas If there are still Fy PES rrmmmg in step 2 otherwse remit an the sa of allowable w~nners go to uncommitted Fy PE and encode Ak onto this PE's reference vector FY FX ca ENCODE PATTERN ONTO WEIGHTS  If the diffacncc bawem the two dvatiau dou not ex the vigilanc parameter then y is represents the pmper dass for the input pattun 4 and th inpu p.rtem is then merged with the smcd pm APPENDIX Two BINARY ADm RLWNAh'CE THEORY  EQUATIONS SYSTEM VARIABLES Note  all vectors are binary valued VI  vJ1. vJ2  vJn  topdown pattern \(templare recalled L I max I.D]<B<I+D A.C M from the winning Fy PE yr Ak during steps 1 3 Ak n VJ during steps 4 6 x  XI x2  Xn  INITIALIZATION Dimt A Inequality 0  w  L  L-l+n Template Learning Inequality B-I  vji S 1 Fy CLASS SEARCH J  index set of allowable 0 otherwise Fy PE winnm Yj  Tk  i Wik Fy PE RESET RULE Remove the winning Fy PE y from thc sct of allowable winnm if 1x1  c xi  I when 0  p S 1 is the vigilance paramter me closer p is to 1 the finer the classification granularity LEARNING LAWS FAST LEARNING Bottom-Up Lenrning Only change the connections that abut the winning PE yJ a Top-Down Laming Only change the connections emanating from thc winning PE yJ VJi  U\(L-I+IXI 


267  Feature dimensions  on which the generated rules may be dimensioned such as merchant, time and area  A volume cube C v is sufficient for deriving the instances of rule X 336 Y if it has a base dimension that represents the base of the rule, and the association conditions for qualifying X 331 Y are definable on C v For deriving cross-sale association rules from cube SaleUnits an association condition can be  for each base and feature dimension C v product A\ > 0 331 C v product B\ > 0 If the association conditions used to compute multidimensional P X  307 P Y  are definable on C v then another kind of condition, called antecedent conditions that are used to compute multidimensional  P X    are also definable on C v such as  for each base and feature dimension C v product A\ > 0 Association cube The association cube C a  for rule X 336 Y gives a volume-based measure of multidimensional association relationships that are computed from the volume cube C v and is used to derive the confidence cube and the support cube of association rules. More exactly, it maintains dimensioned P X 307 P Y i.e the number of base elements that satisfy X 331 Y Usually C a is dimensioned differently from C v In the cross-sale association rule example, the association cube is defined as  CrossSales product, product2, customer_group, merchant time, area  A cell of this cube, CrossSales product 221A\222 product2 221B\222  customer_group \221 engineer\222 merchant 221Sears\222 time 221Jan98\222 area 221Los Angeles\222\eans that there are 4,500 customers who are engineers, who bought item A as well as item B, at a Sears store in Los Angeles in Jan98 For an association cube the item dimensions underlie the counts for deriving association rules, such as dimensions product and product2 for the above CrossSales cube. The dimension product2 has the same set of values as product and we call it the mirror dimension  of product We introduce a mirror dimension simply because the cross-sale association rule involves more than one element of the item dimension  The base dimension   such as the customer dimension  underlies the base of rules. Unlike the volume cube, the association cube does not necessarily have to be dimensioned by the base dimension However, we can dimension rules by a derived dimension, each value of which identifies a group of base dimension values at bottom levels. In the cube CrossSales shown above, we introduce the hierarchical dimension customer_group   which has levels customer_profession\222, \221customer_category\222 and 'top'. A relation is also defined for relating customers and customer groups. For example, a value of the derived customer_group dimension, say, \223engineer\224, is used to identify a group of individual customers who are engineers  An association can cube also have underlying feature dimensions  such as merchant, time and area Population cube and base cube The population cube C p and the base cube C b for rule X 336 Y are also derived from the volume cube C v  C p is used to measure dimensioned P X i.e the numbers of base elements satisfying X  C b is used to represent dimensioned B For the above cross-sale rules, the population cube is defined as NumOfBuyers \(product, customer_group, merchant, time area A cell of this cube NumOfBuyers product 221A\222 customer_group \221 engineer\222 merchant 221Sears\222 time 221Jan98\222 area 221Los Angeles\222  10000  means that there are 10,000 customers who are engineers, and who bought item A in Los Angeles in Jan98. The base cube is defined as  NumOfShoppers \(customer_group, merchant, time, area Note that NumOfShoppers is not aggregated from NumOfBuyers as a single customer may buy multiple products Confidence cube and support cube The confidence of rule X 336 Y defined as P X 307 P Y  P X  and the support, defined as P X 307 P Y B are represented as cubes C f  and C s  C f  is derived from C a and C p and C s is derived from C a  and C b They have the same dimensions as C a For the above cross-sale rules the confidence cube and support cube are defined as  Confidence \(product, product2, customer_group, merchant time, area   Support  product, product2, customer_group, merchant time, area Figure 2 shows the cubes related to cross-sale association rules, with one slice of each cube. The volume-cube is generated from transactions; the 


association-cube, base-cube and population-cube are derived from the volume cube; the confidence-cube is derived from the association cube and population cube and the support-cube is derived from the associationcube and base-cube. The slices of these cubes shown in Figure 2 correspond to the same list of values in dimension merchant, time, area and customer_group  Multidimensional and multilevel rules Representing association rules by cubes and underlying cubes by hierarchical dimensions, naturally supports multidimensional and multilevel rules. Also these rules are well organized and can be easily queried  First, the cells of an association cube with different dimension values are related to association rule instances in different scopes. In the association cube CrossSales cell CrossSales product \221A\222, product2 \221B\222  customer_group 221engineer\222, merchant \221Sears\222, area \221Los Angeles\222, time 221Jan98\222 represents the following multidimensional rule x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x,\221B\222  275 customer_group = \221engineer\222, merchant = \221Sears\222, area 221Los  Angeles\222, time =  \221Jan98\222 If this cell has value 4500, and the corresponding cell in the population cube has value 10000, then this rule has confidence 0.45 Next as the cubes representing rules can have hierarchical dimensions, they represent not only multidimensional but also multi-level association rules. For example, the following cells CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221Jan98\222 CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221 Year98 222 represent association rules at different area levels \(i.e the city level and the state level\d different time levels \(i.e., the month level, the year level x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221Jan98\222 x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221 Year98 222 The cell CrossSales\(product \221A\222, product2 \221B\222,  customer_group 221top\222, merchant \221top\222, area \221top\222,  time \221top\222 represents the customer-based cross-sale association rule for all customers, merchants, areas, and times in the given range of these dimensions, expressed as x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222 4.3  Generating Association Rule Related Cubes The basic task of our OLAP based association rule mining framework, either at the GDOS or at an LDOS is to convert a volume cube i.e. the cube representing the purchase volumes of customers dimensioned by product  area etc, into an association cube a base cube and a population cube These cubes are then used to derive the confidence cube and the support cube of multidimensional association rule instances. The following general steps are involved in cross-sale association rule mining 267  Roll up the volume cube SaleUnits by aggregating it along merchant, time, area dimensions 267  Derive cube NumOfBuyers from SaleUnits based on the antecedent condition SaleUnits 0 267  Populate cube NumOfShoppers by the counts of customers dimensioned by merchant, area  time not by product\at satisfy the antecedent conditions 267  Derive cube CrossSales from SaleUnits based on the association conditions SaleUnits  product  p 1  0 and SaleUnits  product2  p 2 0 267  Derive cube Confidence and cube Support using cell-wise operations 214  Confidence = CrossSales  NumOfBuyers 214  Support  CrossSales  NumOfShoppers  Cubes Confidence  Support  CrossSales are dimensioned by product  product2 customer_group,merchant  time, area NumOfBuyers is dimensioned by product  customer_group, merchant time, area  NumOfShoppers is dimensioned by customer_group, merchant  time, area Rules with confidence and support that exceed specified thresholds  may be considered interesting 4.4. Rules with Conjoint Items Cubes with conjoint dimensions can be used to represent refined multidimensional association rules For example, using OLAP, we can derive association rules across time  Time-variant or temporal association rules such as 


x 316 Customers buy_product\(x,\222 A\222, \221 Jan98\222  336 buy _product\(x, \221B\222, \221 Feb98\222   275 area = \221Los Angeles\222 can be used to answer such questions as \223 How are  the sales of B in Feb98  associated with the sales of A in Jan98 224 The items in this rule are value pairs of dimensions product and time In order to specify this kind of association rule we introduce a conjoint dimension product, time and mirror it with dimension product2, time2 This allows a cell in the association cube to cross two time values. Accordingly, the cubes related to association rule mining are defined as follows Association cube  CrossSales.2 \(<product, time>, <product2, time2 customer_group, merchant, area  Population cube  NumOfBuyers.2  \(<product, time>, customer_group merchant, area Base cube  NumOfShoppers.2  \( customer_group, merchant, area Confidence cube Confidence.2 \(<product, time>, <product2, time2 customer_group, merchant, area Support  cube  Support.2  product, time>, <product2, time2 customer_group, merchant, area  The steps for generating these cubes are similar to the ones described before. The major differences are that a cell is dimensioned by, besides others product, time and product2, time2 and the template of the association condition is  SaleUnit s  product p 1 time t 1  0 and  SaleUnits  product2 p 2 time2 t 2  0 where, in any instance of this condition, the time expressed by the value of time2 is not contained in the time expressed by the value of time The template of the antecedent condition is SaleUnits   product p 1 time t 1  0 In general, other dimensions such as area may be added to the conjoint dimensions to specify more refined rules 4.5. Functional Association Rules A multidimensional association rule is functional if its predicates include variables, and the variables in the consequent are functions of those in the antecedent.  For example, functional association rules can be used to answer the following questions, where a_month and a_year are variables q  What is the percentage of people in California who buy a printer in the next month after they bought a PC x 316 Customer buy_product\(x, \221PC\222, a_ month 336 buy_product\(x, \221printer\222, a_month+1  275 area = \221California\222 q  What is the percentage of people who buy a printer within the year when they bought a PC  x 316 Customer: buy_product\(x, \221PC\222, a_ year 336 buy_product\(x, \221printer\222, a_year 275 area = \221California\222 To be distinct, we call the association rules that are not functional as instance association rules; e.g x 316 Customer: buy_product\(x,\222 PC\222, \221Jan98\222 336 buy_product\(x,\222 printer\222, \221Feb98\222  275 area =  \221California\222 Time variant, functional association rules can be derived from time variant, instance association rules through cube restructuring. Let us introduce a new dimension time_delta that has values one_day, two_day 205, at the day level, and values one_month, two_month, \205, at the month level, etc. Then, let us consider the following functional association rule related cubes Association cube  CrossSales.3 \(product, product2, customer_group merchant, area, time_delta  Population cube  NumOfBuyers.3 \(product, customer_group, merchant area Base cube  NumOfShoppers.3 \( customer_group, merchant, area Confidence cube  Confidence.3 \(product, product2, customer_group merchant, area, time_delta Support cube  Support.3 \(product, product2, customer_group, merchant area, time_delta The association cube CrossSales.3  can be constructed from CrossSales.2   The cell values of CrossSales.2  in the selected time and time2 ranges are added to the corresponding cells of CrossSales.3 For example, the count value in cell  CrossSales.2\(<PC, Jan98>, <printer, Feb98>\205 is added to cell \(bin CrossSales.3\(PC, printer, one_month,\205 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



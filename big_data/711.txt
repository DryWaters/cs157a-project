 A Rigorous Methodology for Security Architecture Modeling and Verification   Yomna Ali American University in Cairo yomnas@aucegypt.edu Sherif El-Kassas American University in Cairo sherif@aucegypt.edu Mohy Mahmoud American University in Cairo mohym@aucegypt.edu    Abstract This paper introduces a rigorous methodology for 
utilizing threat modeling in building secure software architectures using SAM \(Software Architecture Modeling framework\ and verifying them formally using Symbolic Model Checking. Security mitigations are expressed as constraints over a high-level SAM model and are used to refine it into a secure constrained model. We also, propose a translation from SAM Secure models into the SMV model checker where the threats and the elicited security properties from the threat modeling process are used as inputs to the verification phase as well.  This method is developed with the aim of bridging the gap between informal security requirements and their formal representation and verification 
1. Introduction There is a lack of a well-defined process for the analysis, architecture and design of secure software systems t th e sam e tim e, th e lack of f o rm ality in  defining security requirements makes it harder to verify that they are met by the underlying security architecture. In this paper, we propose a rigorous methodology for building and verifying secure system architectures guided by the process of threat modeling that is performed with both architecture and verification in mind. Security constraints are expressed as mitigations and are used as suggested by  in ref i n i n g a h i g h lev el arch itectu re in to a s ecu re 
architecture model. The resulting secure model is translated to a model checker for verification and output from the threat model is also utilized in verifying that the security properties elicited from the threat model are satisfied by the architecture 2. Related Work Our research intercepts with several areas of security engineering, all aimed at the early integration of security in the software life cycle; they are Adversary Modeling, Architecture Modeling and Architecture Verification. In Adversary modeling several methods have been devised in order to model the goals of the adversary and the means he will use 
to achieve these goals. Attack trees o alorien ted analysis d m i s u s e cas e s 5] are all f o rm s of  adversary modeling, targeting the elicitation of security requirements. Threat modeling, also a form of adversary modeling and utilized by Myagmar et al  an d How a rd an d L e Blan c [7] pres e n t s a systematic way of determining the threats to a software system. Threat modeling starts with an initial system decomposition that could be achieved using data flow or UML activity diagrams. This decomposition is useful in identifying assets that need to be protected, their access points, and their 
vulnerabilities. After stepping through each asset, and identifying possible threats as suggested by Xu and Nyga a rd an d L e Blan c [7 My ag m a r et al  s in g th e S T R I DE th reat categ ories 7 th reats  could be documented in a variety of ways \(like threat trees, or threat outlin h reat m odelin g h a s a wider-scope than the attack modeling techniques that consider only the attacker's perspective because system-specific threats require deeper analysis of the unique qualities of the system being modeled [6 Most of the above mentioned adversary modeling techniques lack two aspects: \(1\ey leave it open as to how this modeling process will affect the choice of 
architecture components, or how they could be captured in the architecture and design phases when as Haley et al dicate: th e elaboration  of  requirements and architecture should proceed in parallel, each influencing the other  \(2\ey mostly lack a formal means by which these security properties could be modeled, traced, and verified in the resulting secure architecture Xu et al address the first concern by suggesting utilizing misuse cases in guiding the choice of architecture components. Use/misuse case diagrams are used for deciding on candidate components. They use a tabular approach of components in the rows and 
the use/misuse cases utilizing them in the columns, to decide on the services that the system must provide and prevent the ways that the system might be misused h en  u s in g a f i s h e y e  diag ram of th e candidate architecture, the components that need change are highlighted in size or in color according to the number of interactions that each component has Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


 from the table. This can help system designers later decide on the best fitting candidate architecture However, the lack of formality in their approach would make it harder to trace and verify the security requirements in their resulting architecture Lamsweerde et al d L a m s w eerde 11 address the second concern, as they use temporal logic for formally specifying their security goals Anti-models are introduced in a y  of  defining anti-goals as opposed to system goals. Antigoals are derived using obstacle analysis extended to handle malicious obstacles building on the KAOS framework for generating and resolving obstacles to requirements achievement. Anti-goals are derived through goal negation of the CIA patterns, which are in turn instantiated to objects of the object model Through progressive refinements using techniques such as goal negation, terminal anti-goals can be derived, which can be used to identify antirequirements and vulnerabilities. Later, these antigoal trees are used to build the object and agent antimodels and at the end, alternative countermeasures are derived to augment the primal model of security goals a m s w eerde [10, 11] addres s th e importance of exception handling at the requirements level and therefore maintain their analysis at the goal level. In our research, we also utilize linear time temporal logic for security property specification however through the use of a new threat modeling template, with specific architecture additions and utilizing formal definitions, we continue to follow the requirements from analysis to initial design and its verification to make sure that we have a process for continually verifying and refining the architecture model using security property specifications. In our proposed methodology, the outcome of threat modeling is used to both influence the architecture and verification phases, and at the same time, the outcome of the verification phase can reveal new threats from flawed design uncovered by the tests thereby refining both the threat and architecture models accordingly For architecture modeling, Xu and Nygard propose an approach for modeling threats as Petri nets and mitigations as aspect-oriented Petri nets thereby providing a step towards the formal specification and verification of security requirements and mitigations. SAM, the Software Architecture Modeling framework, can also be used as suggested by Deng et al. [2 to p r o v id e a m u ltilevel architectural model with dual notation \(Petri nets and temporal logic\for "describing different aspects of architecture level design such as structure behavior and constraints". Fu e a variation of the SAM framework called SO-SAM: a service-oriented software architecture model and an extension of the SAM model specifically for modeling web services applications. Deng propose that desired security properties should be expressed as constraints or policies over the SAM high-level architecture using temporal logic. These constraints are then used to further refine the software architecture by decomposing e h i g h lev el architectural model As for verification, and given a petri-net based architecture model, both Xu and Nyga d Deng et al. [2 suggest r eachab ility analy sis f o r  security architecture verification. Whereas Fu et al 12 sugge st tr a n sla ting the a r c h ite c t ur e m o d e ls into  one of the model checking languages, and presenting the checker with logical properties \(such as liveness and deadlock freedom\erify that they are satisfied by the translated models. Unlike reachability analysis, model checking does not require the generation of all states before properties can be examined. Therefore it does not suffer from the state explosion problem In order to verify an architecture model using a model checker, a mapping between the architecture and the model checker language has to be defined Tanuan [14 sugge sts utiliz i ng m o d e l c h e c ki n g in  verifying the constraints in the UML specifications where a specific mapping between UML and SMV is proposed to verify UML specifications. At the same time, others suggest the mapping of SAM petri net behavior models and property specifications into SMV. For example, He et al pro pos e u tilizing symbolic model checking for verifying correctness of an architecture specification in SAM. They suggest translation guidelines for translating petri net behavior models into SMV and then test CTL properties against the translated transition system for verifying the architecture specification. He et al. [16  also propose a translation procedure of SAM behavior models into SMV Most of the above proposed methods for earlier security integration usually target either the phases of requirement specification or architecture modeling but not both, failing to formally trace security requirements from the requirement analysis phase to architecture, design, and verification phases.  At the same time, there is a lack of a rigorous translation methodology specifically targeted for translating the SAM models into SMV and a lack of a verification method targeted at verifying security properties in the presence of threats using symbolic model checking where most research is targeted at verifying correctness and safety properties. In this paper we show that we can express security properties formally using temporal logic over an SAM architecture Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


model, as well as propose a translation methodology between the SAM architecture model and its security properties and the SMV model checker, for verifying that the security properties are met by the architecture 3. Methodology The methodology presented in this paper builds on the work of Xu and Nyga g et al. [2], F u  et   d My ag m a r et al. [6 T h e goal of this research is to guide the process of secure architecture modeling and verification by performing threat modeling th e sof t w a re lif e cycle during the requirements analysis phase. We propose a new threat modeling template that allows the designer to specify architectural artifacts and constraints as mitigations along side the security solutions of the classical threat models h e template also allows the designer to specify the security property specifications that the resulting system should meet if the threat is truly mitigated For architecture modeling, the threat model's architectural mitigations and constraints could be used to refine a high-level architecture model into secure behavior models. Whereas for architecture verification, the threat model's logical property specifications as well as the threat descriptions could be used as inputs to the verification phase to verify that the threats do not violate the security properties under the provided secure architecture model. This way, threat modeling could rigorously influence both secure architecture modeling and verification Threat models give threat descriptions, and provide security mitigations as well as elicit security property specifications. In order to bridge the gap between informal threat descriptions and formal architecture modeling, we propose formally specifying mitigation constraints in temporal logic over the high level Service-Oriented Software Architecture Model \(SOSAM\ed by Fu et al h es e con s train t s  could then formally guide secure architecture decomposition \(as proposed by Deng The resulting architecture model, represented by SAM Petri net behavior models is verified as Fu et al 12  a n d H e e t a l   1 6  sugge st b y tr a n sla ting it into a  high-level model checking language \(where it could be checked for the absence of threats by verifying the stated security properties\. We suggest for this purpose a translation methodology between the SAM Architecture model and the SMV model checker Counter examples provided by the model checker can help the designer identify the problem and refine both the threat and architecture models accordingly The proposed methodology lik e that suggested by Hall et al. [17  attem p ts to b u ild co rrectn ess in to  every step by suggesting a rigorous requirements definition, formal architecture modeling using the Software Architecture Modeling framework \(SAM and formal verification of the resulting architecture against the security property specifications using model checking.  Figure 1, shows the steps of the proposed methodology Figure 1. Proposed Methodology  Step 1: High-level Architecture Build a high-level architecture of the system. Figure 2, shows the e-company server side only of a high level architecture of a shopping cart application proposed by Fu  et al pos ed of t h e  Warehouse and Order components and their interface input/output ports \(petri net nodes responsible for communication with other components or system parts\. Components are numbered and petri net ports are concatenated with numbers denoting which components produce/consume their tokens. For example request_7 is an input interface port to Warehouse component \(number 7\at receives a request token to be consumed by the component whereas response_72 is an output interface port that sends a response token from warehouse component to another component numbered 2 in the model \(not shown in figure  Step 2: Threat Modeling Perform threat modeling on the given architecture where threats to assets and access points are identified and classified based on the STRIDE categories. Fill the proposed threat modeling template with the security threats and their respective mitigations. This template enhances the classical m  w h ere s e c u rit y tec hn iqu e s s u c h as  authentication, authorization, encryption, etc Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


 specified as mitigations -- with the ability to specify architectural mitigations, logical constraints, and property specifications. These enhancements utilize a combination of formal notation, using first order temporal logic, and informal English descriptions Step 3: Building Secure Behavior Models Translate each mitigation to an equivalent Petri net m bu ild a com pon en t beh a v i or m odel using the new transitions and the new places suggested by the mitigation, and the constraints imposed over existing or new transitions  Figure modified from  Figure 2 High level SAM Architecture of ECompany  Step 4: Building the Constraint Architecture Model \(CRM  Build a constraint architecture model for the entire architecture by plugging in the component behavior models at their proper places in the high-level architecture  For each new security technique specified as a  mitigation, insert a black-box new component in the detailed architecture at the proper location  Use system wide constraints to link the new components to existing components according to the provided policy constraints. These system wide constraints are too realized using new transitions and places  For each mitigation realized by a new component if the component is a black box off-the-shelf security solution, we insert a place-holder for the component with its interface ports without refining its internal structure. Otherwise, we refine it by applying threat modeling to it \(go back to step 2 Step 5: Verification  Start translating the SAM model into SMV to perform model checking  Use the SAM high-level architecture to provide the structure for the SMV model by dividing it into system, composition, and component modules, as well as connectors between components  Translate each component behavior model into a component module using our suggested translation methodology  Translate the LTL security properties specified by the threat model into CTL and insert them into the SMV model  Transform each threat into a set of parameters that change the initial marking of the model  Check to see if the security properties are satisfied by the given model, to determine if the architecture is secure given the corresponding threats or not Step 6: Refinement Use counter examples provided by the model checker to refine the threat and architecture models  3.1. Threat Modeling the SAM Architecture Model The proposed threat model integrates the classical form of threat models where security techniques are specified as mitigations, with a new model where architectural constraints, components, or artifacts are specified as mitigations as well. These architectural mitigations are used to guide the refinement of the SAM model into secure constraint behavior models The architectural nature of our threat model facilitates integrating application-security threats resulting from implementation flaws along side the classical security threats resulting from compromising the confid entiality, integrity or authenticity of the system as a whole. A classical threat modeling template would at minimum include a threat Title, a threat Category according to STRIDE model, and the mitigation technique \(access control encryption, etc\he new threat modeling template enhances the classical model with the following architecture and verification-related additions  Threat Type threats could be either Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


 o  Component Threats These are threats that are specific to a component, examples are business logic threats  such as price or quantity tampering  o  Composition Threats These are threats that involve more than one component in the same composition. Examples are threats resulting from a flawed communication between components inside a composition, causing for example a validation bypass o  System-wide Threats These are threats that apply to an entire system \(i.e. the output of the system as a whole will be affected by such a threat\or example a threat to the whole web service with all its respective components, like a spoofing identity threat, or an elevation of privilege threat Threat Target Name of the architectural artifact that the threat could apply to, it could be the name of an entry/exit point of a component, a composition, or the entire system Mitigations Mitigations could be either o  A Logical Constraint   An intermediate component constraint  This could be realized by a logic constraint enforced over an existing transition in the High level Petri net or by adding a new transition/place to the architecture and applying this constraint to it  A system wide constraint  enforces a policy governing interactions between components: expressed as a constraint over one or more of the system components, or the entire system o  An Architectural Mitigation An architectural mitigation enforces a certain control flow. For example, what places should be enablers of a certain transition o  A security technique A security technique could be any of the standard techniques used to provide for security, examples are: firewalls content inspection, access control, or encryption modules  Location/Realized By This entry should specify where the mitigation should be applied: either inside the component \(if a constraint\ween components \(if a system-wide constraint\At the same time, it could specify how it will be realized by either imposing the constraint over an existing transition, or by adding a new transition to the component's internal architecture, in which case we should specify what places are in its preset enablers\ the mitigation is a new component the designer should specify its interface input and output ports, as  well as what components it will interface with  Security property specification If the mitigation is a logical constraint, it could be expressed inside a security property specification using LTL \(Linear Time Temporal Logic\his property could be later used to verify the absence of the threat. LTL describes how the state of the world evolves over time thereby focusing on the ordering rather than the exact timing of events. Temporal formulas are constructed from predicate symbols \(equality and propositions\nction symbols, constants variables, the logical operators         and e quantifiers  and  d the temporal operators Always Eventually, and O: Next   Table 1, shows an example of a component application threat, which is the threat that a customer purchases products at a lower price. This threat, also suggested by Xu and Nyga th e possibility of a customer changing the price of the purchased product to reduce the amount of payment he has to make. The type of mitigation is two fold  Add a component constraint  that is a constraint on the internal behavior of the component. For example, to be able to mitigate this sort of attack we need to compare the prices sent in the purchased products' list \(at port prdLCT\ith the prices stored in the warehouse's product database  An  Architectural mitigation enforces a certain control flow\: Price validation should not occur unless we have validated that the request is a valid checkout request \(at port checkout  The component property specification is derived, by using only interface input/output ports of the component and the new component constraint, and it indicates that when we have a checkout request and a valid price, ordGen_78 should eventually be enabled  3.2. Decomposing the SAM Architecture Model Given the high level architecture and the new transitions and places/nodes over which mitigating constraints are enforced, we could start decomposing the SO-SAM high level architecture to the corresponding constraint architecture models. A behavior model of each component results from refining its high level architecture using the threat model mitigations augmented with the functional behavior model. This could result in a behavior model for each component Starting from the input interface ports of each component in the SO-SAM model \(Figure 2\we use the architectural mitigations and constraints of the threat model, to refine the high-level architecture Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


 Table 1. Component Threat Example Threat /Description/Type Threat Target Mitigation Location Security Property Specification Component Threat  Customer purchasing products at a lower price  Description A customer may change the price of the purchased items in the HTML form at the client side, to pay less than he should pay Type Tampering Warehouse Component  Entry points checkout request checkout_7 prdLCT_7 1-Add component constraint  Name: valid_price prdLCT.price=PRICES\(pname i.e. validate that the price in the product list is the same as the one stored in the products DB 2 Architectural Mitigation Price Validation should only be enabled when validCheckout is enabled In-Component transition  Validate_price New Yes Enabled By validCheckout In-Component Token  ValidPrice New Yes  Type Component Property When we have a checkout request and a valid price, ordGen_78 should eventually be enabled  prdLCT_7   checkout_7   valid_checkout  prdLCT.price=PRICES\(pname  ordGen_78   Figure 3. Warehouse-component Behavior Model Component constraint mitigations are enforced by connecting input interface ports with an internal node or an output interface port using a new transition and imposing the security constraint as an assertion on the new transition as indicated by Deng  T h is process is repeated until we reach a transition that places a token in one of the interface output ports of the component. Figure 3, shows the resulting behavior model from decomposing the warehouse component of Figure 2. From figure 3, we see that possible entry points to the warehouse component are the input interface ports \(that are not enabled by any transition belonging to the component\e request_7, checkout_7 and prdLCT_7, paySucc_7 and backChWh_7, while exit points are the output interface ports that do not fire any transition belonging to the component like response_72 ordGen_78, eno ugh_78, and shipEmail_72. This figure was constructed by starting with the input interface ports of the warehouse component in the high-level architecture \(Figure 2\ then given the suggested constraints and architectural mitigations of the threat model, we start building the inner workings of the component. For example, if we want to build the control flow starting from entry point checkout_7  We locate the threats in which checkout_7 is mentioned in the Target column \(see Table 1  Then we add the specified mitigation constraint\(s for example prdLCT_7.uid  USERS\(uid   prdLCT_7.category  CATEGORIES\(uid   prdLCT_7.prdName  PRODUCTS\(category  i.e.  Check for correct user id, correct category and valid product\ enforcing it on the specified Incomponent-transition validate_checkout  Then we connect the new transition to the place/node specified by the In-Component  token  which in our case was valid_checkout Afterwards, we find another threat targeting the checkout process \(ex Table 1\d we add the specified mitigation constraints  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


 prdLCT.price =  PRICES\(pname\d prdLCT.quantity <= QUANTITIES \(pname   prdLCT.quantity > 0\ to the suggested transitions validate_price and validate_quantity respectively The architectural mitigation specifies that these transitions should not be fired unless checkout was valid, and are hence enabled by the availability of a token in the place validCheckout \(mandating a certain control flow\Finally, we connect the new transition\(s\to the places specified by the InComponent  token which in our case were ordGen_78 and enough_78 respectively. backChWH_7 is an input port that receives an input token from Order Component to cancel warehouse order operations, but that does not result in the warehouse component producing output to the outside world. Therefore, it is not connected to any output port in the figure 3.3. Verification  SAM architecture is hierarchical and is defined as a set of compositions; each composition consists of a set of components, connectors and constrains. At the lowest level, each element whether a component or a connector is defined using a behavior model and a set of temporal logic property specifications. If we can find a mapping between the afore-mentioned SAM elements and the SMV constructs, then we can arguably translate different SAM architecture models into SMV model checking programs to verify that they meet their stated security properties Most of the work targeted at architecture verification, focuses on verifying liveness and correctness properties. At the same time, it mostly focuses on translating the detailed behavioral models of individual components to SM 16 w i t h o u t  regard to the interaction between components and how they behave in the entire system. In addition to translating the lower level abstraction we pay specific regard to modeling compositions, Commercial off the shelf products \(COTS\ow components interact in the system, and the security constraints that apply to the architecture as a whole. Therefore, and in order to preserve structural properties along side behavioral ones, we provide a translation of the SAM model \(i.e the high-level decomposition into compositions and their constituent components, and connectors\nto SMV. SAM elements are textually described clearly in [16 Ou r tran slatio n  h a s t h r ee m a in  step s  3.3.1. Translating SAM Petri Net Behavior Models An SMV program is made up of the sections: VAR, INIT, ASSIGN, DEFINE and SPEC 18 A ge ne r a l p r o c e d ur e fo r t r a n sl a t i n g S A M  behavior models into SMV is suggested by He et al  T h ey s u gg es t th e m a ppin g o f ev er y place to a  corresponding boolean variable under the VAR section, every enabling co ndition of a transition to a symbol represented by an expression in the DEFINE section, the initial marking to initializations in the INIT section, and the specifications \(in our case the security property specifications\nto CTL formulas in the SPEC section of the SMV program. We will base our petri net translation method over this general translation with additions specific to the translation of SAM high-level security architectures. For example we specify each security constraint as an expression defined in the DEFINE section, and use this constraint to decide on the next value of output places when the corresponding transition fires, hence enforcing the execution of the security constraint. We prefer to define the next values of the Petri net nodes using ASSIGN rather than TRANS because of logical absurdities that can occu r in TRANS declarations   T h e n e x t s t ate v a l u e s of places are def i n e d u s ing a case expression under the ASSIGN keyw   where setting the value of the variable is equivalent to placing a token in its corresponding place, and resetting it, is equivalent to consuming this token otherwise the value is kept unchanged this cycle 3.3.2. Translating SAM Components  SMV gives the user a chance to define modules, where each module can be passed parameters, and hold its own set of local variables and definitions. This SMV element maps to the definition of a component in the high level SAM architecture. A module helps abstract the inner workings of the component, and it need only be passed the input/output variables which represent interface ports \(external nodes\ in our case This way the encapsulating module would in a way map to the high-level SAM composition that includes the inner components, where the properties of the composition could be verified with the existence of these components, but without having to concern ourselves with how they actually work. Figure 4 shows a sample translation of a SAM component into SMV. Constraints such as: user1 has to belong to the set of valid user ids, and product1 has to be a valid product id are defined as logical expressions in the DEFINE section and used in the ASSIGN section to decide on the next values of the component's petri net nodes. External in/out nodes' values are formally passed from/to the encapsulating composition responsible for setting/consuming their values 3.3.3. Translating SAM Compositions  A composition is also defined using a module in SMV a composition module in SMV could also contain instance variables of other modules representing each of its constituent components. The function of a Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


 composition is to provide communication between inner components as well as communication with the outside world. Interfacing ports/external nodes are defined as variables inside the composition and are passed by reference to their components. Their values are set by the arrival of tokens from other components or the outside world by the forwarding transitions provided by the composition. Each component is represented by a similar declaration to a variable inside the composition module. Each component is instantiated by the composition in the VAR section, and the input and output ports of each component are defined and initialized in the composition's VAR and INIT sections respectively 3.3.4. Translating SAM Connectors A connector is a building block that enables interaction among components inside compositions. In our translation we represent connectors using forwarding transitions that exist in the composition module and provide interaction between its components. Each forwarding transition is represented using an assignment statement that changes the next value of an input port of one of the components using the token generated by the output port of another. This way the composition handles the communication between its different components 3.3.5. Translating SAM Properties To verify the correctness of the produced model, we need to test several types of properties: Component properties Composition properties, and System-wide properties Security properties are elicited by the threat model and are used in verifying the absence of security threats. SAM property specifications should be transformed from first order LTL \(Linear Time Logic\to CTL utilized by SMV, which is a propositional branching-time temporal logic Whereas LTL considers only one path of computation down a certain state, CTL considers all possible paths from a given state. According to He et al L T L  f o rm u l a can be equ a lly ex pres s ed in  CTL if its execution lies within the common time fragment of LTL and CTL, hence system properties such as liveness and safety can be equally expressed in either computational model without its satisfiability or validity being affected [16 T h is can  be done by adding a universal path quantifier in front of an LTL formula to transform it to CTL [16 th at is an LTL path formula is converted into CTL by quantifying over all the paths using A \(universal quantifier denoting all paths    Component Properties  In component-wide properties, we need to verify the correctness of the component, i.e. that it meets its stated specifications. Dwyer et al. suggest the use of property specificati on patterns for writing CTL properties In our model mos t of the properties are ones that fall under the "Response pattern with a global scope. Response property patterns describe cause effect relationships between two different events, where if the cause occurs, it must be followed by the occurrence of the o mponent properties in our S M V model would basically look like this  AG \(input1 & input2 constraint -> AF output 1 & output2 1 Inputs and outputs are strictly input/output interface ports \(non-internal nodes\ of the component Constraint is a certain test \(logical expression imposed on a transition that when true, a transition that enables the output places should be fired. The following is a translation of the LTL security property in Table 1 into its equivalent CTL form AG \(checkout_7 & prdLCT_7 & WH.valid_checkout WH.valid_price -> AF \(ordGen_78    Composition Properties  In composition properties, we need to verify the interaction between components. So any property that involves interface ports starting at one component and interface ports ending at a different component in the most general of terms is considered a composition property. In a composition-wide property inputs are st rictly input interface ports of the first component, while outputs are output interface ports of the second component  AG \(COMP1.input1 & COMP1.input2 constraint -> AF \(COMP2.output1\                \(2  Note the component.port notation is used to indicate that Comp1 and Comp2 are variable instances inside the composition and that they are used to access input and output ports of these components/modules   System-wide Properties A perimeter component, which could be a commercial-off-the-shelf \(COT\product for example may be a component whose functionality affects the rest of the system, like a firewall for example, where depending on the result of the firewall validation the request is either passed to the respective service or denied. Therefore, COT properties are not only limited to being component-wide properties but they are also system-wide. For example, when a firewall  FW tercepts a web service request wsRequest  and finds that it is valid, it should expect a web service response wsResponse rom the consecutive composition and eventually enable fwResponse  whether this response holds the requested data or an error. This could be expressed in CTL as follows Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


 Figure 4  Sample translation of an SAM component to an SMV module AG \(wsRequest  & FW.valid_request 3 Whereas if you have an invalid request, you should eventually get an invalid fwResponse AG\(wsRequest & !\(FW.valid_request 4 Note how the truth value of the above properties depends on the behavior of the entire system 3.4. Refinement Model checking provides us with the ability to test our architecture behavior models against the security property specifications. SMV automatically executes the model, using the provided marking values to determine the new state of the model at each clock cycle. The goal of refinement is trying to figure out what caused a property violation, then making the necessary changes to the model such that the property is satisfied. In our case, this is achieved by using SMV counter examples to determine what firing sequence caused a property violation in the model Figure 5, shows the SMV output after executing our translated model, which shows how one of the security properties was violated under the initial design. When tracing back the firing sequence through the SMV trace \(lower pane\we discovered that the property \(an order is generated only if order info, credit card info, checkout info is valid\would be satisfied under normal conditions however under other threat conditions it would not \(ex. when user replays another's valid user information without being requested for his user info\ This guided us to an architecture flaw that assumed if we have a valid user information response then the order information must be correct i.e. valid price and quantity \(since no user information is requested unless order info was verified\his lead us to add the threat "possible replay of valid user information to checkout an invalid order \(ex. with an invalid price\d to remodel our architecture so as to check on order validity just before generating the order. By repeatedly performing this task we are able to reach a model that satisfies its security properties under both normal and threat conditions 4. Conclusion Most of the work proposed for earlier security integration usually targets either the phases of requirement specification or architecture modeling but not both, failing to formally trace security requirements from the requirement analysis phase to the architecture, design, and verification phases. At the same time, no rigorous process was proposed to verify the security properties of architecture models beyond testing for Petri-net correctness properties such as liveness and being deadlock-free. This research proposes a rigorous methodology for the analysis, modeling and verification of secure software architectures guided by the process of threat modeling. By combining threat modeling for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


 systematic requirement elicitation with the formal representation of security constraints and architectural artifacts \(as mitigations using temporal logic\we are able to narrow down the gap between informal requirement specification and formal architecture modeling since this would enable the requirements analysis phase to have a direct impact on architecture decomposition. Moreover, formal architecture modeling using modeling frameworks like SAM facilitates subsequent formal architecture verification. By suggesting a mapping between SAM elements and the SMV model checker, we are able to easily translate the resulting secure architecture models into SMV to verify their stated properties  Figure 5. SMV Trace 5. References  Di an xi an g Xu  Kend al l E Nygard  Th r eat Dri ven  Modeling and Verification of Secure Software Using Aspect-Oriented Petri Nets IEEE Transactions on Software Engineering vol. 32,  no. 4,  pp. 265278,  Apr.,  2006 2 Y i D e ng J i a c u n W a ng J e ff r e y J  P  T s a i K ons ta nti n  Beznosov, "An Approach for Modeling and Analysis of Security System Architectures IEEE Transactions on Knowledge and Data Engineering vol. 15,  no. 5,  pp 1099-1119,  Sept/Oct,  2003  Bru ce S c hn ei er  Attack Trees  Dr. Dobb's Journal  December 1999. http://www.schneier.com/paperattacktrees-fig1.html   E b e n ezer Ol ad i m ej i  S a m S u pakku l  an d L a w r en ce Chung, "Security Threat Modeling: A Goal-Oriented Approach  Proceedings of  SEA 06 Dallas, TX, Dec. 2006 5 G u ttorm Sindre  a nd A ndre a s  L  O pda hl E lic iti ng  security requirements by misuse cases Proceedings of TOOLS Pacific 2000 pp. 120-131, 2000 6 S u v d a My a g m a r A d a m J. L e e  a nd W illia m Yurc ik  Threat Modeling as a Basis for Security Requirements Symposium on Requirements Engineering for Information Security \(SREIS in conjunction with 13th IEEE International Requirements Engineering Conference \(RE  Paris, France, Aug., 2005 7 Mic h a e l H o w a rd a nd Da v i d L e Bla n c   W riting Se c u re  Code Microsoft Press 2002 8 Ch arles B. Haley Ro b i n C. L a n e y  Bash ar Nu seib eh  Deriving Security Requirements from Crosscutting Threat Descriptions  Proceedings of the Third Int'l Conf. AspectOriented Software Development pp. 112-121, 2004  Di an xi an g Xu and Jo s h  P a ul i   T h r eat Dri ven Desi gn  and Analysis of Secure Software Architectures Journal of Information Assurance \(JIAS vol. 1, no. 2, June 2006 1 A x el van L a ms w e erd e an d E mman u e l L e t i e r  Handling Obstacles in Goal-Oriented Requirements Engineering  IEEE Transactions on Software Enineering Special Issue on Exception Handling 2000 1 A x el van L a ms w e erd e  E l a b o r at i n g S ecu ri t y  Requirements by Construction of Intentional Anti-Models Proceedings of ICSE'04, 26th International Conference on Software Engineering Edinburgh, pp.148-157, May 2004 12 Y u jia n Fu Zh ijia ng Do ng Xudo ng  M o d e ling   Validating and Automating Composition of Web Services  ACM International Conference Proceeding Series Proceedings of the 6th international conference on Web engineering 2006 13 Mihir  M. Ayachit and Haiping Xu, "A Petri Net Based XML Firewall Security Model for Web Services Invocation Proceedings of the International Conference on Communication, Network, and Information Security CNIS 2006 pp. 61-67, MIT, Cambridge, Massachusetts USA, Oct, 2006 14  Me y e r C T a nua n A utom a t e d a n a l y s is of unif i e d  modeling language \(UML\pecifications Master's thesis presented to the University of Waterloo August 2001 15  X u d ong H e J u nh ua D i ng J   W a ng a nd Y i D e ng  Model checking software architecture specifications in SAM Proceedings of International Conference on Software Engineering and Knowledge Engineering Ischia Italy, July 15-19, 2002 1  Xu do n g He Hu i q un Yu T i an jun S h i J u nh u a Di n g  Yi Deng, "Formally analyzing software architectural specifications using SAM Journal of Systems and Software 71 \(1 2\, pp.11 29, 2004 17 A n th ony H a ll a nd R ode ric k Cha p m a n C orre c t ne s s by  Construction: Developing a. Commercial Secure System IEEE Software, Jan/Feb 2002 pp18 25, 2002 18 Ke n Mc Milla n T he SM V S y ste m   Ca rne g i e Me llon University, Pittsburgh, PA, Feb.1992 19  Ma tthe w B. D w y e r G e orge S. A v runin J a m e s C Corbett. "Property Specification Patterns for Finite-State Verification 2nd Workshop on Formal Methods in Software Practice pp 7 - 15, Clearwater Beach, FL, USA 1998  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


12 R Krishnapuram D Casasent Determination of threedimensional object location and orientation from Range Image IEEE Transactions on Pattern Analysis and Machine Intelligence 11\(11 1158 1167 November 1989 13 R Craig I Gravseth R P Earhart J Bladt S Barmhill L Ruppert C Centamore Processing 3D flash LADAR point-clouds in real-time for flight applications Proc SPIE 2007 Vol 6555 BIOGRAPHY Stphane Ruel is a project manager at Neptec Design Group in Ottawa Canada He currently leads development of novel 3D computer vision algorithms and sensor software for space applications Previously he served as an operations engineer on several Space Vision System SVS Space Shuttle missions He has a B.Sc in Computer Engineering and M.Sc in Aerospace Engineering from Laval University He is also alumni of the International Space University SSP in 2004 Tim Luu is a Vision Systems Engineer at Neptec Design Group Ltd At Neptec he develops 3D vision systems for space and defense applications Most of his time is spent developing real-time 3D pose estimation algorithms using sparse data from non-cooperative targets This research is mostly geared toward the field of autonomous rendezvous and docking Filling out his time is also control systems design 2D image registration onto 3D data as well as other 3D visualization techniques Tim received his M.A.Sc from Carleton University in Mechanical Engineering and his BASc from the University of British Columbia in Engineering Physics specializing in Mechanical Engineering 11 


Time Time 50 350   10 0                   10 1                   10 2 12.5 50 350   10 0                   10 1  12 expected from Figure 7, the width of the uncertainty region is compressed by the curvature of the monopulse response resulting in a detection-primitive with greater uncertainty than the variance admits.  A filter lag or so-called cluster tracking can easily result in a 5% or greater offset and degraded consistency.  After 300 seconds the curves peak up because the target is appr oaching a low-elevation beampoint limit.  This occurs anytime a target is tracked into the edge of the radar\222s field of re gard and can lead to radar-toradar handover difficulty         300 300 80  s D 2 k,1 k y    s D 2 k,1 k y   100 150 200 250 10 1                    10 5 1 0  Figure 8 - Consistency versus distance from beam center Monopulse Mismatch The next set of curves plotted in Figure 9 show the sensitivity of detection-primitive consistency to a mismatch in the monopulse slope.  All of these curves were generated using a linear monopulse response derived from the slope of the true monopulse response at beam center.  The slope of the 80% curve is 0.8 times th e beam-center slope; the 90 curve is 0.9 times the beam-center slope; and so on for 100%, 110% and 120%.  Again, the order of curves in the graph is the same as the legend order A steep slope tends to expand y I 222s uncertainty while a gentle slope tends to compress it.  An expanded uncertainty leads to a smaller consistency while a compressed uncertainty leads to a larger consistency.  This behavior can be observed in the family of curves in Figure 9.  Curves for the steeper slopes are on the botto m while curves for more gentle slopes are on top.  The notable feature of this set of curves is that the sensitivity to a mismatch in the monopulse slope is not very significant       100 150 200 250 10 1                    90 100 110 120  Figure 9 - Consistency versus monopulse mismatch Range-Bias Error The complex nature of the monopulse radar models presents ample opportunity to introduce errors in the software implementation.  One such e rror introduced in a \275 rangecell-width bias in the detection-primitive range which in turn resulted in a significant degradation to 2 9 k D The fact that 2 9 k D is measured in different coordinates compared to the bias made it difficult to determine which value or algorithm was to blame.  Examining the intermediate consistency values led directly to the error source A comparison between biased 2 1 k D  2 2 k D and 2 3 k D values and unbiased 2 2 k D values is shown in Figure 10.  The unbiased 2 2 k D is the bottom-most curve and the biased 2 3 k D is the top-most curve with a value around 80.  This large value for 2 3 k D indicates that there is a lot more uncertainty in the range measur ements compared to what is predicted by the range varian ce.  Since the range-variance calculation is easy to confirm, the problem must be in the algorithms that model or manipulate range A notable feature of Figure 10 is the sensitivity of the centroiding algorithm to range bias in the detection primitives.  The range bias is ba rely noticeable in the biased 2 1 k D and 2 2 k D curves.  Of course, if the unbiased 2 2 k D  curve existed as a baseline it would be relatively easy to spot the error 


Time Time Time 50 350   10 0                   10 1                   10 2 50 350   10 1                   10 0                   10 1 50 350   10 0                   10 1  13         Isolated No SNR Adjust  Figure 11 - Centroiding for isolated range cells Filter Tuning Now that the centroided m easurements are reasonably consistent, the parameters that govern track filtering can be examined.  As previously promised, the effects and corrections for atmospheric refr action and sensor bias have been disabled so that 2 8 k D can be analyzed using a sliding window.  Of course the full analysis would include these effects and 2 8 k D at each time step would be collected and averaged over many trials Plots of the effect of changing process noise in a nearlyconstant-velocity filter are shown in Figure 12 and Figure 13 for Cartesian position and velocity respectively.  In both figures, the plotted values have been divided by 3 so that the desired value is always 1.  Increasing the process noise up to a point should increase the updated uncertainty and reduce 2 8 k D values.  Except near th e end of the trajectory when the measurements are off of beam center, the curves in Figure 12 and Figure 13 appear inconclusive for this expected trend If 2 8 k D values are way out of range there are additional intermediate filter values that can be examined.  For example, the state extrapolati on algorithms can be examined by comparing the consistency of 1 210 Isolated With SNR Adjust 300 300 300 0.005 212 212 212 212 212 kkkk T kkkk D xhzSxhz 35        s D 2 k Range   D 2 k,2 biased D 2 k,1 biased D 2 k,2  Figure 10 - Range bias error in detection primitive Centroiding Algorithm From Section 3, assuming that the centroided-range uncertainty for an isolated range cell is the same as its detection-primitive uncertainty may be incorrect Collecting and plotting 2 3 k D values only from isolated range-cell measurements can be used to analyze such assumptions.  The plots in Figure 11 compare differences between the isolated-cell algorithm defined in Section 3, an algorithm that modifies the uncertainty based on the SNR in the isolated cell, and the 2 3 k D values from all measurements 34\was used to modify the range uncertainty for the upper line labeled Isolated with SNR Adjust    4 22  2 2  resRi o R R Rn bdp bm  s D 2 k,3 Range    s D 2 k,8 Position     212 1 can also be examined using \(35 The residual is also commonly used to determine the assignment cost  212 kk z  P  k  k1 with z k The consistency of the innovation covariance k T kkkkk RHPHS 100 150 200 250 10 1                    D 2 k,3 biased 100 150 200 250 10 2                    100 150 200 250 10 1                    0.5 50  Figure 12 \226 Position consistency, filter tuning example  r  t t 34 If the All Centroided curve \(middle\as the baseline doing nothing \(lower\imates the uncertainty and 33\imates the uncertainty.  Dividing by the square root of the observed SNR leads to a more consistent covariance; however, there is currently no statistical evaluation to justify it             210 210 1 1 1 2 All Centroided 


Time 50 350   10 1                   10 0                   10 1  14         300 0.005  s D 2 k,8 Velocity   100 150 200 250 10 2                    0.5 50  Figure 13 \226 Position consistency, filter tuning example 5  C ONCLUSION  Calculating and observing the behavior of covariance consistency at different levels  in the radar signal processing chain represents a very powerfu l tool that can be used to assess the accuracy and softwa re implementation of radar signal-processing algorithms.  Analyzing covariance consistency is applicable to radar systems both in the field and in simulations.  The primary challenge in both arenas comes down to properly accounting for the true target states that contribute to detections, detection primitives measurements, and state estimates For a fielded radar syst em, achieving covariance consistency is usually a s econdary consideration behind achieving and maintaining track s.  Indeed, until recently radar specifications did not even include requirements for covariance consistency.  Recent covariance consistency requirements stem from the fact that the use of radar systems in sensor netting applications is on the rise Currently the combined e ffects of off-beam-center measurements, atmospheric correction, bias correction clustering and centrioding, data association, and filtering on state covariance consistency throughout a target\222s trajectory are not well known.  This is particularly true for radars using wideband waveforms and multiple hypotheses or multiple frame trackers.  Numerical results presented here indicate that algorithms early in the radar signal processing chain can significantly degrad e covariance consistency and that some errors are better tolerated than others For a simulated target in a modeled system, truth relative to some global reference is known. However, transforming truth through different refere nce frames and accounting for changes that occur during various radar processing algorithms is not as simple as it appears.  The techniques in this paper help expose this hidden complexity and provide a framework for discussing and expanding the future development of covariance consistency techniques.  Such future developments include issues related to mapping truth through the convolution operation typically used to simulate wideband signal processing and the fast Fourier transforms typically used in pulse-Doppler processing.  Sophisticated tracking algorithms that carry multiple hypotheses, associate across multiple frames, or weight the association of multiple targets within a single frame pose significant challenges in properly associating truth with state estimates.  Additional work, including an investigation of track-to-truth assignment, is needed before covariance consistency techniques can be applied to these algorithms Another area that needs furthe r analysis is the use of a sliding window to approximate the covariance behavior expected during a set of Monte-Carlo trials.  Various timedependent variables such as the target\222s range and orientation, the transmit waveform, the radar\222s antenna patterns toward the target, missed detections, and false alarms could easily viol ate the assumption that measurement conditions are nearly stationary over the time of the window.  It is importa nt to understand the conditions when this assumption is violated Finally, the examples presented here included a relatively benign arrangement of targets.  Further analysis in dense target environments with the related increase in merged detections, merged measurements, and impure tracks is needed.  Further analysis for targets traveling over different trajectories is also needed Even so, the techniques presented here can be extended to many of these analyses R EFERENCES  1  S. Blackman and R. Popoli Design and Analysis of Modern Tracking Systems Artech House, 1999 2  Y. Bar-Shalom and X. R. Li Multitarget-Multisensor Tracking: Principles and  Techniques YBS Publishing, Storrs, CT, 1995 3  Y. Bar-Shalom, Editor Multi-target-Multi-sensor Tracking: Advanced Applications and  Vol. I Artech House, Norwood, MA, 1990 4  D. B. Reid, \223An Algorithm for Tracking Multiple Targets,\224 IEEE Trans. on Automatic Control Vol. 24 pp. 843-854, December 1979 5  T. Kurien, \223Issues in the Design of Practical Multitarget Tracking Algorithms,\224 in Multitarget-Multisensor Tracking Y. Bar-Shalom \(ed.\43-83, Artech House, 1990 6  R.P.S. Mahler, Statistical Multisource-Multitarget Information Fusion, Artech House, 2007 


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



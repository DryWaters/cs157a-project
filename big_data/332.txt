SCALABLE SPATIAL EVENT REPRESENTATION Jelena TeiiC Shawn Newsam and B S Manjunath Electrical and Computer Engineering Department University of California, Santa Barbara Santa Barbara CA 93106-9560 jelena snewsam manj ece.ucsb.edu ABSTRACT This work introduces a conceptual representation for com plex spatial arrangements of image features in large multi media datasets A novel data structure, termed the Spatial Event Cube SEC\is 
formed from the co-occurrence ma trices of perceptually classified features with respect to spe cific spatial relationships A visual thesaurus constructed using supervised and unsupervised learning techniques is used to label the image features SECs can be used to not only visualize the dominant spatial arrangements of feature classes but also discover non-obvious configurations. SECs also provide the framework for high-level data mining tech niques such as using the Generalized Association Rule ap proach. Experimental results are provided for a large dataset of aerial images 
1 INTRODUCTION As technology advances and more visual data are available we need more effective systems to handle the image data processing and understanding The framework must effi ciently summarize information contained in the image data it must provide scalability with respect to the nature size and dimension of a dataset; and it must offer simple repre sentations of the results and relationships discovered in the dataset On the user side of the system modelling of a high level human 
concept such as a perceptual event also raises many research questions Humans can instantly answer the question 223Is this highway going through a desert?\222 just by looking at an aerial photograph of a region This query es sentially formulated as a high-level concept cannot be an swered by most existing intelligent image analysis systems Existing image representations based on low-level features This research was supported in part by the 
following grantdawards The Institute of Scientific Computing Research ISCR award under the auspices of the U.S Department of Energy by the Lawrence Livermoxe National Laboratory under contract No W-7405-ENG-48, ONIUASSERT award N00014-98-1-0515 NSF Instrumentation EIA-9986057 and NSF InfrastnrCtUre EIA-0080134 0-7803-7304-9/02/$17.00 C2002 IEEE 229 fail to capture perceptual events. Meaningful semantic anal ysis and knowledge extraction require data representations that are understandable at a conceptual level This paper presents an approach to spatial event repre sentation and 
image analysis at a conceptual level Section 2 describes the image representation model Section 3 de scribes the analysis model knowledge discovery and anal ysis techniques; Section 4 presents conducted experiments and we conclude with a discussion in Section 5 2 VISUAL THESAURUS An image analysis framework requires a representation that allows fast data processing meaningful data swnmariza tion, scalability with respect to dataset size and dimension multi-feature representation and efficient data understand ing Limited success towards this 
end has been achieved by systems that use low-level visual features, such as texture and color descriptors to represent the images However these systems fail to support high-level perceptual interac tion A visual thesaurus provides summarized data informa tion derived from the low-level features  l 2.1 Image Features The first step in constructing a visual thesaurus is feature extraction. Feature extraction is localized by partitioning an image into tiles. Regular partitioning is a simple altemative to segmentation that allows straight-forward 
feature extrac tion and provides a simple spatial layout An MPEG-7 2 compliant homogeneous texture feature vector is extracted for each tile The 62-dimension feature vector is composed of the first and second order statistics of Gabor filter outputs and Euclidean distance is used the similarity measure The MPEG-7 homogenous texture de scriptor effectively captures visual similarity as shown in the online MPEG-7 demonstration 3 Other features can be similarly extracted from the tiles 


a class 16 b class 17 Figure 1 Data Classification Example 2.2 Feature Classification The second step in constructing a visual thesaurus is feature classification Conceptually, visually similar tiles are as signed the same class label by partitioning the high dimen sional feature space This is accomplished using a combi nation of supervised and unsupervised learning techniques A set of training tiles is used to configure a Kohonen Self-organizing Map SOM An SOM converts complex nonlinear statistical relationships between high dimensional data items into simple geometric relationships on a low dimensional display, while preserving the topological lay out of the feature space 4 The output nodes of the SOM are labelled using the training set and a majority-vote prin ciple 5 The labels are manually assigned to a training set so that adjacent class numbers correspond to visually sim ilar classes An example of three training tiles from two agricultural classes is shown in Figure 1 An initial set of class clusters is formed by using the trained SOM to label each of the dataset features. The Learn ing Vector Quantization LVQ3 algorithm is iteratively ap plied to refine the class clusters 4 LVQ is a supervised ex tension of the winner-take-all algorithm 4 The supervised leaming stage of the feature classification is summarized in the following Algorithm 1 Feature Classification SOM summarizes input training feature space label SOM output using training set t  1 while t 5 7 do LVQ fine-tuning of class boundaries re-assign labels using majority-vote approach t=t+l end while The unsupervised leaming stage of the feature classifi cation further partitions the classes into sets of codewords as described next 2.3 Thesaurus Entries High-dimensional feature spaces are usually very sparse so that enforced space partitioning, such as that described above frequently clusters visually dissimilar features into the same class Data partitioning via the Generalized Lloyd Algo rithm 6 is used to further split the classes into more con Iry  X U a PpQ example b Cp\(u v c Multimodal SEC Figure 2 Spatial Event Cube sistent clusters A representative codeword is selected for each cluster and forms the visual thesaurus entry The re maining cluster features are synonyms of the codeword and receive the same codeword label 3 SPATIAL EVENT MINING The motivation for building a spatial event data structure is to discover interesting spatial pattems in extended im age datasets Towards this end we introduce SECS a novel data representation obtained by applying spatial predicates to image features labelled using the visual thesaurus 3.1 Spatial Event Cubes Spatial Event Cubes are a scalable approach to mining spa tial events in large image datasets based on the spatial co occurrence of perceptually classified image features De fine the image raster space R for an image partitioned into M x N tiles as R={~l~=\(z,y ELMI YE[LNI Spatial relationships between coordinates in an image can be defined as a binary relation p p  R x R  0 l or PpQ E 0 l where P Q E R Figure 2\(a shows an example of binary relation p where is p defined as a spatial function of distance and direction Consider the set of thesaurus entries defined as T i.e T  uilui is a thesaurus entrykodeword Let T be the function that maps image coordinates to thesaurus entries i.e r  R  T,or T\(P U where P E Rand U ET A face of a Spatial Event Cube is the co-occurrence ma trix Cp\(u,w of thesaurus entries u,v E T of all points whose spatial relationship satisfies p Cp\(u  II\(f Q PPQ A T\(P  U A T\(Q   Figure 2 shows the structure of an SEC Cp\(u w is the number of tiles with thesaurus entries U and v that sat isfy spatial relationship p A multi-modal SEC structure is a hypercube whose dimensions are defined by image features extracted from the image tiles A three-dimensional exam ple with two texture axes and one color axis is shown in Figure 2\(c 230 


1 1 I1 22 I 32 I 26 1 35 I 41 1 i,j 11 26,2 1 32,ll I 22,s C,\(U~,U 1 855 I 672 1 633 I C,\(U;,~A ii 24298 i 20970 i 18030 i 8368 i 7133 I 26,46 I 332,315 552 1 445 a 3D b 2D Figure 3 Homogenous Texture Region Analysis in an Image Dataset  SEC Visualization 3.2 Generalized Association Rule Association rules were introduced as a way of discovering interesting pattems in transactional databases 171 Frequent item sets are identified using the Apriori algorithm and the most \223interesting\224 rules are selected based on confident fac tors 8 Thesaurus entries and their spatial relationships define a non-traditional space for data mining applications This space can be used to discover interesting rules such as the spatial co-occurrence of orchard and housing regions in aerial images SECs allow us to extend the traditional asso ciation rule approach to multimedia databases An attribute value set T contains N thesaurus entries ui The SEC entries C U v mark the frequency of codeword tuples that satisfy binary relation p Define Fg as a set of fresuent item sets of size K Multiple entry item sets for K  2 will reduce to ones of smaller order with different entries Define SiK as a minimum support value for item UI UP uK UI UP uK E Fg Our goal is to find Fp  UK F i.e sets of tuples that show some depen dency among tile spatial configurations An outline of the extended association de algorithm for spatial relationship follows Algorithm 2 Generalized Association Rule 1 Find frequent item sets Fl  i uj ui j  Sy\222 for K  3 Fg  0 K  do F  UZlC Ui Ui  sp Candidate K-item frequent itemset is formed of K joint elements from any frequent Fgd1 item set Form Fg from candidates that satisfy the following a ordering rule of item indices b minimum support rule end for FP  uK Fk 2 Use the frequent itemsets to generate rules The following experiments demonstrate the use of SECs for mining spatial relationships in a large image dataset Table 1  Codeword Elements of the First-order Item Set Ff and Corresponding Frequencies Table 2 Codeword Elements of the Second-order Item Set F2p and Corresponding Frequencies 4 EXPERIMENTS The proposed visual mining framework is applied to a dataset of 54 large aerial images of the Santa Barbara region The MPEG-7 homogeneous texture descriptor has shown to be effective at characterizing a variety of land-cover types from this dataset 3 Each 5248x5248 pixel image is divided into 128x128 pixel non-overlapping tiles resulting in a dataset of 90,744 tiles A 62-dimension texture feature vector is extracted for each tile A visual thesaurus of the tiles is constructed as described in Section 2 A set of manually labelled tiles is used to train the supervised learning stage of the classification algo rithm \(Section 2.2 This training set contains 60 land-cover classes such as agricultural fields water, parking lots etc The 60 classes are further partitioned into 308 codewords using the data clustering techniques described in Section 2.3 These codewords form the thesaurus entries Every tile in the dataset is labelled with one of these codewords SECs are constructed using tile adjacency as the spatial relation Adjacency is defined as the 8-connectivity neigh borhood 4.1 Visualization The dominant spatial arrangements of the labelled image tiles over the entire dataset are readily observable from the SEC faces or cross-sections An SEC faceplate subspace can be visualized as a three-dimensional graph or a two dimensional image as shown in Figures 3\(a and 3\(b re spectively The X and Y axes of the graph correspond to classes and the Z axis indicates the relative co-occurrence of two classes with respect to the spatial relation When an SEC faceplate is viewed as an image, the co-occurrence value corresponds to image intensity Figure 3 shows a faceplate of the SEC for the 60 classes in the aerial image dataset using adjacency as the spatial re lation We expect large homogeneous regions in the dataset to result in large values along the diagonal of the faceplate The spike in Figure 3 corresponds to the ocean class This makes sense since the aerial images contain large regions of the Pacific Ocean 231 


22 32 26 35 41 Figure 4 Codeword Tiles Corresponding to the Most Frequent Elements in the First-order Item Set Ff 33 203 1 71 14 41 Figure 6 Composite Spatial Arrangement of Ocean and Pasture Tiles in an Aerial Dataset 263 WJ1 22 26946 33235 Figure 5 Codeword Tiles Corresponding to the Most Frequent Elements in the Second-order Item Set F 6 ACKNOWLEDGMENTS 4.2 Mining The most frequent first and second order codeword item sets for the aerial image dataset are presented in Tables 1 and 2 respectively The item sets are computed using the 308 codewords of the visual thesaurus and adjacency as the spatial relation The most frequent elements of the first or der item set Ff correspond to homogeneous regions Fig ure 4 shows the corresponding visual thesaurus codewords namely pasture and ocean tiles Higher order item sets pro vide information about adjacencies between tuples of code words Figure 5 shows the visual thesaurus codewords for the most frequent elements of the second order item set F Figure 6 shows a combination of the the most frequent tu ples and triples Ocean and pasture tiles exhibit composite spatial arrangements 5 DISCUSSION This work introduces a novel approach to spatial event rep resentation for large image datasets Image features are classified using supervised and unsupervised learning tech niques Spatial relationships between the labelled features are summarized using Spatial Event Cubes SECs are shown to be effective for visualizing non-obvious dataset spatial characteristics such as frequently occurring land-cover ar rangements in aerial images SECs also support the exten sion of the general association rule approach to multimedia databases to idenm frequently occurring item sets We are using SECs to summarize other sizable datasets such as a multi-terabyte collection of aerial videos of Ama zonia Future research includes using SECs to construct ef ficient index structures for multimedia database access The authors would like to thank Chandrika Kamath and Imola K Fodor for many fruitful discussions and Motaz El Saban for extracting the dataset features 7 REFERENCES l W Ma and B S Manjunath 223A texture thesaurus for browsing large aerial photographs,\224 Joumal of the American Society of Information Science vol 49 no 7 pp 633-648 September 1998 2 B.S.Manjunath Philippe Salembier and Thomas Sikora Eds Introduction to MPEG7 Multimedia Content Description Interface John Wiley  Sons Ltd., 2002 3 S Newsam J TeSiC M El Saban and B.S Man junath MPEG-7 Homogeneous Texture Descriptor Demo http://vision.ece.ucsb.edu/texture/mpeg7 223Self-organizing maps and learning vector quantization for feature se quences,\224 Neural Processing Letters vol 10 no 2 pp. 151-159 October 1999 5 M Berthold and D.J Hand Eds Zntelligent Data Analysis An Introduction Springer 1999 6 A Gersho and R.M Gray Signal Coding Quantiza tion and Compression Kluwer Academic Publishers fourth edition, 1992 7 D J Hand H Mannila, and P Smyth Principles of DataMining h4IT Press Cambridge MA September 2000 8 R Agrawal and R Srikant 223Fast algorithms for min ing association rules,\224 in Proceedings of 20th Intema tionall Conference on Very Large Data Bases VLDB September 1994 vol 3 pp 487499 4 P Somervuo and T Kohonen I 232 


n set g t 2 16333 103 18.426s 1402 1669.18 1403 Hybr id Total time I I  _I Table 2 Experimental Run of 3 Data Sets Here are some observations and explanations on the results The total time of our comparison includes the time to write the association rules to a file; Bit-AssocRule is 2 to 3 orders of magnitude faster than the various Apriori algorithms 64 221 times faster\The big the test data set the big the time difference between the Bit-AssocRule and the various Apriori algorithms We haven\222t compared our algorithm with some of the other association rule algorithms such as VIPER 15 CHARM 19 CLOSE 6 CHARM and CLOSE are based on the closed frequent itemsets concept but based on their published comparison results with Apriori our Bit-AssocRule is very competitive compared to them and a direct comparison will be conducted and reported in the near future Bit-AssocRule takes the same or litter longer time than the various Apriori algorithms in constructing the I-itemsets because of the extra cost of building the bitmaps for the 1 itemsets But after the 1-itsemtset is done Bit-AssocRule is significant faster than the Apriori algorithms in constructing large frequent itemsets because it only uses the fast bit S os 673.288 68286 68267.5 5144 S s34s 34s 2.56 IQ operations \(AND COUNT and SHIFT\and doesn\222t need to test the subsets of the newly candidate Bit-AssocRule only stores the hitmaps of the frequent items, and the bitmap storage \(uncompressed\is less than the original data set U2 to 1/4 of the original data size The main reasons that Bit-AssocRule algorithm is significant faster than Apriori and its variations are Bit-AssocRule adopts the divide-and-conquer strategy the transaction is decompose into vertical bitmap format and leads to focused search of smaller domain There is no repeated scan of entire database in Bit-AssocRule Bit-AssocRule doesn\222t follow the traditional candidate-generate-and test approach thus saves significant amount of time to test the candidates In Bit-AssocRule the basic operations are hit Count and hit And operations which are extremely faster than the pattern search and matching operations used in Apriori and its variations IV CONCLUSION We present a bitmap based association rule algorithm using granular computing technique and introduce the bitmap technique to the data mining procedure and develop a bitmap based algorithm \(Bit-AssocRule\to find association rules Our Bit-AssocRule avoids the time-consuming table scan to find and prune the itemsets all the operations of finding large itemsets from the datasets are the fast bit operations The experimental result of our Bit-AssocRule algorithm with Apriori AprioriTid and AprioirHybrid algorithms shows Bit-AssocRule is 2 to 3 orders of magnitude faster This research indicates that bitmap and granular computing techniques can greatly enhance the performance for finding association rule and bitmap techniques are very promising for the decision support query optimization and data mining applications Bitmap technique is only one way to improve the performance data mining algorithm. Parallelism is another crucial aspect of DSS and data mining performance We are currently working on paralleling the hitmap-based algorithms and hope to report our fmdings in the near future REFERENCES l Agrawal R Srikant R 223Fast Algorithm for Mining Association Rules\224 Prod of the 20th VLDB conf. 1994  Agrawal R Mannila H Srikant R., Toivonen H Verkamo A 223Fast Discovery of Association Rules\224 in Advances in Knowledge Discovery and Data Mining MIT 1996 3 Aganval R Agganval C., Prasad V 223A Tree Projection Algorithm for Generation of Frequent Itemsets\224 Journal of Parallel and Distributed Computing 2002 141 Bayardo R.J.Jr Agrawal R Gunopulos D 223Constraint-Based Rule Mining in Large Dense 682 The IEEE International Conference on Fuzzy Systems 


Databases\224 Proc of\222 the ISth Int\221l Con on Data Engineering ICDEI999  Bertino E Ooi B.C Sacks-Davis R etc 223Indexing Techniques for Advanced Database Systems\224, Kluwer Publisher 6 Han J Pei J Yin Y 223Mining Frequent Patterns without Candidate Generation\224 Prod of the SIGMOD-2002 7 Lin T.Y 223Data Mining and Machine Oriented Modeling A Granular Computing Approach\224 Journal of Applied Intelligence, Oct. 2000 8 Louie E Lin T.Y 223Finding Association Rules using Fast hit  Computation Machine-Oriented Modeling\224 ISMIS-2000 9 Mannila H., Toivonen H Verkamo A Efficient Algorithms for Discovering Association Rules\224 in KDD94 lo Morzy T Zakrzewicz M 223Group Bitmap Index A Structure for Association Rules Retrieval\224 Prod of the 4\222 Int\222l Conf on Knowledge Discovery and Data Mining KDD-98 ll Pasquier N Bastide Y Taouil R Lakhal L 223Discovering Frequent Closed Itemsets for Association Rules\224, 1CDT2000 I21 Pei J Han H Lu S Nisbio S Tang, and D Yang 223H-Mine: Hyper-structure Mining of Frequent Patterns in Large Databases\224 Proc The 2001 IEEE Int\222l Conference on Data Mining I31 Pei J Han J Lakshmanan, \223Mining Frequent Itemsets with Convertible Constraints in ICDE2001 I41 Savasere  A Omiecinski E Navathe S 223An Efficient Algorithm for Mining Association Rules in Large Databases\224 in Prod. of the 21\224 VLDB conf 15 Shenoy P et al, Turbo-charging vertical mining of large databases in SIGMOD 00 16 Wu M Bucbmann A 223Encoding Bitmap Indexing for Data Warehouse\224, Proc of the 14th Int\222l Conference on Data Engineering, 220-23 1 1998 I71 Zaki M 223Generating Non-Redundant Association Rules\224 in KDD-2002 1181 Zaki M.,et al New Algorithms For Fast Discovery of Association Rules In KDD97 19 Zaki M Hsian C.J 223CHARM An Efficient Algorithm for Closed Association Rule Mining\224, Tech Report CS dept., RPI, USA 683 The IEEE International Conference on Fuzzy Systems 


not share an y itemsets with the b oundary of an y itemset X k 2X whic hisac hild of X  In other w ords for eac h c hild X k 2X of X w e remo v e from F  X c  all mem ber itemsets in F  X k c   Then these pruned b oundaries ma ybe used in order to generate the rules The resulting algorithm is illustrated in Figure 6 This algorithm uses as input the itemsets X whic h are generated in the 014rst phase of the algorithm at the appropriate lev el of minsupp ort  The algorithm FindBoundary of Figure 5 ma y b e used as a subroutine in order to generate all the b oundary itemsets These b oundary itemsets are then pruned and the rules are generated b y using eac h of the itemsets corresp onding to the b oundary in the an teceden t 4.1 Rules with constrain ts in the an teceden t and consequen t It is easy enough to adapt the ab o v e rule generation metho d so that particular items o ccur in the an teceden t and/or consequen t Consider for example the case when w e are generating rules from a large itemset X  Supp ose that w e desire the an teceden t to con tain the set of items P and the consequen t to con tain the set of items Q W e assume that P  Q 022 X  W e shall refer to P as the ante c e dent inclusion set  and Q as the c onse quen t inclusion set  In this case w e need to rede\014ne the notion of maximalit y and b oundary itemsets A v ertex v  Y  is de\014ned to b e a maximal ancestor of v  X  at con\014dence lev el c an teceden t inclusion set P  and consequen t inclusion set Q if and only if P 022 Y  Q 022 X 000 Y  S  Y  S  X  024 1 c  and no strict ancestor of Y satis\014es all of these constrain ts Equiv alen tl y  the b oundary set con tains all the itemsets corresp onding to maximal ancestors of X  It is easy to mo dify the algorithm discussed in Figure 5 so that it tak es the an teceden t and consequen t constrain ts in to accoun t The only di\013erence is that w e add an un visited v ertex v  T  to LIST if and only if S  T  024 S  X  c  and T 023 P  Also a v ertex v  R  is added to BoundaryList  only if it satis\014es the mo di\014ed de\014nition of maximalit y  5 Generation of the adjacency lattice In this section w e discuss the construction of the adjacency lattice The pro cess of constructing the adjacency lattice requires us to 014rst 014nd the primary itemsets There are t w o main constrain ts in v olv ed in c ho osing the n um ber of itemsets to prestore 1 Memory Limits In order to a v oid I/O one ma y wish to store the primary itemsets and corresp onding adjacency lattice in main memory  1 Recall that Theorem 2.1 c haracterizes the size required b y the adjacency lattice for this purp ose Assume that w e desire to 014nd N itemsets Note that b ecause of ties in the supp ort v alues of the primary itemsets supp ort v alues ma y not exist for whic h there are exactly N itemsets Th us w e assume that for some slac kv alue N s w e wish to 1 Storing the adjacency lattice on disk is not suc h a bad option after all The total I/O is still prop ortional to the size of the output rather than the n um b er of itemsets prestored Recall that the graph searc h algorithms used in order to 014nd the large itemsets and asso ciation rules visit only a small fraction of the v ertices in the adjacency lattice F unction NaiveFindThr eshold\(Numb er ofIt emset s N Slack N s  b egin High  max i f Supp ort of item i g Low 0 Gener ated 0 while  Gener ated 62  N 000 N s N  b egin Mid  High  Low   2 Gener ated  DH P  Mid  end return Mid  end Algorithm ConstructL attic e\(Numb er ofItem sets N Slack N s  b egin p  NaiveFindThr eshold\(N N s  F or eac h itemset X  f i 1 i r g with S  X  025 p do Add the v ertex v  X  to the adjacency lattice with lab el S  X  Add the edge E  X 000f i k g X  for eac h k 2f 1 r g end Figure 7 Constructing the adjacency lattice 014nd a primary threshold v alue for whic h the n um ber of itemsets is b et w een N 000 N s and N  2 Prepro cessing Time There ma y b e some practical limits as to ho wm uc h time one is willing to sp end in prepro cessing Consequen tly ev en if it is not p ossible to 014nd N itemsets within the prepro cessing time it ough t to b e able to terminate the algorithm with some v alue of the primary threshold for whic h all itemsets with supp ort ab o v e that v alue ha v e b een found A simple w a y of 014nding the primary itemsets is b y using a binary searc h algorithm on the v alue of the primary threshold using the DHP metho d discussed in Chen et al as a subroutine This metho d is somewhat naiv e and simplistic and is not necessarily e\016cien t since it requires m ultiple executions of the DHP metho d This metho d of 014nding the primary threshold is discussed in the algorithm NaiveFindThr eshold of Figure 7 The time complexit y of the pro cedure can b e impro v ed considerably b y utilizing a few simple ideas 1 It is not necessary to execute the DHP subroutine to completion in eac h and ev ery iteration F or estimates whic h are lo w er b ounds on the correct v alue\(s of the primary threshold it is su\016cien t to terminate the procedure as so on as N or more large itemsets ha v e b een generated at the lev el of supp ort b eing considered 2 It is not necessary to start the DHP pro cedure from scratc h in eac h iteration of the binary searc h pro cedure It is p ossible to reuse information b et w een iterations Let I  s  denote the itemsets whic hha v e supp ort at least s  It is p ossible to sp eed up the preprocessing algorithm b y reusing the information a v ailable in I  Low  Generating k itemsets in I  Mid  is only a matter of pic king those k itemsets in I  Low  whic h ha v e supp ort at least Low  This do es not mean that ev ery itemset in I  Mid  can b e immediately generated using this metho d Recall from 1 ab o v e that the DHP algorithm is often terminated b efore completion if more than N itemsets ha v e b een generated in that iteration Consequen tly  not all itemsets in I  Low  ma ybea v ailable but only those k itemsets for whic h k 024 k 0  for some k 0 are a v ailable Th us w eha v e all 


 0 1 2 3 4 5 6 7 8 9 x 10 4 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 0.016    Primary threshold Number of itemsets prestored T10.I4.D100K  T10.I6.D100K  T20.I6.D100K  Figure 8 Threshold v aration with itemsets prestored DataSet Conf Sup DHP Online T10.I4.D100K 90 0  3 100 sec instan taneous T10.I6.D100K 90 0  3 130 sec instan taneous T10.I6.D100K 90 0  2 240 sec 2 seconds T20.I6.D100K 90 0  5 100 sec instan taneous T able 3 Sample illustration s of the order of magnitude adv an tage of online pro cessing those k itemsets in I  Mid  v ailable for whic h k 024 k 0  These itemsets need not b e generated again 6 Empirical Results W e ran the sim ulation on an IBM RS/6000 530H w orkstation with a CPU clo c k rate of 33MHz 64 MB of main memory and running AIX 4.1.4 W e tested the algorithm empirically for the follo wing ob jectiv es 1 Prepro cessing sensitivit y The prepro cessing tec hnique is sensitiv e to the a v ailable storage space The larger the a v ailable space the lo w er the v alue of the primary threshold W e tested ho w the primary threshold v alue v aried with the storage space a v ailabili t y W e also tested ho w the running time of the prepro cessing algorithm scaled with the storage space 2 Online pro cessing time W e tested ho w the online pro cessing times scaled with the size of the output W e also made an order of magnitude comparison b et w een using an online approac h and a more direct approac h 3 Lev el of redundancy W e tested ho w the lev el of redundancy in the generated output set v aried with user sp eci\014ed lev els of supp ort and con\014dence W e sho w ed that the lev el of redundancy in the rules is quite high Th us redundancy elimination is an imp ortan t issue for an online user lo oking for compactness in represen tation of the rules 6.1 Generating the syn thetic data sets The syn thetic data sets w ere generated using a metho d similar to that discussed in Agra w al et al Generating the data sets w as a t w o stage pro cess 0 1 2 3 4 5 6 7 8 9 x 10 4 0 2 4 6 8 10 12 14 16 18 x 10 4    Number of itemsets prestored Relative Computational Effort for preprocessing T10.I4.D100K  T10.I6.D100K  T20.I6.D100K  Figure 9 Computation v ariation with itemsets prestored 0 5000 10000 15000 0 10 20 30 40 50 60    Number of rules generated Response Time in seconds T10.I4.D100K  T10.I6.D100K  T20.I6.D100K  Figure 10 Online resp onse time v ariation with rules generated 20 30 40 50 60 70 80 90 100 0 2 4 6 8 10 12   Support fixed at 0.15 Confidence Total Rules Generated Essential Rules  T10.I4.D100K  T10.I6.D100K   Figure 11 Redundancy lev el v ariation with con\014dence 


 0.1 0.15 0.2 0.25 0 10 20 30 40 50 60 70 80 90   Confidence fixed at 90 Support Total Rules Generated Essential Rules  T10.I4.D100K  T10.I6.D100K   Figure 12 Redundancy lev el v ariation with supp ort 1 Generating maximal p oten tially large itemsets The 014rst step w as to generate L  2000 maximal p oten tially large itemsets These p oten tially large itemsets capture the consumer tendencies of buying certain items together W e 014rst pic k ed the size of a maximal p oten tially large itemset as a random v ariable from a p oisson distribution with mean 026 L  Eac h successiv e itemset w as generated b y pic king half of its items from the curren t itemset and generating the other half randomly  This metho d ensures that large itemsets often ha v e common items Eac h itemset I hasaw eigh t w I asso ciated with it whic hisc hosen from an exp onen tial distribution with unit mean 2 Generating the transaction data The large itemsets w ere then used in order to generate the transaction data First the size S T of a transaction w as c hosen as a p oisson random v ariable with mean 026 T  Eac h transaction w as generated b y assigning maximal p oten tially large itemsets to it in succession The itemset to b e assigned to a transaction w as c hosen b y rolling an L sided w eigh ted die dep ending up on the w eigh t w I assigned to the corresp onding itemset I  If an itemset did not 014t exactly itw as assigned to the curren t transaction half the time and mo v ed to the next transaction the rest of the time In order to capture the fact that customers ma y not often buy all the items in a p oten tially large itemset together w e added some noise to the pro cess b y corrupting some of the added itemsets F or eac h itemset I w e decide a noise lev el n I 2 0  1 W e generated a geometric random v ariable G with parameter n I  While adding a p oten tially large itemset to a transaction w e dropp ed min f G j I jg random items from the transaction The noise lev el n I for eac h itemset I w as c hosen from a normal distribution with mean 0.5 and v ariance 0.1 W e shall also brie\015y describ e the sym b ols that w eha v e used in order to annotate the data The three primary factors whic hv ary are the a v erage transaction size 026 T  the size of an a v erage maximal p oten tially large itemset 026 L  and the n um b er of transactions b eing considered A data set ha ving 026 T  10 026 L  4 and 100 K transactions is denoted b y T10.I4.D100K W e tested ho w the primary threshold v aried with the n um b er of itemsets prestored This result is illustrated in Figure 8 The 014gure sho ws that the primary threshold initially drops considerably as the n um b er of primary itemsets increases but it b ottoms out after a while W e also illustrate the v ariation of the computational e\013ort required with the a v ailable storage space in Figure 9 W e note that for the itemset T10.I4.D100K the computational e\013ort required in order to 014nd additional large itemsets after 014nding 20000 itemsets increases considerably with the n um b er of itemsets prestored This is b ecause for this particular data set the a v erage size of a maximal p oten tially large itemset or bask et is only 4 Consequen tly  the total n um b er of p ossible large itemsets is relativ ely limited On the other hand the computational e\013ort for prepro cessing required b y the data sets T20.I6.D100K and T10.I6.D100K is relativ ely similar This sho ws that the computational e\013ort required to 014nd a sp eci\014c n um b er of primary itemsets is more sensitiv e to the size of a t ypical bask et in the data rather than to the size of a transaction W e also tested the v ariation in the online running time of the algorithm with the n um b er of rules generated W e ran the online queries for v arying lev els of input parameters in order to test the correlation b et w een the running time and the n um b er of rules generated This is illustrated in Figure 10 This result is signi\014can t in that it sho ws that the running time of the algorithm increases linearly with the n um b er of rules generated for all the data sets used The absolute magnitude of time required in order to generate the rules w as an order of magnitude smaller than the time required using a direct itemset generation approac h lik e DHP  A brief summary of some sample relativ e 014ndings is illustrated in T able 3 W e also discuss the lev el of redundancy presen t in the rule generation pro cedure Figures 11 and 12 illustrate that the n um b er of redundan t rules is often m uc h larger than the n um b er of essen tial rules The b enc hmark for measuring the lev el of redundancy is referred to as the redundancy ratio and is de\014ned as follo ws Redundancy Ratio  T otal Rules Generated Essen tial Rules 1 Th us when the redundancy ratio is K  then the n um ber of redundan t rules is K 000 1 times the n um b er of essen tial rules The redundancy ratio has b een plotted on the Y-axis in Figures 11 and 12 W e see that in most cases the n um ber of redundan t rules is signi\014can tl y larger than the n um ber of essen tial rules This illustrates the lev el to whic h useful rules often get buried in large n um b ers of redundan t rules Also the redundancy lev el is m uc h more sensitiv e to the supp ort rather than the con\014dence The lo w er the lev el of supp ort the higher the redundancy lev el 7 Conclusions and Summary In this pap er w ein v estigated the issue of online mining of asso ciation rules The t w o primary issues in v olv ed in online pro cessing are the running time and compactness in represen tation of the rules W e discussed an OLAP-lik e approac h for online mining asso ciation rules whic ha v oids redundancy  


Ac kno wledgemen ts W ew ould lik e to thank V S Ja yc handran and Jo el W olf for their extensiv e commen ts and suggestions References  Aggarw al C C and Y uP  S Online Generation of Asso ciation Rules IBM R ese ar ch R ep ort R C 20899  Agra w al R Imielinski T and Sw ami A Mining association rules b et w een sets of items in v ery large databases Pr o c e e dings of the A CM SIGMOD Confer enc e on Management of data pages 207-216 W ashington D C Ma y 1993  Agra w al R and Srik an tR.F ast Algorithms for Mining Asso ciation Rules in Large Databases Pr o c e e dings of the 20th International Confer enc eon V ery L ar ge Data Bases pages 478-499 Septem b er 1994  Agra w al R and Srik an t R Mining Sequen tial P atterns Pr o c e e dings of the 11th Internation al Confer enc e on Data Engine ering pages 3-14 Marc h 1995  Agra w al S Agra w al R Deshpande P  M Gupta A Naugh ton J F Ramakrishnan R and Sara w agi S On the Computation of Multidimensi on al Aggregates Pr o c e e dings of the 22nd International Confer enc eon V ery L ar ge Datab ases pages 506-521  Chen M S Han J and Y uP  S Data Mining An Ov erview from Database P ersp ectiv e IEEE T r ansactions on Know le dge and Data Engine ering V olume 8 Num b er 6 Decem b er 1996 pages 866-883  Dyreson C Information Retreiv al from an Incomplete Data Cub e Pr o c e e dings of the 22nd International Confer enc eon V ery L ar ge Datab ases pages 532-543 Mumbai India 1996  Gupta A Harinara y an V and Quass D Aggregatequery pro cessing in data w arehousing en vironmen ts Pr o c e e dings of the 21st Confer enc eon V ery L ar ge Datab ases Zuric h Switzerland Septem b er 1995  Han J and F u Y Disco v ery of Multiple-Lev el Assocaition Rules from Large Databases Pr o c e e dings of the 21st Internation al Confer enc eon V ery L ar ge Data Bases Zuric h Switzerland 1995 pages 420-431  Harinara y an V Ra jaraman A and Ullman J Implemen ting Data Cub es E\016cien tly  Pr o c e e dings of the 1996 A CM SIGMOD c onfer enc e on Management of Data Mon treal Canada June 1996 pages 205-227  Houtsma M and Sw ami A Set-orien ted Mining for Asso ciation Rules in Relational Databases Pr o c e e dings of the 11th Internation al Confer enc e on Data Engine ering Marc h 1995 pages 25-33  Kaufman L and Rousseeu wP J Finding Gr oups in Data A n Intr o duction to Cluster A nalysis Wiley Series in Probabilit y and Mathematical Statistics 1990  Klemen ttinen M Mannila H Ronk ainen P  T oiv onen H and V erk amo A I Finding in teresting rules from large sets of disco v ered asso ciation rules Pr o c e e dings of the Confer enc e on Information and Know le dge Managements Gaithersburg MD USA 28 No v 2 Dec 1994  Len t B Sw ami A and Widom J Clustering Asso ciation Rules Pr o c e e dings of the Thirte enth International Confer enc e on Data Engine ering pages 220-231 Birmingham UK April 1997  Mannila H T oiv onen H and V erk amo A I Ef\014cien t algorithms for disco v ering asso ciation rules AAAI Workshop on Know le dge Disc overy in Datab ases pages 181-192 Seattle W ashington July 1994  Ng R T and Han J E\016cien t and E\013ectiv e Clustering Metho ds for Spatial Data Mining Pr o c e e dings of the 20th Internation al Confer enc eon V ery L ar ge Data Bases San tiago Chile 1994 pages 144-155  P ark J S Chen M S and Y uP  S An E\013ectiv e Hash Based Algorithm for Mining Asso ciation Rules Pr o c e e dings of the 1995 A CM SIGMOD International Confer enc e on Management of Data pages 175-186 Ma y 1995  Piatetsky-Shapiro G Disco v ery  Analysis and Presentation of Strong Rules Know le dge Disc overy in Datab ases 1991  Sa v asere A Omiecinski E and Na v athe S An E\016cien t Algorithm for Mining Asso ciation Rules in Large Data Bases Pr o c e e dings of the 21st Internation al Confer enc eon V ery L ar ge Data Bases Zuric h Switzerland 1995 pages 432-444  Sh ukla A Deshpande P  M Naugh ton J F and Ramasam y K Storage Estimation for Multidimensi on al Aggregates in the Presence of Hierarc hies Pr o c e e dings of the 22nd Internationa l Confer enc eon V ery L ar ge Datab ases pages 522-531 Mum bai India 1996  Srik an t R and Agra w al R Mining Generalized Asso ciation Rules Pr o c e e dings of the 21st International Confer enc eon V ery L ar ge Data Bases  pages 407-419 Septem b er 1995  Srik an t R and Agra w al R Mining quan titativ e association rules in large relational tables Pr o c e e dings of the 1996 A CM SIGMOD Confer enc e on Management of Data Mon treal Canada June 1996  T oiv onen H Sampling Large Databases for Asso ciation Rules Pr o c e e dings of the 22nd International Conferenc eonV ery L ar ge Datab ases pages 134-145 Mumbai India 1996  Ziark o W The Disco v ery  Analysis and Represen tation of Data Dep endencies in Databases Know le dge Disc overy in Datab ases 1991 


CMP A Fast Decision Tree Classifier Using Multivariate Predictions  449 H Wang and C Zaniolo Mining Recurrent Items in Multimedia with Progressive Resolution Refinement  461 0 Zai'ane J Hun and H Zhu Panel Session 22 Is E-Commerce a New Wave for Database Research Moderator Anant Jhingran IBM T.J Watson Research Center USA Panelists Sesh Murthy IBM T.J Watson Research Center USA Sham Navathe, Georgia Institute of Technology USA Hamid Pirahesh IBM Almaden Research Center USA Krithi Ramamrithan University of Massachusetts-Amherst USA Industrial Session 23 Java and Databases Pure Java Databases for Deployed Applications  477 N Wyatt Database Technology for Internet Applications  700 A Nori Session 24 Association Rules and Correlations Finding Interesting Associations without Support Pruning  489 E Cohen M Datar S Fujiwara A Gionis P Indyk R Motwani J Ullman and C. Yang Dynamic Miss-Counting Algorithms Finding Implication and Similarity Rules with Confidence Pruning  501 S Fujiwara J Ullman and R Motwani Efficient Mining of Constrained Correlated Sets  512 G Grahne L Lakshmanan and X Wang Session 25 Spatial and Temporal Data Analyzing Range Queries on Spatial Data  525 J Jin N An and A Sivasubramaniam Data Redundancy and Duplicate Detection in Spatial Join Processing  535 J.-P Dittrich and B Seeger Query Plans for Conventional and Temporal Queries Involving Duplicates and Ordering  547 G Slivinskas C Jensen, and R Snodgrass xi 


Industrial Session 26 XML and Databases Oracle  The XML Enabled Data Management System  561 S Banerjee V Krishnamurthy M Krishnaprasad, and R Murthy XML and DB2  569 J Cheng and J Xu Session 27 High-Dimensional Data Independent Quantization An Index Compression Technique for High-Dimensional Data Spaces  577 S Berchtold, C Bohm H Jagadish H.-P. Kriegel and J Sander Deflating the Dimensionality Curse Using Multiple Fractal Dimensions  589 B.-U Pagel F Korn and C. Faloutsos Similarity Search for Multidimensional Data Sequences  599 S.-L Lee S.-J Chun D.-H Kim, J.-H Lee and C.-W Chung Session 28 Web-Based Systems WRAP An XML-Enabled Wrapper Construction System for Web Information Sources  611 L Liu C Pu and W. Hun Self-Adaptive User Profiles for Large-scale Data Delivery  622 U Cetintemel M Franklin and C. Giles Industrial Session 29 Main Memory and Small Footprint Databases In-Memory Data Management in the Application Tier  637 The TimesTen Team SQLServer for Windows CE -A Database Engine for Mobile and Embedded Platforms  642 P Seshadri and P. Garrett Join Enumeration in a Memory-Constrained Environment  645 I Bowman and G Paulley xii 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



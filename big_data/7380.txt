Mining Signi\002cant Frequent Patterns in Parallel Episodes with a Graded Notion of Synchrony and Selective Participation Salatiel Ezennaya-Gomez 1  2 and Christian Borgelt 1 1 Intelligent Data Analysis Research Unit European Centre for Soft Computing c Gonzalo Guti 264 errez Quir 264 os s/n 33600 Mieres 050Asturias\051 Spain 2 Department of Knowledge and Language Processing Otto-von-Guericke University Magdeburg Germany f salatiel.ezennaya christian.borgelt g softcomputing.es Keywords Graded Synchrony Synchronous Events Temporal Imprecision Selective Participation Frequent Pattern Mining Abstract We consider the task of 002nding frequent parallel episodes in parallel point processes 050or event sequences\051 allowing for imprecise synchrony of the events constituting occurrences 050temporal imprecision\051 as well as incomplete occurrences 050selective participation\051 The temporal imprecision problem is tackled by frequent pattern mining using a graded notion of synchrony that captures both the number of instances of a pattern as well as the precision of synchrony of its events To cope with selective participation a reduction sequence of items 050or event types\051 is formed based on found frequent patterns and guided by pattern overlap We evaluate the performance of this method on a large number of data sets with injected parallel episodes We demonstrate that in contrast to binary synchrony where it pays to consider the pattern instances graded synchrony performs better with a pattern-based scheme than with an instance-based one thus simplifying the procedure 1 INTRODUCTION We present elaborate methodology to identify meaningful frequent synchronous patterns in event sequences 050see e.g 050Mannila et al 1997\051\051 using the principles of frequent item set mining 050FIM\051 050see e.g 050Borgelt 2012\051\051 As is well known the objective of FIM is to 002nd all item sets that are frequent in a transaction database FIM uses the support 050number of occurrences in the transactions\051 to de\002ne an item set as frequent namely if its support reaches or exceeds a 050user-speci\002ed\051 minimum support threshold In standard FIM the support of an item set is a simple count of transactions whereas in our case the event sequence data is continuous in nature since it resides in the time domain and thus no 050natural\051 transactions exist This continuous form causes several problems especially w.r.t the de\002nition of a support measure Frequent pattern mining in continuous time faces two main problems temporal imprecision and selective participation  The former is related to the synchrony of events which is affected by temporal jitter due to which the events are usually not perfectly aligned In frequent pattern mining we tackle temporal imprecision by de\002ning that items 050or events\051 co-occur if they occur in a 050user-speci\002ed\051 limited time span from each other In earlier work the size of a maximum independent set 050MIS\051 of such synchronous groups of items which can be computed ef\002ciently with a greedy algorithm 050see 050Borgelt and Picado-Muino 2013\051 and 050Picado-Muino and Borgelt 2014\051\051 is used as a support measure This method is referred to as binary synchrony in 050Ezennaya-G 264 omez and Borgelt 2015\051 because it allows only for two values either a group of events is synchronous or it is not Unfortunately a greedy algorithm no longer guarantees an optimal solution when a graded notion of synchrony is introduced while a backtracking approach 050as it would be used for a general maximum independent set problem which is NP-complete\051 takes exponential time in the worst case As a consequence an adaptation is necessary which takes the form of an approximation procedure to compute the support but maintaining the crucial property of support being anti-monotone  To this end 050Ezennaya-G 264 omez and Borgelt 2015\051 de\002ned a graded synchrony approach where the support computation takes the precision of synchrony into account That is a pattern that has fewer occurrences but in each of these the items occur very closely together in time is rated better than an item set which has more instances but in each 


of these the synchrony of the events is rather loose 050Ezennaya-G 264 omez and Borgelt 2015\051 The second problem that is selective participation  is related to the lack of occurrence of some items which produces incomplete pattern instances As a consequence only subsets of the actual pattern are present in the instances underlying a pattern This can be caused by imperfections of the measuring technology or by properties of the underlying process 050Borgelt et al 2015\051 presented an approach to solve this problem in the binary synchrony setting we mentioned above The goal of this paper is to transfer this approach from the binary synchrony setting to a graded synchrony setting and to investigate whether the same conclusions can be drawn about the different variants considered in 050Borgelt et al 2015\051 The application area that motivates our work is the analysis of parallel spike trains in neurobiology Such spike trains are sequences of points in time one per neuron that represent the times at which an electrical impulse 050 action potential or spike 051 is emitted The objective is to identify cell assemblies or groups of neurons that tend to exhibit synchronous spiking Such cell assemblies were proposed in 050Hebb 1949\051 as a model for encoding and processing information in biological neural networks Since synchronous spike input to receiving neurons is known to be more effective in generating output spikes 050Abeles 1982 K 250 onig et al 1996\051 such cell assemblies are a plausible hypothesis for neural information processing The objective of this paper is to adapt the selective participation approach in an algorithm called CoCoNAD 050for Co ntinuous-time C l o sed N euron A ssembly D etection a name inspired by the mentioned application domain\051 to detect signi\002cant synchronous patterns with a graded notion of synchrony  As a 002rst step to identify of neuronal assemblies we look for frequent neuronal patterns 050i.e groups of neurons that exhibit frequent synchronous spiking 051 In this setting both temporal imprecision and selective participation are expected to be present and thus require proper treatment Once frequent patterns are detected additional 002ltering is necessary to remove those frequent patterns that are produced by chance events and thus are not relevant Then detection of selective participation is applied Due to the graded nature of the synchrony de\002nition we adopt the selective participation approach needs to be modi\002ed from the approach presented in 050Borgelt et al 2015\051 The remainder of this paper is structured as follows Section 2 covers basic terminology and notation and introduces our graded notion of synchrony In Sections 3 and 4 we show how a support based on graded synchrony is approximated and frequent synchronous patterns are mined and 002ltered using pattern spectrum 002ltering In Section 5 we present our methodology to identify frequent parallel episodes with selective participation with a graded notion of synchrony Section 6 reports experimental results on data sets with injected parallel episodes Finally in Section 6 we draw conclusions from our discussion 2 EVENT SEQUENCES  SYNCHRONY We adopt notation and terminology from 050Mannila et al 1997\051 and 050Ezennaya-G 264 omez and Borgelt 2015\051 The data are sequences of events S  fh i 1  t 1 i      h i m  t m ig  m 2 N  where i k in the event h i k  t k i is the event type or item 050taken from an item base B 051 and t k 2 R is the time of occurrence of i k  k 2 f 1      m g  Note that the fact that S is a set implies that there cannot be two events with the same item occurring at the same time events with the same item must differ in their occurrence time and events occurring at the same time must have different types/items Such data may as well be represented as parallel point processes P  fh i 1  f t 050 1 051 1      t 050 1 051 m 1 gi      h i n  f t 050 n 051 1      t 050 n 051 m n gig by grouping events with the same item i 2 B  n  j B j  and listing the times of their occurrences for each of them Finally note that in our motivating application 050i.e spike train analysis\051 the items 050or event types\051 are the neurons and the corresponding point processes list the times at which spikes were recorded for these neurons 050Ezennaya-G 264 omez and Borgelt 2015\051 A synchronous pattern 050in S 051 is de\002ned as a set of items I 022 B that occur several times 050approximately\051 synchronously in S  Formally an instance 050or occurrence 051 of such a synchronous pattern 050or a set of synchronous events for I 051 in an event sequence S with respect to a user-speci\002ed time span w 2 R  is de\002ned as a subsequence R 022 S  which contains exactly one event per item i 2 I and which can be covered by a time window at most w wide Let f the pattern operator that yields the pattern underlying an instance f 050 R 051  f i j h i  t i 2 R g  Hence the set of all instances of a pattern I 022 B  I 6   0  in an event sequence S is E S  w 050 I 051  010 R 022 S j f 050 R 051  I  j R j  j I j  s w 050 R 051  0 011  where s w is the synchrony operator which measures the degree of synchrony of the events in R  The synchrony operator should conincide with binary synchrony for limiting cases as follows if all events in R coincide 050i.e have exactly the same oc 


Figure 1 Degree of synchrony as a function of the distance between the latest and the earliest event currence time perfect synchrony\051 the degree of synchrony should be 1 while it should be 0 if the events are spread out farther than the window width w 050no synchrony\051 However if the 050time\051 distance between the earliest and the latest event in R is between 0 and w  we want a degree of synchrony between 0 and 1 Such a synchrony operator was described in 050Picado-Muino et al 2012\051 based on the notion of an in\003uence map which is placed at each event and describes the vicinity around an event in which synchrony with other events is de\002ned Such an in\003uence map for an event occurring at time t is de\002ned as a function f t 050 x 051  032 1  w if x 2  t 000 w  2  t  w  2   0 otherwise Based on in\003uence maps events are synchronous iff their in\003uence maps overlap The area of the overlap measures the degree of synchrony 050Figure 1\051 s w 050 R 051  Z 245 0 min h i  t i2 R f t 050 x  w 051 d x  Alternatively we may use the equivalent de\002nition s w 050 R 051  max n 0  1 000 1  w 020 max h i  t i2 R t 000 min h i  t i2 R t 021o  The synchrony operator underlies the de\002nition of a support operator s S  w 050 I 051 that is used to mine synchronous patterns The support should capture 050also\051 the number of occurrences of a pattern in a given event sequence S  In addition in order to be ef\002cient frequent pattern mining requires support to be anti-monotone  8 I 022 J 022 B  s S  w 050 I 051 025 s S  w 050 J 051  Or in words if an item is added to an item set its support cannot increase  This implies the so-called apriori property  8 I  J 022 B  050 J 023 I  s S  w 050 I 051  s min 051 051 s S  w 050 J 051  s min  Or in words no superset of an infrequent pattern can be frequent  The apriori property allows to prune the search for frequent patterns effectively 050Borgelt 2012\051 Given a support measure and a 050user-speci\002ed\051 minimum support s min  the task of frequent synchronous pattern mining is de\002ned as the task to identify all item sets I 022 B with s S  w 050 I 051 025 s min 050\050Borgelt 2012\051\051 Figure 2 Support computation for three items a  b  c  Each event has its in\003uence map 050represented as a rectangle\051 If two in\003uence maps overlap the resulting in\003uence map is the maximum 050union\051 of these in\003uence maps The intersection of in\003uence maps is the minimum which de\002nes the synchrony operator In the diagram item b has two events the in\003uence regions of which overlap The support results from the integral over the intersections 3 SUPPORT COMPUTATION FOR GRADED SYNCHRONY For binary synchrony the support is computed ef\002ciently using a greedy algorithm However following 050Ezennaya-G 264 omez and Borgelt 2015\051 and as we mentioned in the introduction for graded synchrony such an approach does not guarantee an optimal result and thus needs to be replaced by an approximation As such an approximation de\002ned in 050EzennayaG 264 omez and Borgelt 2015\051 the integral over the maximum 050union\051 of the minimum 050intersection\051 of in\003uence regions is chosen the minimum represents the synchrony operator the maximum takes care of a possible overlap between instances of synchronous event groups and the integral 002nally aggregates over different instances Formally s S  w 050 I 051  Z 245 000 245 max R 2 E S  w 050 I 051 020 min h i  t i2 R f t 050 x 051 021 d x  The advantages of this support measure are mainly two in the 002rst place the support measure de\002ned in this way is anti-monotone due to the minimum over i 2 I  Secondly it allows to compute the support by a simple intersection of interval lists since all occurring functions only take two values namely 0 and 1  w  and therefore it suf\002ces to record where they are greater than 0 Thus the list of intervals for each item i 2 B in which max h j  t i2 S  j  i f t 050 x 051  0 is computed These intervals can then be intersected to account for the minimum Summing the interval lengths and dividing by w we obtain the area under the functions 050see the example described in Figure 2\051 


Note that this computation scheme is very similar to the Eclat algorithm 050Zaki et al 1997\051 050which works by intersecting transaction identi\002er lists\051 transferred to a continuous domain 050and thus to effectively in\002nitely many transactions\051 As a consequence Eclat's item set enumeration scheme which is based on a simple divide-and-conquer approach can be applied with only few adaptations 050concerning mainly the support computation\051 to obtain an ef\002cient algorithm for mining frequent synchronous patterns 050see e.g 050Borgelt 2012\051\051 4 PATTERN SPECTRUM FILTERING The large number of patterns in the output of synchronous pattern mining method is a problem and thus further reduction is necessary This is done by identifying statistically signi\002cant patterns Previous work showed that statistical tests on individual patterns are not suitable 050Picado-Muino et al 2013 Torre et al 2013\051 The main problems are the lack of proper test statistics as well as multiple testing  that is the huge number of patterns makes it very dif\002cult to control the family-wise error rate even with control methods like Bonferroni correction  the BenjaminiHochberg procedure or the false discovery rate etc 050Dudoit and van der Laan 2008\051 To overcome this problem we rely here on the approach suggested in 050Picado-Muino et al 2013\051 and re\002ned in 050Torre et al 2013\051 namely Pattern Spectrum Filtering 050PSF\051 This method is based on the following insight even if it is highly unlikely that a speci\002c group of z items co-occurs s times it may still be likely that some group of z items co-occurs s times even if items occur independently From this insight it was derived in 050Picado-Muino et al 2013\051 that patterns should rather be judged based on their signature h z  s i  where z  j I j is the size of a pattern I and s its support A pattern is not signi\002cant if a counterpart which has the same or larger pattern size z and same or higher support s can be explained as a chance event under the null hypothesis of independent events In order to determine the likelihood of observing different pattern signatures h z  s i under the null hypothesis of independent items a data randomization or surrogate data approach is employed The general idea is to represent the null hypothesis implicitly by 050surrogate\051 data sets that are generated from the original data in such a way that their occurrence probability is 050approximately\051 equal to their occurrence probability under the null hypothesis Such an approach has the advantage that it needs no explicit data model Figure 3 Pattern spectrum generated from 10 4 surrogate data sets for the null hypothesis which in many cases 050including the one we are dealing with here\051 may be dif\002cult to specify Instead the original data is modi\002ed in random ways to obtain data that are at least analogous to those that could be sampled under conditions in which the null hypothesis holds An overview of several surrogate data methods in the context of neural spike train analysis can be found in 050Louis et al 2010\051 Summarizing the objective of PSF is to pool the resulting patterns from the output of synchronous pattern mining with the same or larger signature h z  s i 002ltering by the surrogate data sets generated as an implicit representation of the null hypothesis An example of such a pattern spectrum for data as it will be used in Section 6 is shown in Figure 3 It captures what pattern signatures occurred in a large number of surrogate data sets Note that since we are working in continuous time domain the support values are 050nonnegative\051 real numbers 5 SELECTIVE PARTICIPATION METHOD To achieve the purpose of this paper we draw in the same idea described in 050Borgelt et al 2015\051 to identify parallel episodes in the presence of selective participation The approach is based on the following insight although incomplete occurrences of a pattern may make it impossible that the full pattern is reported by the mining procedure it is highly likely that several overlapping subsets will be reported An example of this situation is illustrated in Figure 4 which shows parallel spike trains of six neurons a to f with complete and incomplete instances of the parallel episode comprising all six neurons 050in blue while background spikes are shown in gray\051 Although the full set of neurons 002res together only once 050leftmost instance\051 and thus would not be detected the other 002ve incomplete occurrences give rise to 002ve subsets of size 4 each of which occurs twice and many sub 


Figure 4 Parallel episodes 050indicating neuron assembly activity\051 with selective participation 050blue\051 as well as background spikes 050gray\051 sets of size 3 occurring 3 or more times Since these patterns overlap heavily it should be possible to reconstruct the full pattern by analyzing pattern overlap and combining patterns The method views the set of patterns that were found in a given data set as a hypergraph 1 on the set of items 050which are the vertices of this hypergraph\051 each pattern forms a hyperedge Patterns that are affected by selective participation thus give rise to densely connected sub-hypergraphs Hence we should be able to identify such patterns by 002nding densely connected sub-hypergraphs 050Borgelt et al 2015\051 The method draws on the approach proposed in 050Tsourakakis et al 2013\051 for detecting dense subhypergraphs Although this approach was designed to 002nd dense subgraphs in standard graphs its basic idea is easily transferred and adapted we form a reduction sequence of items by removing in each step the item that is least connected to the other items 050that are still considered\051 Then we identify from this sequence the set of items where the least connected item 050i.e the one that was removed next\051 was most strongly connected 050compared to other steps of the sequence\051 This item set is the result of the procedure 050Borgelt et al 2015\051 Although this limits the basic procedure to the identi\002cation of a single pattern it is clear that multiple patterns can easily be found with the same amendment as suggested in 050Tsourakakis et al 2013\051 002nd a pattern and then remove the underlying items 050vertices\051 from the data Repeat the procedure on the remaining items to 002nd a second pattern Remove the items of this second pattern and so on A drawback of this approach is that it can 002nd only disjoint patterns and thus fails to identify overlapping patterns However given the general dif\002culty to handle selective participation we believe that this is an acceptable shortcoming Formally a reduction sequence of item sets is constructed starting from the item base B  as  1 While in a standard graph any edge connects exactly two vertices in a hypergraph a single hyperedge can connect arbitrarily many vertices J n  B  where n  j B j  J k  J k  1 000 f argmin i 2 J k  1 x S  w  s min 050 i  J k  1 051 g  for k  n 000 1  n 000 2      0  where x S  w  s min 050 i  J k 051 denotes the strength of connection that item i 2 J k has to the other items in the set J k  as it is induced by the 050closed\051 frequent patterns found when mining the sequence S with window width w and minimum support s min 050concrete functions x S  w  s min 050 i  J k 051 are studied below\051 Then we assign a quality measure to each element of this reduction sequence 8 k  0 024 k 024 n  x S  w  s min 050 J k 051  min i 2 J k x S  w  s min 050 i  J k 051  Finally we select the pattern 050item set\051 I  argmax J k 0 024 k 024 n x S  w  s min 050 J k 051  that is the pattern with the highest quality 050subhypergraph density\051 as the result of our procedure To obtain concrete instances of the functions x S  w  s min 050 i  J k 051  two different approaches were de\002ned in 050Borgelt et al 2015\051 a pattern-based approach which works with patterns and support and instancebased approach which tries to remove instances to focus the evaluation on instances that likely resulted from the actual assembly activity These methods are described for binary synchrony To apply them to our graded synchrony a re-de\002nition of the latter was necessary and it is described further down Pattern-based Approach Let C 003 S 050 w  s min 051 022 2 B be the set of closed frequent patterns that are identi\002ed by the CoCoNAD algorithm with a graded notion of synchrony 050if executed with window width w and minimum support s min on S 051 for which no counterpart 050no signature with the same size and greater or equal support constitutes a counterpart\051 was observed in any of the surrogate data sets 050that is the closed frequent patterns remaining after pattern spectrum 002ltering\051 Let C 003 S  J 050 w  s min 051  f I 2 C 003 S 050 w  s min 051 j I 022 J g be the subset of these patterns that are subsets of an item set J  Then we de\002ne the hypergraph connection strength of item i 2 J to the other items in J as x 050 pat 051 S  w  s min 050 i  J 051  345 I 2 C 003 S  J 050 w  s min 051 050 j I j 000 r 051 001 s S  w 050 I 051  where r 2 f 0  1 g is a parameter that determines whether the full pattern size 050hyperedge size\051 should be considered 050 r  0\051 or whether the item i itself should be disregarded 050 r  1\051 The support of the item set I enters the de\002nition because a larger support clearly means a stronger connection 


Figure 5 Experimental results with n  1 050each item missing from one instance\051 Patterns 002ltered by 10 100 and 1000 surrogate data sets Intuitively x 050 pat 051 S  w  s min 050 i  J 051 sums the grades of synchrony underlying each of the patterns that connect i to the other items in J  Note that in this de\002nition we assume 050as is common practice\051 that x 050 pat 051 S  w  s min 050 i  J 051  0 if C 003 S  J 050 w  s min 051   0  This approach has the advantage that merely the 002ltered set of closed frequent patterns is needed However it has the disadvantage that subset patterns which by chance occur again outside of the instances of the full pattern may deteriorate the detection quality An example of such an occurrence can be seen in Figure 4 the neurons a  b and e 002re together between the second and third instance of the full set However this is not an incomplete instance of the full set but rather a chance coincidence resulting from the background spikes This can lead to a subset being preferred to the full pattern even though the sum in the above de\002nition gives higher weight to events that support multiple instances 050as these are counted multiple times\051 Removing instances is necessary to improve the detection quality To obtain concrete instances of the functions x S  w  s min 050 i  J k 051 we de\002ne Instance-based Approach We start from the same idea in 050Borgelt et al 2015\051 that we only want to consider instances that are not 223isolated\224 but 223overlap\224 some other instance 050preferably of a different pattern\051 The reason is that isolated instances likely stem from chance coincidences while instances that 223overlap\224 other instances likely stem from the same 050complete or incomplete\051 instance of the full pattern we try to identify Unlike 050Borgelt et al 2015\051 where the instance-based approach merely counts spikes without considering the precision of synchrony in our approach we recompute the support from the reduced set of instances which is simple as the instances are known Let C 003 S 050 w  s min 051 and C S  J 050 w  s min 051 be de\002ned as above Let U S  w 050 I 051 022 E S  w 050 I 051 be the set of all instances of I that was identi\002ed by the CoCoNAD algorithm in order to compute the support s S  w 050 I 051  Furthermore let V S  w  s min 050 J 051  S I 2 C 003 S  J 050 w  s min 051 U S  w 050 I 051  That is V S  w  s min 050 J 051 is the set of all instances underlying all patterns found in S that are subsets of J  To implement our idea of keeping overlapping instances of different patterns we de\002ne V 003 S  w  s min 050 i  J 051  f R 2 V S  w  s min 050 J 051 j  9 T 2 V S  w  s min 050 J 051  f 050 T 051 6  f 050 R 051  o i 050 T  R 051  1 g  where f is the pattern operator de\002ned in Section 2 and o i 050 R  T 051 is an operator that tests whether the instances R and T overlap In words V 003 S  w  s min 050 i  J 051 is the set of instances of patterns that contain the item i 2 J and are subsets of the set J  which overlap at least one other instance of a different pattern The operator o i checks whether the instances have a non-empty intersection The instance-based approach has the advantage that chance coincidences are much less likely to deteriorate the detection quality However its disadvantage is that it is more costly to compute because not just the patterns but the individual instances of all relevant patterns have to be processed 


Figure 6 Example of generated data sets that imitate parallel neural spike trains Each row of blue dots represents the spike train of each neuron In this example the injected patterns are drawn in red The selective participation adaptation method proposes to study only instances that overlap with other instances of different patterns re-compute the support for these patterns and 002nally apply the pattern-based approach 6 EXPERIMENTS We implemented our frequent synchronous pattern mining method in Python using an ef\002cient C-based Python extension module that implements the pattern mining and surrogate generation 2 We generated event sequence data as independent Poisson processes with parameters chosen in reference to our application domain 100 items 050number of neurons that can be simultaneously recorded with current technology\051 20Hz event rates 050typical average 002ring rate observed in spike train recordings\051 3s total time 050typical recording times for spike trains range from a few seconds up to about an hour\051 Into such independent data sets we injected a single synchronous pattern each with sizes z ranging from 2 to 12 items and numbers c of occurrences 050instances\051 ranging from 2 to 12 To simulate imprecise synchrony the events of each pattern instance were jittered independently by drawing an offset from a uniform distribution on  000 1ms   1ms  050which corre 2 The implementation of the CoCoNAD algorithm is developed in Python 050Rossum 1993\051 and the core of the algorithm is developed in C 050Kernighan and Ritchie 1978\051 This implementation can be found at http://www.borgelt.net/coconad.html and http://www.borgelt.net/pycoco.html A Java graphical user interface is available at http://www.borgelt.net/cocogui.html The scripts with which we executed our experiments as well as the complete result diagrams 050all parameter combinations\051 will be available at http://www.borgelt.net/hypernad.html sponds to typical bin lengths for time-binning of parallel neural spike trains which are 1 to 7ms\051 An example of such a data set is depicted in Figure 6 To simulate selective participation we deleted each item of a parallel episode from a number n 2 f 1  2  3  4  5 g of their instances This created data sets with instances similar to those shown in Figure 4 050which corresponds to z  6 c  6 and n  1 but has much fewer background spikes\051 a few instances may be complete but most lack a varying number of items For each signature h z  c i of a parallel episode and each value of n we created 1000 such data sets Then we tried to detect the injected synchronous patterns with the methods described in Sections 4 and 5 For mining closed frequent patterns we used different values of the window width w 2 f 2  3  4  5 g 050matching the jitter of the temporal imprecision\051 using a minimum support s min  1  0 and a minimum pattern size z min  2 Based on results presented in 050Ezennaya-G 264 omez and Borgelt 2015\051 the window value used is 3  2 j  Then 002ltering patterns mined with different pattern spectrum derived from 10 100 and 1000 data sets with independent spike trains The method described in Section 5 is applied to the resulting patterns Some of the results we obtained are depicted in Figures 5 7 and 8 In each row of the 002gures the 002rst diagram shows the number of 050strict\051 false negatives that is the fraction of runs 050of 1000\051 in which something else than exactly the injected pattern was found In order to elucidate what happens in those runs in which the injected parallel episode was not 050exactly\051 detected the diagrams in columns 2 and 3 show the fraction of runs in which a superset or a subset respectively of the injected parallel episode was returned Column 4 shows the fraction of runs with overlap patterns 050the reported pattern contains some but not all of the items of the injected parallel episode and at least one other item\051 column 5 the fraction of runs with patterns that are unrelated to the injected parallel episode On top of each diagram the different approaches are shown with its parameters The 002rst value corresponds to the number of missing instances followed by the type of 002lter and the type of reduction sequence approach applied and value of r parameter Figure 5 shows the different results obtained by 002ltering closed frequent patterns with the different patterns spectra 05010 100 and 1000\051 Note that graded synchrony has less problems with unrelated patterns We observe that 002ltering by surrogates derived from 100 and 1000 performs better w.r.t unrelated patterns That is 002ltering with 100 and 1000 surrogate data sets detect every injected pattern if only something is detected at all Figure 7 shows a comparison between 


Figure 7 Experimental results with instance-based approach and pattern-based approach for graded synchrony 050each item missing from one instance\051 Figure 8 Comparison between the instance/pattern-based approach for graded synchrony and the instance-based approach for binary synchrony the instance-based approach and the pattern-based approach using graded synchrony The 002rsts two rows of diagrams show results for r  0 and the second two rows correspond to r  1 The pattern-based approach is slightly better than the instance-based approach in terms of false negatives 050exact pattern detection\051 Concretely for r  1 the pattern-based approach has better ratios in supersets and overlaps by 


paying a price of a slightly worse ratio for subsets Taken together the price of having more subsets is preferred because subsets contain only items actually in the assembly while superset and overlap patterns also contain unrelated items The 002rst and second row of 002gure 8 correspond to the instance and the pattern-based approach for graded synchrony The third corresponds to the instance-based approach for binary synchrony Comparing the diagrams for unrelated patterns our graded method detects all injected patterns 050\002rst and second rows\051 while the binary method also produces unrelated pattern In 050Borgelt et al 2015\051 it is demonstrated that the instance-based approach yields slightly better results than the pattern approach However this approach does not consider the precision of synchrony Surprisingly using only the pattern-based approach with a graded notion of synchrony yields a better ratio for overlap and superset patterns 7 CONCLUSIONS In this paper we presented a method to detect frequent synchronous patterns in event sequences using a graded notion of synchrony for mining patterns in the presence of imprecise synchrony of events constituting occurrences and selective participation 050incomplete occurrences\051 Our method adapts methods presented in the literature to tackle selective participation using binary synchrony especially the instancebased approach which looks at instances of patterns to improve the detection by removing instances that are likely chance events checking the precision of synchrony of these instances We demonstrate in our experiments that using a graded notion of synchrony for support computation helps to simplify the detection of selective participation because a pattern-based approach yields better results or at least equally good results as an instance-based approach This is a considerable advantage since identifying the individual pattern instances is costly and thus it is desirable to avoid it ACKNOWLEDGMENTS The work presented in this paper was partially supported by the Spanish Ministry for Economy and Competitiveness 050MINECO Grant TIN2012-31372\051 and by the Principality of Asturias through the 2013-2017 Science Technology and Innovation Plan 050Programa Asturias CT1405206\051 and the European Union through FEDER funds REFERENCES Abeles M 0501982\051 Role of the cortical neuron Integrator or coincidence detector Israel Journal of Medical Sciences  18\0501\051:83\22692 Borgelt C 0502012\051 Frequent item set mining In Wiley Interdisciplinary Reviews 050WIREs\051 Data Mining and Knowledge Discovery  pages 437\226456 050 J Wiley  Sons Chichester United Kingdom 2 Borgelt C Braune C and Loewe K 0502015\051 Mining frequent parallel episodes with selective participation In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  Gijon Spain Atlantis Press Borgelt C and Picado-Muino D 0502013\051 Finding frequent synchronous events in parallel point processes In Proc 12th Int Symposium on Intelligent Data Analysis 050IDA 2013 London UK\051  pages 116\226126 Berlin/Heidelberg Germany Springer-Verlag Dudoit S and van der Laan M J 0502008\051 Multiple Testing Procedures with Application to Genomics  Springer New York USA Ezennaya-G 264 omez S and Borgelt C 0502015\051 Mining frequent synchronous patterns with a graded notion of synchrony In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  pages 1338\2261345 Gijon Spain Atlantis Press ISBN 050on-line\051 978-94-62520-77-6 Hebb D O 0501949\051 The Organization of Behavior  J Wiley  Sons New York NY USA Kernighan W and Ritchie D 0501978\051 The C Programming Language  Prentice Hall K 250 onig P Engel A K and Singer W 0501996\051 Integrator or coincidence detector the role of the cortical neuron revisited Trends in Neurosciences  19\0504\051:130\226137 Louis S Borgelt C and Gr 250 un S 0502010\051 Generation and selection of surrogate methods for correlation analysis In Gr 250 un S and Rotter S editors Analysis of Parallel Spike Trains  pages 359\226382 Springer-Verlag Berlin Germany Mannila H Toivonen H and Verkamo A 0501997\051 Discovery of frequent episodes in event sequences In Data Mining and Knowledge Discovery  pages 259\226 289 Springer New York NY USA 1\0503\051 Picado-Muino D and Borgelt C 0502014\051 Frequent itemset mining for sequential data Synchrony in neuronal spike trains Intelligent Data Analysis  18\0506\051:997\226 1012 Picado-Muino D Borgelt C Berger D Gerstein G L and Gr 250 un S 0502013\051 Finding neural assemblies with frequent item set mining Frontiers in Neuroinformatics  7 Picado-Muino D Castro-Le 264 on I and Borgelt C 0502012\051 Fuzzy frequent pattern mining in spike trains In Proc 11th Int Symposium on Intelligent Data Analysis 050IDA 2012 Helsinki Finland\051  pages 289\226300 Berlin/Heidelberg Germany Springer-Verlag 


Rossum G V 0501993\051 Python for unix/c programmers copyright 1993 guido van rossum 1 In Proc of the NLUUG najaarsconferentie Dutch UNIX users group  Torre E Picado-Muino D Denker M Borgelt C and Gr 250 un S 0502013\051 Statistical evaluation of synchronous spike patterns extracted by frequent item set mining Frontiers in Computational Neuroscience  7 Tsourakakis C Bonchi F Gionis A Gullo F and Tsiarli M 0502013\051 Denser than the densest subgraph Extracting optimal quasi-cliques with quality guarantees In Proc 19th ACM SIGMOD Int Conf on Knowledge Discovery and Data Mining 050KDD 2013 Chicago IL\051  pages 104\226112 New York NY USA ACM Press Zaki M J Parthasarathy S Ogihara M and Li W 0501997\051 New algorithms for fast discovery of association rules In Proc 3rd Int Conf on Knowledge Discovery and Data Mining 050KDD 1997 Newport Beach CA\051  pages 283\226296 Menlo Park CA USA AAAI Press 



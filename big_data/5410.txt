Real-Time Scheduling in MapReduce Clusters 
Abstract 
Chen He                            Ying Lu                     David Swanson Computer Science & Engineering Department, University of Nebraska-Lincoln Lincoln NE, United States che, ylu, dswanson}@cse.unl.edu 
MapReduce has been widely used as a Big Data processing platform. As it gets popular, its scheduling becomes increasingly important. In particular, since many MapReduce applications require real-time data processing, scheduling realtime applications in MapReduce environments has become a significant problem. In this paper, we create a novel real-time scheduler for MapReduce, which overcomes the deficiencies of 
an existing scheduler. It avoids accepting jobs that will lead to deadline misses and improves the cluster utilization. We implement our scheduler in Hadoop system and experimental results show that our scheduler provides deadline guarantees for accepted jobs and achieves good cluster utilization 
Keywords: real-time scheduling; MapReduce; cluster utilization 
 
I INTRODUCTION MapReduce is a framework used by Google for processing huge amounts of data in a distributed environmen d Had oop 2 is A p ach eês open s o u rce  implementation of the MapReduce framework. Due to the simplicity of the programming model, MapReduce is widely used for many applications en t log s  f r o m F acebook s  
website are imported into a Hadoop cluster every hour where they are used for a variety of applications, including analyzing usage patterns to improve site design, detecting spam, data mining and ad optimization T h e New York  Times rents a Hadoop cluster from Amazon EC o  conduct large scale image conversions als o  used to store and process tweets, log files, and many other types of data generated across Tw A s Map R e du ce clusters get popular, their performance modeling   26 an d s c h e du li n g b eco m e in creas i n g l y i m portan t Yahoo! developed the capacity scheduler to share a Hadoop cluster among multiple groups and users  s  fair scheduler enabled fair sharing in MapRedu  particular, since many MapReduce applications  including some of the aforementioned ones \(e.g., online data 
analytics for spam detection and ad optimization\, require real-time data processing, scheduling real-time applications in MapReduce environments has become a significant problem     20 23  Polo et al. [11 elope d a s o f t realti m e s c h e du ler th at  allows performance-driven management of MapReduce jobs. Dong et al. [13 ten ded th e w o rk b y P o lo et al  where a two-level MapReduce scheduler was developed to schedule mixed soft real-time and non-real-time jobs according to their respective performance demands Although taking MapReduce jobsê QoS into consideration most existing approaches [1    20  do n o t  provide deadline guarantees for the jobs. Ferguson et al developed Jockey r o v i de gu aran teed j ob laten c y i n  
data parallel clusters. Their approach, however, can only be applied to control recurring jobs. Kc and Anyanw  developed a Deadline Constraint scheduler, aiming to provide time guarantees for MapReduce jobs. However, the Deadline Constraint scheduler has several deficiencies which may lead to not only resource underutilization but also deadline violations \(please refer to Section III for detailed analysis This paper develops a novel Real-Time MapReduce RTMR\eduler to not only provide deadline guarantees for MapReduce applications but also ensure good utilization of MapReduce clusters.  The remainder of this paper is organized as follows. Section 2 presents the background. In Section 3, we briefly describe the Deadline Constraint sche d its def ici en cies  Section 4 pres e n ts o u r  
new scheduling algorithm in detail. Evaluations of these two schedulers are provided in Section 5. Section 6 concludes the paper II 
BACKGROUND In this section, we briefly describe how a Hadoop cluster works since other MapReduce-style clusters work similarly In later parts of this paper, we will thus use the terms Hadoop clusteré and çMapReduce cluster interchangeably. A Hadoop cluster is often composed of many commodity PCs, where one PC acts as the master node and others as slave/worker nodes. A Hadoop cluster uses Hadoop Distributed File System \(HDFS t o  manage its data. It divides each file into small fixed-size e.g., 128 MB\s and stores several \(e.g., 3\ of 
 
each block in local disks of cluster machines. A MapReduce  pu ta tion i s co m pos ed of t w o s t a g es  m a p a n d redu ce   which take a set of input key/value pairs and produce a set of output key/value pairs. When a MapReduce job is submitted to the cluster, it is divided into M map tasks and R reduce tasks, where each map task will process one block of input data A Hadoop cluster uses worker nodes to execute map and reduce tasks.  There are limitations on the number of map and reduce tasks that a worker node can accept and execute simultaneously \(i.e., map and reduce slots\, a worker node sends a heartbeat signal to the master node Upon receiving a heartbeat from a worker node that has empty map/reduce slots, the master node invokes the 
MapReduce scheduler to assign tasks to the worker node. A worker node that is assigned a map task reads the content of the corresponding input data block from a local or remote disk, parses input key/value pairs out of the block, and passes each pair to the user-defined map function. The map function generates intermediate key/value pairs, which are buffered in memory, and periodically written to the local disk and divided into R regions by the partitioning function The locations of these intermediate data are passed back to the master node, which is responsible for forwarding these locations to reduce tasks. A reduce task uses remote procedure calls to read the in termediate data generated by 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6 2013 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/HPCC.and.EUC.2013.216 1536 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6 2013 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/HPCC.and.EUC.2013.216 1536 


m n m n m n r s r s r s 
Map function Map function Reduce function Reduce function 
r s 
s r 
  
min number of map slots available upon the jobês arrival, the job can still finish its map stage on time and meet the jobês deadline if we have more resources available at a later time point Furthermore, the constraint scheduler does not consider the case where slots become available and utilized at different time points. Due to these reasons, the Deadline Constraint scheduler rejects tasks unnecessarily and cannot well utilize system resources Last but not the least, the schedulability test conditions checked by the scheduler are insufficient to ensure the deadline constraint. As a result, accepted jobs may actually miss their deadlines, violating the schedulerês real-time property. The cause for the deadline violation is that the scheduler only checks if a certain number of reduce slots are available at a particular time point max 
max A amount of time to complete its map stage Unlike for the reduce stage, the Deadline Constraint scheduler assumes that each job executes at a minimum degree of task parallelism for the map stage. That is, the scheduler only assigns the job the minimum number min 
   
the M map tasks of the job. Each reduce task is responsible for a region \(partition\ of intermediate data with certain keys. Thus, it has to retrieve its partition of data from all worker nodes that have executed the M map tasks. This process is called shuffle, which involves many-to-many communications among worker nodes. The reduce task then reads in the intermediate data and invokes the reduce function to produce the final output data \(i.e., output key/value pairs\or its reduce partition Fig u r e I  illustrates Hadoop framework and computation  Figure 1 III Deadline Constraint Scheduler The Deadline Constraint schedu s to ens u re  deadlines for real-time MapReduce jobs. After a job is submitted, the scheduler first determines whether the job can be completed within the specified deadline or not using a schedulability test. It assumes that 1\ a jobês reduce stage does not start until the jobês map tasks finish and 2\obês reduce tasks all start execution simultaneously for the same amount of time that is known a priori. Based on these assumptions, it first calculates the latest start time max for a jobês reduce stage, which is also the deadline for the jobês map tasks. If the job arrives at time A, then the job has at most of map slots that are required to meet its deadline. The scheduler, however, demands all min map slots to be available simultaneously at the jobês arrival time Upon a jobês submission, the constraint scheduler carries out the schedulability test. The job is rejected if min number of map slots are not available at that time. The job is also rejected if the number of reduce slots available at max is smaller than the total number of reduce tasks specified for the job The Deadline Constraint scheduler, however, has some limitations and deficiencies, which may lead to resource underutilization and deadline vi olations. First, because the scheduler assumes that all reduce tasks of a job start to run simultaneously, it cannot accept a job with more reduce tasks than the clusterês total number of reduce slots. Second by checking the aforementioned two conditions in the schedulability test, the scheduler only considers a single scenario where the jobês deadline might be satisfied. Those conditions are, however, unnecessary for meeting a jobês deadline. Many jobs that do not pass the test can nevertheless be accepted and completed by their deadlines For instance, even if the system does not have Instead, the job requires the specified number of reduce slots available for the whole time interval max  h ere D is th e j ob s  deadline IV RTMR Scheduler In this paper, we develop a new Real-Time MapReduce RTMR\ scheduler for heterogeneous clusters. RTMR scheduler not only provides deadline guarantees to accepted jobs but also well utilizes system resources. We have made the following three assumptions when designing RTMR scheduler The input data is available in Hadoop Distributed  File System \(HDFS\ore a job starts No preemption is allowed. The proposed scheduler  orders the job queue according to job deadlines  However, once a job starts to execute its first map  task, the job will not be preempted. That is, even if  a new coming job B has an earlier deadline than a  currently running job A, our scheduler makes no  attempt to execute Bês tasks before Aês tasks A MapReduce job contains two stages: map and  reduce stages. Similar to [11  13 w e ass um e  that a jobês reduce stage does not start until the  jobês map tasks have all finished RTMR scheduler is composed of three components. The first and most important one is the admission controller which makes decisions on whether to accept or reject a job The second component is the job dispatcher, which assigns tasks to execute on worker nodes. The last component is the feedback controller. Since a job may finish at a different time than estimated, a feedb ack controller is designed to keep the admission controller up-to-date 
Hadoop Framework and Computation 
H D F S Slave nodes Master node Intermediate K,V Slave nodes Shuffle Shuffle H D F S Output Output Output Assign Map Task Assign Reduce Task 
     
Input Input Input Map Stage Reduce  Stage 
n m 
1537 
1537 


rrrr q Tttt 
003\004 005\006 
 
M i m i 
002 002 002 004 004 003 003 
J l J J 
             
002\002 
Before describing the algorithm, we first present the parameters and data structures used in RTMR scheduler J=\(A, D, M, R A MapReduce job J is specified  by the tuple \(A, D, M, R where A is the job  arrival time, D is the relative deadline, M and R  respectively specify the number of map and reduce  tasks for the job, and is the input data size of the  job. For a MapReduce job, each map task processes  a unique part of the jobês input data where  the estimated maximum ratio between a jobês  intermediate data size and input data size for the jobês reduce  stage is at most of the jobês intermediate data, where   c m the estimated time of retrieving and processing a  unit of data in a map task the estimated longest time of retrieving and  processing a unit of data in a map task. The time to  retrieve data for a map task varies depending on  where the input data is located \(i.e., in memory  local disk, or remote disk\. In addition, for a  heterogeneous cluster, the task execution time  differs on different nodes max gives the worst-case estimation c r the estimated time of retrieving and processing a  unit of data in a reduce task the estimated longest time of retrieving and  processing a unit of data in a reduce task  12   For each accepted job  J, we maintain a sorted vector to record the  available time of the clusterês map slots  after the scheduled execution of J and Jês  predecessors. In the vector denotes the total  number of map slots in the MapReduce cluster  12   For each accepted job J  we maintain a sorted vector to record the  available time of the clusterês reduce  slots, after the scheduled execution of J and Jês  predecessors. In the vector, q denotes the total  number of reduce slots in the MapReduce cluster      21 For each accepted job J  we use a sorted vector to represent the   available time of the clusterês map slots after  considering the actual execution of J and Jês predecessors      21 For each accepted job J  we use a sorted vector to represent the   available time of the clusterês reduce slots after  considering the actual execution of J and Jês predecessors The threshold that we set for triggering the  feedback controller. That is, if the difference of a  jobês actual and estimated finish times is larger than  RTMR scheduler will invoke the feedback  controller to keep the admission controller up-to date the execution time of the i th map task of job J the execution time of the i th reduce task of job J RTMR scheduler uses historical job execution data to estimate some of the aforementioned parameters  max  and max After executing a job J, we could update ratio  through the following equation max  Similarly, we update the values of max and max as follows max 2 2 1 1 max max  max 2 2 1 1 max max  In a heterogeneous environment, worker nodes have different data retrieving and processing power. In order to avoid deadline miss, we follow the same mechanism as adopted by the Deadline Constraint schedu h ere the longest time of running a map/reduce task is used in the execution time estimation In this paper, we assume, for both Deadline Constraint and RTMR schedulers, that jobs are put in a priority queue following EDF \(earliest deadline first\r admission control mechanism is, however, applicable beyond EDF, in general, to any policy \(e.g., FIFO\at defines an order in which jobs should be given resources. When a new MapReduce job arrives, the admission controller determines if it is feasible to schedule the new job without compromising the guarantees for previously admitted jobs Algorithms I, II, and III show the pseudo code of the admission control. RTMR scheduler first checks if the new 
A Definitions estimated estimated actual actual B Admission Controller 
002 002 
 
002 002 002 002\002 005 005 
002 
002 002 003\003  002 005 002 005 002 005  002 005 002 005 002 005  
  
             
 
r r r i R i rr i m c m c r c 
m V 
1 1 max max 
r q rrr vvvV r V m i r i m c r c r m c r c m M m M m m m m m m c c r R r R r r r r r r c c 
m i 
mmmm l Tttt m T r T m l mmm vvvV 
J 
 
003\004 005\006 
002 003  For a MapReduce job, each  one of the R reduce tasks processes a unique part  
003 002   That is, the input data size 
    
1538 
1538 


003\004 005\006 003\004 005\006 
 max  max  1 2    6  max  max  1 2   
J J J J 
 
1 1  ma x  1 current Time 5 1  1  7:    sort items in 
 005 005  005 005 
 
  
12   1  
C Dispatcher 
job Jês deadline can be satisfied or not, i.e., to check if e A D, where e is the estimated finish time of the job Algorithm I lines 1-9\o estimate Jês finish time, we start with identifying Jês preceding job J p if J were inserted in the priority queue. If J were at the head of the queue is the job that has been started latest by the dispatcher. If J is the first job submitted to the cluster, it does not have a preceding job. Since and record the estimated available time of the clusterês map and reduce slots after the scheduled execution of and s predecessors, we can estimate job Jês finish time based on these vectors. If the new job Jês deadline can be satisfied, RTMR scheduler then checks whether accepting J will violate the deadline of any previously admitted job \(Algorithm I lines 10-21\ce only jobs that succeed job J in the priority queue will be delayed, RTMR scheduler re-estimates their finish times. If any of them will miss deadline as a result of Jês acceptance RTMR scheduler rejects job J. Finally, once the admission controller decides to accept job J, the priority queue and the and vectors of J and Jês su ccessors will be updated to reflect the change \(Algorithm I lines 22-23 ALGORITHM I. ADMISSION CONTROLLER As mentioned in Section II, a Hadoop cluster uses worker nodes to execute map and reduce tasks. Each worker node has a fixed number of map slots and reduce slots which limit the number of map tasks and reduce tasks that a worker node can execute simultaneously. Periodically, a worker node sends a heartbeat signal to the master node Upon receiving a heartbeat from a worker node with empty map/reduce slots, the master node invokes the scheduler to assign tasks. RTMR schedulerês dispatcher fulfills this role allocating tasks to execute on worker nodes. Algorithm IV shows the pseudo code of the dispatcher When jobs are inserted into the priority queue, their map stages can start and their map tasks are ready to run Therefore, it is straightforward to dispatch map tasks following the job order/priority. No modification is needed here and RTMR scheduler dispatches map tasks following the same approach as the default Hadoop system \(lines 4-5 
Identifying Jês p receding job J p if J were inserted in the queue 1:   J p getPredecessor\(J, Priority-Q 2 J p   0,0 i f  J p nil 3 J p   0,0 i f  J p nil invoke Algorithms II and III to do the calculation 4  Cal J   5  Cal J    6:    e = Cal J  e 7 e > A + D  8  9 10: J p J 11: J s getSuccessor\(J p Priority-Q 12 J s nil invoke Algorithms II and III to do the calculation 13 Cal J s J p    14 Cal J s J p  J p    15:          e s Cal J s J p  J p  e 16 e s J s A + J s D then 17 18  19:         J p J s  20:         J s getSuccessor\(J p Priority-Q 21 22: Proiority-Q.insert\(J 23: record     and computed above as the new  vectors for J and Jês successors 24  ALGORITHM II. CACULATION OF AND  This algorithm estimates job Jês map stage finish time and  the available time of map slots after the scheduled execution of J and Jês p redecessors 1  2 k =1 to M  3:     pick the smallest value in vector i.e 4  to keep a sorted vector 8  9    ALGORITHM III. CACULATION OF AND e This algorithm estimates e, job Jês finish time and the available time of reduce slots after the scheduled execution of J and Jês predecessors invoke Algorithm II to estimate Jês map stage finish time 1 Cal J   2  3 k = 1 to R  4:      pick the smallest value in vector i.e  6 7:      e to keep a sorted vector 9 10  e 
mmmm l Tttt m e m e m e mmm l Ttt m e m e m e 
p J m p T r p T p J p J m T r T m p T m T m p T r p T r T r p T m T m T m p T m T r T r T m p T r p T r T r T m p T r p T m T m T m T r T m T r T r T r T m T r T m T r T m T r T m T m T m T m m T m t m t m t m t m m t m T m T m T r T r T 
m s T r s T m s T r s T m e 
003\004 005\006 
m mi ciM r ri ciR r T r T r T 
1  1  5 1  ma x  1  1  1  8:      sort items in 
002 Priorit y Q 002  002  
006 
 
rrr q Ttt r T m T m T r r t r t r t r t r r t r T 
AC\(J = \(A, D, M, R if then return false end if while do  if return false end if end while return true Cal J = \(A, D, M, R    for do  end for return Cal J = \(A, D, M, R    for do    end for return  
002  002  
1539 
1539 


m T r T m c r c m T r T m V r V m V r V m V r V m U r U m V r V m U r U m T r T 
i  2:  r: available reduce slots on node i T T T i 
002 Priority-Q,i,Ra 
003 004 
J J J 
m p T 
 if then  if then  for do if then break for end if if then break for else if then end if end for end if 
1:  m: available map slots on node 3:  Ra: the number of available reduce slots in the cluster, which is counted upon calling this algorithm dispatch map tasks 4 m>0  5 follow the same approach as the default Hadoop system to dispatch map tasks dispatch reduce tasks 6 r > 0 7:      reservedSlot: the number of reduce slots reserved for high-priority jobs 8:      reservedSlot = 0 9 J from Priority-Q  10 reservedSlot > Ra  11  12  13 findAReadyReduceTask\(J 14  nil  15:             assign to node 16  17 J has not reached its reduce stage  18:             reservedSlot += J.R 19 20 21  
J J J J J J J J J 
 
However, since a jobês map stage finish time depends on not only the jobês map stage start time but also the number of map tasks the job has, when there are multiple jobs concurrently running in the cluster, which jobs can finish their map stages and start their reduce stages earlier is not determined by the job priority alone. Although jobs start their map stages following the job order/priority, it is highly likely that jobs will not finish their map stages in that order As a result, the reduce tasks of a lower-priority job could become ready earlier than those of a higher-priority job Thus, if ready reduce tasks are assigned to execute on worker nodes without any constraint, the proper execution of higher-priority jobs may be interfered by the execution of lower-priority jobs, leading to deadline violations. One simple method to avoid such interferences is to strictly enforce that jobs start their reduce stages following the job order. That is, a job cannot start the reduce stage until all preceding jobs have finished their map stages. However, this straightforward method puts a strong constraint on job parallelism and causes inefficient utilization of system resources. Therefore, we instead design a reservation-based dispatcher, which simply ensures that a lower-priority job does not occupy slots that belong to higher-priority jobs That is, the dispatcher reserves slots that are needed by higher-priority jobs to avoid potential interferences. Upon receiving a heartbeat from a worker node with empty reduce slots, the dispatcher assigns a reduce task to the worker node only if enough reduce slots have been left unused for higherpriority jobs \(lines 6-21 We have proved that all jobs accepted by the admission controller can be successfully dispatched and completed by their deadlines in normal scenarios when there is neither a node failure nor a task re-execution \(please refer to the Technical Report for the proof   ALGORITHM IV. DISPATCHER DP\(J=\(A, D, M, R A feedback controller is developed to keep the admission controller up-to-date.  As described in Section B, the admission controller makes decisions based on information maintained in job records, i.e  and  vectors These vectors record the estimated available time of the clusterês map and reduce slots after the scheduled execution of job J and its predecessors. However, these jobsê actual execution may be different from the estimate. For instance due to the pessimistic estimation where we use max and max as the estimated cost of retrieving and processing a unit of data in a map and a reduce task and as the estimated ratio between a jobês intermediate data size and input data size, it is highly likely that a job finishes earlier than that estimated by the admission controller. In addition node failures or speculative re-execution of slow tasks can result in a job finish time later than expected. To reduce false negatives \(i.e., rejecting jobs that can meet their deadlines\d deal with unexpected events \(such as node failures\feedback controller is invoked to update all waiting jobs and vectors if the difference between a jobês actual and estimated finish times is larger than a certain threshold The feedback controller is also triggered if a job misses its deadline due to unexpected events. As a result of the update, the admission controller makes decisions based on more accurate estimates. Algorithms V and VI show the pseudo code of the feedback controller To avoid high algorithm overhead, we do not keep track of  and  the actual available time of the clusterês map and reduce slots after considering the actual execution of job J and Jês predecessors. Tracking these vectors is not an easy task.  First, it requires identifying the correct execution slot and updating it after each taskês execution. Second, as mentioned in Section C, to well utilize system resources, we develop a reservation-based reduce task dispatcher, which allows out of order execution of jobs reduce stages and out of order completion of jobs. Thus, a job may finish its execution before some of its predecessors and after some of its successors. Due to these cases, simply taking snapshots of the cluster when a job Jês tasks finish will not give the correct  and  vectors. In addition, there is a more critical problem: due to out of order job completion, if some of Jês predecessors are still executing, the actual values of  and  are unknown when job J finishes and when the feedback controller is triggered. Thus, instead of tracking these vectors, we derive and vectors as updated estimates of  and  This estimation is carried out only when the feedback controller \(Algorithm V\okes the slot available time update \(Algorithm VI\rive and like deriving  and  we still assume all Jês predecessors finish and make the slots available at and Then the actual execution of job Jês map and reduce tasks are considered following a non-decreasing 
r p T 
D Feedback Controller 
1540 
1540 


r p T 
 Cal  Cal    sorted vector containing the actual finish time of job Jês map tasks 4  sorted vector containing the actual finish time of job Jês reduce tasks 5  is not empty  say it is   9  where  is not empty  say it is   14  where  and  are based on 
 getPredecessor\(J, Priority-Q 4  J 13  getSuccessor  getSuccessor 
F C\(J=\(A, D, M, R if then while do  end while else return end if SATU \(J=\(A, D, M, R     while do  end while  while do end while return 
e e e 
 the sorted vector containing the actual finish time of job Jês map tasks 9:     build  the sorted vector containing the actual finish time of job Jês reduce tasks invoke Algorithm VI to calculate the updated estimates 10      SATU\(J     
007 007 007 007 007 007 007 007 007 007 
    
 SATU\(J 
002 Priorit y Q 004 004 002  
1 threshold to trigger the update 2 J p   0,0 f J p nil 5 J p   0,0, É0 if  J p nil invoke Algorithm III to do the calculation 6:  e = Cal J  e 7 e or 8:     build    11    12 Priority-Q 14  nil invoke Algorithms II and III to do the calculation 15    16   17   18 Priority-Q 19 20  21 ALGORITHM VI. SLOT AVAILABLE TIME UPDATE 1 map slot available time in Jês predecessorês record 2 reduce slot available time in Jês predecessorês record 3   6   7  8:     remove the item currently located at the beginning of vector  10:   sort  items in to keep a sorted vector 11  12  13:    remove the item currently located at the beginning of vector  15:    sort  items in to keep a sorted vector 21 22   We have proved the correctness of the feedback controller by showing that 
m p T 
 
 job Jês actual finish time 3    A+D 
  1  1 is the first and smallest item in vector 1  1 is the first and smallest item in vector 
m U r U m V r V m UJ m V r UJ r V p J m p T m T m p T r p T r T r p T r T m p T r p T m E r E m TJ m p T r p T m E r E m U r TJ m p T r p T m E r E r U p J s J p J s J m s TJ m T s J m p TJ m T r s TJ r T s J m p TJ r p TJ r T p J s J s J p J m p T r p T m E r E m E r E m U m p T r U r p T m E m E m i e m u m i e m u m U m U m U r E r E r i e r u r i e r u r U r U r U m U r U m UJ m V r UJ r V m T r T m U r U m TJ m V r TJ r V m s TJ r s TJ m T r T m TJ m V r TJ r V s J m T s J m V s J r T s J r V s J 
J J J J J J J J 
007 
order of task finish time and it is assumed that the earlier an execution slot becomes available, i.e., the earlier an execution slot starts to run a task, the earlier it finishes the task execution \(Algorithm VI lines 7-21\. These assumptions may not hold in the actual execution and thus and are only updated estimates of  and  However, as long as  and  the feedback controller still works correctly and preserves RTMR schedulerês real-time property ALGORITHM V. FEEDBACK CONTROLLER  and  Therefore after updating job Jês vectors and with and in Algorithm V \(lines 10-11\e condition   and   i.e., the estimated slot available time is greater or equal to the actual available time\l holds for job J \(please refer to the Technical Report for the proof  i n ce t h e deriv a tio n of  and  see Algorithm V   and   also ensures that   and   for all succeeding jobs  V EVALUATION Our implementation of RTMR scheduler and Deadline Constraint schedu all bas ed on Hadoop 0.2 1 1  These two schedulers are implemented and compared experimentally in terms of real-time property and cluster utilization. To test the effects of feedback control, we run RTMR scheduler twice, with and without the feedback controller enabled. In addition since the cluster utilization is    1 Kc and Anyanw m pl e m e n t e d C o n s t r ai n t s c h e dul er in Hadoop 0.20.2. We instead choose Hadoop 0.21 because it is the closest version to 0.20.2 but with improved features necessary for small and medium size clusters. Since Hadoop 0.23/2.x is mainly designed for large clusters, it is not adopted for our experiments  
1541 
1541 


004 
JobQueueJobInProgressListener RTMRTaskScheduler TaskScheduler JobQueueJobInProgressListener JobQueueJobInProgressListener DCTaskScheduler TaskScheduler Loadgen 
Nodes Quantity Hardware and Hadoop Configuration Bin #Maps Jobs at Facebook Maps in Benchmark of jobs in Benchmark Bin #Maps Reduces Deadline second 
determined by not only the scheduling algorithm but also the workload volume, we run the default Hadoop FIFO scheduler, which accepts all jobs to execute in the cluster collecting its resultant cluster utilization to reflect the workload volume. If a real-time scheduler achieves a cluster utilization close to that achieved by the default Hadoop FIFO scheduler, we think that the resource cost of providing the real-time property is not high For the RTMR scheduler, the admission controller is implemented in the class which makes the admission control decision and maintains the MapReduce job queue. The dispatcher is in the class which extends from the class and is in charge of dispatching map and reduces tasks. The feedback controller is also in the class, where we set the threshold to be a typical map task execution time Similarly, Deadline Constraint schedulerês admission controller is in class and its dispatcher, called extends from the class A heterogeneous Hadoop cluster that contains one master node and 30 worker nodes is used as the testbed. The 30 worker nodes are configured as one rack and they are of two types. 20 of them are 2 dual-core CPU nodes and 10 of them are 2 single-core CPU nodes. Table I gives the detailed hardware information of the cluster. We make the number of map slots in a worker node equal to the number of CPU cores. Because each node has only one Ethernet card, we configure one reduce slot per worker node to avoid bandwidth competition between multiple reduce tasks on a single node a test example in Hadoop source code for evaluating Hadoop schedulers  is u s ed as the test application TABLE I. EXPERIMENTAL ENVIRONMENT 
Master node 1 2 single-core 2.2GHz Opteron248 CPUs, 8GB RAM, 1Gbps Ethernet Type I worker nodes 20 2 dual-core 2.2GHz Opteron275 CPUs, 4GB RAM, 1 Gbps Ethernet, 4 map and 1 reduce slots per node Type II worker nodes 10 2 single-core 2.2GHz Opteron64 CPUs, 4GB RAM, 1 Gbps Ethernet, 2 map and 1 reduce slots per node We first create a submission schedule \(workload I\at is similar to the one used by Zah a h a ria et al    e n e rat ed a s u b m i s s i on s c h e d u l e f o r 100 j obs b y  sampling job inter-arrival times and input sizes from the distribution seen at Facebook over a week in October 2009 By sampling job inter-arrival times at random from the Facebook trace, they found that the distribution of interarrival times was roughly exponential with a mean of 14 seconds. They also generated job input sizes based on the Facebook workload, by looking at the distribution of the number of map tasks per job at Facebook and creating datasets with the corresponding sizes \(i.e., each map task requires a 128 MB input block\o make it possible to compare jobs in the same bin within and across experiments job sizes were quantized into nine bins, listed in Table II  r w o rk load I h a s  s i m ilar j ob s i zes a n d j ob in terarrival times. In particular, our job size distribution follows the first six bins of the benchmark shown in Table II, which reflect about 89% of the jobs at the Facebook production cluster. Because our testbed is limited in size, we exclude those jobs with more than 300 map tasks. Like the schedule in e distribu tion of int erarriv al ti m es i s ex pon e n tial with a mean of 14 seconds, making our workload totally 21 minutes long The submission schedule used by Zaharia et al. [17  however, does not specify the number of reduce tasks and the deadline for a job. To generate workload I, we create two intervals in each job bin \(see Table II\e for reduce task number and one for deadline. Two random numbers from the two intervals are picked as the number of reduce tasks and the deadline for a job. Because the Deadline Constraint scheduler cannot accept a job with more reduce tasks than the clusterês total number of reduce slots, for workload I, we fix the maximum number of reduce tasks per job to be 30, the total number of reduce slots in the cluster TABLE II. DISTRIBUTION OF JOB SIZES \(in Terms of Number of Map Tasks\ at Facebook 1 1 39% 1 38 2 2 16% 2 16 3 3-20 14% 10 14 4 21-60 9 50 8 5 61-150 6 100 6 6 151-300 6 200 6 7 301-500 4 400 4 8 5011500 4% 800 4 9 1501 3 4800 4 TABLE III. WORKLOAD IêS CONFIGURATION\(in Terms of Number of Map, Reduce Tasks and Deadline 1 1 1 200,3 2 2 1  200 3 00 3 10 5 300,4 4 50 10 500,8 5 100 20 1000,150 6 200 30 [2000,250 Since most jobs in the Facebook workload are small, in particular, some of them having only 1 map task, we create workload II to include more jobs with higher parallelism That is, in workload II, we let the number of map tasks per job follow normal distribution with an average of 100 Again, because of the moderate size of our cluster, we do not include the three jobs that have more than 300 map tasks Table IV shows the detailed information of workload II. To test how RTMR scheduler works with large jobs, we also create some jobs with more reduce tasks than the clusterês total number of reduce slots in workload II. However, since we already know that Deadline Constraint scheduler cannot accept such jobs, they are not included in workload II when Deadline Constraint scheduler is tested 
1542 
1542 


 
_ ____ _ ____ 
jobs accepted jobs successful SuccessR successful_jobs slot_time_used_by_successful_jobs slot_time_used_by_all_jobs available_slot_time_during_workload_exe job accept ratio cluster utilization 
 
exe workload during timeslot available jobs successful byusedtimeslot Util 
workload ainjobs jobs accepted AcceptR 
job accept ratio, job success ratio cluster utilization 
exe workload during timeslot available jobsallbyusedtimeslot Util 
 
 
For performance evaluation of the real-time schedulers the following three metrics, i.e and are used  
1 9 1  1 5  200 3 00 2 24 10 5  300 5 00 3 25 [50,10  15  30  100 0 150 0 4 18 [100,2  25  50  150 0 250 0 5 13 [200,3  35  70  250 0 350 0 Accept Ratio 71.6% 56.8% 46.6 n/a Success Ratio 85.7% 100 100 n/a Cluster Utilizatio n 5.7% 15.5% 11.6 21.3 TABLE VI. SCHEDULER PERFORMANCE WITH WORKLOAD II Accept Ratio 49.4% 24.7% 15.7 n/a Success Ratio 22.5% 100% 100 n/a Cluster Utilization 0.7% 64.6% 49.8% 69.7 VI Dean, J. and Ghemawat, S. 2008. çMapReduce: Simplified Data  Processing on Large Clustersé. Commun. ACM, 51\(1\:107Ö113 2 Apache Hadoop http://hadoop.apache.org  3 M. Zaharia, D. Borthakur, J. S. Sarma, K. Elmeleegy, S. Shenker, and  I. Stoica, çJob scheduling for multi-user mapreduce clusters,é EECS  Department, University of California, Berkeley, Tech. Rep., Apr 2009 4 American Express https://www.americanexpress.com  5 The Compact Muon Solenoid Experiment. Available  http://cms.web.cern.ch/cms/index.html  6 The Large Hadron Collider. Available http://lhc.web.cern.ch/lhc  7 Attebury, G.;    Baranovski, A.;    Bloom, K.;    Bockelman, B  Kcira, D.;    Letts, J.;    Levshina, T.;    Lundestedt, C.;    Martin, T  Maier, W.;    Haifeng Pi;    Rana, A.;    Sfiligoi, I.;    Sim, A  Thomas, M.;    Wuerthwein, F.;  çHadoop distributed file system for  the Gridé. Nuclear Science Symposium Conference Record  NSS/MIC\, 2009 IEEE. pp. 1056 Ö 1061 8 Open Science Grid. Available http://www.opensciencegrid.org  9 Hadoop Users http://wiki.apache.org/hadoop/PoweredBy#F  10 Capacity Scheduler http://hadoop.apache.org/common/docs/r0.19.2/capacity_scheduler.html 
___ _  
  
_  _     TABLE IV. WORKLOAD IIêS CONFIGURATION \(in Terms of Number of Map, Reduce Tasks and Deadline The following equation is used to calculate the cluster utilization achieved by default Hadoop FIFO scheduler  Here denotes those jobs that finish before their deadlines and refers to the total map and reduce slot time used to execute them. Since Hadoop FIFO scheduler does not consider job deadlines and provides no real-time guarantees, it accepts all jobs and its cluster utilization is calculated using instead refers to the total usable time of cluster map and reduce slots during the execution of a workload, i.e., the product of the number of slots and the turnaround execution time of all accepted jobs in a workload Tables V and VI show how schedulers perform with workload I and II respectively.  As we can see, although compared to RTMR scheduler Deadline Constraint scheduler accepts more jobs, it fails to provide deadline guarantees to all accepted jobs, with job success ratio of 85.7% and 22.5% respectively. Since not all accepted jobs are successful while more jobs are accepted, which prolong the workloadês execution in the cluster, Deadline Constraint scheduler leads to much lower cluster utilizations of only 5.7% and 0.7% respectively. In contrast, RTMR scheduler maintains good cluster utilization of 15.5% and 64.6%, in comparison to 21.3% and 69.7% achieved by default Hadoop FIFO scheduler. Deadline Constraint schedulerês very poor performance with workload II experimentally demonstrates its deficiencies in handling real-time MapReduce jobs with high parallelism. From the data, we can also conclude that RTMR scheduler performs better when we enable the feedback controller to keep the admission controller up-to-date, which results in better and  TABLE V. SCHEDULER PERFORMANCE WITH WORKLOAD I CONCLUSION AND FUTURE WORK This paper develops, implements, and experimentally evaluates a novel Real-Time MapReduce \(RTMR\ scheduler for cluster-based scheduling of real-time MapReduce applications. RTMR scheduler overcomes the deficiencies of an existing algorithm and achieves good cluster utilization and 100% job success ratio, ensuring the realtime property for all admitted MapReduce jobs In the future, we will investigate real-time scheduling in MapReduce Online clusters h ich  s u pport pipelin i n g to allow reducers to begin processing data as soon as it is produced by mappers VII ACKNOWLEDGEMENTS The authors acknowledge support from NSF award 1018467. This work was completed utilizing the Holland Computing Center of the University of Nebraska REFERENCES 1 
 
_ ____ _____ 
          
Bin No Job Maps #Reduces Deadline second Metrics Deadline Constraint RTMR RTM R w/o Feedback Hadoop FIFO Metrics Deadline Constraint RTMR RTMR w/o Feedback Hadoop FIFO 
1543 
1543 


Jorda Polo, David Carrera, Yolanda Becerra, Malgorzata Steinder  and Ian Whalley. Performance-driven task co-scheduling for  mapreduce environments. In Network Operations and Management  Symposium \(NOMS\2010 IEEE, pages 373 Ö380, 19-23 2010 12 K. Kc and K. Anyanwu, çScheduling hadoop jobs to meet deadlines  in 2nd IEEE International Conference on Cloud Computing  Technology and Science \(CloudCom\, 2010, pp. 388 Ö392 13 Xicheng Dong, Ying Wang, Huaming Liao çScheduling Mixed Real time and Non-real-time Applications in MapReduce Environment  In the proceeding of 17th International Conference on Parallel and  Distributed Systems. 2011, pp. 9 Ö 16 14 Xuan Lin, Ying Lu, J. Deogun, and S. Goddard. Real-time divisible  load scheduling for cluster computing. In Real Time and Embedded  Technology and Applications Symposium, 2007. RTAS ê07. 13th  IEEE pages 303 Ö314, 3-6 2007 15 HDFS  http://hadoop.apache.org/common/docs/current/hdfsdesign.html  16 Chen He, Ying Lu, David Swanson. çMatchmaking : A New  MapReduce Scheduling Techniqueé. In the proceeding of 2011  CloudCom, Athens, Greece, 2011, pp. 40 Ö 47 17 Matei Zaharia, Dhruba Borthakur, Joydeep Sen Sarma and Khaled  Elmeleegy, Scott Shenker, and Ion Stoica, çDelay scheduling: a  simple technique for achieving locality and fairness in cluster  schedulingé. In the proceedings of the 5th European conference on  Computer systems, 2010.  pp 265-278 18 Zhuo Tang, Junqing Zhou, Kenli Li, and Ruixuan Li "A MapReduce  task scheduling algorithm for deadline constraints.", Cluster  Computing, Vol. 15,  2012 19 Eunji Hwang, and Kyong Hoon Kim. "Minimizing Cost of Virtual  Machines for Deadline-Constrained MapReduce Applications in the  Cloud." Grid Computing \(GRID\, 2012 ACM/IEEE 13th  International Conference on. IEEE, 2012 20 Micheal Mattess, Rodrigo N. Calheiros, and Rajkumar Buyya  Scaling MapReduce Applications across Hybrid Clouds to Meet Soft  Deadlines." Technical Report CLOUDS-TR-2012-5, Cloud  Computing and Distributed Systems Laboratory, the University of  Melbourne, August 15, 2012 21 
 
11 
                
Chen He, Ying Lu, David Swanson. çReal-Time Application Scheduling in Heterogeneous MapReduce Environments Technical Report TR-UNL-CSE2012-0004, University  of Nebraska-Lincoln, 2012 Available: http://cse apps.unl.edu/facdb/publications/TR-UNL-CSE20120004.pdf 22 T. Condie, N. Conway, P. Alvaro, J. M. Hellerstein, K  Elmleegy, and R. Sears. çMapreduce Onlineé. In NSDI 2010 23 A. D. Ferguson, P. BodÌk, S. Kandula, E. Boutin, and R  Fonseca. çJockey: Guaranteed Job Latency in Data Parallel Clusters. In EuroSys, 2012 24 G. Wang, A. R. Butt, P. Pandey, and K. Gupta. çA Simulation Approach to Evaluating Design Decisions in MapReduce Setupsé. In MASCOTS 2009 25 H. Herodotou and S. Babu. Profiling, çWhat-if Analysis and Cost-based Optimization of MapReduce Programs In VLDB 2011 26 H. Herodotou, F. Dong, and S. Babu. çNo One \(Cluster Size Fits All: Automatic Cluster Sizing for Dataintensive Analyticsé. In SoCC 2011  
1544 
1544 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



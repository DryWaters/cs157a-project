CrowdPlanner A Crowd-Based Route Recommendation System Han Su 1  Kai Zheng 2  Jiamin Huang 003 1  Hoyoung Jeung y 1  Lei Chen z 1  Xiaofang Zhou 3  The University of Queensland Australia 003 Nanjing University China y SAP Australia z HKUST Hong Kong 1  2  3 f 
h.su1,uqkzheng,uqxzhou g uq.edu.au 003 1 hjm10@software.nju.edu.cn y 1 hoyoung.jeung@sap.com z 1 leichen@cse.ust.hk Abstract 227 As travel is taking more signi\002cant part in our life route recommendation service becomes a big business and attracts many major players in IT industry Given a pair of userspeci\002ed origin and destination a route recommendation service aims to provide users with the routes of best travelling experience according to criteria such as travelling distance travelling time traf\002c condition etc However previous research shows that even the routes recommended by the big-thumb service 
providers can deviate signi\002cantly from the routes travelled by experienced drivers It means travellers preferences on route selection are in\003uenced by many latent and dynamic factors that are hard to model exactly with pre-de\002ned formulas In this work we approach this challenging problem with a very different perspective\226 leveraging crowds knowledge to improve the recommendation quality In this light CrowdPlanner 226 a novel crowd-based route recommendation system has been developed which requests human workers to evaluate candidate routes recommended by different sources and methods and determine the best route based on their feedbacks In this paper we particularly focus on two important issues that affect system performance signi\002cantly 1 how to ef\002ciently generate tasks 
which are simple to answer but possess suf\002cient information to derive user-preferred routes and 2 how to quickly identify a set of appropriate domain experts to answer the questions timely and accurately.Speci\002cally the task generation component in our system generates a series of informative and concise questions with optimized ordering for a given candidate route set so that workers feel comfortable and easy to answer In addition the worker selection component utilizes a set of selection criteria and an ef\002cient algorithm to 002nd the most eligible workers to answer the questions with high accuracy A prototype system has been deployed to many voluntary mobile clients and extensive tests on real-scenario queries have shown the superiority of CrowdPlanner in comparison with the results given by map 
services and popular route mining algorithms I I NTRODUCTION Travelling plays a vital role in our daily life Thanks to the rapid development of GPS technologies and a number of navigation service providers e.g Google Map Bing Map TomTom we can now travel to unfamiliar places with much less effort by simply following the recommended routes While the detailed mechanisms that are adopted to recommend routes are different travelling distance and time are the most important criteria and factors in those recommendation algorithms which result in the shortest route and/or fastest route With increasing numbers of users who rely on these map services to travel a natural question arises are these routes always good enough to be the best choice when people 
travel Ceikute et al are the 002rst to assess the routing service quality by comparing the popular routes the ones most drivers prefer and the ones recommended by a big thumb map service provider The study concludes that there are substantial differences between popular routes and recommended routes in which experienced/frequent drivers preferences do not always correspond to the routes recommended by the navigation service The primary reason for the route differences is that drivers preferences are in\003uenced by lots of factors in addition to distance and time such as the number of traf\002c lights speed limitation road condition weather amongst many others a Similarity between routes obtained from web services and popular route mining algo 
rithms b Recommended routes from different sources Fig 1 Ef\002ciency of landmark selection algorithms In order to take into account the diversity of the preference factors simultaneously some previous studies propose to use popular routes mined from historical trajectories as recommended routes This approach however has signi\002cant drawbacks First it is not always possible to have a suf\002cient amount of historical trajectories to derive reliable route recommendation Second there exists a number of popular route mining algorithms The de\002nitions of popularity in those algorithms slightly differ from each other which can suggest different routes for users As a result it is still dif\002cult for users to select one particular route as a best choice For 
example Fig 1\(a shows different popular routes mined using different algorithms In this experiment we 002rst randomly select 5000 source-destination pairs as the testing queries For each of them we test the similarity between the route recommended by a big thumb Web map service WS and the route obtained from three popular route mining algorithms namely Most Popular Route MPR Local Dri v er Route LDR and Most Frequent P ath MFP 14 all of which perform reasonably well according to their reported results The results of average similarity are shown in Fig 1\(a One 978-1-4799-2555-1/14/$31.00 002 2014 IEEE ICDE Conference 2014 1144 


can see that the similarities are at best around 60 which means that different sources recommend quite different routes Fig 1\(b demonstrates the recommended routes from different sources on map where two routes recommended by WS are different from those by MPR and MFP respectively Going beyond the limitation of the route recommendation based on popular routes we take the emerging concept of crowd sourcing that explicitly leverages human knowledge to resolve complex problems Speci\002cally we propose a novel crowd-based route recommendation system CrowdPlanner which can effectively blend domain-expert knowledge for route recommendation Instead of proposing new or optimizing existing routing algorithms our work takes an entirely different approach by consolidating candidate routes from different sources e.g map service providers popular routes and requesting experienced drivers to select amongst them Our system returns the most promising one according to the selection of drivers Taking domain-expert's knowledge to evaluate the route quality is a very challenging task The 002rst yard stone to be placed is how to automatically generate a user-friendly task so that domain experts can do the job more comfortably and accurately As the performance of system largely relies on the quality of an answer given by each worker how to choose a set of suitable worker for a given task is another problem we need to solve CrowdPlanner tackles the above challenges by two carefully designed core components More speci\002cally task generation component utilizes a set of signi\002cant and discriminative landmarks to generate a binary question set by analysing the given candidate route set Then those questions are presented to the workers with optimized orders based on the informativeness of each question whether it is more likely to lead to the 002nal answer and the response of the worker In worker selection component we identify a few key attributes of workers that mostly affect their performance on a given task and propose an ef\002cient search algorithm to 002nd the most eligible workers Our key contributions in this work can be summarized as follows 017 We identify the intrinsic dif\002culties in the route recommendation task by solely relying on computational methodologies and propose an entirely new approach that actively involves human to improve the recommendation quality 017 We design and develop a novel crowd-based route recommendation system CrowdPlanner which is able to generate concise yet informative task intelligently and assign it to the selected worker who can accomplish the task with high accuracy and low latency 017 We deploy the system and conduct extensive experiments with a large number of workers users and queries in real scenarios The results demonstrate that CrowdPlanner can recommend the most satisfactory routes ef\002ciently in most cases The rest of this paper is organized as follows Section II introduces the preliminary concepts and overviews the CrowdPlanner system The two core components task generation and worker selection are discussed in Section III and Section IV respectively The experimental observations are presented in Section V followed by a brief review of related work in Section VI Section VII concludes the paper and outlines some future work II P ROBLEM S TATEMENT In this section we present some preliminary concepts and give an overview of the CrowdPlanner system Table I summarized the major notations used in the rest of the paper TABLE I S UMMARIZE OF NOTATIONS   Notation  De\002nition    R  a recommended route    R  candidate set of recommended routes    p  a place in the space    l  a landmark in the space    l:s  signi\002cance of landmark l    L  a landmark set    L R  the questioned landmark set of route set R    d  l i  l j   Euclidean distance between landmarks l i and l j    w  a worker of the system    W  a worker set    W R  the selected workers of routes set R   A Preliminary Concepts De\002nition 1 Route A route R is a continuous travelling path We use a sequence  p 1  p 2  001 001 001  p n   which consists of a source a destination and a sequence of consecutive road intersections in-between to represent a route De\002nition 2 Landmark A landmark is a geographical object in the space which is stable and independent of the recommended routes A landmark can be either a point i.e Point Of Interest a line i.e street and high way or a region i.e block and suburb in the space De\002nition 3 Landmark-based Route A landmark-based route 026 R is a route represented as a 002nite sequence of landmarks i.e 026 R   l 1  l 2   l n   In this paper we will also use 026 R as the set f l 1  l 2  001 001 001  l n g without ambiguity In order to obtain the landmark-based route from a raw route we employ our previous research results on anchorbased trajectory calibration to re write the continuous recommend routes into landmark-based routes by treating landmarks as anchor points De\002nition 4 Discriminative landmarks A landmark set L is called discriminative to a set of landmark-based routes 026 R if for any two routes 026 R 1 and 026 R 2 of 026 R  the joint sets 026 R 1  L and 026 R 2  L are different For example L 1  f l 3  l 4 g is discriminative to R 1  f l 1  l 2  l 3 g and R 2  f l 1  l 2  l 4 g  since the joint sets R 1  L 1  f l 3 g and R 2  L 1  f l 4 g are different but L 2  f l 1  l 2 g is not discriminative to R 1 and R 2  1145 


Fig 2 System Overview B Overview of CrowdPlanner CrowdPlanner is a two-layer system mobile client layer and server layer which receives user's request from mobile client specifying the source and destination processes the request on the server and 002nally returns the veri\002ed best routes to the user Fig 2 shows the overview of the proposed CrowdPlanner system which comprises two modules traditional route recommendation TR and crowd-based route recommendation CR The work\003ow of CrowdPlanner is as follows the TR module 002rstly processes user's request by trying to evaluating the quality of candidate routes obtained from external sources such as map services and historical trajectory mining the CR module will generate a crowdsourcing task when the TR module can not judge the quality of candidate routes and return the best route based on the feedbacks of human workers of the system 1 Traditional Route Recommendation Module This module processes the user's request by generating a set of candidate routes from external sources route generation component and evaluating the quality of those routes automatically without involving human effort route evaluation component Control logic component This component receives the user's request and controls the work\003ow of the entire system It also coordinates the interactions between the TR module and CR module Once a user's request is received by the control logic component it will invoke reuse truth component to match the request to the veri\002ed routes truth between two places at his departure time If the new coming request is a hit of the truth the system will return result immediately Otherwise the component will invoke the route evaluation component to automatically generate some candidate routes and evaluate the qualities of these candidate routes using the veri\002ed truth Route evaluation component This component evaluates the routes using computer power and it provides an ef\002cient way to reduce the cost of CrowdPlanner since it can largely reduce the amount of tasks generated The component will 002rstly build up a candidate route set by invoking route generation component  If some of these routes agree with each other to a high degree one of them will be selected as the best recommended route and added into a truth database with the corresponding time tag If a best recommended route can not be determined the system will assign each candidate route a con\002dence score which is generated by the veri\002ed truths and illustrates the possibility of the route to be the best recommended route A route with the highest con\002dence score that is greater than a threshold 021 will be regarded to be the best recommended and returned to the user otherwise the logic control will hand over the request to the CR module Route generation component This component generates two types of candidate routes the one provide by web services such as Google Map and the one generated from historical trajectories by using popular route mining algorithms i.e MPR LDR and MFP 2 Crowd Route Recommendation Module Crowd route recommendation module will take over the route recommendation request when the traditional route recommendation module cannot provide the best route with con\002dence high enough The module will generate a Crowdsourcing task consisting of a series simple but informative binary questions task generation component and assign the task to a set of selected worker who are most suitable to answer these questions worker selection component Task generation component As the core of CrowdPlanner this component generates a task by proposing a series of questions for workers to answer It is bene\002cial to have these questions as simple and compact as possible since both the accuracy and economic effectiveness of the system can be improved The design of this component will address two important issues what to ask in questions and how to ask the questions  We will discuss the detailed mechanism of this part in Section III Worker selection component This is another core component of CrowdPlanner In order to maximize the effectiveness of the system we need to select a set of eligible workers who are most suitable to answer the questions in a given task by estimating the worker's familiarity with the area of request Technical details of this component will be presented in Section IV Early stop component In most cases we do not to need to wait for all the answers of the assigned workers When partial feedbacks have been collected this component will evaluate the con\002dence of the answer and return the result to the user as early as possible when the con\002dence is high enough Rewarding component This component rewards the workers according to their workload and the quality of their answers The reward points can be used later when they request a route recommendation in CrowdPlanner In the following two sections we will present the design and technical details of the two core components of CrowdPlanner task generation and worker selection III T ASK G ENERATION Almost everyone has the experience of being unable to explicitly describe a route even you know the directions clearly which implies that this kind of job is hard for humans in its nature Therefore we cannot simply publish a task to workers and expect them to describe the best route in a 1146 


turn-by-turn manner In an alternative and more friendly way we may provide several pictures which demonstrate several candidate routes on a map as a multiple-choice question for workers to choose Take the route recommendation request in Fig 3 as an example we publish a multiple-choice question to workers by showing four routes on a map and asking them to pick the route they most prefer Even when all the routes have been visualized on a map it is still effort-demanding to tell the subtle differences between candidate routes and especially so if doing it on a small-screen device say a smartphone To make the question easier to answer we take into consideration that it is human nature to utilize signi\002cant locations i.e landmarks to help describe a route in high-level whereas a computer sees a route as a sequence of continuous roads indifferently Thus we choose to proactively present the differences in candidate routes to the workers using landmarks  instead of waiting for them to 002nd out Besides how the questions are presented can also affect the complexity of a task For example a multiplechoice question with all candidate routes presented at the same time would be more dif\002cult to answer than an equivalent combination of binary questions such as 223do you prefer the route passing landmark A at 2:00pm?\224 Actually has pointed out that several binary choice questions are easier and more accurate than a multiple-choice question Based on the above analysis we will generate a task as a sequence of binary questions each relating to a landmark that can discriminate some of the candidate routes from the others Fig 3 An example of landmark-based recommended routes between l 1 and l 10 Next we will present in detail our task generation process which can be divided into three phases inferring landmark signi\002cance landmark selection and question ordering In speci\002c the 002rst phase infers the signi\002cance of each landmark which indicates people's familiarity The second phase tries to use a set of most signi\002cant landmarks to summarize the difference among the candidate routes The third phase generates the 002nal task by ordering the questions in a smart way so that the expected number of issued questions is as small as possible A Inferring Landmark Signi\002cance It is common sense that landmarks have different signi\002cances For instance the White House is world famous but Pennsylvania Ave where the White House is located is only known by locals of Washington DC People tend to be more familiar with the landmarks that are frequently referred to by different sources e.g public praise news bus stop yellow pages In this work we utilize the online check-in records from a popular location-based social network LBSN and trajectories of cars in the target city to infer the signi\002cance of landmarks for these two datasets are large enough to cover most areas of a city By regarding the travellers as authorities landmarks as hubs and check-ins/visits as hyperlinks we can leverage a HITS-like algorithm such as to infer the signi\002cance of a landmark Readers who are interested in the technical details can refer to B Landmark Selection Although any landmark can be used to generate a question not all of them are suitable for the purpose of generating easy questions for a certain candidate route set 026 R notably throughout this section we use the landmark-based routes 026 R  which is generated by rewriting all the routes in R as described in Section II First the selected landmark set L should be discriminative to the candidate routes 026 R  which ensures that the difference between any two routes can be presented Second the landmarks of L should have high signi\002cance so that more people can answer the question accurately Third in order to reduce the work load of workers the selected landmark set L should be as small as possible Therefore the problem of landmark selection is to 002nd a small set of highly signi\002cant landmarks which are discriminative to all the candidate routes It can be formally represented as an optimization problem as below Given n landmark-based candidate routes 026 R  and the signi\002cance of each landmark Select a landmark set L with the size of k  d log 2  n  e 024 k 024 n  which is discriminative to 026 R  Maximize j L j 000 1 001 P l 2 L l:s Here the target function aims to maximize the total significance of selected landmarks  P l 2 L l:s  normalized by the size of L  j L j  It is a non-trivial task to trade-off between maximizing accumulate signi\002cance of the selected landmark set L and minimizing the size of L  while guarantees the restriction that L must be discriminative to 026 R  A straightforward method is to enumerate all combinations of the landmarks from 026 R  and 002nd a discriminative landmark set with the maximized target value However the time cost of this algorithm grows exponentially with the size of landmark set making this method impractical To speed up this process we propose a greedy algorithm called GreedySelect The main idea is to enumerate all the possible landmark combinations in a smart order so that it enables pruning early in the enumeration process Let S denote the current testing landmark set and L best denote the best landmark set which is discriminative and has the highest target value The landmark selection process can be divided into three steps Preparation step During preparation we 002lter out some non-bene\002cial landmarks i.e the ones which cannot discriminate any routes of 026 R  A straightforward way is to 002lter out all landmarks which are shared by all the candidate routes and those which do not appear on any candidate route Thus the bene\002cial landmarks set of 026 R can be generated as following L  S 026 R 2 026 R 026 R 000 T 026 R 2 026 R 026 R  We sort L in descending order of their signi\002cances in order to enable our pruning technique later 1147 


We still use L to refer to the sorted bene\002cial landmarks Expansion step This step generates the test landmark set S  We recursively generate and test the test landmark set S as shown in Algorithm 1 The test step will be explained below In each recursion step for each discriminative S we 002nd all the landmarks not in S  pick non-added biggest landmark of them and add the landmark to S  For example as shown in Fig 6\(a the algorithm starts by adding l 2 to S  Since S  f l 2 g is not discriminative the S will be expanded by adding l 8 to S which is shown in Fig 6\(b so as adding l 7 to S  f l 2  l 8 g  shown in Fig 6\(c Once S is discriminative we stop adding landmark to it no longer visit supersets of S  and roll back to upper layer recursion E.g in Fig 6\(c S  f l 2  l 8  l 7 g will not be expanded and the system will roll back l 7 and expand S  f l 2  l 8 g with l 6  Due to the same S may be generated in different order to eliminate duplication we only consider those landmarks with a lower signi\002cance than any element in S  The process stops when all the possible combinations have been visited Test step Each time a new S is generated we conduct a test to see whether S is discriminative If S is not discriminative return false Otherwise we use GetM axSet  S  to get maximum superset of S  i.e the set which contains all the points in S  and maximizes the target function We compare the superset got with the current best set L best  If the target value of the superset is bigger than that of L best  then the superset is current best landmark combination and we assign the superset to L best  Note that since the landmarks in L are sorted the time complexity of GetM axSet  S  is O  k   where k is no larger than n the number of candidate routes  Algorithm 1 Expand and Test  1 if j S j  n then  2 stop or S  landmark with the next biggest signi\002cance  3 else  4 SetOf S  all the landmarks has a lower sini\002cance than any landmark of S  5 Sort SetOf S in descending order of the signi\002cances of landmarks 6 for each l 2 SetOf S do  7 isDiscriminative  test S  f l g  8 if isDiscriminative is false then  9 expand S  f l g      However the above process can be very time consuming when the sizes of L and n are large since there will be a large amount of landmark sets to be tested In order to improve the ef\002ciency we need to 002lter out more non-bene\002cial landmarks in the preparation step test less landmark combinations in test step and generate less landmark combination in expansion step Next we will present the optimizations for each step 1 Optimization at preparation step Each landmark l of L can divide the routes set R into two parts the set of routes that pass l  and the set of routes that dose not The divided two parts are de\002ned as the discriminative information of l  For instance the discriminative information of all the landmarks of Fig 3 are shown in Fig 4 We can see that l 2 has the same discriminative information of l 3  so as l 8 and l 9  For each discriminative combination S containing l 3  there must exist an discriminative combination  S 000 f l 3 g   f l 2 g according to the following theorem Fig 4 Discriminative information of landmarks Theorem 1 Given two landmarks l i and l j sharing the same discriminative information and a landmark combination S  the two combinations S  f l i g and S  f l j g are either both discriminative or both non-discriminative to 026 R  Proof Consider any two routes 026 R  026 R 0 from 026 R  If S is discriminative to 026 R and 026 R 0  i.e 026 R  S 6  026 R 0  S  clearly 026 R   S  f l i g  6  026 R 0   S  f l i g   so as S  f l j g  that is S  f l i g  S  f l j g  is discriminative to 026 R  026 R 0  Otherwise 026 R  S  026 R 0  S  There are two cases 1 Both l i and l j are discriminative to 026 R and 026 R 0  W.l.o.g assume l i  l j 2 026 R but l i  l j  2 026 R 0  Then l i 2 026 R   S  f l i g  but l i  2 026 R 0   S  f l i g   so as l j  Thus S  f l i g and S  f l j g are discriminative to 026 R and 026 R 0  2 Both l i and l j are not discriminative to 026 R and 026 R 0  W.l.o.g assume l i  l j 2 026 R 026 R 0  Then 026 R   S  f l i g    026 R  S   f l i g   026 R 0  S   f l i g  026 R 0   S  f l i g   so as l j  Thus S  f l i g and S  f l j g are not discriminative to 026 R and 026 R 0  According to Theorem 1 and since the target value of  S 000 f l 3 g   f l 2 g is no less than S  all the combinations containing l 3 can be pruned So for landmarks which share the same discriminative information we keep the landmark with the highest signi\002cance and drop others Thus we drop l 3 and l 9  while keep l 2 and l 8  2 Optimization at expansion step In each recursion step within the expansion step given the current selected landmark set S  there are a set of routes N D  S  where for any 026 R 2 N D  S   there exists some other route 026 R 0 2 N D  S   such that S is non-discriminative to 026 R and 026 R 0  i.e 026 R  S  026 R 0  S  We call N D  S  the non-discriminative route set of S  Depending on N D  S   there are two special set of landmarks in the set of landmarks to explore  SetOfS in Algorithm 1 contributive set and con\003ict set  A contributive set is the set of landmarks where each landmark can discriminate some pair of routes in N D  S   A con\003ict set is the set of landmarks where adding any of the landmarks to S will form a superset of some discriminative set that has already been pruned 1148 


Next we will introduce how to generate the contributive set of S  For each non-discriminative set S  N D  S  is not empty A landmark l is a contributive landmark for S if there exists two routes 026 R i and 026 R j from N D  S  such that l is only on one route of 026 R i and 026 R j  So the contributive set L contri can be generate by the following equation L contri   026 R i  026 R j 2 N D  S   026 R i  S  026 R j  S  026 R i 000 026 R j    026 R j 000 026 R i  As the discriminative landmarks of two routes are 002xed we can pre-compute all the discriminative landmarks between any two routes in 026 R  Fig 5 demonstrates the discriminative landmarks of routes in Fig 3 Fig 5 Discriminative landmarks of any two routes A landmark l is an element of the con\003ict set L conf lict of a non-discriminative set S if and only if S  f l g is a superset of an discriminative set already being pruned In other words a landmark l is an element of L conf lict of S if there exists a pruned discriminative set S 0 satisfying l 2 S 0 000 S  j S 0 000 S j  1  Therefore during processing we keep track of all the pruned discriminative sets in S record  The L conf lict of S can be generated as follows L conf lict   S 0 2 S record f l j l 2 S 0 000 S  j S 0 000 S j  1 g However the above equation needs to compare with all the pruned discriminative sets which is costly when there are a large amount of pruned discriminative sets To speed up the con\003ict set generating we build inverted index for each landmark to indicate which pruned discriminative sets contain it 3 Optimization at test step Our optimization for the test step comes from this important observation Observation 1 For any set S and S 0  where S 032 S 0  if 8 l i 2 S l j 2 S 0 000 S  l i s  l j s  then the target value of GetM axSet  S 0  is always smaller than the target value of GetM axSet  S   Based on this observation during testing we eagerly retrieve the maximum super of the current S  If the maximum target value is less than the target value of the current L best  then we stop expanding S  as all the following added landmark will have a lower signi\002cance than the elements in S  and following Observation 1 the following expansion cannot generate a better landmark set than the current L best  For example in Fig 6\(d the target value of current L best equals to 0  8 which is given by S  f l 2  l 8  l 7 g  Since the possible maximum target values given by landmark sets containing f l 2  l 6 g and f l 2  l 4 g are 0.725 given by f l 2  l 6  l 8  l 7 g  and 0.65 given by f l 2  l 4  l 8  l 7 g  respectively then the landmark sets containing f l 2  l 6 g or f l 2  l 4 g will be not be expanded so as the landmark sets containing f l 6 g  f l 5 g or f l 4 g in Fig 6\(e a GreedySelect starts b Adding l 8 to S c Adding l 7 to S and Pruning supersets of S d Use upper bound to prune landmark combinations e Use upper bound to prune landmark combinations Fig 6 ILS algorithm C Question Ordering In the previous step we select questions landmarks which can be regarded as the question library  However presenting those question to workers with random order is unwise because of the following two reasons 1 it is not necessary to ask all the questions in most cases For example in Fig 3 if a worker indicates that she prefers the routes passing l 2 from l 1 to l 10  we do not need to ask whether he recommend to pass l 8 since all the routes passing l 2 do not pass l 8  2 each time we ask a question we would like to obtain the most informative feedback which is more likely to identify the 002nal answer This implies that 1 the next question to be asked depends on the result of the previous question so the question order is a tree-like structure 2 the informativeness of a question landmark l is proportional to people's familiarity of the landmark the signi\002cance of the landmark and how many routes the landmark can prune the information gain if we ask the question In order to arrange the questions into a tree-like structure we 002rst give the formula to calculate the strength of a question Here we use 026 R l   000 k 1 l   000 k 2 001\001\001 l   000 k i to denote the subset of 026 R in which each route satis\002es the answers of questions l k 1  l k 2 001 001 001  l k i and the l  k i denotes that the answer of k i is yes and l 000 k i denotes that the answer of k i is no Thus the informativeness IS  l k i  of question l k i is de\002ned as following IS  l k i   l k i s  H  026 R k i 000 1  000 026 R  k i  026 R  k i  026 R 000 k i H  026 R  k i  000 026 R 000 k i  026 R  k i  026 R 000 k i H  026 R 000 k i  where H  003  is the empirical entropy of 003  026 R k i 000 1 stands for 026 R l   000 k 1 l   000 k 2 001\001\001 l   000 k i 000 1  while 026 R  k i and 026 R 000 k i represent 026 R l   000 k 1 001\001\001 l   000 k i 000 1 l  k i and 026 R l   000 k 1 001\001\001 l   000 k i 000 1 l 000 k i respectively 1149 


In order to get more information after each question we employ the Iterative Dichotomiser 3 ID3 algorithm which recursively selects the question with the largest informativeness as the next question to build tree-like question format T  The algorithm consists of four steps 1 Calculate the informativeness of every question using the whole routes set 026 R  2 Split the routes set 026 R k i 000 1 into two subsets 026 R  k i and 026 R 000 k i 3 make a decision node of T containing question l k i 4 perform the above steps recursively on routes subsets 026 R  k i and 026 R 000 k i using remaining questions until all the subsets have only one route For example the question ordering result of the routes in Fig 3 is shown in Fig 7 The system will issue questions according to the workers answers to each question Here workers only need to answer two questions till the system getting their preference Fig 7 Discriminative landmarks of any two routes IV W ORKER S ELECTION Some Crowdsourcing platforms such as AMT and CrowdFlower give workers the freedom to choose any questions However this may cause some problems For example many workers choose to answer a same question while some other questions are not picked by anyone workers have to view all the questions before they choose workers may answer questions that they are not familiar with CrowdPlanner avoids these problems by designing a dedicated component to assign each task to a set of eligible workers In order to judge whether a worker is eligible for a task many aspects of the worker have to be taken into consideration i.e number of outstanding tasks worker's response time and familiarity with a certain area First since each worker may have many outstanding tasks in order to balance the workload and reduce the response time we use a threshold 021  q to restrict the maximum number of tasks for each worker Second each user of CrowdPlanner can specify the longest time delay she allows to get an answer so this task will not be assigned to workers who have a high probability to miss the due time Last a recommended route will have high con\002dence to be correct if the assigned workers are very familiar with this area Again the worker's familiarity with respect to a certain area can also be affected by several factors such as whether the worker lives around the area whether the worker has answered questions relating to this area correctly in the past etc In summary an eligible worker should meet three conditions 1 has quota to answer the question 2 has high probability to answer a question before the due time 3 has relatively high familiarity level with the query regions A Response Time Each task has a user-speci\002ed response time by which an answer must be returned We assume the probability of the response time t of a worker follows an exponential distribution i.e f  t  025   025 exp 000 025t  which is standard assumption in estimating worker's response time The cumulative distribution function of f  t  025  is F  t  025   1 000 exp 000 025t  If the probability of a worker to respond a task within time  t  represented by F   t  025   is less than the threshold 021 time  we will not assign the task to him B Worker's Familiarity Score People usually have the best knowledge for areas where they live or visit frequently In CrowdPlanner we develop a familiarity score f l w to estimate the knowledge of a worker w about a landmark l  f l w is mainly affected by two factors 1 worker's pro\002le information including her home address p home  work place p work and familiar suburbs p f s  which can be collected during her registration to the system and 2 history of worker's tasks around this area f l w of landmark is de\002ned as f l w  013 001 exp f\000  d  l p home   d  l p work   d  l p f s  g  1 000 013  001  correct  f 001  wrong  where 013 is a smoothing variable d  l p 003  is the distance between l and p 003   correct is the number of correctly answered questions of l   wrong is the number of incorrectly answered questions of l  and f is a constant less than 1  which measures the gain of a wrong answer Notably to avoid one's knowledge of far away places affect the calculating of her knowledge here we assign  1 to d  l x  if d  l p 003  is bigger than a threshold 021 dis  With all the n workers and m landmarks in our system a n 003 m matrix M with m ij  f l j w i is built where f l j w i is worker w i s familiarity score of landmark l j  Since the number of landmarks a worker has answered is always small compared with the large number of landmarks in the space M is very sparse Hence if task assigning is only based on the sparse M  the assigning process has a strong bias to assign tasks to only a few well-performed workers Actually workers who have similar pro\002le information or have answered several similar questions are highly possible to share the similar knowledge For example if a worker w 1 has high familiarity score with l 1  l 2 and l 3 and another worker w 2 living nearby has high familiarity score with l 1 and l 2  w 2 is also likely to be familiar with l 3 though w 2 has not answered any question relating to l 3  Similar situations hold for landmarks Therefore we need to predict familiarity scores of workers on landmarks using the latent similarity between workers and that of landmarks The familiarity scores of different pairs of worker landmark are determined by some unweighed or even unobserved factors which are regarded as some hidden knowledge categories e.g certain type of landmarks However we do not manually specify these factors as hard-coded factors are usually limited and biased Instead we assume the familiarity 1150 


score of each worker-landmark pair is a linear combination of two groups of scores i.e 1 how a worker is familiar with each hidden knowledge category and 2 how a landmark is related to each hidden knowledge category Then we employ Probabilistic Matrix Factorization PMF to f actorize M into two latent feature matrices W 2 R d 002 n and L d 002 m  which are the latent worker and landmark feature matrices respectively That is M  W T L  where W i;k describes how familiar worker w i is with knowledge category k  and L j;l describes how related landmark l j is to knowledge category k  Further we assume there exists observation uncertainty R  and the uncertain follows a normal distribution Thus the distribution of a new worker-landmark familiarity matrix M 0  which predicts some familiarity by leveraging the similarity between different workers and landmarks conditioned on W and L is de\002ned as follows p  M 0 j W L 033 2   n Y i 1 m Y j 1  N  M ij j W T i L j  033 2  I ij 1 where N  x j 026 022 2  is the probability density function of the normal distribution with mean 026 and variance 022 2  and I ij is a indicator which is equal to 1 if M ij is not zero otherwise 0 The prior of W and L are de\002ned as follows p  W j 033 2 W   n Y i 1 N  W i j 0  033 2 W I  p  L j 033 2 L   m Y i 1 N  L i j 0  033 2 L I  where I is identity matrix The following objective function maximizes the posterior of W and L with regularization terms which minimizes the prediction difference between our model and the observed M  and also automatically detects the appropriate number of factors d through the regularization terms n X i 1 m X j 1 I ij  M ij 000 W T i L j  2  025 W n X i 1 k W i k 2 F  025 L m X j 1 k L j k 2 F where 025 W  022 2 022 2 W  025 L  022 2 022 2 L  and k\001k 2 F denotes the Frobenius norm A local minimum of the objective function can be found by performing gradient descent in W and L  Afterwards more familiarity scores between workers and landmarks are inferred in M  A worker with a familiarity score of a landmark means he has some knowledge about the region around the landmark not just the landmark itself As a result the accumulated familiarity score F l j w i of l j of a worker w i is a weighted sum of all the landmarks in the 021 dis range of l j  We assume the weight around a landmark l follows a normal distribution of the distance to l  and the region that the knowledge of l can cover is limited in a circle with the center of l and the radius of 021 dis  Thus F l j w i is evaluated as follows F l j w i  X l 2 L near f l j g 016 l f l w i where L near is the set of landmarks in the 021 dis range of l  The weight 016 l  N  d  l l j  j 0  033 2 0  where 033 0  021 dis  3  We use M 003 to denote the worker-landmark matrix of the accumulated familiarity score where m 003 ij equals to F l j w i  C Finding Top-k Eligible Workers Next we discuss how to 002nd the top-k eligible workers for a given task Given a task the selected n landmarks L R  the worker-landmark accumulated familiarity score matrix M 003  a response time t  a positive integer k  a topk eligible workers query returns k workers who have the most knowledge of landmarks in L R among all the workers and have high possibility to 002nish the task within time t  For a single landmark l j  there may be several workers denoted as W l j  who have non-zero accumulated familiar scores which means these workers have some knowledge of l j  For a task a set of landmarks L R  S l 2 L R W l represents workers who have knowledge of any landmark of L R  Then we 002lter out workers of who the possibility of 002nishing the task within time t is no more than 021 time  from S l 2 L R W l  Afterwards the remained workers in S l 2 L R W l are regarded as candidate workers denoted by W  However simply adding up a worker's accumulated familiarity scores on all the landmarks of L R may lead biased result in worker selection For example there are ten landmarks in a task and two candidates workers w 1 and w 2  that w 1 only has a very good knowledge of landmark l 1  say F l 1 w 1 2 and knows nothing about the rest landmarks F l i w 1  0   2 024 i 024 10  while w 2 has some knowledge of all the landmarks that F w 2  l i   0  1  1 024 i 024 10  Comparing the adding up sum of accumulated familiarity scores of the ten landmarks w 1 will be selected to be assigned the task However the coverage of w 1 s knowledge of the landmark set is too narrow that w 1 may feel hard to answer questions about l 2  l 3  001 001 001  l 10  in the knowledge coverage manner w 2 is a better choice Thus when selecting workers from candidate workers not only their sum of accumulated familiarity scores of all the landmarks but also the knowledge coverage of all the landmarks should be considered The choosing rules are quite similar to rated voting system of which the wining option is chosen according to the voters preferences score of options and the number of voters preferring the options In our system we can treat each landmark of L R as a voter and each worker of W as an option Adopting the idea of rated voting system we can measure the landmark l j s preference of all the candidate workers by the following two steps 1 rank workers of W l j  W  who are in the candidate workers set W and have accumulated familiar scores F l j w bigger than zero in descending order of F l j w  2 the preference score p w l j of l j to each worker w in W l j  W is de\002ned as follows p w l j   1 000 rank  w  000 1  j W l j  W j  if w 2 W l j  W 0  otherwise where rank  w  is the ranked place of w among W l j  W  In this way the worker with high accumulate familiarity score will 1151 


get a relatively high preference score and ensure the preference score will not result in a bias in worker selecting Afterwards all the landmarks will vote their preferences to the candidate workers Then we sum up the preferences of each worker voted by landmarks and choose the workers with the topk biggest adding up preference scores as the query results V E XPERIMENTS In this section we conduct extensive experiments to validate the effectiveness and ef\002ciency of the two core components of our proposed CrowdPlanner system namely landmark selection and worker selection All the algorithms in our system are implemented in Java and run on a computer with Intel Core i5-3210 CPU 2.50GHz and 4 GB memory A Experiment Setup Trajectory Dataset We use two real trajectory datasets generated by taxis trucks and private cars in Beijing and Nanjing big cities of China The detail information of these trajectory datasets is shown in Table II TABLE II D ATASET   Id  City  trajectory  Duration     A  Beijing  112,232  six months    B  Nanjing  35,340  three months   POI Clusters We get two POI datasets of the Beijing and Nanjing cities from a reliable third-party company in China After performing DBSCAN on these POI datasets approximately 50,000 POI clusters are obtained and each POI cluster is used as a landmark Ground truth route We carefully choose 1000 popular routes agreed by all three route mining algorithms in each city as the ground truth These routes are treated as the correct answers for the route recommendation request between corresponding places Workers In each of the cities we have several volunteers to answer the questions generated by CrowdPlanner B Evaluation Approach For each ground truth route we query a big thumb map service provider to get three recommended routes from its source to its destination The ground truth and the recommended routes form the candidate route set based on which a task will be generated and assigned to workers In this way we can assess the accuracy of the answers returned by the system by comparing the answer with the ground truth Table III lists all the parameters we use throughout the experiments All the parameters are assigned the default values unless speci\002ed explicitly C Performance Evaluation 1 Case Study Before conducting the quantitative performance evaluation we give a demonstration of the CrowdPlanner system Fig 8 shows the system interface when a TABLE III P ARAMETER SETTINGS   Notation  Explanation  Default value     n  number of candidate routes  6    j L j  size of landmarks on candidate routes  200    013  in\003uence factor of people's living space to their knowledge  0.3    f  in\003uence factor of people answering a question wrong to their knowledge  0.3    021  q  the maximum number of outstanding tasks of each worker  3    021 dis  radius of knowledge in\003uence region  500m    021 t  the minimal possibility to answer a question in time  80   client user submit a recommendation request which speci\002es she wants to get the best recommended routes from Nanjing Confucius Temple to Nanjing Railway Station 002fteen minutes later about 1:48am and she awards the request for 002ve coins the virtual currency of CrowdPlanner After Fig 8 A request for route evaluating receiving the request the server matches the request to the veri\002ed routes and generating candidates routes by invoking web services and popular route mining algorithms in turn Since the system cannot automatically evaluate these candidate routes it generates a route evaluation task and assigns it to some eligible workers Fig 9\(a illustrates the evaluation task on a client where four candidate routes from Nanjing Confucius temple to Nanjing railway station are shown in red and blue lines The 002rst binary question is do you prefer to go past 223Xinjiekou\224 from Nanjing Confucius temple to Nanjing railway station at 1:48 Xinjiekou is one of the most 003ushing commercial districts of Nanjing Thus to avoid traf\002c the worker may prefer not to pass Xinjiekou which prunes the two red routes The second question for her is whether the route should pass 223Jiuhuashan Tunnel\224 As shown in Fig 9\(b 223Jiuhuashan Tunnel\224 is the most famous tunnel under the Xuanwu Lake which is the major difference between the two routes left 1152 


a Question 1 b Question 2 Fig 9 Questions of evaluating best route from Nanjing Confucius Temple to Nanjing Railway Station 2 Quality of Recommendation The goal of CrowdPlanner is to give users the veri\002ed best routes between two places In the 002rst set of experiments we evaluate the accuracy of routes recommended by CrowdPlanner by comparing with the ground truth As shown in Fig 10\(a the system can achieve very high accuracy  025 90  in the cities when suitable workers are selected which means our system can recommend the best route from the set of candidate routes in most cases Note that as shown in Fig 10\(b the system still has about 70 accuracy even if the tasks are assigned to random workers demonstrating the robustness and tolerance to the workers qualities of our system a Precision with worker selection b Precision without worker selection Fig 10 Accuracy of route recommendation 3 Effectiveness of Worker Selection In this experiment we test whether the overall performance of the system can be improved by assigning tasks to suitable workers with good knowledge about the query area As a comparison we also assign the same tasks to random workers without any selection algorithms applied The accuracy of the route recommendation is shown in Fig 10 from which we can see that the overall accuracy can improve by 20 by applying the proposed worker selection methods We also collect statistics of the workers knowledge about the queried area to further demonstrate why worker selection is necessary Since a worker's knowledge is hard to quantify exactly we propose to use four familiarity levels to assess the worker's knowledge 1 has no idea of the area 2 have heard the area but never been there 3 have visited the area several times 4 knows this area very well local resident We ask the workers to classify themselves into one of the four levels based on her familiarity to the query area Fig 11\(a shows the knowledge level of randomly picked workers RPW and selected workers SW of the querying regions We can see that nearly 70 of the randomly picked workers have not travelled to the query regions and even 27 know nothing about the regions on the other hand 70 of selected workers have travelled at least once in these regions and about 20 selected workers know the area very well This implies that the proposed worker selection algorithms can effectively 002nd the workers with good knowledge about the query area a Workers knowledge about querying places b Relationship between knowledge and precision Fig 11 Analysis of worker's knowledge To further demonstrate the relationship between worker's knowledge and the accuracy of an answer we analyze the relationship between the precision of recommended routes and workers knowledge level The result is shown in Fig 11\(b from which we can see that the precision grows steadily with workers getting more familiar with the area 4 Effect of Question Format The question format adopted by CrowdPlanner is a series of binary questions with a certain order In this experiment we evaluate the effect of different question formats to the performance of the system We compare our question format BO with three other format candidates 1 map only format MO show the candidate routes directly on map and ask workers to choose 2 checkbox format CB workers need to choose all the landmarks on their preferred routes and 3 binary question without smart ordering BwO the questions are asked in the descending order of the signi\002cance We generate the same tasks using the four question formats and assign to the same set of workers Both ef\002ciency and accuracy are evaluated The results are shown in Fig 12 From Fig 12\(a we can see that MO takes the longest time for workers to 002nish a task which is because the workers need to spend lots of time to realize the differences between candidate routes All other question formats of which the differences are automatically summarized by the system cost around 10s for each task Notably BO format costs less time than BwO since by presenting the questions in a smarter order the number of questions needed for each task 1153 


has reduced CB takes the least time as many workers do not bother to check a lot of landmarks and simply skip the questions Fig 12\(b shows the results of accuracy in which CB format has the lowest precision since people pay least time and attention on this type of question Binary question format both BwO and BO outperform MO in precision since MO is hard for people to realize the difference between candidate routes on a map Furthermore the precision of BO is more than 10 higher than that of BwO demonstrating that smart ordering not only reduces the time cost but also improves the accuracy of answers a Time cost of different question formats b Precision of different question formats Fig 12 In\003uence of question formats 5 Time Cost of Landmark Selection We also test the time cost of landmark selection process which is important for CrowdPlanner to respond to user request in real-time In general two factors can in\003uence the time cost a the number of landmarks on the candidate routes and b the number of candidate routes Both factors are tested in our experiments by comparing the GreedySelecting GS method with the Incremental Landmark Selecting ILS introduced by The average time cost for selecting landmarks of a candidate route set with the size of 6 is shown in Fig 13\(a from which we observe that both the time costs of GS and ILS grow with the landmark size increasing from 50 to 400 However GS constantly outperforms ILS by three orders of magnitudes The average time costs for selecting landmarks with different number of candidate route set are shown in Fig 13\(b It illustrates that the running time of GS is much more stable as the number of candidate routes grows compared to the exponential growth of the time cost of ILS a Time cost of k  6 b Time cost of j L j  200 Fig 13 Ef\002ciency of landmark selection algorithms 6 Precision of Map Service and Popular Route Mining Algorithms The last set of experiments are conducted to demonstrate the precision of six kind of candidate routes i.e three provided by the web service and the others provided by three popular routes mining algorithms respectively The three routes denoted by WS1 WS2 and WS3 are recommended by the web service with different levels of recommendation where WS1 is the best recommended route of the web service while WS3 is the least We randomly generate 100 route recommendation tasks in each city and assign each task to its top-5 eligible workers to get the best route of each task Fig 14 shows the percentage of desirable results of each kind candidate route de\002ned as precision Clearly it shows that the precision of routes provided by web services WS1 WS2 and WS3 is about 70 however the best recommended route WS1 has less 40 precision Moreover none of these providers can have the probability high enough to provide best routes Though the precision of MFP is the highest about 43 among the six kinds of routes it is still not satisfactory Fig 14 Precision of routes from different sources VI R ELATED W ORK To our knowledge there is no existing work on evaluating the quality of recommended routes As the goal of this work is to evaluate the quality of recommended routes by web services and mining algorithms the route recommendation algorithms mining frequent path algorithms used in this paper are reviewed 002rst Also we leverage the generating easy questions and 002nding target workers to improve the quality of evaluating and reduce the workers workload which share the same motivation of some research works of Crowdsourcing question designing and workers selecting Therefore in the last of this section we will review previous works of these two aspects Route Recommendation Algorithms The popular routes mining has received tremendous research interests for a decade and a lot of works are on it such as 15 6 7 27  15 7 27 12 11 5 10 Am o ng these w orks  26 14 3 are the most representati v e Chen et al  proposes a no v el popularity function for path desirability evaluation using historical trajectory datasets The popular routes recommended by it tends to have fewer vertices The work in pro vides k popular routes by mining uncertain trajectories The recommendation routes of this work tend to be rough routes instead of correct routes claims the popular routes change with time so it carries out a popular routes mining algorithms which can provide the recommended 1154 


routes in arbitrary time periods speci\002ed by the users provides the evidences that the routes recommended by web services are sometimes different from drivers preference Thus it mines the individual popular routes from his historical trajectories The recommended routes of this method re\003ect certain people's preference Question Designing Question designing is always an application dependent strategy which may consider the cost of questions or the number of questions 18 propose strategies to minimize the cost of the questions designed The question designing strategy of is to minimize the number of questions The question designing strategy of is to generate the optimal set of questions b uilds the desired traveling plans incrementally optimally choosing at each step the best questions so that the overall number of questions to minimize the number of the asked questions Worker Selecting Selecting workers with high individual qualities for tasks always does bene\002cial to the 002nal quality of answers Thus propose an algorithm to select w ork ers ful\002lling some skills with the minimized the cost of choosing them In use emails communication to identifying skillful workers Cao et al assign tasks to micro-blog users by mining users knowledge and measuring their error rate VII C ONCLUSIONS In this work we present a novel crowd-based route recommendation system 226 CrowdPlanner which evaluates the quality of routes recommended from different sources by leveraging the knowledge and opinions of the crowd Two core components task generation and worker selection have been carefully designed such that informative and concise questions will be created and assigned to the most suitable workers By having the system deployed and tested in real scenarios we demonstrate CrowdPlanner is able to recommend users the most satisfactory routes with at least 90-percent chances much higher than either the most well-known map services or the state-of-art route mining algorithms Besides this research sheds light on some other crowd-based recommendation systems such as location recommendation and itinerary planning which can be used in more application scenarios A CKNOWLEDGMENTS This research is partially supported by Natural Science Foundation of China Grant No.61232006 and the Australian Research Council Grants No DP110103423 DP120102829 and LP130100164 Lei Chen's work is partially supported by Hong Kong RGC-NSFC N  HKUST637/13 National Grand Fundamental Research 973 Program of China under Grant 2012-CB316200 Microsoft Research Asia Gift Grant and Google Faculty Award 2013 R EFERENCES  C Campbell P  Maglio A x Cozzi and B Dom Expertise identi\002cation using email communications In CIKM  pages 528\226531 ACM 2003  C Cao J g She Y  T ong and L Chen Whom to ask jury selection for decision making tasks on micro-blog services PVLDB  5\(11 1506 2012  V  Ceikut and C Jensen Routing service quality\007local dri v er beha vior versus routing services In MDM  pages 195\226203 IEEE 2013  Z Chen H Shen and X Zhou Disco v ering popular routes from trajectories In ICDE  pages 900\226911 2011  S Gaf fne y and P  Smyth T rajectory clustering with mixtures of regression models In SIGKDD  pages 63\22672 ACM 1999  F  Giannotti M Nanni F  Pinelli and D Pedreschi T rajectory pattern mining In KDD  pages 330\226339 2007  H Gonzalez J Han X Li M Myslinska and J Sondag Adapti v e fastest path computation on a road network A traf\002c mining approach In PVLDB  pages 794\226805 2007  S Guo A P aramesw aran and H Garcia-Molina So who w on dynamic max discovery with the crowd In SIGMOD  pages 385\226396 ACM 2012  T  Lappas K Liu and E T erzi Fi nding a team of e xperts in social networks In SIGKDD  pages 467\226476 ACM 2009  J Lee J Han X Li and H Gonzalez T raclass trajectory classi\002cation using hierarchical region-based and trajectory-based clustering PVLDB  1\(1 2008  J Lee J Han and K Whang T rajectory clustering a partition-andgroup framework In SIGMOD  pages 593\226604 ACM 2007  X Li J Han J Lee and H Gonzalez T raf 002c density-based disco v ery of hot routes in road networks Advances in Spatial and Temporal Databases  pages 441\226459 2007  I Lotosh T  Milo and S No vgorodo v  Cro wdplanr Planning made easy with crowd In Data Engineering ICDE 2013 IEEE 29th International Conference on  pages 1344\2261347 2013  W  Luo H T an L Chen and L Ni Finding time period-based most frequent path in big trajectory data In SIGMOD  pages 195\226203 ACM 2013  N Mamoulis H Cao G K ollios M Hadjieleftheriou Y  T ao and D Cheung Mining indexing and querying historical spatiotemporal data In KDD  pages 236\226245 2004  A Mnih and R Salakhutdino v  Probabilistic matrix f actorization In NIPS  pages 1257\2261264 2007  L Nordmann and H Pham W eighted v oting systems Reliability IEEE Transactions on  48\(1 1999  A P aramesw aran H Garcia-Molina H P ark N Polyzotis A Ramesh and J Widom Crowdscreen Algorithms for 002ltering data with humans In SIGMOD  pages 361\226372 ACM 2012  A P aramesw aran A Sarma H Garcia-Molina N Polyzotis and J Widom Human-assisted graph search it's okay to ask questions PVLDB  4\(5 2011  J R Quinlan Induction of decision trees Machine learning  1\(1 106 1986  D Sacharidis K P atroumpas M T erro vitis V  Kantere M Potamias K Mouratidis and T Sellis On-line discovery of hot motion paths In EDBT  pages 392\226403 2008  H Su Cro wdplanner A cro wd-based route recommendation system CoRR  abs/1309.2687 2013  H Su J Deng and F  Li Cro wdsourcing annotations for visual object detection In AAAI  2012  H Su K Zheng H W ang J Huang and X Zhou Calibrating trajectory data for similarity-based analysis In SIGMOD  pages 833\226844 ACM 2013  J W ang T  Kraska M Franklin and J Feng Cro wder Cro wdsourcing entity resolution PVLDB  5\(11 2012  L.-Y  W ei Y  Zheng and W C Peng Constructing popular routes from uncertain trajectories In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining  pages 195\226203 ACM 2012  Y  Zheng L Zhang X Xie and W  Ma Mining interesting locations and travel sequences from gps trajectories In WWW  pages 791\226800 2009 1155 


                  


  


                                               


   


                                


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



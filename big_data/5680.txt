The Application of Grey Correlation Analysis in the Big Electrical Customers from Baoding City   Shuliang Liu, Yining Ma School of Management North China Electric Power University, Baoding 000\023\000\032\000\024\000\023\000\023\000\026 China 123lsl@163.com, mayining2000@126.com   Abstract By analyzing the data of 20 big electrical customers from Baoding city, Hebei province, calculating the consumer values and adopting the grey correlative analysis method, this paper has found out the VIP customers from many electrical customers based on incomplete information and defined a clear correlative degree between the important customer and the enterprise. After that, this pap er puts forward a point of view based on sorting correlative degree, which asks us to devote plentiful time and energy to the loyal customers, and give them man-to-man service. The customers with low correlative degree are called low-value customers, their current and potential values are low, and enterprises should analyze the reason and give them certain training and education. Enterprise should al so abandon those customers who are sensitive to price, less loyal hard to persuade and have poor credit records 1. The calculation of Customer's value Customers are a kind of valuable resource for enterprises but not every customer has contri bution to enterpriseês profit Itês the aim of every enterprise to have high-value customers and maximize customer values. Many enterprisesê attention has moved from possession of market to the value of customer Many scholars have done som e research from different perspectives on how to define customer value and how to do quantitative analysis of customerês value. How much will lose if the enterprise loses one custom er? What will happen in the increasing of profit if we can reduce 5% losing of the customer Every company will have a go od financial balance between investing on new business and investing on the existing customers if it knows the profit losing accompanying with dropping a customer. Unfortunately, the fiscal system could not calculate the value of one loyal customer, and the financial system often ignores the cash flow when the customer keeps relationship with the company The existing customers will contribute to the profit of the company year by year if they can always receive good services Now we will talk about the detailed calculation of the customerês value At first, supposing the customer will keep relationship with the company for 5 years: N=5. The initial cost of one customer marketing cost 002 500. The price when the customer first buy the product is 10000 Yuan: P0 002 10000 The increasing income that the companies want to get from each customer is 5000 Yuan: R 002 5000. The lending rate is 6%: r =6%. Then, the value of one customer is equal to the product, at the first time plus the expenditure in next years, at last subtract the marketing cost from the sum Customerês value =P0 003 C0+ R 004 002\003 r r N 004 005 1  1 1  10000-500+5000 004  002\003  6  6 1  1 1 5 004 005 005 30563 If we can use the Customer Relationship Management CRM\ake the customers buy more electrical products after they have become customers of the electrical company the value of customer will increased also. For example, if the customer has purchased a service valued 3000 Yuan after his first purchasing of a commodity valued 10000 Yuan, the company may hope the customer purchase it every year. So the value of customer is increased as follows 3000+3000 004 002\003  6  6 1  1 1 6 004 005 005\002 15637 Therefore, the value of customer is 46200 Yuan, the sum of 30563 Yuan and 15637 Yuan Then, let us talk about the losi ng of profit after dropping one customer In the calculation before we can see the value of this customer, the profit is 46200 Yuan. If the customer does not have any dealing with the compa ny, firstly the company will lose the 46200 Yuan secondly the credit standing of the company will be damaged. If th e damaged quotiety is 10%, the economic losing will be 46200 ◊ 10%=4620. So, if the company loses one customer, the direct profit losing is 50820 Yuan Actually, the losing of the company is not only that. Every customer who left the company has his own reason. Maybe the product or the service of this company has some problems Maybe the company could not give a satisfying response to the customerês complaint. If a company reduces its customer losing rate by 5% every year its profit could increase by 25 to 85%. The cost of obtaining a new customer is as 5 times as that of retaining an existing customer, and an unsatisfied customer can affect 5 more others on average. So we can see that losing one customer actually means losing a series of customers 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 115 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 115 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 10.1109/ICNC.2008.827 115 


Supposing that only 10% of the customer will lodge a complaint against th e company, it means when the company has received 100 lodgings, there are 1000 customers who are not satisfied. All of these customers will take damage to the market of the company, and the losing is every customerês value multiple the number of the customer. In this example the final losing will be more than 5000000 Yuan 2. The approach of grey correlation analysis The loyal customer can give the company rich profit, so obtaining the loyal customer is every companyês aim. Some companies take much time and money to find out the loyal customer, but the result is failing. They have got more and more customers, but the customers do not give profit to the company. The reason of this situation is they can not use the right method to find out the most valuable customers. The theory of grey system is firstly advocated by a Chinese professor named Deng Julong in 1982. In this theo ry, all of the systems are divided in to three kinds: the white system, the black system and the grey system. The white means all of the system is known, the blac k means all of the system is unknown, and the grey means some part of the system is known and some part is unknown So the grey system is a kind of system which includes known information and unknown information. The objective of analyzing the grey system is making the system be known, namely using the known information to open out the unknown information. Every company which wants to implement management of loyal customer should establish a scientific and reasonable recognize model to find out th e loyal custom er, to support pertinent service and improve the quality of product and service Amusing there has one referenced numerical sequence X0} \(the industrial power quan tity of Baoding city comparative numerical sequence {Xi 002 i=1 002 2 002»\001\002\002 n \(the big customers of industrial po wer from Baoding city essential idea of the correlation analysis is to find out the VIP customers by analyzing how the changing of the co mparative sequence took effect on the referenced sequence. The basic approaches are as follows 2.1. Make the original data standardized Because the dimension and the unitage of original data are different with each other, they should be standardized before conducting the correlation analysis. The common approaches are initial value method and av erage value method. In this paper we adopt the first one, namely use the first number Xi \(l to divide other numbers. After the standardization, we will get a balanced and comparable ratio 2.2. Use subtraction sequence to have the absolute difference between Xi and X0 in its referenced sequence at every time 2.3. Calculate the two level minimal and maximal difference Two level minimal difference is 006 k 000 k\inimum is selected at every moment,  min|X0\(k\Xi\(k\nd then the minimum is selected from the minimums. That is the minimum difference between the poles 002\003 002\003 002\003 a k k in inm m k in inm m x x i k i i k i 006 005 006 007 0 the maximum difference between poles 000 k\and then the maximum is selected at every moment. max|X0\(k Xi\(k\the maximum is selected from the maximums. That is the maximum difference between poles 002\003 002\003 002\003 b k k ax axm m k ax axm m x x i k i i k i 006 005 006 007 0  i=k=1,2 001\002 n 2.4. Calculate the cor relative degree 000 i\(k\X 1 002 X 2 X k to X 0  002 003 002 003 002 003 002 003 002\003 002\003 002\003 002\003 k k ax k axm i 002m k k k k ax k axm i 002m k k in k inm i m x x x x x x x x 0 0 0 0 0 0 0 0 005 004 005 005 004 005 006 010  002\003 002\003 002b k k b a x x 004 005 004 006 0 0 011  2.5. Calculate the correl ative degree 012 006 006 n k i k n r 1   1 010 i=1 002 2 002»\001\002\002 n 2.6. Analyze the correlative degree r i  According to the r i to fix on the correlative degree between every factor and the system high degree means the high correlation with the system 3. Application examples 3.1. Data source In Dec. 2007, the writer conducted a statistical survey on the consumption amount of elect ric power from Mar. to Nov in 2007 from Baoding cityês 20 big industrial electricity customers. For the lack of data the data should not be coped with multi recursion 002 stepwise recursion and other methods We could get the VIP customer by conducting grey correlative analysis Table 1 The consumption of el ectricity and influence factor of the big industrial customers from Baoding City   unit: MWH     
116 
116 
116 


Table 1  The consumption of electricity and influence factor of the big industrial customers from Baoding City      unit: MWH Month                                 3              4             5                   6               7              8 9              10             11 Power quantity            X 0 225250     210850 197900 194280 209920 215860 219330 218900 229560 Huaxian                       X 1 17768         17108 16897 17108        14910 16629 18348 18285 16336 Yaxin Steel               X 2 14015 13542 2749 13542        13586 16829 20072 20342 23183 Jingdeng Steel          X 3 10930 10428 11656 10428        11728 12226 12725 12461 11491 Baoshuo Steel          X 4 14120       13197 14492 13197        11088      13202 15317 21220 18386 Quyang Fertilizer      X 5 12953 12298 12952 12298          1846      12433          13020 17526 17133 Huabei Aluminium  X 6 9012           8609 8935 8609           9458 9242 9026 9297 8875 Bank paper               X 7 9209 9015 9730 9015           3240         4451           5662 5357          5912 Yimian                      X 8 5632 5512 5284 5512           5926 5824 5722        5064 4915 Huabei petroleum    X 9 7147 6303 4293           6303 5615 5174           4733        5822 5211 Sanlian Paper           X 10 5591          5515 5854 5515 5386        5358 5331 6028          5258 Shuohuang Steel     X 12 5419          6580 6613 6580 6844 6615 6387        6658 5 825 Fengfan                    X 13 4969 4807 4119 4807 4482 4782 5082 5185 4786 Film                          X 14 3866 4406 4301 4406 4427 4510 4593 3945 3937 HuaQiang Spin       X 15 2966 2912 2990 2912 2964 2992 3020 2944 2514 Yixian Fertilizer     X 16 4156          4219 3651 4219 350 183 17             21 39 Baoshuo Green       X 17 3872 3644 2879 3644 3347 3360 3373 3134 2984 Tianwei                  X 18 1570 1321           1388 1321 2102 1904 1707 1622 1481 Aoyu Steel             X 19 8752          8339 7050 8339 8320 8886 9453       10729 14120 Taihang Cement     X 20 7829 6508 8594 6508 8724 9104 9484 10266 11328 3.2. Step of Calculation 3.2.1. Standardization Disposal In this example, we deal with the data using initial value method. Every data would be divided by the first data in th e column. For example, in the X0 column, X01=2252 50 /225250=1 002 X02=210850/225250 0.9361. Repeating this process, we will get Table Table 2 000\003 Data without Dimension Table 2 000\003 Data without Dimension 3            4             5                6            7              8             9             1 0         11 X0    1 0.9361 0.8786 0.8625 0.9319 0.9583 0.9737 0.9718 1.0191 X2    1 0.9629 0.9510 0.9629 0.8391 0.9359 1.0326 1.0291 0.9194 X3    1 0.9663 0.1961 0.9663 0.9694 1.2008 1.4322 1.4514 1.6542 X4    1 0.9541 1.0664 0.9541 1.0730 1.1186 1.1642 1.1401 1.0513 X5    1 0.9346 1.0263 0.9346 0.7853 0.9350 1.0848 1.5028 1.3021 X6    1                   0.9494 0.9999 0.9494 0.9145 0.9599 1.0052 1.3530 1.3227 X7    1 0.9553 0.9915 0.9553 1.0495 1.0255 1.0016 1.0316 0.9848 X8    1 0.9789 1.0566 0.9789 0.3518 0.4833 0.6148 0.5817 0.6420 X9    1                   0.9787 0.9382 0.9787 1.0522 1.0341 1.0160 0.8991 0.8727 X10   1                  0.8819 0.6007 0.8819 0.7856 0.7239 0.6622 0.8146 0.7291 X11   1                  0.9864 1.0470 0.9864 0.9633 0.9583 0.9535 1.0782 0.9404 X12   1 1.2142 1.2203 1.2142 1.2630 1.2207 1.1786 1.2286 1.0749 X13   1                  0.9674 0.8289 0.9674 0.9020 0.9624 1.0227 1.0435 0.9632 X14   1 1.1397 1.1125 1.1397 1.1451 1.1666 1.1880 1.0204 1.0184 X15   1                   0.9818 1.0081 0.9818 0.9993 1.0088 1.0182 0.9926 0.8476 X16   1 1.0152 0.8785 1.0152 0.0842 0.0440 0.0041 0.0051 0.0094 X17   1 0.9411 0.7435 0.9411 0.8644 0.8678 0.8711 0.8094 0.7707 X18   1 0.8414 0.8841 0.8414 1.3389 1.2127 1.0873 1.0331 0.9433 X19   1 0.9528 0.8055 0.9528 0.9506 1.0153 1.0801 1.2259 1.6133 X20   1 0.8313 1.0977 0.8313 1.1143 1.1629 1.2114 1.3113 1.4469  3.2.2. Subtraction sequence  000 1\(1\=|1-1|=0 002  006 1\(2\9361|=0.0268 Repeating this process, we will get Table 3 Table 3  Difference Table 3            4             5                6            7              8             9             10 11 0021\(k\     0 0.0268 0.0724 0.1004 0.0928 0.0224 0.0589 0.0573 0.0997 0022\(k\     0 0.0302 0.6824 0.1038 0.0374 0.2425 0.4585 0.4796 0.6350 0023\(k\     0 0.0180 0.1878 0.0916 0.1411 0.1603 0.1905 0.1683 0.0322 0024\(k\     0 0.0014 0.1478 0.0722 0.1467 0.0233 0.1111 0.5310 0.2830 0025\(k\     0 0.0134 0.1213 0.0870 0.0174 0.0015 0.0315 0.3812 0.3036 0026\(k\     0 0.0192 0.1129 0.0928 0.1175 0.0672 0.0278 0.0598 0.0343 0027\(k\     0 0.0429 0.1780 0.1165 0.5801 0.4750 0.3589 0.3901 0.3772 0028\(k\     0 0.0426 0.0596 0.1162 0.1203 0.0758 0.0423 0.0727 0.1464 0029\(k\     0 0.0542 0.2779 0.0194 0.1463 0.2344 0.3115 0.1572 0.2900 00210\(k\    0 0.0503 0.1685 0.1239 0.0314 0.0000 0.0202 0.1064 0.0787 00211\(k\    0 0.2782 0.3418 0.3518 0.3310 0.2624 0.2049 0.2568 0.0558 00212\(k\    0 0.0313 0.0496 0.1049 0.0299 0.0041 0.0490 0.0717 0.0560 00213\(k\    0 0.2036 0.2339 0.2772 0.2132 0.2083 0.2143 0.0486 0.0008 00214\(k\    0 0.0457 0.1295 0.1193 0.0674 0.0505 0.0445 0.0208 0.1715 
117 
117 
117 


00215\(k\    0 0.0791 0.0001 0.1527 0.8477 0.9143 0.9696 0.9668 1.0098 00216\(k\    0 0.0050 0.1350 0.0787 0.0675 0.0905 0.1026 0.1624 0.2485 00217\(k\    0 0.0947 0.0055 0.0211 0.4069 0.2544 0.1135 0.0613 0.0758 00218\(k\    0          0.0167 0.0730 0.0903 0.0187 0.0570 0.1064 0.2541 0.5942 00219\(k\    0          0.1048 0.2191 0.0312 0.1824 0.2045 0.2377 0.3395 0.4278 3.2.3. Calculate the mini mal and maximal value miaxmkax 000 i\(k 1.0098,miin mkin 000 i k\0 3.2.4. Calculate the correlative degree 002\003 1 0098  1 5  0 0 0098  1 5  0 1 006 013 004 013 006 010  002\003 9496  0 0098  1 5  0 0268  0 0098  1 5  0 2 006 013 004 013 006 010  Repeating this process we will get Table 4   Table 4 Correlative degree 0031\(k\    1 0.9496 0.8746 0.8341 0.8447 0.9575 0.8955 0.8981 1.2461 0032\(k\    1 0.9436 0.4252 0.8295 0.9310 0.6756 0.5241 0.5128 0.4429 0033\(k\    1 0.9656 0.7288 0.8464 0.7816 0.7591 0.7260 0.7500 0.9401 0034\(k\    1 0.9972 0.7736 0.8749 0.7749 0.9559 0.8197 0.4874 0.6408 0035\(k\    1                 0.9742 0.8062 0.8531 0.9667 0.9970 0.9414 0.5698 0.6245 0036\(k\    1 0.9633 0.8173 0.8447 0.8112 0.8825 0.9478 0.8941 0.9363 0037\(k\    1 0.9217 0.7394 0.8126 0.4653 0.5153 0.5845 0.5641 0.5724 0038\(k\    1 0.9222 0.8944 0.8129 0.8076 0.8695 0.9228 0.8742 0.7752 0039\(k\    1 0.9031 0.6450 0.9629 0.7753 0.6830 0.6185 0.7626 0.6352 00310\(k\   1 0.9093 0.7498 0.8029 0.9415 1.0000 0.9615 0.8260 0.8652 00311\(k\   1 0.6448 0.5963 0.5894 0.6040 0.6580 0.7113 0.6628 0.9005 00312\(k\   1 0.9416 0.9105 0.8279 0.9440 0.9920 0.9115 0.8757 0.9002 00313\(k\   1 0.7126 0.6834 0.6456 0.7031 0.7080 0.7020 0.9122 0.9985 00314\(k\   1 0.9170 0.7959 0.8088 0.8823 0.9092 0.9190 0.9605 0.7464 00315\(k\   1 0.8646 0.9998 0.7678 0.3733 0.3558 0.3424 0.3431 0.3333 00316\(k\   1 0.9901 0.7890 0.8652 0.8820 0.8479 0.8311 0.7566 0.6702 00317\(k\   1 0.8421 0.9892 0.9600 0.5537 0.6649 0.8164 0.8917 0.8694 00318\(k\   1 0.9679 0.8736 0.8482 0.9643 0.8986 0.8260 0.6652 0.4594 00319\(k\   1 0.8281 0.6973 0.9418 0.7346 0.7117 0.6799 0.5980 0.5413 000\003 3.2.5. Calculate the correlative degree r1=1/9*\(1+0.9496+0.8746 007 1.2461\9445 010 r2=0.6983 ,r3=0.8331 r4=0.8138 ,  r5 0.8592, r6=0.8997 r7=0.6861, r8=0.8754 r9=0.7762, r10=0.89 51, r11=0.7075 r12=0.9226, r13=0.7850 r14=0.8821, r15=0.5 978, r16=0.8480 r17=0.8431, r18=0.83 37, r19=0.7481 So, the correlative degree sequence are as follows Huaxian 0.9445 > Fengfan 0.922 6 > Huabei Aluminum 0.8997 > Sanlian Paper 0.8951 uaqiang Spin 0.8821 Yimian 0.8754 > Quyang Fer tilizer 0.8592 > Baoshuo Green 0.8480 > Tianwei 0.8 431 > Aoyu Steel 0.8337 > Jingzheng Steel 0.8331 > Baoshuo 0.8138 Film 0.7850 > Huabei petroleum 0.7762 > Taihang Ceme nt0.7481 > Shuohuang Steel 0.7075 > Yaxin Steel 0.6983 Bank Paper 0.6861 > Yixian Fertilizer 0.5978 4. Conclusion The grey correlative analysis c ould tell us the correlation among all factors of the grey system when the system changes Through processing the past data, we can make clear the correlation between the factors and the system; get factors which affect the system mostly Getting the approach degree of these factors, finding primary factor, we will nail down the emphases of the work. The correlation indicates the correlative degree between relatively sequence and referenced sequence The degree is more correlative when itês more nearer to 1 Looking for VIP customer by the grey-correlative analysis, we can serve the customer effectively with less blindness and more scientism. The order of correla tive degree indicates that the correlations of Huaxian, Fengfan, Huabei Aluminum and Sanlian Paper are the highest and these customers are the most useful to the profit, Huaqiang Spin, Yimian, Quyang Fertilizer etc are less useful. Bank Paper and Yixian Fertilizer work indistinctively. So, we should invest more time and energy on Huaxian, Fengfan, Huabei Aluminum and Sanlian Paper, but instruct the customers who are at the bottom of the sequence with less time and energy 5. References  Julong Den g. Grey Prediction and Decision-m aking W uhan: Huazhong  University Press, pp. 104-107, 2001  Xiang Lin. Use In kling Judg m ent to Judge Recent Years Food Sanitation in Wuzhou. China Health Stat. pp. 43-47, 1998  Zengzhen W a ng, Junrong Li. Correla tion Degree Analy sis and the Comparison about the Analysis. China Health Stat. pp. 22-29, 1991  Lijun Ma  The C o rrelation Degree Analysis in Me dicine Research China Health Stat. pp. 41-46, 1992  Dongxiao Niu,Shuhua Cao,Lei Zh ao.Prediction and Application of Equipotential Charge. Beijing: China Power Pr ess. pp. 156-187,1998  Yonghong Hu,Sihui He The Genera l Judg m e nt. B e ijing: Science Press pp. 186-200,.2000  Xuerui Tan. The Analysis of Gre y  Correl ation A  N e w Multi Factor Method of Stat. Stat. Research pp. 40-43,1995 010   Fu Li. The Th eory and Application of Grey Sy ste m  Beijing Technology and Literature Pr ess pp. 201-216, 1992  Hongde Yang, ling Li Successful Ca se in CRM.  pp. 101-126,.2002   
118 
118 
118 


ral order on these groups We denote this ordering as  2 3    where the index of corresponds to the step at which the edges of the group are deleted Instead of weuse to characterize the graph decomposition Our main goal now is to speed up the decomposition algorithm from 2 using t h e f o llo wing simple observation deletion of any edge    from its tree of color     where is a parent of in a DFS ordering of the tree of color    always forms two trees such that one of them is rooted at and all nodes in that tree are descendants of  We slightly modify the graph decomposition algorithm from   T he edg e s t o b e d ele t e d a t t he ne xt s tep are identi ed at the end of the preceding step and marked for deletion At the rst step  is marked for deletion and no other action is performed Each iterative step in consists of removing the marked edges of some color and identifying and marking the edges crossing the cuts of the opposite color  that appear after removing the marked edges We also note that once the original graph has split into several connected subgraphs the decomposition proceeds independently on each subgraph and the problem of nding the edges to be deleted at the subsequent step can be viewed as several independent subproblems each on a distinct connected subgraph Consider the graph and its two edge disjoint spanning trees and  rooted at vertices and  respectively Let    be the depthrst search traversal of starting at and using only edges of color where is either red or black We assign each vertex of two DFS order numbers one from     and another one from     New edges are never added to the trees so the numbers never change For any edge of color  it is always possible to establish the parent-child relationship of its endpoints by looking at their DFS numbers for color  Whenever an edge is mentioned in this text as a vertex pair the rst vertex is always the parent of the second vertex in       When an edge    of color is deleted from a tree rooted at some and spanning a connected subgraph  two trees emerge rooted at and rooted at  Only the vertices of are descendants of in DFS\(c The ancestor/descendant relationship can be established in the    tree by looking at the discovery and nish times     and     respectively of the vertices Lemma 4.1 An edge    of color crosses the cut      induced by the deletion of the edge    of color if and only if one of its endpoints is a descendant of and the other one is not i.e exactly one of its endpoints discovery times is in       Proof If   6 and   then and so clearly crosses the cut A symmetric argument applies if   and   6  If   6 and   6  neither nor are in  so both endpoints of are in and does not cross the cut If   and    both endpoints of are in and does not cross the cut 2 From Lemma 4.1 it follows that if we associate an interval      with every edge of color theintervals corresponding to the edges crossing the cut have exactly one endpoint in  We identify such intervals using a segment tree data structure enhanced with two lists at each internal node one sorted by the start time of the intervals stored at the node and one sorted by their nish time A segment tree 1 is a b alan ced bina ry s ear ch t r ee th at s t o r es a s et of intervals with endpoints from a nite set of abscissae intervals corresponding to edges of color forexample Each of its nodes has an interval   associated with it and stores a list of input intervals intersecting    Binary search in a segment tree allows to report the intervals containing a query point In our case the endpoints of the intervals are integer numbers so an interval containing a point  for any 0 1  contains the point as well First we nd the intervals with one endpoint before   and the other endpoint in by querying for intervals containing the point    Second we nd the intervals with one endpoint in and the other endpoint after   by querying for intervals containing the point    To ensure that each returned interval has an endpoint in we augment the standard segment tree by storing two sorted lists at each node instead of just one list With each node  we store a list    of intervals that intersect   that is sorted by the nish time of the intervals in non-decreasing order similarly the list  stores the same intervals sorted by their starting time in non-increasing order We give both queries above an additional parameter   for the rst one and   for the second one The rst query only looks at the lists  and reports the intervals that have their right endpoint no greater than    The second query only looks at the lists  and reports the intervals that have their starting point no earlier than    Thus this data structure allows us to return intervals with exactly one endpoint in  Each query with an edge interval  takes log   time where is the number of intervals crossing edges reported To avoid reporting an interval more than once the interval is deleted from the segment tree including the sorted lists associated with the nodes that store it when it is returned by a query This can be easily done in log  time Having two segment trees one for the red intervals        Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


of the black edges and the another one for the black intervals        of the red edges allows to ef ciently identify edges of the cuts at each step of the decomposition Lemma 4.2 The decomposition of can be done in  log  time Theorem 4.3 Given a graph with vertices and edges deciding whether is a Laman graph or not can be done in    log  time where   is the time to extract two edge disjoint spanning trees from or decide no such trees exist Proof We can check that 2 3 in   time Finding two edge disjoint spanning trees or deciding no such trees exist takes   time The best known algorithm so far gives    3 2  log  time 3 The decomposition takes  log  time  log  for the segment trees  log  to answer all queries and   to check if has any edges left at the end of the decomposition 2 5 The reconstruction algorithm The order in which edges are deleted from during the decomposition determines the structure of the corresponding red-black hierarchy sogiven onecanunambiguously construct in top-down fashion according to the rules from 2  T he v e rtices o f correspond to subtrees of and  and there is a vertex in for each distinct sub-tree of or  that appeared during the decomposition of  In the original approach to construct the th level of  one has to know the spanning sub-trees at step 2 of the decomposition and to gure out what trees appear after removal of edges at the beginning of step  It takes   time to nd the emerging trees We consider the decomposition process in reverse order i.e start from red and black disjoint trees and add edges to them until two spanning trees are formed and take advantage of the fact that it is faster to union the disjoint sets into larger sets than to partition the trees into disjoint sub-trees As a result the proposed bottomup construction method is faster and produces the same graph as the top-down approach The last group of  2 3  contains edges of some color deleted at the very last step of the decomposition Each endpoint of edges of corresponds to a subtree of of color spanning only the vertex  A leaf node    is added to the th level of foreachsuchvertex  Only one leaf vertex is created for the endpoint shared by multiple edges from  For every edge    of a corresponding cross edge         is added to For p op o p o Figure 3 after considering edges of 8        m o p m p op mo p o Figure 4 after considering edges of 8 and 7           every leaf vertex   of  its parent should be at level 1 of  corresponding to a subtree in that is of color and spans only the vertex Suchparentvertex      is added to level 1 of along with a tree edge connecting and   we call this the parent creation rule  The vertices of connected by a cross edge have the same grandparent For every cross edge tree formed at the thlevel,avertex is added to level 2 of aswellasatree edge connecting and forevery Wehave completed level of as well as added some elements to the two upper levels See Figure 3 and Figure 4 for an illustration At the th iterative step for each cross edge    of of color two vertices and on the th level of are identi ed They correspond to trees in of color that contained and respectively at the thstepof the decomposition If for some endpoint of an edge from does not exist on the th level of anew vertex should be created at the th level and a parent for it should be added following the parent creation rule Then the cross edge corresponding to    is added to between and  After all edges of are considered all cross-edges of the th level of are in place For each cross edge tree formed at the th level of Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


 a node is added to level 2 of  That grandparent node becomes a parent of the parents of the vertices of spanned by the cross-edge tree  At this time the th level of is complete and levels 1 and 2 of are partially constructed Repeating these steps for all  2  yields the RBH  Lemma 5.1 Given two edge-disjoint spanning trees for  a red-black hierarchy for ifitexists,canbeconstructed in  log  time Proof Obtaining for takes  log  time Lemma 4.3 The time spent on reconstructing one level is proportional to the number of cross edges at that level The total number of cross edges is   Weuse a standard UNION-FIND data structure for maintaining the vertices of that the vertices of correspond to at each step notice that the actual trees of color or  dened by those vertices in are not needed to construct  This allows to complete the reconstruction phase in  log  time so the total time for constructing the RBH is  log   2 References  Se r g e y Be re g  F a s t e r a l g o r ith m s fo r r ig id ity in th e p la n e  http://arxiv.org/abs/0711.2835  Se r g e y Be re g  Ce rtify i n g a n d c o n stru c tin g m in im a lly rigid graphs in the plane In SCG 05 Proceedings of the twentyrst annual symposium on Computational geometry  pages 73 80 2005 3 H arol d G abo w and H erbert W e st erman n F o rest s frames and games algorithms for matroid sums and applications Algorithmica  7\(1\65 497 1992 4 R ut h H aa s Au dre y L ee Il ean a S t r ei nu a n d L oui s Theran Characterizing sparse graphs by map decompositions Journal of Combinatorial Mathematics and Combinatorial Computing JCMCC  62 2007 5 R ut h H aas  D a v id Or d e n Gu nt er Rot e  F r a nci s co S a nt o s  Brigitte Servatius Herman Servatius Diane Souvaine Ileana Streinu and Walter Whiteley Planar minimally rigid graphs and pseudo-triangulations Computational Geometry Theory and Applications 31:31 61 2005 6 D on al d J a c ob s a n d Br u c e H en dr i c kso n  A n a l gor i t h m for two dimensional rigidity percolation The pebble game Journal on Computational Physics  137\(2\46 365 2007 7 Aud r e y L e e a nd I l ea na S t r e in u P e bb l e game al gor i t h ms and sparse graphs Discrete Mathematics  308\(8\:1425 1437 2008 8 A ud r e y L ee  I le ana S t r ei nu  a nd L o u i s T her a n  Fi nd i n g and maintaining rigid components In Proceedings of the 17th Canadian Conference on Computational Geometry CCCG 05  pages 219 222 2005 9 L  L o v a s z a nd Y  Y e mi ni  O n g e n er i c r i gi di t y i n the plane SIAM J Algebraic and Discrete Methods  3\(1\:91 98 1982  F r an co P  P r eparat a a n d M i chae l I an S h amos  Computational Geometry An Introduction Springer-Verlag 1985  A Recsk i  A ne twor k t heo r y a ppr o ach t o t h e r i g i d i t y of scheletal structures II Laman s theorem and topological formulae Discrete Applied Math 8:63 68 1984  I l ea na St r e i n u  P s eud o t r i an gul at i o n s  r ig id i t y a n d motion planning Discrete  Computational Geometry  34:587 635 2005  I l ea na St r e i n u a n d L o u i s T her a n  S p ar se hyp er graphs and pebble game algorithms Available at http://arxiv.org/abs/math/0703921  I l ea na S t r e i n u a nd Lo ui s T he r a n Sp ar sit y c er ti f y in g graph decompositions http://arxiv.org/abs/0704.0002 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


Appendix A sample construction of the decomposition characterizing graph As an example we consider the decomposition of the graph from Figure 5 The red tree drawn with thick lines is rooted at the vertex and the blacktreeisrootedatthevertex  All vertices of except the top one are marked with the lists of vertices of their corresponding subtrees The edges of deleted at the step are shown with dashed lines Figure 20 presents the resulting graph characterizing the decomposition of   de k l g f n o q m p e add a b c j i h Figure 5 Original example graph  de k l g f n o q m p e add a b c j i h Figure 6 at the end of step 1  no changes in the original graph Figure 7 at the end of step 1  de k l g f n o q m  p e add  a b c j i h Figure 8 at the end of step 2  c d a i h b l g e f p o n m q k Figure 9 at the end of step 2  de k l g f n o q m  p  a b c j i h Figure 10 at the end of step 3  c d a i h b l g e f p o n m q k h g f n m o p b a i l q k j cd e Figure 11 at the end of step 3  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


 c j i h de k l g f n o q m    p  a b  Figure 12 at the end of step 4  e  q k a i j b g c d c d lf h a i h b l g e f p o n m q k h g f n m o p p o n m b a i l q k j cd e Figure 13 at the end of step 4  c j i h de k l g f n o q m    p  a b  Figure 14 at the end of step 5  e  q k a i j b h g c d c d lf a i h b l g e f p o n m q k h g f n m o p p o n m m o p b a i l q k j cd n g h k q l a bij f e Figure 15 at the end of step 5  a b c j i h de k l g f n o q m  p   Figure 16 at the end of step 6  e  q k a i j b h g c d c d a q k m n j lf i a i h b l g e f p o n m q k h g f n m o p p o p o n m m o p b a i l q k j cd n g h k q l a bij f e Figure 17 at the end of step 6  a b c j i h de k l g f n o q m   p Figure 18 at the end of step 7  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


e  q k a i j b h g c d c d a q k m n j lf i a i h b l g e f p o n m q k h g f n m o p p o p p o n m m o p b a i l q k j cd n g h k q l mo a bij f e Figure 19 at the end of step 7  e q k a i j b h g c d c d a q k m n j lf i a i h b l g e f p o n m q k h g f n m o p p o p p o n m m o p op b a i l q k j cd n g h k q l mo a bij f e Figure 20 at the end of step 8 that completes decomposition of  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Dr Mohammad Mojarradi is an expert in developing mixedsignallmixed-voltage electronic circuits for drive and control of actuators power supplies sensors and micro-machined electromechanical interface applications He manages the development of the electronic circuits for the thermal cycle resistant electronics task for Mars Science Laboratory at JPL and leads a research consortium of universities developing electronics for extreme environments He received his Ph.D from UCLA in 1986 has twenty-five patents eighty publications and is a senior member of IEEE Prior to joining JPL he was an Associate Professor at Washington State University and the Manager of the mixed-voltagelspecialty integrated circuit group at the Xerox Microelectronics Center El Segundo CA Patrick McCluskey is an Associate Professor of Mechanical Engineering at the University of Maryland College Park where he is associated with the CALCE Electronic Products and Systems Center He has published extensively in the area of packaging and reliability Of electronics and microsystems for high power and extreme temperature environments including two books and numerous book chapters He has also served as general or technical chairman for numerous conferences in these research areas Dr McCluskey is an associate editor of the IEEE Transactions on Components and Packaging Technologies He received his Ph.D in Materials Science and Engineeringfrom Lehigh University Benjamin J Blalock received his B.S degree in electrical engineering from The University of Tennessee Knoxville in 1991 and the M.S and Ph.D degrees also in electrical engineering from the Georgia Institute of Technology Atlanta in 1993 and 1996 respectively He is currently an Associate Professor in the Department Of Electrical Engineering and Computer Science at The University of Tennessee where he directs the Integrated Circuits and Systems Laboratory ICASL His research focus there includes analog integrated circuit design for extreme environments both wide temperature and radiation on CMOS and SiGe BiCMOS multi-gate transistors and circuits on SOI analog circuit techniques for sub 100-nm CMOS mixed-signallmixed-voltage circuit design for systems-on-a-chip and biomicroelectronics Dr Blalock has co-authored over 80 refereed papers He has also worked as an analog IC design consultant Dr Blalock is a senior member of the IEEE Raymond J Garbos is VP and Chief Engineer of Aura Instrumentation Inc He is responsible for the development of advanced avionics concepts architectures and technologies for aerospace applications He has over thirty five years of circuit logic and system architecture design experience He was an Engineering Fellow for Sanders Associates 1984-8 5 Lockheed Martin 1986 2000 and BAE Systems 2001-06 He was the RL V Avionic IPT lead for Lockheed Martin and has participated in many Advanced Space Avionics Studies supporting MSFC He received BSEEIMSEM degrees from Northeastern University in 196811971 and a MAT degree from Rivier College in 2001 Leora Peltz is a scientist at Boeing Phantom Works responsible for the development and application of sensors and advanced avionics and insertion   into flight applications She has experience in evaluation and modeling of circuits and materials in extreme environments and the real-time operation of distributed architectures Leora received a PhD degree from Case Western Reserve University in 2003 Dr Michael Alles is a Research Associate Professor in the Electrical Engineering Department and the Program Manager for Commercial Systems with Vanderbilt University's Institute for Space and Defense Electronics ISDE where he works in the area of radiation effects in microelectronics He spent 2 years as a Business Unit Director for Silvaco International 10 years with Ibis Technology Corporation in product development and program management and 1 year with Harris Semiconductor as a design engineer Dr Alles has a strong background in semiconductor technology including manufacturing and metrology computer-aided design tools for semiconductor fabrication processes devices and integrated circuit design and expertise in modeling and simulation of radiation effects in semiconductor devices and circuits Dr Alles has served on the SIA ITRS starting materials working group since 1999 serving as chairman of the SOI materials group for the 2001 revision of ITRS and has been a reviewer for Transactions on Nuclear Science several times He has over 40 technicalltrade publications and 2 patents Dr Alles received his Ph.D in Electrical Engineering 12192 MS in Electrical Engineering 8190 11 


and his B.E in Electrical Engineering with a Double Major in Physics 5187 allfrom Vanderbilt University Dr Alles present research focus is in the application of advanced and emerging semiconductor technologies in radiation environments R Wayne Johnson is a Samuel Ginn Distinguished Professor of Electrical Engineering at Auburn University and Director of the Laboratory for Electronics Assembly and Packaging LEAP At Auburn he has established teaching and research laboratories for advanced packaging and electronics manufacturing His research efforts are focused on the materials processing and reliability aspects of electronics manufacturing Current projects include lead free electronics assembly mixed leadfree and Sn/Pb electronics assembly wafer level packaging flip chip assembly assembly of ultra thin Si die 30,um and electronics packagingfor extreme environments 2300C to 4850C Wayne was the 1991 President of the International Society for Hybrid Microelectronics ISHM He received the 1993 John A Wagnon Jr Technical Achievement Award from ISHM was named a Fellow of the Society in 1994 and received the Daniel C Hughes Memorial Award in 1997 He is a Fellow of the Institute of Electrical and Electronics Engineers IEEE and a member of the Surface Mount Technology Association SMTA and IPC Association Connecting Electronics Industries He is currently a member of the IEEE Components Packaging and Manufacturing Technology CPMT Society Board of Governors and Vice President of Publications He is also Editor-in-Chief of the IEEE Transactions on Electronics Packaging Manufacturing He has published 58 journal papers 140 conference papers 6 book chapters and co-edited one book on electronics packaging and electronics manufacturing He has also presented a number of invited talks Wayne holds one U.S patent Wayne received the B.E and MSc degrees in 1979 and 1982 from Vanderbilt University Nashville TN and the Ph.D degree in 1987 from Auburn University Auburn AL all in electrical engineering 12 


11 Xiao Yang L Haizhon S Choi 2004 Protection and Guarantee for Video and Voice Traffic in IEEE 802.1 le Wireless LANs INFOCOM 2004 Twenty-third Annual Joint Conference of the IEEE Computer and Communication Societies Volume 3 Issue 7-11 21522162 12 W Spearman J Martin A Distributed Adaptive Algorithm for QoS in 802.1 le Wireless Networks Proceedings of the 2007 International Symposium on Performance Evaluation of Computer and Telecommunication Systems SPECTS'07 San Diego CA July 2007 pp 379-386 13 Lim L.W Malik R Tan P.Y Apichaichalermwongse C Ando K Harada Y Panasonic Singapore Labs A QoS Scheduler for IEEE 802.1l e WLANs Consumer Communications and Networking Conference 2004 pp 199-204 14 V Vleeschauwer J Janssen G Petit and F Poppe Quality bounds for packetized voice transport Alcatel Tech Rep 1st Quarter 2000 15 ITU Series H Audiovisual and Multimedia Systems Infrastructure of audiovisual services Coding of moving video H.264 03/2005 International Telecommunication Union 12 BIOGRAPHY cooperative signal received his B.S Engineering from respectively processing and sensor networks He M.S and Ph.D degree in Electrical UCLA in 1993 1995 and 2000 Will Spearman is a Master's Candidate at Clemson University's School of Computing His work focuses on QoS in 802.cle and wireless networks His background includes a B.S in Psychology with a minor focus in Computer Science He currently is employed at Network Appliance Inc Dr Jim Martin is an Assistant Professor in the School of Computing at Clemson University His research interests include broadband access autonomic computing Internet protocols and network performance analysis He has received funding from NASA the Department of Justice BMW IBM and Cisco Dr Martin received his Ph.D from North Carolina State University Prior to joining Clemson Dr Martin was a consultant for Gartner and prior to that a software engineer for IBM Jay Gao joined the Jet Propulsion Laboratory in 2001 and is currently a senior research staff in the Communications Networks Group in the Telecommunication Research and Architecture section His research is primarily focused on space-based wireless communications and networking with emphasis on applications for the Mars Network He is currently conducting research for developing quality-of-service QoS protocols for the envisioned Interplanetary Network IPN and study optimization and protocols for deep space Ka-band communications He also supports requirements definition and interface design activities for the Department of Defense's Transformational Communications MilSatcom project and system engineering effort for NASA's Exploration System and Mission Directorate ESMD supporting the Constellation Program for return of human to the Moon and Mars Other research interests include optical-based sensorweb discrete event simulation of distributed communication/sensor systems energy efficient routing and self-organization algorithm for 13 


  14  Figure 5:  Site B1 Terrain horizon ma sk with 1 degree azimuth spacing  Figure 6:  Site B1 Terrain horizon mask with 1 de gree azimuth spacing, in e quatorial coordinates 


  15  Figure 7: Lunar South Pole Solar Illumination Yearly Average  Figure 8:  Lunar South Pole DTE Visibility Yearly Average 


  16  Figure 9: Lunar North Pole Sola r Illumination Yearly Average  Figure 10:  Lunar North Pole D TE Visibility Yearly Average 


  17  Figure 11: Site A1 Elevation Topography  Figure 12: Site A1 Yearly Average Solar Illumination and DTE visibility, Medium Resolution 


  18   Figure 13:  Site LB Te rrain Horizon Mask  Figure 14:  Theory and Computed values of Average Yearly Solar Illumination 


  19  Figure 15:  Theory and Computed values of Average Yearly DTE Communication  Figure 16:  Heliostat Mirror Design to Eliminate Cable Wrap 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



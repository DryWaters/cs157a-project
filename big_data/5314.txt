GUI Software Fault Localization Using N gram Analysis   Zhongxing Yu, Hai Hu, Chenggang Bai, Kai-Yuan Cai 1  Department of Automatic Control Beijing University of Aeronautics and Astronautics Beijing, China yuzhongxing88@gmail.com W. Eric Wong Department of Computer Science University of Texas at Dallas Richardson, TX ewong@utdallas.edu   Abstract Graphical User Interfaces \(GUIs\ have become an important and accepted way of interacting with today's software. Fault localization is considered to be one of the most 
expensive program debugging activities. This paper presents a fault localization technique designed for GUI software. Unlike traditional software, GUI test cases usually are event sequences and each individual event has a unique corresponding event handler. We apply data mining techniques to the event sequences and their output data in terms of failure detections collected in the testing phase to rank the fault proneness of the event handlers for fault localization. Our method applies N gram analysis to rank the event handlers of GUI programs and data collected from case studies on four real life GUI programs demonstrate the effectiveness of the proposed technique Keywords-GUIs; fault localization; event sequences; event 
handler;  N-gram analysis I   I NTRODUCTION  Graphical User Interfaces \(GUIs\ provide people with a convenient and straightforward way of operating software systems by displaying rich information on the screen and enables easier interaction between human and computer systems. Thus GUIs are widely used in todayês software applications and act as an essential part in modern software applications. GUI software applications refer to the software applications that communicate with users through GUIs They have been the majority of modern software applications. GUIs bring great convenience to users However, they also make the GUI software applications 
much more complicated and fault prone. As the result debugging GUI software has been a very important issue in software quality assurance 1  Fault localization is considered to be one of the most expensive program debugging activities, and therefore, a large number of fault localization techniques have been proposed over the recent years [1  2  3 4 12  U s ua ll y  fa u l t  localization utilizes test cases, i.e., sets of inputs with known expected outputs, and information collected during the execution of the test cases for later analysis. Such information may include statement coverage and exact execution sequence. Then techniques are implemented to  
  1  Cai was supported by the National Natural Science Foundation of China Grant Number 60973006\ and the Beijing Natural Science Foundation Grant Number 4112033  analyze such information and rank the statements of the subject program by level of suspicion. The result can help programmer to find the fault and finally fix it Although there has been a surge in the development of fault localization techniques, but to the best of our knowledge, this is the first work that proposes a fault localization technique especially designed for GUI software Unlike traditional software, test cases for testing GUI programs are event sequences instead of individual input data or files [5   F o r  ea ch ev en t th er e m u st h a v e a p i e c e o f  
source code which addresses the event, we call it the eventês corresponding event handler [6  B y r a n k in g th ese ev en t  handlers by their level of suspicion accounting for faults encountered during the testing, we can help programmer pinpoint the failure causing event handlers in the source code Due to the huge volume of GUI event sequences, usually infinity, we apply data mining techniques on the test data to extract the most relevant sequences From each test case, we generate N grams, i.e subsequences of length N From these, we choose N grams that appear more than a certain number of times in the event sequence of failing test case. For these 
N grams, we calculate the confidence Öthe conditional probability that a test case fails given that the N gram appears in that test caseês event sequence. We sort the N grams in descending order of confidence and report the events of the program in the order of their first occurrence in the sorted list. We have examined the proposed technique on the widely studied TerpOffice 3.0 Suite developed by the University of Maryland students [7   including TerpWord  TerpSpreadSheet  TerpPresent and TerpPaint Data indicate that the proposed technique can indeed help programmer to check a few event handlers to 
detect most of the faults This paper is organized as follows. In Section II, we discuss the related terminologies and ideas. In Section III, we present the N gram algorithm for GUI software fault localization. In Section IV, we discuss the results of applying our algorithm on TerpOffice 3.0 Suite. In Section V, we discuss other relevant research. Finally, in Section VI, we present the conclusions from this study and discuss future directions of research  
2011 IEEE 13th International Symposium on High-Assurance Systems Engineering 1530-2059/11 $26.00 © 2011 IEEE DOI 10.1109/HASE.2011.29 325 


II  B ACKGROUND  In this section, we discuss the concepts, ideas and definitions related to our method of solving the problem A  Representation of the GUI and Its Operations 1  GUI Components Objects of a GUI include some windows and all kinds of GUI widgets \(e.g., button, menu in the windows [5 n  a  b r o a d de finiti o n t h e wind ow it s e l f  can also be viewed as a kind of GUI widget. Each window or GUI widget has a fixed set of properties, such as the size and position of the GUI widget. At any specific point in time, the GUI can be described in terms of the specific GUI widgets that it contains and the values of their properties  2  Event The basic inputs for GUI software are events When a GUI application is running, usersê operations trigger events and the application responses to these events. Since events may be performed on different types of GUI widgets in different contexts, yielding different behavior, they are parameterized with objects and property values. Commonly we can use a 3-tuple <a, o, v> to represent event where a is the action of the event \(e.g., click the mouse\, o stands for the GUI widget the event deals with \(e.g., a button\ and v is the set of parameters of this action [6   3  GUI Test Cases Unlike traditional software, GUI test cases usually are defined as event sequences [5  A f o r m a l  representation of a GUI test case is a Legal Event Sequence 002 003 002 004 002 005  consisting of n events. çLegalé refers to that for 006=1,2,É,\007ä1,\002 010\011\003 can be immediately accepted by GUI software and executed after the execution of 002 010 Cai et al. extend this definition by defining GUI test cases in the way of a hierarchical language [1  P e o p l e  c a n f i r s t ge ne ra t e  some simple test cases as low order test cases. Then, more test cases can be generated by combining these low order test cases 4  EFG and EIG Due to the hierarchical relationship between GUI widgets, some events can only be accepted by the GUI software after the execution of some other events. If event 002 012 can be immediately accepted and executed after the execution of event 002 010 we say 002 012 follows 002 010 and  002 010  002 012 s called a Event Interaction. In model-based GUI testing Event-Flow Graph \(EFG\ is used to model all possible Event Interactions of GUI software E F G i s a di re c t e d gr a p h that contains nodes \(that represent events\nd edges \(that represent a relationship between events  Event-Interaction Graph \(EIG\ is an improvement for EFG [8  E I G n o d e s   on t h e  o t he r ha nd   do n o t r e pre s e n t  events to open or close menus, or open windows. Because these events are only structural events and usually do not interact with the underlying software. The result is a more compact, and hence more efficient, GUI model Fig. 1 presents a GUI that consists of four events, Undo Redo, Select, and Edit. Fig. 1\(b\ shows the GUIês EFG; the four nodes represent the four events; the edges represent the follows relationships. For example, in this EFG, the event Undo follows Edit, represented by a directed edge from the node labeled Edit to Undo. Fig. 1\(c\ shows the GUIês EIG Since Edit event is a menu-open event and we only use it to get the availability of the three other events so the EIG model does not contain it. Following the deletion of event Edit, each edge 002 013 Edit\ in the original EFG was replaced with edge 002 013  002 014 for each occurrence of edge \(Edit e 015    a\                            \(b\                   \(c Figure 1  a\ a simple GUI, \(b\ its EFG, and \(c\ts EIG  Every path in GUI softwareês graph model may be a test case, so we can use specific graph traversal algorithms to generate specific test cases. The test cases we use in this paper are generated by çwalkingé the EIG graph for smoke testing [8  Bec a us e  E I G n o d e s  d o  no t r e p r es ent events to open or close menus, or open windows, the sequences obtained from the EIG may not be executable. To yield an executable test case, other events needed to reach the EIG events should be automatically generated and inserted [8   B  Event Handler When one event executes on the software, all the pieces of source code that is possible to be executed are called the eventês corresponding event handler [6  Th e ev en t h a n d l e r  usually includes message response function and source code called by this function. Each event at most has an event handler. In addition, an event handler may response to several events. For example, pressing the shortcut key éCtrl+Sé has the same effect as clicking the çSave button on the toolbar in Micros oft Word, therefore these two events have the same event handler. Fig. 2 gives an example of event handler, the figure lists two eventsê event handler out of five h 003 and h 004 which respectively stand for the event handler for the event of clicking the çAbouté button and typing in through the textbox   Figure  2.  Example of Event Handler C  N-gram For a GUI application, let 016={ \017 003 017 004 017 005  be the test set with n test cases in it. Each test case 017 010  020 010 021 010  is composed of the input 020 010 i.e., a set of events and 021 010 the expected output of 020 010 When input 020 010  is executed, it produces the actual output 022 010 If 022 010 021 010 then we regard 017 010  as a passing test case, and if 022 010 023\021 010 then 017 010  is regarded as a failing test case. Let 024 010  002 003 002 004 002 025  be the event void CalcDlg::OnEditChange   m_Input=StrToDouble\(Edit.Text  h 004  void  CalcDlg::OnAbout  dlg=new AboutDlg Dlg s how Modal  Void AboutDlg:: AboutDlg   h 003  Und o  Select Re do  Edi t  Und o Select Re do 
326 


sequence corresponding to test case 017 010 then the total event sequences of the entire test set is 024=<\024 003 024 004 024 005  We define two sets based on the outcome of the test cases passing event sequences which is 024 026  024 010  017 010 is a passing test case} and failing event sequences which is 024 027  024 010  017 010 is a failing test case Given an ordered list, an N gram is any sub-list of N consecutive elements in the list. The elements of the N gram must be in the same order as they were in the original list and they must be consecutive. Given an event sequence 024 010  an N gram 030 031 032 033,\034 is a contiguous subsequence  002 034 002 034\011\003  002 033\011\034\035\003 of length N starting at position \002 Taking the difference of \002 into account, the set of all N grams for 024 010 is G 031 032 033  036 030 031 032 033,\003 030 031 032 033,\004 030 031 032 033,\025\035\033\011\003 037  Deleting the duplicated N grams, then 030 031 ,\033  030 031  033 030 031  033 030 031  033 is the N grams corresponding to the total event sequences E  D  Association Rule Mining Association Rule Mining searches for interesting relationship among items in a given data set w h i c h  involves the following two procedures 1  Frequent Itemset Generation Search for sets of items occurring together frequently, called a Frequent Itemset whose frequency in the data set, called Support, exceeds a predefined threshold \(known as the Minimum Support For an N gram 030 031 032 033,\026 Support is the number of failing test case containing 030 031 032 033,\026   017  030 031 032 033,\026  024 012 030 031 032 033,\026 024 012 and \024 012 024 027  1 2  Association Rule Generation Look for association rules like A B among the elements of the frequent itemsets meaning that the appearance of A in a set implies the appearance of B in the same set. The conditional probability P\(B|A is called Confidence which must be greater than a predefined Minimum Confidence for a rule to be considered For an N gram 030 031 032 033,\026 Confidence is the conditional probability that the test case outcome is failure given that 030 031 032 033,\026 appears in the event sequence of that test case. That is 002  007/\0060\002\0073\002  030 031 032 033,\026   031 4 5 6 032 7,8 031 4 9:; \031 4 031   031 4 5 6 032 7,8 031 4  2  III  M ETHODOLOGY  In this section, we present our methodology for GUI software fault localization. As input we use the source code the test case types and the event sequences of all the test cases, and produce as output an ordered list of events, sorted in order of probability of their corresponding event handler containing the fault. We apply N gram analysis on these event sequences to generate all possible unique N grams for a given range of N For each N gram, we calculate its frequency in passing and failing event sequences. The set of N grams and their frequencies are analyzed using the association rule mining technique described above The execution of the faulty event handler may not always cause failure of the test case. There might be quite a number of test cases in which the faulty event handler was executed but it did not cause a failure. In most cases, the failure is dependent on the execution of other events. A specific event sequence of execution will cause the program to fail, and this event sequence will be very common in the failing event sequences but not so common in the passing event sequences Therefore we can find these subsequences that are most likely to contain the fault by analyzing the event sequences of passing and failing test cases A  General Approach In our research, we model the events as items and the event sequence corresponding to a test case as the transaction For example 024 010  002 003 002 004 002 025  is a transaction corresponding to the test case 017 010 We generate frequent itemsets from the transactions with the additional constraint that the items in an itemset must be consecutive in the original transaction. To do this, we generate 030 031 ,\033 and from them, we choose the ones with at least the Minimum  Support  Then, we try to discover association rules of the form 022 /@\006A\006\007B from these itemsets where the antecedent is an N gram and the consequent is failing. Therefore, the N grams that appear as antecedents in the association rules are most likely to have caused the failure of the test case. We sort these N grams in descending order of Confidence. After sorting the N grams, we convert the N grams back to event orders B  N-Gram Fault Localization Algorithm 1  Parameters There are two major parameters in the algorithm - the first one is MinSup the minimum support for selecting the N grams, and the second is C DEF the maximum value of N for generating the N grams. Taking a low value of minimum support will result in the inclusion of irrelevant N grams in consideration. The other way around giving a high value of minimum support may cause us to discard some very important N grams. So we should give MinSup a median value. For GUI software, the execution of event 002 003 may differ because of the execution of the previous event 002 004 If event sequence 002 004 002 003  can be executed without inserting other intermediate event \(e.g., event to open menu\, such differences can be detected by 2-grams otherwise such differences can be commonly detected by 3grams.Consequently we believe a choice of 3 for C DEF  should give good results in most cases. If we give C DEF  higher value, the algorithm will still be able to find the fault, but due to larger N grams, we will have to examine more event handlers to find the fault  2  Algorithm Pseudo-Code In this section, the complete algorithm is presented in Algorithm 1. Following is a description of the steps in the algorithm  a  Generate N-grams In this step, we first generate all possible N grams of lengths 1 to C DEF from the event sequences of all test cases and then delete the duplicate ones The generation of all C H grams from a set of event sequences for   a  given  length C H  is  carried  out  in  lines   2   to  5  of 
327 


A LGORITHM 1.GUI  F AULT L OCALIZATION USING NGRAM A NALYSIS  1: procedure LocalizeFaults  E  024 027  MinSup  2 NG 003 002  3:   for N 1 to C DEF do 4 NG 003 NG  001  GenerateNGrams  E  N  5:   end for 6 024 IJK 003 n  n  002  NG and n 1 7:   for all n  001\031  024 IJK do 8:      if n do not exist in any event sequence of L M  then 9 Remove n from NG and L NOP  10:      end if 11:   end for 12 C\030 003 003 n  n  002  NG and for all s  002 024 IJK  s Q n  13 NG 003 NG  C\030 003  14:   for all n 002  NG do 15:       if Support  n  MinSup then 16 Remove n from NG  17:       end if 18:   end for 19:   for all n  002  NG do 20 NF 003 024 025  024 025  002  024 027  and n  002  024 025  21 NT 003 024 025  024 025  002  E and n  002  024 025  22 n confidence \003 NF  NT  23:   end for 24 Sort NG in descending order of confidence  25 Report the event numbers in the order of their first  26 appearance in NG  27: end procedure  A LGORITHM 2  R S GRAM GENERATION  1: function GenerateNGrams  E  C H  2 G 003 002  3:  for 024 010  002  E do 4 G 003 G  001  030 031 032 033 T  5:  end for 6:  for all n 002 G do 7:    if n exists more than one time in G then 8 remove duplicate n from G  9:    end if 10:  end for 11:  return G  12: end function  Algorithm 2, the deletion of the duplicate C H grams is done in lines 6 to 10 of Algorithm 2 and the generation and combination of all the N grams C=1 \017' C DEF are done in lines 2 to 5 of Algorithm 1  b  Find Relevant Events From 1-gram, where the length of the sub-list is 1, we construct a set of relevant events, denoted by 024 IJK It contains only those events that have appeared at least in one of the failing event sequences in lines 6 to 11 of Algorithm 1 c  Eliminate Irrelevant N-grams From lines 12 to 13 of Algorithm 1, we discard those N grams that do not contain any event from the relevant event set 024 IJK  d  Find Frequent N-grams From lines 14 to 18 of Algorithm 1, we eliminate N grams with support less than the MinSup  e  Rank N-grams by Confidence For each surviving N gram, we compute its confidence. This is done in lines 19 to 23 of Algorithm 1. Then we rank the N grams in order of confidence in line 24 of Algorithm 1 f  Convert N-grams to Event Numbers and Rank Events We traverse the ordered list of N grams, and report the event numbers in the order of their first appearance in the list. This is done in line 25 to 26 of Algorithm 1 If there are multiple N grams with the same confidence then concerning the order for new events do not exist in N grams with a higher confidence\these N grams contain, the best case will be the ordering in which the more new faults do not exist in the event handler of higher ranking event\one event handler contains, the earlier position the corresponding event appears in the event group, we call this the best situation and the worst case will be the ordering in which the more new faults one event handler contains, the later position the corresponding event appears in the event group, we call this the worst situation if two event handler contain the same number of new faults we break tie by random selection. For example, if we finally have two 2grams 002 003   002 004 and 002 U   002 V of the same confidence 0.8 suppose 002 003  002 004  002 U  002 V are ç\007\002W \002X\002\007\017Yéand the event handler for 002 003  002 004  002 U  002 V individually contains 1,0,0,2 new faults then we get event order 002 V 002 003 002 004 002 U   or 002 V 002 003 002 U 002 004  under the best situation and  002 004 002 U 002 003  002 V or ç\002 U 002 004 002 003 002 V  under the worst situation   IV  C ASE S TUDY   For GUI software, if one technique can help programmers to detect most of the faults by checking a few event handlers, it should be viewed as an effective fault localization technique. Experiments on four GUI subject programs are conducted in this case study to demonstrate the effectiveness of the proposed N gram GUI software fault localization technique A  Subject programs To demonstrate the effectiveness of the proposed GUI software fault localization technique, four open-source applications, known as the TerpOffice suite, are examined in this case study. Table I depicts key metrics for TerpOffice  These applications are selected very carefully for a number of reasons. First, they are the subject programs that have been widely studied in many previous works on GUI testing Second, to adequately reflect the characteristic of GUI software, the selected applications are non-trivial, consisting of several GUI windows and widgets. Moreover, to avoid distinction between GUI code and underlying çbusiness logicé, GUI-intensive applications were selected, i.e., most of the source code implemented the GUI itself rather than the underlying çbusiness logic Around 200-300 faults were seeded in each application The   artificially   seeded   faults   are   similar  to  faults  that TABLE I T ERP O FFICE A PPLICATIONS  Subjects Windows  Widgets  LOC  Methods  Te rpPai nt  16  301  11803  1253  Te r pP re s en t  11  322  10847  2057  TerpSpreadSheet  9  176  5381  746  Te rp Wo rd  26  617  9917  1380   
328 


naturally occur in real programs due to mistakes made by developers [8  I n or de r t o  a v o i d f a ult  inte r a c tion, m u l t i p le  versions of each application \(mutants\ were created; each version was then seeded with ex actly one fault. Hence, a test case is regarded to be capable of detecting fault i if its output indicates a mismatch between version i \(i.e., the version that was created by seeding fault i\ and that of the original version. Some faulty versions were not used in our study because none of the test cases we obtained can reveal them Table II depicts summary of detailed information: for example, with regard to TerpPaint the total number of faulty versions is 263, there are 424 failing test cases out of the total 17977 test cases, and only 148 faulty versions can be revealed, so we only use the 148 faulty versions in our study TABLE II. T EST S UITE AND F AULT I NFORMATION OF THE S UBJECT P ROGRAMS   Subjects  total fault versions  total test cases  total failing test cases  detected fault versions  Te rpPai nt  263  17977  424  148  Te r pP re s en t  265  22770  32  139  TerpSpreadSheet  234  5272  1172  139  Te rp Wo rd  295  24288  772  224   B  Data collection According to the test cases downloaded from the online repository hosted by the University of Maryland [1 we extract the event sequence for every test case. Then we obtain the failing test cases and which fault can be revealed by which test case from the downloaded fault matrix Regarding to the faulty versions which can be revealed by the downloaded test cases, we download these faulty versions and artificially compare them with the original to confirm which event handlers contain these faults, eventually we manage to establish the one-to-one relationship between event handler and fault We should notice that currently our method makes use of the information of the whole test case suite. However, it is impractical to assume that large comprehensive test sets are always available. In the future, we should apply our method on random test case suite to further evaluate its feasibility C  Evaluation For all the experiments, we tentatively set Z\006\007  1,2   and compare the result of different MinSup Due to the limited length of test cases obtained and our analysis of the choice for C DEF  above, we set C DEF  The number of faulty versions revealed against the percentage of event handlers to be examined is charted for both the best case and worst case. Recall that the best case and worst case individually correspond to the best situation and worst situation  1  TerpPaint Fig. 3 and Fig. 4 respectively show the result of our method on TerpPaint in the best case and worst case under different parameter MinSup Different curves represent the result of different parameter MinSup for example, the curve MS-1 stands for the result of our method in condition of MinSup equals to 1.The horizontal axis represents the cumulative percentage of event handler to be examined and the vertical axis represents the total number of faulty versions for which bug can be detected by examining this percentage of event handler. If we set Z\006\007  1 we can detect 90% of total faults by examining only 21 event handlers out of the total 310 event handlers in the best case but in the worst case, we have to examine 199 event handlers to detect the same percentage of faults. Table III shows the number of event handler we have to examine to detect 90 of total faults in the best case and worst case under different parameter MinSup From this table we can draw a conclusion that to TerpPaint our method performs very well in both the best case and worst case if we set Z\006\007     Figure 3. Data from TerpPaint best case  Figure  4. Data from TerpPaint worst case TABLE III. N UMBER OF EVENT H ANDLER EXAMINED TO REV EAL 90 OF THE 148 FAULTY VERSIONS OF T ERP P AINT  Case  Z\006\007  1 2 3  4 5 6 7 8 Best 21  106  78  77  72  61  52  40  Wo r st  199  112  83  250  304  308  308  309  2  TerpSpreadSheet Fig. 5 and Fig. 6 respectively show the result of our method on TerpSpreadSheet in the best case 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS-3 MS-4 MS-5 MS 6 MS-7 MS-8 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS 1 MS 2 MS-3 MS-4 MS-5 MS-6 MS-7 MS-8 
329 


and worst case under different parameter MinSup The axes and curves have the same meaning as described above. If we set Z\006\007  1 we can detect 90% of total faults by examining only 16 event handlers out of the total 176 event handlers in the best case, but in the worst case, we have to examine 89 event handlers to detect the same percentage of faults. Table IV shows the same meaning statistics as Table III but to TerpSpreadSheet From this table we can come to a conclusion that to TerpSpreadSheet our method performs very well in both the best case and worst case except that Z\006\007$%& equals to 1 Attention should be paid that although we may have to check same number of event handler to detect 90% of total faults both in the best case and worst case under some parameter MinSup but the two figures clearly indicate that we have to check fewer event handlers to detect a lower percentage of total faults in the best case. We should also not neglect that besides MinSup  equals to 1, the other 7 curves overlap each other highly both in the best case and worst case  Figure 5. Data from TerpSpreadSheet best case  Figure 6. Data from TerpSpreadSheet worst case  3  TerpWord Fig. 7 and Fig. 8 respectively show the result of our method on TerpWord in the best case and worst case under different parameter MinSup If we set MinSup 1 we can detect 90% of total faults by examining only 7 event handlers out of the total 617 event handlers in the best case but in the worst case, we have to examine 150 event handlers to detect the same percentage of faults. Table V shows the same meaning statistics as Table III but to TerpWord  Judging from this table, we can conclude that to TerpWord  our method performs very well in both the best case and worst case except that MinSup equals to 1, 7 or 8.Simliarly although we may have to check roughly same number of event handler to detect 90% of total faults both in the best case and worst case under some parameter MinSup on the whole, our method performs better in the best case. Also besides MinSup equals to 1 or 8, the other 6 curves coincide with each other highly both in the best case and worst case TABLE IV. N UMBER OF EVENT H ANDLER EXAMINED TO REVEAL 90 OF THE 139 FAULTY VERSIONS OF T ERP S PREAD S HEET  Case  Z\006\007  1  2  3  4  5  6  7  8  Best 16  30  28  28  27  26  26  26  Wor st  89  32  29  29  28  27  27  27   Figure 7. Data from TerpWord best case  Figure 8. Data from TerpWord worst case 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS 3 MS-4 MS-5 MS-6 MS-7 MS-8 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS-3 MS-4 MS-5 MS-6 MS-7 MS-8 0 50 100 150 200 250 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS-3 MS-4 MS-5 MS-6 MS 7 MS-8 0 50 100 150 200 250 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS 3 MS-4 MS-5 MS-6 MS-7 MS-8 
330 


TABLE V. N UMBER OF EV ENT H ANDLER EX AMINED TO REVEAL 90 OF THE 224 FAULT VERSIONS OF T ERP W ORD  Case  Z\006\007  1 2  3  4  5  6  7 8 Best  7 40  40  40  42  41  57  57 Wo r st  150  40  40  40  43  42  617  617   4  TerpPresent Fig. 9 and Fig. 10 respectively show the result of our method on TerpPresent in the best case and worst case under different parameter MinSup If we set MinSup 1, we can detect 90% of total faults by examining only 2 event handlers \(these two event handlers contain most of the faults for TerpPresent in the best case, but in the worst case, we have to examine 34 event handlers to detect the same percentage of faults. Judging from Table VI, we can reach a decision that to TerpPresent our method performs very well in both the best case and worst case except that MinSup equals to 1 or 8. Equally, we should take care that the other 6 curves overlap each other highly besides MinSup equals to 1 or 2 in the best case, meanwhile another 5 curves coincide with each other highly besides MinSup  equals to 1, 2 or 8 in the worst case From the above results we can say that our proposed method performs well for GUI software. After applying N gram analysis to the event sequences of all test cases, we can rank the event whose corresponding event handler contains faults high. Making use of the result, programmer can check a few event handlers to detect a majority of the total faults At present we have no common rule for the value selection of MinSup but we can observe from this result that if we give MinSup a too low value, then we may take into consideration some irrelevant N grams, in this condition we will get a pretty good result in the best case yet a relatively poor result in the worst case. On the contrary, if the value of MinSup is too high, some very important N grams will be abandoned by us, this will cause our fault localization technique to lose efficacy. Considering all these factors, we can give MinSup a median value when putting our method into practice, in such a case, we can expect to get a good result both in the best case and worst case. Our preliminary result indicates 3 is a candidate value for MinSup  TABLE VI. N UMBER OF EVENT HANDLER EXAMIN ED TO REVEAL 90 OF THE 139 FAULT VERSIONS OF T ERP P RESENT  Case  Z\006\007  1  2  3  4  5  6  7  8 Best  2  8  3  3  3  3  3  3 Wo r st  34  9  4  4  4  4  4  322  D  Threats to Validity There may be several threats to the validity of this paper that include, but are not limited to, the following. The results of the study, presented above, should be interpreted keeping in mind the following threats to validity  Figure 9. Data from TerpPresent best case   Figure 10. Data from TerpPresent worst case  First of all, although we can sort the events in order of probability of their corresponding event handler containing the fault successfully using N gram analysis, but to certain event of GUI software, the eventês event handler contains much source code and consequently there exists many faults in the event handler. Until now we can only identify this kind of event handler has high level of suspicion but can not identify which specific part of it is doubtful. Maybe we can combine with various traditional software fault localization techniques to further analyze this kind of event handler Another important threat to validity concerns the complexity of a few event handlers. Some event handlers may contain nested function call. Although when establishing the one-to-one relationship between event handler and fault, we take one thing with another to the best of our ability, but owing to the complication of GUI software we canêt guarantee the fullness between event handler and fault, i.e., there may exist few event handlers that also contain certain fault but the relationship is neglected by us this also can to some degree affect the accuracy of our result But the relationship between event handler and fault we use in our study exists in no doubt, if we can find the complete 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS-3 MS-4 MS-5 MS-6 MS-7 MS-8 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 Number of faulty versions of event handler that need to be examined MS-1 MS-2 MS-3 MS-4 MS-5 MS-6 MS-7 MS-8 
331 


relationship between event handler and fault, we can anticipate a better numeral result As described above, our downloaded test cases are generated according to GUIês graph model EIG and are used for smoke testing, so the length of each test case is limited For one thing, our method makes use of the information of the whole test case suite, the experimental results may not be valid under random smaller test case suite, i.e., they may not be statistically repeatable. Moreover, restricted by the limited length of each test case, we canêt systemically observe the effect of C DEF by giving it a variation range although we have full reason a choice of 3 for it should be reasonable  V  R ELATED W ORKS  In this section, we briefly review previous work related to GUI software fault localization To the best of our knowledge, this is the first work that focuses on GUI software fault localization. However, many fault localization techniques based on the contrast between failing and passing cases run-time information has been applied to conventional software. In [1   2   the autho r s  make use of various heuristics and apply them to program traces to rank statements in order of their relative suspiciousness. In [3   s t a tis ti c a ll y b a s e d tec h niq u e s r e l y o n  the instrumentations and evaluations of predicates in programs to produce a ranking of suspicious predicates. In 12  t h e au t h o r s m o d e l s o f t w a r e  e x e c u t io n t r ac es as  networks and two centrality measures are adopted to calculate the suspiciousness of each statement. Especially in 4  the m e tho d  N gram analysis is used to analyze the exact execution sequence of the program to rank the executable statements of software by level of suspicion Our proposed GUI software fault localization technique based on some important achievements in GUI testing several researchers and practitioners have discussed the following concepts and definitions that are relevant to its specific parts. In [5  Mem o n  b u ild s up  a g ood b a s i s  f o r th e  future research of GUI software by giving a reasonable and effective GUI Representation, including the representation of GUIês state, GUI events, GUI test cases, etc., also, the definition of EFG is brought up  us ing  s p e c if ic gr a p h traversal algorithms, an improvement for EFG, namely EIG is employed to generate smoke test cases. In [6  the autho r s  give a relatively formal definition of event handler   VI  C ONCLUSIONS AND F UTURE W ORKS  This paper presents a GUI software fault localization technique by analyzing the event sequences of faulty versions to sort the events in order of probability of their corresponding event handler containing the fault. Our proposed technique has been evaluated with respect to four subject programs under different parameters and results clearly demonstrate its effectiveness if we take appropriate parameter GUI software fault localization is a totally new research issue, how to carry out effective fault localization in connection with GUI softwareês characteristic is a challenging problem. This research has presented several exciting opportunities for future work. To begin with, we can combine GUI software fault localization with traditional software fault localization, we can first successfully sort the event using our proposed method, then regarding the event whose corresponding event handler has much source code we can use traditional software fault localization technique to further analyze the event handler to get a more detailed result Moreover, a process of using certain random strategy to select some test cases from the whole test case suite and then applying our method on the relatively smaller test case suite can be implemented, the mean result of this repetitive process can be used to more comprehensively evaluate the feasibility of our proposed method. We are also working on applying our proposed technique on GUI applications with different kinds of characteristics to further demonstrate its effectiveness and commonality, such as programs with complex underlying business logic and a fairly simple GUI even other event-driven software \(EDS\, including Web applications, device drivers and embedded software  R EFERENCES  1  J. A. Jones and M. J. Harrold, çEmpirical evaluation of the Tarantula automatic fault-localization technique,é in Proc. 20th IEEE/ACM Int Conf. Automated Softw. Eng., Long Beach, CA, pp. 273Ö282, Nov 2005 2  W. E. Wong, V. Debroy, and B. Choi, çA family of code coveragebased heuristics for effective fault localization,é J. Syst. Softw., vol 83, no. 2, pp. 188Ö208, Feb. 2010 3  C. Liu, L. Fei, X. Yan, J. Han, and S. P. Midkiff, çStatistical debugging:a hypothesis testing-based approach,é IEEE Trans. Softw Eng., vol. 32 000\003 no. 10, pp. 831Ö848, Oct. 2006 4  S. Nessa, M. Abedin, W. E. Wong, L. Khan, Y. Qi, çSoftware fault location using N-gram analysis,é in Lecture Notes in Computer Science including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, \(2008\, vol. 5258 LNCS, pp 548-559 5  Atif M. Memon, A Comprehensive Framework for Testing Graphical User Interface, Ph.D. Dissertation, University of Pittsburgh, USA 2001 6  Zhao L and Cai K. Y., çE vent Handler-Based Coverage for GUI  Testing,é in Proceedings of the tenth International Conference on Quality Software \(QSIC 2010\, pp.326-331, 14-15 July 2010 7  Atif M. Memon,   http://www.cs.umd.edu/~atif/TerpOfficeWeb TerpOfficeV3.0/index.html 8  A. M. Memon and Q. Xie, çStudying the fault-detection effectiveness of GUI test cases for rapidly evolving software,é IEEE Trans. Softw Eng., vol. 31, no. 10, pp. 884Ö896, 2005 9  Han, J., Kamber, M.: Data Mining: Concepts and Techniques Morgan Kaufmann Publishers, San Francisco \(2001 10  Atif M Memon http://www.cs.umd.edu/~atif/Benchmarks UMD2005b.html 11  Cai K. Y., Zhao L., Hu H., and Jiang C.H.,çOn the Test Case Definition for GUI Testing,é in Proceedings of the Fifth International Conference on Quality Software \(QSIC 2005\, pp.19-28 Melbourne,Australia, September 2005 12  Zhu L.Z., Yin B.B., Cai K. Y., çSoftware Fault Localization Based On Centrality Measures,é compsacw, pp.37-42, 2011 IEEE 35th Annual Computer Software and Applications Conference Workshops, 2011    
332 


3 Check the user is registered or not, if YES then 4       whether the user is first time visitor, if YES then 5  return W\(Pi 6    else 7      calculate FW\(Pi 4 8 SET   W\(Pi Pi 9 return W\(Pi 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 197 spent on a page is inversely proportional to the degree of information useful to user. The formula to calculate the weight based on time spent on each page is given in \(6  TW?u? = T??? ????? ?? ? ???????/P??? S??? ????????U?T??? ????? ?? ? ???????/P S??? ????                  \(6  The Frequency and Time spent based page Weight FTPW spent on a particular page, as biasing factors. Frequency and Time spent based page Weight can be calculated by the formula given in \(7  W\(u u u 7  Where FW\(u which can be computed from \(4 u page based on time spent on a page which can be computed from equation \(6 u based on frequency and time spent both The Pseudo code of FPW algorithm given as follows            


   V. PERFORMANCE EVALUATIONS The performance of the proposed approach in terms of various parameters is discussed in this section A.  Data Set We have evaluated the performance of proposed algorithms by using the synthetic data set for different users to calculate the weight of each web page. Consider the structure of a web site consisting of four web pages namely A, B, C and D and their respective interconnection shown by direct edges as shown below in Figure 1       Figure 1: Web Site Structure The following factors are considered for performance evaluation Outbound links which shows the out degree of nodes for the graph of Figure1 Page Rank \(PR which can be calculated on the basis of the equation \(3 Number of visit shows the visiting frequency of each web page by user, it can be decided on the basis data received from web log Page Size defines the size of page on the basis of information content of the web page, which can be measured in bytes Time spent describes the resumption of a particular web page by user in seconds  The above parameters used in proposed experimental set up for the Web Path Traversal, by considering the graph mentioned in Figure1 B. Evaluation Method The attributes considering for the training data set for each user of a web site is represented in terms of time spent on each page and frequency. From these data sets we are 


calculating the weight for each web page for respective web site. The proposed approach uses Visiting Frequency and Time Spent on a Web page as two parameters to measure the weight of each web page To estimate the performance of the proposed two algorithms i.e. FPW and FTPW, discussed in section IV based on the above parameters involved in estimation C. Experimental Results The performance of the proposed approach can be evaluated by comparing the performance of FPW and FTPW algorithms which differ in number of parameters considered for experimentation. The comparison is made by taking the attribute like Visiting Frequency in FPW, and further Visiting Frequency and Time spent on a web page are clubbed together in FTPW as another attribute. The experimental setup uses five users and weights are plotted against various parameters Figure 2 shows the plot of Visiting Frequency v/s Weight of a web page              Figure 2: Plot between frequency and weight Algorithm: FTPW Input: Web traversal path database Output: Weight for each page 1 Calculate PageRank for each page \(PRi 3 2 Initially Set W\(Pi 3 Check the user is registered or not, if YES then 4       whether the user is first time visitor, if YES then 5  return W\(Pi 6    else 7      calculate FW\(Pi 4 


8            calculate TW\(Pi 6 9   SET   W\(Pi Pi Pi 10   return W\(Pi A C B    D 0 0.05 0.1 0.15 0.2 0 5 10 15 20 w ei gh t Visiting Frequency User1 User2 User3 user4 User5 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 198  Using the weights calculated in Figure the higher weight for more frequently visited information in FPW algorithm the different the scenario described in Figure 1 for all th plotted in Figure 3            


   Figure 3: Recommendation for Web Path Trave Algorithm  The weight assigned to various pages Visiting Frequency and Time spent on web Figure 4                  Figure 4: Plot between \(frequency + time sp  The Figure 5 gives the details of recomm Traversal for different users by FTPW a weights calculated by considering two para and time spent in Figure 4 which indicates for more frequently visited pages and in term on web pages  0 0.02 0.04 0.06 0.08 0.1 0.12 


0.14 0.16 0.18 W ei gh t Web Pages Us Us Us Us Us 0 0.2 0.4 0.6 0.8 1 1.2 1.4 W ei gh t FTPW \(Frequecy  and 2 which indicate pages. Using this traversal paths in e users have been rsal based on FPW by combining the page is plotted in ent ended Web Path lgorithm and use meters frequency the higher weight s more time spent    


         Figure 5: Recommendation W Algo Figure 6 shows the relative on the synthetic data sets, in w more efficient than FPW algor performance of proposed a increase the complexity of alg and provide better Web Path Tr    Figure 6: Relative Access  The proposed FTPW algorithm parameters which otherwise ar FPW algorithm. A matrix dep comparison between above two parameters are performance ce show that the performance o increase the number of param FPW algorithm to FTPW algori The experimental results d better and provides a methodo optimized Web path traversal past navigation behavior by c page 0 1 2 3 4 5 1 2A 


cc es si bi lit y Ti m e fo r M or e re qu ir ed In fo rm at io n er1\(A->C->D->B er2\(D->B->A->C er3\(D->B->C->A er4\(C->B->A->D er5\(B->A->D->C Time User1 User2 User3 User4 User5 0 0.2 0.4 0.6 0.8 1 1.2 


W ei gh t Web Pages eb Path Traversal based on FTPW rithm  execution for FPW and FTPW hich we can see that FTPW is ithm. Hence, it is clear that the lgorithm increases when we orithm in terms of parameters aversal in less time  ibility time for FPW and FTPW consists of clubbing of various e not available in first proposed icted in the Figure 7 describes proposed algorithms. Here the ntric and a comparison results f the system improves as we eters i.e. when we move from thm rawn for FTPW algorithms are logy for effective, efficient and for various users based on their omputing weight for each web 3 4 5 User FTPW FPW User1\(C->B->A->D User2\(A->B->C->D User3\(B->C->A->D User4\(D->A->C->B User5\(B->D->A->C 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 199 Figure 6: Comparison Matrix VI.  CONCLUSION & FUTURE WORK 


 Web Usage Mining have been used in improving Web site design and marketing decision support, user profiling, and Web server system performance. Web page prediction technique is a very important role in web technologies. This paper proposes efficient algorithms for web path recommendation based on Weighted Association Rule. Two factors frequency and time spent were used to decide the web path traversal. The experimental results show that in the proposed approach when we increase the number of parameters for finding the web path the accuracy of the system is enhanced drastically and FTPW produces more accurate results than those achieved by FPW In the future, we shall improve the Web Path Traversal by considering the parameter Data Transfer Rate to provide the accurate Web Path traversal REFERENCES 1] M. S. Chen, X. M. Huang and I. Y. Lin, Capturing User Access Patterns in the Web for Data Mining, Proceedings of the IEEE International Conference on Tools with Artificial Intelligence, pp. 345348, 1999 2]  R. Cooley, B. Mobasher, and J. Srivastava, Web Mining: Information and Pattern Discovery on the World Wide Web, Proceedings of the 9th IEEE International Conference on Tools with Artificial Intelligence, pp 558-567, 1997 3]  B. Mobasher,N. Jain,E. Han et al, Web mining: pattern discovery from World Wide Web transactions, Tech Rep: TR96-050, 1996 4]  C. Shahabi, A. Zarkesh, J. Abidi, V. Shah, Knowledge discovery from user's Web-page navigation,  in Proceedings of the 7th IEEE International Workshop on Research Issues in Data Engineering, 1997 5]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Web Usage Mining: Integrating Path Traversal Patterns and Association Rules, Proceedings of International Conference on Informatics Cybernetics, and Systems \(ICICS'2003 6]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Mining Traveling and Purchasing Behaviors of Customers in Electronic Commerce Environment, Proceedings of IEEE International Conference on e-Technology, e-Commerce and e-Service \(EEE'2004 pp. 227-230, 2004 7]  J. Srivastava, et al. Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data. SIGKDD Explorations, pp. 12-23 2000 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



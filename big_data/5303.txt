Implementation of Projected Clustering based on SQL queries and UDFs in Relational Databases Sandhya Harikumar 003  H Haripriya y  M.R Kaimal z Department of Computer Science and Engineering Amrita Vishwa Vidyapeetham Amritapuri Kollam Kerala India 003 sandhyaharikumar@am.amrita.edu y haripriyagireesh@gmail.com z mrkaimal@am.amrita.edu Abstract 227Projected clustering is one of the clustering approaches that determine the clusters in the subspaces of high dimensional data Although it is possible to ef\002ciently cluster a very large data set outside a relational database the time and effort to export and import it can be signi\002cant In commercial RDBMSs there is no SQL query available for any type of subspace clustering which is more suitable for large databases with high dimensions and large number of records Integrating clustering with a relational DBMS using SQL is an important and challenging problem in todays world of Big Data Projected clustering has the ability to 002nd the closely correlated dimensions and 002nd clusters in the corresponding subspaces We have designed an SQL version of projected clustering which helps to get the clusters of the records in the database using a single SQL statement which in itself calls other SQL functions de\002ned by us We have used PostgreSQL DBMS to validate our implementation and have done experimentation with synthetic as well as real data I I NTRODUCTION Big data is described by a large number of attributes and huge volume of records which pose challenges such as standardizing the data inorder to have all the attributes to a common scale transforming the data inorder to reduce the dimensionality constructing a distance measure for knowing the similarity between two objects etc Comprehensible analysis of data is required to help data scientists and industry people so that the data being loaded into the database can make sense Clustering is one such way to analyze the data and has many applications in various domains such as Bank Supermarket Bioinformatics etc Recent DBMS like Oracle 11g and SQL Server 2008 facilitate clustering using SQL Clustering algorithm or any such algorithm with a relational DBMS is an important and challenging problem Although it is possible to ef\002ciently cluster a very large data set outside a relational database the time to export it can be signi\002cant Moreover dynamic updating of the databases will decelerate the clustering process When we implement clustering in some other languages like C Java etc we need to frequently export and import the 002les for maintaining the ACID properties of database Therefore being able to cluster data set stored inside a relational database has signi\002cant advantage There are many algorithms for clustering data such as Kmeans 2 3 11 EM 5 and projected clustering 6  One of the main characteristics of projected clustering is that the records are projected along the most relevant attributes which give us a better understanding of the data In case of big data the volume of data is too huge and the structure is quite unordered However there is an implicit structured format for this type of data too Nowadays large volume of data are generated in every domain and the databases are quite big with too many attributes Not all attributes are relevant for all the formed clusters By knowing the relevant attributes we can remove insigni\002cant attributes thereby reducing the storage requirement of each cluster So we need to apply a clustering technique to 002nd the relevant clusters in various subspaces with appropriate attributes relevant for that subspace The subspace clustering is the task of detecting al l clusters in all subspaces of a given dataset This means that a data point might be a member of multiple clusters each existing in a different subspace Projected clustering is a type of subspace clustering which seeks to assign each point to a unique cluster but clusters may exist in different subspaces This technique can be more suitable for high dimensional data since projection of relevant dimensions for a cluster is intended to reduce the dimensionality of data speci\002c to that cluster Thus it is a way of 002nding the most relevant dimensions for a cluster thereby 002nding the projection of data with high dimensions onto these relevant dimensions Implementation of projected clustering using SQL allows clustering of large data sets stored inside a relational DBMS eliminating the need to export data Apart from this we can also have clustered data in the form of a table which can help us to build the visualization in a comparatively easy manner The clustered data of a table have certain meaning and some order So when a query comes the probability of accessing the data from the same cluster is more Hence clustering can be a preprocessing step to build some sort of organizing structure of the table which can pave the way for ef\002cient query processing This clustered table can also be used for the fragmentation of the data in a meaningful manner in distributed environment There are attempts to use SQL queries and User De\002ned Functions\(UDFs for implementing Data mining algorithms in The major challenge in SQL v ersion of any algorithm is that apart from executing the required tasks one has to work around the storage of data and manipulating the data such that the time complexity of the algorithm is not accelerated.SQL version of projected clustering in general has not been addressed in the literature to the best of our knowledge The major contributions in this paper are 2013 IEEE Recent Advances in Intelligent Computational Systems \(RAICS 978-1-4799-2178-2/13/$31.00 ©2013 IEEE 7 


1 Design and Implementation of SQL procedures for projected clustering 2 Optimized version of SQL projected clustering for effective and fast computation of the clusters II C LUSTERING R ELATIONAL D ATABASES USING SQL A Motivating concepts In K-means clustering a data set is partitioned into K clusters in such a way that the sum of the total clustering errors for all clusters is reduced as much as possible while inter distances between clusters are maintained to be as large as possible 1  Traditional K-means clustering forms clusters with dataset consisting of all the attributes In high dimensional spaces not all dimensions may be relevant to a given cluster and different sets of points may cluster better for different subsets of dimensions So there may be a possibility of clusters within clusters or different clusters within one application based on different attributes 2  A hybridized K-means clustering approach for high dimensional dataset is for reducing the dimensions of the database Due to the gro wth of high dimensional dataset conventional data base querying methods are inadequate to extract useful information Principal Component Analysis  L 2 PCA is used as a 002rst phas e for K-means clustering for dimensionality reduction But the relevant attribute selection for a cluster is a question here and in case of a high dimensional data it is good if we select some relevant attributes for a particular cluster and can remove all remaining attributes Fast Algorithms for Projected Clustering PROCLUS is based on some relevant attribute selection for clustering as described in PR OCLUS returns clusters along with the rele v ant dimensions in each cluster that signify the correlation among the dimensions in that particular cluster The performance is enhanced by computation of Manhattan distance for 002nding potential data points for each cluster as well as 002nding the relevant dimensions of each cluster Hence it can be adopted to cluster high dimensional data with relational DBMS The problem of projected clustering for categorical datasets is addressed in This method has a probability for more number of outliers which will not help us in an advantageous manner to cluster all the required set of records in the database relation In the paper mean is used to represent a cluster which implies that center of the cluster may not exist physically Thus a non-existent record may form the center of the cluster which may create ambiquity in understanding the records within the cluster B Clustering using SQL Programming K-means clustering algorithm in SQL sho ws that it is feasible to get an SQL implementation of the wellknown K-means clustering algorithm in DBMS that can work on the records of a table with numerical attributes The paper introduced two implementations of K-means in SQL Carlos extended the idea of programming K-means in SQL by Integrating K-means clustering with a relational DBMS using 1 http://en.wikipedia.org/wiki/Cluster analysis 2 http://cs.gmu.edu/cne/modules/dau/stat/clustgalgs-/clust5 bdy.html SQL Three SQL implementations of the popular K-means clustering algorithm have been presented by him in the paper SQLEM is fast clustering based on the ef 002cient SQL implementation of the EM algorithm It provides a cluster membership probability per record There are three strategies to implement EM in SQL horizontal vertical and a hybrid one In general EM is based on probability computation which may become computationally complex with increase in size and dimensionality of RDBMSs But we do not have a standard algorithm that addresses this problem of complexity in EM 3  A fast K-means prototype to cluster transaction data sets using disk-based matrices is an ef\002cient disk-based K-means clustering for relational databases The disk-based implementation and the SQL-based implementation represent complementary solutions to implement K-means in a relational DBMS but the SQL-based solution will become more valuable as disk density and CPU speed increase and hardware costs decrease The problem of integrating projected clustering in relational databases using SQL has to take care of many aspects such as storage of data accessing data in an optimized manner manipulation of data inorder to perform the actions as well as creation or redesigning a relational schema for storing the output of the algorithm In general these problems are not addressed in the literature Hence we are focussing on the integration of projected clustering using SQL TABLE I L IST OF SYMBOLS Symbol De\002nition N Total number of records in a relation N l Number of records in locality l N k Number of records in cluster k K Total number of clusters k A cluster t Total number of attributes l Average number of dimensions Bcnt Number of badmedoids r i j Value of j th attribute of i th record in a relation R k Set of records in cluster k A The set of attributes in a relation A k The set of attributes of k th cluster in a relation Y k Mean of k th cluster Y kj The average distance between records in cluster k to it's centroid along dimension j X kj The average distance between records in a locality to the medoid k along dimension j 033 k The standard deviation of k th cluster Z kj Value indicating the relationship between mean average distance and standard deviation w k Weight of cluster k III D EFINITIONS AND N OTATIONS To understand the algorithm a few de\002nitions and notations are de\002ned here The symbols we used are shown in Table I Let D be the database R   r 1  r 2   r N  be the set of records with each r i being described by a set of t attributes as A   a 1  a 2  a t   In the context of database each point feature vector of a cluster is in fact a record r i and each dimension feature is an attribute a i  The centroid or mean of a cluster of records R k 022 R with attributes A is the algebraic average of all records along each attribute in a cluster k  In most of the clustering algorithms the distance between two records is calculated with the help of norms F or a record 3 http://en.wikipedia.org/wiki/Expectation-maximization algorithm 8 


Fig 1 Locality of medoid A with respect to medoid B and medoid C on the basis of 016 value r i and a record r j  with t attributes L p  p-norm distance  is de\002ned in 1 L p  020 X t k 1 j r i k 000 r j k j p 021 1 p 1 When p  1  it is L 1 norm when p  2 it is L 2 norm and so on The L 1 norm is the absolute difference between two records as shown in 1 This is same as M anhattan distance  or the City block distance 4  M anhattan segmental distance  This is de\002ned relative to some subset of dimensions A i  Speci\002cally for any two records r i and r j with A i dimensions the M anhattan segmental distance between r i and r j relative to A i  is de\002ned in 2 d A i  r i  r j   P k 2 A i j r i k 000 r j k j j A i j 2 Employing the M anhattan segmental distance as opposed to the traditional M anhattan distance is useful when comparing records in two different clusters that have varying number of attributes Locality  Assume we have a dataset with many clusters and each cluster is represented by a medoid m k  If we need to 002nd the locality of medoid L k then 1 Calculate the M anhattan distance d k to it's nearest medoid 2 Find all the records R k 032 R which fall within distance d k  R k calculated above is the locality of medoid m k  In Figure 1 A B and C are three medoids and the nearest medoid of A is C with distance 016  We have taken 016 instead of 016 2 inorder to include the possibility of overlapping localities around medoids The average distance  X kj between records in a locality L k to it's medoid m k along each attribute j with N l records in it's locality is shown in 3 X kj  P N l i 1 f f m k;j 000 r i j f f N l 3 Based on the average distance we can calculate the mean of a cluster Y k with t attributes by using 4 Y k  t P j 1 X kj t 4 4 Books.google.co.in/books?isbn=080582281X Fig 2 SQLPROCLUS takes as input SQL query for clustering a table and gives three tables as output signifying the clusters relevant dimensions for each cluster and best medoids The computed mean and average distance of a cluster k can be used for 002nding the standard deviation which is explained in 5 033 k  s P j  X kj 000 Y k  2 t 000 1 5 We can compute Z kj  that indicates how the j dimensional average distance  X kj associated with the medoid m k is related to the average M anhattan segmental distance associated with the same cluster with mean Y k  by using 6 A smaller value of Z kj indicates that along dimension j the records R k are more closely correlated to the medoid m k  Z kj  X kj 000 Y k 033 k 6 The weight w k of a cluster k calculated by using Y kj with j A k j attributes  projected cluster  is de\002ned in 7 w k  X j Y kj j A k j 7 IV SQL VERSION OF PROCLUS We have implemented the projected clustering algorithm in PostgreSQL 5 using the following two methods 1 A naive translation of projected clustering in PostgreSQL 2 An optimized version using ef\002cient indexing rewritten queries and reduced intermediate database tables SQL PROjected CLUStering has mainly three phases Initialization phase  Iterative phase and Ref inement phase  The purpose of the Initialization phase is to 002nd a potential set of medoids by a greedy approach Thus if K clusters are required to be formed select B 003 K medoids from the set of original records where B is a small integer constant This greedy approach has the advantage of picking some representatives from each cluster using L 1 and the reduction to the sample set signi\002cantly reduces the running time of the Initialization phase  The Iterative phase is the core part of SQLPROCLUS for selecting a good set of medoids This is presented as an optimization problem The 002nal Ref inement phase is for improving the quality of clustering Ref inement phase uses the distribution of records in clusters for 002nding the dimensions and assigning records to each cluster We implement each part of PROCLUS as separate SQL functions and 002nally implement PROCLUS in SQL named NAIVE SQLPROCLUS The advantage of each function is that we can use it separately for 002nding medoids 002nding dimensions assigning records to each clusters detection and replacement of bad medoids etc 5 http://www.PostgreSQL.org/docs/8.0/static/tutorial.html 9 


A Basic Framework The overview of the framework is shown in Figure 2 1 Setup Create and populate tables with the required records 2 PROCLUS a Initialization phase b Iterative phase c Ref inement phase 3 Output a Assign table Clustered table b Dimension table c BestM edoid table Apart from the main tables speci\002ed above certain temporary tables like M edoid  Submedoid  Locality  etc are also used The main tables as well as the temporary tables used in the implementation are shown in Table II and Table III respectively TABLE II M AIN TABLES IN SQLPROCLUS Table name Size Contents Data N x t Original records Dimension l*K x 2 Medoids and their relevant dimensions Assign N x t+1 Original records with their assigned medoid BestMedoid K x t Best medoid set TABLE III T EMPORARY TABLES IN SQLPROCLUS Table name Size Contents Medoid B*K x t Potential medoids obtained using greedy approach SubMedoid K x t Required medoids selected during iterative phase Locality N l x t+1 Medoids with records in its locality which is subject to change during iterative phase BadMedoid Bcnt x 1 Detected bad medoids B NAIVE SQLPROCLUS We implement SQL procedures inorder to facilitate the projected clustering within relational databases The input to this algorithm is a Data table which we want to cluster number of clusters K  the average number of dimensions for each cluster l as explained in Algorithm 1  NAIVE SQLPROCLUS is a direct translation of the projected clustering algorithm into SQL We are making use of several intermediate tables various disk accessing statements such as Select  U pdate  Delete  Insert for storing and retrieving the result of each function The main algorithm for SQLPROCLUS is as follows Algorithm 1 SQLPROCLUS for clustering procedure S QLPROCLUS  Datatable K l  f 1.Initialization Phase g P erf orm Greedy  K  f 2 Iterative Phase g BestObjective  1 P erf orm Subset  K  repeat f Approximate the optimal set of dimensions g P erf orm locality   P erf orm F indDimensions  K l  f Form the clusters g P erf orm Assignpoints  K l  P erf orm Evaluateclusters  K l  Store the result of Evaluateclusters in objectiveV ar  if  ObjectiveV ar  BestObjective  then BestObjective  ObjectiveV ar Insert records of SubM edoid table into BestM edoid table P erf orm Detectbadmedoids  K  end if Insert count of records of M edoid table in mednt  Insert count of records of Badmedoid table in badmedcnt  if  medcnt and badmedcnt  0  then P erf orm Replacebadmedoids   else exit end if if  BestM edoid remains same  then Terminate the iterative phase Insert records of BestM edoid table into SubM edoid table P erf orm Assignpoints  K l  end if until termination condition is met f 3.Re\002nement Phase g Insert the records of Assign table into Locality table P erf orm F indDimensions  K l  P erf orm AssignP oints  K l  return Assign table end procedure Each function takes as input the number of clusters to be formed K and the average number of dimensions in each cluster l  The output of the functions is in the form of tables At the beginning of each function we delete the records from the output table using T runcate statement to make the table empty so as to avoid redundancy of data before insertion The excerpts from the implementation of one of the user de\002ned functions FindDimensions in SQL is as follows CREATE OR REPLACE FUNCTION FindDimensions\(K int l int returns table\(medoidid int dimsnvalue numeric as declare begin 10 


Fig 3 Main table 003ow in SQLPROCLUS Fig 4 Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS by varying N x      x[q][k]::float/clstrcnt[q  FOR k IN 1  dim LOOP mul:=0 mul    mul mul  mul   squaresigma[q]+mul END LOOP    squaresigma[q]::float/\(dim-1   z[k]::float/sigma[q  update Dimset set dimsn=999999 where dimsn=minval  Return query select  from Dimension end language plpgsql C OPTIMIZED SQLPROCLUS The naive translation of PROCLUS into SQL has certain limitations in performance These limitations are due to the large number of scans required for convergence in clustering algorithm Iterative phase of PROCLUS require multiple scans of the same data in order to compute the segmental distances with respect to the medoids selected Several optimizations Fig 5 Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS by varying l Fig 6 Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS by varying k were done to improve the performance without changing the PROCLUS behavior In this paper the optimizations include index creation cursor usage rewrite SQL functions for reducing the overhead of disk access replacing certain intermediate tables consisting of few records by arrays The excerpts from the implementation of optimized SQL version of FindDimensions is as follows CREATE OR REPLACE FUNCTION FindDimensions\(K int l int returns void as declare begin insert into avg_dim_dist select meid,avg\(dist_a  Fig 7 Performance comparison of OPTIMIZED and NAIVE SQLPROCLUS by varying t 11 


from locality group by meid insert into avg_dim SELECT meid,COALESCE\(am,0  COALESCE\(bm,0   FROM avg_dim_dist   update avg_dim_dist t set am  am s.dist bm  bm s.dist  from avg_dim s where t.meid  s.meid update avg_dim s set dist  sqrt\(\(COALESCE\(t.am  t.am,0    FROM avg_dim_dist t where t.meid  s.meid update avg_dim_dist t set am  am/s.dist bm  bm  s.dist   from avg_dim s where t.meid  s.meid  end language plpgsql V E XPERIMENTAL E VALUATION We evaluated the performance of NAIVE SQLPROCLUS and OPTIMIZED SQLPROCLUS on synthetic data and on real data by varying the size of database average dimensionality of clusters number of clusters and dimensions of original table In varying the number of records we 002xed the attribute size to be 10 average number of dimensions to be 5 and number of clusters as 5 This analysis is shown in Figure 4 We can see a sudden rise in time from 20000 to 25000 This is due to the time taken for page access of the database records from the hard disk In NAIVE SQLPROCLUS the number of disk accesses is quite high since the records were fetched as and when required and lots of redundant computations were done without looking into the optimizations such as batch update local caching and temporary table creation But in OPTIMIZED SQLPROCLUS the time has reduced drastically showing the optimal performance In varying the average number of dimensions we 002xed the size of the records to be 10000 and number of clusters to be 3 The analysis based on average dimensionality of clusters shows that the graph remains almost constant for both the cases but the time is very large for NAIVE as shown in Figure 5 In varying the number of clusters we 002xed the size of the records to be 10000 and average number of dimensions to be 5 This analysis is shown in Figure 6 In analysis based on varying the number of dimensions we 002xed the number of records to be 10000 average dimensions as 4 and number of clusters as 3 This analysis is shown in Figure 7 Figure 4 Figure 5 Figure 6 and Figure 7 clearly exhibit that OPTIMIZED version has signi\002cant improvement with respect to all parameters over the NAIVE version VI C ONCLUSION Integrating clustering algorithm with a relational DBMS using SQL is an important and challenging problem There are many algorithms for clustering data such as K-means and EM Among them projected clustering is the one which is more suitable for high dimensional data since it projects the relevant dimensions for each cluster Hence each cluster can be stored with limited storage requirement We incorporated the operations needed for projected clustering in SQL Our experiments show that optimized version of SQL for projected clustering has good performance This clustering can be further utilized for developing a prototype for ef\002cient query processing This will have signi\002cant relevance in query processing applications in mobile tablet and other such portable devices which has limited storage A CKNOWLEDGMENT We would like to thank the faculty members of the Department of Computer Science and Engineering Amrita Vishwa Vidyapeetham for their support R EFERENCES  C.Ordonez 224Programming the K-Means Clustering Algorithm in SQL\224 Proc ACM Int'l Conf Knowledge Discovery and Data Mining pp 823-828 2004  Carlos Ordonez 224Inte grating K-Means Clustering with a Relational DBMS Using SQL\224 IEEE transactions on knowledge and data engineering vol 18 no 2 February 2006  Rajashree Dash Debahuti Mishra Amiya K umar Rath2 Milu charya3 224A hybridized K-means clustering approach for high dimensional dataset\224 International Journal of Engineering Science and Technology Vol 2 No 2 2010 pp 59-66  Bradle y  F ayyad Cory 224Scaling Clustering Algorithms to Lar ge Databases\224 Microsoft Research Report 1998  Carlos Ordonez P aul Cere ghini 224SQLEM F ast Clustering in SQL using the EM Algorithm\224 ACM SIGMOD 2000   Charu C Agg arw al Cecilia Procopiuc 224F ast Algorithms for Projected Clustering\224 SIGMOD 99   Minho Kim and R.S.Ramakrishna 224Projected clustering for cate gorical datasets\224 2006 Elsevier B.V  Carlotta Domeniconi,Dim itris P apadopoulos Dimitrios Gunopulos,Sheng Ma 224Subspace Clustering of High Dimensional Data\224 SIAM Int Conf on Data Mining 2004  Jollif fe Ian T 224Principal component analysis\224 Springer v erlag,2002  Gentle James E 224Matrix algebra t heory  computations and applications in statistics\224Springer Verlag,2007  Rui Xu and Donald W unsch II Fello w  IEEE 224Surv e y of Clustering Algorithms\224,1045-9227 2005 IEEE  Carlos Ordonez Carlos Garcia-Alv arado 224A Data Mining System Based on SQL Queries and UDFs for Relational Databases\224 CIKM Conference 2011 12 


B IOGRAPHY  Eugene Levin is currently a Program Chair of Surveying Engineering and Assistant Professor at School of Technology at Michigan Tech University Dr Levin also directing Integrated Geospatial Technology graduate program He received M.S degree in Astrogeodesy from Siberian State Geodetic Academy in 1982 and Ph.D in Photogrammetry from Moscow State Land Organization University in 1989  He has over 25 years of experience in US Israeli and Russian academy and geospatial industry He held research and managing positions with several Russian Israeli and US research academic institutions and high-tech companies including Research Institute of Applied Geodesy Omsk Agricultural Academy Rosnitc 224Land\224 Ness Technologies Physical Optics Corporation Digital Map Products American GNC and Future Concepts He has served as a Principal Investigator and Project Manager in multiple awardwinning government programs Aleksandr Sergeyev is currently an Assistant Professor in the Electrical Engineering Technology program in the School of Technology at Michigan Technological University Dr Aleksandr Sergeyev is earned his bachelor degree in electrical engineering in Moscow University of Electronics and Automation in 1995  He obtained the Master degree in Physics from Michigan Technological University in 2004 and the PhD degree in Electrical Engineering from Michigan Technological University in 2007  Dr Aleksandr Sergeyev research interests include high energy lasers propagation through the turbulent atmosphere developing advanced control algorithms for wavefront sensing and mitigating effects of the turbulent atmosphere digital inline holography digital signal processing and laser spectroscopy He is also involved in developing new eyetracking experimental techniques for extracting 3-D shape of the object from the movement of human eyes 7 


 intermediary is implemented and tested, demonstrating that the intervention of intermediaries won  t affect the performance of cipher system. On the other hand, there  re no obvious reductions in transmitting speed during experiment due to the utility of RC4+ algorithm. The efficiency experiment confirms this conclusion will be presented later in Section D C  Key Generation and Distribution Experiment Generating and distributing keys are, strictly speaking parts of cipher system. Before any actual uploading or downloading actions, peers should obtain the key corresponding to data from tracker by sending  getcipher   request along with identity information, public key and signature. The detail has been covered in Part III In the experiment, key generator on tracker generates keys to new torrents, illustrated in Fig. 12. Also, peers use their own generator to produce key pairs \(public and private keys\ sign their identity information and send required message to tracker in order to obtain file key. The public key will be used in two ways on tracker: \(1\ to verify the signature; \(2\to encrypt the requested file key The identity information which will be signed is arbitrary only if it  s consistent with peer  s identity and has no ambiguities. In this experime nt, it will be produced as  usernam  passw o rd  i p   t o rr ent h ash    An example of parameters to request a file key recoded in experiment, is shown below \(instructions are shown in italic form and not actually contained in HTTP request   info_hash=%BE%86%A0%C7   torrent hash    getCipher=yes indicates to get file key    sign=PCGqKJ0fM4K   signature    key=MIGfMA0GCSqGSIb3DQEBAQUAA4GN ADCBiQKBgQCQO   peer  s public key  The signature and public key are encoded by Base64, a common algorithm to produce HTTP parameters Different from the original BT, peers who  re not intermediary will send the request containing these parameters before uploading or downloading to obtain file key, and then be able to pe rform data transmission through cipher system In the experiment, all the responses of file keys to peers are identical with the keys generated by tracker generator. Hence the encrypting transmission is also correct D  Efficiency Experiment and Analysis IVCSD provides protection to the network and data with cost of time consumed by identity verification procedure and cipher system. Since looking up authority levels of peers and torrents can be processed in parallel with existing functions of original BT \(such as looking up existing torrents or registering new peers\it  s reasonable to argue that new consumption of time occurs in cipher system, especially encryption, decryption and key generation. Therefore, in this section, cost of time will be tested and analyzed 1  Testing Procedure a  Encryption and Decryption  Figure 12  An example of generated key for a torrent A random byte array with the size of 16KB \(16384 bytes, identical to the size of a default piece in BT network is generated and encrypted by RC4+ algorithm. Run this program for 10000 rounds, 100 times per round, and record the cost of time in each round The decryption of stream cipher algorithm \(such as RC4+\ very similar to encryption, typically just reversing the procedure. It  s sure that the time consumed in decryption is nearly the same as that in encryption. So the result and analysis in uploader \(encryption\ will be similar to that in downloader \(decryption b  Key Generation Nowadays, a secure length of key can be 1024 bits 128 bytes\. Recording the time used by random-number generator to produce a 128-bytes array will be crucial to determine the cost of time in key generator. Again, the program will be run for 10000 rounds, 100 times per round 2  Result Analysis After running the programs described above, the averages of encrypting times and key generating times are 31.24 milliseconds per round and 0.11 milliseconds per round, respectively a  Analysis of Encryption and Decryption With simple calculation, it  s easy to have the conclusion that in every second, approximately 3200 arrays \(reciprocal of 0.0003124\an be encrypted, in other words, 50MB data \(multiply 3200 and 16KB As mechanism of parallel and pipeline is so common on today  s machines, the encrypting/decrypting procedure will not really delay any transmission only if the transmitting speed in BT network is no more than 50MB/s defined as  speed bound  here. What  s more, if parallel mechanism is performed in encryption, allowing uploader to encrypt data \(or downloader to decrypt data\ore than one array at a time, the speed bound should be multiplied by the number of parallels, illustrated in Fig. 13 as solid line. 50MB/s is quite acceptable because it s beyond the bandwidth in most of machines today, especially household computers and portable laptops which uses wide bands giving a max transmitting speed of 10MB/s 89 89 89 


 Even using a 2Gbps optical fiber, five parallel encryptions suffice to the requirement of max speed of 250MB/s. The max speeds are also illustrated in Fig. 13 as dot lines Since the speed bound line ascends linearly, it  s easy to determine, as the method above, how many parallels should be deployed to achieve the maximum transmitting speed of bandwidth  Figure 13  Speed bounds comparing to max transmitting speed b  Analysis of Key Generation Since key generation occurs only once for a new torrent file, it  s easy to determine that generating ten thousand keys consumes only 11 seconds \(multiply 0.11 milliseconds to 10,000\. So it  s safe to argue that the cost of time is negligible 3  Efficiency of IVCSD According to the results and analyses above transmission in IVCSD is as efficient as original BT meaning that adding these functions and schemes will not affect the overall performance in BT network V  C ONCLUSION  This paper proposes a scheme, Identity Verification and Cipher System Distribution \(IVCSD\, to address secure problems in distributing big data. Identity verification protects the network in the aspect of peer admittance and data spreading, by assigning authority to torrents and peers, blocking unauthorized behaviors and keeping track of peers  actions. Cipher system protects the transmission in the aspect of data security and transmitting efficiency. With data encryption, intermediaries are allowed to participate into network without getting original data, sustaining the advantage of BT protocol After implementing IVCSD in testing machines experiment is performed and the results are analyzed Functionality and efficiency is positively demonstrated in the experimental results. As a conclusion, IVCSD is a feasible scheme to distribute big data, with some compromises between security and complexity There  re still some imperfect conditions. \(1\lthough behavior of intermediaries are proposed, implemented and tested, details about how or who to trigger or stop these actions are still absent. \(2\ The code implementing IVCSD for experiment in this paper uses Java. It may have some effects on evaluating efficiency. Other languages may be used in realistic deployment to achieve better performance 3\ Restricted by facilities an d environments in lab, all experiments and evaluations are completed within the local area network, instead of wider one such as Internet This fact may result in inaccuracy of experimental results but according to the analyses in Part IV, the functionality won  t be affected and the efficiency will still be acceptable in future implementation A CKNOWLEDGMENT  This paper is supported by the Hi-tech Research and Development Program of China \(863 Program\ under Grant No. 2011AA01A205, the Open Research Fund of The Academy of Satellite Application under grant NO SSTC-YJS-01-03, the National Natural Science Foundation of China under Grant No. 61232009, the Doctoral Fund of Ministry of Education of China under Grant No. 20101102110018,Beijing Natural Science Foundation under Grant No. 4122042, the fund of the State Key Laboratory of Software Development Environment under Grant No. SKLSDE-2012ZX-06 R EFERENCES  1  The Coming Data Deluge, IEEE Spectrum, February 2011 2  The data deluge, www.economist.com/node/15579717, Feb 25 2010 3  Arun Chokkalingam, Firasath Riyaz. BitTorrent Protocol Specification V 1.0. CSI 5321, Dec 12 2004 4  Zhang, X., Liu, D., Chen, S., Zhang, Z., & Sandhu, R. \(2008 Towards digital rights protection in BitTorrent-like P2P systems Proc. 15th SPIE/ACM Multimedia Computing and Networking MMCN 5  Balfe, S., Lakhani, A. D., & Paterson, K. G. \(2005, August Trusted computing: Providing security for peer-to-peer networks In Peer-to-Peer Computing, 2005. P2P 2005. Fifth IEEE International Conference on \(pp. 117-124\. IEEE 6  So, Jung Ki. Defending against Malicious Behaviors in BitTorrent Systems. Diss. NORTH CAROLINA STATE UNIVERSITY 2012 7  Douceur, J. R. \(2002\. The sybil attack. In Peer-to-peer Systems pp. 251-260\ Springer Berlin Heidelberg 8  Jun, S., & Ahamad, M. \(2005, August\. Incentives in BitTorrent induce free riding. In Proceedings of the 2005 ACM SIGCOMM workshop on Economics of peer-to-peer systems \(pp. 116-121 ACM 9  Sit E, Morris R. Security considerations for peer-to-peer distributed hash tables[J   Pe e r t o Peer Sy ste ms 2 0 0 2  2 6 1 2 6 9     Kinateder M, Pearson S. A privacy-enhanced peer-to-peer reputation system[J E Co m m e r ce a n d W e b T e chno l o g i e s  2 0 0 3   206-215   Damiani E, di Vimercati D C, Paraboschi S, et al. A reputationbased approach for choosing reliable resources in peer-to-peer networks[C P r o ce e d ing s o f t h e 9t h A C M co nf e r e n ce o n  Computer and communications security. ACM, 2002: 207-216   Shamir, A. \(1985\. Identity-based cryptosystems and signature schemes. InAdvances in cryptology \(pp. 47-53\. Springer Berlin/Heidelberg   Cohen B. Incentives build robustness in BitTorrent[C  W o r ks ho p  on Economics of Peer-to-Peer systems. 2003, 6: 68-72 90 90 90 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



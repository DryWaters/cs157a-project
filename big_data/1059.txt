Case-Control Study of Binary Disease Trait Considering Interactions between SNPs and Environmental Effects using Logistic Regression Reiichiro Nakamichi Seiya Imoto Satoru Miyano Human Genome Center Institute of Medical Science University of kyo 4-6-1 Shirokanedai Minato-ku kyo 108-8639 Japan  rei-naka imoto miyano  ims.u-tokyo.ac.jp Abstract In this paper e propose a combination of logistic  
gression and genetic algorithm for the association study of the binary disease trait We use a ogistic regression model to describe the relation of multiple SNPs environments and the target binary trait The logistic regression model can capture the continuous effects of environments without categorization which causes the loss of the information To construct an accurate prediction rule for binary trait we adopted Akaike information criterion AIC to 223nd the most effective set of SNPs and environments That is the set of SNPs and environments that gives the smallest AIC is cho 
sen as the optimal set Since the number of combinations of SNPs and environments is usually huge we propose the use of the genetic algorithm for choosing the optimal SNPs and environments in the sense of AIC We show the effectiveness of the proposed method through the analysis of the case/control populations of diabetes patients We succeeded in 223nding an ef\223cient set to predict types of diabetes and some SNPs which have strong interactions to age while it is not signi\223cant as a single locus 1 Introduction 
Single nucleotide polymorphisms SNPs are the most frequent genomic variations A large number of SNPs have been developed and genome-wide association study has been proposed to identify complex trait loci This kind of association study is roughly divided into two categories case-control study and transmission disequilibrium test TDT 10 Although TDT has the advantage on handling the population strati\223cation as a cause of false positive association case-control study is still popular because independent individual data under case-control design is far easier to gather than fam 
ily data for TDT Because of this low cost of case-control study e may expect more data and more precise analysis Traits are often controlled by multiple genes and environments and the researchers have been paying attention to the interactions among genes and environments However since the contribution of each genetic and environmental effect is relatively small 3 5 it is dif 223cult to detect these interactions by testing each locus separately Recently several methods have been proposed to estimate the combinations of loci interacting with each other Classi\223ca 
tion tree method constructs a tree splitting the sample individuals into the nodes by the genotype of SNPs Proportion of case/control individuals is tested at each node and the tree giving highly biased case/control proportion is searched Combinatorial partitioning di vides the samples by the genotypes of any two SNPs Phenotypic variance explained by this partitioning is tested for each combination of two SNPs and the combination giving high explanation rate is searched Sum-statistics methods 4 calculate the test statistics at each SNP based on simple meth 
ods such as  and 223nds the set of SNPs that maximizes the sum of each statistics Generally these methods are powerful but dif\223cult to consider the continuous effect of the environment especially for the interaction between SNPs and environments Furthermore the evaluation of the statistical signi\223cance is unclear and they require empirical threshold such as permutation test to search the optimal combination of SNPs and they require heavy calculation when analyzing a huge number of SNPs So we need to construct a statistic model considering multiple SNPs envi 
ronmental effects and their interactions simultaneously In this paper e propose a combination of logistic regression and genetic algorithm for the association study of the binary disease trait We use a logistic regression model to describe the relation of multiple SNPs environments and Proceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


the target binary trait The logistic regression model can capture the affection of multiple SNPs continuous effects of environments and their interactions to the binary trait based on a probabilistic model When we know the correct relationship among them completely e can construct a prediction rule for binary trait by estimating the parameters in the correct model However the effect of SNPs and environments to the trait is generally unknown Therefore we need to 223nd the most effective set of SNPs and environments to predict the trait from a statistical point of view This problem can be considered as a statistical model selection problem When the parameter estimation is done by the maximum likelihood method the Akaike information criterion AIC 1 can pro vide an ef 223cient solution from a predictive viewpoint That is the set of SNPs and environments that gives the smallest AIC is chosen as the optimal set of them On the other hand since the number of combinations of SNPs and environments is usually large the optimization of the set of SNPs and environments is a dif\223cult problem Moreover this optimization is sometimes impossible when we consider a huge number of SNPs To solve this problem we propose the use of the genetic algorithm GA for choosing the optimal SNPs and environments in the sense of AIC In our GA candidates for the SNPs are encoded as 215genotypes\216 and AIC as 215\223tness\216 In Section 2.1 we introduce the logistic regression model to predict the binary trait by using the information of multiple SNPs environmental effects and their interactions The estimation method of the parameters in the logistic regression model is described in Section 2.2 Akaike\220s information criterion for selecting informative SNPs and environmental effects is introduced in Section 2.3 together with the genetic algorithm for solving the optimization problem In Section 3 we show the effectiveness of the proposed method through the analysis of the case/control populations of diabetes patients 14 2 Method for redicting Binary Trail 2.1 Logistic Regression Model We consider a population of independent individuals We randomly sample a number of cases affected by disease and controls not affected from this population and observe the genotypes of candidate SNPs and environmental factors for each individual The probability of affection p  is described by the logistic regression model using the linear combination of the SNPs and environmental factors as p  1  1+exp z   1 where z  265  N s 001 i 1 001 i x i  N s 212 1 001 i 1 N s 001 j  i 1 002 ij x i x j 2  N e 001 k 1 003 k e k  N s 001 i 1 N e 001 k 1 004 ik x i e k  Here N s is the number of SNPs associated with this disease and N e is the number of observed environmental factors The observation of the i th SNP x i  i 1 N s s de\223ned by x i  002 1  if the i th SNP is observed 0  if the i th SNP is not observed The observation x i may be both single SNP observation and the observation of the haplotype set When considering the haplotype set estimation of the haplotype frequencies also is required as a preprocessing of the data The environmental factor e k  k 1 N e  allows both discrete and continuous value 265  001 i  002 ij  003 k and 004 ik are parameters estimated by data The 3rd and 5th terms of the right hand side of equation 2 are the interactions between the i th and j th SNPs and between the i th SNP and k th environment respectively The advantage of the logistic model is the handling of the continuous effect of environments Other methods we mentioned in the introduction part also can incorporate environmental factor but they need to categorize the environmental effects by some thresholds which causes the loss of the information The logistic model is free from this problem 2.2 Estimation of Parameters We use the maximum likelihood method for estimating the parameters 265  001 i  002 ij  003 k and 004 ik  in the logistic regression model Suppose that we have N s SNPs and N e environment factors of N samples The logistic regression model for the n th  n 1 N  observation can be pressed as p n  1 1+exp z n   3 where z n  265  N s 001 i 1 001 i x ni  N s 212 1 001 i 1 N s 001 j  i 1 002 ij x ni x nj 4  N e 001 k 1 003 k e nk  N s 001 i 1 N e 001 k 1 004 ik x ni e nk  Suppose y n is the indicator that expresses whether the n th observation is affected by disease  y n 1  r not  y n 0  Proceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


The likelihood function can be written of the form L  001  N 003 n 1 p y n n 1 212 p n  1 212 y n  5 The maximum likelihood estimate MLE 032 001 is obtained as the maximizer of L  001   The MLE 032 001 is obtained as the solution of 005 log L  001  005 001 0  ever this equation is nonlinear in 001 for the logistic regression model and we use the Newton-Raphson method to compute 032 001  2.3 Selection of SNPs and Environmental Factors The MLE 032 001 can be obtained when we set the set of SNPs and environmental factors as the candidates for predicting the trait However the relationship between disease and SNPs and environment factors is generally unknown Therefore we need to select the set of SNPs and environmental factors from the data in practice This problem can be viewed as a statistical model selection problem To choose the best set of SNPs and environment factors we use Akaike\220s information criterion known as AIC AIC  212 2log L  032 001   001   6 where   001  is the number of parameters included in the model The optimal model i.e the optimal set of SNPs and environment factors is obtained as the minimizer of AIC r the logistic regression model given n 3 and 4 the number of parameters is   N s 2 N e   N s 1   2 and the AIC is de\223ned as AIC  212 2log L  032 001   N s 2 N e   N s 1  7 For choosing the optimal set of SNPs and environment factors we need to compute the score of AIC for all possible combinations In practice the exhaustive search is just not realistic because the number of combinations of SNPs and environment factors is huge To solve this problem we perform the genetic algorithm GA for choosing the better set of SNPs and environment factors as follows GA genotype and 223tness We simply use the list of SNPs as the GA genotype and AIC described in 7 as the GA 223tness GA selection A number of the GA individuals are tracted from the GA population and the one with the highest 223tness is adopted as a parent The same procedure of parent selection is repeated twice without replacement for each GA offspring Fig.1 GA crossover The number of SNPs for the GA offspring is selected randomly from the range determined by the numbers of SNPs of the GA parents The SNPs of GA   Create number N GA of GA individuals  Calculate AIC Current GA generation Random sampling Parent GA individual 1 Random selection of SNPs from the parents Offspring GA individual Parent GA individual 2 Next GA generation Insertion Deletion Substitution There re number N i of identical GA individual in the next generation Drastic tion  Yes rate P d  No rate 1P d  Slight mutation  Yes rate P s N t  No rate 1P s N t  Select a SNP and change to adjacent SNP Number of GA individuals in the next generation is N GA  Yes No Convergence  End Yes No   Tournament 1 size N t   Select the one with lowest AIC Random sampling Tournament 1 size N t  Select the one with lowest AIC Figure 1 Overview f A N GA   of A individuals N t  tournament size P d  probability of drastic mutation N i   f identical GA individuals P s  base probability of slight mutation Probability of slight mutation is P s 327 N i   offspring are selected randomly without duplication from the list of SNPs contained in GA parents Fig 2 GA mutation of drastic change GA mutation has three patterns Fig 3 insertion adds a random SNP to the GA genotype deletion randomly deletes a SNP from the GA genotype and substitution randomly selects a SNP and Proceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


 Parent 1 List up SNPs without duplication Select SNPs randomly from the list snp1  snp2 Parent 2 snp3  snp4  snp5  snp6 Available number of SNPs 2~4 Offspring List of available SNPs snp1  snp2  snp3  snp4  snp5  snp6 snp2  snp3  snp5 Figure 2 GA crossover The SNPs of the offspring are selected randomly m the SNPs of parents Insertion Add one SNP  Change one SNP Deletion Remove one SNP snp2  snp3  snp5 snp2  snp3  snp5  snp7 snp2  snp3  snp5 snp2  snp3  snp5 snp2  snp5 snp8  snp3  snp5 Figure 3 GA mutations The offspring created in GA crossover is randomly adopted one of the three types of mutations insertion deletion and substitution changes it to a random another SNP One of these three mutations is randomly selected and applied to the GA offspring GA mutation of slight modi\223cation To avoid the premature convergence to the local optima we introduce very slight mutation occurring with the probability proportional to the number of identical GA individuals This additional mutation randomly selects a SNP from the GA genotype and shifts it to an adjacent SNP GA controlling parameters In our GA four parameters control the speed and the certainty of the search size of GA population tournament size probabilities of drastic Individual SNPs age disease 1 ATAGGCATGT CG 35 not affected 2 AT T GGCATGTACG 42 affected 3 ATAGG G ATGTACG 30 not affected 4 ATAGG G ATGTACG 57 affected 5 ATAGGCATGT CG 31 affected  nkniik ki nk k k njniij ji ni i i n exexxxZ 001 002 003 004 265 005\005+\005+\005\005+\005   exp 1 1 n n Z P 212  probability of affection  Logistic Regression 1 1 n n y n y n PPL 212 212\006 likelihood  Genetic Algorithm candidates SNPs evaluation 1 snp1 snp3 snp7 AIC1 2 snp2 snp5 AIC2 3 snp1 snp5 snp6 snp8 AIC3 4 snp4 snp5 snp8 AIC4    The optimal set of SNPs and environmental effects  Ob servat i on Figure 4 Conceptual view f the proposed method and slight mutations Regarding the certainty of the search rather than the speed we settled on the number of GA individuals being 200 the tournament size was  the rate of the drastic GA mutation was 0.1 and the rate of slight mutation was set to be 0.3 of the number of identical GA individuals to a ewly created GA individual Finally we would like to show a conceptual chart of our proposed method in Fig.4 as a summarization of this section 3 Analysis of Diabetes Patients Data We analyze the case/control populations of diabetes patients served in mtSNP database The data is consisted of normal type II diabetes patients control and type II diabetes patients with angiopathy case and each population is consisted of 96 Japanese patients The mitochondrial SNP genotype and the age are observed for each patient Totally 720 SNPs are observed in these populations Since mitochondrial DNA s the haploid we can observe the SNP hapProceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


 e  Detected SNPs in the optimal model nucleotide location locus wild type SNP SNP1 6455 CO1 CT SNP2 11647 ND4 CT SNP3 14470 ND6 TC SNP4 15874 Cytb AG SNP5 16217 MajorNCR2 TC SNP6 16261 MajorNCR2 CT SNP7 16291 MajorNCR2 CT e 2 Estimated coef\223cients in the optimal model p value coef\223cient SNP1 0  0311 212 0  4323 SNP2 0  3320 212 0  1928 SNP3 0  3176 212 0  4858 SNP4 0  0540 0  4352 SNP5 0  0453 0  4678 SNP6 0  0187 0  4979 SNP7 0  3098 0  3229 SNP2 vs SNP7 0  4010 212 0  7172 Age  10 212 4 1  3903 SNP2 vs Age 0  5363 212 0  1399 SNP3 vs Age 0  2433 1  3980 SNP7 vs Age 0  2708 212 1  5299 lotype directly Here we consider the age as an environmental factor to apply our method The results of this analysis can be summarized as follows We found seven SNPs in the optimal model Table 1 SNP 1 at the 6455th base in CO 1 cytochrome c oxidase subunit 1 SNP 2 at the 11647th base in ND 4 NADH dehydrogenase subunit 4 SNP 3 at the 14470th base in ND 6 NADH dehydrogenase subunit 6 SNP 4 at the 15874th base in Cytb Cytochrome b and SNP 5  6  7 at the 16217th 16261st and 16291st base in the non-coding region Table 2 shows the estimates and p values of the parameters of the optimal model We observed that interaction 215 SNP 2 and SNP 7 216 and strong interactions 215age and SNP 3 216 and 215age and SNP 7 216 Using this optimal model we applied leave-one-out cross-validation to evaluate the effectiveness of the proposed method in terms of predicting diabetes type Type I true negative and Type II false positive error rates were 0.1256 and 0.1147 respectively Therefore total error rate was 0.2403 Since the optimal model based on AIC may be easily changed by the 224uctuation of the data signi\223cant SNPs may be excluded from the optimal model Therefore we next checked the 2nd or lower ranked models Table 3 shows the SNPs included in the 1st to 20th ranked model by GA We observed that the seven SNPs detected in the optimal model frequently appear in the lower ranked models i.e SNP 1  267\267\267  SNP 7 appear 8 9 16 17 13 20 and 14 times respectively Although almost all the other SNPs appear a few times three times or less we found a SNP at the 5417th base which is not contained in the optimal model appears six times in Table 3 This SNP namely SNP 8 isin ND 2 NADH dehydrogenase subunit 2 and appears 223rst in the 3rd optimal model We found an interesting behavior of SNP 8  In the 3rd model the main effect of SNP 8 is weak  001  212 0  1999  p value 0  1207  the interaction between SNP 8 and age is however fairly strong  004 2  5578  p value 0  1179  Since the differences of AIC among these 20 models are not large we need to pay attention to the SNPs not contained in the optimal model when using these results to the group recognition or prediction of binary traits 4 Discussion We proposed the combination of the logistic regression and the genetic algorithm for the association study of binary disease trait By the use of logistic regression we could directly incorporate the continuous effects of environments into the model without loss of information Of course other conventional methods also can incorporate the environmental effects but the categorization is required to transfer the continuous effects into some discrete classes by some thresholds and causes the loss of information Actually we succeeded in detecting SNPs which are not significant as a single locus but have strong interactions to the environmental factor Therefore we expect to utilize the information of the environments more effectively for the further discoveries in the association analysis We consider the following problems of our method as future work 1 We adopted AIC as the criterion for the model selection As we mentioned in the experiment section the optimal model detected by AIC may be changed by the 224uctuation of the observed data Therefore we have to pay attention to the 2nd or lower ranked models A possible way o do this is constructing a posterior distribution of the model using the frequency of the SNP appearance 2 We used a single SNP as a variable of the logistic regression model but it is often the case that closely linked SNPs yield highly correlated information because of extensive linkage disequilibrium Therefore we need to select a subset of adjacent SNPs and use them as a single variable of the regression model In that case we need to construct a method of haplotype selection and estimation into the SNP search of Proceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


 e  Detected SNPs in the top 20 models rank location of SNPs AIC 1 6455 11647 14470 15874 16217 16261 16291 192.77 2 6455 14470 15874 16217 16261 16291 16519 193.57 3 5417 14470 15874 16217 16261 16291 16519 194.57 4 4386 15874 16217 16261 16311 16519 194.72 5 6455 14470 15874 16217 16261 16291 194.84 6 11647 14470 15874 16217 16261 16291 16519 195.19 7 4386 5417 14470 16261 16519 195.44 8 6455 11647 14470 15874 16261 16291 195.81 9 5417 11647 12771 15874 16217 16261 196.01 10 6455 11647 14470 16217 16261 16291 196.17 11 12771 15874 16261 16311 16519 196.27 12 5417 11647 14470 15874 16261 16291 196.64 13 12771 14470 15874 16129 16217 16261 16311 196.90 14 14470 15874 16217 16261 16291 196.96 15 5417 14470 15874 16217 16261 16291 197.15 16 5417 11647 14470 15874 16217 16261 16291 197.23 17 6455 11647 14470 15874 16261 16291 197.67 18 6455 14470 15874 16261 16260 16291 198.15 19 11647 12771 15874 16260 16261 16519 198.16 20 6455 14470 16217 16261 16291 198.84 GA in the future work 3 The use of the logistic regression has many other merits We can statistically evaluate the accuracy and reliability of the estimation because the result is provided as the posterior probability We also can extend our model for handling nonlinear behavior of genetic or environmental factors Furthermore we can extend the conventional two-group recognition susceptible or not susceptible to more precise multi-group recognition We would like o investigate these topics in our future paper References 1 H Akaike Information theory and an extension of the maximum likelihood principle Proc 2nd Inter Symp on Information Theory Petrov B.N and Csaki F eds Akademiai Kiado Budapest 267-281 1973 2 H Akaike A ew look at the statistical model identi\223cation IEEE Trans Autom Contr AC-19 716-723 1974 3 I.C Gray D.A Campbell and N.K Spurr Single nucleotide polymorphisms as tools in human genetics Hum Mol Genet 9 2403-2408 2000 4 K Hao X Xu N Laird X Wang and X Xu Power estimation of multiple SNP association test of case-control study and application Genetic Epidemiology 26 22-30 2004 5 E.S Lander and N Schork Genetic dissection of complex traits Science 265 2037-2048 1994 6 P McCullagh and J.A Nelder Generalized Linear Models  2nd ed Chapman and Hall/CRC London 1989 7 M.R Nelson S.L.R Kardia R.E Ferrell and C.F Sing A combinatorial partitioning method to identify multilocus genotypic partitions that predict quantitative trait variation Genome Research 11 458-470 2001 8 N Risch and K Merikangas The future of genetic studies of complex human diseases Science 273 1516-1517 1996 9 R.J Sigal A Doria J.H Warram and A.S Krolewski Codon 972 polymorphism in the insulin-receptor-substrate1 gene obesity and risk of non-insulin-dependent diabetes mellitus J Clin Endocrinol Metab 81 1657-1659 1996 10 R.S Spielman R.E McGinnis and W.J Ewens Transmission test for linkage disequilibrium the insulin gene region and insulin-dependent diabetes mellitus IDDM Am J Hum Genet 52 506-513 1993 11 R.S Spielman and W.J Ewens The TDT and other familybased tests for linkage disequilibrium and association Am J Hum Genet 59 983-989 1996 12 A Wille J Hoh and J Ott Sum statistics for the joint detection of multiple disease loci in case-control association studies with SNP markers Genetic Epidemiology 25 350-359 2003 13 H Zhang and G Bonney Use of classi\223cation trees for association studies Genetic Epidemiology 19 323-332 2000 14 http://www.giib.or.jp/mtsnp/index_e.html Proceedings of the Fourth IEEE Symposium on Bioinformatics and Bioengineering \(BIBE\22204 0-7695-2173-8/04 $ 20.00 \251 2004 IEEE 


512 The T-norms min produce 2.0 examples of A&amp;B, 0.6 of A&amp;+3, and 0.6 of -A&amp;-B. The corresponding values for the product T-norm are 1.7, 0.3, and 0.3. The measures yield prod I 0.85 I 0.7 I 0.35 I 5.7 I 0.0 1 0.0 As with the data in TI, there is a notable difference between the confdence measures with the two T-norms. There are also differences in the ratio of examples to counterexamples and the interest measures. The analysis of the examples generated by the minimum indicate that the association A =$ B may he of interest. However, with the examples produced by the product T-norm, both of the interest measures are neutral One fnal example considers tuples tuples with no discem able pattem af T m={a,b,p with parameter p .  Setting p to 0 produces the minimum and 1 produces the product. For a particular set of data, the optimal T-norm could he identifed by Ending the value of the parameterp E [0,1] that maximizes the validity measure under consideration. The optimization could use either algebraic or numeric methods, hut the latter seem more suitable for the analysis of large data sets VI. CONCLUSION The determination of the degree that a tuple is an example of a fuzzy rule or association depends upon the underlying relationship between the attributes. In data mining, this re lationship is not known a number of possible methods for determining 'examplehood' should be considered. When the attribute domains are covered or partitioned by the predicates the relationship between joint and marginal distributions im pose restrictions on the suitability of T-norms to evaluate the degree a tuple is an example of an association. The parametric representations of T-norms presents the possibility of simultaneously learning both the relationship between the attributes and the proper assessment of the number of examples and counterexamples REFERENCES I] C. Alsina. On a family of connective for fuzzy sets. Fuzzy Sets and Systems, 16:231-235, 1985 17.1 P. Bosc, D. Dubois, 0. PriveR H. Prade, and M. de Calm&amp;. Fuzzy summarization of data using fuzzy cardinalities. In Pmceedings of the Ninth Intematioml Conference IPMU 2002, Pages 1553-1559, Annecy, . France, 2002 3] S .  Brin. R. Motwani, and C. Silverstein. Beyond market baskets: Gner alizing association N I ~ S  to correlations. In SIGMOD 1997, Proceedings ACM SIGMOD Intemtionol Conference on Management of Doto, pages 265-276, May 1997 141 K C. C. Chan and W.-H. Au. An effective algorithm for mining inter esting quantitative association rules. In Selected Areas in Cryptography pages 88-90, 1997 51 1. M. de Gruaf, W. A. Kosters, and I. J. W. Wilteman. Interesting fuzzy association rules in quantitative databases. Lecture Notes in Computer Science, 2168:14&amp;152, 2001 6] M. Delgado, N. Marin, D. S&amp;chez, and M. A. Vila. F w y  association rules: General madel and applications. IEEE Tromoctiom on Fuuy System, pages 21k225, 2003 7] M. Delgado, D. Sanchez, and M. A. Wa. Fuzzy cardinality based evaluation of quantifed sentences. Intemtionol Joumal of Appmximote Rearming, 2323-66, 2000 8] D. Dubois, E. Hullermeier, and H. Prade. Toward the representation of imolication-based fuuv rules in tenns of C ~ ~ S P  rules. In Pmceedinns of r the Joint 9th IFSA C o ~ r e s s  and NAFIPS ZOth'lntemational Confe&amp;i pages 1592-1597, Vancouver. July 2001 9] D. Dubois, H. prade, and T. Sudkamp. A discussion of indices for the evaluation of fuzzy associations in relational databases. In T. Bilgic B. De Baets. and 0. Kavnak. edilors. Pmceedinms of the Ek-vemh IFSA World Congkss, pages i l l - I  IS, Istanbul, June"2003 lo] Tzung-Pei Hang, Kuei-Ying Lin, and Shyue-Liang Wang. Fuzzy data mining for interesting generalized association rules. Fuuy Sets Sysr 138\(2 I l l  E. Hullermeier. Fuzzy association rules semantic issues and quality 


I l l  E. Hullermeier. Fuzzy association rules semantic issues and quality measures. In B. Reusch, editor, Computotianal Intelligence: Theory ond Applicotions, LNCS, pages 38W391. Springer-Verlag, Berlin, 2001 i2] M. Klemettinen, H. Manila, P. Ronkainen, H. Toivonen. and A. 1 Verkamo. Finding interesting rules fmm large sets of discovered association rules. In N. R. Adam, B. K. Bhargava, and Y. Yesha editors, Third Intemtionol Conference on Infomt ion and Knowledge Management \(CIKM'94 I31 Y. Kodratoff. Comparing machine leaming and knowledge discovery in databases: An application to knowledge discovery in texts. In G. Paliouras, V. Karkaletsis, and C. D. Spympoulas, editors, Machine Leoming nnd Its Applications, volume 2049 of Lecture Notes in Com puter Science, pages 1-21. Berlin, 2001. Springer-Verlag 5 I41 C. M. Kuok A. W.-C. Fu, and M. H. Wong. Mining fuzzy association rules in databases. SIGMOD Record. 27\(1 IS] 1. H. Lee and H. L. Kwang. An extension of association rules using fuzzy sets. In Pmceedings of IFSA 1997, pages 399-402, Prapue, lune 1997 16] M. I. Marrin-Bautista D. Sanchez, M. A. Vila, and H. m e n .  Measuring effectiveness in fuzzy information reldeval. In Flexible Query Answering in Fuuy Informtion Retrieval, pages 396-402. Physic-Verlag, 2001 171 R. 1. Miller and Y. Yang. Association rules over interval data. In SIGMOD 1997, Pmceedings ACM SIGMOD lntemntionol Conference on Monogement of Data, pages 452451, Tuscan, AR, May 1997. ACM Press 18] G. Piatetsky-Shapim. Discovey. analysis and presentation of strong rules. In G. PiatetsQ-Shapim and W. Frawley, editors, Knowledge Discovery in Databases, pages 229-248. AAAllMIT Press, Menlo Park CA, 1991 I91 P. Smets. Elementary semantic operators. In k. R. Yagez editor, Fuuy Set ondPossibility Theory: Recent Advances, pages 247-256. Pergamon Press, 1982 20] R. Srikant and R. Agrawd. Mining quantitative association rules in large relational tables. In H. V. Iagadish and 1. S. Mumick, editon Pmceedings of the I996 ACM SIGMOD Intemtioml Conference on Monogemnt of Dola, pages 1-12, Montreal, 1996 211 T. Sudkamp and R. J. Hammell n. Interpolation. completion. and l e m ing fuzzy rules. IEEE Transactions on System, Man, and Cybernetics 24\(2 221 P. Tan, V. Kumar, and J .  Srivastava. Selecting the right interestingness measure for association pauems. In Pmceedings of the Eight ACM SIGKDD Intemtionol Conference on Knowledge Discovery and Dora Mining, pages 3241.  Edmonton. July 2002 231 L. A. Zadeh. Pmbabilily measures of fuzzy Sem. Jouml of Mnrhew icnl Analysis and Applications, 23421427, 1968 13 pre></body></html 


4J H. Fu and E. Mephu Nguifo. Partitioning large data to scale up lattice-based algorithm. In Proceedings ofICTAI03 pages S37-S41, Sacramento, CA, November 20 03. IEEE Press SJ H. Fu and E. Mephu Nguifo. How well go lattice algo  rithms on currently used machine learning testbeds? In 4emes journees d' Extraction et de Gestion des Connais  sances, pages 373-384, France, 20 04 61 B. Ganter and R. Wille. Formal Concept Analysis. Mathe  matical Foundations. Springer, 1999 7J J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. Naughton, and P. A Bernstein, editors, 2000 ACM SIGMOD Intl. Conference on Management of Data, pages 1-12. ACM Press, OS 2000 Data file Objects Items Min support FCI PFC \(msec msec audiology 26 110 1 30401 1302 8563 soybean-small 47 79 1 3541 516 431 lung-cancer 32 228 1 186092 21381 279689 promoters 106 228 3 298772 120426 111421 soybean-large 307 133 1 806030 357408 364524 dermatogogy 366 130 50 192203 20204 18387 breast-cancer-wis 699 110 1 9860 3529 1131 kr-vs-kp 3196 75 1100 2770846 1823092 483896 agaricus-Iepiota 8124 124 100 38347 34815 1462 connect-4bi.data 67557 126 1000 2447136 1165806 65084 Table 1. Experiments on real data.\(FCI means frequent closed itemsets. msec means milliseconds For Ref., + means PFC is faster than CLOSET Data file Min support FCI PFC \(msec msec Worst16 1 65534 571 470 271 9 Worst17 1 131070 1112 1002 541 9 Worst18 1 262142 2243 2174 1091 9 Worst19 1 524286 4576 4466 2213 10 Worst20 1 1048574 9243 9484 4606 10 Worst25 20 68405 2103 66916 451 11 Worst25 19 245505 6099 1095065 1552 11 Worst25 18 726205 15452 10235287 4486 11 Worst25 17 1807780 33348 / 10755 11 Worst25 15 7119515 102237 / 39296 11 Worst30 25 174436 6980 426964 1302 12 Worst30 20 53009101 1029771 / 344035 12 Worst50 47 20875 1132 1042 422 14 Worst50 45 2369935 227207 / 29102 14 Worst60 57 36050 7320 3205 821 15 Worst60 56 523685 82938 1665715 9123 15 Worst60 55 5985197 772210 / 92102 15 Worst70 68 2485 1102 190 121 15 Worst70 67 57225 18096 9483 1933 15 Worst70 66 974120 242138 / 26398 15 Table 2. Experiments on the worst case data 8] S. Kuznetsov and S. Obiedkov. Comparing performance of algorithms for generating concept lattices. lETAI Special Issue on Concept Lattice for KDD, 14\(2/3 9j E. Mephu Nguifo, M. Liquiere, and V. Duquenne. lETA Special Issue on Concept Lattice for KDD. Taylor and Fran  cis, 2002 IOj N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient mining of association rules using closed itemsets lattices lournal of Information Systems, 24\(1 II j 1. Pei, 1. Han, and R. Mao. CLOSET: An efficient algo  rithm for mining frequent closed itemsets. InACM SIGMOD Workshop on Research Issues in Data Mining and Knowl  edge Discovery, pages 21-3 0, 200 0 12] 1. Wang, 1. Han, and 1. Pei. Closet+: Searching for the best strategies for mining frequent closed itelnsets. In In Pro  ceedings of the Ninth ACM SIGKDD International Confer  ence on Knowledge Discovery and Data Mining \(KDD'03 Washington, DC, USA, 2003 13] M. I. Zaki and C.-I. Hsiao. CHARM: An efficient algorithm for closed item set mining. Technical Report 99-10, Rensse  laer Polytechnic Institute, 1999 


laer Polytechnic Institute, 1999 pre></body></html 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



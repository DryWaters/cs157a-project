FOOM A Fuzzy Object-Oriented Modeling for Imprecise Requirements Jonathan Lee and Nien-Lin Xue Software Engineering Lab Department of Computer Science and Information Engineering National Central University Chungli Taiwan  yjlee,nien}@seOl .csie.ncu.edu tw Abstract One of the foci of the recent develop ment in object-oriented modeling OOM has been the extension of OOM to fuzzy logic to capture and analyze informal requirements that are imprecise in nature In this paper a novel approach to object oriented modeling based on fuzzy logic is proposed to formulate imprecise requirements 
along four di mensions 1 to extend a class by grouping objects with similar properties into a fuzzy class 2 to en capsulate fuzzy rules in a fuzzy class to describe the relationship between attributes 3 to evaluate the membership function of a fuzzy class by considering both static and dynamic properties and 4 to model fuzzy associations between classes The proposed ap proach is illustrated using the problem domain of a meeting scheduler system Keywords Fuzzy logic imprecise requirements object-oriented modeling technique I INTRODUCTION One of the foci of the recent 
developments in objecboriented modeling OOM has been the ex t,ension of OOM to fuzzy logic to capture informal requirements that are imprecise in nature Rum baugh and his colleagues have argued that OOM is a way of thinking about problems using models orga nized around real-world concepts which are usually espressed in natural languages As Zadeh pointed out in 14 it is evident that almost all concepts in or about natural languages are almost fuzzy in na ture Several researchers such as Dubois et al 4 George et 
al 6 and Lano ll have further advo cated that object classes with fuzzy memberships values are therefore a natural representation frame work for real-world concepts As a continuation of our previous work 1121 in using fuzzy logic as a basis for formulabing im precise requirements we propose in the paper a fuzzy object-oriented modeling technique FOOM t.o capt,ure and analyze imprecise requirements In FOOM we have identified several kinds of fuzziness that are required to model imprecise information in volved in user requirements 1 classes 
with impre cise boundary t,o describe a group of objects with similar attributes similar operations and similar re lationships 2 rules with linguistic terms that are encapsulated in a class to describe the relationships between attributes 3 ranges of an attribute with linguistic values or typical values in a class to define the set of allowed values that instances of that class may take for the attribute 4 the membership de gree \(i.e ISA degree between an object and a class and between a subclass and 
its superclass i.e AKO degree can be mapped to the interval O 11 and 5 associations between classes that an object instance may participate to some extent In the next section different kinds of fuzziness rooted in FOOM are fully discussed in Section 11 Related work is described in Section 111 The ben efits of our approach is summarized in Section IV The notations used throughout the paper is an ex tension of Unified Modeling Language UML 11 FUZZY OBJECT-ORIENTED MODELING A Inside a Fuzzy Class Traditionally 
a class is used to describe a crisp set of objects with common attributes common opera tions and common relationships In order to model the impreciseness rooted in user requirements we extend a class to describe a fuzzy set of objects called a fuzzy class in which objects may have similar attributes similar operations and similar re lationships for example a set of interesting books or a class of clever students In the meeting scheduler syst,em the class ImportantPartmpant is modeled as a fuzzy class that is 
a part,icipant may be an important one to a degree A fuzzy class in FOOM is an encapsulation of a number of properties that can be classified as static properties or dynamic ones Static properties are viewed as integral features of an object t,hat exist for its lifetime including identifier attributes and operations On the other hand dynamic properties approach SI We have adopted this classification scheme from Zenith 0-7803-4453-7/98 1 0.00 0 1998 IEEE 345 


2 A Fig 1 An Example of a Fuzzy Class are optional for an object and can be short-lived such as fuzzy rules2 and fuzzy relationships Since a fuzzy class is a group of objects with simi lar static properties i.e attributes operations\and similar dynamic properties i.e relationships and rules the membership degree of an instance to a fuzzy class is dependent on the properties especially the values of attributes and the values of link at tributes In our example the degree that a person belongs to the class ImportantParticipant depends on his status and his role in the meeting he attends The domazn of an attribute is the set of all values the attribute may take irrespective of the class it falls into whereas the range of an attribute in a class is defined as the set of allowed values that a member of a class may take for the attribute The range of an attribute ai in the class C is denoted as R.\(ai C In FOOM the fuzziness in the range of an attribute in a class may be due to either a linguistic term or a typical value e A class may be fuzzy for the linguistic values its attributes can take For example the class YoungMan has a fuzzy range for the attribute age since a person may take yomg or very young as values for his age The range of an attribute is fuzzy because some of its values are deemed as atypical i.e less possible than other values there fore each value the attribute may take is as sociated with a typical degree3 In our exam ple the class ImportantParticipant has a fuzzy range student/0.4 sta f f/0.7 facultyll for the attribute status which means that a faculty is typically an important participant and a stu dent is an important participant with a typical degree of 0.4 Using fuzzy rules is one way to deal with impreci sion where a rule's conditional part and/or the con clusions part contains linguistic variables Fuzzy rules are an optional feature for a fuzzy class in FOOM and are thus classified as a dynamic prop erty Fuzzy rules can be used to describe the internal relationship between attributes inside a class For example rules in Figure 1 describes the relationship between the attributes role and padicipant impor tance B Fuzzy Classification We extend crisp class memberships to fuzzy class memberships by allowing the existence of perceptual fuzziness The notion of inheritance and its impact on the perceptual fuzziness are also elaborated B.l Subclassing and Subtyping Inheritance plays an important role in object oriented analysis and design Generally, inheritance is separated into two different concepts implemen tation inheritance and subtyping inheritance Im plementation inheritance refers to the sharing of representation and implementation code between a subclass and its superclass In contrast subtyping refers to some kind of conformance between a sub class and its superclass in terms of their interfaces Subclassing is concerned with how a class is im plemented that is a new class is constructed from a parent class by reusing some or all of the par ent's operations l In general a subclass can be constructed through extension redefinition and re striction On the other hand a type defines an ab stract interface and can be viewed as the specifica tion of objects behavior In the specification level the subtype-supertype relationship can be defined in terms of the weak form of the principle of substi tutability Subclassing and subtyping are not necessarily re lated l namely, a subclass may be of different typ ing relationships subt.ype same type or supertype to its superclass In FOOM a subclass is guaran teed to be either a subtype or a same type of its superclass that is the weak form of the principle of substitutability is maintained B.2 R.elationship between Classes and Subclasses As the weak form ofsubstitutability is maintained in FOOM a subclass is constructed through esknd ing new operations redefining the inherited opera tions or modifying the inherited attribute ranges In the first two cases since an instance of a sub class possesses all properties that its superclass has it is also an instance of its superclass namely, the AKO degree is equal to 1 In the case of modifying the inherited attribute ranges the attribut,e range in the superclass may include the attribute range in the subclass to some extent that is an instance Encapsulating rules in an object is also proposed in SOMA 181  The notion of typical values is adopted from 4 of the subclass can be an instance of its superclass 346 


3 to a degree Therefore we will focus our attention on the case of modification for computing the AKO degree below The perceptual fuzziness is investigated by eval uating its static properties and dynamic properties The criticality of an attribute indicates the relevance of the attribute tp a perceptual fuzziness For ex ample, the attribute participant importiince is more relevant than the attribute status while examining if a participant is an important one therefore it is as signed a higher criticality To determine the critical ity of attributes we utilize the Analytic Hierarchy Process which compares pairwise attributes accord ing to their relative criticality We use CRI\(ai C to denote the criticality of an attribute a to the perceptual fuzziness for the fuzzy class C The membership degree of a class in its superclass has to account for the criticalities of the attributes and the degree of inclusion of the range of each at tribute of the class in that of its superclass Sup posed that the class C is a superclass of the class D The membership degree of the class C in the class D is denoted as AKO\(D C and defined as AKO D C  CRI\(a C x AKO D C a,EAtt\(C E EA C bJEAtt C,EI  where A\(C is the set of classes associated with C Att\(C is the set of attributes in C and Att C Ek  is the set of link attributes in the associ at,ion  C Ek  which is established between the classes C and Ek The degree AKO,,\(D C is the AKO degree with respect to wrt the attribute ai and AKObj\(D,C refers to the AKO degree wrt to the link attribute bj Both static properties object attributes and dynamic properties link attributes are required for computing the membership degree of an object in a class To calculate AIiO,,\(D C we need to examine whether the fuzziness of R\(ai,C is of the type of linguistic terms or typical values In the case of linguistic terms, the membership degree is defined as the fuzzy inclusion of R\(ai D into R\(ai C AKO D C  INCr\(R\(a C a D The degree of inclusion of fuzzy sets is defined as In the case of typical values the membership de gree is defined by a fuzzy inclusion based on Godel's fuzzy implicat,ion 4fi-Oa 0,C  INCG\(R C a 0 The fuzzy inclusion INCcjillB between the fuzzy sets A and I3 is defined as INCG\(AIB  inf~\(~\(lg  PA\(S Note that INC\(R\(a;,C ai,D  1 if the attribute a in the subclass is included in the corresponding range of its superclass More specif ically the subclass inherits attributes from its par ents by specializing their ranges Similarly to calculate AKOb D C we also need to examine whether the fuzziness of R\(bj   C Ek   is of the type of linguistic fuzziness or typical val ues In the case of linguistic terms, the membership is defined as the fuzzy inclusion of R\(bj   D Er  into R\(b   C Ek  tfS,PR\(a,,D S 5 PR\(a,,C S that is the range of AKOb,\(D,C  INCI\(R\(b C,Ek  b D,Ek  In the case of typical values the degree is defined as INCG\(R  c,Ek  b  D,Ek  B.3 Relationship between Classes and Objects The class membership between an object and a class is crisp that is the ISA degree of an object to a class is either 1 or 0 In FOOM a perceptual fuzziness between an object and a class is allowed An object may belong to a class to a degree In the meeting scheduler system a person may belong to the class ImportantPartzcapant to some extent The perceptual fuzziness of an object to a class is investigated by evaluating its static properties and dynamic properties In our example the member ship degree of a person to the class ImportantPartac zpant can be obtained by checking his status and his partzczpant zmportance in the meeting he attends The membership degree of an object 2 in a fuzzy class G is denoted as ISA\(2 C and defined as ISA\(z,C  CRl\(a,,C x ISA,,\(z,C a,EAtt\(C  CRI\(b,.C x ISAbJ\(z,C E EA C b E Att C,EI  The degree ISAa,\(z C is the membership degree of the object z in the class C with respect to wrt the attribute ai and ISAbJ z C refers to the mem bership degree wrt to the link attribute bj To calculate ISA 2 C we also need to examine whether the fuzziness of R\(a;,C is of the type of linguistic terms or typical values In the case of linguistic terms the membership degree is defined as the degree of inclusion of the value of ai of x int.0 the range of ai in C that is IS z c  I]VCr\(R\(a C R Z where V\(a z is the value of z for a In the case of typical values the membership degree is defined To calculate the membership degree wrt to a link attribute we also need to check to see whether the as PR\(a,,C aiJ 347 


4 Fig 2 An Exampk of Perceptual Fuzziness-for ISA Rela tionship fuzziness of the range of the link attribute\222s values is of the type of linguistic terms or typical values In the case of linguistic terms the membership degree is defined as the degree of inclusion of the value that bj takes for the link  x e  into the range of bj in  C Ek  where e is an instance of Ek connected with the object x ISAsj\(x C  INCr\(R\(a  C Ek  a  z e  In the case of typical values the degree is defined as In our example supposed that we have the follow PR\(a C,Ek  1 x ing information in the meeting scheduler system R\(status IP  studentl0.4 stafjl0.6, facultyll.0 R\(pi  IP Meeting   important V\(status, John  student V\(roie, John  stajf V\(pi  John MlOl   less important CRl\(status IP  0.3 CRl\(pi IP  0.7 where pi is the abbreviation of the attribute participate importance and IP is the abbreviation of the class Importantparticipant To calculate the membership degree of a participant John to the class IP abbreviated as IF we first calculate the mem bership degrees wrt the attributes status and pi ISA,t,t,,\(John IP  fy~~~~~~,lp student  0.4 and ISA John IF\221  INC\(important1iess important  0.6 Therefore we have ISA\(John IP  0.54 It should be noted that the importance degree of John is dynamically determined by the meeting he at tends The example above describes that 223John is a more or less important participant since the degree is 0.54 for the meeting M101\224 C Associations In traditional object-oriented approaches only crisp associations are introduced namely an object either participa.tes in an association or not at all An association A between classes C1 and Cz can be defined as a set of links A\(CI,GZ   Z.Y  E ci E Cz An association in FOOM is defined by a set of links and their corresponding degree of participatzon reflect the intensity that 2 and y participate in the association Supposed that 4 is an association be tween class C1 and C.\221 we define A\(CI,C2  l\(\(z.Y z,Y E cl,Y E c2 where p~\(z y is the degree of participation of the link  x,y  In our example if the degree of par ticipation prefer\(i~,~ocation  John L102 it means that the degree John prefers the location L102 is 0.9 111 RELATED WORK A number of researchers have reported progress towards the successful integration of fuzzy logic and object-oriented modeling which can be classified into three categories based on their intended mod eling purposes A Knowledge representation for AI systems Lano has proposed to combine fuzzy reasoning and object-oriented representation for the real-world information ll A knowledge base is organized as a class hierarchy for representing concept categories each class corresponds to a fuzzy set whose mem bership functions is the proximity metric defined for the class Learning is the process that transforms a knowledge base and a new example to a new knowl edge base To support an approximate reasoning in sys tems based on prototypical knowledge representa tion Torasso and Console have defined a formal ism for the representations and a general evaluation mechanism to deal with the form of knowledge 13 Each frame has three kinds of weighted attributes necessary sufficient and supplementary The evalu ation mechanism is based on fuzzy logic the fuzzy match between prototypical description and sets of data is based on possibility theory and the relevance measure of each slot B Data modeling for database systems In 4 Dubois and Prade have advocated that classes can be intensionally described in terms of at tributes which are distinguished between the range of allowed values and the range of typical values The degree of inclusion between a class C1 and a subclass Cz is computed by comparing the ranges or the typical ranges of C1 with the ranges or the typical ranges of Ca Three kinds of inheritance are proposed typical inheritance normal inheritance and atypical inheritance In 9 the problem of object recognition is viewed as a classification problem which is characterized by an objected-oriented knowledge representation and control strategies based on fuzzy pattern matching procedures Taxonomies of classes are represented by hierarchies of frames Which class matching the unknown object is decided by fuzzy matching theory based on possibility theory The matching process is seen as a quantification of similarity and differ 348 


5 ences of both objects and the computation of these measures strongly depends on the types of the pro totypes and object fields and the weight of each field Bodogna et al 2],propose a Fuzzy Object Ori ented model for management of crisp and fuzzy data Their work develops a fuzzy graph-based data model which intends to generalize a graph model so that imprecision nd uncertainty can be-managed at different levels To formulate imprecise queries and retrieve precise or imprecise object with a degree of plausibility associated with them fuzziness in man aged in two level imprecise in the data themselves and knowledge of the data i.e uncertainty in the information on the data C Object-oriented modeling for conventional sofl ware systems George et al have utilized the ranges of fuzzy values of classes and objects for computing the de gree of inclusion and membership respectively 6 To measure the class memberships a similarity met ric is formulated to measure the nearness between at,tributes\222 values in a superclass and its subclasses Graham 7 has focused on the derivation of un known values of attributes through the use of a kind-of relation AKO generalized modus ponen and defuzzification techniques 7 In Graham\222s work the notion of an object is extended to that of a fuzzy object in two ways 1 attributes\222 values may be fuzzy and 2 AKO is a matter of degrees The AKO degree between classes is assumed to be known by a system and unknown attributes\222 values are derived through AKO generalized modus ponen and defuzzification techniques In lo the focus has been on the representation of uncertain information based on a generalized fuzzy sets notation Gyseghem et al represent fuzzy in formation as fuzzy sets and uncertainty by means of generalized fuzzy set A generic class Fuzzy-Set is introduced to capture fuzziness associated with at,tributes Uncertain information is modeled by a kind of generalized fuzzy sets in which each element of the universe is associated with a fuzzy truth value p,ltrue n false However none of these work is devot.ed to the development of an object-oriented technique for in formal requirements but either t,o the formulation of class memberships e.g 4 TI or t,o the rep resenta.tion of prototypical knowledge as in 13 9 Furthermore features of object orientation are not fully explored in these work Types of fuzziness in consideration are also somewhat limited IV CONCLUSION As was pointed by Borgida et al 3 a good re quirement modeling approach should take the prob lem of describing natural kinds into account fur thermore Zadeh have indicated that almost all con cepts in or about natural languages are almost fuzzy In this paper we have proposed an approach to in corporating fuzzy concepts into object-oriented sys tems for modeling imprecise requirements Our ap proach offers two major benefits 1 extending tra ditional object-oriented techniques by incorporating different kinds of fuzziness that. are rooted in user requirements and 2 providing a more flexible ap proach to evaluating the class memberships by tak ing both static and dynamic properties into account ACKNOWLEDGE This research was supported by National Sci ence Council Taiwan, R.O.C under grants NSCS\222i 22 13-E008-0 19 REFERENCES B.S Blair Object-Oriented Languages Systems and applications Pitman 1991 G Bordogna D Lucareila and G Pasi 4 fuzzy object oriented data model In Proceedings of the Third IEEE Conference on Fuzzy Systems pages 313-318 1994 A Borgida S Greenspan and J Mylopoulos Knowl edge representation as the basis for requirements speci fication Computer pages 82-91 April 1985 D Dubois H Prade and J.P Rossazza. Vagueness typ icality and uncertaintyin class hierarchies International Journal of Intelligent Systems 6:161-183,1991 Z.P Kemp et al Zenith system for object management in distributed multimedia design environments Infor mation and Software Technology 34\(7 1992 R George R Srikanth F.E Petry and B.P Buckles Uncertainty management issue in the object-orient.ed data model IEEE Transitions on Fuzzy Systems I Graham Fuzzy objects Inheritance under uncer tainty In Object Oriented Methods pages 103-433 Ad dison Wesley 1994 I Graham Migration using SOMA A semantically rich method of object-oriented analysis Journal of Object Oriented Programming pages 31-42 February 1993 C Granger An application of possibility theory to ob ject recognition Fuzzy Sets and Systems 28\(3 1988 N.V Gyseghem R.D Caluwe and R Vandenberghe UFO Uncertainty and fuzziness in an object-oriented model In proceedings of the Internation1 Conference on Fuzzy Systems pages 773-778 1993 I Lano Combining object-oriented representations of knowledge with proximity to conceptual prototypes In Proceedings of Computer Systems and Software Engs neering pages 442-446 1992 J Lee and J.Y Kuo A ne approach to require ments trade-off analysis for complex systems to ap pear IEEE Transactions on Knowledge and Data En gineering 1998 R.B Terwilliger and R.H Cambell Please Executable specifications for incremental software develoment Thi Journal of Systems Software 10:97-112 1989 L..4 Zadeh Test-score semantics as a basis for a com putational approach to the representation of meaning Literacy Linguistic Computing 1:24-35 1986 4 2 1996 349 


Y A-LAA I I o U c o m o U c a Y I LAAA I o U c a m o U c o I t 1 1548  


processing elements Standard LAN technologies were also immature so that we were forced to design and implement our own interconnection networks Now that the circumstances have dramatically changed it is reasonable to use commodity PCs as processing elements and ATM technology for interconnection With ATM connected PC clusters we have only to develop software for parallel query processing So we ported the system software developed for the SDC to our PC cluster system Currently we emulate the device driver layer of the SDC code by user level threads POSIX thread on Solaris 2.5.1 operating system We are also planning kernel level implementation for maximal efficiency Figure 4 depicts the global architecture of our database server Queries issued from the user applications are compiled and optimized at the front-end machine to produce the executable code We take the compiled mode where the generated code consists of the processor\220s native code instead of the interpreted mode for efficiency and flexibility Currently however the SQL compiler and optimizer are not yet ready and the work has to be done by hand That is we determine a plan for the query and write a C code for the plan Execution of a query is initiated by the coordinator program The coordinator broadcasts the generated code to each PC node where a server process for query execution is running Figure 5 shows the structure of the server process called database kernel The database kernel consists of several permanent threads and one of such threads named the dbk server interacts with the coordinator It creates a user thread for executing the code passed from the coordinator and monitors exceptional events from the user thread or the coordinator The exceptional conditions from the user thread are reported to the coordinator and cause user threads running at other nodes to abort The generated code contains only parts specific to the corresponding query such as the initialization and finalization code according to the execution plan and evaluation code for predicates in the query Commonly used code such as hash table manipulation and various conversion routines are contained in the database kernel and are dynamically linked to the target code before its execution Each of the user threads then sets up the I/O streams and registers an operator to each input stream as a callback function Another permanent thread dispatcher keeps polling all the registered input streams and evaluates callback functions with data delivered by I/O threads for disk and network Thus most of the processing is done within the context of the dispatcher and the user thread suspends until the EOF condition is met This model of 217\217centralized I/O\220\220 is designed so as to support multiple queries running at the same time Once execution starts the PCs perform their operations without any centralized control Barrier synchronizations are encapsulated within open and close operations of network connections to simplify the code On completion of the network open operation  dbk  connect  all the nodes are guaranteed to be ready for receiving data and on completion of the network close operation  dbk shutdown  it is guaranteed that no more data will arrive 3.3 Performance evaluation using a TPC-D benchmark query TPC-D benchmark consists of 17 complex queries issued to a database which contains eight Among them the most time consuming query is the query 9 which requires five join operations Figure 6 shows SQL description of the query Here we examine the execution times of this query with different plans We generated a 100GB test database shown in table 2 using a modified version of the dbgen program and partitioned tuples of each relation horizontally over the 100 disks according to the hash values of the primary key In fact NATION and REGION are not partitioned but replicated because they are quite small We didn\220t create any indexes to force the full scan of the relations because the indexes wouldn\220t help ad-hoc queries Figure 7 depicts an execution plan of the query 9 with the right-deep tree First four hash tables are 7 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


select Nation Year sum\(Amount as Sum_Profit from select N_Name as Nation extract\(year from O_Orderdate as Year L_Extendedprice  1 L_Discount PS_Supplycost  L_Quantity as Amount from part supplier lineitem partsupp orderx nation where S_Suppkey  L_Suppkey and PS_Suppkey  L_Suppkey and PS_Partkey  L_Partkey and P_Partkey  L_Partkey and O_Orderkey  L_Orderkey and S_Nationkey  N_Nationkey and P_Name like 222%green%\222  group by Nation Year order by Nation Year desc Figure 6 SQL description of TPC-D query 9 built from relations PART PARTSUPP SUPPLIER and ORDER and then they are probed in sequence by LINEITEM Because only a part of the attributes are necessary for the query the tuples shrink so much that whole hash tables can fit in memory while all tuples are selected from three of the relations 000 in the plan represents the aggregation the sum by group which is first performed independently at each node before gathering the results at the master node node 0 to lower the network traffic The final join of the aggregation results and NATION is performed locally at the master node because NATION is too small for parallelization Figure 8 shows a trace of the CPU utilization and the effective throughput of the disk and the network at the master node during execution of this plan In the build phases from the phase 1 through the phase 4 the CPU utilization was less than 30 and the disk throughput reached near the maximum value  Relation Number of Tuples Tuple length SUPPLIER 1,000,000 208 bytes PART 20,000,000 176 bytes PARTSUPP 80,000,000 220 bytes CUSTOMER 15,000,000 236 bytes ORDER 150,000,000 140 bytes LINEITEM 600,037,902 156 bytes NATION 25 192 bytes REGION 5 188 bytes Table 2 Database for 100GB TPC-D benchmark 8 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 PARTSUPP LINEITEMPART ORDER PS_Suppkey = L_Suppkey PS_Partkey = L_Partkey P_Name like \222%green%\222 1 SUPPLIER 2 NATION S_Nationkey = N_Nationkey 246\262 6 7 3 4 5 P_Partkey = L_Partkey S_Suppkey = L_Suppkey O_Orderkey = L_Orderkey Figure 7 Execution plan of TPC-D query 9 with right-deep tree 0 20 40 60 80 100 0 50 100 150 200 Time [s 0 10 8 6 4 2 Throughput [MB/s CPU usage 2 4 5#1 Disk NetSend NetRecv Figure 8 Execution trace of TPC-D query 9 with right-deep tree 8.8 MB/sec resulting in the disk I/O bound However in the probe phase 5 the CPU load increased to 100 with the disk throughput decreasing The reason of this transition to the CPU bound is due to the heavy CPU load required for processing multiple probe operations concurrently Figure 9 depicts another execution plan with the left-deep tree which does not involve concurrent probe operations In this case the results of each probe operation turn into the hash table for the next probe operation Figure 10 shows an execution trace of this plan Except for the phase 4 the disk throughput reached near the maximum In the phase 5 the CPU load increased to near 70 because the aggregation was performed concurrently with the probe operation by ORDER but the bottleneck was still in the disk I/O In the phase 4 though the CPU was heavily loaded higher disk throughput was obtained compared with the phase 5 of the right-deep plan The difference of the disk throughput between these phases resulted in the different elapsed times because the same relation LINEITEM was accessed in these phases The elapsed time of the phase 5 of the right-deep plan was 140 seconds while that of the phase 4 of the left-deep plan was 123 seconds In the above experiments execution times are dominated by the disk read times of input relations 9 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 LINEITEM SUPPLIER ORDER PS_Suppkey = L_Suppkey PS_Partkey = L_Partkey L_Orderkey = O_Orderkey NATION S_Nationkey = N_Nationkey 4 5 246\262 6 7 PARTSUPPPART P_Partkey = PS_Partkey P_Name like \222%green%\222 1 2 3 PS_Suppkey = S_Suppkey Figure 9 Execution plan of TPC-D query 9 with left-deep tree 0 20 40 60 80 100 0 50 100 150 200 Time [s 0 10 8 6 4 2 CPU usage Throughput [MB/s 1 2 4 5 Disk NetSend NetRecv Figure 10 Execution trace of TPC-D query 9 with left-deep tree Though the execution plans affect the performance of query processing the effect is rather small unless extra I/Os are incurred Because the disks are providing data at a high rate near the maximum of 8.8 MB/sec we have to reduce the amount of I/O in order to obtain further speedup Without indexes which are not so helpful to this query this can be accomplished by avoiding extra data transfer of unnecessary attributes in each relation For this purpose we store each attribute of a relation in an individual file separately from others This physical storage organization is called transposition or vertical partitioning[4 Figure 9 shows an execution plan of the query 9 for the transposed file organization Due to the increase in number of input files the execution tree gets rather complicated The join operations in the tree can be classified into two types inter-relation joins which are essential to the query and intra-relation joins tuple ID joins for reconstructing original tuples in projected forms from disconnected attributes The former appear as red links in the figure and the latter as light blue However we omit the further details here Figure 12 shows an execution trace of this plan Throughout the execution the CPU utilization stayed almost 100while the disk throughput dropped significantly meaning that the bottleneck turned from I/O to CPU Because of this heavy CPU load the execution time wasn\220t reduced proportionally to the amount 10 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 s_suppkey s_nationkey ps_partkey ps_suppkey ps_supplycost p_partkey p_name   l_partkey l_discount l_quantity l_orderkey l_suppkey l_extendedprice o_orderkey o_orderdate n_nationkey n_name p_partkey p_name   246\262 1 2 3 4 5 7 6 8 9 10,#11,#12,#13 14 15 16 17 18 1 2 Figure 11 Execution plan of TPC-D query 9 for transposed files 2 0 20 40 60 80 100 0 50 100 150 200 Time [s CPUusage NetSend NetRecv Disk 10 8 6 4 0 Throughput [MB/s CPU usage 8 9 10 13 Figure 12 Execution trace of TPC-D query 9 with transposed files 11 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


of I/O But the resulting speedup compared with the previous plans exceeds 2 which is quite satisfactory Table 3 shows the results of above right-deep rd left-deep ld and transposed file tp methods along with the reported results of other commercial systems for 100GB TPC-D query 9 Because our system lacks the software and maintenance price metrics the overall system price can\220t be determined accurately Hardware components themselves cost less than 0.5M We can observe that our system achieves fairly good performance Above all the execution time with the transposed files is twelve times as short as the most powerful commercial platform These results strongly support the effectiveness of the commodity PC based massively parallel relational database servers  System Exec Time Price Teradata on NCR 5100M 160 000 133MHz Pentium 20GB Main Memory 400 Disk Drives 953.3 17M Oracle 7 n DEC AlphaServer 8400 12 000 437MHz DECchip 21164 24GB Main Memory 84 Disk Drives 1884.9 1.3M Oracle 7 n SUN UE6000 24 000 167MHz UltraSPARC 5.3GB Main Memory 300 Disk Drives 2639.3 2.1M IBM DB2 PE on RS/6000 SP 306 96 000 112MHz PowerPC 604 24GB Main Memory 96 Disk Drives 2899.4 3.7M Oracle 7 n HP9000 EPS30 12 000 120MHz PA7150 3.75GB Main Memory 320 Disk Drives 7154.8 2.2M Our Pilot System 100 000 200MHz Pentium Pros 6.4GB Main Memory 100 Disk Drives rd 193.7 ld 177.2 tp 77.1 see text Table 3 Execution time of 100 GB TPC-D Q9 on several systems 12 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


4 Data mining 4.1 Association rule mining Data mining which is a recent hot research topic in the database field is a method of discovering useful information such as rules and previously unknown patterns existing behind data items It enables more effective utilization of transaction log data which have been just archived and abandoned Among the major applications of data mining is association rule mining so called 217\217basket analysis.\220\220 Each of the transaction data typically consists of a set of items bought in a transaction By analyzing them one can derive some association rule such as 217\21790 of the customers who buy both A and B also buy C.\220\220 In order to improve the quality of obtained rules a very large amount of transaction data have to be examined requiring quite a long time to complete First we introduce some basic concepts of association rule Let 000 000 001 000 1 001\000 2 001\002\002\002\001\000 000 002 be a set of items and 003 000 001 003 1 001\003 2 001\002\002\002\001\003 001 002 be a set of transactions where each transaction 003 002 is a set of items such that 003 002 004\000  n itemset 004 has support 005 in the transaction set 003 if 005  f transactions in 003 contain 004  here we denote 005 000 005\006\007\007\b\t 003 001 004 002 An association rule is an implication of the form 004 005 n  where 004\001 n 004 000  and 004 006 n 000 007  Each rule has two measures of value support and confidence  The support of the rule 004 005 n is 005\006\007\007\b\t 003 001 004 b n 002  The confidence 013 of the rule 004 005 n in the transaction set 003 means 013 of transactions in 003 that contain 004 also contain n  which can be written as 005\006\007\007\b\t 003 001 004 b n 002 f\005\006\007\007\b\t 003 001 004 002  For example let r 1 000 001 1 001 3 001 4 002  r 2 000 001 1 001 2 001 3 001 5 002  r 3 000 001 2 001 4 002  r 4 000 001 1 001 2 002  r 5 000 001 1 001 3 001 5 002 be the transaction database Let minimum  support and minimum confidence be 60 and 70 respectively First all itemsets that have support above the minimum support called large itemsets  are generated In this case the large itemsets are 001 1 002 001 001 2 002 001 001 3 002 001 001 1 001 3 002  Then for each large itemset 004  n association rule 004 t n 005 n 001 n 004 004 002 is derived if 005\006\007\007\b\t 003 001 004 002 f\005\006\007\007\b\t 003 001 004 t n 002 n minimum confidence  The results are 1 005 3 001 005\006\007\007\b\t 003 000 60 001 b\016\017 000\020\021\016\013\021 000 75 002 and 3 005 1 001 005\006\007\007\b\t 003 000 60 001 013\b\016\017 000\020\021\016\013\021 000 100 002  The most well known algorithm for association rule mining is the Apriori algorithm[1 We have studied several parallel algorithms for mining association based on Apriori One of these algorithms called HPA Hash Partitioned Apriori is discussed here Apriori first generates candidate itemsets and then scans the transaction database to determine whether each of the candidates satisfies the user specified minimum support and minimum confidence Using these results the next candidate itemsets are generated This continues until no itemset satisfies the minimum support and confidence The most naive parallelization of Apriori would copy the candidates over all the processing node and make each processing node scan the transaction database in parallel Although this works fine when the number of candidates is small enough to fit in the local memory of a single processing node memory space utilization efficiency of this method is very poor For large scale data mining the storage required for the candidates exceeds the available memory space of a processing node This causes memory overflow which results in significant performance degradation due to an excessive amount of extra I/Os HPA partitions the candidate itemsets among the processing nodes using a hash function as in the parallel hash join which eliminates broadcasting of all the transaction data and can reduce the comparison workload significantly Hence HPA works much better than the naive parallelization for large scale data mining The 022 th iteration pass 022  f the algorithm is as follows 1 Generate the candidate itemsets Each processing node generates new candidate itemsets from the large itemsets of the last  001 022 t 1 002 th iteration Each of the former itemsets contains 022 items while each of the latter itemsets contains 001 022 t 1 002 items They are called 022 itemsets and 001 022 t 1 002 itemsets respectively The processing node applies the hash function to each of the candidates to determine the destination node ID If the candidate is for the processing node itself it is inserted into the hash table otherwise it is discarded 13 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



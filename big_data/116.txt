A FUZZY LOGIC APPLICATION TO REPRESENT LOAD SENSITIVITY TO VOLTAGE SAGS B.D Bonatto Student Member, IEEE T Niimura Member IEEE H.W Dommel Fellow Member IEEE Department of Electrical and Computer Engineering University of British Columbia Vancouver B.C Canada, V6T 124 Abstract This paper presents a case study application of fuzzy logic in a power quality issue It describes the computer-based load sensitivity to voltage sags by using fuzzy sets and IF-THEN 
inference rules The load sensitivity is based on the steady-state and transient voltage versus time profile according to the IEEE Std 446 also referred to as the CBEMA Computer Based Equipment Manufacturer Association curve Fuzzy logic allows the modeling of the inherent uncertainty of the load reliability This expresses how the success or failure of computer based loads is correlated with short term voltage variations in the electric supply system A fuzzy inference system is experimentally implemented for these cases showing the general procedures of how to use this theory 
It appears that fuzzy set theory can play an important role in diagnosing power quality disturbances and hence it can offer insights towards the satisfaction of the needs of manufacturers utilities and customers Keywords fuzzy sets fuzzy logic application power quality voltage sag, intelligent systems I JNTRODUCTION The main objective of this research is to explore new pos sibilities to represent the reliability of computer-based loads such as an electronically controlled equipment with respect to transient phenomena in electric power systems such as voltage sags 
In recent years it has been a big con cern for the electric utilities to satisfy the expectations of the industrial commercial and residential electricity customers with respect to the quality in the supplied electric energy Due to the development of automated control systems, com puter-based loads and other power electronic devices their sensitivity to the quality of power has increased. Further more the expectations are highly differentiated reflecting the great variety of products and processes Sometimes power electronic loads are also responsible for the electric 223pollution\224 in the system, and are the source of power qual ity 
problems  Receiving a scholarship from CAPES Brasilia Brazil 0-7803-5105-3/98/$10.00 0 1998 WEE Voltage sags, voltage swells, outages, cold load pick-up transient impulses waveshape faults harmonic distortions flicker frequency deviations are examples of disturbances related to power quality problems. These variations can orig inate and/or manifest themselves at various places in the network Some of these power quality concerns are associ ated with design operation and random environmental events in the electric power system for example a fault caused by lightning. Many of them are associated with the operation and design of customer 
facilities e.g concerns associated with wiring and grounding problems switching transients load variations harmonic generation Most of the power quality cases are due to the incompatibility between the susceptibility of electronic based loads with the present power systems normal operation  11 To analyze the voltage magnitude and duration sensitivity of a specific computer-based load it is important to consider its intrinsic manufacturing characteristics Sometimes this is not known by the customers who complain about some power quality problems to the utilities The load voltage sen sitivity varies depending on the manufacturer, differences 
in equipment or application life-time previous conditions etc These real uncertainties make hard the decision task of fore casting the success or failure of computer-based loads against possible power quality related problems by the utili ties Therefore, fuzzy logic 2 seems to be appropriate to represent load sensitivity to voltage sags An example of such application will be described in this paper The proposed fuzzy logic application to represent load sensitivity to voltage sags is based on the CBEMA Compu ter Business Equipment Manufactures Association computer tolerance envelope presented 
by the IEEE Std 446-1987 3 Some necessary practical knowledge was also used as reference from realistic power quality monitoring from Brazilian utility CESP Companhia Energetica de S%o Paulo SZo Paulo Brazil This real experience was devel oped through some power quality troubleshooting within customers installations and also within power system facili ties 4 5 This paper is composed of five sections. Section I1 of the paper presents some of the fuzzy sets fundamentals A 60 


description of the load voltage sensitivity as a power quality issue is discussed in section III The formulation of the load voltage sensitivity case study based on the fuzzy set theory is shown in section lV Section V presents the conclusions II Fuzzy SETS FUNDAMENTALS The mathematical representation of vagueness or uncertainty is not an easy task Usually for real problems there is a lack of complete and reliable information on things that are supposed to be given or known Typically the modeling criteria to be taken into account for this representation are neither precisely known nor remain constant with time context nor situation i.e forecasts proved to be wrong random disturbances occumng subjective judgments and so on  11 Fuzzy logic is a technique to handle such uncertainties A fundamental element of fuzzy logic is the 223membership function\224 which describes the degree of a certain variable 223x\224 belonging to a fuyy set 223A\224 This degree of membership expressed in an interval of 0 11 is a measure of proximity to this set A membership value of 1 for a particular value 223xi\222 means that the variable is completely satisfactory for the fuzzy set 223A whereas a value of 0 means that it is completely unacceptable in that fuzzy set i.e it doesn\222t belong to the set 223A\224 at all Any deviation is acceptable with an intermediate degree of satisfaction between 0 and 1 This is a special property that is very useful to model some real world uncertainties that are linguistically expressed by experts IF-THEN logic rules can be used to combine membership values for fuzzy variables trying to mimic the human reasoning process All the consequences for each defined rule are aggregated to give the result that is expected to be a real value which is supposed to be the closest to the real knowledge being modeled When fuzzy set theory is used to solve real problems, the following steps are generally followed 6 1 Description of the original problem in a linguistic or mathematical form 2 Definition of the input and output variable for the fuzzy inference system whose range and thresholds can be based on empirical knowledge 3 Appropriate definition of the number and shape of mem bership functions for each input and output variables The membership functions express the degree of satisfaction of a certain variable value into a defined fuzzy set 4 Definition of IF-THEN inference rules that must repre sent the system practical behavior being modeled by an expert 5 Selection of the fuzzy operators for the defuzzification process in order to assure that the results obtained are similar to those observed in the real world 6 Tuning the fuzzy inference system by feedback to the pre vious steps III DESCRDPIlON OF THE LOAD VOLTAGE SENSITMTY AS A POWER QUALITY ISSUE Usually voltage sags that are short term depressions in supply voltages are responsible for the majority of distribu tion power quality problems l An appropriate way to express voltage sags disturbances is through a graph of rms voltage magnitude in percentage of the nominal voltage ver sus the time duration in cycles 60 Hz or milliseconds A commonly used voltage duration profile for power line dis turbance is presented in Fig 1 This typical Automatic Data Processing power requirements profile from IEEE Std 446 1987 3 is a computer tolerance envelope which is also referred to as CBEMA curve lV FORMULATION OF THE LOAD VOLTAGE SENSITIVITY CASE STUDY BASED ON FUZZY SETS Because most of the power quality problems are related to voltage sags, for this project only this type of voltage vari ation will be considered for modeling the load sensitivity Fig 2 shows a set of waveforms of the magnitude versus duration of voltage disturbance taken from monitoring a 138 kV substation, supplying a pulp and paper industry customer A common sense about electronic or computer-based load reliability, expressed as success or failure. regarding voltage magnitude depression and time duration can be stated lin guistically in general terms as follows WNode Grq Triggehg sa Max Depth Fskuary 07,1997 at 16:30:53 Local 021[33197 22:51:37 Local I I  1 0.001 0.01 0.1 1 10 Ibo id00 1  BMI/EkctrOtCk cYw Fig 1 Qpical Automatic Data Recessing Power Requirements Profile from IEEE Std 446-1987 CBEMA curve 61 


CHAMWol Phase A-B Voltage RMS Variation Fehua~y 23,1997 at 192952 Local Member Xnputl Input 2 funchon I cycles Voltage Duration ship 120 10 __ 60 output Reliability I I 150  II L Long 3 U 100 50 po s 50 100 1 S A Short Average 0 25 50 75 100 125 150 175 200 T ntSuc RYUMek Fig 2 Voltage Sag Disturbance in a 138 kV substation supplying a pulp and paper industry customer IF THEN the load always will succeed IF THEN the load may fail IF THEN the load certainly will fail the voltage is normal and time duration has no effect the voltage is low and the duration is very short the voltage is extremely low and the duration is long 4 A fuzzy logic application was developed to represent load voltage sensitivity according to the steps presented above The software MATLAFi version 5.1 with a fuzzy logic tool box was used to implement the case studies N L AS Normal Long Almost Success For this fuzzy inference system, the two input variables chosen are the voltage magnitude expressed in percentage of the load nominal voltage in a range from 0 to 106 and the time duration of this undervoltage expressed in cycles 60 Hz in a range from 0 to 60 cycles or milliseconds The one output variable chosen is the reliability expressed in percentage in a range from 0 to 100 Note that although the reliability measure is expressed by percentage those fig ures do not necessarily represent the probability of occurrence Table 1 explains the meaning of each defined fuzzy set for each of the input and the output variables Four trapezoidal membership functions are defined for each of the input variables as shown in Fig 3 and Fig 4 The thresholds are defined based on the CBEMA curve and from practical experience. The output variables are defined by five membership functions as shown in Fig 5 Success is interpreted as 100 reliability whereas failure is inter preted as  0 reliability To represent the phenomena or practical knowledge IF THEN rules must be stated to form a fuzzy inference sys tem For each possible combination of the fuzzy sets belonging to two input variables there is one fuzzy set out put variable Examples of rules are shown in Fig 6 51 S I Success Voltage Fig 3 Voltage Magnitude Input Membership Function JD 0 40 80 120 160 200 msl Duration Fig 4 e Duration Input Membership Function 62 


Reliability Fig 5 Reliability Output Membuship Function It is important to note that because four fuzzy sets were defined for voltage input variables, and four other fuzzy sets for the time duration input variables this combination resulted in 16 inference rules Generally the number of rules increases as the product of the number of defined input fuzzy sets This could be a concern if a large number of fuzzy sets are defined. The fuzzy inference process is illus trated in Fig 7 The selection of the fuzzy operators and the defuzzifica tion method was made as shown in Table 2 1 IF Voltage is EL and Duration is ES THEN Reliability is S 2 IF Voltage is EL and Duration is VS THEN Reliability is AF 3 IF Voltage is EL and Duration is S THEN Reliability is F 4 IF Voltage is EL and Duration is L THEN Reliability is F 5 IF Voltage is VL and Duration is ES THEN Reliability is S 6 IF Voltage is VL and Duration is VS THEN Reliability is A 7 IF Voltage is VL and Duration is S THEN Reliability is AF 8 IF Voltage is VL and Duration is L THEN Reliability is F9 9 IF Voltage is L and Duration is ES THEN Reliability is S 10 IF Voltape is L and Duration is VS THEN Reliabiliw is AS I 1 I IF VolGe is L and Duration is S THEN Reliability-is A 12 IF Voltage is L and Duration is L Reliability is AF I 13 IF Voltage is N and Duration is ES THEN Reliability is S 14 IF Voltage is N and Duration is VS THEN Reliability is S IS IF Voltage is N and Duration is S THEN Reliability is S 16 IF Voltage is N and Duration is L THEN Reliability is S Fig 6 Inference rules for voltage sags Table 2 Fuzzy Operator and Defuzzification Method AND 1 min I I OR I max I Implication Aggregation Defuzzification centroid 25 125 a 10 Fig 7 Process of the fuzzy inference The simulation results of this fuzzy logic application in representing load sensitivity to voltage sags is presented in the following figures. Fig 8 shows the surface view quanti fying the load reliability expressed in percentage. Success is interpreted as 100 whereas failure is 0 Fig 9 illustrates the same resulting reliability in a two-dimensional chart resembling the CBEMA curve for the voltage sag cases lower half of Fig 1 V CONCLUSIONS This paper has presented a case study application of fuzzy logic to a power quality issue It describes the computer based load sensitivity to voltage sags by using fuzzy sets and IF-THEN inference rules Using a typical computer volt age tolerance envelope as a standard reference IEEE Std 446 or CBEMA curve a fuzzy reasoning process was developed to decide about the reliability 223how much\224 suc cess or failure of computer-based loads when voltage disturbances occur in the neighborhood of the electric sup ply system This type of sensitive load has an inherent uncertainty i.e power quality tolerance varies according to differences in equipment manufacturers device application and so on This uncertainty was formulated by fuzzy logic theory through membership functions which usually do not use strict boundaries and such feature was found suitable in dealing with the vagueness associated with the power qual ity problem The results presented show the potential of intelligent system techniques for diagnosing power quality disturbances, giving answers to the needs of manufacturers utilities and electric energy customers 63 


r31 W.E Kazibwe and M.H Sendaula Electric Power Fig 8 3D Surface view of voltage sag load sensitivity Fig 9 Two-dimensional view of voltage sag load sensitivity ACKNOWLEDGEMENTS The authors would like to express their gratitude to CAPES of Brazil for financial support by a Ph.D scholar ship given to Mr Bonatto and to CESP for providing some of the data REFERENCES  11 E.W Gunther and H Mehta 223A Survey of Distribution System Power Quality  Preliminary Results\224 IEEE Transactions on Power Delivery Vol 10 No.1 pp K Tanaka An Introduction to Fuzzy Logic for Practical Applications Springer-Verlag New York Inc New York NY USA 1997 322-329 January 1995 2 51 Quality Control Techniques Van Nostrand Reinhold New York 1993 L.E.O Pinheiro et al 223Measurements for Power Quali ty Monitoring in Distribution System\224 I SBQEE  First Brazilian Seminar on Power Quality Uberlsndia MG Brazil June 10-13 1996 in Portuguese L.E.O Pinheiro et al 223Power Quality Monitoring  Practical Cases Solutions and the Planning Perspec tive\224 XIII SENDI  National Seminar in Electric Ener gy Distribution S6o Paulo \(SP May 11-16, 1997 in Portuguese IEEE PICA 22197 Tutorial Course Fuuy Set Applica tions in Power System IEEE Power Industry Compu ter Applications Columbus Ohio USA May 1997 BIOGRAPHIES Benedito Donizeti Bona was bom in Conchal, Brazil on August 05 1%6 He received the B.S in Electrical Engineering with honors from the Federal School of Engineering of Itajuba EFEI Itajuba., Brazil 1991 and the M.A.Sc in Electrical Engineering from the State University of Campinas \(UNICAMP Campinas Brazil 1995 He joined CESP  Com panhia Energetica de SBo Paulo Brazil in 1994 at the Distribution Planning and Protection Divison. where his main tasks were power quality measurements diagnosis and proposal of solutions for distribution custom ers He also joined CEETEPS  The State Center of Technological Education Paula Sou Brazil in 1995 as a teacher for the electrotechnical and eleamelectronics technical high school courses. Currently he is on a leave absence from CESP and CEETEPS to pursue his Ph.D degree at the Department of Electrical and Computer Engineering of The University of British Columbia UBC Vancouver Canada His field of interests includes simulation and analysis of electromagnetic transients phenomena in electric power systems and power quality issues He is a student member of the IEEE Takahide Niimura was bom in Tokyo Japan on November 22 1958 He received B.S M.S and Ph.D degrees in electrical engineering from Tokyo Metropolitan University Tokyo, Japan in 1981 1983 and 1992 respectively. He joined Fuji Electric Co. in 1983 and from 1988 to 1995 he worked for the Power System Control Development Depamnent of Fuji Electric Corporate Research and Development, Ltd He is currently an assistant professor at the University of British Columbia Vancouver Can ada His field of interests includes design and optimization of control systems, and application of fuzzy set theory to electric power systems con trol problems Dr Niimura is a member of the Japan Society for Fuzzy Theory and Systems SOFT Institute of Electrical Engineers of Japan and EEE Hermann W Dommel was bom in Germany in 1933 He received the Dip1-Ing and Dr.-Ing degrees in electrical engineering from the Technical University of Munich, Germany in 1959 and 1962 respectively From 1959 to 1966 he was with the Technical University of Munich and from 1966 to 1973 he worked for Bonneville Power Administration Portland Oregon Since July 1973 he has been with the University of British Columbia Can ada Dr Dommel is a Fellow of IEEE and a registered professional engineer in British Columbia Canada 64 


Proceedmgs of the First International Conference on Machme Learning and Cybernetics Beijing 4-5 November 2002 161 171 81 191 Guozhu Dong, Jiawei Han, Joyee Lam Jean Pei and Ke Wang Mining Multi-Dimensional Constrained Gradients in Data Cubes VLDB 2001 R.Ng L.V.S.Lakshmanan J.Han and A.Pang Exploratory mining and pruning optimizations of constraned association rules. ACM SIGMOD 1998 R.Agrawal T.Imielinski and ASwami Fast algorithms for mining association ruels. VLDB 1994 Jiawei Han, Jianyong Wang Guozhu Dong, Jian Pei Ke Wang CubeExplorer online exploration of data cube ACM SIGMOD 2002 1033 


4.1 Simulation model In the section we evaluate the performances of the three algorithms including BASIC 1121 Cumulate 12 and GMAR on a DELL PowerEdge 4400 Server with Intel" Xeon Processor and 756MB main memory running Windows 2000 server All the experimental data are generated randomly and stored on a local 30GB SCSI Disk Ultra 160 with a RAID controller The relative simulation parameters are shown in Table 1 To make our data representative, we generate two types of databases in the experiments i.e DENSE databases and SPARSE databases. Each item in the DENSE database is randomly generated from a pool P called potentially frequent itemsets with size 300 while each item in the SPARSE database is randomly generated from a pool N i.e the set of all the items\with size 1000 Since the items in the DENSE database are more clustered than those in the SPARSE database, larger frequent itemsets will probably be produced in the DENSE database for the same minimum support Besides we use the notations T for average number of items per transaction I for average number of items in a frequent itemset, and D for number of transactions. For example the experiment labeled with 7lOB.DIK represents the simulation environment with IO items on the average per transaction 3 items on the average in a frequent itemset, and 1000 transactions in total Table 1 Simulation parameters with default values ID INumber of transactions 1000-500,000 7 INumber ofthe items per transaction 15-15 P INumber of potentially frequent 1300  litemsets I I Number of the items in a frequent 12-5 4.2 Experimental results Experiment 1 In the experiment we explore the execution time of BASIC Cumulate and GMAR algorithms for the environment 7lO.L3,DIK under different minimum support and minimum confidence pairs as shown in Figure 9 In the figure, we find that our algorithm GMAR is almost faster 2-16 times than BASIC especially for larger minimum support and minimum confidence pairs whereas Cumulate is only faster 1.3-1.5 times than BASIC although R Srikant and R Agrawal claimed that Cumulate runs faster 2-5 times than BASIC 1121 In general the larger the minimum support and minimum confidence pair is the faster the execution time of the three algorithms becomes To be fair to all algorithms, we have added the extra time of generating original frequent itemsets and association rules for GMAR However the time is helow 1 of total execution time thus we do not show it in the figure h n  B a 3 i.m.26 i.ma 1.~1.3 i.mm 1.740.3 I.w Figure 9 Execution time for different pairs minimum support  Confidence Experiment 2 In the experiment we extend Experiment 1 by fixing the minimum support IS and observe their variations For the minimum support 1.5 all the algorithms except GMAR are not sensitive to the changes of the minimum confidences as shown in Figure IO The reason is that larger minimum confidences will make GMAR prune more irrelevant rules. Nevertheless, GMAR is still in the first rank D  2 4M cm 22 CUlIIUlStt  gm BASIC 8 Irn 0 0 0.26 0.28 0.3 0.32 0.34 0.3 minimum confidence Figure 10 Execution time for different minimum confidences Experiment 3 In the experiment, we explore the execution time of the three algorithms for the environment ZlO.I3.DxK i.e different numbers of transactions generated in the SPARSE database and in the DENSE database as shown in Figure Il.\(a and b respectively. Both cases have the same minimum confidence 0.3 However to get comparable number of frequent itemsets, we set a smaller minimum support 1 in the SPARSE case and a larger 233 


minimum support 2 in the DENSE case As expected GMAR is still the hest one among them in the SPARSE and DENSE case especially when there are a huge amount of transactions From the both cases we find that much more frequent itemsets are generated in the DENSE database than in SPARSE database so that BASIC and Cumulate are not practicable candidates there B Ixa 8 Imo 222ixa 80 0 Imo 3033 m m loo30 number of transactions Figure 11 a Execution time for different numbers of transactions in the SPARSE database cumh?t  6 loo30  rma 2230 lorn m 5m 7cw IwD3 number of transactions Figure 1 l.\(b Execution time for different numbers of transactions in the DENSE database 5 Conclusions In the paper we try to find the association rules between the items at different levels in the taxonomy tree under the assumption that original frequent itemsets and association rules have already been generated beforehand The primary challenge is how to make use of the original frequent itemsets and association rules to directly generate new generalized association rules rather than rescanning the database In the proposed algorithm GMAR we use join methods and pruning techniques to generate new generalized association rules Through several comprehensive experiments we find that the GMAR algorithm is much better than BASIC and Cumulate algorithms since it generates fewer candidate itemsets and furthermore prunes a large amount of irrelevant rules based on the minimum confidence 6 Acknowledgments This research was supported in part by the National Science Council Taiwan under contract NSC-90-22 13-E-224-026 7 References I R Agrawal T Imielinski and A Swami 223Mining Association Rules between Sets of Items in Large Databases,\224 Pmc ACM International Conference on Mananement of Data  1993 pp 207-216 121 R Anrawal and R Srikant 223Fast Alaorithms for Mmine Adsociation Rules,\224 Pmc 2Vh Internationaiconference on Ve Large Data Bases 1994 pp 487-499 131 Yong-Jian Fu 223Data Mining,\224 IEEE Potentials Yol 16 No 4 1997 pp 18-20 141 Jia-Wei Han and Yong-Jian Fu 223Mining Multiplelevel Association Rules in Large Databases,\224 IEEE Transactions on Knowledge and Data Engineering Yo 11 No 5 1999 pp 798-805 5 Iia-Wei Han and Micheline Kamber Data Mining Concepts and Techniques Morgan Kaufmann Publishers 2001 6 Iia-Wei Han lian Pei and Yi-Wen Yin 223Mining Frequent Patterns without Candidate Generation,\224 Pmc ACM International Conference on Management o Data 2000 pp 1-12 7 Mon-Fong Jim Shian-Shyong Tseng and Shan-Yi Lia 223Data Types Generalization for Data Mining Algorithms,\224 Pmc IEEE International Conference on stems Man and Cybernetics 1999 pp 928-933 8 Bing Liu Wynne Hsu and Yi-Ming Ma 223Minin Association Rules with Multiple Minimum Supports,\224 Pmc 5 ACM International Conference on Knowledne Discovery and B DataMining 1999 pp 337-341 191 J S Park M S Cben and P S Yu 223An Effective  H&h-based Algorithm for Mining Association Rules,\224 Pmc ACM Internotional Conjerence on Mamgement o Data 1995 pp 175-186 IO A Savasere E Omiecinski, and S Navathe 223An Efficient Algorithm for Mining Association Rules in Large Databases,\224 P 21\224 lnternationk Conference on Very La Data Bases 1995 pp 432-443 Ill Pradeep Shenoy layant Haritsa S Sudarshan Gaurav Bhalotia, Mayank Bawa and Devavrat Shah 223Turbo-charging Vertical Mining of Large Databases,\224 Pmc ACM International Conference on Management of Data 2000 pp 22-33 I21 R Srikant and R Agrawal 223Mining Generalized Association Rules,\224 Pme 21\224 International Conference on Very Large DataBases 1995 pp 407-419 I31 S Y Sung K Wag and L. Chua 223Data Mining in a Large Database Environment,\224 Pmc IEEE International Conference on Systems Man and Cybernetics 1996 pp 988-993 I41 H Toivonen 223Sampling Large Databases for Association Rules,\224 Pmc 2T\221 International Conference on Very Large Data Bases 1996 pp 134-145 I51 Ming-Cheng Tseng Wen-Yang Lin and Been-Chian Chien 223Maintenance of Generalized  Association Rules with Multiple Minimum Supports,\224 Pmc 9th IFSA World Congress and 20th NAFIPSInternational Conference 2001 pp 1294-1299 234 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



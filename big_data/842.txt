  1 On-Line Drilling Process Monitoring by Marginalized Particle Filter 1-2 A. BA 1 N. Mechbal 1 M. Verg\351 2 S. Hbaieb 1 Laboratoire de M\351canique des Syst\350mes et des Proc\351d\351s  \(UMR-CNRS Ecole Nationale Sup\351rieure d\222Arts et M\351tiers, 151, Boulevard de l\222h\364pital, Paris, France 2 Schlumberger Riboud Product Centre, 1, rue He nri Becquerel, 92142 Clamart, Cedex, France 331-45-37-70-87 aba2@slb.com  Abstract 227Real-time monitoring of a drilling process is an essential task in improving their performances 12 Faults that 
might occur have to be detected as soon as possible in order to preserve drilling efficiency. In this paper, drilling process monitoring by identifying time varying parameters through Marginalized Particle Filter \(MPF\. The idea consists in enhancing the tracking ability of parameters change by integrating into the process model a part that represents the faulty process and another when the process is safe. The efficiency of the developed approach is highlighted through simulated and experimental data obtained from tests campaign   T ABLE OF C ONTENTS  1  I NTRODUCTION 1  2  
B IT ROCK INTERACTION MODEL 2  3  P ARTICLES FILTER 2  4  L INEAR REGRESION AND FD BY MPF 3  5  L INEAR REGRESION AND FD BY MPF AND SIMULATED DATA 4  6  L INEAR REGRESION AND FD BY MPF AND EXPERIMENTAL DATA 5  7  C ONCLUSIONS 6 
 A CKNOWLEDGMENT 6  R EFERENCES 6  1  I NTRODUCTION  Drilling process performances are adversely affected when a fault occurs. For this reas on, a system for the faults detection \(FD\plays a vital role. It may enable to be able to safeguard some of the process performances by taking efficient corrective action, in case of early diagnosis Drilling processes are very widespread in several fields and their efficiencies are more a nd more required, owing to the hostile environments that they are confronted and to the expense of maintenance procedure. As an example, oilfield 
industry necessitates to have an efficient drilling process Fig.1\(a\in order to drill in a more challenging context such as high temperature, high pressure, heterogeneous rock, among others problematic cases. Aerospace domain Fig.1\(b\that inte grates a drill bit for planetary exploration, potentially to look for evidence of possible life 1  1 978-1-4244-2622-5/09 25.00 \2512009 IEEE 2 IEEEAC paper#1725 Version 1, Updated 2008:12:18   Al l t h ese cases requi re an effi ci ent di agnosi s sy st em  t o  detect in real time faults that might occur. This paper deals with a monitoring strategy to detect poor performances of the drill bit. When this scenario happens, the drilling operation cannot be achieved as expected. In this paper, the 
FD strategy investigated concerns a drilling process used in oilfield industry. Nevertheless, the developed approach can be experimented for other drilling processes, especially those used in aerospace technology. Indeed, there is no doubt that the differences in processes lead to the discrepancies in their dynamics. But, the principle of the bit rock interaction in both cases shows great similarities. Any of these processes requires, at the bit, two forces to grind the rock: the Weight On Bit WOB he Torque On Bit  TOB this study, the fault to detect is characterized by the change in the drill bit properties, consequently in forces values for a constant Rate Of Penetration \(ROP\It is interesting to make clear that the change in rock properties 
for example, moving from slight to hard rock, provides similar behavior in measur ement compared with those viewed in the case where the drill bit is faulty. Here, the question is how to dissociate these two phenomena? To provide an answer to this question it is developed in  a model of bit rock interaction. This model gives the possibility to express for ces between them without involving the rock properties. When a fault occurs on the drill bit, the coefficients which characterize these relationships will change. The idea is to monitor these coefficients and to detect th eir possible modification. To achieve this task, we propose to investigate MPF in order to detect faults might occurs in the bit. The FD approach proposed is based on the principle which consists in defining two functioning modes, one corresponding to the 
case where the process is safe and another when it is faulty Each of the defined functioning modes is modeled by a state space representation system Through this approach, the classic identification methods provide poor performances For this reason, we investig ate the MPF. Its specificity comes from the possibility to be able to combine the features of the Kalman Filter \(KF d th o se p r o v i d ed  by the Particle Filter \(PF e ro le o f th e KF is to  treat each of the defined state sp ace representation whereas the PF is dedicated to select th e one to be treated. The FD strategy is achieved through two linear regressions obtained by using MPF approach and the detection is made when the process model move from the model which corresponds to the process when it is safe to the faulty case. In this paper 


007   The subscripts c and f denote cutting and friction respectively. The cutting components c TOB and c WOB  correspond to the forces tran smitted by the cutting face of each cutter and the friction components f TOB and f WOB  correspond to the other contacts obtained from bit-rock interaction. The response of the bit is obtained by combining the cutting and frictional   DOCa WOB DOCa TOB 006 002\002  ROP DOC 002  2   The relationship \(2\hat the slope of E as a function of S is only dependent on the bit shape factor and the friction coefficient. Hence the rock properties are not involved When a change occurs on the b it, for example the bit wear or break, these two parameters will be affected Consequently, the fault detecti on approach developed in this study is based on the detection of a change in   2 our study is restricted to two possible classes in which the process can evolve, but the  Fig.1\(a Fig.1 \(b study can be extended to other classes. Before the use of MPF for linear regression and FD, we briefly present the model of bit-rock interaction as developed in  2  B IT ROCK INTERACTION MODEL  The model of bit rock interaction has been subject of intensive researches activities and interesting results are reported in These m odels account for the cutting action of a single cutter. Cutting action of each cutter is represented by two independent processes, the cutting process and the friction process. The forces TOB and WOB  are defined by f c TOB TOBTOB    where 2  2 c DOCaa TOB 003 004  c   2  f WOBa TOB f 002\002\002  005\265   2 005 265 0  2 where   f c WOB WOB WOB 002\002\002 t 005 265 b 002\002   The specific energy which co rresponds to the necessary energy to grind a given volume of rock is defined in by   SEE 003 b 002\212 1 0 E   2\he following relations have been obtained DOCa WOB S 265 and / or 005  That leads to the cha nge in the slope of E as a function of S  as indicated in \(2\he model \(2\s exploited in order to monitor the drill bit. For this reason, MPF algorithm is used in order to identify the parameters corresponding to the two slopes, before and after the change, as well as the time from which the change occurs  TABLE  I V ARIABLES USED  Symbol Quantity Unity a  Bit radius m DOC  Depth of cut m  E  Specific energy Mpa S  Drilling strength Mpa TOB  Torque on bit Nm c TOB  Torque on bit, cut Nm f TOB  Torque on bit, friction Nm WOB  Weight on bit N c WOB  Weight on bit, cut N f WOB  Weight on bit, friction N 003  Intrinsic specific energy Mpa ROP  Rate of penetration \(ROP m/h 006  Bit angular velocity rad/s 265  Friction coefficient  004  Coefficient characterizing cutting force  005  Bit shape factor  3 PARTICLES FILTER  In this paper it is not intended to provide a detail regarding the theory of PF. The interested reader is refereed to [5]. To make easy the understanding of the MPF approach we present the idea of PF. The PF is a statistic tool which approximates a probability density function trough simulation. To achieve this aim, the PF algorithm requires a large number of samples called particles in order to represent accurately the real st ate of the process. At each time, the samples generation is needed. When a measurement becomes available weights are assigned to the 002   DOCa TOB E 002\002  003  DOCa WOB 002 002\002+\002\212 002 002 005\265\003\b 1 2 2  1 with 002\002 


 z k nz 1 n f\r 013 f\f 002+\002 002  212  4 Where 016 denotes the unknown state: Here the safe state is considered when 1  k z and the faulty state when 2  k z  017\016 is the parameter vector y n y 017\016 is the measurement vector k 013 and k n are respectively the process noise and the measurement noise, considered to be known, independent and identically distributed \(i.i.d T k f The model of equation 4\ables to define the algorithm-1. In this algorithm the main step are given. At the starting, N particles are drawn according to  0  10 zpz i 016 i k z According to the i k z value one of the models is involved. Notice that the purpose of the MPF approach is to estimate the following probability density function Yz\(p\Y,z\(p\Yz,\(p kk kkk kkk  From this equation, it is clear that the PF will be used for estimating the probability density function  kk Yzp and the KF is employed to estimate  kkk Yzp  21 kkk xxx 212 And the KF associated with each parameter sample are initialized as 212 kk xxP between these two states and to have a priori knowledge concerning the variable 1 k x At last, to generate samples from  1 1 1 212 kk xxP It can be noticed that the KF only do not enables to solve this kind of problem Therefore, there is necessity to have, at each time an algorithm estimating 1 k x to serve the KF to run 2 k x To accomplish this objective, a set of N particles is generated at every time step, maintained and updated. As an example at the time k the i th particle is defined as n 013 002+\002 002+\002   3 Where 2 k x is considered to model the evolution of the process. As suggested in i t i s i m port a nt t o  m a ke cl ear that the model can possess one or more of the matrices k A  k G  k C and k H evolving possibly under nonlinear, non-Gaussian conditions. The variables k n and k 013  are considered zero mean and Ga ussian. As matrices in this system can change according to the state in which the process progress, solving the problem requires to achieve another set of variables, describing the evolutions of these parameters. This context brings us to define by 1 k x as this set of parameters. Thereby, the aims becomes the use of the MPF for the overall state   3 probable state. It can be considered as the degree of confidence that we need to have on the particles in their representation of the true state of the process. The weight values depend on how they fit the measurements as well as the sequence of the past measurements. Only, the most likely particles to represent the true states are maintained onto the next step and the other are discarded through the resampling algorithm. As an extension of the PF, the MPF algorithm [6-8 p licab le to the case where the dependencies within the states variables can be analytically used. To illustrate that, let us consider the case where two process models can be defined, one representing the process when it is safe whereas the ot her when it is faulty, and each of the model having a linear state space representation. It is obviously clear that the two models cannot be exploited at the same time; as a result one of them is selected when it is considered as the most probable scenario by the PF. In this context, the standard KF is used for the two linear state space models, and the PF to select the one to be involved To formalize this situation we consider the following state space representation kk 2 kkk kk 2 kk 2 1k HxCy GxAx r Thus we get the following state space representation k i kkk i k T kk k i kkk1k 1kk k z\(H\z\(y z\(G zz\(p~z r is the regressor vector, \(i e particle associated to the model k G and k H are the matrices associ ated to the noises As said above, two states of the process are defined, thus  In order to achieve this requirement, it is essential to define the transition probability  1 1 1  k k yyY  0  2,1  002  f f  5 In the equation \(5 k Y denotes the sequence of measurements up to time k f  1 k x by k z  k A by identity matrix and k C by T k f f n  212\212  f f  Then weights are evaluated and normalized according to   1  1   i k i kk i kk i kk i k SyNzYypq 212 212  where  i k S is the innovation term associated to each particles. After that, the particles having the highest we ight are multiplied and those   For each iteration 1 i k x corresponds to a unique  i k A   i k G   i k C and  i k H  4  L INEAR REGRESION AND FD BY MPF  The objective of this study is to perform a FD task by using MPF. The FD approach developed here is based on parameter estimation technique particularly on linear regression method. The aim is to detect a change, which corresponds to the fault appariti on, in the slope progress. To perform the MPF approach we define two slopes where one represents the process in th e case where it is safe and another when it is faulty. We model these two slopes by two state space representations, the algorithm switch from one model to another through a variable which evolves under PF principles. For the reason of clarity, we redefine the model 3 regression form. That is we replace 2 k x by   N i ii P P 1 00  10  10   2\\(,1  i k i k i k Kxx  where  i k K corresponds to the covariance of 2 i k x given the set  k r i r i k xX 0 1\\(,1 


   4 having the lowest weight are discarded through the resampling algorithm defined in the algorithm-2 Then the particles are updated by using the KF. At the end the parameter vector is es timated. In the algorithm1 k R denotes the variance of the noise measurement k 013  Algorithm: MPF for FDI  1  for i 1,\205 N Propagate samples    000 0  0  10 10 10 i i i zzpzYp Yzzpz 212 212 020   where  1  1 1  i kk i kk T kkk z y 212 016 and let 1i 212 212 002 212  and set 002 103.0 1  7 rand x y 002\002\212 002\212 002\002 002\002 212 212 212 212 212 212 f\r f\f r r r 6 In the equation \(6 i k K is the Kalman gain which minimizes the posterior error covariance i k S is the innovation matrix k R denotes the variance of the noise measurement k n  Algorithm 2: Resampling algorithm   Generate an uniformly distributed random point  N  0  u 1 1 212\002 212  2  If  002 1 03.0  1  1 rand xy 002 12 015.0  1  2   In general term, we get for each model the following state space representation 212 212 212 002  f r  k i kk k i kk i kk T k i k RzPzS 002 12015.0 2  8 These equations can be rewritten as rand xy 212 kk xxP The aim is to use the presented algor ithm in order to identify the slopes defined in \(7 8 well as to detect the faults For reliable FD, robustness against measurement noise and other possible disturbance is required. For this reason we choose reasonable amplitude of rand The Fig. 3 presents the slope obtained by using the proposed approach. Notice   N 1i 00 i 10 i 10 P,P    For j=1:N 1  Let 1j\(Nuu 1 1j  002   kk T kk kk k e y 1111 1111 002   kk T kk kk k e y 2222 2212  212  4  Kalman filter measurements update equation \(6 5\pute the parameters vector equation \(7 The equation \(6 T i k i k i k i kk i kk i kk i kk T kk i k i kk i kk i k i kk T k i kk i k i kk k i kk i kk T kk i k KSKPP zyK SzPK zPzRS       1   1   1  1   1    1    002\002  212 212 212    1  1  1  r r  b\alize the weight f\r 013\f\f  f\r 013\f\f   The MPF allows to define one general model for both cases k i kkk i k T kk k i kkkk zHzy zG n f\r 013 f\f 002+\002 002       1   Where  i k z allows to move from one model to another through the transition matrix given by  1 1 1 n  k Q is the covariance of process noise k   0q 0 k  212\212  f f  end for 2  for i 1,\205 N  a  evaluate the weight   1  1   i k i kk i kk i k k i k Sy zYypq  212  021 i 0l l k j 1i 0l l k quq set i 1kk j k xx 212   3  Otherwise go to step \(3\1   End for The resampling step is achie ved according to the algorithm2, during this stage the partic les having the highest weight are multiplied and those having the lowest weight are discarded 5  L INEAR REGRESION AND FD BY MPF AND SIMULATED DATA  In the past sections we desc ribed the MPF approach and the use of this technique for FD task. The proposed FD strategy uses the model selection approach, where a PF choose between two defined models, one representing the process running in normal operation and other for the faulty process. The advantage of such approach compared with the classical identification techni que comes from the fact that the fault is detected by a discrete state as soon as possible Here we are concerned to detect the change in the slope which characterizes a fault apparition by using MPF. We start by appraising this approach in its ability to be able to detect fault, by using simulated data: Let us take two equations as defined in \(7 nd \(8 corresponds to the case where th ere is no fault \(7 other when the process is faulty 8\it is added the measurements noises, denoted by e randxy   N j j k i k i k q q q 1     end for 3  Resample with replacement, \(Algorithm2    1    j k j kk i kk qzzP 


1000 1500 2000 2500 3000 3500 4000 4500 5000 0.012 0.014 0.016 0.018 0.02 0.022 0.024 0.026 0.028 0.03 1000 1500 2000 2500 3000 3500 4000 4500 5000 0.012 0.014 0.016 0.018 0.02 0.022 0.024 0.026 0.028 0.03   5 that when the fault occurs the MPF model for normal operation is substituted by the MPF model considering that fault is active. In the first ex ample, the number of particles is equal to 50 ROP \(m/h Temporal measurement                             500 10 0.02 1000 1500 2000 2500 3000 3500 4000 4500 5000 2 3 4 1000 1500 2000 2500 3000 3500 4000 4500 5000 5 1000 1500 2000 2500 3000 3500 4000 4500 5000 0.04 265 or/and the bit shape factor 005 These changes reveal a dysfunction on the bit However, in real drilling conditions it is not a straightforward task to dia gnose this kind of faults by looking at the progress in measurements. It is mainly caused by the similar behavior viewed on S and E either in case of changeover from slight rock to hard rock or the bit dysfunction. For this reason we have developed an on-line identification method to determine the slope which characterizes E as a function of S and consequently detecting the dysfunction on the bit                               0 1 0 0 0 0 Samples Slope  Fig.4. Slopes progress simu lated data \(100 particles  6  L INEAR REGRESION AND FD BY MPF AND EXPERIMENTAL DATA  To emphasize the possibility and to show the ability of the MPF algorithm to perform parameter estimation and fault detection scheme, an illustrative actual application is presented in this section. This application uses real experimental data. The aim is to detect a fault often encountered in oilfield industry This fault concerns a head of a drilling process \(drill bit in other words, it occurs on the part of the drilling process which grinds the rock. Here the objective is to detect the malfunction that might occur on this bit. As explained in the previous section, these malfunctions are described by a change in a parametric slope. To understand how this kind of dysfunction can interfere with process operation, plots of E  S and ROP over time are given in Fig. 5. Before sample number 1500 ROP  was adjusted continuously to fi nd a set of points that allows to construct a slope. It can be noticed that during this samples interval S is almost constant. It is due to the fact that dysfunction has not yet occurred. In this case, the mean value of the drilling strength comes from rock hardness. In spite of rock homogeneity and a constant ROP in the sample   S and E increases. These increases come from TOB and WOB and are due to the change in the friction coefficient E\(Mpa                             Samples Slope  Fig.3. Estimated slope data \(50 particles In this figure, two functioni ng modes can be noticed, one corresponding to the safe func tioning and the other to the faulty process. Each of thes e two modes presents a stable regime. Between 2500 and 2700 samples the process is in transient regime. There is no fl uctuation in the evolution of the slope that corresponds to the good performances of the algorithm. Here, the transient re gime is achieved by the PF In addition, the MPF shows good performances in terms of rapidity to detection, c onvergence to the value which characterizes the fault, among others. Its performances depend on the number of particles. When the number of particles is increased the dura tion of the transient stage is reduced as shown in Fig. 4 S\(Mpa Samples  Fig. 5. Behavior of measurements in case of dysfunction on the drill bit 500 500 500 500 


0.1 0.5 E as a function of S S \(Mpa E \(Mpa   Raw measurement 1000 3000 4500 0.005 0.015 0.025 0.3 500 2500 4000 0.01 0.02 0.03   6                                       0.005 0 0.2 0.4 0.6 0.7 0.8 1 2 3 4 5 6 7 8 9    Slope obtained by MPF   Fig.6. E as a function  of S-raw data- and linear regression by MPF                                        0 1500 2000 3500 5000 Samples Slope    Fig.7. Slopes progress real data \(50 particles  The Fig.6 presents an exampl e of application of the MPF algorithm by using experimental data. It can be seen from this figure the raw measurement and the slope obtained by using MPF. The Fig.7 presents the temporal evolution of the slope in the case where the number of particles is equal to 50. It can be seen from this figure two regimes of functioning the first one corresponds to the absence of faults, in this case the mean value of the slope is equal to 0.025 and the second corresponds to the case where there is fault the mean value of the slope becomes equal to 0.012 7  C ONCLUSIONS  A FD approach based on the MPF is studied in this paper The approach proposed uses two models: one represents the process evolution in presence of fault and another when the process is safe. The performances of the proposed approach are highlighted by using simu lated and experimental data This approach showed interesting results in terms of rapidity in detection, convergen ce to the final value, as well as robustness against noises The requirement to diagnose bit dysfunction when it is incipient is useful concerni ng appropriate corrective action to take and that brings the process to an optimal drilling condition. The next step of this study is to develop a fault tolerant control algorithm in or der to automatically adjust the input of the drilling proce ss in case of bit dysfunction detection. Also, in the future research we will consider the case where several classes of faults are defined, that will help to detect and define the fault severity A CKNOWLEDGMENT  The authors would like to thank the Schlumberger Riboud Product centre for supporting this work R EFERENCES    G. Paulsen, K.Zacny  P. C hu, E.M u m m   K.Davis S.Frader-Thompson, H. Cannon, B. Glass, \223Robotic Drill Systems for planetary Exploration\224, Proc. AIAA Space 2006, San Jose, CA, September, 2006 2  T  Richard and E. Detournay, E. \223Influence of bit rock interaction on stick slip vibrations of PDC bits\224 Society of Petroleum and E ngineers, Texas, October 2002   L Ljung 223Sy s tem identification \226Theory for the user\224 Prentice Hall, Upper Saddle River, NJ, 2nd edn 1999   A Doucet, N.J Gordon, and V. Krishnam u rthy   223Particle filters for state estimation of jump Markov linear system\224, IEEE Trans Signal Process., \(49 3 pp. 613-624, 2001   A Doucet N De Freitas and N. Gordon, \223Sequential Monte Carlo methods in pr actice\224. Springer, Verlag 2001  T. Sch\366n, R  Karlsson and F Gustafsson 223The marginalized particle filter in practice\224. In proceedings IEEE Aerospace Conference, Big Sky, USA, Mars 2006  223Particle filters for system  identification of state-space models linear in either parameters or states\224. In proceedings of the 13 th IFAC symposium in system identification, pages 1287-1292 Rotterdam, The Netherlands, September, 2003  ac 223Particle filters for system identification with applica tion to chaos prediction\222 Proceedings to 13 th IFAC symposium in system identification, Rotterdam, Th e Netherlands, September 2003  P. Li, R  Goodall, and V Kadirkamanathan. \223Estimation of parameters in a linear state space model using Raoblackwellised particle filte r\224. IEEE proceedings of Control Theory Applications, 151\(6 November, 2004    0 0 


paper the presented meter-wave radar height-finding model only considers the influence of the specular reflection However when the reflection surface is rough the model should be further modified REFERENCES 1 He Jin Chen Jian-wen Liu Zhong Azimuth superresolution approach for meter wave radar based on realvalued genetic algorithm Chinese journal of radio science,19\(3 2004 2 Hu Xiao-qin Chen Jian-wen Chen Hui Height-finding of meter-wave radar using the neural network Journal of wuhan radar institute 18\(3 2004 3 Chen Jian-wen Wang Bu-hong Hu Xiao-qin Meterwave radar heightfinding using radial basis function neural network The 9th radar annual conference Qingdao.307309 2004 4 Merrill.Skolnik Radar handbook\(Second Edition Publishing house of electronics industry 2003 5 Russia R.V.Ostrovityanov  F.A.Basalov Statistical theory of extended radar targets Artech House 1985 6 Bassem R.Mahafza Huntsville Alabama Radar systems analysis and design using MATLAB,2000 7 T.Lo J.Litva Use of a highly deterministic multipath signal model in low-angle tracking IEEE PROCEEDINGS-F 138\(2 1991 8 Katarina Boman Petre Stoica Low angle estimation models methods and bounds Digital Signal Processing 11\(1 2001 9 Schmidt R 0 Multiple emitter location and signal parameter estimation IEEE Trans on AP 34\(3 1986 BIOGRAPHY Hu Xiaoqin received the B.S degree in array signal processing from Wuhan Radar Institute Wuhan Hubei China in 2005 She is now studying in the College of Electronic Science and Engineering National Univ of Defense Technology Changsha Hunan China for the doctor's degree Her research interests are array signal processing and meter-wave radar height-finding 7 


hospital is an example of a service that might be of interest to visitors as well Exercise tips is an example of a dynamic information object that can take parameters from a CitiScape and return specific information depending on the context of the CitiScape.  Here, different exercise information will be presented, depending on the role of the CitiScape, which in turn depends on the role of the user.  The time facet may be used to determine in which situations or times information is available; for instance, in case of a health emergency, users visiting any of the health CitiScapes may be redirected to a CitiScape dealing specifically with emergency services and information.  Thus, for example, the items from the table above could be dynamically assembled into the identified CitiScapes in Figure 4.  These CitiScapes cater to the interests of different users based on their context of interaction    Figure 4: Example CitiScapes associated with Health  4. Application Benefits of CitiScapes Architecture  In this section we explore the more strategic benefits of the CitiScape architecture further  Business Intelligence Mining  CitiScape architecture realizes that the knowledge of the services that the user needs is available only partially with the user while the Government itself holds a lot of that knowledge.   Hence, a symbiotic interaction is facilitated by CitiScapes between the user and the Government.  With every step in the interaction, the user reveals more of his interest and context of interaction and the system narrows these services and pushes them to the user.  The interaction sequence could be also monitored as follows 1  A user enters the system through a general CitiScape providing value for location and time  2  When a user is identified as a citizen, the system knows that the user could be interested in spaces like Citizen Finding Healthcare, Citizen Emergency, Citizen Staying Healthy, but they could also be interested in other spaces like job opportunities, community events, filing taxes etc They could even be interested in more specific spaces like Senior Health or Family Health.  This provides intelligence on populations and in certain areas  3  If the user indicates interest in finding healthcare the system narrows down the services that it will push to the user. So, the focus now will be on spaces related to healthcare as opposed to spaces related to employment or taxes, for example.  The user may then access an item like general exercise tips or finding a doctor.  Thus, the spaces of Citizen, Staying Healthy, Citizen Finding Healthcare and Citizen Emergency will be relevant for this level of interaction.  Now we have a significant understanding of the users interests The user may choose to stop at this level if their need has been met, or he may continue interacting with the system to get more services.  This type of telescoping can provide significant understanding of trends within populations as well 4  Next if this user is a senior citizen, they could enter the CitiScape for senior citizens and now access additional items or even view the same items from the perspective of a senior citizen.  So if they want to look at exercise tips, they could find those specific to senior citizens in this CitiScape.  They would also be able to find other information such as nutrition, common ailments and access services such as participation in community events for senior citizens.  They could access a general service like finding the nearest doctor or hospital but could also access a specific service such as finding a doctor specializing arthritis, since they are now a part of the Senior Health CitiScape.  Thus, they are now looking at not only those services that they initially thought they wanted, but also related services in which they would now be interested, even if they weren t aware of them initially.  Again, this provides insights into new needs   In summary, this sequence illustrates several aspects 1\he user has an intuitive and progressive interaction with the system that provides needed services, 2\e sharing and reuse of items like exercise tips across spaces and in contexts that are both general \(as in the Citizen Staying Healthy CitiScape\r more specific \(as in the Senior or Family Health CitiScapes\d finally, 3\ the dynamic population of the spaces based on citizen interaction to provides significant intelligence Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


Dynamically enhanced navigation and user experience In a traditionally organized website, the citizen might begin at the city homepage, and traverse links through a structure that is often organized by department.  We can think of the CitiScape architecture and navigation path as a continual narrowing down of the user s intent until the user arrives at a place where they can complete their intended interaction.  However, even this generalization is optimistic for many government web presences which have become cluttered and disorganized due to the rapid increase in demand for online services and the lack of time and/or experience necessary to keep all of the information contained in a web presence accurate, timely and organized.  In addition, the internal organization structure \(e.g departments\ is not an appropriate structure for navigability.   For instance, given a certain service need, how would a citizen know whether his or her request should go to the Public Service or the Public Safety department?  As shown in the previous section CitiScapes addresses these issues by providing views of services relevant to users, their roles and interests and the additional facets that account for their individual context for using the system  Improved reuse and searchability  The overall approach used at all levels is to dynamically populate the CitiScapes and the items within them with content.  The content objects themselves are all maintained in a self-contained and local fashion and used whenever and wherever they meet the criteria.  This occurs not only when populating the CitiScapes but also when developing content.  To illustrate the point, suppose a content provider role needed to add a new news story to Getting Health Care In the proposed layered CitiScapes architecture, the news story would be a specific independently maintained object with a collection of attributes, such as Title, Author, Date Created, Date of Expiration, Summary, Body, and Subject, along with additional attributes to define its position in an underlying taxonomy and its applicability to various CitiScapes.   Instead of creating all of the attributes values uniquely, the content role will have the opportunity to select from existing objects as values for attributes of the news story object Selecting an object and content that most likely already exists in the system enforces reuse of the existing information, avoids duplication, and specifies a dynamic relationship between the two objects Getting health care and news story.  Next a query can be easily constructed to find any news story releases related to a given subject Moving to such a dynamic approach also allows us to take advantage of semantic querying.  For example logic and ontology languages such as RDF and OWL can be used to express relationships between objects and facilitate flexible queries and searches, as well as inference  Improved services The role facet allows great flexibility of user access to objects in a CitiScape-based system.  It supports the integration of various services using data from the enterprise directory and CMS-based user registration as well as profiles gathered from user behavior and online transaction activity As the users in different roles narrow their intent by navigating and providing values for the different facets that the CitiScapes are built on; the system pulls appropriate service items based on accumulated knowledge about the particular user.  For instance, if there exists some profile or cookie information indicating that the given user has used the website many times to find information on public parks, the system might direct them to a CitiScape having a focus on parks or outdoor activities.  If we know that the user is a citizen of the city, the system will direct them to a citizen-centered CitiScape, as opposed to directing a visitor to a visitor-centered CitiScape. This two-way interaction will help us identify those services that are used often and in what context, those that are not used and even what CitiScapes are effective.  Thus the information can help the government strategically to develop services that are more specific to the citizens  Service Use and IT Traceability A CitiScapes implementation improves the ability to collect and mine relevant information about how when, and where services and information are used For example, we can now track for each object which CitiScapes are being used to access it, and thereby know which user groups and roles are associated with its use.  Combining this information with traditional web presence metrics such as length of time spent viewing information or completing a service navigation patterns, and frequency of access will allow more user-centric performance data to be gathered Deriving patterns from these observations will allow the government organization to truly understand the needs and habits of the citizenry, and incrementally improve the services and information it provides Additionally, we will be able to provide business-IT traceability, because we also know which back-end system each object is residing in, and therefore track the usage of these systems in order to provide better analysis of technology use  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


5  Conclusions  Structuring an eGovernment system around the concept of CitiScapes will provide significant benefits to users of the system as well as administrators and stakeholders.  The dynamic population of CitiScapes presents users with services chosen to match their roles and needs, thereby affording the opportunity to push  highly relevant services to a user in addition to retrieving information to satisfy a given need, while ensuring trustworthiness and security by only providing services that the user can access based on their role.  The organization of services by relevant facets gives users easy access to needed services without having to understand how the government organization is structured.  The support for underlying information objects and relationships provided by the CMS allows the connection to be made between the different dimensions of the portal environment; it is now possible to keep track of when, where, how and by whom services are being used, and gather this information to provide performance feedback to the system for future improvement. In addition, the reusability of information and service objects across multiple CitiScapes increases maintainability of the web presence by centralizing the change process away from pages toward services.  Finally, we envision that eventually the support for CitiScape-type features will be incorporated into CMS systems to enable better socio-technical interactions   6.   References  1 H M G o v e r n m e nt. T r a n sf or m a tiona l G o v e r n m e n t Ena b le d  by Technology. TSO, Norwich, UK, 2005  2 Hille r, Ja nine S., Be la ng e r F. P r iv a c y Stra te g i e s  f o r  Electronic Government. The PricewaterhouseCoopers Endowment for the Business of Government Report, January 2001  3 Mc C l ure  D  G o v e rn m e nt T r a n sf or m a tion: G e tting Joined-Up Governance Right. Gartner, Inc., September 2007  4 D i Ma io, A  G ove rnm e nt a nd W e b 2.0: T h e Em e r g i ng Midoffice. Gartner, Inc., September 2007   DiM a io  A  W h at Do es W e b 2  0  M ean to G o vern men t Gartner, Inc., March 2007  6 D a w e s  S., Eg le ne O  N e w  m ode ls of c o lla bora tion f o r  delivering government services: A dynamic model drawn from multi-national research Proceedings of the 2004 Annual National Conference on Digital Government Research, 2004   I P S V Bo ard Int egrat e d P u b l i c S e ct o r  Vo cab u l ary   Version 2.00. Porism Limited, SW9 8BJ, 2006  8 L a m b e  P  O r g a nis i ng K now le dg e  Ta x onom ie s   Knowledge and Organisational Effectiveness. Chandos Publishing Ltd, Oxford, 2007  9 T o lone W A hn, G P a i, T  H ong S. A c c e s s C ontr o l i n  Collaborative Systems. ACM Computing Surveys, Vol. 37 No. 1, March 2005, pp. 29 41  10 Ni ta-Ro taru  C L i N. A Frame w o rk f o r Ro le-Based  Access Control in Group Communication Systems. ISCA 17th International Conference "Parallel and Distributed Computing Systems". San Francisco, CA, USA. 15-17 Sept 2004  11 But l e r T Cole m a n, D  Mode ls of Colla bo ra tio n  Collaborative Strategies, September 2003 http://www.collaborate.com/publication/newsletter/publicatio ns_newsletter_september03.html   12 Ce nte r f o r D i g ita l G o v e rnm e nt. Eng a g e Cre a ting e Government that supports Commerce, Collaboration Community and Commonwealth. e.Republic Inc., 2007  13 Ci ty of  T a m p a  Ta m p a G ov  http www ta m pa g o v ne t  14 Ci ty of  A u rora CO. htt p w ww a urora g o v org   15 Be lk in N. J   Cr of t, B 199 2 Inf orm a tion f ilte ring  and information retrieval Communications of the ACM  35 12\, 29-38  16 Ce nte r f o r D i g ita l G ove rnm e nt http://www.centerdigitalgov.com/index.php   17  Sing a pore I n f o m a p. http w w w sg    18 Ma c M a n us R i c h a r d. EG o v e r n m e nt Me e t s W e b 2.0  ReadWriteWeb, November 5, 2007  19 L i bra r y of Cong re s s  Sum m it on Se ria l s in t h e D i g ita l Environment Glossary http://www.loc.gov/acq/conser/glossary.html   20 USA g ov ht tp www usa gov   21 Dire c t G o v  htt p w ww dire c t g ov uk    Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


  11 to request, review, and propose changes to the current state of the science plan Distributed Operations 227 Cassini distributed all aspects of the instrument operations to the science teams. Science Teams were required to develop the spacecraft commanding for pointing the spacecraft. Th is significantly complicated the interfaces and coordination required by the JPL science and sequencing teams. The distribution of internal instrument commanding and monitoring instrument health and safety worked well. Dedicated full-time operations personnel were required at all instrument sites. The liaison between the distributed sites and JPL required definition of a strong JPL Investigation Scientist \(i.e., Experiment Representative\le Distributed operations is a two-edged sword. Scientists personally worked operations and were better able to optimize for their science objectives. Their insight provided the feedback necessary to quickly respond to science discoveries in the science selection and uplink processes This allowed the operations team to capitalize on truly extraordinary opportunities to a degree not thought possible However, this was at the cost of doing science analysis and publishing science results Software Development 227 The Cassini mission deferred most of its ground software development until post launch. In fact, considerable effort was spent accelerating the development of the tools required to plan the Jupiter flyby observations in 2001. For the start of the science integration for Cassini\222s prime mission, many of the ground software planning tools were immature or unavailable. To compensate, homegrown tool development occurred at the instrument sites and within science planning. System engineering of these types of ground software tools was lacking. A better paradigm would have been to develop the operations and ground system\222s architecture, requirements models, and software to a level sufficient to support operations pre-launch. Sufficient project resources needed to be applied to Phase B/C/D development. The science planning tools should be developed to a sufficient level during these phases such that th ey can be used as part of evaluating the ground and flight system requirements and capabilities. Based on this evaluation, refinements could be made during cruise and throughout the mission to the unified ground and flight system architecture and software requirements Programmatic  Project Science 227The orbiter consists of 8 Principal Investigator \(PI\struments and 4 Facility Instrument with corresponding Team Leads. In a ddition, there are 5 different science discipline teams: Rings, Saturn, Titan, Icy Satellites and Magnetosphere. The Project Science leader ship needed to be highly involved in the tactical and strategic science planning activities. The consensus building culture used on Cassini was time consuming. The Project Science support staff should be funded adequately to allow the Project Scientist to participate in the integration process. Clear Project Science guidelines are very helpful Instruments 227 Instrument Flight Rule development must be mature pre-launch. Instruments should be designed to minimize impacts on the operations of the other instruments, e.g., radiator placement. Data compression internal to instruments is vital. For Cassini, the science instruments had internal sequencing memory for storing instrument commanding for upcoming sequence. This allowed the science teams th e ability to send real-time noninteractive instrument commands that bypass the sequencing process by using the Automated Sequence Processor \(ASP  In-flight Testing 227 The targeted gravity assist flybys provided a unique opportunity to exercise the ground system on realistic science data acquisition scenarios that simulates the operational environment during the Tour phase of the prime mission. This also had the advantage of providing the science instrument teams an opportunity to acquire useful science data for the purposes of instrument checkout and science data analysis. The in-flight exercises should use the processes, procedures, software, and ground system capabilities in the same manner, to the extent possible, as will be used during Tour and Orbital operations The entire flight team \(mission planning, science planning sequencing, spacecraft, naviga tion, and science teams should be fully engaged to provide the maximum benefit to the Project 7  C ONCLUSION  Even though Cassini was a NASA flagship mission maximizing the science return was a challenge to science planning operations. Decisions aimed at saving both prelaunch and operations costs added considerable complexity to both the spacecraft and the ground system. Among the key ones were removing the scan platform, opting for distributed operations rather than co-location, and delaying development of some flight software and most of the ground system until after launch Understanding the operational challenges to maximizing Cassini science return and the successful techniques employed to overcome those challenges as presented in this paper should be of value to other deep space science missions.  Future missions should carefully consider the following advice 200  Pay careful attention to operational scenarios in development cost saving decisions, both spacecraft and ground. Additional, more sophisticated commanding constructs may be required in operations to compensate for lack of spacecraft capabilities. Ground management of stressed or 


  12 degraded spacecraft components will be labor intensive   R EFERENCES    N. Vanderm ey and B G. Paczkowski 223The C a ssi ni Huygens Mission Overview,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Andrew M i shki n and B a rbara Larsen 223Im p l e m e nt i ng Distributed Operations: A Comparison of Two Deep Space Missions,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006 3 Barb ara Larsen 223Bu ilt Bu t No t Used Need ed  Bu t No t Built: Ground System Guidance Based On CassiniHuygens Experience,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Spi l k er, Li nda J \(edi t o r o  a R i nged Wold\224,NASA SP-533, 1997  Jennifer Long Maxwell, W illiam M Heventhal, III, and Shahram Javidnia, \223The Cassini-Huygens Sequence Development Process\224, 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Paczkowski  B G, \223C assi ni Sci e nce Pl anni ng Process\224 2004 AIAA SpaceOps Conference Proceedings, May 17 21, 2004 200  Recognize that lack of margin in any resource required for science return will require compensatory staffing. Pr edefined, prevalidated options for resource management such a power modes can compensate. Tools that validate resource allocation are essential 200  Anticipate alternative costs for failing to meet MOS development schedules. The ground system needs to have reached sufficient maturity to support key operations tasks before those tasks commence 200  Distributed science operations introduces delays and complications to sequence development, which must be managed in science planning. System engineering will need to deal with overlap in and conflict between ground systems 200  Acknowledge that complexity in any form\227 spacecraft design, science objectives, MOS architecture\227may be managed to enhance science return but the science planning operations must be funded and structured to manage that complexity The processes to develop science commanding will be lengthy and highly iterative In the end, with an appropriate funding profile, adequate and timely staffing, and effective processes and tools all the facets of mission complexity can be managed to extract amazing science return 8  A CKNOWLEDGEMENTS  The authors would like to acknowledge the dedication and hard work done by the Cassini-Huygens Flight and Science Teams. Without their efforts the unrivaled science collected by the Cassini mission would not have been achieved This work was performed at the Jet Propulsion Laboratory California Institute of Technol ogy, under contract with the National Aeronautics and Space Administration  251 2008 California Institute of Technology. Government sponsorship acknowledged 


  13 B IOGRAPHY  Brian Paczkowski is currently the Deputy Section Manager of the Planning and Execution Section within the Systems and Software Division at JPL. Prior to that he spent 9 years as the Cassini Science Planning Manager responsible for the development and implementation of the Science Operations Plan. Prior to Cassini, he was the Science Planning and Operations Team Chief for the Galileo Mission to Jupiter. He has also been involved with the pre-launch development of the science instruments on Galileo, Comet Rendezvous and Asteroid Flyby \(CRAF\ and Cassini missions. He has a BS in Astronomy from Villanova University and did graduate studies in Astronomy at Ohio State University  Barbara Larsen  is the Mission Operations System Engineer for the Cassini Mission. She is also on the science planning staff and previously worked in system engineering for the Mission Sequence Subsystem. She has a MS in Mathematics from California State University Long Beach and a BS in Mathematics from USC Trina Ray  is currently the Titan Orbiter Science Team \(TOST\ co-chair and the Science System Engineer for the Project Scientist for Cassini. She has been working on the Cassini Mission since before launch as an instrument operations lead for the Radio Science Team, and then as part of the Science Planning Team supporting Titan integrati on and sequence development She has a MS in Astronomy from San Diego State University and a BS in Physics, Astronomy option from CSUN  


  14  


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



Correlation Hiding by Independence Masking Yufei Tao1, Jian Pei2, Jiexing Li1, Xiaokui Xiao3, Ke Yi4, Zhengzheng Xing2 Abstract Extracting useful correlation from a dataset has been extensively studied. In this paper, we deal with the opposite namely, a problem we call correlation hiding \(CH fundamental in numerous applications that need to disseminate data containing sensitive information. In this problem, we are given a relational table T whose attributes can be classified into three disjoint sets A, B, and C. The objective is to distort some values in T so that A becomes independent from B, and yet their correlation with C is preserved as much as possible. CH is different from all the problems studied previously in the area of data privacy, in that CH demands complete elimination of the correlation between two sets of attributes, whereas the previous research focuses on partial elimination up to a certain level. A new operator called independence masking is proposed to solve the CH problem. Implementations of the operator with good worst case guarantees are described in the full version of this short note I. INTRODUCTION Correlation elimination is fundamental in applications that need to disseminate data containing sensitive information Assume, for example, that the census bureau has produced a table T with attributes A = {Race}, B = {Income}, and C Investment-expense, Food-expense, Entertainment-expense which needs to be put online to allow the public to study the spending behavior of various ethnic groups and income classes. Doing so, however, will also reveal the correlation between Race and Income, which should be avoided, because such correlation may lead to sensitive debates such as how much wealthier an ethnic group is than another. In other words, the government would like to release T in such a way that hides the correlation between Race and Income, and yet preserves all the other correlations The problem cannot be settled by giving away two tables: \(i T1 that has only A and C, and \(ii is because their equi-join T1  T2 may restore a significant portion of the original T . The worst case is that no two tuples in T have the same values on C, allowing the equi-join to rebuild T precisely A good solution in the above scenario should fulfill two requirements. First, it must totally destroy the dependence 


between Race and Income. That is, the Income distribution of any specific race, such as Caucasian, should look exactly the same as that of any other race, such as Asian. Second, it needs to do so by distorting as little information in T as possible Otherwise, the resulting table would not allow researchers to perform meaningful data mining, thus defeating the objective of publication This paper deals with a general version of the problem described earlier. Assume that we are given a table T whose attributes have been classified into three disjoint subsets A, B and C. The goal is to compute another table T ? where the set A of attributes is independent from the set B of attributes a large number of values of T are retained We refer to the above problem as correlation hiding \(CH to which we are not aware of any adequate solution. It is opposite to the classic topic of correlation extraction in data mining. The closest existing works are found in the areas of privacy preserving data publication \(PPDP rule hiding \(ASH fundamentally different from both PPDP and ASH, in that CH demands complete elimination of some designated correlation whereas PPDP and ASH focus on partial elimination up to a certain level. Such a difference renders the solutions of PPDP and ASH inapplicable to CH In this short note, we propose an operator called independence masking \(I-masking The operator works by masking some values in T in order to make the sets of attributes A and B appear mutually independent. The goal is to minimize the number of values masked. In the full version of this short paper, we show that the problem is NP-hard, and describe several fast approximate algorithms with good approximation guarantees. The full paper also contains experiments that verify the practical effectiveness of I-masking in the context of association rule mining II. RELATED WORK In this section, we review two problems that are similar to the problem of correlation hiding \(CH and explain why the existing solutions are not applicable to CH Privacy preserving data publication \(PPDP PPDP has received considerable attention from the database 


and data mining communities \(see the recent work [1] and the references therein information, PPDP aims at computing an anonymized version T ? that satisfies a privacy constraint, such as k-anonymity 3], [4] or -diversity [2], pre-determined by the administrator PPDP is similar to CH in the sense that both of them need to distort the correlation between two sets of attributes A and B in the original table T The key difference between PPDP and CH is the degree of distortion. Specifically, the goal of PPDP is to distort just to the level required by the underlying privacy constraint. Any 1 Chinese University of Hong Kong 2 Simon Fraser University 3 Nanyang Technological University 4 Hong Kong University of Science and Technology 978-1-4244-5446-4/10/$26.00  2010 IEEE ICDE Conference 2010964 additional distortion should be avoided because, in PPDP, the remaining \(un-distorted released, as it is the target of research studies. In contrast, CH aims at complete removal of the correlation between A and B namely, they must appear totally independent from each other in the published T In fact, CH even differs from PPDP in their fundamental rationales. Specifically, the motivation of PPDP is to conceal the details of a distribution, but preserve its big picture. The reason is that statistical analysis does not require fine details anyway; hence, even with some details removed, the resulting dataset can still be useful for statistical studies. In contrast the distribution targeted by CH must be fully destroyed, and is not meant to be analyzed at all Association rule hiding \(ASH each of which is a set of items from a discrete domain such as products sold by a supermarket. Denote by R the set of association rules that can be mined from S. Assume that there is a subset R? of R that is sensitive, and should not be known by the public. The objective of ASH [5] is to modify S to another dataset S? such that the \(insensitive in R ? R? can still be discovered from S?, but those in R cannot Unlike ASH that deals with transactions, CH is concerned with relational tables. Even if one regards a relational table as a set of transactions \(by treating each cell as an item, and each 


tuple an item set CH due to two reasons. First, ASH demands two parameters namely support and confidence, to define association rules It is unclear how these parameters would fit in CH. Second similar to PPDP, an ASH algorithm does not fully eliminate the data correlation, because some \(insensitive rules must remain discoverable. CH, as mentioned before demands complete removal of the correlation between two sets of attributes. In fact, it appears rather difficult to even cast CH as an ASH problem. The reason is that association rules are essentially a specific type of correlations, whereas the objective of CH is to eliminate any correlation in general III. PROBLEM DEFINITION In this section, we will formalize the problem of correlation hiding \(CH been classified into three disjoint subsets A, B, and C. The correlation between attribute sets A and B is sensitive, and must be fully concealed. C, on the other hand, involves all the remaining attributes of T that do not belong to A and B. CH aims at converting T to another dataset T ? such that I. A and B are independent in T ?, and II. T ? preserves the other correlations in T as much as possible We refer to T as the source table, and T ? as the sanitized table Note that the two requirements are not equally important requirement I has a higher priority. Specifically, if T ? has not destroyed the correlation of A and B, it is always a poor solution no matter how well it retains the other correlations in T . This is due to the protective nature of the applications modeled by CH. For instance, consider the motivating example in Section I where A = {Race}, B = {Income}, and C Investment-expense, Food-expense, Entertainment-expense As long as the government is not convinced that the correlation between Race and Income has disappeared, it would prefer to keep the data away from public access Requirement I can be described in a more rigorous manner as follows. Let a be any value in the domain of T ?.A, and similarly, b be any value in the domain of T ?.B. Note that in case A \(B b vector. Denote by Pr[a] \(or Pr[b T ? whose values of A \(B b 


by Pr[a, b] as the percentage of tuples in T ? carrying both a and b simultaneously. Then, the independence in requirement I can be specified as Pr[a, b] = Pr[a]  Pr[b]. \(1 As an immediate corollary, one can easily verify that if the above equation holds, then any subset of A is also independent from any subset of B The other correlations in requirement II can be specialized into 5 concrete types 1. Correlation A: the correlation among the attributes in A 2. Correlation B: the correlation among the attributes in B 3. Correlation C: the correlation among the attributes in C 4. Correlation AC: the correlation between the attributes of A and those of C 5. Correlation BC: the correlation between the attributes of B and those of C Apparently, it is straightforward to preserve correlation C because the attributes in C do not need to be touched in correlation hiding at all. Among the other types of correlations correlations AC and BC are of higher importance. This is because in practice C is typically a set of measures, such that the goal of scientific studies is to find out how those measures are influenced by the attributes in A and B, respectively CH is a general problem that may be attacked using different methodologies. This is analogous to the opposite problem of correlation extraction, which can be performed by clustering association rule mining, classification with decision trees, etc In the next section, we describe a feasible methodology to perform CH IV. INDEPENDENCE MASKING We present an operator called independence masking \(Imasking parameter u, whose effect will be explained later. Denote by n the cardinality of the source table T . In the sequel, we will assume that n is a multiple of u. In case it is not, we randomly remove at most u ? 1 tuples from T to make the property hold. As will be clear later, u is typically by far smaller than 965 BA tuple ID Age Occupation Income 1 30~50 CEO 25k 2 30~50 Salesman 4k 


3 30~50 Prof 10k 4 > 50 Prof 20k 5 30~50 Prof 11k 6 < 30 Prof 6k 7 < 30 Manager 18k 8 < 30 Manager 13k 9 < 30 Manager 7k 10 30~50 Prof 15k 11 30~50 Prof 9k 12 30~50 Prof 6k tuple ID Age Occupation Income 1 30~50 CEO 3 2 30~50 Salesman 1 3 30~50 Prof 2 4 > 50 Prof 3 5 30~50 Prof 2 6 < 30 Prof 1 7 < 30 Manager 3 8 < 30 Manager 2 9 < 30 Manager 1 10 30~50 Prof 3 11 30~50 Prof 2 12 30~50 Prof 1 BA BA tuple ID Age Occupation Income 1 30~50 * 3 2 30~50 * 1 3 30~50 * 2 4 * Prof 3 5 * Prof 2 6 * Prof 1 7 < 30 Manager 3 8 < 30 Manager 2 9 < 30 Manager 1 10 30~50 Prof 3 11 30~50 Prof 2 12 30~50 Prof 1 a b c Fig. 1. Example 1 \(B has only one attribute a b intermediate table T  after replacing each Income value with a cluster label. \(c n; hence, removing at most u ? 1 tuples will not lose much 


information To facilitate discussion, let us assume, without loss of generality, that A has d attributes A1, A2, ..., Ad. Denote by dom\(Ai T ? that has as many tuples as T . Furthermore, the attributes of T ? can also be classified into disjoint subsets A, B, C such that A has d attributes corresponding to those in T . Specifically, the domain of each attribute in A augments the domain of the corresponding attribute of T by a special symbol ?. Formally, dom\(T ?.Ai T .Ai for all 1 ? i ? d B has a single attribute whose domain is the set of integers from 1 to u. It relates to the set B of attributes in T such that each integer of T ?.B represents a cluster of T in its subspace B C is exactly the same as the C of T . Namely, I-masking touches only A and B, and leaves C intact More precisely, I-masking has three steps detailed as follows 1. Partition T based on its attribute set B into u clusters such that every cluster has an equal number of tuples Label the clusters as 1, 2, ..., u, respectively Once this is done, the values of T .B are no longer needed we will be concerned only with the clusters. Hence, let us replace the B values of each tuple with the label of the cluster it belongs to. This creates an intermediate table T , whose A and C are the same as T , but its B has an integer domain of [1, u 2. Mask some A values of T  as ? so that A and B are independent from each other. Let the resulting table be T 3. Return T ?, as well as the u clusters of B values obtained earlier in the first step Next we illustrate the above steps with two examples. Since I-masking does not alter the attributes in C, we will omit them in our examples but their presence should be implicitly understood Example 1. Consider that T is the table in Figure 1a, where A Age, Occupation} and B = {Income}. Note that 30?50 is a raw value of Age \(as opposed to a generalized value as one would find in k-anonymization [3], [4 


equals 3. Step 1 of I-masking creates u equal-sized clusters out of the values in T .B. Here, B has a single numeric attribute. So the clustering results in three intervals: [4k, 7k 9k, 13k], and [15k, 25k], each of which covers the Income of exactly 4 tuples. Label these intervals \(i.e., clusters 2, 3, respectively. Replacing each Income value with the label of the interval it falls in gives the intermediate table T  in Figure 1b Step 2 of I-masking hides some values of A with the symbol until A and B have become independent. The resulting table T ? is shown in Figure 1c, where 6 ? are used. To see the independence of A and B, notice that Equation 1 holds for any values a and b in the domains of A and B in Figure 1c respectively. For example, let a = \(*, Prof we have Pr\(a, b Pr\(a b Finally, I-masking returns the table in Figure 1c, together with the Income values in clusters, namely, cluster 1 = {4k 6k, 6k, 7k}, cluster 2 = {9k, 10k, 11k, 13k}, cluster 3 = {15k 13k, 20k, 25k In Example 1, B involves only a single attribute. Next, we will see another example where B has multiple attributes Example 2. Let T be the table in Figure 2a, where A Race} and B = {Income, Saving}. Assume u is 2. For clarity, we denote the B values of each tuple as a 2D point in Figure 2b. As before, Step 1 of I-masking clusters these points into u clusters, as illustrated in Figure 2b. Figure 2c shows the intermediate table T  after replacing the B values with cluster labels. Step 2 of I-masking generates the sanitized 966 Race Income Saving r1 point 1 \(see right r1 point 2 r1 point 3 r1 point 4 r1 point 5 r1 point 6 r2 point 7 r2 point 8 r2 point 9 r2 point 10 r2 point 11 


r2 point 12 A B Income Saving cluster 1 51 2 3 6 7 4 9 8 cluster 2 11 12 10 A B Race Cluster r1 1 r1 1 r1 1 r1 1 r1 2 r1 2 r2 2 r2 2 r2 2 r2 2 r2 1 r2 1 A B Race Cluster r1 1 r1 1 1 1 r1 2 r1 2 r2 2 r2 2 2 


2 r2 1 r2 1 a b c d Fig. 2. Example 2 \(B has multiple attributes a b clustering on T .B. \(c d table T ? as in Figure 2d, where the two attributes have become independent. This T ? is returned, together with the points in Figure 2b \(i.e., the B values of T Although in the previous examples B contains only numeric attributes, I-masking also works even if some or all the attributes in B are categorical. The only thing we require on B is the ability to cluster its values. This can be achieved by many algorithms, such as k-means \(with straightforward adaptation to ensure all clusters are equally large clustering in the metric space. These algorithms are applicable as long as one can supply a distance function to calculate the similarity of two objects, which is easy to formulate in most applications Quality of correlation preserving. It is clear that I-masking completely retains Correlations B and C \(see the classification of correlations in Section III attributes are returned directly. The introduction of ?, apparently, loses a part of Correlations A and AC. Furthermore the choice of u also affects Correlation BC. To see this, recall that, in T ?, I-masking essentially presents the projection of T on B in the form of u clusters; hence, a larger u captures Correlation BC better It would be nice if we could put an upper bound on how much of Correlations A, B, and AC is lost. This, unfortunately, is not possible because CH has a compulsory goal eliminating the correlation between A and B \(see requirement I in Section III related such that removing their correlation would necessitate masking all values. It thus follows that I-masking is a besteffort process. Namely, we should reduce the information loss as much as possible, on condition that requirement I is satisfied. Put differently, given a specific value of u, we would like to generate T ? using the smallest number of Following this rationale, I-masking can be cast as the following optimization problem 


PROBLEM 1: Let T  be a table with d + 1 attributes Among these attributes, there is one, denoted as B, whose domain consists of integers from 1 to u. Denote by A as the set of all other d attributes in T T  has the property that exactly 1/u of its tuples carry 1 2, ..., u as their B values, respectively. Let T ? be a table that is identical to T  except that some values in the attributes of A have been masked by ?. T ? is said to be independent if its A and B are independent from each other. The goal is to find an independent T ? containing the smallest number of stars V. WHAT IS IN THE FULL PAPER The full paper contains several formal results on Problem 1 Specifically, the paper first shows that the problem is NPhard, and then, gives two fast approximate algorithms with approximation ratios u ? 1 and d, respectively. Furthermore the full version also includes experimentation to demonstrate the effectiveness of I-masking in association rule mining ACKNOWLEDGEMENTS This work is supported by Grants GRF 4161/07 and GRF 4173/08 from HKRGC REFERENCES 1] Y. Bu, A. W.-C. Fu, R. C.-W. Wong, L. Chen, and J. Li. Privacy preserving serial data publishing by role composition. Proc. of the VLDB Endowment PVLDB 1 2] A. Machanavajjhala, J. Gehrke, D. Kifer, and M. Venkitasubramaniam diversity: Privacy beyond k-anonymity. In Proc. of International Conference on Data Engineering \(ICDE 3] P. Samarati. Protecting respondents identities in microdata release. IEEE Transactions on Knowledge and Data Engineering \(TKDE 6 1027, 2001 4] L. Sweeney. Achieving k-anonymity privacy protection using generalization and suppression. International Journal on Uncertainty, Fuzziness and Knowledge-based Systems, 10\(5 5] V. S. Verykios, A. K. Elmagarmid, E. Bertino, Y. Saygin, and E. Dasseni Association rule hiding. IEEE Transactions on Knowledge and Data Engineering \(TKDE 4 967 


tags. However, only a few algorithms have been proposed to handle tags synonymy problem, by mainly focussing on clustering similar tags together using mostly similarity metrics In Szomszor et al. [14], the authors present an algorithm for the tag merging by synonymy. The proposed algorithm performs the task in three stages: \(i matrix of synonyms by using WordNet; \(ii non-ambiguous synonym and; \(iii synonym pairs with the term that is most popular. Even though this can be of help ?nding a pair of synonym tags it can somewhat restrict synonym tags discovery. Indeed if a synonymy between a pair of tags is found, the pair is directly replaced by the synonym term without further checking, whereas one of the tags pair may have other synonyms. In the following, we introduce a new algorithm called EXTRACTSYNTAGSET, that investigates all possible synonymys relationships between tags. Thus, EXTRACTSYNTAGSET searches in WordNet synonyms candidate in folksonomy by invoking the SEARCHSYN procedure. Moreover, contrarily to the Szomszor et al. approach, [14], the extracted set of tags synonyms is added to the set of synonyms tagsets, i.e., SSyntagset, for tags meanings enrichment. The pseudo-code of EXTRACTSYNTAGSET is sketched by Algorithm 1, whereas the used notations are summarized in Table II EXTRACTSYNTAGSET takes as input the set SSimtagset resulting from the previous step and outputs the set SSyntagset, which contains the representative tags with their associated synonyms. The EXTRACTSYNTAGSET procedure operates as follows: in Lines 2-3, it initializes the set SL by the ?rst representative tag in the set of representatives tags extracted from SSimtagset, i.e., RT , and an empty set, i.e., all synonyms of the tag occurring in folksonomy must not be retrieved later in the search procedure, and initializes the set SSyntagset to the empty set From Line 4 to 21, the algorithm iteratively searches for synonym tags corresponding to the representative tag in the folksonomy. This is done until the set SL becomes empty Thus, in each iteration, STagset is initialized by tagsets associated to st1.tag in SSimtagset where st1 is the ?rst 


element in SL In Line 7, EXTRACTSYNTAGSET invokes the SEARCHSYN procedure to search for synonym tags, i.e., SS . Thereafter, in Lines 8-9, st1 and the related tag st1.tag are respectively removed from SL and RL 373 Table II NOTATIONS USED IN THE EXTRACTSYNTAGSET ALGORITHM SSimtagset : The set of tagsets which contains all equivalent tags and their representative tag SSyntagset : The set of tagsets which contains all synonym tags and their representative tag RT : The set of representatives tags extracted from SSimtagset STagset : The set of tagsets which contains the representative tag and the associated synonyms SL : The set of pairs \(tag, notSynTags SS : The set of synonym tags of the representative tag Next, cf., Lines 10-18, EXTRACTSYNTAGSET selects each tag t from SS and checks whether it has not been treated yet In such case, EXTRACTSYNTAGSET checks whether it is already inserted in SL, i.e., it has been retrieved with another tag, then st1.tag have to be added to the set t.notSynTags Otherwise, a new entry associated to t must be created with a set containing st1.tag and added to the set SL At end of the iteration \(outer loop its set of synonyms tagsets, i.e., STagset, is added to SSyntagset. Thereafter, cf., Lines 20-21, if RT = ? and SL = ?, then EXTRACTSYNTAGSET adds a new entry to the set of pairs. Otherwise, the algorithm comes to an end with the set SSyntagset Step 4: Filter infrequent tagsets Filter out tags occurring less than a certain threshold B. Group related tags The second step of NONTAXFOLKS is to identify groups of related tag, i.e., representative tag in folksonomy. Approches using clustering or statical similarity metrics techniques for the organisation of related tags into clusters are widely used. Hence, in [5], the author uses a subsumption based model, derived from the co-occurrence of tags, to ?nd groups or related tags. On the other hand, Begelman et al 15] organise the tag space as an undirected graph, repre 


senting co-occurring tags as vertices, weighting the edges between them according to their co-occurrence frequency and applying a spectral clustering algorithm to re?ne the resulting groups. However, in such approches, correlation between tags, users and resources are often lost. Indeed, a semantically relation between tags is usually discovered if they had been assigned by users with similar interests. On the other hand, related resources are usually tagged many times by semantically related tags and ?nally users may have similar interests if they share many resources in their assignments In [4], the author use co-occurrence information to build graphs relating tags with users and tags with resources and applies techniques of network analysis to discover sets of clusters of semantically related tags. Similarly, in our proposed approach, we make use of the semantic relatedness embodied in the different frequencies of co-occurences among users, resources and tags in the social bookmarking Algorithm 1: EXTRACTSYNTAGSET Data: SSimtagset : {\(rt, {tagset Result: SSyntagset : {\(rt, {tagset Begin1 SL = {\(RT [1 T S = ?;3 While SL = ? do4 st1 = SL[1];5 STagset = {tagsets1 | ? \(st1.tag, tagsets1 SSimtagset SS = SEARCHSYN\(st1 RT = RT \\ {st1.tag};8 SL = SL \\ {st1};9 Foreach tag t ? SS do10 If t ? RT then11 If ? st2 ? SL | st2.tag = t then12 st2.notSynTags = st2.notSynTags13 st1.tag Else14 st2.tag = t;15 st2.notSynTags = {st2.tag};16 SL = SL ? {st2};17 STagset = STagset ? {tagsetst | ? \(t,18 tagsetst 


SSyntagset = SSyntagset ? {\(st1.tag,19 STagset If RT = ? ? SL = ? then20 SL = {\(RT [1 return SSyntagset ;22 End23 system, i.e., folksonomy. However, instead of using probabilistic models or network analysis techniques for grouping related tags, we mine frequent triadic concepts. Indeed, the triadic concept structure describes three types of sets: \(i set T of related tags; \(ii i.e., users whose have tagged by T and; \(iii resources, i.e., which were assigned with T by users U Hence, triadic concepts allow grouping semantically related tags taking into account the Users tagging behavior in a folksonomy In fact, in [16] and [11], the authors have considered a folksonomy as a triadic context and proposed an algorithm called TRIAS to get out implicit shared conceptualizations formally sketched by triadic concepts. TRIAS takes as input a folksonomy F := \(U , T, R, Y by its representative tag beforehand identi?ed, i.e., trep, as well as three user-de?ned thresholds : u ? minsupp, t minsupp and r ?minsupp. The TRIAS algorithm outputs the set of all frequent T C that ful?ll these aforementioned 374 thresholds Hence, running TRIAS algorithm on the triadic context depicted by Table I, with u ?minsupp = 2, t ?minsupp 2 and r?minsupp = 2 yields the following tri-concepts T C1 = {\(u1, u2, u3, u5, u7 t2, t3, t4 r1, r2, r3 T C2 = {\(u5, u6, u7 t4, t5 r1, r2 T C3 = {\(u2, u3, u4, u7 t1, t4 r2, r3 After the group related tags step, we present in the following the extraction of non-taxonomic relationships C. Non-taxonomic relationship extraction In the following, we introduce an algorithm called NTREXTRACTION for extracting non-taxonomic relationships between pairs of tags picked from the triadic concepts structure. As we previously mentioned, two tasks have to be carried out for learning non-taxonomic relationships: \(i 


discovery and selection of all pairs of related tags; \(ii discovery and selection of predicates, i.e., non taxonomic labels, used for expressing non taxonomic relationships between the pairs of tags according to their semantic meaning Notations used in this algorithm are summarized in Table III The pseudo-code of the NTREXTRACTION algorithm is sketched by Algorithm 2. NTREXTRACTION takes as input two sets: the set of triadic concepts T C and the set of representative tags. NTREXTRACTION outputs the set of all non-taxonomic relationships candidates NT R between tags discovered from T C. NTREXTRACTION operates as follows: ?rstly, NTREXTRACTION discovers all pairs of concepts from the sets of tags contained in the tri-concepts structure. For performing this task and to avoid the useless computation of pairs, NTREXTRACTION invokes the procedure DESCSORTTC which sorts the set of tri-concepts in a descending order with respect to the size of the tag set Line 4 Thereafter, NTREXTRACTION, cf., Lines 10-20, extracts the set of non-taxonomic relationships from each pair of tags. Speci?cally, in Line 11, NTREXTRACTION invokes the SEARCHWIKIPEDIA procedure to identify from Wikipedia sentences containing both tags \(ti, tj we use sentences as text units for analysis since they are Table III NOTATIONS USED IN THE NTREXTRACTION ALGORITHM T C : The set of all frequent tri-concepts T : The set of representative tags NT R : The set of non-taxonomic relationships extracted from Wikipedia T T S : The list of sets of tags which have been used to extract pairs PS : The set of pairs \(ti, tj tri-concepts ST C : Sorted list of tri-concepts SSent : Set of sentences extracted from Wikipedia Stree : Syntactic tree of sentence Algorithm 2: NTREXTRACTION Data 1 2 Result: NT R : {Non-taxonomic relationships Begin1 


T T S = ? ;2 PS = ? ;3 ST C = DESCSORTTC\(T C Foreach tri? concept tc ? ST C do5 If  t ? T T S | tc.tags ? t then6 PS = PS ? {\(ti, tj tc.tags ? tj ? tc.tags ? i < j T T S = T T S ? {tc.tags};8 NT R = ? ;9 Foreach pair \(ti, tj SSent = SEARCHWIKIPEDIA\(ti, tj Foreach sentences ? SSent do12 STree = PARSESENTENCE\(s subject = EXTRACTSUBJECT \(STree, ti, tj If subject = null then15 predicate =16 EXTRACTPREDICATE\(STree If predicate = null then17 object = EXTRACTOBJECT\(STree,18 ti, tj If object = null ? object = subject19 then NT R = NT R ? {subject,20 predicate, object return NT R ;21 End22 more informative than single words to detect relationships between tags pairs. Thus, in the inner loop \(Lines 12-20 NTREXTRACTION invokes the PARSESENTENCE procedure which uses the Stanford Parser to generate a Treebank parse tree for each input sentence Example 5: The parse tree for the sentence S = The concept of open source and free sharing of technological information has existed long before computers existed.. The triplet, i.e., < subject, predicate, object >, is extracted out from this sentence. Since \(S a tree having three children: a noun phrase \(NP concept of open source and free sharing of technological information, a verbal phrase \(V P before computers existed and the full stop TRACTSUBJECT procedure extracts the NP and searches for a mapping with at least one tag of the selected pair 


ti, tj open source, long 375 procedure extracts the compound verb from V P , i.e., has existed. Similarly, the EXTRACTOBJECT procedure extracts one of the three phrases: noun phrase NP , adjective phrase ADV P and prepositional phrase PP Once identi?ed, the set NT R of non-taxonomic relationships candidates have to be pruned to withdraw all infrequent relations. Hence, we make use of Borgelts ef?cient implementation of the APRIORI algorithm for frequent termsets extraction [17]. In the following, we remind some de?nition that will be of need in the sequel De?nition 6: An extraction context is a triplet K NT R, E , M taxonomic relationships, E is a ?nite set of terms and M is a binary \(incidence i.e., M ? NT R  E couple \(ntr, e ntr ? NT R contains the item e ? E Example 6: An example of an extraction context K is depicted by Table IV with O = {ts1, ts2, ts3, ts4, ts5, p1 p2, p3, p4, p5, to1, to2, to3, to4, to5} and I = {ntr1, ntr2 ntr3, ntr4, ntr5, ntr6, ntr7 De?nition 7: A termset9 E is said to be frequent if Supp\(E threshold, denoted minsup. The set of frequent termsets will be denoted FEK Note that we have added a restriction in the APRIORI implementation algorithm for considering only possible combinations between frequent terms. Since only two combinations are allowed, i.e., tag subject and predicates and tag subject and tag object. Therefore, once the set FEK is discovered, the association rules must have to derived only from the frequent 3-itemsets. Indeed, we paid attention to association rules of the form R: ts, to?p, where ts denotes a subject tag, to denotes an object tag and p denotes a predicate Example 7: Given the extraction context depicted by Table IV with minsup = 2 and minconf = 0.5, the derived valid association rules are given by the following table ts1, to4 ? p1 \(2, 0.5 ts1, to4 ? p2 \(2, 0.5 ts3, to4 ? p3 \(2, 1.0 


V. EXPERIMENTAL RESULTS The problem of evaluating non-taxonomically related concepts is quite complex since the non-taxonomic relationships are rarely contained in a gold standard. Hence, few experimental evaluations have been reported for comparing ontologies on the lexical as well as on the taxonomic level, e.g., [18] compares the generated ontology by their methodology against category structure from Open Directory 9 Note that each term may refer to a tag subject, a tag object or a predicate Project10 \(ODP  evaluation of the resulting ontology structure by comparing it to an ontology extracted from sei.cmu.edu and cluster from FLICKR. In fact, an investigation of the structure of existing ontologies via the Swoogle ontology search engine [19] has shown that domain ontologies very occasionally model this kind of relationships. Due to the problem of ?nding gold standards with good non-taxonomic relationships coverage and the amount of the obtained results, a manual evaluation is not reliable. So, we will focus the evaluation step on objective and automatic assessments. In this case, due to the lack of general purpose automatic evaluation procedures new mechanisms should be designed. In the following, we present an approach to evaluate non taxonomic relationships results in an automatic way against an electronic general domain repository: WordNet A. The dataset description We investigate the tag sets in DEL.ICIO.US thanks to both its popularity and availability. In fact, DEL.ICIO.US is a fast growing social bookmarking service. It offer hosts its users to centrally collect and share their bookmarks, which can refer to any resource on the web as long as this resource can be identi?ed by an URL. When adding a bookmark, users can provide a description, by default the title of the web site, an extended description and tags they consider related A bookmark can be added by going to the DEL.ICIO.US web site or, more conveniently, by using one of the many browser plug-ins which make bookmarking to a social bookmarking system as easy as browser wise bookmarking DEL.ICIO.US went online in September 2003 and is still constantly growing. Hence, we apply our NONTAXFOLKS approach on a snapshot11 described in the following table 


Dataset Nb users Nb resources Nb tags Del.icio.us 1518 12813 5621 B. Evaluation measures Assessing semantic similarity between words is a central issue in many research ?elds such as Psychology Linguistics, Cognitive Science, Biomedicine, and Arti?cial Intelligence. Semantic similarity can be exploited to improve accuracy of current Information Retrieval techniques, e.g 20], to discover mapping between ontology entities [21], to validate or repair mappings [22] or to perform word-sense disambiguation [23]. As a matter of fact, semantic similarity is relevant in many research areas and therefore, designing accurate methods is mandatory for improving the performance of the bulk of applications relying on it. Basically similarity or distance methods, e.g., [24] aims at assessing a score between a pair of words by exploiting a semantic 10 http://www.dmoz.org 11 http://data.dai-labor.de/corpus/delicious 376 Table IV AN EXTRACTION CONTEXT Relations/Terms ts1 ts2 ts3 ts4 p1 p2 p3 p4 to1 to2 to3 to4 ntr1 ntr2 ntr3 ntr4 ntr5 ntr6 ntr7 ntr8 network such as WordNet. Different relatedness measures implemented by WordNet::Similarity12 are proposed Given that the basis for the assessment of a relationship between a pair of terms13 comes back to statistical scores computed between terms. In this respect, we use the Jiang relatedness metric [25] that de?nes the link strength between two terms, i.e., e1 and e2. Thus, we have distJIANG\(e1, e1 e1 e2 LCA\(e1, e2 Where LCA\(e1,e2 de?ned in WordNet taxonomy and IC\(ei i ? {1,2 describes the information content of a term e which is de?ned as the negative log likelihood of the probability of 


encountering a related term, i.e. IC\(c e intuition behind the use of the negative likelihood is that the more probable a term to appear, the less information it conveys. All these features show that Jiangs measure tends to be more general and more appropriate for evaluating nontaxonomically related terms. Indeed, a high score of the relatedness measures suggests a strong relationship between terms Nevertheless, all relatedness measures have limitations because they assume that all the semantic content of a particular term is modeled by semantic links in WordNet Consequently, in many situations, truly related terms obtain a low scores even though their belongings to a certain category of tags, e.g., jargon tags Additionally, when measuring the quality of an automatically knowledge acquisition results, the typical measures used in Information Retrieval are Recall, Precision and F-Measure. However, computing Recall and F-Measure requires the availability of a Gold Standard. Hence, we will only compute the Precision which speci?es to which extent the non-taxonomic relationships is extracted correctly. In this case, the ratio between the correctly extracted relations i.e., their relatedness measures is greater than or equal to a minimum threshold, and the whole number of extracted ones is computed. Thus, we have Precision Total correctly selected entities Total selected entities 12 http://search.cpan.org/dist/WordNet-Similarity 13 A term refers to a tag subject or a tag object C. Evaluation of non-taxonomic relationships Only a percentage of the full set of non-taxonomic relationships \(89 is caused by the presence of non standard terms which are not contained in WordNet and, in consequence, cannot be evaluated using WordNet-based relatedness measures. Fig. 5 depicts the evaluation results of the extracted non-taxonomic relationships against their relatedness measures High relatedness score \(88 17% of the extracted relationships, as most of terms are strongly related with respect WordNet Null Scores were obtained for 5% of the extracted 


relationships. Analyzing this case in more detail, we have observed that the poor score is caused in many situations by the way in which Jiangs distance metric works. This latter completely depends on the distance between two terms based on the number of edges found on the path between them in WordNet. In consequence this measure returns a value that does not fully represent reality. For example, on the one hand, Jiangs distance metric returns a null value for the relationship between insurance and car, even though the ?rst is a commonly related to the second, i.e., car involved insurance Finally with a minimal Jiangs distance metric threshold, set to 46%, the computed precision of correctly extracted relationships candidates is equal to 68.8 An example of extracted non-taxonomic relationships is depicted in Table V where each relation describes the subject tag, e.g., tool, the predicate, e.g is being developed within, and the object tag, e.g mesh. Fig. 4 represent a fragment output of the extracted ontological structure where each concept de?nes a set of similar and synonym tags and labels, i.e., mentions has been, revealed, caused and is created with describe the predicates of the non-taxonomic relationships between terms Due to the limitations observed by the automatic evaluation procedure and the lack of gold standards containing non-taxonomic relationships, we have examined the extracted non-taxonomic relationships from a linguistic point 377 Top space      distance     quad great     groovy nifty caused address      addresses extension      quotation   reference  references extensions        referenz     source      refrence sources    rfrences    quotations research    search     searching searchs open-source     open_source 


opensource linux aim     design     designer      designers patern    project     patterns     projekte projects web+design    web_design webdesign internet       internetbs net          web network      networking networks      web discussion     news       password word      words community      communities is_created_with mentions revealed has_been Figure 4. A fragment output of the extracted ontological structure of view. This qualitative evaluation can bring some interesting insights about the kind of results one can expect Invalid relations are extracted: Even though a relation such as music cities skill is considered as correct one since tag subject, tag object and predicate are correctly extracted. From a semantic point of view, this relation has no meaning. Hence, a higher precision is expected Figure 5. Summary of non-taxonomic evaluation measure Table V EXAMPLES OF EXTRACTED NON TAXONOMIC RELATIONSHIPS Subject Predicate Object search has been reference reference mentions search tool is being developed within mesh security added encoding search revealed reference java provides library by performing the sense analysis on complete relations An ambiguity in the extracted predicates between terms is observed: Hence, same relations are redundant since they use a synonym predicates between terms, e.g java provides library and java yields library. Thus we expect that the redundancy removal within extracted relations will be of bene?t for the improvement of the 


obtained results VI. CONCLUSION AND FUTURE WORK The extraction of non-taxonomic relationships from folksonomies is to the best of our knowledge is the least tackled task within ontology building from folksonomy. This is why there is a need of novel and general purpose approaches covering the full process of learning relationships. In this paper, we introduced a new approach called NONTAXFOLKS that starts by pre-processing tags aiming at getting a set of frequent tagsets corresponding to an agreed representation Then, they are used to retrieve related tags using external resources such as WordNet. Thanks to the particular structure of triadic concepts, it allows grouping semantically related tags by considering the semantic relatedness embodied in the different frequencies of co-occurences among users, resources and tags in the folksonomy. Thereafter we introduced an algorithm called NTREXTRACTION for extracting non-taxonomic relationships between pair of tags picked from the triadic concepts. In summary, our approach uses several well known techniques \(such as formal concept analysis or association rule discovering the social bookmaring environnement in order to propose a new way of extracting labeled non-taxonomic relationships between tags. Currently, we are investigating the following topic concerning the discovered predicates between two terms. Indeed, in order to avoid relationships redundancy and thus a redundancy in the builded ontology. One can try to classify them into prede?ned semantic classes, detect synonyms, inverses, etc. A standard classi?cation of verbs could be used for this purpose, adding additional information about the semantic content, e.g., senses, verb types, thematic roles, etc., of predicates relationships 378 REFERENCES 1] J. Pan, S. Taylor, and E. Thomas, Reducing ambiguity in tagging systems with folksonomy search expansion, in Proceedings of the 6th Annual European Semantic Web Conference \(ESWC2009 2] V. S. M. Kavalec, A. Maedche, Discovery of lexical entries for non-taxonomic relations in ontology learning, in Proceedings of the SOFSEM 2004, LNCS, vol. 2932, 2004, pp 249256 


3] L. Specia and E. Motta, Integrating folksonomies with the semantic web, in Proceedings of the 4th European Semantic Web Conference \(ESWC 2007 Innsbruck, Austria, vol. 4519, June 2007, pp. 624639 4] P. Mika, Ontologies are us: A uni?ed model of social networks and semantics, in Proceedings of the 4th International Semantic Web Conference \(ISWC2005 3729, Galway, Ireland, June 2005, pp. 522536 5] P. Schmitz, Inducing ontology from ?ickr tags, in Proceedings of the Workshop on Collaborative Tagging \(WWW 2006 Edinburgh, Scotland, May 2006 6] M. Zhou, S. Bao, X. Wu, and Y. Yu, An unsupervised model for exploring hierarchical semantics from social annotations, in Proceedings of the 6th International Semantic Web Conference and 2nd Asian Semantic Web Conference ISWC/ASWC2007 Korea, vol. 4825, November 2006, pp. 673686 7] C. Schmitz, A. Hotho, R. Jaschke, and G. Stumme, Mining association rules in folksonomies, in Proceedings of the 10th IFCS Conference \(IFCS 2006 2006, pp. 261270 8] A. Hotho, A. Maedche, S. Staab, and V. Zacharias, On knowledgeable unsupervised text mining, in Proceedings of Text Mining Workshop, Physica-Verlag, 2003, pp. 131152 9] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme, Information retrieval in folksonomies: Search and ranking, in The Semantic Web: Research and Applications, vol. 4011 Springer, 2006, pp. 411426 10] F. Lehmann and R. Wille, A triadic approach to formal concept analysis, in Proceedings of the 3rd International Conference on Conceptual Structures: Applications, Implementation and Theory. Springer-Verlag, 1995, pp. 3243 11] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G.Stumme Discovering shared conceptualizations in folksonomies Web Semantics: Science, Services and Agents on the World Wide Web, vol. 6, pp. 3853, 2008 12] A. Mathes, Folksonomies - cooperative classi?cation and communication through shared metadata, Graduate School of Library and Information Science, University of Illinois Urbana-Champaign, Tech. Rep. LIS590CMC, December 2004 13] H. Lin, J. Davis, and Y. Zhou, An integrated approach 


to extracting ontological structures from folksonomies, in Proceedings of the 6th European Semantic Web Conference ESWC 2009 vol. 5554, 2009, pp. 654668 14] M. Szomszor, H. Alani, K. OHara, and N. Shadbolt, Semantic modelling of user interests based on cross-folksonomy, in Proceedings of the 7th International Semantic Web Conference \(ISWC 2008 15] G.Begelman, P. Keller, and F.Smadja, Automated tag clustering: Improving search and exploration in the tag space, in Proceedings of the the Collaborative Web Tagging Workshop WWW 2006 16] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G. Stumme TRIAS - an algorithm for mining iceberg tri-lattices, in Procedings of the 6th IEEE International Conference on Data Mining, \(ICDM 2006 2006, pp. 907911 17] C. Borgelt, Ef?cient implementation of APRIORI and ECLAT, in FIMI, COEUR Workshop Proceedings, COEURWS.org, vol. 126, 2003 18] J. Tang, H. Leung, Q. Luo, D. Chen, and J. Gong, Towards ontology learning from folksonomies, in Proceedings of the 21st international jont conference on Arti?cal intelligence IJCAI 2009 20892094 19] L. Ding, T. Finin, A. Joshi, R. Pan, R. Cost, Y. Peng P. Reddivari, V. Doshi, and J. Sachs, Swoogle: A search and metadata engine for the semantic web, in Proceedings of the 13th ACM Conference on Information and Knowledge Management, ACM Press, 2004, pp. 652659 20] A. Hliaoutakis, G. Varelas, E. Voutsakis, E. Petrakis, and E. E Milios, Information retrieval by semantic similarity, International Journal on Semantic Web and Information Systems IJSWIS 21] G. Pirro, M. Ruffolo, and D. Talia, Secco: On building semantic links in peer to peer networks, Journal on Data Semantics XII, LNCS 5480, pp. 136, 2009 22] C. Meilicke, H. Stuckenschmidt, and A. Tamilin, Repairing ontology mappings, in Proceedings of the International Conference AAAI 2007, Vancouver, British Columbia, Canada 2007, pp. 14081413 23] S. Ravi and M. Rada, Unsupervised graph-based word sense 


disambiguation using measures of word semantic similarity in Proceedings of the International Conference ICSC 2007 Irvine, California, USA, 2007 24] H. G. A. Budanitsky, Semantic distance in wordnet: an experimental application oriented evaluation of ?ve measures in Proceedings of the International Conference NACCL 2001 Pittsburgh, Pennsylvania, USA, 2007, pp. 2934 25] J. Jiang and D. Conrath, Semantic similarity based on corpus statistics and lexical taxonomy, in Proceedings of the International Conference ROCLING X, 1997 379 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



An efficient algorithm for frequent itemsets in data mining  Jiemin Zheng 1, Defu Zhang 1, Stephen C. H. Leung 2, Xiyue Zhou 1 1Department of Computer Science, Xiamen University, 361005, China \(zhengjiemin@gmail.com 2Department of Management Sciences, City University of Hong Kong, Hong Kong mssleung@cityu.edu.hk  ABSTRACT Mining frequent itemsets is one of the most investigated fields in data mining. It is a fundamental and crucial task Apriori is among the most popular algorithms used for the problem but support count is very timeconsuming. In order to improve the efficiency of Apriori, a novel algorithm, named BitApriori, for mining frequent itemsets, is proposed Firstly, the data structure binary string is employed to describe the database. The support count can be implemented by performing the Bitwise And operation on the binary strings. Another technique for improving efficiency in BitApriori presented in this paper is a special equal-support pruning. Experimental results show the effectiveness of the proposed algorithm, especially when the minimum support is low Keywords: data mining; frequent itemsets; Apriori; binary string  1. INTRODUCTION  Data mining is a widely-used process for discovering information from large databases, within which association rules discovery is one of the most popular technologies. It was first formulated in 1993 by Argawal et al. [1]. Data mining based on association rules can be divided into two parts: finding all frequent itemsets, and generating reliable association rules from all frequent itemsets. Frequent itemsets mining plays an essential role in association rules mining. It is a very time-consuming procedure. Frequent itemset and association rules mining problems have attracted increasing research interest. In order to solve these mining problems more efficiently, hundreds of research papers have presented new algorithms or improvements on existing algorithms. Frequent itemsets mining appears as a subproblem in many data mining problems besides association rules, such as correlations 


classification, clustering, Web mining, and so on. Since association rules are useful and easy to understand, they have been successfully applied to many business fields None of the prevalent methods can outperform other methods for all datasets with every support threshold However, there are three algorithms that are playing a central role. These algorithms are Apriori [2], Eclat [3 and FP-growth [4]. Due to their efficiencies, many of the developed algorithms are modifications or combinations of these basic methods  The first frequent itemsets mining algorithm, AIS, was published by Agrawal et al. [1]. A year later, Apriori [2 one of the most noticeable algorithms, was proposed by the same authors. Over the next few years, studies on improvements or extensions of Apriori have been extensive. Many modifications to Apriori have been proposed. DHP \(direct hashing and pruning initial candidate set generation, proposed in Pork et al 5], is widely viewed as an effective algorithm. This method efficiently controls the number of candidate 2-itemsets, pruning the size of database. In Brin et al 6], the dynamic itemset count \(DIC proposed. For finding large itemsets, it uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling \(Brin et al. [7 proposed in Toivonen [8] reduces the number of database scans to a single scan, but still wastes considerable time on candidate itemsets. Partitioning technique is introduced by Savasere et al. [9 Cluster-based association rule \(CBAR tables by scanning the database once in Tsay et al. [10 The algorithms support count is performed on the cluster table and it need not scan all transactions stored in the cluster table  Recently, a FP-growth algorithm is proposed by Han et al. [4]. FP-growth is a depth-first search algorithm that scans the database only two times. The data structure FP-tree is used for storing frequency information of the original database in a compressed form. No candidate 


generation is required in the method. Dynamically considering item order, intermediate result representation, and construction strategy, as well as tree traversal strategy, are introduced in Liu et at. [11]. An array based implementation of prefix-tree-structure for efficient pattern growth mining is proposed in Grahne et al. [12  In 1996, Zaki et al. [13] developed algorithm Elcat. In Elcat, database is vertically represented. Later, dElcat was introduced in Zaki et al. [14]. It employs a technique, called diffset, for reducing memory requirement  Recently, BitTableFI with data structure BitTable has been introduced by Dong et al. [15]. BitTable is used horizontally and vertically to compress database for quick candidate itemsets generation and support count respectively. Later, in Song et al. [16], Index-BitTableFI employed index array to improve the algorithm  978-1-4244-6487-6/10/$26.00 2010 IEEE In this paper, the Trie, that has been shown to be a very efficient data structure for mining frequent itemsets in Ferenc [17], is employed to record frequent itemsets. In Apriori, on one hand, support count is the most time wasting process. On the other hand, candidate generation dominates the run-time, which consumes large quantities of processing memories, particularly in dense, medium-size databases. In order to overcome these issues, in this paper, a novel data structure, binary string, is added into each leaf of the Trie, which compresses the database for quick support counting and avoiding candidate itemsets generation. An equal-support pruning, based on two important properties introduced in Ferenc [18], is employed in BitApriori. It contributes to reducing not only the execution time but also the required memory, for the procedure. Experimental results show that equal-support pruning is very efficient in BitApriori  There are four major advantages in BitApriori. First, it 


needs to scan the database only twice. Second, the equal-support pruning contributes to reducing the height of the Trie. Third, only frequent items in each transaction are inserted as nodes into the Tree, and their support count can be implemented by performing operation, on the corresponding binary strings. Finally all frequent itemsets are generated by checking the leaves of Trie, without traversing the tree recursively which significantly reduces computing time  The rest of this paper is organized as follows. Section 2 briefly revisits the problem definition, of frequent itemset mining. Two important properties are listed in Section 3. In Section 4, we propose the BitApriori algorithm. Section 5 analyzes the performance of the proposed algorithm. Section 6 concludes this study and points out some directions for future research  2. PROBLEM STATEMENT  Frequent itemsets mining can be formally stated as follows. Let I be a finite set of symbols called items Any subset X I?  is called an itemset. An itemset with k items is called a k-itemset. Let D be a set of transactions, where each transaction T is a set of items such that T I? . For any itemset X I? , the set of transactions that contains X is defined as the cover of X  1 The support of X is the number of elements in set coverD\(X contain X, is denoted as sup\(X  sup  Dcover XX D  2 An itemset X is called frequent if sup\(X or equal to some given percentage of min_sup, where min_sup is called the minimum sup. The set F is the set of frequent itemsets 


sup 3 The task of frequent itemset mining \(FIM compute the set F of all frequent itemsets for the given database D and a support threshold min_sup  3. TWO IMPORTANT PROPERTIES  In this section, two important properties are introduced which are used for equal-support pruning in BitApriori  Property 3.1 Let , ,X Y Z I?  and X Y? . If sup     Proof. For X Y? , so  sup          be deduced. For         sup   If the support of a frequent itemset { }X i?  is equal to the support of X, then support of every superset X i Z? ?  is equal to the support of X Z? . So there is no need to generate all such supersets anymore one only has to keep the information, such that every superset of { }X i?  is represented by a corresponding superset of X  Property 3.2 Let Y be the prefix of itemset Y z where | | 1z = . If Y has a subset X such that 1 | |X Y+ =  and sup  sup   Proof. Derived from Property 3.1  Based on property 3.2, a special equal-support pruning can be designed. The equal-support pruning has two main steps. First, before the support of a candidate itemset Y z?  is counted, support of the itemset 


Y z?  is equal to the support of the frequent itemset Y if one of its subset X has the same support with X z The frequent itemset Y z?  is pruned, and put in the equal-support set of its parent, frequent itemset Y Second, before a new frequent itemset is inserted into the Trie, it is pruned and put in the equal-support set of its parent, if its support is equal to its parent  Lemma 3.1 When checking all subsets of a k+1 for all d<k+1, need to be considered, if the special equal-support pruning based on Property 3.2 is employed \(see Ferenc [18  Proof. This statement can be proved by contradiction As we all know, if a frequent itemset is generated as a node in the Trie, all its subsets have been generated as a node already. Let the candidate denoted by P 1P k= + . One of its subsets is Q, Q={i1, i2, , ij, , ik i?I. Let Q={i1, i2, , ij-1} and E={i1, i2, , ij}. If ij is in the equal-support set of 'Q , \\E P Q?  has been pruned at iteration 1j + . But \\E P Q?  is a subset of P, so P cannot be a candidate itemset  In Apriori, the special equal-support pruning based on Property 3.2 can be employed. Before the k+1 check if all k-subsets of the candidate itemset are frequent. An extra checking at the \(k-1 prefixes of k-subsets can be added, to apply the equal-support pruning. If one of the k-subsets is in the equal-support set, the candidate itemset can be pruned immediately, and put in the equal-support set of its parent. But to use the pruning based on Property 3.2, it is required to check if the support of the newly generated frequent itemset is equal to its parent. So in Apriori, after support count, it must add an additional tree traversal to check if the support of the new leaf is equal to that of its parent. In BitApriori, the additional tree traversal is not necessary  4. THE PROPOSED BITAPRIORI ALGORITHM 


 The data structure and implementation related techniques introduced in [19, 20] can also be employed by BitApriori, which is an Apriori-like algorithm. The main differences between Apriori and BitApriori lie in candidate itemsets generation and support count approach. These two steps consume the most time and memory in the Apriori algorithm. The time required for mining frequent k-itemset grows significantly when k increases in Apriori. But BitApriori performs much better because it has no candidate generation and needs to traverse the Trie only once. The pseudocode for BitApriori is shown in Table 1 TABLE 1 THE PSEUDOCODE FOR BITAPRIORI Input: dataset D, min_sup Output: frequent itemsets 1: Scan database D once and delete infrequent items 2: Sort frequent single items into nondecreasing order by supports 3: Scan database D again and find all frequent 2-itemset, then establish the Trie with the binary string in each leaf 4: k  3 5: while the height of the Trie is increased do 6:     generation\(k 7:     k  k+1 8: end while 9: write out the frequent itemsets from Trie As shown in Table 1, in Step 1, the database is scanned the support of each item is counted, and infrequent items are deleted. In Step 2, frequent single items are sorted into a nondecreasing order, according to their respective supports. The database is scanned again to find all frequent 2-itemsets, and record each of the frequent 2-itemsets with a corresponding binary string After that the Trie with the binary string in each leaf is established. Then the next layer of the Trie is generated until the height of the Trie is not increasing. In the last step, the frequent itemsets are written out from the Trie TABLE 2 THE PSEUDOCODE FOR THE PROCEDURE GENERATION\(K Procedure: generation\(k 1: for each node p in the \(k-1 2:     for each node q?{brother nodes of p at right side} do 3:         check \(k-1 


4:         if equal-support do 5:             put the item in node q into the equal-support set of p 6:         end if 7:         else if infrequent do 8:             continue 9:             end if 10:        else 11:            string s  \(string in p string in q 12:            count The number of 1 in s 13:            if count < min_sup*|D| do 14:                nothing 15:            end if 16:            else if count is equal to the support in p do 17:                put the item of node q into the equal-support set of p 18:                end if 19:            else 20:                add a son node to p, recording count and the item in q 21:            end else 22:        end else 23:    end for 24:    delete the binary string in node p 25:end for  The pseudocode of the procedure generation\(k in Table 2. The k-layer of the Trie is generated. Each node p, in the \( 1 combined with one of its right side brother nodes q. All 1 1 is in the equal-support set, the item in node q is put into the equal-support set of p. If one of the \( 1 is infrequent, all of its supersets are infrequent. If none of the \( 1 equal-support set, the & operation between the string of node p and q is performed. The support of the candidate itemset is the number of 1 in the result string. If the support is equal to p, the item in node q is added into the equal-support set of p. If the support is not equal to p, or is larger than the minimum support, a new son node of p, recording the support and the item in node q, is inserted into the Trie 


 To demonstrate the process of BitApriori, an example is given, as follows. As shown in Table 3, the example database is in the second column. In the database, there are 10 transactions TABLE 3 THE EXAMPLE DATABASE TID Items Ordered frequent items 1 A B D E F L A E 2 A G O G A 3 C E I C E 4 A C D E G G C A E 5 A B C E G K G C A E 6 E H E 7 A B C E F J C A E 8 A C D C A 9 A C E G M G C A E 10 A C E G N G C A E Suppose the support threshold min_sup is 40%. The support of each item is counted, and infrequent items are deleted, during the first scan of the database. The support of each item is given as follows A:8, B:3, C:7, D:3, E:8, F:2, G:5, H:1, I:1, J:1, K:1, L:1 M:1, N:1, O:1 Since the minimum support is 4, frequent items are sorted into a nondecreasing list, according to their respective supports. And if two items have the same support, they will be sorted according to their lexicographic order. The result is shown in Table 4 TABLE 4 FREQUENT ITEMS Item G C A E support 5 7 8 8 TABLE 5 FREQUENT 2-ITEMSETS TID Ordered items G C G A G E C A 


C E A E 1 A E 0 0 0 0 0 1 2 G A 0 1 0 0 0 0 3 C E 0 0 0 0 1 0 4 G C A E 1 1 1 1 1 1 5 G C A E 1 1 1 1 1 1 6 E 0 0 0 0 0 0 7 C A E 0 0 0 1 1 1 8 C A 0 0 0 1 0 0 9 G C A E 1 1 1 1 1 1 10 G C A E 1 1 1 1 1 1 sup  4 5 4 6 6 6 In Step 2 of BitApriori, all frequent 2-itemsets are found as shown in Table 5. The Trie with the binary string shown in each leaf is established, which is shown in Fig 1  5 8 8 G C A E A 4 C 0001100011 4 E 0001100011 6 A 0001101111 6 E 0011101011 6 E 1001101011 7  Fig. 1.  Trie after generation\(2 The next step is to generate the third layer of the Trie First, itemset {G, C, E} is checked. All of its subsets are 


frequent, and there is no equal-support pruning in its subsets. So the Bitwise And Operation on binary strings of 0001100011 and 0001100011 is employed. As the result is 0001100011, the support of the itemset {G C, E} is 4, which is equal to {G, C}. E is put into the equal-support set of {G, C}, and does not need to add a new son node. When itemset {C, A, E} is checked, all of its subsets are frequent, and none of them is in the equal-support set. The corresponding two bit strings 0001101111 and 0011101011, are operated by &. The resultant string is 0001101011. The number of 1 in string 0001101011 is 5. So the support of itemset {C, A E} is 5, which is not equal to the support of {C, A}. So a new son node is added to {C, A}. The Trie after generation\(3  5 8 8 G C A E A 4 C 4 E 6 A 6 E 6 E 7 5 E 0001101011 E  Fig. 2. Trie after generation\(3 In generation\(4 therefore, the height of the Trie does not increase. All frequent itemsets are in Fig. 2. In the last step, all frequent itemsets are written out according to the Trie  5. EXPERIMENTAL RESULTS  


The proposed algorithm is tested on all the five datasets prepared by Roberto Bayardo, from UCI and PUMSB datasets. The datasets are available at http://fimi.cs.helsinki.fi. The characteristics of the datasets are shown in Table 6. The first column contains the names of the datasets. The second column shows the number of items contained in each dataset. The third column shows the average length of each transaction and the last column indicates the total number of transactions in each dataset TABLE 6 DATABASE CHARACTERISTICS Datasets Items Avg. length Records mushroom 119 23 8,124 chess 75 37 3,196 pusmsb* 2,088 50.4 49,046 connect 129 43 65,557 pusmsb 2,113 74.0 49,046 In order to illustrate the performance of the proposed algorithm, BitApriori is compared to the fast Apriori implemented in Ferenc [20], and another similar recently published, algorithm Index-BitTableFI proposed by Song [16]. In order to show the efficiency of the pruning technology employed in BitApriori another algorithm BitAprioriNE, which is the same as BitApriori, except that it does not use the special equal-support pruning, is designed. All of the above four algorithms are implemented in C++ and compiled with Microsoft Visual C++ 6.0. The experiments are performed on a Windows XP PC equipped with a Pentium 2.0 GHz CPU and 1.5 GB of RAM memory  For each dataset, a mass of different support thresholds are tested, and the five most important of them are chosen for reporting in this paper. The experimental results are shown in Fig. 3-7. In the figures, the y-coordinate denotes the execution time \(in seconds while x-coordinate denotes the support threshold 0 100 200 300 400 


500 600 0.05 0.06 0.07 0.08 0.09 0.1 0.11 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.3 Execution time comparison on mushroom  0 200 400 600 800 1000 0.45 0.5 0.55 0.6 0.65 0.7 0.75 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.4 Execution time comparison on chess  0 500 1000 1500 2000 2500 3000 3500 4000 0.25 0.3 0.35 0.4 0.45 0.5 0.55 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.5 Execution time comparison on pusmsb 0 1000 


2000 3000 4000 5000 6000 0.65 0.7 0.75 0.8 0.85 0.9 0.95 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.6 Execution time comparison on connect  0 500 1000 1500 2000 2500 0.675 0.725 0.775 0.825 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.7 Execution time comparison on pusmsb  As shown in Fig. 3, BitApriori outperforms all other algorithms, and the dominance is apparent. In this dataset, the special equal-support pruning works efficiently. In Fig. 4, BitAprioriNE beats Apriori and Index-BitTableFI. In Fig. 5, the effectiveness of the proposed algorithm is verified, especially when the minimum support is low. In Fig. 6, BitAprioriWE exhausts the memory when the support threshold is lower than 0.8, but BitApriori does not. That means the special equal-support pruning contributes to save the memory. In Fig. 7, when the threshold is larger than 0.725, Apriori beats the BitApriori. But BitApriori outperforms the Apriori, when the threshold is lower than 0.725  


Apriori does not use the binary string and the special equal-support pruning. The BitTable is employed in Index-BitTableFI, but there is no special equal-support pruning, except for the frequent 2-itemsets BitAprioriNE outperforms Apriori in Fig. 3-5, but not in Fig. 6-7, because of the limitation of memory BitAprioriNE does better than Index-BitTableFI in Fig 4 and Fig. 5. In the mushroom, there is a vast number of equal-support itemsets for frequent 2-itemset. So Index-BitTableFI outperforms BitAprioriNE  On one hand, the special equal-support pruning is a useful technique for improving efficiency. The performance is improved significantly, especially when the databases contain many equal-support itemsets, such as the mushroom. It also reduces memory requirement On the other hand, the technique of binary string in BitApriori improves the efficiency of Apriori. These two techniques combine perfectly in BitApriori. So BitApriori has very good performance. It is the best for all of the five datasets  6. CONCLUSIONS  In this paper, two effective techniques are employed to improve the performance of Apriori, by reducing the cost of candidate generation, and by support counting The two effective techniques are integrated perfectly in BitApriori, and improve the computational efficiency significantly. Experimental results have shown that BitApriori outperforms the fast Apriori and Index-BitTableFI, especially when the minimum support threshold is low  When the database is large, the BitApriori may suffer the problem of memory scarcity. So how to solve the memory problem will be the question addressed in one of our future works. And another work is to improve Bitwise And Operation on the binary string, or replace it by some more effective techniques  REFERENCES 


 1] Agrawal R., T. Imielinski, A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the ACM SIGMOD Conference on Management of Data. pp. 207-216 1993 2] Agrawal R., R. Srikant, Fast algorithms for mining association rules, The International Conference on Very Large Databases, pp. 487-499, 1994 3] Zaki M.J., S. Parthasarathy, M. Ogihara, W. Li New algorithms for fast discovery of association rules, in Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, pp. 283-296, 1997 4] Han J., J. Pei, Y. Yin, Mining frequent patterns without candidate generation," in Proceedings of the 2000 ACM SIGMOD international conference on Management of data, ACM Press, pp. 1-12, 2000 5] Pork J.S., M.S. Chen, P.S. Yu, An effective hash based algorithm for mining association rules, ACM SIGMOD, pp. 175-186, 1995 6] Brin S., R. Motwani, J.D. Ullman, S. Tsur Dynamic itemset counting and implication rules for market basket data, in Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 255264, 1997 7] Brin S., R. Motwani, C. Silverstein, Beyond market baskets: generalizing association rules to correlations, in Proceedings of the ACM SIGMOD International Conference on Management of Data Tuscon, Arizona, pp. 265-276, 1997 8] Toivonen H., Sampling large databases for association rules, in Proceedings of 22nd VLDB Conference, Mumbai, India, pp. 134-145, 1996 9] Savasere A., E. Omiecinski, S.B. Navathe, An efficient algorithm for mining association rules in large databases, in Proceedings of 21th International Conference on Very Large Data Bases VLDB'95 10] Tsay Y.J., J.Y. Chiang, CBAR: an efficient method for mining association rules, Knowledge Based Systems, 18 \(2-3 


11] Liu G., H. Lu, W. Lou, Y. Xu, J.X. Yu, Efficient mining of frequent patterns using ascending frequency ordered prefix-tree, Data Mining Knowledge Discovery, 9 \(3 12] Grahne G., J. Zhu, Fast algorithms for frequent itemset mining using FP-Trees, IEEE Transaction on Knowledge and Data Engineering, 17 \(10 1347-1362, 2005 13] Zaki M.J., Scalable algorithms for association mining, IEEE Transactions on Knowledge and Data Engineering, 12 \(3 14] Zaki M.J., K. Gouda, Fast Vertical Mining Using Diffsets, in Proceedings of the ACM SIGMOD International Conference on Knowledge Discovery and Data Mining, pp. 326-335, 2003 15] Dong J., M. Han, BitTableFI: an efficient mining frequent itemsets algorithm, Knowledge Based Systems, 20 \(4 16] Song W., B.R. Yang, Z.Y. Xu, Index-BitTableFI An improved algorithm for mining frequent itemsets, Knowledge Based Systems, 21 \(6 507-513, 2008 17] Ferenc B., Surprising results of trie-based FIM algorithms, IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'04 CEUR Workshop Proceedings, vol. 90, G. Bart, J.Z Mohammed, and B. Roberto, Eds, Brighton, UK 2004 18] Ferenc B., A Survey on Frequent Itemset Mining Technical Report, Budapest University of Technology and Economic, 2006 19] Bart G., Survey on Frequent Pattern Mining Manuskript, 2002 20] Ferenc B., A fast APRIORI implementation IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'03 USA, 2003  


15] R. Agrawal and R. Srikant, "Fast algorithms for mining association rules in large Databases," presented at the Proceedings of the 20th International Conference on Very Large Data Bases, 1994 16] NKUDIC. \(June, 2006, National Kidney and Urologic Diseases Information Clearinghouse:Prostate Enlargement. Available http://kidney.niddk.nih.gov/kudiseases/pubs/prostateenlargement accessed on 10/06/2010 17] M. J. ZAKI, "Mining Non-Redundant Association Rules," Data Mining and Knowledge Discovery, 2004 18] Y. Xu and Y. Li, "Mining for Useful Association Rules Using the ATMS," presented at the International Conference on Computational Intelligence for Modelling, Control and Automation, and International Conference on Intelligent Agents, Web Technologies and Internet Commerce \(CIMCA-IAWTIC05 544 2010 10th International Conference on Intelligent Systems Design and Applications 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



Data Mining-based Informationization Amalgamation Case Study on Advanced Orbit Traffic Equipment Manufacturing Xiufei Li Dalian JiaoTong University Dalian, China xiufei_li@163.com Xiufei Li Dalian University of Technology Dalian, China lixiufei@hotmail.com 
Abstract 
204it is a synthesized and complicated big production activity for advanced orbit traffic equipment manufacturing which needs bulkiness and high content technology, so the informationization is necessary. The amalgamation phase model between Informationization and enterprise\as given. On the base of this, informationization should be used in some case of 
advanced orbit traffic equipment manufacturing quality management. The original and behindhand management method can not realize the real dynamic quality management in quality management actuality. Then the quality management system design was given, which used the data mining, network system structure, dynamic quality management and B/S structure. The model function structure includes power management, collection data management etc. Meanwhile, the quality management system was developed, which has construction log management subsystems. Finally, information technology was given. The practicability, validity and economy of the system were proved through the application in some advanced orbit traffic equipment 
manufacturing companies 
I I NTRODUCTION February 4, 2009 the State Council executive meeting examined and approved in principle the equipment manufacturing industry restructuring and rejuvenation program. The "high-speed rail, urban rail transit" project a top ten light industries in focus Advanced orbit traffic equipment manufacturing production is a synthesized and complicated big production activity, which need bulkiness and high content technology. Its quality control primarily indicate that how to insure the project to reach the need [1, 2  w h ich in clu d e th e qu ali ty lay ou t qu a lity pl e d g e 
Keywords- Data Mining; Advanced Orbit Traffic Equipment Manufacturing; Informationization; Quality management 
and quality control. Quality control management system can analysis, state and access the build project, which will reduce the manpower model on a certain extent and disentangles the management form fussy data processing II Q UALITY M ANAGEMENT S TUDY A CTUALITY Foreign countries have the system theory and practice method and deeply study on different management method Quality control and management is the import factor in insuring the advanced orbit traffic equipment manufacturing project quality, which impenetrate its whole project course [3  Grafting information technology onto advanced orbit traffic equipment manufacturing can make the transition from 
industry society to information society at society economy base, structure, productivity and production relation Meanwhile, it can make the industrial structure to upgrade and update and urge the style of economic increase urge to change from extensive condition to intensive condition. Furthermore, it can urge core business of enterprise production [4 
zation Grafting information technology onto advanced orbit traffic equipment manufacturing can be divided into three phase partial amalgamation, basis amalgamation and complete amalgamation for grafting information technology\(IT\ onto enterprise at side of stratagem, operation, technology 
   operation and service etc. to realize informati  
equipment and resource, which were shown in Fig.1. This paper only discusses the use of information technology in advanced orbit traffic equipment manufacturing quality management Figure 1 amalgamation phase model Production unit should take aberrance coefficient of inspecting quality target as the estimate target [6  T h ey sh o u ld  build allowed limited value for every construction quality target aberrance coefficient. In the advanced orbit traffic equipment manufacturing production, the production quality database should be built and input the production quality checked result into database at any moment. On the base of this, production quality was assessed and quality was tracked 
 
Complete amalgamation  
Basis amalgamation  
978-1-4244-7874-3/10/$26.00 \2512010 IEEE 
Partial amalgamation 
IT Enterprise Technology, equipment Stratagem, operation Resource 


Quality management and control has the characteristic of huge information quantity, better integration, complex management factor and strict disposal method [7  B u t  e x i s t i ng advanced orbit traffic equipment manufacturing company quality control yet settle in manpower disposing phase and use the original and behindhand management method Now, our country has less quality management system software for advanced orbit traffic equipment manufacturing company production management system. Meanwhile, the original and behindhand management method can not realize the real dynamic quality management In order to insure the advanced orbit traffic equipment manufacturing company production quality and improve the management work efficiency, the consummate advanced orbit traffic equipment manufacturing company production quality control management system should be developed based on the system project and whole quality management theory realizing the information management on advanced orbit traffic equipment manufacturing company production III Q UALITY M ANAGEMENT S YSTEM D ESIGN The three aim of advanced orbit traffic equipment manufacturing company production management is investment quality and rate of progress. But, the quality management is the most import task in three aims. Modern quality management is whole orientation quality management emphasizing dynamic control, whole orientation thought, and much knowledge application, especially the computer assistant system application Through the computer assistant system application advanced orbit traffic equipment manufacturing company production quality control was better executed. Meanwhile, the engineering quality was better and timing analyzed and appraised through up growth network and formidable computer technology, which offers the cogent decision-making for the railroad engineering building management. The differences among the construction plan log, inspecting log and data collection log were duly discovered. Then, the reasons were discovered. Thus, the needed sound and image datum were duly draw-out right knowing the engineering whole circulation situation and improving the level of advanced orbit traffic equipment manufacturing company production management In order to solve the memory collection and query problem in advanced orbit traffic equipment manufacturing company production for the manager to know the project build quality data and have assistant right decision-making, a quality management system should be developed by using network technology, computer technology and management theory visual laying out advanced orbit traffic equipment manufacturing company production quality, realizing the fast query and state function This system use the B/S structure adapting the çlean client and fat serveré development current, which is convenience for system maintenance and spread, shown in Fig.2. The system directly meets the internet, so the user can login the system by using the network IE browser at any place. Construction inspecting and data gather manager can finish the data writing and maintenance  mobile notebook user user1 INTERNET /  inner special web usern user2 construction unit user stakeout unit user Management system  Submit data database Figure 2 system network structure According to the system design and demand analysis, the system should reach below aim: The dynamic management and control should be realized for the advanced orbit traffic equipment manufacturing company production quality by using the information technology Collection, store, deal with, protract figure and print table by using the locale check data of advanced orbit traffic equipment manufacturing company production Analysis, plot and count the locale check data by using quality management tools Stat and analysis the locale check data through time, a section of a highway, construction unit and inspecting unit Access data should be deal with and memory for advanced orbit traffic equipment manufacturing company production quality According to function partition, this system has 8 parts in below, shown in Fig.3 Taking quality analysis management model as example amount stat. method is the effective method in whole quality management. The subsystem control the construction quality by using amount stat. method including frank square chart control chart, arrange chart and correlation chart, through which the system can finish the data input, analysis, account construct and print output etc.. This will give the effective quality information A Power Management This model can enroll the user by role and popedom. For example, the advanced orbit traffic equipment manufacturing company production unit user can but vindicate their own unit data and have no power to vindicate other unit data. The system manager can grant other userês power etc B Subproject Management This model can insert, modify, delete and query sub-project etc. work.  For example, it can append the subjectês subproject 


C Quality Access Management Quality access is an import base for management decision This subsystem strictly executes the standard according to railroad engineering quality checking up standardé. This system can automatically accessed the quality and gather the quality stat. and access result Figure 3 model function structure D Construction Log Management Construction unit can insert, modify, delete and query the construction log by using this model. Meanwhile, they can upload and save the important production sound and image datum, which is convenience to be lookup and report IV L OCALE P RODUCTION Q UALITY T RACK A SSISTANT M ANAGEMENT A Redirector Project Locale Construction Quality Track Assistant Management For the redirector of locale construction mass scout assistant management, it is import to supervise and urge assistant locale construction collect data, store, deal with, and plot and report forms, which is uploaded network. Locale check data is calculated, plot and analysis by using quality management tools.  For example, redirector project quality check access is the access in the construction course and after production done with.  First, subentry project and subsection project should be accessed. Then, the project quality should be accessed after the production done with B Bodywork Project Locale Construction Quality Track Assistant Management Giving priority to defend is an import principle, which should analyze the infection factor of the subentry project quality and delete the bad factor. Each tache and working procedure in production should be strictly, system and roundly supervised and managed from the complete game of the bodywork project. In order to control the quality and construction activity for the inspector, a science and logical quality management procedure should be established to instruct the engineering construction and inspection. Quality control is the emphases in the advanced orbit traffic equipment manufacturing company production including: checking the concealment project, go on a tour of inspection for project quality, taking out and check project material and check the pledge system etc C Locale Construction Quality Track Assistant Management First side should assign technology personnel to the advanced orbit traffic equipment manufacturing company production unit to instruct and supervise correspond personnel to put in the observation data and log. Meanwhile, the import production sound and image should be uploading and save First side should engage some professional people to give some accomplish quality analysis, input data, plotting and print table work so that the effective quality information for the project quality control V I MPORTTANT I NFORMATION T ECHNOLOGY A Selected  Server Hardware Flat Roof Because of the big processing data, in order to insure the high stability, security and expansibility, good high capability server and disk array system have been used, such as IBM server and SAN disk array etc B Server Software Flat Roof Oracle8i database and Windows 2003 Server is used. Data layer use oracle database system to effectively store and management the plan data and model data. Logic layer use the JAVA, JSP technology to deal with the data flow answer for project quality logic realization, such as store and show figure data. Application layer realize the quality data application C Data mining design First, the web surrogate server extracted and switched data through extracted switched monitored system from other system and sent the integrated data to partial database with metadata. Then, the quality management system decided the quality through OLAP and data mining system by processing completed multi-dimension data and partial multi-dimension and sent these data to browsers by web application sever. The data mining framework is shown in Fig.4 1 Extracted Data Extracted data is to organize, trim the data in database and offer the data to other system according to certain form demand Extracted data has two methods: the one is extracting tools the other is to write program. The extracting tools have weak security and adaptability. They need to connect with the operation system and data warehouse. In addition, the extracting tools were hardly competent for their work when the extracting process had complex calculation and transition. But the extracting tools can reduce our work and increase extracting effect. In the other hand, to write program had good security and adaptability, but it would increase our work and depress the extracting effect The operation system characteristic of advanced orbit traffic equipment manufacturing engineering build is very complex. It had a lot of data fountain and complex hardware  Advanced orbit traffic equipment manufacturing company production quality management system Power mana g ement Subproject management Construction log mana g ement Stakeout log management First delegate data management Collection data management Quality analysis mana g ement Quality access management 


environment and operation system plat roof. It is just in this sense, we adopted the PL/SQL program to extract the data from the database and organize them according to certain form Increment extracting and complete extracting combined to extract the data from the database. Increment extracting is used to the data with time prickle. The complete extracting and bestrow method is used to extract the data without time prickle if the data number is not large. Otherwise, modified and new data was judged according to the systematic log information and then the method of increment extracting is used 2 Cleaned out and switched data The extracted data must be cleaning out and switching so that they can be validly load into data warehouse. The reason is that the operation is independent and different criterion, but the extracted data in data warehouse must be integrated and accordant There are dirty data in extracted data because the operation systems of advanced orbit traffic equipment manufacturing company production face different operation and the program form criterion are disunion. The dirty data are as following a The format went out of line The data types have potential mistakes  b The consult integration went out of line The data cannot find the consult c The cross system went out of line The same data existed in several operation systems, but they werenêt matching d The inside coherence went out of line The same note repeatedly appeared in the same table, most situations are that some fields had nuance. The fashion of writing PL/SQL program was adopted to clean out switch the data because of many data fountain. Modifyin g and standardizing the repeated data, dealing with the exception and making up the half-baked data were adopted to above problem 3 Loaded and updated data The fashion of writing PL/SQL program was adopted to load data into data warehouse. Corresponding index was made according to referring custom and data structure and number in order to increase the referring speed a First loaded data First loading data can defined that all the operation data including history data were first time extracted to center database from the operation database when the centre database was built up. Manual fashion was adopted because of the large number of data in the first loading data Daily maintenance can be divided into batch maintenance and increment maintenance b Batch maintenance Expert maintenance tools and manual maintenance can be used in batch maintenance. It is divided into three steps: uninstalling data from the operation database, formatting the switched data and loading data c Increment maintenance Only the changed data were extracted every time after the first extracted data in increment maintenance. Meanwhile, the unchanged data were not extracted again. As a result, the communication and maintenance quantity decreased greatly. So the automatic maintenance was adopted in common increment maintenance 4 Algorithm We give quality comparability algorithm example. The function is comparing all kinds of quality information in appointed a period of time Practical application indicates that this system has better application foreground and itês robust and validity, which has society and economic value  Figure 4 data mining framework A CKNOWLEDGMENT It is a project supported by National Funds of Social Science \(Grant No. 09BJY055 the National Natural Science Foundation of China \(Grant No. 70772086\the post doctor funds of Dalian University of Technology \(Grant No. 1200112009\ the doctor opening funds of Dalian JiaoTong University \(Grant No. 888049\ the Dalian Funds of Social Science \(Grant No. 10DLSK115\he Dalian Funds of Social Science \(Grant No. 09DLSK205\, Liaoning Province Social Science Planning Fund \(Grant No.L09AJL001\nd Chinese Education Ministry Special Purpose Research Subject \(Grant No.2007110 R EFERENCES 1 X  F   LI   et c  Gen et i c A l gor i t h m s b a s ed A p p r oa ch on A n E n t e r p r i s e  Resource Supply ChainManagement Problem with Primary and Secondary Warehouses,é Chinese Journal of Management Science 2004, 12\(3\pp.98-102 2 C. Z o po un i d is  M. D o u m po s   M ul ti g r o up dis cr im in at io n us i n g m u l t i criteria analysis: Illustrations from the field of financeé. European Journal of Operational Research, 2002, 139\(2\, pp.371-389 3 B  S h a n n o n  Ja va T M 2 Pla t form  E n t e rp ri se  E d i t i o n J 2 E E T M   Speeifieation. Sun Mierosystems Ine, 2003 4 K  T  Hu a n g Y W  L ee  I  Y W a n g  Qu a lit y  I n fo rma t i ona nd Knowledge. New Jersey: PrentiCe HallPTR 1999 5 C  O Y a n g  S  J  Hon Deve lop i n g an a g en t b a s e d A P S a n d ER P  collaboration frameworké. The International Journal of Advanced Manufacturing Technology, 2008, \(35\, pp.943-967 6 T  G u d e h u s H K o t z a b  Pla nn in g an d s c h e du li n g  p r odu c t i on s y s t em s  from a logistics perspectiveé,  Logistics Research, 2009,\(1\, pp.163-172 7 R  F r ey W  Ru ng g a l d ie r   P r i c ing c r e d it de r i v a t i v e s  un de r i n co m p l e te  information: a nonlinear-filtering approaché. Finance and Stochastics Published online:09 July 2010 


4.1 Dealing with Complex Hazard Functions As indicated before one of the main problems dealing with malicious acts such as intrusions or other attacks are the different degrees of unpredictability In this was captured with the introduction of so-called UUUR events Unpredictable latent Unobserved and Unobservable Risks In order to assess the consequences of UUUR events survival analysis with its sister elds competing risks analysis and multivariate survival analysis were introduced in and 16 respecti v ely  A three-layer survi vability analysis architecture was introduced that consisted of tactical strategic and operational levels This architecture allows to integrate reliability hybrid fault models and survivability under a uniìed paradigm A comprehensive introduction of three-layer survivability analysis is beyond the scope of this paper Here we only brieîy discuss one aspect of the tactical level dealing with complex hazard functions We completely skip the strategic and operational level modeling which can be found in and In the absence of UUUR events the tactical level is largely equivalent to traditional reliability analysis Indeed the most fundamental deìnition in survival analysis is the survivor function S  t  Pr  T>t   which has the exact same deìnition as the reliability function The hazard function h  t  and the cumulative hazard functions H  t  even use the same terminology besides the common mathematical deìnitions However there are additional advantages from introducing survival analysis over the traditional reliability analysis Major advantages of survival analysis are i more exible time-variant and covariates-dependent hazard functions ii built-in procedures to deal with censored events iii multivariate failure beyond binary failure and iv more effective modeling of dependent failure events through competing risks and shared frailty modeling Details can be found in 13 14 15 Our interest is with regard to the hazard functions listed in the advantages of i Therefore we now brieîy introduce several forms of hazard functions from survival analysis to show one of the advantages of adopting survival analysis The simplest type of hazard function is the constant hazard function which is when the failure time follows exponential distribution It takes the form h  t   1 With the original Cox Proportional Hazards Model PHM the hazard function becomes time and covariates dependent   t z   0  t  e Z 2 where Z is the vector of covariates such as environment factors that inîuence the hazard function and  o  t  is the baseline hazard function The Cox PHM has been extended numerously e.g 18  T w o simple e xtensions the stratiìed Cox PHM and the Cox PHM with time-dependent covariates are of particular interest and their applicability will be discussed below First we introduce the stratiìed Cox PHM Suppose there is a factor that occurs on q levels and for which the socalled proportionality assumption of PHM may be violated The hazard function for an individual in the j th stratum or level of this factor is  j  t z   0 j  t  e Z 3 for j 1  2   q  The baseline hazard function  01       0 q    for the q strata are permitted to be arbitrary and are completely unrelated The second generalization to the PHM is the Cox PHM with time-dependent covariates Here the covariates Z depend on time t  i.e Z  Z  t   For unstratiìed PHM the hazard function is   t  z  t    0  t  e Z  t   4 and for stratiìed PHM it is  j  t  z  t    0 j  t  e Z  t   j 1  2   q 5 With the increase of the hazard function complexity from Equation 1 to 5 their descriptive power and exibility also increase For example the stratiìed PHM Equations 3 and 5 may be used to formulate a uniìed hazard function for various levels of security alerts e.g low medium and high The choice of the hazard function that can be used has signiìcant implications on the complexity of the system analysis 4.2 Model Changes and State Changes The view of the functionality-based analysis model described above has several advantages in theory 1 Different functionalities can have different fault descriptions 2 Different functionalities can utilize different hazard functions 3 Each functionality may change its fault description and/or hazard function in time The rst advantage is the exibility to view the fault description of each functionality in isolation This design for analyzability feature allows for ease of analysis The second advantage is signiìcant since the type of hazard function has huge implications on the complexity of the analysis Note that the term complexity is not to be Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


interpreted as computational complexity but as the complexity of the approach Having the exibility of selecting an appropriate hazard function for individual functionalities rather than for the entire complex system allows to study the effects of speciìc assumptions about failing rates This way one can move in the trade-off space of simplicity of analysis versus accuracy of the hazard function For example the simple hazard function of Equation 1 is suitable for the analysis of certain functionalities but it is not generally suitable for malicious act From an analysis point of view it is desirable to select the least complicated hazard function suitable for each functionality Thus just because certain aspects of the systems may be subjected to UUUR events the entire system does not have to use the complicated hazard model The third advantage is the exibility to consider the analysis in different phases with potentially different hazard functions at different stages This can be modeled using a state machine Consider the three different threat levels e.g low medium and high one may use the stratiìed Cox PHM model expressed with Equations 3 and 5 Such system may adapt to threat levels announced by some authority The system hazard function may transition from one stratum to another when the threat levels change For example the sequence h i   h k   h j   h i would represent a system that transitions through various states strata each with their respective hazard functions The sequence could be from the state machine shown in Figure 1  h i h k h j Figure 1 Thread Model State Machine 5 Fault Model Adaptation As information becomes available that may change the systemês landscape changes to the system model or parameters need to be considered Such adaptation is considered to be an integrated feature in any design for survivability For example in 6 survi v ability w a s described in terms of Resistance Recognition Recover and Adaptation Adaptation implemented the mechanism to adapt the system to knowledge gained in the prior three phases Our interest is primarily in adaptation related to the fault model Adaptation may be the result of diverse scenarios such as 1 The fault description F i is no longer valid due to a speciìc event For example intelligence suggests that authentication may be compromised As a result fault types that are not reîected in F i may occur 2 The fault description of f i should be strengthened by design This may be the result of analysis indicating that a functionality may be the weakest link 3 The infrastructure that f i relied on has changed The implications of this change on the fault description need to be evaluated Of special interest is the case where the infrastructure may not be able to support tolerance of certain fault types In general adaptation is viewed to address the dynamics of changes in fault descriptions F i  which however has to be addressed in the context of the capabilities of the system or infrastructure that supports functionality f i  Thus we want to be able to point out if there is a mismatch between 1 what is assumed or implemented by f i and 2 inherently theoretically possible in the system We deìne the active fault description as the fault model that the system currently subscribes to i.e the faults that f i assumes to be able to tolerate or deal with Thus for functionality f i the fault description F i is the active fault description The speciìcation of F i is determined by the system designer or more speciìcally by the designer of f i  The real question that remains is whether the systemês infrastructure can support this F i  In contrast to the active fault description the imposed fault description denoted by  F i  is the fault model that the infrastructure of the system or application imposes on f i  It encompasses those fault types that the system has to explicitly deal with by distinct mechanisms For example  F i  b s  indicates that for the given infrastructure benign and symmetric faults are possible and theoretically unavoidable However note that  F i does not list asymmetric faults The reason is that the infrastructure is assumed to be capable of theoretically eliminating this fault type An infrastructure that has an imposed fault description  F i  b s  is a broadcast network In such a network asymmetric faults are not possible due to the fact that every module in the broadcast domain can see every message The active and imposed fault descriptions can serve the system designers to analyze the survivability of f i  Letês consider the authentication example in a general network environment under the fault model of and assume that messages are signed First we assume that point-to-point communication e.g TCP/IP is used Furthermore consider the two cases where 1 TCP/IP provides reliable transmission and 2 when TCP may time out With respect to the infrastructure in case 1 this leads to an imposed fault description of  F i  s a   meaning that there are no benign Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


faults However value faults both symmetric and asymmetric cannot be resolved without explicit mechanisms If we consider case 2 in which TCP may time out then  F i  b s a   Next letês consider the active fault descriptions If our authentication scheme is assumed to be uncompromisable then F i  b   otherwise it is F i  b s a   The interesting case in the example above is when authentication is compromised Value faults cannot be dealt with unless the authentication mechanism is implemented to provide redundancy levels of N  2 s 1 and N  3 a 1 for symmetric and asymmetric behavior respectively Note that in order to avoid common mode faults the redundant modules should be dissimilar In order to deal with symmetric faults one needs a simple majority of unaffected modules However asymmetric faults do not only require a higher degree of redundancy but also require that agreement algorithms be used These algorithms typically work in rounds of message exchanges The result is high message overhead in addition to the high component count However since in our example the imposed and active fault descriptions both contain s and a  there is no easy way around having to deal with these faults explicitly For the system designer the choices seem clear 1 one lives with the risk of authentication compromises or 2 one pays the cost of module and message overhead But how high is that cost This depends on how many faults of type s and a one wants to tolerate In addition common mode faults need to be addresses and thus the cost of dissimilar components needs to be considered Design Changes The advantage of working with imposed fault description is that it gives insight about what the infrastructure cannot inherently deal with This allows for adaptation that can bring signiìcant simpliìcations to the application Consider the example above and assume that authentication may be compromised i.e assume that F i   F i  b s a   The largest challenge is to avoid having to deal with costly asymmetric faults However the infrastructure cannot tolerate such faults implicitly and thus explicit mechanisms such as agreement algorithms must be used Therefore letês consider what changes can be made to the infrastructure in order to avoid asymmetric faults With respect to networking this is actually quite simple As indicated before a broadcast environment cannot exhibit asymmetric behavior Therefore assume that point-to-point networking in authentication is eliminated and that broadcasting is used instead Under the broadcast paradigm every node can see the same messages so that Byzantine faults can be immediately detected Now  F i  b s   and thus the application can provide simple mechanisms to take advantage of the imposed tolerance to asymmetric faults Thus by observing the limitations of the imposed fault description an infrastructure-related change can make large improvements Adaptive Policies In the previous example the design of the authentication mechanism was motivated by low cost which resulted in an active model considering only benign faults If value faults are suspected then the high cost of dealing with value faults most signiìcantly asymmetric faults was required However in most applications the worse case behavior e.g broken authentication may be only of importance during times of high threat levels This suggest a security policy that is exible and sensitive to the threat level Such a policy would select the lowest overhead solution possible under a given threat level In our authentication example this could mean using the benign model under normal situations and augmenting value faults if the threat level is high Such gear shifting is not new and has been used in the context of agreement algorithms to reduce overhead Infrastructure Changes Lastly if the infrastructure used by functionalities f i changes then one should consider if these changes have implications on the imposed fault description If they do then perhaps one can take advantage of this change On the other hand it may mean that now the limitations of the infrastructure need to be compensated by more sophisticated solutions An example of such degeneration is when a network changes from a broadcast to a point-to-point communication primitive In all the cases above the careful analysis of F i and  F i should be undertaken Misjudging the fault model can render the application non-survivable 6 Conclusions A new view of fault models was presented that shifted away from the fault cause and instead focused on the effect of faults This allows for the use of fault models in the analysis of systems operating in hostile environments A general view of design for survivability was adopted This implied that the application and infrastructure were viewed in concert in order to determine which fault models they required and supplied By viewing a system as a collection of functionalities each functionality could be separately analyzed This simpliìed the determination of the active and imposed fault description which was then used to determine a mapping between what the application functionality required and what the infrastructure could or could not support In the latter case explicit solutions must be used to overcome the infrastructure induced limitations With respect to system analysis the functionality-based view of the system allowed exibility in the choice of hazard functions Rather than using one model for the entire system now each functionality can be analyzed using its appropriate hazard functions The exibility was then Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


extended to the time domain thus allowing to change the model over time in response to external changes References  A A vizienis et.al Fundamental Concepts of Dependability  Information Survivability Workshop ISW2000 Boston Massachusetts Oct 24-26 2000  M.H Azadmanesh and R.M Kieckhafer  Exploiting Omissive Faults in Synchronous Approximate Agreement  IEEE Trans Computers 49\(10 pp 1031-1042 Oct 2000  Bar No y  A D Dole v  C Dw ork and H R Strong Shifting Gears Changing Algorithms on the Fly to Expedite Byzantine Agreement  Information and Computation Vol 97 pp 205-233 1992  D  R  Cox Regression models and life tables  Journal of the Royal Statistical Society Series B Methodological Vol 34 No 2 pp 187-220 1972  S Elbaum and J Munson Intrusion Detection Through Dynamic Software Measurement  Proceedings of the Eighth USENIX Security Symposium 1999  R J Ellison D A Fisher  R  C  Linger  H  F  Lipson T  Longstaff and N R Mead Survivable Network Systems An Emerging Discipline  Technical Report CMU/SEI97-TR-013 November 1997 Revised May 1999  A Krings et al A Two-Layer Approach to Survivability of Networked Computing Systems  Proc International Conference on Advances in Infrastructure for Electronic Business Science and Education on the Internet SSGRRê2001 LêAquila Italy Aug 06 Aug 12 pp 1-12 2001  A Krings Survivable Systems  Chapter 5 in Information Assurance Dependability and Security in Networked Systems Morgan Kaufmann Publishers Yi Qian James Joshi David Tipper and Prashant Krishnamurthy Editors in press 2008  Ax el Krings Design for Survivability A Tradeoff Space  Proc 4th Cyber Security and Information Intelligence Research Workshop Oak Ridge National Laboratory May 12-14 2008  L Lamport et.al The Byzantine Generals Problem  ACM Transactions on Programming Languages and Systems Vol 4 No 3 pp 382-401 July 1982  J.C Laprie editor  Dependability Basic Concepts and Terminology  Springer-Verlag 1992  Y  Liu and K S T r i v edi Survivability Quantiìcation The Analytical Modeling Approach  International Journal of Performability Engineering Vol 2 No 1 Jan 2006 pp 29-44  Z.S Ma New Approaches to Reliability and Survivability with Survival Analysis Dynamic Hybrid Fault Models and Evolutionary Game Theory  Ph.D dissertation University of Idaho Computer Science Department 177pp 2008  Z.S Ma and A W  Krings Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management PHM  Proc IEEE AeroSpace Conference March 1-8 Big Sky MT 2008  Z.S Ma and A W  Krings Competing Risks Analysis of Reliability Survivability and Prognostics and Health Management PHM  Proc IEEE AeroSpace Conference March 1-8 Big Sky MT 2008  Z.S Ma and A W  Krings Multivariate Survival Analysis I Shared Frailty Approaches to Reliability and Dependence Modeling  Proc IEEE AeroSpace Conference March 1-8 Big Sky MT 2008  Z S Ma and A W  Krings Dynamic Hybrid Fault Models and the Applications to Wireless Sensor Networks WSNs  to appear in The 11-th ACM International Symposium on Modeling Analysis and Simulation of Wireless and Mobile Systems ACM MSWiM 2008 2008  T  Martinussen and T  H Scheik e Dynamic Regression Models for Survival Data  Springer Verlag 466pp 2006  N R Mead R J Ellison R C Linger  T  Longstaf f and J McHugh Survivable Network Analysis Method  Technical Report CMU/SEI-2000-TR-013 Software Engineering Institute Carnegie Mellon 2000  P  Thambidurai and Y K P ark Interactive Consistency with Multiple Failure Modes  Proc 7th Symp on Reliable Distributed Systems Columbus OH pp 93100 Oct 1988  T  Therneau and P  Grambsch Modeling Survival Data Extending the Cox Model  Springer Verlag 2000  Jay J W ylie et.al Selecting the Right Data Distribution Scheme for a Survivable Storage System  Technical Report CMU-CS-01-120 Carnegie Mellon University May 2001 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


 9   These parameters were calculated using the relations  Analysis of Model A and B  Since both models A and B had same wave deflection angle the analysis gave similar results  For M 1 1.73, ratio of specific heats 1.4 and 12 degrees the ratio of pressure after and before the shock was calculated to be 1.920  The Mach number after the shock was found to be 1.25, it shows that it is still in supersonic regime and therefore the oblique shock formed is a weak oblique shock  Wave angle is also given by the sum of the Mach angle  and small angular difference Therefore      Here is given by the relation   1 1 2 4 \(M 1 2 226 1    That is, for a finite deflection angle the direction of weak oblique shock wave differs from the Mach wave direction  by an amount which is of the same order as   The Mach wave direction was calculated as 35 degrees and was calculated to be around 12 degrees. Sum of these two parameters gave the wave angle to be 40 degrees This is in good accordance with the experimental analysis of Models A and B, which is about 50 degrees  Pressure and temperature before and after the shocks were calculated from the isentropic relationships as the flow was assumed to be isentropic. The following values were determined  P1 = 0.197 bar = 19.7kPa P2 = 0.38 bar = 38kPa  T1 = 187.8 K T2 = 228.6 K  Analysis of Model C  Detached shock was observed near the nose of Model C This shock resulted as the wall deflection angle was greater than max Model C had was designed to have a blunt nose. In such a case, the shock wave remains detached at all supersonic Mach numbers. The flow immediately behind the shock was subsonic. It was difficult to determine the sonic line  The analysis of the flow fiel d associated with detached shock becomes very difficult because of transonic flow which prevails behind the shock. In such a case, the shape of the shock was observed and the detachment distance was determined. It becomes co mplicated to measure the properties in such rarefied flows. Hence the following parameters were found  The detachment distance was found to be 0.3cm from the nose of the model and the shape of the detached shock resembled conventional detached shock wave. However oblique shocks were noticed towards the downstream flow over the model as marked in the picture. The strength of the detached shock waves weakens with the formation of the oblique shock and further weakens until it becomes a Mach line, far away from the object. Unfortunately due to the unavailability of rectangular windows the entire section of the model could not be studied  6. F LUENT S OFTWARE A NALYSIS   Fluent is a general purpose CFD code based on the finite volume method on a collocated grid. Fluent technology offers a wide array of physical models that can be applied to a wide array of industries. Th is software was chosen to compute, analyze and model the flow conditions in and around moving models  The wind tunnel models were modeled in Gambit software package and two dimensional analyses was done. Two dimensional analyses were to simplify the complexities arising from turbulent flow model analysis. The top and side views of the models were meshed using Gambit and were exported to Fluent to model the flow conditions  The 2ddp version in Fluent was used. The flow was modeled using density based solver, k-epsilon viscous model was used and properties of air were assumed to be constant. The analysis was done for normal supersonic cruising conditions at 50000 ft at a pressure of 12000 Pa and temperature 216 K. The Mach number was set to about 1.8 for analyzing Model A and B and sonic Mach number for Model C  Analysis of Model B  The top and sectional side views of the model were plotted and meshed using Gambit mesh solver. The mesh was imported in Fluent and the operating conditions were set as stated in the previous paragraphs. The analysis gave contours of pressure, temperat ure, velocity, Mach number and turbulence      
 


 10    The above contour shows static pressure distribution across the model. It can be seen that th ere is a pressure rise near the nose when the flow first encounters the body  There is a gradual rise in pressure as shown by yellow region. This is due to the reas on that pressure increases after the bow shock about compression corners     The contour above gives the static temperature. A gradual rise in temperature is observed downstream of shock wave This is due to the supersonic flow around the compression around the corners. The static temperature distribution may help in selecting the materials required in certain areas to withstand the conditions at cruising  Mach number variation over the aircraft profile is plotted in the following page. A drop in the Mach number is noticed after the shock formation. This is due to the formation of oblique  shock wave at the nose. The following contour gives the turbulence intensity over the profile 
 


 11   Maximum turbulence is encountered at the wing tips. This could be attributed to the fact that vortex is generated near the trailing edges. This could be minimized by providing alterations to the design of the wing tips. The remaining region around the boundaries seems to be fairly stable and validates this to be a good design The sectional view of Model B was also analyzed. The resulting contours are presented here in the following page    
 


 12  Figure 15 \226 Static Pressure Contour side view of Model A    Figure 16 \226 Static Temperature Contour   Figure 17 \226 Velocity Magnitude Contour   Figure 18 \226 Turbulent Energy Contour  Figure 19 \226 Static Pressure Contour side view of Model B   Figure 20  226  Static Temperature Contour  Figure  21  226  Mach Number Contour  Figure  22  226 Strain Rate Contour 
 


 13 Analysis of Model A The analysis of Model A gave varying results owing to the variation in the profiles of the plan view and the sectional side view. The sectional side view is diamond type unlike that of Model B which is convex in shape. Both are however, ideal supersonic airfoils The sectional side view of Model A shows a rise in pressure behind the shock wave. This is because of the oblique shock wave formation around the compression corners. A drop in pressure is noticed at the expansion corner due to the formation of expansion fan at the convex corners The top view of Model A, when analyzed in Fluent gave the following contours. Formation of a high pressure region ahead of the wing profile sh ows the formation of a bow wave. This may induce very high wave drag and may not be a good optimized model    
 


 14 Analyses of Model C Analyses of Model C were done at Mach 1 to avoid divergence in the solution. The following results were obtained. The analyzed cont our clearly shows a high pressure region ahead of the nose This is the detached shock wave that is formed as seen in the shadowgraph. A region of high pressure exists after the detached shock      
 


 15      7  C ONCLUSION  The results from experimental theoretical and software analysis validate the fabricated models to work well over the supersonic regimes. Models A and B have reduced shock strength. This advantage could be explored in the design of a transcontinental supersonic passenger airliner. The models prove to be aerodynamically efficient and have lesser wave drag However, there were a few shortcomings in this approach The fabrication of such an ai rliner at a bigger scale could 
 


 16 prove to be a challenging task. Installation of engines would have to be looked into from a different aspect This work could be extended to study various other complicated supersonic aircraft profiles; the distribution of pressure, shock pattern and shock strength can be studied Unless efforts are continued on this regard, the viability of an efficient supersonic airc raft is likely to languish  R EFERENCES  1  United States Patent - 4828204 , Supersonic  Airplane by Gottfried O. Friebel, Bellevue, Wash  2 United States Patent \226 5518204, High Efficiency Supersonic Aircraft \226 Richard.R.Tracy  3  Jones, R., 1991. \223The Flying Wing Supersonic Transport.\224 Aeronautical Journal March    A b o o k o n Gas Dy nam i c by  R a t h i n a k ri s hna n    A st udy of Detache d S h oc k wave in 2-D  by Morton      Alperin, CALTECH, 1950 6 In trodu ction to fligh t  b y Ja m e s And e rson   Ai rcra ft De si gn  by  J o hn P F i e l d i ng  A CKNOWLEDGEMENT  The author wishes to express his hearty appreciation to all those people who have been instrumental in successful completion of this work. The author wishes to thank the principal, Dr. J. Shanmugam and management of Velammal Engineering College for their continual support. In particular, the author wishes to mention Mr Vickneshkumar, who has been a source of constant support throughout the project and Mr. Murugan for his kind cooperation and help during the fabrication of the models The author is indebted to Mr. Palani, IIT Madras for his invaluable guidance on FLUENT software and Dr Muruganandam, IIT Madras for his kind permission to conduct the tests in the wind tunnel facility at IIT Last but not the least; the author extends his warm thanks to his father, Mr. Arun Banerjee and his family who have been a great moral support throughout the course of this work       BIOGRAPHY Arijeet Banerjee is a Bachelor of Engineering \(Mechanical Engin eering\ student at Velammal Engineering College, Anna University, Chennai  India. He has completed his senior secondary schooling under the Central Board of Secondary Education. A keen aerospace enthusiast has taken part and won various competitions at both state and national levels. Visit the author at www.arijeetbanerjee.synthasite.com  
 


C. \(2005 Implementation and Use in an Existing Clinical Information System. In Connecting Medical Informatics and Bio-Informatics: Proceedings of MIE2005 - The XIXth International Congress of the European Federation for Medical Informatics, 328-333. IOS Press, 2005  4] Fetterman, D. M. Ethnography, 2nd ed. Thousand Oaks CA: Sage, 1997  5] Furukawa, N.  Ikeda, H.  Kato, Y.  Sako, H. D-Pen: a digital pen system for public and business enterprises. In Frontiers in Handwriting Recognition 2004: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition \(IWFHR-9 2004  6] Guimbreti  re, F. 2003. Paper augmented digital documents. In Proceedings of the 16th Annual ACM Symposium on User interface Software and Technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 UIST ?03 November 2003  7] Holman, D., Vertegaal, R., Altosaar, M., Troje, N., and Johns, D. 2005. Paper windows: interaction techniques for digital paper. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems \(CHI ?05 Portland, Oregon. New York: ACM, 2005  8] Kiewra, K., DuBois, N., Christian, D., McShane, A Meyerhoffer, M., &amp; Roskelley, D. Note-taking functions and techniques. Journal of Educational Psychology, 83 240-245, 1991  9] Kobayashi, K. Combined effects of note-taking/reviewing on learning and enhancements through interventions: a meta-analytic review. Educational Psychology, 26, 459-477, 2006  10] Liao, C., Guimbreti  re, F., and Hinckley, K. 2005 PapierCraft: a command system for interactive paper. In Proceedings of the 18th Annual ACM Symposium on User interface Software and Technology \(UIST ?05 Seattle, WA. New York: ACM, 2005  11] Livescribe. Pulse Smartpen [electronic device http://www.livescribe.com/, last retrieved May 28, 2008  12] Logitech. io2 Digital Pen [electronic device http://www.logitech.com/index.cfm/mice_pointers/digital_ pen/devices/408&amp;cl=us,en, last retrieved May 28, 2008  13] Norrie, M. C., Signer, B., and Weibel, N. Print-n-link weaving the paper web. In Proceedings of the 2006 ACM Symposium on Document Engineering \(DocEng '06 New York: ACM, 2006  14] Randall, D., Harper, R., and Rouncefield, M Fieldwork for Design: Theory and Practice. London Springer-Verlag, 2007  15] Searle, J. R. Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge Univ. Press, 1969  16] Sellen, A. J. and Harper, R. H. The Myth of the Paperless Office. Cambridge, MA: MIT Press, 2003  17] Signer, B. and Norrie, M. C. 2007. PaperPoint: a paper-based presentation and interactive paper prototyping 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






Modeling Heterogeneous Time Series Dynamics to Pro“le Big Sensor Data in Complex Physical Systems Bin Liu Rutgers University NJ USA binben.liu@rutgers.edu Haifeng Chen Abhishek Sharma Guofei Jiang NEC Laboratories America Princeton NJ USA  haifeng absharma gfj  nec-labs.com Hui Xiong Rutgers University NJ USA hxiong@rutgers.edu Abstract While a massive amount of time series can now be collected in many physical systems it is a challenge to build an analytic model that can correctly pro“le the data because those time series usually exhibit various behaviors In this paper we propose an integrated method to address the heterogeneity issue in modeling big time series data We rst extracts relevant features to summarize the underlying dynamics of those series We present both linear and nonlinear feature extraction techniques as well as a procedure to determine the right extraction method for individual time series Given extracted features our method f urther models the trajectory pattern of time series in the fea ture space Both a regression based and a density based method are presented to pro“le different types of feature trajec tories Experimental results in a real power plant illustrate that our feature extraction and trajectory model are effective to pro“le various time series Our method has been used to successfully detect anomalies in the system Keywords Time series Trajectory model Anomaly detection I I NTRODUCTION With the decreased hardware cost and increased sensor capability traditional physical systems undergo revolutionary changes recently in their c omputing communication and storage capabilities They are now equipped with a large network of sensors distributed across different parts of the system which leads to a tremendous amount of time series data available to system operators It is important to build effective models to pro“le those time series so that we can better understand the underlying dynamics of system operation and hence monitor its status to detect anomalies However different time series in the collected data usually demonstrate totally different behaviors due to the diversities in system components and their functionalities Figure 1 presents some examples of time series collected from a real power plant system As we can see they are dramatically different in terms of shape trend seasonal variation and periodicity Some series exhibit deterministic periodic behaviors whereas others show irregular curves in their evolutions While there already exist a number of time series modeling techniques in the literature current methods This work was performed while the rst author was an intern at NEC Laboratories America Princeton NJ usually rely on certain assumptions and are limited for the category of time series that follow those assumptions For example the commonly used autoregressive\(AR model 1 a s s umes that current obs er vation in time series linearly depends on its previous observations While the support vector regression\(SVR 2 h as been propos ed t o handl e nonlinear behaviors in time series it requires the knowledge of correct window size to determine the number of predictors in the regression In addition some time series may t poorly in regression based models and can only be pro“led by nonparametric techniques such as density based methods Given a massive number of heterogeneous time series it is necessary to have a more general method to treat different time series differently so that we can identify the best pro“le for each time series based on its characteristics To this end this paper proposes an integrated method to model the dynamics of time series so that the heterogeneous behaviors in big sensor data can be correctly pro“led Given a time series x   x 1 x 2 x t    our method rst extracts related features that best summarize its dynamics and then builds a model to capture the evolutionary trajectory of extracted feature vectors In the feature extraction step we apply a sliding window on x to derive a sequence of state vectors z t  x t  d 1   x t  1 x t   which leads to a state matrix Z  z 1  z 2  z n  T  Compact features are then extracted by applying subspace decomposition from Z  We use the singular value decomposition SVD to extract linear features whereas a kernel based method is presented to extract featur es from nonlinear time series We also present an intrinsic dimension based test 5  t o determine whether an linear or nonlinear feature extraction is appropriate for a given time series Since the extracted features summarize the underlying dynamics of time series their trajectory re”ects the evolution of time series We will show that for many time series their evolution trajectories demons trate stronger regularities in the feature space than in the ori ginal data space Therefore we further propose two techniques to model the trajectory traces in the feature space Two techniques are proposed for that purpose The vector-autoregressive VAR method which has been shown be effective to describe a variety of trajectory shapes 6  i s p res e nt ed t o model f eat ure t raj e ct ory 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 631 


 0 500 1000 1500 2000 2500 3000 35 40 45 0 500 1000 1500 2000 2500 3000 22.5 23 23.5 0 500 1000 1500 2000 2500 3000 100 150 0 500 1000 1500 2000 2500 3000 0 5 10 0 500 1000 1500 2000 2500 3000 0 20 40 0 500 1000 1500 2000 2500 3000 350 355 360 0 500 1000 1500 2000 2500 3000 175 176 177 0 500 1000 1500 2000 2500 3000 2 0 2 0 500 1000 1500 2000 2500 3000 0 500 1000 0 500 1000 1500 2000 2500 3000 1 1.5 2 Figure 1 Heterogeneous time series from a physical system with regular patterns We also present a density based approach to model feature trajectories with less regularities Since our feature extraction and trajectory modeling are performed on each individual time series our method can be easily parallelized to handle data from a massive amount of sensors That is we divide the time series into several groups and each machine builds the pr o“les of series from a speci“c group The learned pro“les can be used to monitor the online status of time series Given a new observation x t of series x  we retrieve the model of x from the corresponding machine compute the value of its feature vector and compare it with that derived from the feature trajectory estimation An alert will be issued if a large deviation is observed Experimental results have demonstrated the good performance of our method in the system anomaly detection Contributions This paper has made the following contributions 1 We propose an integrated approach to pro“le heterogeneous time series collected from a large amount of sensors in physical systems It rst extracts relevant features from time series to represent the dynamics followed by modeling the trajectory of feature values along the time Our method has correctly pro“led all the time series in a real power plant It outperforms other state-of-the-art approaches in the application of anomaly detection 2 In extracting features from time series we have made signi“cant improvements over current methods such as SSA to handle general behavior of time series In addition to the linear subspace decomposition our method also includes nonlinear feature extraction to model nonlinear time series 3 Rather than focusing on individual feature values we propose to model the evolution trace of time ser ies features Two trajectory modeling techniques are presented to handle different types of feature trajectories II E XTRACTING F EATURES OF T IME SERIES D YNAMICS Figure 2 illustrates the process of extracting relevant features from time series We rst use the sliding window based technique to construct a sequence of state vectors i.e the vectors that contain series dynamics along the time After that we discover non-redundant features from state vectors Both linear and nonlinear extraction methods Figure 2 Feature extraction work”ow are presented to cover various behaviors of time series In addition we also propose a statistical test procedure to determine the linearity of a given time series and hence choose the appropriate extraction method A State Vector Construction The time series in most physical systems are generated from underlying physical processes that can be modeled by some differential equations That is the current value x t at time t is produced by a hidden function on its previous samples While the underlying physical processes are usually unknown that fact guides us to construct a state vector at each time t to cover the dynamics of time series at that moment It is represented as a d dimensional vector z t  R d that contains the current observation x t as well as its past d  1 samples z t  x t   d  1   x t  1 x t   1 As long as the number of delayed samples in z t is greater than the order of underlying physical process the state z t contains the full dynamics of x at time t  By constructing the vector z t at every sample time we can get the whole picture of the evolution in time series If the true value of d is known the state vector can be directly used as the feature of time series In practice however that information is unavailable A common way to address that is to relax the d value at the beginning and then discover the compact repr esentation of features from state vectors In order to achieve that we stack all the state vectors into a matrix Z  z 1  z 2   z n  T  which is called the Hankel matrix 7 and i dent i f y a l o w d i m ens i onal s ubs pace 632 


that contains all the information in Z  The projection of each state vector into that subspace is then regarded as the feature of time series x  There are different ways to discover the signal subspace from matrix Z  If time series x is linear i.e the current sample x t is linearly dependent on its past observations the singular value decomposition SVD can be directly applied to identify the subspace However nonlinear methods need to be utilized if the behavior of x violates the linear assumption Before performing the corresponding feature extraction we rst propose a procedure the discover the linear or nonlinear character istics of time series B Intrinsic Dimension Based Test A statistical test based on the concept of intrinsic dimension[4 i s des c ri bed h ere t o d i s co v e r t he l i n ear or nonlinear behavior of time seiries Given a sequence of d dimensional state vectors z t  t 1    the intrinsic dimension r describes the number of underlying variables that are needed to represent the state vector Its estimation is based on the observation that for an r dimensional data set the number of pairs of points closer to each other than   as described in equation 2 is proportional to  r C n    2 n  n  1 n  i<j 1  z i  z j   2 where 1 is the indicator function of the event A  Then the intrinsic dimension r is de“ned as r  lim   0 lim n  log C n    log   We compute C n    for different  i and t a line through log  i  log C n   i  to derive r  Based on the estimated dimension r  we test whether the linear subspace decomposition is suf“cient for time series 1  Given the state matrix Z from time series x we rst apply the singular value decomposition Z  U  V T  where U and V represent the column and row spaces of Z respectively and  are the singular values  diag   1    r  r 1    k   k min  d n  Wethen check whether the linear subspace with dimension r covers enough variances of the original space by computing     2 1   2 2     2 r  2 1   2 2     2 k  1  2 3 If the  value is larger than a prede“ned threshold we use the linear subspace decomposition to extract features Otherwise we use the nonlinear feature extraction method C Linear Feature Extraction The linear subspace of matrix Z directly comes from the SVD results i.e the rst r columns of U form the bases of signal subspace U s  u 1 u 2   u r   Given a state vector z  we can obtain its low-dimensional representation in the signal subspace as y t  U T s z t Since y t effectively summarizes the information in z t  we use it as the feature of time series x at time t  D Nonlinear Feature Extraction For time series with nonlinear behaviors we use a nonlinear function    to transform the state vector z t into  z t   and then identify the signal subspace in the transformed vector space The transformed vector space is also called feature space in the literature but we do not use the term here to avoid the confusion with the feature space described in Section III The base vectors   u 1     u r  of signal subspace from transformed vectors  Z    z 1    z 2     z n  T can be obtained by the eigen-decomposition of covariance matrix C  1 n  n j 1  z j   z j  T  which can be solved by using the kernel trick 8 That is  i ns tead of computing t he mapping  z j   we use common kernel functions such as the Gaussian kernel and polynomial kernel to represent their dot product K i,j    z i    z j   in the eigendecomposition which turns into solving K     where matrix K  K i,j  is called the kernel matrix and  is its eigen-vector associated with eigen-value   It was shown in 9 t hat t he k th base vector  u k of the signal subspace k 1   r  can be derived from  k  i.e the eigen-vector associated with k th largest eigen value  u k   n j 1  k j  z j  where  k j is the j th element in  k  Given a transformed state vector  z T t   its projection on that base vector is  u T k  z T j   n j 1  k j  z T j   z T j   which can be computed by the kernel function  n j 1  k j K  z i  z j  The nonlinear features of time series are the projections of  z T t  on all the r base vectors in the transformed vector space III M ODELING S YSTEM D YNAMICS The pro“ling of data samples in the projected feature space have been studied for general data types   10  F o r example 5 u sed t h e statistic o f Ho tellin g T 2 to describe the distribution of projected features However since this paper deals with time series we exp ect that feature vectors also exhibit temporal patterns in their evolutions As an example given a time series in Figure 3\(a its extracted 3-dimensional features in Figure 3\(c demonstrate strong regularity in the evolution path We also plot the 3-dimensional state vectors  x t x t  1 x t  2  in Figure 3\(b Clearly the points in feature space demonstrate strong trajectory patterns This is because the feature vector includes all the dynamics of time series By modeling the trajectory of feature vectors we can build a pro“le of time series dynamics Two techniques are proposed to model the feature vector trajectory The Vector-Autoregression\(VAR is used rst to capture trajectories with strong regularities We will show that VAR model can cover a majority of time series we encountered in real systems However for some time series whose feature trajectories do not t the VAR model well we also provide a density based model to describe their behaviors By combining those two complementary techniques we can build the pro“le for all time series received in real applications 633 


  0  500  1000  1500  2000  2500  3000  0.6  0.4  0.2  0  0.2  0.4  0.6  0.8     t  x\(t      1  0.5  0  0.5  1  1  0.5  0  0.5  1  1  0.5  0  0.5  1          x\(t  x\(t1   x\(t2       40  20  0  20  40  60  40  20  0  20  20  10  0  10  20  30  40            y 1  y 2  y 3 a Time series b State vect ors c Feature trajectory Figure 3 An example of a the original time series from a real physical system b the trajectory of 3-dimensional state vectors c the trajector y of extracted features A Vector-Autoregression Model It has been shown that VAR model is effective to describe trajectories with strong regularities 6  G i v en a s eq u e n c e of feature vectors y 0    y t  VAR describes the relation between current feature y t and its past p fetaures y t  c  p  i 1  i  y t  i    t  4 where  i is a r  r transition matrix and c is the intercept vector The noise   t  re”ects the in”uence of external randomness on the physical system We transform equation 4 into a compact expression y t  Bw t    t  where B is a r   rp 1 parameter matrix B   c   1    p  and w t  1 T  y T t  1   y T t  p  T Weassume the noise follows Gaussian distribution   t  N 0   and use the least square method to estimate transition matrices and the intercept vector  B k   kp 1   N  t 1 y t w T t  N  t 1 w t w T t   1  5 We use the Bayesian Information Criteria BIC to determine the optimal lag p in equation 4 After obtaining model parameters   c    1    2     p   we can predict the next feature value based on past p features by equation 4 Note that VAR model may not always lead to a good pro“le of time series For some feature trajectories with a lot of randomness it will produce large errors   t  and hence is not reliable Here we use the R-square R 2  statistic to measure the goodness of t in VAR which is computed as R 2 1   N t 1  y t   y t  2  N t 1  y t   y  2 6 where y t is the feature vector  y t is its estimation based on equation 4 and  y is the mean  y   N t 1 y t N  Equation 6 can be interpreted as R 2 1   residual sum of squares    total sum of squares  Alarge R 2 indicates that the model provides a good t to the data B Density Estimation Model A non-parametric method is also proposed here to handle feature trajectories with low tness in VAR model It relies on the density distribution of feature vectors in the trajectory However instead of modeling feature vectors directly we model the increment of feature vector  y t  y t 1  y t to re”ect the temporal coherence i n the trajectory The kernel density based regression is used to describe the feature increment  y t   N n  y t  k 1 w  y t  y k  y k  which leads to y t 1  N n  y t   k 1 w  y t  y k   y k 1  y k  y t 7 where w  y t  y k  represents the weights of  y k in the regression and y k is one of the N n  y t  nearest neighbors of y t  That is given all the feature vectors we search the nearest neighbors of y t and include the closest N n  y t  features in the density model The motivation here is that if two feature vectors are similar their path increment  should also be similar Therefore we only include the most similar features in estimating the path increment In addition among the selected feature y k s those that are closer to y t should contribute more to the estimation of y t 1 in equation 7 We use the kernel function w  y t  y k  K h   y t  y k    N n  y t  k 1 K h   y t  y k   to determine the weight value where K h  b  1 h K  b h   K    is a kernel function and h is the bandwidth of the kernel In the experiment we use K    as the Gaussian kernel and the bandwidth h is determined by employing a simple plug-in rule described in 11 1 Comments We have presented two complementary strategies to model the feature trajectory While the VAR model is effective in capturing the shape of trajectory the density based approach is applicable to general feature distributions We use VAR here to get an accurate prediction of features based on past feature values whereas the density model is used to improve the model coverage for various time series collected from real systems From the results in a real power plant system we observe that around 93 of the 997 time series can be modeled by VAR model with a high tness score The remaining time series are then handled by the density model IV A NOMALY D ETECTION IN T IME S ERIES Our proposed method is used to detect anomalies in time series which are data points that signi“cantly deviate from the normal pattern The anomaly detection includes a training stage and a detection stage In the training we 634 


  0  500  1000  1500  2000  2500  3000  60  70  80  90    t x\(t   40  30  20  10  0  10  20  5  0  5      y 1 y 2   0  500  1000  1500  2000  2500  3000  0  5  10    t x\(t   5  0  5  10  2  0  2     y 1 y 2   0  500  1000  1500  2000  2500  3000  0  500  1000    t x\(t   1500  1000  500  0  500  1000  1500  1000  0  1000  2000   y 1 y 2   0  500  1000  1500  2000  2500  3000  0  50  100  150   t a x\(t     150  100  50  0  50  100  150  200  0  200    y 1 b y 2 Figure 4 Four time series left a nd their extracted feature trajectories right apply our method to normal time series x t  t 0    t As a result we obtain the extracted features and a model that correctly pro“les the evolution of feature vectors In the detection stage given a new observation x t 1  we perform the following steps to determine whether it is normal or abnormal 1 Construct the state vector z t 1 from x t 1 and its past observations 2 Compute the new feature value y t 1 based on the method in Section II 3 Use past feature vectors to predict the new feature  y t 1 based on the method described in Section III 4 there is a large deviation between y t 1 and  y t 1  i.e   y t 1  y t 1    x t 1 is regarded as abnormal and an alarm is generated The threshold  for anomaly detection is determined based on the trade-off between false positives and negatives in different applications In our experiments the threshold  is determined as the maximum residual obtained from the training process V E VA L UAT I O N We apply the proposed method to model a large number of time series from a real power plant and use it to detect anomalies in the system In the following we rst describe the collected data in Section V-A Section V-B then presents the training results from the data The results of detection are described in Section V-C Section V-D then evaluates the the effect of different sliding window size d  described in Section II-A on the performance of proposed algorithm In addition we further look into the results and investigate the contribution of nonlinear featur es in the model performance which will be described in Section V-E A Data Description Thedatacontain 997 time series collected from sensors located at various positions in a real power plant The sensors collected the operational data every 30 seconds Our data cover a whole day of system operation in which each time series contain 2880 samples Some of the time series are illustrated in Figure 1 We can see that those time series vary dramatically in terms of shape variance covariance trend seasonal variation and periodicity  0.8 0.85 0.9 0.95 1 0 20 40 60 80 100 120 140 R 2 Figure 5 Histogram of R 2 values generated by VAR model We divide the time series into training and test sets The training data contains 1920 samples of all time series and the test set takes the remaining samples We use the training data to build a model for each time series and then use the test data to evaluate the performance of the model B Model Construction We follow the steps described in previous sections to build a pro“le for each time serie s In the feature extraction stage we compare the  value in Equation 3 with 0.9 to determine the intrinsic dimension Figure 4 plots some time series and their extracted feature vectors As we can see the evolution of feature vectors demonstrate strong regularities with different shapes such as polynomial sinusoid circle and ellipses Note that here we only plot the rst two dimension of feature vectors in Figure 4\(b whereas in reality feature vectors can have more than two dimensions Since many time series demonstrate regular feature trajectories our VAR based technique can correctly model feature trajectories from a majority of time series Figure 5 presents the histogram of VAR model tness R 2 s from all time series It shows that most time series have a high tness score on the VAR model Here we choose the threshold 0  893 As long as the R 2 value is greater than the threshold we use VAR to model the feature trajectory of time series It turns out that VAR can cover 922 time series around 92  48 of total series For remaining time series we use the density based approach to model their behaviors C Anomaly Detection Two commonly used metrics to evaluate a model in anomaly detection are the detection rate and false alarm rate Since all the experiment al data are collected from the system normal operations the test time series can only be used to evaluate the false alarm rate of proposed method In order to evaluate the detection rate we manually inject some anomalies in the test data to mimic some faulty situations in system operations By tuning different values of detection threshold  as described in Section IV we can obtain a receiver operating characteristic ROC curve to fully describe the performance of the algorithm In order to demonstrate the advantage of our proposed method we compare three different algorithms to model time series and then detect anomalies 1 the autoregressive AR model 1  2  t he s i ngul ar s p ect rum a nal y s i s  S S A  12  a nd 3 our propos ed met hod W e compare our met hod 635 


AR d=10 d=50 d=100 model SSA Proposed SSA Proposed SSA Proposed  false alarms 881 181 5 1864 9 3632 9 Table I The total number of false alarms generated by the AR model SSA model and our proposed method with different sliding window sizes anomaly AR d=10 d=50 d=100 level model SSA Proposed SSA Proposed SSA Proposed weak 0.8107 0.8867 0.9007 0.8933 0.9187 0.9000 0.9413 middle 0.8607 0.9067 0.9227 0.9067 0.9360 0.9133 0.9567 strong 0.8993 0.9133 0.9460 0.9133 0.9567 0.9400 0.9807 Table II The detection precision rate generated by the AR model SSA model and our proposed method with different sliding window sizes with AR model because AR is one of the most widely used methods for time series modeling The SSA model is used here for comparison because it also uses a sliding window to extract state vectors from time series and decomposes the state matrix into differ ent subspaces However the SSA method does not model feature vectors but instead reconstructs the original time series by removing the noise part in the decomposition Since both SSA and our proposed method use the slide window to construct state vectors the size of sliding window d may affect the performance of algorithms In the experiments we have tried different window sizes and the methods are compared under each individual d value In Section V-D we will further explain the effect of window size to the model performance 1 False Alarm Rate In the testing period we use the maximum residual in the training process as the threshold to ag an alarm if   y t 1  y t 1    We count the number of alarms generated in the test time series Since the original tets data are all from normal system operations the number of observed alarms are false alarms Table I shows the total number of false alarms generated by the AR model SSA model and the proposed method with different sliding window sizes As we can see our proposed method can signi“cantly reduce the false alarms in anomaly detection Compared with hundreds of alarms generated by other methods our method only produce less than 10 false alarms 2 Detection Rate As all the data are from system normal operations we randomly add synthesized anomaly event values We randomly select a time t  and we inject 5 consecutive noise by choosing the value from  1   ax  x t  t  w k  t  w  1   in  x t  t  w k  t  w  for window size w  According to noise amplitude parameter   we compare the anomaly detection perform ance for different level of anomalies failures namely weak middle and strong It is more dif“culty to detect a weak anomaly as the failure value would be more similar to normal data We count it a success of anomaly detection when it ags one alarm during  t t 4     0 0.2 0.4 0.6 0.8 1 0.75 0.8 0.85 0.9 0.95 1    False positive True positive   AR   SSA   Proposed Figure 6 The ROC curves of anomaly detection generated by the AR model SSA model and our proposed model under the middle level anomaly and d 50  We repeat this process K 10 times We de“ne the detection precision  1 K 012  K i  i  1 N  N j 1 I  d ij  015 where I    is an index function of detection success de“ned as I  d ij     1 if anomaly detection success at experiment i for time series j 0 otherwise We compare the results with three failure levels week middle and strong and changing the embedding size d  Table II shows the detection rate of our linear subspace decomposition based method compared to AR model and SSA model From Table II and Table I for middle level anomaly with d 50  we can see that compared with AR model only linear subspace decomposition based method can achieve 7  53 percent improvement of detection rate while signi“cantly remove the f alse alarms reduced from 881 to 9  compared with SSA model our method can achieve 1  33 percent improvement of detection rate and can reduce false alarms from 1864 to 9  Also we set different normalized anomaly ag threshold and we got the ROC curves as shown in Figure 6 Actually our method can improve the two baselines even more when the anomaly level is weak which make the anomaly detection more dif“cult For example for weak level anomaly with d 50  our method improves AR model by 10  8 percent and improves SSA model by 1  8 percent respectively D Effects of Sliding Window Size The sliding window size d in Section II-A determines the dimension of state vectors wh ich will affect the performance of anomaly detection A large window can contain more complete time series dynamics and hence make the model more accurate However increasing the window size will also introduce more noise and a lot of redundant information which may lead to an over“tted model As shown in Table I and II with the increase of d  the anomaly detection rate is improved whereas more false positives are also introduced However compared with the SSA method our method does not have a signi“cant increas e of false alarms for large d s This is probably because the feature trajetory model can lter out irrelevant dynamics to make the model more robust 636 


         0   500   1000   1500   2000   2500   3000   0.02   0.021   0.022   0.023   0.024                0   500   1000   1500   2000   2500   3000   0.2   0.18   0.16   0.14   0.12       t t x\(t x\(t          6   4   2   0   2   4 x 10 3   5   0   5 x 10 3      y\(t y\(t-3          0.06   0.04   0.02   0   0.02   0.04   0.06   0.1   0.05   0   0.05   0.1      y\(t y\(t-3  y 1  y 1  y 2  y 2          3   2   1   0   1   2   3   4   2   0   2   4      y\(t y\(t-3          2   1   0   1   2   3   4   2   0   2   4      y\(t y\(t-3  y 1  y 1  y 2  y 2 a Time series b Linear c Nonlinear Figure 8 Examples of feature trajectory extracted by linear and nonlinear subspace decomposition a original time series b feature trajectory extracted by linear subspace decomposition c feature trajectory extracted by nonlinear subspace decomposition    10  20  30  40  50  60  70  80  90  100  0  5  10  15    d False alarm    10  20  30  40  50  60  70  80  90  100  0.7  0.75  0.8  0.85  0.9  0.95  1     d Detection rate a False alarm b Detection rate Figure 7 Anomaly detection precision versus the sliding window size Since the number of false positives generated by our method is quite small we mainly investigate the effect of sliding window size on the anomaly detection rate We set different values of d and perform experiments to get the corresponding detection rates which is shown in Figure 7 It illustrates that detection rate improved with the increase of s  However In the experiments we use 10 E Do Nonlinear Features Really Help We further look into the results to pick those nonlinear time series and check whether our nonlinear feature extraction in Section II-D contributes to the improvement of detection performance compared with linear method Among the 997 time series we get 9.3 of them whose feature vectors are obtained by nonlinear extraction We apply linear feature extraction on those time series as well and compare the performance between lin ear and nonlinear features It turns out that nonlinear features can produce more regular shapes in their evolution trajectories Figure 8 plots two nonlinear time series and their features extracted by linear and nonlinear methods respectively While it is hard to nd strong geometry patterns in the trace of linear features in Fig 8\(b the trajectories of nonlinear features are much more smooth as shown in Fig 8\(c This is because nonlinear features correctly embed the dynamics of time series We compare the anomaly detection rate of those time series with linear and nonlinear features Table III illustrates Anomaly level weak middle strong Method linear nonlinear linear nonlinear linear nonlinear Detection rate 0.5524 0.8000 0.7079 0.8413 0.8619 0.9206 Table III Comparison of anomaly detection rate using linear and nonlinear features app lied to nonlinear time series the results with different levels of anomalies For the middle level anomaly nonlinear method can improve linear method by 13  34 in the detection For the weak level anomaly nonlinear method can improve linear method by 24  76  Such performance improvements are signi“cant enough to conclude that the nonlinear feature extraction is a necessary part in our proposed method which can better pro“le nonlinear time series and enhance the detection rate Although in the system we studied the nonlinear time series only occupy around 10 of total series we believe that more nonlinear time series will be encountered in other complex systems VI R ELATED W ORK Our work is related to two areas of interest time series modeling and the anomaly detection for complex physical systems Time series modeling is an active research area in several communities including data mining and a number of methods have been proposed The most widely used techniques include the auto-regressive AR moving average MA and ARMA models which assume the current observation of time series is linearly dependent on its past values or some noise items 1 In order t o h andl e nonl i n ear behaviors the paper p ro vi des a s u rv e y on us i n g s upport vector regression SVR to model time series Kalman lters and state space models 1 h a v e a lso b een wid e ly u s ed f o r sequence and time series data and has a wide range of applications Understanding and capturing the underlying system dynamics have been widely investigated in time series analysis 13   14  F o r e xampl e  t he del a y c oordi nat e embeddi ng 14  was proposed to study the chaotic behavior of time series 637 


However that method requires expensive computations to obtain a reliable delay parameter as well as the embedding dimension which is not well suited to handle a massive number of time series The singular spectrum analysis SSA 12 a v o i d s su ch an issu e b y s ettin g t h e d e lay a s o n e an d using a xed embedding dimension But SSA decomposes time series based on the least square criterion which is optimal only when the underlying dynamics is linear In addition SSA mainly focuses on the decomposition and reconstruction of time series to study its individual component such as trend and periodic items It does not model the whole trajectory of time series in the embedded feature space Compared with those methods our approach handles both linear and nonlinear dynamics of time series which can properly address the various behaviors in big sensor data Trajectory mining is also attracting a lot of attentions recently due to the increasing popularities of spatial temporal data in many applications For instance 15 propos ed a trajectory clustering algorithm to group similar trajectories The paper 16 es timated the t raf“c density given a lot of vehicle trajectories In this paper we borrow the idea from trajectory mining to model the evolution path of time series in the feature space However our method does not compare different trajectories but rather model the trace of each individual trajectory We use the VAR model to describe trajectories with strong regularities and also propose a density based technique to model irregular trajectories As a result different evolution patterns of time series features can be captured in our method Anomaly detection has been studied for a long time in data mining community 17 p res e nt ed an e x cel l e nt and comprehensive survey Some anomaly detection methods for time series data include 18  T he anomaly d etection methods have been applied to a wide range of application domains including spacecraft systems 19  s ys tem h ealth management[20  a ut omobi l e 21   p o w er s y s t em 22   a nd so on With the increasing number of sensors installed in physical systems we will see more data mining based applications to facilitate the system management tasks VII C ONCLUSIONS This paper has proposed a method to model a large number of time series with heterogeneous behaviors We have presented a technique to extract appropriate features from time series that can represent its underlying dynamics We have also proposed two techniques to model the evolution pattern of feature vectors along the time By combining the feature extraction and trajectory model we have correctly pro“led all the time series in a physical power plant We have demonstrated the effectiveness of the proposed method to detect anomalies in that system R EFERENCES 1 J  D  H a m ilto n  Time-series analysis  Princeton Univerity Press 1994 2 N  S apank e vych a nd R  S a nkar  T i m e S er i e s P r e di ct i o n Using Support Vector Machines A Survey Computational Intelligence Magazine IEEE  vol 4 no 2 pp 24…38 2009 3 A  H ar v e y a nd V  O r yshchenk o K er nel d ensi t y est i mat i on for time series data Journal of Forecasting  vol 28 4 P  G r a ssber ger a nd I  P r ocacci a Measur i n g t he st r a ngeness of strange attractors Physica D  vol 9 pp 189…208 1983 5 H  C hen G  Ji ang and K  Y oshi hi r a   Moni t o r i ng hi ghdimensional data for failure detection and localization in large-scale computing systems IEEE Trans on Knowl and Data Eng  vol 20 no 1 Jan 2008 6 Y  T ao C  F al out sos D  Papadi as a nd B  L i u P r e di ct i o n a nd indexing of moving objects with unknown motion patterns ser SIGMOD 04 2004 pp 611…622 7 J  R  P ar t i ngt on An Introduction to Hankel Operators Cambridge University Press 1989 8 B  S chol k opf and A  J  S mol a  Learning with Kernels Support Vector Machines Regularization Optimization and Beyond  MIT Press 2001 9 B  S ch  olkopf A Smola and K.-R M uller Nonlinear component analysis as a kernel eigenvalue problem Neural Comput  vol 10 no 5 pp 1299…1319 Jul 1998  L  R a l a i v ol a F  d A l che B uc U  P i e r r e  a nd M C u r i e Dynamical modeling with kernels for nonlinear time series prediction in NIPS  2003 p 2004  M P  W a nd and M  C  J ones Kernel Smoothing  Chapman and Hall/CRC 1995  R  V a ut ar d a nd M G h i l   S i ngul ar spect r u m a nal y si s i n nonlinear dynamics with applications to paleoclimatic time series Physica D  vol 35 no 3 pp 395…424 1989  F  T a k e ns  D e t e ct i n g s t r ange at t r act o r s i n t u r b ul ence  Dynamical Systems and Turbulence  vol 898 pp 366…381 1981  M S m al l  Applied Nonlinear Time Series Analysis Applications in Physics Physiology and Finance  World Scienti“c Publishing Company 2005  H  P  K r i e g el  M  R enz M S c huber t  a nd A  Z  e S t a t i st i cal density prediction in traf“c networks in SDM 2008 SIAM 2008 pp 692…703  J G  L ee J H a n and K  Y  W h ang T r a j e ct or y c l u st er i ng a partition-and-group framework ser SIGMOD 07 2007 pp 593…604  V  C h andol a A  B a ner j ee and V  K umar   A nomal y d et ect i on Asurvey ACM Comput Surv  vol 41 no 3 pp 15:1…15:58 Jul 2009  J Ma and S  P er ki ns  O n l i ne no v e l t y d et ect i o n o n t empor al sequences ser KDD 03 pp 613…618  R  F u j i maki  T  Y ai r i  a nd K  Machi d a  A n a ppr oach t o spacecraft anomaly detection problem using kernel feature space ser KDD 05  S  S a l v ador and P  C han L ear n i n g S t a t e s a nd R u l e s f or Detecting Anomalies in Time Series Applied Intelligence  vol 23 no 3 pp 241…255 Dec 2005  R  F u j i maki  T  N akat a H  T s ukahar a  a nd A  S a t o   Mi ni ng abnormal patterns from heterogeneous time-series with irrelevant features for fault event detection in SDM  2008 pp 472…482 22 H M o ri  State-o f-th e art o v e rv ie w o n d ata m in in g i n p o w er systems in IEEE Power Systems Conference and Exposition 2006 638 


Proposition 8 By adding noise randomly selected from the Lap 012 1   012 1 r  1 3  k g  distribution to the output of E  X   San will be   2 e  3  k g  ZKP with respect to agg k  A similar San mechanism can be proposed for E  Y  by substituting for the sensitivity and sample complexity IX C ONCLUSIONS We addressed zero-knowledge privacy for graph summarization We focused on group connection measures that are supported by virtually all the social-graph software products Our techniques are crucial to be applied on summary graphs before public release of the information To the best of our knowledge this is the rst work to use the ZKP framework for graph summarization We focused on ZKP mechanisms for edge privacy and introduced methods to compute the ZKP parameters Furthemore we presented an approach to achieve ZKP for the release of graph-summarization for probabilistic data The upshot is that ZKP is quite useful for protecting not only the participation of a connection but also the evidence of its participation However from a utility point of view ZKP can only be applied meaningfully on big social graphs R EFERENCES  Gephi http://gephi.or g  Netdriller  http://pages.cpsc.ucalgary ca nk oochak/NetDriller  Node xl http://node xl.codeple x.com  P ajek http://vlado.fmf.uni-lj.si/pub/netw orks/pajek/def ault.htm  S Bhagat A Go yal and L V  S Lakshmanan Maximizing product adoption in social networks In WSDM  pages 603…612 2012  A Blum C Dw ork F  McSherry  and K Nissim Practical pri v a c y  the sulq framework In PODS  pages 128…138 2005  C Budak D Agra w al and A E Abbadi Limiting the spread of misinformation in social networks In WWW  pages 665…674 2011 8 S C h e s t e r B M K a p r o n  G  R a m e s h G S r i v a s t a v a  A  T h o m o  a n d S Venkatesh k-anonymization of social networks by vertex addition In ADBIS  pages 107…116 2011 9 S C h e s t e r B M K a p r o n  G  R a m e s h G S r i v a s t a v a  A  T h o m o  a n d S Venkatesh Why waldo befriended the dummy k-anonymization of social networks with pseudo-nodes SNAM  2012  C Dw ork Dif ferential pri v a c y  I n ICALP 2  pages 1…12 2006  C Dw ork Dif ferential pri v a c y  A surv e y of results In TAMC  pages 1…19 2008  C Dw ork Dif ferential pri v a c y in ne w settings In SODA  pages 174 183 2010  C Dw ork F  McSherry  K  Nissim and A Smith Calibrating noise to sensitivity in private data analysis In TCC  pages 265…284 2006  J Gehrk e E Lui and R P ass T o w ards pri v a c y for social netw orks A zero-knowledge based de“nition of privacy In TCC  pages 432…449 2011  S Goedeck er  Remark on algorithms to nd roots of polynomials 15\(5 Sept 1994  N Hassanlou M Shoaran and A Thomo Probabilistic graph summarization In WAIM  pages 545…556 2013  M Hay  C  Li G Miklau and D Jensen Accurate estimation of the degree distribution of private networks In ICDM  pages 169…178 2009  J J P  III and J Ne ville Methods to determine node centrality and clustering in graphs with uncertain structure In ICWSM  2011  M A Jenkins Algorithm 493 Zeros of a real polynomial c2 ACM Trans Math Softw  1\(2 June 1975  D Kifer and A Machana v ajjhala No free lunch in data pri v a c y  I n SIGMOD Conference  pages 193…204 2011  D Kifer and A Machana v ajjhala A rigorous and customizable framework for privacy In PODS  pages 77…88 2012  G K ollios M Potamias and E T erzi Clustering lar ge probabilistic graphs IEEE Trans Knowl Data Eng  2012  K Liu and E T erzi T o w ards identity anon ymization on graphs In SIGMOD Conference  pages 93…106 2008  A Machana v ajjhala D Kifer  J  Gehrk e and M V enkitasubramaniam L diversity Privacy beyond k anonymity TKDD  1\(1 2007  M Mitzenmacher and E Upf al Probability and Computing Randomized Algorithms and Probabilistic Analysis  Cambridge University Press New York NY USA 2005  A Narayanan and V  Shmatik o v  De-anon ymizing social netw orks In IEEE Symposium on Security and Privacy  pages 173…187 2009  V  Rastogi M Hay  G  Miklau and D Suciu Relationship pri v a c y  output perturbation for queries with joins In PODS  pages 107…116 2009 605 


  10  te m p e r a tu r e  s e n s o r  pol ynom i a l  i s  0 9977  w hi l e  t he  R 2   fo r  t h e  ba s e pl a t e  t e m pe r a t ur e  s e ns or  pol ynom i a l  i s  0 9984   Ta b l e  8  pr e s e nt s  t he  pol ynom i a l  c oe f f i c i e nt s     Fi g u r e  14  q ue nc y  H z    Te m p e r a t u r e  d  Ce l s i u s   f o r  A u x i l i a r y  O s c i l l a t o r  a n d  Ba s e p l a t e   Ta b l e  8  Co e f f i c i e n t s  fo r  F r e q u e n c y  v s  T e m p e r a t u r e  Po l y n o m i a l s    Al t h o u g h  t h e  h i g h  R 2  va l ue s  s e e m  t o pr ovi de  r e a s on f or  co n f i d en ce i n  t h es e t em p er at u r e p r ed i ct i o n s   t h e E D L  th e r m a l e n v ir o n m e n t d if f e r s  n o ta b ly  f r o m  th a t in  c r u is e  St e a d y  t e m p e r a t u r e s  a n d  t h e r m a l  e q u i l i b r i u m  c h a r a c t e r i z e  th e  c r u is e  th e r m a l e n v ir o n m e n t  T h e  E D L  th e r m a l i ro n m e n t  i s  c h a ra c t e ri z e d  b y  ra p i d  h e a t i n g    A s  a  re s u l t   th e  S D S T  a n d  its  in te r n a l c o m p o n e n ts  w e r e  n o t in  th e r m a l eq u i l i b r i u m  d u r i n g  E D L   In  t h e rm a l  e q ui l i br i um   a s  s how n  Fi g u r e  15  be l ow   t he  A U X  O S C  i s  nor m a l l y s om e w ha t  wa r m e r  t h a n  t h e  b a s e p l a t e    Ho we v e r   a s  Fi g u r e  15   sh o w s  d u r i n g  E D L   t h e  b a se p l a t e  t e m p e r a t u r e  r o se  re l a t i v e l y  q u i c k l y  a n d  ra p i d l y  o v e rs h o t  t h e  A U X  O S C  te m p e r a tu r e   A lth o u g h  A U X  O S C  te m p e r a tu r e  r o s e  s lo w ly  to   c a tc h  u p   w ith  b a s e p la te  te m p e r a tu r e  th e  S D S T  w a s  n o t in  th e r m a l e q u ilib r iu m  d u r in g  E D L   T h is  im p a c ts  th e  accu r acy  o f  an y  f r eq u en cy  p r ed i ct i o n s  b as ed  o n  b as ep l at e te m p e r a tu r e     15  MS L  E D L  S D S T  T e m p e r a t u r e s  S 34 S 45 34 m y  a  As  a  b a c k up t o t he  pr i m e  70 m a n t e n n a   D S S 43   t he  si g n a l s f r o m  a b eam  w av eg u i d e  34 m a n t e n n a s   D S S 34    a h i g h  ef f i ci en cy  3 4 m a n t e n n a   S 45  w e r e  co m b i n ed  an d  r eco r d ed    k up  da t a  w a s  not  ne e de d in r e a l  d  wa s  a n a l y z e d  i n  p o s t ng  Di r e c t to h   re c e i v e d  b y  t h e  D S S S y dur i ng M S L  E D L  i s  s how n i n  Fi g u r e  16   Av e r a g e  c er to noi s e  pow e r   P c N o  p l o t t e d  i n  l i g h t  b l u e  m e a s u re d  by th e  E D A  us i ng t he  D S S S 45 a r r a y dur i ng E D L  w a s  dB     Fi g u r e  16  MS L  E D L  P c N o P e N o a n d R e s id u a l Fr e q u e n c y  w i t h  D SS S y  An t e n n a  se n si t i v i t y  i s m e a su r e d  b y  T  w h e r e  G  is   an t en n a g ai n   an d  T  is  th e  s y s te m   te m p e r a tu r e   G   fu n c t i o n  o f w a v e l e n g t h     phys i c a l  a pe r t ur e  a r e a   A p   ap er t u r e ef f i ci en cy     as  s h o w n  b el o w                    6    Ba s e d  s o l e l y  o n   ap er t u r e  ea  A p    T   a  34 m a n t e n n a  is  a b o u t 1 7  0  1 7  0  3 5  0  3 5    6   T   0   Ho we v e r   t h e  N 70 m a n t e n n a  al s o  h as  b et t er  ap er t u r e ef f i ci en cy     a n d  a  lo w e r  s y s te m  noi s e  t e m pe r a t ur e   T  th a n  th e  D S N  3 4 e    th e s e  f a c to r s  c o n s id e r e d  th e  T  of  a  D S N  34 m a n t e n n a  i s  ab o u t  1 8   t h e T  of  a  D S N  70 m a n t e n n a  8    pr e di c t e d di f f e r e nc e  i n a r r a y ga i n be t w e e n t he  70  an d  t w o  ar r ay ed  3 4 m a n t e n n a s  i s  10 g 10   1 0   18  18    4 44  dB   a s s um i ng no c om bi ni ng l os s   P c N o  is  p r o p o r tio n a l  T   Th e  m e a s u r e d  d i f f e r e n c e  i n  P c N o   S S S n  17   Th e  m e a n  m e a s u r e d  d i f f e r e n c e  f r o m  E 645 s e c onds  t o E 2 9 9  s e c o n d s  w a s  4  2 6  d B   Th e r e f o r e  m e a n  c o m b i n i n g  lo s s d u r in g th is tim e w a s  ab o u t  0  1 8                      0 1 23 45''67626 84  3 6 9 2 7 7    6593 9\(:6 562\(6\(2'47   0        0 1 5'695\(95 87 7 3 5   4 7 5 2  97599 562\(6\(&765 


  11   Fi g u r e  17  e re n c e  i n  D S S 43 a nd D S S S P c N o   Af t e r  E DL   E v e n t  R e c o r d s   E VR s   t h a t  l o g g e d  e a c h  t o n e  is s u e d  d u r in g  E D L  w e r e  obt a i ne d f r om  M S L   Th e s e  l o g s  we r e  c o m p a r e d  wi t h  t h e  r e a l tim e  r e s u lts  p r o v id e d  b y  th e  ED A  t o  d e t e r m i n e  p e r f o r m a n c e    Th e  D TE c o m m u n i c a t i o n s  sy st e m  r e c e i v e d  a n d  c o r r e c t l y  i d e n t i f i e d  1 0 0   o f  ra d i a t e d   i n r e a l tim e  d u r in g  M S L  E D L   Th e s e  r e s u l t s  a r e  co n s i s t en t  w i t h  t h e t h eo r et i cal  pr oba bi l i t i e s  of  c a r r i e r  acq u i s i t i o n  t r ack i n g  an d  d at a t o n e d et ect i o n  co m p u t ed  i n  Se c t i o n  3   5   C ON   Th e  D i r e c t to Ea r t h  X ba nd c om m uni c a t i ons  s ys t e m  ut i l i z e d dur i ng M S L  E D L  s uc c e s s f ul l y de t e c t e d a l l  ra d i a t e d   de s pi t e  c ha l l e ngi ng s i gna l  dyna m i cs  w i t h  l ar g e u n k n o w n  ch an g es  i n  D o p p l er  f r eq u en cy   r at e  an d  accel er at i o n   Fu t u r e  m i s s i o n s  w i t h  p e r i o d s  o f  r a p i d  a n d  u n k n o w n  s i g n a l  dyna m i c s  s uc h a s  Ma r s  o r  i c y  m o o n  la n d e r s  can  l ev er ag e fr o m  t h e  M S L  de s i gn f or  D T E  c om m uni c a t i ons    6   A CK NO W L E DG E M E NT S   T he  a ut hor s  w oul d l i ke  t o a c know l e dge  t he  c ont r i but i on s   Ja n  T a r sa l a   te s tin g  o f  th e  E D A  p r io r  to  M S L  E D L  us i ng a  P R S R  a nd M S L  t e s t be d    Th e  a u t h o r s  w o u l d   th a n k  J e r e m y  S r  fo r  p r o v i d i n g  6 D O F  s i m u l a t i o n  d a t a  th a t w a s  v a lu a b le  in  c o n f ig u r in g  th e  E D A   Th e  a u t h o r s  wo u l d  a l s o  l i k e  t o  t h a n k  t h e  C DS C C  s t a t i o n  p e r s o n n e l  f o r  th e ir  e x c e lle n t s u p p o r t a n d  ope r a t i ons  of  t he  D S N  eq u i p m en t  an d  t h e F u l l  S p ect r u m  P r o ces s o r  A r r ay  i n  u   Th i s  r e s e a r c h  w a s  c a r r i e d  o u t  a t  t h e  J e t  P r o p u l s i o n  La b o r a t o r y   C a l i f o r n i a  I n s t i t u t e  o f  Te c h n o l o g y    Co p y r i g h t  2012 C a l i f or ni a  I ns t i t ut e  of  T e c hnol ogy  Go v e r n m e n t  sp o n so r sh i p  a c k n o w l e d g e d     


  12  R EF ER EN C ES   1  E  S a t o r i u s   P   Es t a b r o o k   J   W i l s o n   D   F o rt    D i re c t to  Ea r t h  c o m m u n i c a t i o n s  a n d  s i g n a l  p r o c e s s i n g  f o r  M a r s  ex p l o r at i o n  r o v er  en t r y   d es cen t  an d  l an d i n g   T h e In t e rp l a n e t a ry  N e t w o rk  P ro g re s s  R e p o rt   IP N  P ro g re s s  Re p o r t  4 2 2003  2 A n d re  J o n g e l i n g  an d  S u s an  F i n l ey     M ar s  S ci en ce La b o r a t o r y  Te l e c o m  S y s t e m  En g i n e e r i n g  P r e  Re v i e w   E D L  D a t a  A n a l y s i s  S i m u l a t i o n s  Re s u l t s     A p r i l  24  2007   3 W   J   H u rd   P   E s t a b ro o k   C   S   R a c h o   a n d  E   S a t o ri u s   C r i t i cal  sp acecr af t to ear t h  co m m u n i cat i o n s   ex p l o r at i o n  r o v er   M E R   en t r y   d es cen t  an d  l an d i n g   Pr o c   I E E E  A e r o s p a c e  C o n f e r e n c e   v o l  3   p p   1 2 8 3  MT   Ma r c h  2 0 0 2    4 M  S o r i a n o   S   F i n l e y   A   J o n g e l i n g   D   F o r t   C   G o o d h a r t   D  R o g s t a d   R   Na v a r r o    Sp a c e c r a f t to Ea r t h  Co m m u n i c a t i o n s  fo r J u n o  a n d  M a rs  S c i e n c e  L a b o ra t o ry  Cr i t i c a l  E v e n t s   P r o c  I E E E  A e r o sp a c e  C o n f e r e n c e   M T   2   5 A   M a k o v s k y   P   Il l o t t   J   T a y l o r    M a rs  S c i e n c e  La b o r a t o r y  Te l e c o m m u n i c a t i o n s  S y s t e m  D e s i g n    D e e p  Sp a c e  C o m m u n i c a t i o n s  a n d  N a v i g a t i o n  Sy s t e m s  C e  of  E xc e l l e nc e  D e s i gn a nd P e r f or m a nc e  S um m a r y S e r i e s   No v e m b e r  2 0 0 9   6 M   S o ri a n o  a n d  P   E s t a b ro o k    M S L  E D L  S i m u l a t i o n s   i n t e rn a l  d o c u m e n t   J e t  P ro p u l s i o n  L a b o ra t o ry   P a s a d e n a   CA   M a y  7   2 0 1 2   7  Sa t o r i u s  R e v i s e d  T h r e s h o l d s  f o r  E D L    i n t e r n  doc um e nt    J e t  P r opul s i on L a bor a t or y  P a s a de na   C A   Ja n u a r y  1 4   2 0 0 3   8 A   K w o k     M o d u l e  2 0 6  Te l e m e t r y  G e n e r a l  In fo rm a t i o n    i n DS N  T e l e c o mmu n i c a t i o n s  L i n k  De s i g n  k B   D S N  N o  8 1 0 005   P a s a de na  Ca l i f o r n i a   J P L   Oc t o b e r  3 1   2 0 0 9  ht t p   e i s  j pl  na s a g o v d e e p s p a c e d s n d o c s 8 1 0 005     


  13  M el i s s a  S o r i a n o  ff f tw a r e  e n g in e e r  in  th e  T r a c k in g  Sy s t e m s  and A ppl i c at i ons  Se c t i on at  t he  J e t  P r opul s i on L abor at or y    She  has  de v e l ope d r e al  so f t w a re  f o r t To  co m m u n i ca t i o n s  w i t h  M a r s  Sc i e nc e  L abor at or y  dur i ng E nt r y   De s c e n t   a n d  L a n d i n g   th e  L o n g  W a v e le n g th  Ar r a y   N AS A s  Br e a d b o a r d  Ar r a y   a n d  t h e  W i d e b a n d  VL BI  S c i e n c e  Re c e i v e r  u s e d  i n  t h e  D e e p  S p a c e  N e t w o r k   Me l i s s a  i s  a l s o  cu r r en t l y t h e s o f t w a r e co g n i z a n t  en g i n eer  f o r  t h e D S C C  Do w n l i n k  A r r a y   She  has  a B  S   fr o m  C a lte c h  d o u b le  m a jo r  in  E le c tr ic a l a n d  C o m p ut e r  E ngi ne e r i ng and B us i ne s s  Ec o n o m i c s  a n d  M a n a g e m e n t    S h e  a l s o  h a s  a n  M  S    Co m p u t e r  S c i e n c e  fr o m G e o r g e M a so n  U n i v e rsi t y   Sus a n F i nl e y  is  a  k e y  s ta ff me mb e r  i n  t h e  P r o c e s s o r  S y s t e ms  De v e l o p me n t  Gr o u p  a t  J P L     is  th e  s u b s y s te m  e n g in e e r  fo r  th e  Fu ll S p e c tr u m  P r o c e s s o r  su b sy st e m  d e p l o y e d  i n  N A S A  s De e p  S p a c e  N e t w o r k     exp er i en ce i n cl u d es  t h e o p er a t i o n  of  t he  E D A  f or  bot h of  t he  M E R  l andi ngs  on M ar s  as  w e l l  as  th e  o p e r a tio n  o f th e  R a d io  S c ie n c e  R e c e iv e r  fo r  th e  la n d in g  o f th e  H u y g e n s  P r o b e  o n  T it an and f or  t he  P hoe ni x  l andi ng on s    Da v i d  t  re c e i v e d  a  B  A  S c  i n  En g i n e e r i n g  Ph y s i c s  a n d  M  S c  i n  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  o f  To r o n t o  a n d  a n  M S c   a n d  P h  D   i n  Ra d i o  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  of  M anc he s t e r    H e  j oi ne d N R C  C a n a d a  i n  1 9 7 2  a n d  w o r k e d  o n  a l l  as pe c t s  of  V L B I  unt i l  1987   H e  su b se q u e n t l y  j o i n e d  J P L  i n  se c t i o n  3 3 5  a n d  w o rk e d  o n  a  num be r  of  har dw ar e  and s of t w ar e  pr oj e c t s  f or  t he   be c am e  s upe r v i s or  of  t he  P r oc e s s or  Sy s t e m s  de v e l opm e nt  Gr o u p  f o r  t h e  t w o  y e a r s  p r i o r  t o  r e t u r n i n g  t o  N R C  i n  2 0 0 2   Un t i l  h i s  r e t i r e me n t  i n  2 0 1 0  h e  w o r k e d  o n   Co r r e l a t o r  P r o j e c t    No w a   G u e s t  W o r k e r    h e  h e l p s  o u t  wi t h  t h e  E V L A  a s  i t  b e c o m e s f u l l y  o p e ra t i o n a l  a n d  w i t h  oc c as i onal  que s t i ons  f r om  J P L    Br i a n  S c h r a t z  is  th e  le a d  e n g in e e r  fo r  th e  E D L  te le c o m m u n ic a tio n s  o n  th e  Ma r s  S c i e n c e  L a b o r a t o r y  m i s s i o n  a n d  a m e m be r  of  J P L  s  C om m uni c at i ons  Sy s t e m s  and O pe r at i ons  gr oup      jo in e d  J P L  th r e e  y e a r s  a g o   B S  E E  a n d  M  S  E E   Pe nns y l v ani a St at e  U ni v e r s i t y    Pe t e r  I l o t t  is  th e  te le c o m m u n ic a tio n s  sy st e m  l e a d  f o r t h e  M S L  m i ssi o n   H e  has  w or k e d on s pac e c r af t  te le c o m m u n ic a tio n s  s y s te m  d e s ig n  fo r  2 5  y e a r s  1 1  y e a r s  o n  c o m m e r c ia l sp a c e c ra f t   a n d  si n c e  2 0 0 0  a t  J P L    wo r k e d  o n  M E R   P h o e a te le c o m m u n ic a tio n s  s y s te m  e n g in e e r  Pe t e r  w o r k e d  o n  a l l  t h e  M a r s  ED L   e n t r y  and la n d in g   e ffo r ts  s in c e  M E R  a n d  in  b e tw e e n  M a r s  m is s io n s  he l pe d out  on t he  D e e p I m pac t  and C l oudat  mi s s i o n s  a t  J P L   He  c u r r e n t l y  s u p p o r t s  t h e  M S L  s u r f a c e  mi s s i o n  p h a s e   a n d  i s  th e  te le c o m m u n ic a tio n s  le a d  fo r  th e  E u r o p a  m is s io n  cu r r en t l y u n d er  s t u d y  I l o t t  h o l d s  B S c  M S c  a n d  P h D  de gr e e s  i n phy s i c s  and e l e c t r i c al  en g i n eer i n g  f r o m  M cG i l l  i st y  o f  M o n t re a l    i  re c e i v e d  t h e  B  S  E  E   and t he  M  S E  E   i n 1997 and t he  Ph  D   i n  El e c t r i c a l  En g i n e e r i n g  i n  2003  al l  f r om  U C L A    He  h a s  b e e n  em p l o yed  a t  t h e Jet  P r o p u l s i o n  La b o r a t o r y  a s  a  Te l e c o m m u n i c  en g i n eer  s i n ce 1 9 9 9  a n d  h a s  s er ved  on t he  M ar s  E x pl or at i on R ov e r   DA W N   C a s s i n i   J u n o   a n d  M a r s  Sc i e nc e  L abor at or y  pr oj e c t s     Po l l y  E s t a b r o o k  is  th e  d e p u ty  ma n a g e r  o f  t h e  C o mmu n i c a t i o n  Ar c h i t e c t u r e s  a n d  Re s e a r c h  S e c t i o n  at  J P L     She  i s  a m e m be r  o f N A S A  s  Spac e  C om m uni c at i on and Na v i g a t i o n  P r o g r a m  s u p p o r t i n g  t h e  de f i ni t i on of  t he  N A SA  s  f ut ur e  In t e g r a t e d  C o m m u n i c a t i o n  a n d  Na v i g a t i o n  Ne t wo r k  a n d  i s  a  m e m b e r  o f  t h e  I n t e g r a t e d  Sy s t e m  E ngi ne e r i ng t e am  f or  t he  M ar s  Sc i e nc e  L abor at or y  r   Fr o m  2 0 0 5  t o 2010  s he  l e d s e v e r al  c om m uni c at i on sy st e m  d e si g n  t e a m s w i t h  t h e  g o a l  o f  d e f i n i n g  t h e  mo d i f i c a t i o n s  t o  N A S A  s  S p a c e  C o mmu n i c a t i o n  a n d  Na v i g a t i o n  i n f r a s t r u c t u r e  n e e d e d  t o  s u p p o r t  t h e  p l a n n e d  hum an m i s s i ons  t o t he  M oon and M ar s   F r om  2000 t o 2004 sh e  w a s t he  l e ad t e l e c om  s y s t e m  e ngi ne e r  f or  t he  M ar s  Ex p l o r a t i o n  Pr o j e c t   r e s p o n s i b l e  f o r  t h e  p e r f o r m a n c e  o f  t h e  en t r y d es cen t  a n d  l a n d i n g  t el eco m m u n i ca t i o n s  s ys t em  a n d  fo r  th e  o v e r a ll d e s ig n  a n d  p e r fo r m a n c e  o f th e  D ir e c t to  Ea r t h  a n d  r e l a y  c o m m u n i c a t i o n s  s y s t e m s   In  2 0 0 4   D r   Es t a b r o o k  r e c e i v e d  t h e  N AS A Ex c e p t i o n a l  Ac h i e v e m e n t  Me d a l  f o r  h e r  w o r k  o n  t h e  Ma r s  E x p l o r a t i o n  R o v e r  T e l e c o m  Sy s t e m   She  has  w r i t t e n ov e r  35 t e c hni c al  pape r s  and ch a i r ed  n u m er o u s  I E E E  a n d  A I A A  co n f er en ce S es s i o n s    Po l l y  Es t a b r o o k  r e c e i v e d  h e r B  A   i n  e n g i n e e ri n g  p h y si c s fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  B e r k e le y  a n d  M S  a n d  Ph  D   d e g r e e s  i n  e l e c t r i c a l  e n g i n e e r i n g  f r o m  S t a n f o r d  Un i v e r s i t y   S t a n f o r d   C A      


  14  Ka m a l  O u d r h i r i  is  a  s e n io r  r  in  th e  R a d io  S c ie n c e  Sy s t e m s  G r oup at  NA S A  s  J e t  Pr o p u l s i o n  L a b o r a t o r y   As  a co n t r a ct  t ech n i ca l  m a n a g er   Ou d r h i r i  lti di s c i pl i nar y  te a m s  th r o u g h  th e  de s i gn  im p le m e n ta tio n  a n d  d e liv e r y  of  flig h t h a r d w ar e  t o t he  r adi o sc i e n c e  c o m m u n i t y   Ov e r  t h e  l a s t  d e c a d e   Ou d r h i r i  se rv e d  i n  key r o l es  o n  m u l t i p l e N A S A  mi s s i o n s   T h e  M a r s  E x p l o r a t i o n  s  M E R   t h e  In t e r n a t i o n a l  C a s s i n i  m i s s i o n  t o  Sat ur n T he  GR A I L  l u n a r  mi s s i o n  a n d  T h e  M a r s  S c i e n c e  La b o r a t o r y     Da n i e l  K a h a n  is  a s e ni or  m e m be r  of  S ci en ce S ys t em s  G r o u p  at  NA S A  s  J e t  Pr o p u l s i o n  La b o r a t o r y   Ov e r  t h e  l a s t  ei g h t  yea r s   h e h a s  pr ov i de d e ngi ne e r i ng s uppor t  f or  t he  i o s c i e nc e  c om m uni t y   NA S A  m i s s i o n s   i n c l u d i n g  M a r s  G l o b a l  Sur v e y or   M ar s  R e c onnai s s anc e  Or b i t e r   th e  G R A I L  lu n a r  m is s io n  th e  In t e r n a t i o n a l  C a s s i n i  mi s s i o n  t o  S a t u r n   a n d  Ma r s  S c i e n c e  La b o r a t o r y   Ed g a r  H   S a t o r i u s  is  a  p r in c ip a l me mb e r  o f  t h e  t e c h n i c a l  s t a f f  i n  th e  F lig h t C o m m u n ic a tio n s  Sy s t e m s  Se c t i on of  t he  J e t  Pr o p u l s i o n  L a b   H e  p e r f o r m s  sy st e m s a n a l y si s i n   de v e l opm e nt  of  di gi t al  s i gnal  e ssi n g  a n d  c o m m u n i c a t i o n s sy st e m s w i t h  sp e c i f i c  a p p l i c a t i o n s t o  b l i n d  d e m o d u l a t i o n   di gi t al  di r e c t i on f i ndi ng and di gi t al  r e c e i v e r s   H e  has  publ i s he d ov e r  90 ar t i c l e s  and hol ds  t w o pat e nt s  i n t he  f i e l d of  di gi t al  s i gnal  pr oc e s s i ng and i t s  appl i c at i ons   I n a ddi t i on  he  i s  an A dj unc t  A s s oc i at e  P r of e s s or  at  t he  U ni v e r s i t y  of  Sout he r n C al i f or ni a w he r e  he  t e ac he s  di gi t al  s i gnal  pr oc e s s i ng c our s e s   H e  r e c e i v e d hi s  B  Sc   i n e ngi ne e r i ng fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  L o s  A n g e le s  a n d  th e  M S  and P h D   de gr e e s  i n  el ect r i ca l  en g i n eer i n g  f r o m  t h e Ca l i f o r n i a  I n s t i t u t e  o f  T e c h n o l o g y   P a s a d e n a   Ca l i f o r n i a   


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators – Data Element Methods – Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Today’s cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlight’s data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlight’s hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlight’s method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






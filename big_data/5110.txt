Artem Chebotko John Abraham Pearl Brazier Anthony Piazza Andrey Kashlev Shiyong Lu I I NTRODUCTION In scientiìc workîow environments scientiìc discovery reproducibility result interpretation and problem diagnosis primarily depend on the availability of provenance  metadata that records the complete history of an in-silico experiment 2 3 4 Using the terminology of 
Department of Computer Science University of Texas Pan American Edinbug TX USA chebotkoa jabraham brazier utpa.edu Piazza Software Consulting Corpus Christi TX USA tony@piazzaconsulting.com Department of Computer Science Wayne State University Detroit MI USA andrey.kashlev shiyong wayne.edu 
Storing Indexing and Querying Large Provenance Data Sets as RDF Graphs in Apache HBase 
Provenance which records the history of an insilico experiment has been identiìed as an important requirement for scientiìc workîows to support scientiìc discovery reproducibility result interpretation and problem diagnosis Large provenance datasets are composed of many smaller provenance graphs each of which corresponds to a single workîow execution In this work we explore and address the challenge of efìcient and scalable storage and querying of large collections of provenance graphs serialized as RDF graphs in an Apache HBase database Speciìcally we propose i novel storage and indexing techniques for RDF data in HBase that are better suited for provenance datasets rather than generic RDF graphs and ii novel SPARQL query evaluation algorithms that solely rely on indices to compute expensive join operations make use of numeric values that represent triple positions rather than actual triples and eliminate the need for intermediate data transfers over a network The empirical evaluation of our algorithms using provenance datasets and queries of the University of Texas Provenance Benchmark conìrms that our approach is efìcient and scalable scientiìc workîow provenance big data HBase distributed database SPARQL RDF query scalability 
Abstract Keywords 
    
the Open Provenance Model OPM pro v enance of a single workîow execution is a directed graph with three kinds of nodes 
e.g data products e.g computations or actions and e.g catalysts of a process Nodes are connected via directed edges that represent ve types of dependencies process artifact artifact process process agent process process and artifact artifact In addition OPM includes a number of other constructs that are helpful for provenance modelling A sample provenance graph that uses the OPM notation and encodes provenance of a workîow for creating and populating a relational database is shown in Fig 1 In this graph ellipses and rectangles denote artifacts and processes respectively and edges denote dependencies whose interpretations can be inferred based on their domains and ranges 
artifacts processes agents used wasGeneratedBy wasControlledBy wasTriggeredBy wasDerivedFrom 
Create Table SQL Statements Create Index SQL Statements Create Trigger SQL Statements 
Create Database Schema Schema 
Load Data Dataset Instance 
The provenance graph is now effectively converted to an RDF graph or set of triples that encode its edges and can be further stored and queried using the SPARQL query language SPARQL and other RDF query languages have been frequently used for provenance querying 7  A pro v enance query  such as Find all artif acts and their values if any in a provenance graph with identiìer http://cs.panam.edu/utpb#opmGraph can be expressed in SPARQL as 
utpb:schema rdf:type opmv:Artifact  utpb:instance rdf:type opmv:Artifact  utpb:dataset rdf:type opmv:Artifact  utpb:loadData rdf:type opmv:Process  utpb:loadData opmv:used utpb:schema utpb:dataset  utpb:instance opmv:wasGeneratedBy utpb:loadData  utpb:instance opmv:wasDerivedFrom utpb:schema utpb:dataset  
Figure 1 Sample OPM Provenance Graph This provenance graph can be serialized using the Resource Description Framework RDF and OPM vocabularies such as Open Provenance Model Vocabulary OPMV or Open Provenance Model OWL Ontology OPMO As an example we show a partial serialization of the presented provenance graph using OPMV and Terse RDF Triple Language Turtle 
2013 IEEE Ninth World Congress on Services 978-0-7695-5024-4/13 $26.00 © 2013 IEEE DOI 10.1109/SERVICES.2013.32 1 
2013 IEEE Ninth World Congress on Services 978-0-7695-5024-4/13 $26.00 © 2013 IEEE DOI 10.1109/SERVICES.2013.32 1 


  002 003     
n i i n 
1 2 1 2 
0  
SELECT artifact value FROM NAMED http://cs.panam.edu/utpb#opmGraph WHERE  GRAPH utpb:opmGraph  artifact rdf:type opmv:Artifact  OPTIONAL  artifact rdf:label valu e   
The main focus of our research in this work is on the efìcient and scalable storage and querying of large collections of provenance graphs serialized as RDF graphs in an Apache HBase database With the development of user-friendly and powerful tools such as scientiìc workîow management systems 10 11 12 13 14 scientists are able to design and repeatedly execute workîows with different input datasets and varying input parameters with just a few mouse clicks Each workîow execution generates a provenance graph that will be stored and queried on different occasions A single provenance graph is readily manageable as its size is correlated with the workîow size and even workîows with many hundreds of processes produce a relatively small metadata footprint that ts into main memory of a single machine The challenge arises when hundreds of thousands or even millions of provenance graphs constitute a provenance dataset Managing large and constantly growing provenance datasets on a single machine eventually fails and we turn to distributed data management solutions We design such a solution for large provenance datasets based on Apache HBase an open-source implementation of Googleês BigTable While we deplo y and e v aluate our solution on a small cluster of commodity machines HBase is readily available in cloud environments suggesting virtually unlimited elasticity The main contributions of this work are i novel storage and indexing schemes for RDF data in HBase that are suitable for provenance datasets and ii novel and efìcient querying algorithms to evaluate SPARQL queries in HBase that are optimized to make use of bitmap indices and numeric values instead of triples Our solution enables the evaluation of queries over an individual provenance graph without intermediate data transfers over a network In addition we conducted an empirical evaluation of our approach using provenance graphs and test queries of the University of Texas Provenance Benchmark Our e xperiments conìrmed that our proposed storage indexing and querying techniques are efìcient and scalable for large provenance datasets II R ELATED W ORK Besides HBase there are multiple projects under the Apache umbrella http://projects.apache.org that focus on distributed computing including Hadoop Cassandra Hive Pig and CouchDB Hadoop implements a MapReduce software framework and a distributed le system Cassandra blends a fully distributed design with a column-oriented storage model Hive deals with data warehousing on top of Hadoop and provides its own Hive QL query language Pig is geared towards analyzing large datasets through use of its high-level Pig Latin language for expressing data analysis programs which are then turned into MapReduce jobs CouchDB is a distributed document-oriented database that supports incremental MapReduce queries written in JavaScript Along the same lines other projects in academia and industry include Cheetah data warehousing on top of MapReduce Hadoop an improved MapReduce framework based on Hadoop G-Store a key-value store with multi key access functionality and Hadapt data warehousing on top of MapReduce None of the above projects targets RDF data speciìcally or supports SPARQL RDF data management in non-relational often called NoSQL databases has only recently been gaining momentum Due to the paper size limit we only brieîy introduce the reader to the most relevant works in this area Techniques for evaluating SPARQL basic graph patterns using MapReduce are presented in and 19 Ef cient approaches to analytical query processing and distributed reasoning on RDF graphs in MapReduce-based systems are proposed in and 21 The translation of SP ARQL queries into Pig Latin queries that can be evaluated using Hadoop is presented in Ef cient RDF querying in distrib uted RDF-3X is reported in RDF storage schemes and querying algorithms for HBase and MySQL Cluster are proposed in our own work Bitmap indices for RDF join processing on a single machine have been previously studied in While e xisting w orks deal with v ery lar ge graphs that require partitioning this work deals with very large numbers of relatively small RDF graphs which enables us to apply unique optimizations in our storing indexing and querying techniques III S TORING AND I NDEXING RDF G RAPHS IN HB ASE In this section we rst formalize deìnitions of RDF dataset RDF graph and SPARQL basic graph pattern We then propose our indexing and storage schemes for RDF data in HBase Deìnition 3.1   An RDF dataset is a set of RDF graphs  where each graph is a named graph that has a unique identiìer and  The RDF dataset deìnition requires each RDF graph to have a unique identiìer which is frequently the case in large collections of RDF graphs to allow easy distinction among graphs Such an identiìer is either a part of the graph description or can be assigned automatically without a loss of generality Deìnition 3.2   An RDF graph is a set of RDF triples  where and each triple 
A RDF Data and Queries RDF dataset RDF graph 
D G G   G G D G id n G t t   t n G 
2 
2 


             1          1             1  2     1 2 1        1  2     1 2 1        1  2     1 2 1         
        
1 2 1 2 1 2 1 1 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 2 1 1 1 2 1 1 
Basic graph pattern B Indexing Scheme Index Index Index Indices and 
002 004 004 004   002  002   002        003 002 002   002     002         005 005 005 002       002 002 002       002 002 002       002 002 
t G s p o s p o P D P P P  P P p s p o G G D D G G   G num G num t i t G G t t   t num i t i G t t   t bgp tp tp tp tp AN D tp AN D AN D tp n AN D tp bgp sp pp op sp pp op I I G D p v  p v  p v p P D n P v G k t num k t G t p p I I p p G P P  G I I s p o I s I p I o I I I I I G D v  v  n v n G  n G v G k t num k t G t num i t G t s t s I I G D v  v  n v n G  n G v G k t num k t G t num i t G t o t o I I I G D v  v  n v n G  n G v G k t num k t G t num i t G t o t s I I I I 
i n i i i n i i n i n n n i p p n n i i k k k i p p s o s p o s p o ss ss n i k k i i k i oo oo n i k k i i k i so os so n i k k i i k i os so os T so 
is a tuple of the form with   and denoting a subject predicate and object respectively The RDF graph deìnition views an RDF graph as a set of triples whose subjects objects and predicates correspond to labeled nodes and edges respectively Each node in an RDF graph is labeled with a unique identiìer i.e Universal Resource Identiìer or URI or a value i.e literal Edges are labeled with identiìers i.e URIs and multiple edges with the same label are common While the number of distinct labels for nodes which correspond to subjects and objects increases with the growth of an RDF graph or RDF dataset as new nodes are added the number of labels for edges which correspond to predicates is usually bound to the number of properties deìned in an annotation vocabulary e.g OPMV deìnes 13 properties and reuses a few properties from the RDF and RDFS namespaces OPMO extends OPMV and supports around 50 properties Therefore for any large RDF dataset it is safe to assume that the number of distinct predicates is substantially smaller on the order of dozens or hundreds than the number of distinct subjects or objects We use to denote a set of all predicates in an RDF dataset  formally  where   and  In an RDF graph the order of RDF triples is not semantically important Since any concrete RDF graph serialization has to store triples in some order it is convenient to view a set of triples in an RDF graph as an ordered set We use function to denote the position of a triple in an RDF graph  such that returns position  where and  Furthermore inverse function returns triple found at position in graph  To query RDF datasets and individual RDF graphs the standard RDF query language called SPARQL is used SPARQL allows deìning various graph patterns that can be matched over RDF graphs to retrieve results While SPARQL distinguishes basic graph patterns optional graph patterns and alternative graph patterns in this paper we restrict our presentation to the basic graph patterns as deìned in the following Deìnition 3.3   A basic graph pattern is a set of triple patterns  also denoted as  where  is a binary operator that corresponds to the conjunction in SPARQL and each is a triple  such that   and are a subject pattern predicate pattern and object pattern respectively A basic graph pattern consists of the simplest querying constructs called triple patterns A triple pattern can contain variables or URIs as subject predicate and object patterns object patterns can also be represented by literals that are to be matched over the respective components of individual triples Unlike a URI or a literal in a triple patten that has to match itself in a triple a variable can match anything Multiple occurrences of the same variable in a triple pattern or a basic graph pattern must be bound to the same values Matching a basic graph pattern over an RDF graph involves matching of constituent triple patterns over a set of RDF triples Each triple pattern yields an intermediate set of triples and such intermediate results must be further joined together to nd matching subgraphs To speed up this computation we deìne several bitmap indices Deìnition 3.4   A bitmap index for an RDF graph is a set of tuples  where is a predicate in a set of all predicates in an RDF dataset   and is a bit vector of size that has in th position iff triple   and  Index helps quickly identify triples their positions in an RDF graph that have a particular predicate denotes a bit vector for predicate  The size of the bit vector is xed and equals the number of triples in the graph i.e  The number of vectors in the index equals the number of distinct predicates i.e  which is relatively small usually  Similarly indices and to quickly identify triples with a given subject and object can be deìned Intuitively to nd a triple with subject  predicate  and object in an RDF graph a logical AND of the corresponding vectors can be computed  While the purpose of indices  and is to speed up matching of individual triple patterns the indices that we deìne next can be used to join intermediate results obtained via triple pattern matching into subgraphs Deìnition 3.5   A bitmap index for an RDF graph is a set of tuples  where  are the consecutive triple positions in  and is a bit vector of size that has in th position iff     and  Deìnition 3.6   A bitmap index for an RDF graph is a set of tuples  where  are the consecutive triple positions in  and is a bit vector of size that has in th position iff     and  Deìnition 3.7   A bitmap index for an RDF graph is a set of tuples  where  are the consecutive triple positions in  and is a bit vector of size that has in th position iff     and  A bitmap index is the transpose of  such that  
3 
3 


     1 
graph identiìer  triple pattern  table bit vector that has in th position i.e  if triple   and matches non-variable components of   and be the respective indices in the row with rowid of table be a bit vector that has 1 in every position  where is not a variable is not a variable is not a variable 
   002 
rowid data:graph index index index index index index function applySelectionIndices input output if then end if if then end if if then end if return end function 
Algorithm 1 
1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 
T I I I I I I G id G I I I I I I G id G I I I I I I G id G I I I I I I ss oo so os i i i ss s p o ss oo so os os so G.id tp sp pp op T v k v k t num  k t G t tp I I I G.id T v k k G tp.sp v v I tp.sp tp.pp v v I tp.pp tp.op v v I tp.op v 
1   1      1          
D s p o ss oo so s p o ss oo so s p o ss oo so n n s n p n o n ss n oo n so n D k k k s p o D s p o 
I I I I G G G i t G t num i G t s I i I I I I I I I I I 
Figure 2 HBase Storage Scheme Indices 2 3 4 Let 5 Let 6 7 8 9 10 11 12 13 14 15 16 
         002 003 003  004 004 004 
   and are all of the same size of bits for a given graph  They can be used to quickly match triples from two sets based on the equality of their subjects objects subjects-objects and objects-subjects respectively Intuitively if given a position that corresponds to a triple such that  other triples their positions in with the same subject as can be found in the bit vector  It should be noted that indices that allow matching triples based on predicates subjectspredicates and objects-predicates equalities can also be deìned however their usability is limited since graph patterns with variables shared by predicate patterns and other patterns are rarely used We denote indices  and as selection indices and indices    and as join indices  Note that index can be obtained from index and vice versa Although we introduce both types of indices for theoretical completeness only one is required in practice C Storage Scheme HBase stores data in tables that can be described as sparse multidimensional sorted maps and are structurally different from relations found in conventional relational databases An HBase table hereafter table for short stores data rows that are sorted based on the row keys Each row has a unique row key and an arbitrary number of columns such that columns in two distinct rows do not have to be the same A full column name hereafter column for short consists of a column family and a column qualiìer e.g family:qualiìer  where column families are usually speciìed at the time of table creation and their number does not change and column qualiìers are dynamically added or deleted as needed Rows in a table can be distributed over different machines in an HBase cluster and efìciently retrieved based on a given row key and if available columns To store provenance datasets composed of provenance graphs serialized as RDF graphs we propose a single table storage scheme shown in Fig 2 Each row in the table stores 1 an RDF graph identiìer as a unique row id/key 2 a complete RDF graph as one aggregate value in the data column family and 3 precomputed bitmap indices for the respective RDF graph in the index column family The decision to store each RDF graph as one value rather than partition it into subgraphs or even individual triples is motivated by the following observations First such storage avoids unnecessary data transfers that may occur if a graph is partitioned and distributed over different machines Second Applying selection indices 1 as we show in detail in the next section expensive query processing operations i.e joins can be performed using compact bitmap indices and an RDF graph is only required to be accessed once to replace triple positions in query results with actual triples Finally unlike some applications that require dealing with very large graphs that cannot t into main memory of a single machine and therefore require partitioning individual provenance graphs are relatively small in general yet their number can be very large and can be stored as one aggregate value We present query processing over this storage scheme next IV RDF Q UERY P ROCESSING IN HB ASE To be able to evaluate SPARQL queries in HBase we design four efìcient functions that deal with application of selection indices application of join indices handling of special cases not supported by the indices and basic graph pattern evaluation Function applySelectionIndices is outlined in Algorithm 1 It takes a graph identiìer and a triple pattern and returns a bit vector of triple positions in the graph where value signiìes that a position-corresponding triple matches URIs and/or literals found in the triple pattern Selection indices for a particular graph identiìer are applied using the conjunction of bit vectors A resulting bit vector encodes the result of one triple matching over a graph Function applyJoinIndices is outlined in Algorithm 2 This function given a graph identiìer a triple pattern with one known solution represented by a triple position and a 
4 
4 


p D k k k p ss oo so D ss oo so T so n D n sel D sel i n sel i D join j j i i j join sel j i j join join j i D j tp i join tp i join join tp i join 
G.id tp tp p t num p tp T v k v k t num k t G t t I I I G.id T v k k G v p p tp.sp tp sp tp.sp tp sp v v I p tp.op tp op tp.op tp op v v I p tp.sp tp op tp.sp tp op v v I p tp.op tp sp tp.op tp sp v v I p v bgp S F S F S tp bgp s F s F F s t s tp tp bgp tp.pp tp bgp tp tp s F s F F s t s t s tp tp F G.id bgp tp tp tp n T S g g G g bgp bgp bgp tp tp   tp v G.id tp T S k v k S S tp tp   tp v G.id tp T S TP tp tp tp tp   tp j<i tp tp s S v v tp tp tp   tp tp TP v v G.id tp tp s j T s j tp s j S k v k s S S S s S S S S S S s S s num k k s s s S S bgp S S n 
002   002 002 002 002 002 002 002 002 002 002 002 002   002  002 
002 003 003  004 004 004 004 005 002 002   002 002 002 006 002   002 002   007         002  004      010     002  
applyJoinIndices handleSpecialCases matchBGP applySelectionIndices applySelectionIndices applyJoinIndices handleSpecialCases 
1 1 1 2 1 2 1 2 1 2 1 1 2 1 1 
function input output if then end if if then end if if then end if if then end if return end function Algorithm 3 function input output if then for each do end for end if if then for each do end for end if return end function function input output if then return end if for each do for each do for each do if then end if end for end for if then return end if end for for each do end for return end function 
Applying join indices 1 Handling special cases 1 to-be-joined triple pattern can quickly compute a bit vector that encodes solutions triple positions that join with the known solution A join condition is implicitly coded by the use of the same variable in the two triple patterns It can be represented by the equality of subjects objects and/or subjects-objects in the two triple patterns Join indices are also applied using the conjunction of the respective bit vectors Function is outlined in Algorithm 3 This function performs post-processing of nal results obtained via basic graph pattern matching It takes a basic graph pattern and its set of solutions where each solution is represented by a sequence of actual triples and Matching a basic graph pattern over a graph 1 deals with special cases not supported by selection and join indices In particular selection indices have no means to verify that if a triple pattern contains the same variable twice or even three times then a matching triple must have identical values that can be bound to multiple occurrences of this variable Join indices do not support join conditions based on the equality of a predicate and any other term in a triple It is possible to add additional indices to handle selection and join operations on predicates however such indices will be rarely needed for real-life queries Finally main function is outlined in Algorithm 4 This function matches a SPARQL basic graph pattern that consists of a set of triple patterns    over an RDF graph with a known identiìer that is stored in HBase The nal result is a set of subgraph solutions  The algorithm starts by ordering triple patterns in lines 4 and 5 using two criteria 1 triple patterns that yield a smaller result should be evaluated rst to decrease the number of iterations and 2 triple patterns that have 
handleSpecialCases matchBGP 
Algorithm 2 Algorithm 4 
bgp tp tp tp S bgp 
graph identiìer  triple pattern with known solution  to-be-joined triple pattern  triple position  i.e triple matches  table bit vector that has in th position i.e  if triple   and can join with based on the equality of their subjects objects and/or subjects-objects 4 Let   and be the respective indices in the row with rowid of table be a bit vector that has 1 in every position  where  to avoid joining triple at position with itself  7 and are variables and and are variables and and are variables and and are variables and basic graph pattern  set of solutions set of solutions Any contains any two variables with the same name  i.e  if triple that corresponds to has different bindings for such variables 9 Any has a variable at that also occurs in some other   i.e  if triples and that correspond to and have different bindings for such variables 15 graph identiìer  basic graph pattern and  table set of subgraph solutions is a sub of and matches  such that triple patterns that yield a smaller result and triple patterns that have a shared variable with preceding triple patterns are evaluated rst 5 Let ordered    7 solutions for the rst triple pattern 8 in    11 Let set solutions for current join 12 Let set   and and have variables with the same name as subject or object patterns in  in in     is a solution triple position for found in sequence at position  18 solutions for current triple pattern 21 Compute Cartesian product of and  i.e with actual triples  27 in with in    32 
2 3 5 Let 6 Let 8 9 10 11 12 13 14 15 16 17 18 19 20 2 3 4 Let 5  Special case not supported by selection indices rare in practice  6 7 8 Discard 10 11  Special case not supported by join indices rare in practice  12 13 14 Discard 16 17 18 2 3 4 Order triple patterns in 6 9 10 13 14 15 16 17 19 20 22 23 24 25 26  Replace triple positions in 28 29 Replace 30 31  Handle special cases that are not supported by the selection and join indices  33 
   1      1                        1                                   1 2 
5 
5 


handleSpecialCases 
400 1 11 
 
Hardware Hadoop and HBase Our implementation 
num S D 
a shared variable with preceding triple patterns should be given preference over triple patterns with no shared variables to avoid unnecessary Cartesian products Next lines 6-8 the algorithm applies selection indices and obtains a set of solutions for the rst triple pattern Each solution in the set is represented by a sequence with one triple position An empty set of solutions results in an empty result for the whole basic graph pattern All subsequent triple patterns are further evaluated and joined with already available results lines 9-25 For any subsequent triple pattern selection indices are applied line 10 an empty set of join solutions is prepared line 11 and preceding triple patterns that share variables with the current triple pattern are identiìed line 12 For each solution that has been obtained for the preceding triple patterns lines 13-22 join indices are applied line 14-19 a bit vector resulting from both selection and join index applications is converted to a set of solutions for the current triple pattern line 20 and the join result is computed by combining the known solution with newly computed ones line 21 The set of known solutions is updated line 23 and veriìed that it is not empty line 24 The process repeats for the next available triple pattern Once all joins are processed each triple position in the set of solutions is replaced with an actual triple from the graph using the function lines 26-30 The solutions are then post-processed by function to accommodate cases that are not supported by selection and join indices line 31 Finally the resulting set is returned line 32 Some of the advantages of these algorithms include 1 expensive selection and join computations are performed over indices rather than a graph 2 computation heavily relies on numeric values that represent triple positions rather than actual triples with lengthy literals and URIs 3 computation can be fully completed on the same machine where data resides eliminating all intermediate data transfers over a network V P ERFORMANCE S TUDY This section reports our empirical evaluation of the proposed approach and algorithms  Our experiments used nine commodity machines with identical hardware Each machine had a latemodel 3.0 GHz 64-bit Pentium 4 processor 2 GB DDR2533 RAM 80 GB 7200 rpm Serial ATA hard drive The machines were networked together via their add-on gigabit Ethernet adapters connected to a Dell PowerConnect 2724 gigabit Ethernet switch and were all running 64-bit Debian Linux 6.0 and Oracle JDK 7  Hadoop 1.0.0 and HBase 0.94 were used Minor changes to the default conìguration for stability included setting each block of data to replicate two times and increasing the HBase max heap size to 1.2 GB Out of nine identical machines in the cluster one was designated as an HBase master and the other eight were HBase region servers slaves  Our algorithms were implemented in Java and the experiments were conducted using Bash shell scripts to execute the Java class les and store the results in an automated and repeatable manner The experiments used the University of Texas Provenance Benchmark UTPB UTPB includes pro v enance templates deìned according to the three vocabularies of the Open Provenance Model OPM 1  provenance generation software capable of generating provenance for any number of workîow runs based on a provenance template and provenance test queries in several categories We used UTPB to generate datasets of varying sizes using the Database Experiment template for a successful workîow execution that was serialized based on the Open Provenance Model OWL Ontology OPMO Each generated RDF graph in these datasets represented the provenance of a single workîow execution and contained roughly RDF triples Table I indicates the characteristics of each generated UTPB dataset The table does not take into account the dictionary le also an RDF graph that was generated by UTPB for each dataset and contained all graph identiìers The number of triples in this graph was the same as the number of RDF graphs in the dataset from Table I e.g 100,000 triples for  We used UTPB test queries in the rst four categories     and  to benchmark the performance of our implementation The exact queries expressed in SPARQL can be found on the UTPB website 2  When a provenance dataset was stored in our HBase cluster according to the proposed schema HBase automatically partitioned the table into regions subsets of rows Available region servers were assigned to handle certain regions In other words the provenance dataset was partitioned into subsets of provenance graphs that were stored on individual machines in the cluster Every provenance graph along with its indices was stored as a whole on one of the machines with no partitioning Therefore any query over an individual provenance graph was processed by a machine that stored the graph avoiding any expensive data transfers of intermediate results among region servers The nal result of a query was transferred to a client application running on the HBase master 1 Open Provenance Model http://openprovenance.org 2 University of Texas Provenance Benchmark http://faculty.utpa.edu chebotkoa/utpb 
1 
A Experimental Setup B Datasets and Queries Graphs Dependencies Artifacts Processes 
6 
6 


1 2 1 2 1 1 5 2 11 1 1 2 3 7 4 4 8 9 8 9 18 9 10 11 10 11 11 1 1 
D D D D D 
0 1,000 2,000 3,000 4,000 D1 D2 D3 D4 D5 0 20 40 60 80 D1 D2 D3 D4 D5 0 10 20 30 D1 D2 D3 D4 D5 0 5 10 15 D1 D2 D3 D4 D5 0 10 20 30 D1 D2 D3 D4 D5 0 10 20 30 D1 D2 D3 D4 D5 0 5 10 15 20 D1 D2 D3 D4 D5 0 10 20 30 40 50 D1 D2 D3 D4 D5 0 20 40 60 80 D1 D2 D3 D4 D5 0 10 20 30 D1 D2 D3 D4 D5 0 20 40 60 D1 D2 D3 D4 D5 
Q Q Q Q Q D D Q Q Q Q  Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q 
   1 2 3 4 5 
Table I D ATASET C HARACTERISTICS  Figure 3 Query Performance and Scalability 
C Query Evaluation Performance and Scalability Graphs Dependencies Artifacts optional optional ler union Processes optional union 
100,000 40,000,000 2.1 GB 200,000 80,000,000 4.2 GB 300,000 120,000,000 6.3 GB 400,000 160,000,000 8.4 GB 500,000 200,000,000 10.5 GB 
Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Legend 
 
Query performance and scalability of our approach are reported in Fig 3 Queries and were in the category and had basic graph patterns with one triple pattern Both and yielded larger results compared to other queries returned all graph identiìers in a dataset e.g 100,000 triples for and 500,000 triples for  and returned all triples in a particular provenance graph e.g returned around 400 triples for each dataset Even though these queries were the simplest queries among the UTPB test queries they showed to be more expensive due to larger result sets which is especially evident for query  the only query whose performance was on the order of seconds In the case of both and  which involved no joins the major factor in query performance is the transfer time of nal query results to a client machine and it is hardly possible to achieve better performance on the given hardware By contrast all other queries performed on the order of tens of milliseconds required joins and returned subsets of triples in a particular provenance graph  400 triples Queries were in the category and dealt with various dependencies among artifacts and processes in provenance graphs They all had similar complexities basic graph patterns with three triple patterns each They also returned comparable result sets in terms of the number of triples except query that returned an empty result set for the selected UTPB provenance graph template As a result these queries showed very similar query evaluation performance with being the fastest as it only required the evaluation of its rst triple pattern to compute the nal empty result Queries and were in the category and dealt with data artifacts in provenance graphs contained six triple patterns and two clauses had triple patterns two clauses two and one constructs is the most complex query of all yet it was shown to be efìcient and scalable with our approach The last two queries and  were in the category and dealt with processes in provenance graphs had two triple patterns and one clause While is a complex query with triple patterns and one clause it yielded an empty query result in our experiments due to the selected provenance template In summary the proposed approach and its implementation proved to be efìcient and scalable showed linear scalability and took the most time to execute due to a relatively large result set The other queries showed nearly constant scalability technically linear with a small scope This can be explained by the fact that each query except  dealt with a single provenance graph of xed size with minimal data transfers and fast index-based join processing VI C ONCLUSIONS AND F UTURE W ORK In this paper we studied the problem of storing and querying large collections of scientiìc workîow provenance graphs serialized as RDF graphs in Apache HBase We designed novel storage and indexing schemes for RDF data in HBase that are suitable for provenance datasets Our storage scheme takes advantage of the fact that individual provenance graphs generally t into memory of 
X-axis: Dataset Y -axis: Query execution time, ms 
Dataset of RDF graphs of RDF triples Size  of workîow runs 
7 
7 


a single machine and require no partitioning Our bitmap indices are stored together with graphs and support both selection and join operations for efìcient query processing We also proposed efìcient querying algorithms to evaluate SPARQL queries in HBase Our algorithms rely on indices to compute expensive join operations make use of numeric values that represent triple positions rather than actual triples with lengthy literals and URIs and eliminate the need for intermediate data transfers over a network Finally we conducted an empirical evaluation of our approach using provenance graphs and test queries of the University of Texas Provenance Benchmark Our experiments conìrmed that our proposed storage indexing and querying techniques are efìcient and scalable for large provenance datasets In the future we plan to compare our approach with other SQL and NoSQL solutions in the context of distributed scientiìc workîow provenance management as well as experiment with a multi-user workload to measure query throughput of our system R EFERENCES  Y  Simmhan B Plale and D Gannon  A surv e y of data provenance in e-science 
 vol 34 no 3 pp 31Ö36 2005  S B Da vidson S C Boulakia A Eyal B Lud  ascher T M McPhillips S Bowers M K Anand and J Freire Provenance in scientiìc workîow systems  vol 30 no 4 pp 44Ö50 2007  S B Da vidson and J Freire Pro v enance and scientiìc w orkîows challenges and opportunities in  2008 pp 1345Ö1350  V  Cue v as-V icentt  n S C Dey S K  ohler S Riddle and B Lud  ascher Scientiìc workîows and provenance Introduction and research opportunities  vol 12 no 3 pp 193Ö203 2012  L Moreau B Clif ford J Freire J Futrelle Y  Gil P  T  Groth N Kwasnikowska S Miles P Missier J Myers B Plale Y Simmhan E G Stephan and J V den Bussche The Open Provenance Model core speciìcation v1.1  vol 27 no 6 pp 743Ö756 2011  A Chebotk o S Lu X Fei and F  F otouhi RDFPro v A relational RDF store for querying and managing scientiìc workîow provenance  vol 69 no 8 pp 836Ö865 2010  J Zhao C A Goble R Ste v ens and D T uri Mining Tavernaês semantic web of provenance  vol 20 no 5 pp 463Ö472 2008   http://twiki.ipaw.info/bin/view Challenge/ThirdProvenanceChallenge  C Lin S Lu X Fei A Chebotk o D P ai Z Lai F  F otouhi and J Hua A reference architecture for scientiìc workîow management systems and the VIEW SOA solution  vol 2 no 1 pp 79 92 2009  T  M Oinn et al T a v erna lessons in creating a w orkîo w environment for the life sciences  vol 18 no 10 pp 1067Ö1100 2006  B Lud  ascher I Altintas C Berkley D Higgins E Jaeger M B Jones E A Lee J Tao and Y Zhao Scientiìc workîow management and the Kepler system  vol 18 no 10 pp 1039Ö1065 2006  S P  Callahan J Freire E Santos C E Scheide gger  C T  Silva and H T Vo Managing the evolution of dataîows with VisTrails in  2006 p 71  J Kim E Deelman Y  Gil G Mehta and V  Ratnakar  Provenance trails in the Wings/Pegasus system  vol 20 no 5 pp 587Ö597 2008  Y  Zhao et al Swift F ast reliable loosely coupled parallel computation in  2007 pp 199Ö206   http://hbase.apache.org  F  Chang J Dean S Ghema w at W  C Hsieh D A Wallach M Burrows T Chandra A Fikes and R E Gruber Bigtable A distributed storage system for structured data  vol 26 no 2 2008  A Chebotk o E D Ho yos C Gomez A Kashle v  X Lian and C Reilly UTPB A benchmark for scientiìc workîow provenance storage and querying systems in  2012 pp 17Ö24  M F  Husain L Khan M Kantarcioglu and B M Thuraisingham Data intensive query processing for large RDF graphs using cloud computing tools in  2010 pp 1Ö10  J Myung J Y eon and S Lee SP ARQL basic graph pattern processing with iterative MapReduce in  2010 pp 6:1Ö6:6  P  Ra vindra V  V  Deshpande and K An yanwu T o w ards scalable RDF graph analytics on MapReduce in  2010 pp 5:1Ö5:6  J Urbani S K otoulas E Oren and F  v an Harmelen Scalable distributed reasoning using MapReduce in  2009 pp 634Ö649  A Sch  atzle M Przyjaciel-Zablocki and G Lausen PigSPARQL mapping SPARQL to Pig Latin in  2011 p 4  J Huang D J Abadi and K Ren Scalable SP ARQL querying of large RDF graphs  vol 4 no 11 pp 1123Ö1134 2011  C Frank e S Morin A Chebotk o J Abraham and P  Brazier  Distributed semantic web data management in HBase and MySQL Cluster in  2011 pp 105Ö112  M Atre V  Chaoji M J Zaki and J A Hendler  Matrix Bit loaded a scalable lightweight join query processor for RDF data in  2010 pp 41Ö50 
SIGMOD Record IEEE Data Engineering Bulletin Proc of SIGMOD Conference Datenbank-Spektrum Future Gen Comp Syst Data Knowl Eng Concurr Comput  Pract Exper Third Provenance Challenge IEEE Transactions on Services Computing Concurr Comput  Pract Exper Concurr Comput  Pract Exper Proc of ICDE Workshops Concurr Comput  Pract Exper Proc of SWF Apache HBase ACM Transactions on Computer Systems Proc of SWF Proc of CLOUD Proc of MDAC Proc of MDAC Proc of ISWC Proc of SWIM PVLDB Proc of CLOUD Proc of the WWW 
8 
8 


Jorda Polo, David Carrera, Yolanda Becerra, Malgorzata Steinder  and Ian Whalley. Performance-driven task co-scheduling for  mapreduce environments. In Network Operations and Management  Symposium \(NOMS\2010 IEEE, pages 373 Ö380, 19-23 2010 12 K. Kc and K. Anyanwu, çScheduling hadoop jobs to meet deadlines  in 2nd IEEE International Conference on Cloud Computing  Technology and Science \(CloudCom\, 2010, pp. 388 Ö392 13 Xicheng Dong, Ying Wang, Huaming Liao çScheduling Mixed Real time and Non-real-time Applications in MapReduce Environment  In the proceeding of 17th International Conference on Parallel and  Distributed Systems. 2011, pp. 9 Ö 16 14 Xuan Lin, Ying Lu, J. Deogun, and S. Goddard. Real-time divisible  load scheduling for cluster computing. In Real Time and Embedded  Technology and Applications Symposium, 2007. RTAS ê07. 13th  IEEE pages 303 Ö314, 3-6 2007 15 HDFS  http://hadoop.apache.org/common/docs/current/hdfsdesign.html  16 Chen He, Ying Lu, David Swanson. çMatchmaking : A New  MapReduce Scheduling Techniqueé. In the proceeding of 2011  CloudCom, Athens, Greece, 2011, pp. 40 Ö 47 17 Matei Zaharia, Dhruba Borthakur, Joydeep Sen Sarma and Khaled  Elmeleegy, Scott Shenker, and Ion Stoica, çDelay scheduling: a  simple technique for achieving locality and fairness in cluster  schedulingé. In the proceedings of the 5th European conference on  Computer systems, 2010.  pp 265-278 18 Zhuo Tang, Junqing Zhou, Kenli Li, and Ruixuan Li "A MapReduce  task scheduling algorithm for deadline constraints.", Cluster  Computing, Vol. 15,  2012 19 Eunji Hwang, and Kyong Hoon Kim. "Minimizing Cost of Virtual  Machines for Deadline-Constrained MapReduce Applications in the  Cloud." Grid Computing \(GRID\, 2012 ACM/IEEE 13th  International Conference on. IEEE, 2012 20 Micheal Mattess, Rodrigo N. Calheiros, and Rajkumar Buyya  Scaling MapReduce Applications across Hybrid Clouds to Meet Soft  Deadlines." Technical Report CLOUDS-TR-2012-5, Cloud  Computing and Distributed Systems Laboratory, the University of  Melbourne, August 15, 2012 21 
 
11 
                
Chen He, Ying Lu, David Swanson. çReal-Time Application Scheduling in Heterogeneous MapReduce Environments Technical Report TR-UNL-CSE2012-0004, University  of Nebraska-Lincoln, 2012 Available: http://cse apps.unl.edu/facdb/publications/TR-UNL-CSE20120004.pdf 22 T. Condie, N. Conway, P. Alvaro, J. M. Hellerstein, K  Elmleegy, and R. Sears. çMapreduce Onlineé. In NSDI 2010 23 A. D. Ferguson, P. BodÌk, S. Kandula, E. Boutin, and R  Fonseca. çJockey: Guaranteed Job Latency in Data Parallel Clusters. In EuroSys, 2012 24 G. Wang, A. R. Butt, P. Pandey, and K. Gupta. çA Simulation Approach to Evaluating Design Decisions in MapReduce Setupsé. In MASCOTS 2009 25 H. Herodotou and S. Babu. Profiling, çWhat-if Analysis and Cost-based Optimization of MapReduce Programs In VLDB 2011 26 H. Herodotou, F. Dong, and S. Babu. çNo One \(Cluster Size Fits All: Automatic Cluster Sizing for Dataintensive Analyticsé. In SoCC 2011  
1544 
1544 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



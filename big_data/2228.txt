A Novel Anti-Data Mining Technique Ba sed On Hierarchical Anti-Clustering HAC   Tung-Shou Chen, Jeanne Chen, Yuan-Hung Kao*, and Tsang-Chou Hsieh Graduate School of Computer Science and Info rmation Technology, Nati onal Taichung Institute of Technology, Taichun g, 404 Taiwan tschen, jeanne, s17963007 s33939036}@ntit.edu.tw   Abstract Data Mining is a technique to search potential valuable information from databases. Preventing personal data and high security data therefore pose a difficult task to IT experts. In this paper, we propose a novel anti-data mining \(ADM\ database security scheme, that protect against data mining. The scheme makes use of hierarchical clustering where noise is added to change the cluster structure of data. The proposed hierarchical anti-clustering \(HAC\ scheme modifies the cluster structure of the original data Experimented results show that data may be protected against during the HAC key can be used reverse the cluster structure to its original.  At the meantime, HAC also designs the key value to restore correctly the protected database Keywords Data Mining, Anti-Data Mining Hierarchical Clustering, Anti-Clustering, Noise data  1. Introduction  Data Mining is a technique using information technology and statistics method to search potential valuable information from a large database which can be used to support administrative decisions [21  Examples of which include the data mining of on-line database, ERP database or Data Warehouse using techniques like association rules, clustering classification, sequential pattern analysis and prediction [21,22    In addition enterprise uses data mining to know companies, working status and to analyze potential information values. Information mined must be protected from disclosure of company secrets In this internet era, database of companies are web based to provide employees and clients a convenient want to accept information. However, this kind of services results in security problems. Techniques have been developed to protect data such as symmetric key algorithm and asymmetric key algorithm to protect the access and deliver of data [18 and a nony m o us user  identi However, these m e thods can not efficiently protect data from being mined Clifton [7,8  p r o p o s ed th e thr eatenin g and clash  o f  data mining to protect database. He considered that mining of database will exposed sensitive data or rules Some mining techniques were aimed at processing with association rules [1,9,12 t r ans act io ns  decompositions [1 v i c t i m  i t e m s  17 o r  ot he r methods to prevent mining sensitive data. Basically sensitive data could be mined and important knowledge pertaining to a companyês competition ness could be exposed In this paper, we proposed a novel Anti-Data Mining \(ADM\atabase security concept by adding interference data to harass knowledge content of database. Illegal users can not use data mining technique to analyze the knowledge value in database This scheme is used to negate data mining, but will not destroy the original data. The protected database can be retrieve to its original by reversing the harass rule  2. A Novel Anti-Data Mining Technique of Protected Database  The clustering technique used in Data Mining Group data according to feature attribution of data where each object within group has high intra-group similarity, and low inter-group similarity [5,6 th e process of clustering analysis, there is neither advance designate class information, nor any information showing records relationship. Therefore, clustering is regarded as unsurpervised learning The anti-data mining \(ADM\method proposed in this paper is a novel method to protect content of data based on clustering of data mining that complements 
Eighth International Conference on Intelligent Systems Design and Applications 978-0-7695-3382-7/08 $25.00 © 2008 IEEE DOI 10.1109/ISDA.2008.155 426 


we proposed, Hierarchical Clustering \(HC  Hierarchical Anti-Clustering \(HAC\ich protects the analyses result of clustering of database. Our research produces noises by random seed and adds certain amount of noise data into database to HAC in order to disturb the clustering result and to destroy the original clusters. Therefore similar data become dissimilar ones and belongs to the wrong clusters  2.1. Hierarchical Clustering \(HC  Clustering Algorithm is divided into two parts composing of Hierarchical Clustering \(HC\ and NonHierarchical Clusteri HC f o r m s a tree or hierarchical structure for the clustering process. In the tree structure, the height of nodes represents the similar degree between clusters, users can use this characteristic to observe the clustering results of data HC can also be further divided into two parts which are Agglomerative algorithm an Divisive algorithm 5,6,22  Ag g l o m erati v e Alg or i t h m reg ard s e v er y  data in dataset as a cluster, then into two clusters with feature and attribute that are most similar repeatedly until all data become one. Divisive algorithm regards the whole dataset as a cluster, then divides them into two smaller cluster by lowest similarity repeatedly until every data is independent. \(See Figure 1  Figure 1. Hierarchical Clustering Algorithm [22  Generally speaking, the evaluation method of data similarity mainly regard the distance of two data records distance calculation methods include Euclidian distance, Manhattan distance  and Chebychev distance 4 e dif feren t calculati n g  m e th o ds resu lt i n  different clustering results, and are dependent on data characters and spread conditions. HC provides four methods for similar evaluation [1 e fir st m e th od  is Centroid Linkage, which evaluates the distance of two clusters centroids. The second is Complete Linkage, which evaluates the distance of two farthest data points between two clusters. The third is Average Linkage, which evaluates the average of sum distance of any two data between two clusters. The fourth is Single Linkage, which evaluates the distance of two nearest data in different cluster In this paper, we will add noise to data columns to produce wrong clustering results with HC clustering The cluster tree structure is HC where the data of similar height original nodes, offer adding noise to data columns method will let the height distance of data nodes to become dissimilar. Wrong cluster structure will protect the clus tering knowledge of HC  2.2. Hierarchical Anti-Clustering \(HAC Algorithm  In this paper, we design HAC Algorithm to be a new protection method of database which change the cluster structure of HC, and be the main idea of ADM The essence of this method is to add the noise to data to change the analysis result of HC, then producing the wrong clustering information to mislead the person who get database illegally This method set up the dataset which needs protection to be D initially, the column numbers of dataset to be c data sum records to be n Then   3  2  1   n i d D i 002 002 after analyzing by HC that clustering result composed of a Tree, which represent by H  H include n 1 nodes, dividing up different nodes acquires different clusters i H   1  1   i ij i n j k i d H 003 003 003 003 002  ij d is the data included by i H  k is the number of clustering i n is each data of i H HAC is the method which adding the noise to column data to make original data D become D 004 then using HC to analyze D 004 to get the clustering result H 004  which added the noise to column data, and calculating simultaneously clustering result i H and i H 004  both include the same data numbers s which is the data numbers of i ij H d 005 and i ij H d 004 005 the lower the values of unchanged part of i H in i H 004 is the better Show as the formula \(1   min 1 i ij i k i ij H d and H d s 004 005 005 002 006 002 1 After acquiring s then divide by data sum records n  equals HR which is a rate of similarity of H 004 to H also is a rate of clustering result of HC changed by HAC, if the rate of HR is lower which means the structure of HC changed by HAC is higher, it also means the effect of HAC is better. Finally, use c Seed Random 007   to acquire the position of noise column data which adding 
427 


the dataset finally, and adding the noise column data into the original dataset to output the dataset PD which protected by HAC. The following of HAC Algorithm is Step 1 Set up the initial date D and make D be clustering analyzed by HC which result in H  Step 2 Set the range of noise data q and noise data increasing rate r and Seed value be the key value of HAC, and set two threshold values set noise rate r T and executing frequency t T  be the conditions of executing, and set t 1 Step 3 Use the formula \(2\ to produce the noise data i Z    1  n i 005 and let i Z join D acquiring D 004  q Seed Random Z i 007 002    2 Step 4 Make D 004 be clustering analyzed by HC which result in H 004  Step 5 Calculate the same data number S between i H  and i H 004 and n s HR 010 002  Step 6 If r T HR 011 and t T t 003 then drop D 004 and set r q q 007 002 and t  t 1 003 repeat Step 3  Step 6  Step 7 Run c Seed Random 007   then acquire the column position of noise column data, then output the dataset PD which protected by HAC Through the method above, it let users decide producing the range of noise data, noise data increasing rate and long for the effect of protection by depending data characters. Thus, the protected data content and possible clustering knowledge of HC can be adjusted flexibly, then increasing the trustworthy and protection effect of database protected by HAC In the other hand, about the setting of noise data range and adding column, the character of original data must be considered, in order to avoid the removing noise data columns because of guessing easily including the attribution, maximum, minimum, the number of decimal, the name of columns, the number of columns of original data column, etc, which should be considered, therefore, the adding noise column data are similar with original dataset, that is difficult to recognized. In the meantime, in order to increase the difficulty of recognizing, it can use more than one noise column data to increase the difficulty of breaking HAC and the effect of noise  2.3. Restoring the Protected Database by HAC  In section 2.2, we describe the database protection method of HAC, and we will describe how to restore the protected database PD in this section, let legal users can use and analyze data correctly When the noise data produced, then run it by c Seed Random 007   to acquire a position, then insert the position into noise column, therefore, when restoring data set, it should be produced correct noise data then calculating the position of noise column and remove it, the restore flow as following Step 1 Pick up the same key value as being protect the range of noise data q and noise data increasing rate r and Seed value Step 2 Using formula \(2\ to produce the same noise data i Z 004  Step 3 Run  1    012 004 007 c Seed Random to find out the position of noise column in dataset Step 4 Remove the noise column and output restored dataset D  Due to the function Random  Seed produce the same random values, when repeating execute, as long as set up the same Seed value that will produce the same random values. Therefore, this research set up the Seed value and the range of noise data and noise data increasing rate to be the key value of HAC method, then only the users who have correct key value can restore the protected database by HAC correctly, and analyze database by clustering technique and acquire the correct knowledge content of database  3. Experimental Results  In order to proceed the experiment exactly, this research use the famous Iris dataset in UCI Machine Learning Repository [23 web sit e to  b e t h e o r igin al dataset for experiment, proceeding the knowledge protection experiment of HAC, and illustrating the experiment result as following Iris is a dataset which has 150 four-column records they are divided into three clusters by data character  experim ent pr oceeding, set Iris dataset is D  then do HC to acquire correct clustering result     3 2 1 H H H H i 002 Example, Table 1. HC Analysis Result of Iris Dataset. The value in Table 1 is the data number of cluster. Simultaneously Picking the maximum and minimum of Iris dataset to be the range of noise information q noise data increasing rate r  1.1, noise rate  50 002 r T and execution time limit 10 002 t T   Table 1. HC Analysis Result of Iris Dataset  1 H  2 H  3 H  n 13 87 50 
428 


In the next, we proceed the protection flow of HAC adding noise column data by q Seed Random 007   to destroy the original cluster structure, and re-analyzing the protected dataset D 004 which added the noise column data by HC to produce the protected clustering result     3 2 1 H H H H i 004 004 004 002 004 and compare with the unprotected clusters H calculating the data numbers of i ij H d 005 and i ij H d 004 005 to acquire the effect of clustering knowledge of Iris dataset protected by HAC See Table 2  Table 2. The Clustering Result of Iris Protected by HAC   1 H 004  2 H 004  3 H 004  n 004  48 62 40 1 H 8 5 0 2 H 32 37 18 3 H 8 20 22  The experiment result is analyzed by three clusters characters of Iris dataset, In this paper, we divide the clustering result of Iris dataset into three clusters, then calculating the difference of unprotected data by HAC and protected ones of each cluster data n 004 in Table 2 is the cluster data number of HC which added noise column data by HAC Finally, acquiring s which is the data number of i ij H d 005 and i ij H d 004 005 and the effect of clusters structure changed by HAC. For example: Table 3 HAC Experimental Result of Iris Dataset i HR in Table 3 is the data rate which reserve the original data clusters i H in i H 004 Finally HR is the average of i HR  It also is the rate of HC result of Iris dataset changed by HAC. In this experiment, when t = 9, which meet the need that  50 002 r T then the cluster structure of i H 004 is exactly different from i H This proves that HAC is the solution to protect HC knowledge of Data Mining  Table 3. HAC Experimental Result of Iris Dataset  1 H  2 H  3 H  n 13 87 50 s 8 37 22 i HR  61.53% 42.52 44 HR 49.35  4. Conclusions  In this paper, we propose an anti-data mining ADM\cheme to protect data from mining Hierarchical anti-clustering \(HAC\ is used to modify the structure of clusters example, for protecting the knowledge of database clustering analysis, not only considering the security of system frame The ADM method is different from traditional mode of data encryption and decryption, it wonêt affect normal access of data, only base on data mining knowledge to protect principal part. The main function is adding noise data to disturb information structure of database, then users canêt use the clustering technique of data mining to analyze correct knowledge. In the meantime, this method also can disturb the clustering result of data mining and approaching effect of cheating enemy  5. References  1 R. Ag rawal, and R. Sr ikant F as t Algor ithms  f o r M i ning Association Rules In proceedings of the IEEE International Conference 1998, pp. 402-411  2  E Berti no S   Cas t ano, E. Ferr ari, and M  M e s iti Protection and Administration of XML Data Sources Data Knowledge Engineering Vol. 43, 2002, pp. 237-260  3 E. Ber tino, çData Security  Data & Knowledge Engineering  Vol. 25, 1998, pp. 199-216   N. Bolshakova F. Azuaje, and P  Cunningham An Integrated Tool for Microarray Data Clustering and Cluster Validity Assessment Bioinformatics Vol. 21, 2005, pp 451-455    C. L i n, Y H. Chiu, and R.C. Chen Combined Density-based and Constraint-based Algorithm for Clustering Journal of Donghua University Vol. 23 2006, pp. 36-38  6 T.S  C h en, T.H Ts ai, Y T. Chen, C  C   Lin, R.C Chen S.Y. Li and, H.Y. Chen, çA Combined K-Means and Hierarchical Clustering Method For Improving the Clustering Efficiency of Microarray In Proceedings of 2005 International Symposium on Intelligent Signal Processing and Communications Systems 2005, pp. 406-408   C. Clifton, and B. Thurais ingham, çEmergin g Sta n d a rds for Data Mining Computer Standards & Interfaces Vol. 23 2001, pp. 187-193   a rks   S ecurity  and Priva cy  Implications of Data Mining Proceedings of the ACM SIGMOD Workshop on Data Mining and Knowledge Discovery 1996, pp. 15-19 
429 


  F  Coenen, P  Le n g and S. Ahmed  D ata S t ructur e f o r Association Rule Mining: T-trees and P-trees IEEE Transactions on Knowledge and Data Engineering Vol. 16 2004, pp. 774-778    A. Dragut, and C.M Nichitiu  A  M onotonic On-Line Linear Algorithm for Hierarchical Agglomerative Classification Information Technology and Management  Vol. 5, 2004, pp. 111Ö141   G. Gautam, and B.B Chaudhuri A Novel Genetic Algorithm for Automatic Clustering Pattern Recognition Letters Vol. 25, 2004, pp. 173Ö187   L. Glimcher R Jin, and G. Agrawal M id dlewa r e for Data Mining Applications on Clusters and Grids Journal of Parallel and Distributed Computing  Vol. 68, 2008, pp. 3753   W  J i ang C Clifton, and M   Kantarc 002 o 003lu Transforming Semi-honest Protocols to Ensure Accountability Data & Knowledge Engineering Vol 65 2008, pp. 57-74   M  S. Hwang, and C.H. Lee S ecure Access  Schemes  in Mobile Database Systems European Transactions on Telecommunications Vol. 12, 2001, pp. 303-310   M.J L. de Hoon S  Imoto  J   Nolan and S M i y a no Open Source Clustering Software Bioinformatics 2004 pp. 1453\0041454   U M a ulik, and S  Bandy opadhy a y P e r formance  Evaluation of Some Clustering Algorithms and Validity Indices Pattern Analysis and Machine Intelligence IEEE Transactions, Vol. 24, 2002, pp. 1650-1654   e i ra, and O. ZaÔane P rivac y Pres erving Frequent Itemset Mining Proceedings of the IEEE International Conference on Privacy Security and Data Mining, 2002, pp. 43-54   S   Rapuano, and E  Zimeo M eas urement of Performance Impact of SSL on IP Data Transmissions Measurement Vol. 41, 2008, pp. 481-490   V PN T echnolog y  IP SE C VS S S L  Network Security Vol. 2007, 2007, pp. 13-17    J a v a Tr e e viewExtens ible Vis ualization of Microarray Data Bioinformatics 2004, pp. 3246-3248   M.H Dunham, Data Min g: Introductory and Advance d Topics, Prentice Hall, 2003   J  Han, a n d M  Kamber, Data M i ning: Concepts  and Techniques, Morgan Kaufmann, 2006   A Asuncion and D J Newman UC I Ma chine  Learning Repository http://www.ics.uci.edu/~mlearn/MLRepository.html, 2007   
430 


gsI I2s g2 1 1 g4 0.5 g5 1,0.5 g6 UsI s2 s3 1  GENE ExIlRESSION DATAS1ETS  Class I Class 0  Class I  Class 0 Dataset Genes label label samples samples ALL/AMNL ALL 7129 ALL AML 47 25 Lung Cancer LC 12533 MPM ADCA 31 150 Prostate Cancer PC 12600 tumor normal 77 59 0varian Cancer OC 15154 tumor normal 162 91 although Q doesn't express 96 Q does expresses g4 Thus in total we only consider half of the simple 95,sl rule to be satisfied i.e the S5 exclusion list is the weakest link Continuing to use BSTC's approximation scheme for the expected probability of Q's correct Cancer classification via the Figure 1 BST we obtain Figure 3 Note that only Figure 3 gene rows corresponding to genes expressed in Q are nrnempty If we now evaluate BST-EXPECT\(T\(Healthy Q we obtain a final8 value of  To finish BSTC will compare Q's Cancer classification value of 4 to Q's Healthy classification value of 0.5  0.75 1 1 0.5 CANCER classification value  0.75  1  0.5  0.75 Fig 3 BSTC cell rule Evaluation Example T\(1   T\(N Thus BSTC requires tirme and space O S 2 GQ to construct Furthermore during classification BSTC must calculate BSTCE\(T\(i Q for I  i  N BSTCE Algorithm 2 runs in O  S Ci  G Ci  time per query sample Therefore the BSTC worst case evaluation time is also f S 2  G per query sample See Sectiorn VII for more on BSTC's per-query classification time 2 Biological Meaning of BSTC Classificationrl Association rules mined from gene expression data provide an intuitive representation of biological knowledge e.g the expression of certain genes implies cancer Hence CAR-based classifiers have the desirable ability to justify each non-default consequent class query classification with the biologically meaningful CAR\(s the query satisfied BSTC being rulebased and related to CAR-classifiers also has this property BSTC can support it's query classifications with BARs of any user specified complexity Most simply for any given query sample Q and c E 0,1 BSTC can justify it's classification of Q as class Ci by reporting all T\(i atomic cell rules with satisfaction levels  c Note that returning this information requires no additional per-query classification time Also note that section III-B 1 methods can be used to mine more complex highly satisfied BARs if desired D BSTC Example Consider our running example from Table I In order to construct BSTC we must construct both T\(Healthy and T\(Cancer shown in Figure 1 Once both BSTs have been constructed we can begin to classify query samples Suppose for example we are given the query sample f gl expressed g2 not expressed g3 not expressed g4 expressed g5 expressed g6 not expressed To classify this query we must first calculate BSTCE\(T\(Cancer 9 and BSTCE\(T\(Healthy 9 The evaluation of BSTCE\(T\(Cancer Q proceeds as follows Since our query sample Q expresses gene g9 we can see that we must for example determine the fraction of both of the 95 s cell's exclusion lists satisfied by 9 The 95 si cell's S4  gl exclusion list is totally satisfied since 9 expresses ga Hence it gets a value of 1 However the 85s 94g 96 exclusion list is only half satisfied since TABLL 11 3 and conclude that Q is most probably Cancer Hence Q will be classified as Cancer V EXPERIMENTAL EVALUATION All experiments reported here were carried out on a 3.6 GHz Xeon machine with 3GB of memory running Red Hat Linux Enterprise 4 For our empirical evaluation we use four standard real microarray datasets 16 Table II lists the dataset names class labels and the number of samples of each class All discretization was done using the entropy-minimized partition 17 as in 1 Executables for both RCBT and Top-k were provided by the authors of 1 In all experiments the Top-k rule generator was used to generate rule groups for RCBT Unless otherwise noted we ran both Top-k and RCBT with the author suggested parameter values i.e support 0.7 k 10 nl 20 10 RCBT classifiers Hence while generating rules for RCBT we used Top-k with a minimum support value of 0.7 and found the 10 most confident covering rule groups i.e k  10 Furthermore during classification we used RCBT with the suggested 10 classifiers 1 primary and 9 standby Finally ni the number of lower bound rules to use for classification per Top-k mined rule group was set equal to 20 We coded BSTC in C A Preliminary Experiments Each of Table II's four gene expression datasets comes with a clinically determined training set The authors of 1 provided us with their discretizations of these four datasets We ran BSTC on their discretizations and BSTC matched RCBT's reported mean accuracy about 96 outperforming CBA 87 IRG 8lX1 Weka 3.2 C4.5 family single tree 74 bagging 78 boosting\(74 and SVMligh 5.0 93C in reported mean performance 1 To compare BSTC and RCBT with the most recent R el 071 package SVM implementation  18 and randomForest version 4.5 19 we rediscretized the four datasets and reran 1067 sI s2 s3 


7 5769 l00 97.67 l005 I00 Avg Accuracy ______ __95.59 95.98 89.5 8954 BSTC/RCBT To keep comparisons fair we ran SVM and randomForest on the same genes selected by our entropy discretization except with their original undiscretized gene expression values SVM was run with its default radial kernel We ran randomForest 10 times with its default 500 trees for ALL LC and OC and its accuracy was constant For PC we had to increase randomForest's number of trees to 1000 before its accuracy stabilized over the 10 runs Table III contains the number of class 0/1 samples in the clinically determined training set the number of genes selected by our entropy discretization and our experimental results As shown in this table the overall average accuracies of BSTC and RCBT are again best at about 96 each When compared against RCBT SVM and randomForest on the individual tests we can see that BSTC is alone in having 100 accuracy on the majority of datasets However BSTC's performance on the preliminary AML/ALL dataset test is relatively poor This is likely due to over fitting Every error BSTC made mistook a class 0 AML test sample for a class 1 ALL test sample i.e all errors were made in this same direction And the ALL training data has both i about 2.5 times as many class 1 samples as class 0 samples and ii a small number of total samples/genes When the training set is more balanced and the number of samples/genes is larger we can expect that cancellation of errors will tend to neutralize/balance any over fitting effects in BSTC And BSTC is a method meant primarily for large training sets where CAR-mining is prohibitively expensive As we will see below in Section V-B.1 BSTC s performance is much better for larger AML/ALL training set sizes B Holdout Validation Studies Holdout validation studies make comparisons less susceptible to the choice of a single training dataset and provide performance evaluations that are likely to better represent program behavior in practice We next present results from a thorough holdout validation study completed using 100 different training/test sets from each of the ALL LC PC and OC data sets For these holdout validation tests we benchmark BSTC against Top-k/RCBT because i BSTC/RCBT perform hest in our preliminary experiments ii Top-k/RCBT is the fastest/most accurate CAR-based classifier for microarray data and iii we are interested in BSTC's CAR-related vs Topk/RCBT s CAR based scalability For the holdout validation study we generated training sets of sizes 40 60 and 80 of the total samples Each training set was produced by randomly selecting samples from the original combined dataset We then used the standard R dprep package's entropy minimized partition 17 to discretize the selected training samples Finally the remaining dataset samples were used for testing the two classifiers after rule/BST generation on the randomly selected training data For each training set size we produced 25 independent tests In addition to these training sets we created an additional 25 1-x/0-y tests To create these tests we chose training data by randomly selecting x class 1 samples and y class 0 samples to be used as training data As before the remaining samples were then used to test both classifiers For each dataset the x and y values are chosen so that the resulting 25 classification tests have the exact same training/test data proportions as the single related dataset test reported in section V-A For each training set size we plot our results using a boxplot Boxplot Interpretation Each boxplot that we show in this section can be interpreted as follows The median of the measurements is shown as a diamond and a box with boundaries is drawn at the first and the third quartile The range between these two quartiles is called the inter-quartile range IQR Vertical lines a.k.a whiskers are drawn from the box to indicate the minimum and the maximum value unless outliers are present If outliers are presents the whiskers only extend to 1 5 x IRQ The outliers that are near i.e within 3 x IRQ are drawn as an empty circle and further outliers are drawn using an asterisk 1 ALIJAML ALL Experiment Figure 4 shows the classification accuracy for the ALL/AML dataset As can be seen in this figure BSTC and RCBT have similar accuracy across the ALL/AML tests as a whole BSTC outperforms RCBT in terms of median and mean accuracy on the 40 and 80 training set sizes while RCBT has better median/mean accuracy on the 1-27/0-11 training size tests And both classifiers have the same median on the 60 training set size Over the 100 ALL/AML tests we see that BSTC has a mean accuracy of 92.13 while RCBT has a mean accuracy of 91.39 they are very close It's noteworthy that BSTC is 100 accurate on the majority of 80 training size tests However BSTC appears to have slightly higher variance than RCBT on all but the 40 training tests Considering all the results together both BSTC and RCBT have essentially equivalent classification accuracies on the ALL/AML dataset 2 Lung Cancer LC Experiment The results for the Lung Cancer dataset are reported in Figure 5 Here again both BSTC and RCBT have similar classification behavior RCBT has higher mean and median accuracies on the 40 and 60 tests while BSTC outperforms RCBT on the 1-16/0-16 tests Meanwhile both classifier have the same median on the 80 training test Over all 100 LC tests we find that BSTC has a mean accuracy of 96 32 while RCBT has a mean accuracy of 97.08 again they are very close As before BSTC is alone in having 100 accuracy more 1068 TABLE III USINC GIVEN RES Ul TS TRAINING DATA  Class I  Class 0 Genes random Training Training After BSTC RCBT SVM Forest Dataset Samnples Samnples Discr Ac or Accr Ac o Accuracy ALL 27 11 866 82.35 91 18 91 18 85.29 LC 16 16 2173 100 97.99 93.29 99.33 PC 52 50 1554 100 97.06 73.53 73.53 OC 133 


TABLE IV AVERACGE RUN TIMLES FOR THE PC TESTS IN SEC-NI t INDICATES nl WAS LOWERED TO 2 Training Median  Mean 260 Near outliers  25/25t T O Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 80 Training 1 27/0-11 Training 1.0 1.0 1 0]0.95 0.9 0.9 0.7 0.7 0.850.8 0.80.80.80.750.7 0.70.70.7 650.6 0.60.60.6Holdout Validation Results 25/25t cJ CZ C O Far outliers 40 Training 60 Training 80 Training 1-16/0-16 Training h0 1.0 T 1.0 1.00.95 0.9 0.9 0 0.8 0.8 0.80.80.8LC Holdout Validation Results THE PC TESTS THAT RCBT FINISHED Training BSTC RCBT 40U 75.08 79.27 60 78.18 85.45 80 84.98 1-52/0 50 81.65%o 1069 cJ CZ C 5.06 120.63 21.32 RCBT  7110  7200  7200  RCBT DNF 0 P 00 24/25 t per training set test Finally the  RCBT DNF column gives the number of tests RCBT was unable to finish in  the cutoff time over the number of tests for which Top-K finished mining rule group upper bounds Explanation for varying nd values Run time cutoffs were necessary to mitigate excessive holdout validation CARmining times Even with a cutoff of 2 hours these 100 PC experiments required about 11 days of computation time with most experiments not finishing For the 80 and 1-52/0-50 training set sizes RCBT with nl  20 failed to finish lower bound rule mining for all 50 tests within 2 hours Thus RCBT's nl parameter was lowered from the default value of 20 to 2 in an attempt to improve its chances of completing tests Not surprisingly decreasing nl i.e mining fewer lower bound rules per Top-k rule group decreases RCBT s runtime However RCBT was still unable to finish lower bound rule mining for any tests Classification Accuracy Figure 6 contains accuracy results for BSTC on all four Prostate Cancer test sets Prostate Cancer boxplots for RCBT weren't constructed for training set sizes that RCBT was unable to complete all 25 tests within the time cutoffs In contrast BSTC was able to complete each of the 100 PC classification tests in less than 6 seconds Table V contains mean accuracies for the PC dataset with 40 60 80 and 1-52/0-50 training For each training set the average accuracies were taken over the tests RCBT was able to complete within the cutoff time Hence the 40 row means were taken over all 25 results Since RCBT was unable to complete any 80 or 1-52/0-50 training size tests we report these BSTC means over all 25 tests RCBT has slightly better accuracy then BSTC on 40 training For 60 training TABLE V MEAN AcCURACIES FOR 40 60 80 1.52/0.50 BSTC 3 4.93 5.78 5.57 Top0.09 BSTC F a RCBT BSTC RCBT BSTC RCBT b c Fig 5 BSTC RCBT BSTC RCBT b c ALL BSTC RCBT a Fig 4 BSTC RCBT d then half the time for any training set size see Figure 5 d However RCBT has smaller variance for 3 of the 4 training set sizes Therefore as for the ALL/AML data set both BSTC and RCBT have about the same classification accuracy on LC 3 Prostate Cancer PC Experiment RCBT begins to run ilnto a comiputational difficulties on PC's larger training set sizes This is because before using a Top-k rule group for classification RCBT must first mine nt lower bound rules for the rule group RCBT accomplishes rule group lower bound mining via a pruned breadth-first search on the subset space of the rule group's upper bound antecedent genes This breadthfirst search can be quite time consuming In the case of the Prostate Cancer PC dataset all 100 classification tests 25 tests for each of the 4 training set sizes generated at least one top10 rule group upper bound with more than 400 antecedent genes Due to the difficulties involved with a breadth-first search over the subset space of a several hundred element set RCBT began suffering from long run times on many PC classification tests Table IV contains four average classification test run times in seconds for each PC training size The BSTC column run times reflect the average time required to build both class 0 and class I BSTs and then use them to classify all the test samples Each Top-k column run time is the average time required for Top-k to mine the top 10 covering rule groups with minimum support 0.7 for each training set Table IV's RCBT column gives average run times for RCBT using a time cutoff value of 2 hours for all the training sets For each classification test if RCBT was unable to complete the test in less than the cutoff time it was terminated and it s run time was reported as the cutoff time Hence the BSTC RCBT d RCBT column gives lower bounds on RCBT s average run time 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



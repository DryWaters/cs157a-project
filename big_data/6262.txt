GPApriori: GPU-Accelerated Frequent Itemset Mining Fan Zhang Department of Computer Science University of South Carolina Columbia, SC, U.S zhangf@email.sc.edu Yan Zhang Department of Computer Science University of South Carolina Columbia, SC, U.S zhangy@email.sc.edu Jason Bakos Department of Computer Science University of South Carolina Columbia, SC, U.S jbakos@cse.sc.edu Abstract  In this paper we describe GPApriori, a GPUaccelerated implementation of Frequent Itemset Mining 
FIM\  We tested our implementation with an Nvidia Tesla T10 graphic processor and demonstrate up to 100X speedup as compared with several state-of-the-art FIM algorithms on a CPU.  In order to map the Apriori algorithm onto the SIMD execution model, we have designed a çstatic bitseté memory structure to represent the input database.  This data structure improves upon the traditional approach of the vertical data layout in state-of-the art Apriori implementations.  In our implementation, we perform a parallelized version of the support counting step on the GPU.  Experimental results show that GPApriori consistently outperforms CPU-based Apriori 
implementations.  Our results demonstrate the potential for GPGPUs in speeding up data mining algorithms Keywords: Association rule mining, Frequent itemset mining, CUDA GPU computing, Parallel Computing I I NTRODUCTION Frequent Itemset Mining \(FIM\ algorithms are used for finding common and potentially interesting patterns in large-scale databases. In FIM algorithms, the data in the database are called transactions, each of which is a set of items labelled by a unique ID. The purpose of FIM is to find the most frequently-occurring subsets from the transactions. The frequency of the subset is measured by support ratio, which is the number of transactions 
containing the subset divided by the total number of transactions in the database.  FIM algorithms are given a minimum support ratio threshold, and returns all the frequent item sets with support ratio meeting the threshold FIM is common in many research and commercial applications. An example can be shown in the sales data analysis of supermarkets. Customers usually purchase goods in a pattern \(e.g. people who buy vegetables often also buy salad dressing\d those common shopping patterns can be discovered by mining receipts. Analysis of those patterns can be useful for designing the layout of the supermarket: products usually sold together can be placed near each other. FIM is also useful in database management 
systems, information retrieval, bioinformatics, data stream analysis, and computer vision Our GPU implementation includes a set of fine-grained parallel data structures and algorithms design to achieve premising degree of speed up on modern GPU compared with state-of-the-art serial implementation. Experiment results show that our GPU implementation is more effective \(over 100x speed up \ large and dense datasets II BACKGROUND AND RELATED WORK Three of the best-known FIM algorithms are Apriori [1  3 an d FP G row th 4 A p riori an d Eclat iteratively generate k 1-sized frequent item sets by joining frequent 
k sized item sets.  This step is called candidate generation After generating each new set of candidates the algorithm scans the transaction database to count the number of occurrences of each candidate.  This step is called support counting The primary difference between Apriori and Eclat is the way they represent candidate and transaction data and the order that they scan the tree structure that stores the candidates.  FP-Growth is the most recently-developed algorithm and operates much differently. It executes two complete scans over the transaction database to build up a frequent pattern tree, and then generates frequent item sets by bottom-up traversal 
and identifying sections of the tree that represent frequent subsets. The main difference from the previous two approaches is that FP-Growth doesnêt generate candidate sets iteratively In general, much of the work in FIM algorithm development were focused on serial algorithms, which is likely due to the high degree of data dependence that is fundamental to FIM methods. Single-threaded performance comparisons generally show that the FP-Growth method is generally faster than Apriori and Eclat, however, when minimum support is high, Apriori outperforms FP-Growth  portan tl y   h o w e v e r, is t h at A p riori con tai ns more easily exploitable task- and data-level parallelization 
than GP-Growth, giving it potentially more scalability than GP-Growth for parallel execution. In other words, while GP-Growth may outperform Apriori on a single processor Apriori has more performance potential for multi- and many-core platforms There has been much recent interest in implementing FIM algorithms. Ferec Bodon implemented Apriori using trie-based data structure and candidate hashing   Christian Borgelt implemented Apriori in his work using recursion pruning, Bart Goethals implemented Apriori based on Agrawalês algorithm o m p ari s on 
2011 IEEE International Conference on Cluster Computing 978-0-7695-4516-5 2011 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/CLUSTER.2011.61 585 
2011 IEEE International Conference on Cluster Computing 978-0-7695-4516-5 2011 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/CLUSTER.2011.61 590 


between those implementations can be found in Bodonês work III INTRODUCTION TO APRIORI ALGORITHM Apriori-based frequent item mining algorithms are based on the property that the subset of a frequent itemset must be frequent, this property allows the algorithm to incrementally build longer candidates from shorter ones. In the algorithm, first we generate all 1-item candidates, test their frequencies by scanning the transaction database, keep those whose support ratio is larger than given threshold then join the 1-item candidates to generate 2-item candidates and test the frequency of 2-items candidates This procedure will continue until thereês no frequent candidate left in the new generation Apriori algorithm requires all current candidate sets to be stored in memory, which can be expensive when the candidate set is large. The trie data structure has been developed to overcome the fast expanding of candidates The key idea is that the candidates from the k th generation and k 1 th generation share the same k length prefix, thus those candidates from different generations can be stored in a hierarchical tree structure. New candidate generation can be done by merging the leaf nodes and their siblings and appending new leaves to the current leaf layer.  Figure 1 shows an example of a candidate trie Figure 1 Example of trie representation On the other hand, the method used to represent the transactions is also an important aspect of FIM implementation.  The most straightforward way to store transactions is to store a list of items that comprise each transaction.  This is called the horizontal representation An alternative approach is the vertical representation which instead stores a list of transaction ids that correspond to each item.  This approach is referred to as a çtidset Each list can also be represented as a bitmask, which is referred to as a çbitseté.Figure 2 shows a comparison of vertical representation \(tidset and bitset The vertical representation has been utilized by most of the state-of-art Apriori algorithms. Experimental results show that the vertical representation usually can speed up the algorithm by one order of magnitude on most of the test dataset When the candidates are represented as bitsets, new candidates can be generated by joining leaf nodes with siblings in the trie, and the support of the new candidate can be computed by counting number of elements in its vertical list. This method of candidate generation is called Equivalent-Class Clustering, which is first devised by Zaki  It s p eeds u p can dida te g e n e ration b y av oiding th e  slow O\(n 2  complete join Transactions ID 1,2,3,4,5 1 2,3,4,5,6 2 3,4,6,7 3 1,3,4,5,6 4 Candidate tidset bitset 1 1,4 1001 2 1,2 1100 3 1,2,3,4 1111 4 1,2,3,4 1111 5 1,2,4 1101 6 2,3,4 0111 7 3 0010 1,2 1 1000 1,3 1,4 1001 1,4 1,4 1001  A  B  Figure 2 Comparison of horizontal representation \(A\ and vertical representation of transactions \(B\, the differences of tidset and bitset are also shown in \(B IV GPA PRIORI I MPLEMENTATION In this section we describe GPApriori.  The novelty of our approach is includes a new trie and vertical transaction list data structures and fine-grain parallelization of the support counting algorithm 1\  Data structure orientation Accelerating Apriori with a GPU involves careful consideration of the vertical transaction list representation Tidsets are stored as linear ordered arrays, and when traversing them during the support counting operation, the resultant memory access pattern and instruction stream branching behavior is unpredictable and leads to poor performance on the GPU a\ Tidset join is uncoalesced b\ Bitset join is coalesced Figure 3 A comparison between tidset join and bitset join, tidset join is not continuous in memory access and may cause uncoalesced read on GPU As shown in Figure 3, the tidset representation is compact but join operations on tidsets are highly data dependent and difficult to parallelize.  On the other hand the bitset representation requires more memory space but it is more suitable for designing a parallel set join operation which is better suited for GPU.  Joining two bit-represented 
586 
591 


transaction lists can be performed by a çbitwise and operation between the two bit vectors 2\  Support counting In Apriori, Support ratio is computed by scanning transaction database to count the occurrences of the candidates. This mainly involves considerable binary searches and trie traversal, both of which will cause irregular memory access when placing on GPU Our GPU Support counting is based on complete intersection In complete intersection, candidates are copied from main memory to graphic memory by host code the GPU calculates their support ratio value by executing bitwise intersections on their vertical transaction lists, and the support value results are copied back to main memory Figure 4 shows how complete intersections are computed. Only the vertical lists of first generation will be saved in graphics memory,  As shown in the example, the fourth generation is {\(1,2,4,5\, \(1,2,4,6\\(1,2,5,6\d the supports are computed by intersecting \(V 1 V 2 V 4 V 5  V 1 V 2 V 4 V 6 d \(V 1 V 2 V 5 V 6 ompared to the equivalent class clustering method, complete intersection adds computational complexity in order to reduce memory usage and memory operations.  On a GPU, the cost of these additional logic operations is lower than performing the additional memory references required to transfer the candidates from the host 3\  Support counting on CUDA CUDA computation is organized into threads and threads are organized into blocks.  Each list intersection will be computed by one block Figure 5 shows how support counting is computed on one thread block.  Threads within the same block will process a word-length subset, the size of vertical lists are aligned on the 64 byte boundary to ensure coalesced memory access.  The intersection result of each thread is stored in a 32-bit integer, and the number of ç1é bit in the integer is counted by CUDA build-in popcount function and stored in an integer array in shared \(on-chip\memory A parallel summation reduction algorithm us ed to add all the support values recursively into its first element The resultant support number for the candidate is written back to graphic memory and then transferred back to main memory Several optimization techniques which make the algorithm be faster are \(1 candidate preloading that is executed at the beginning of the kernel execution in which candidates will be preloaded to shared memory to prevent repeating global memory read manual, hand-tuned loop unrolling to further improve the kernel speed; and \(3 hand-tuned block size  1 2 4 Vertical list of item 1 Vertical list of item 2 Vertical list of item 3 5 6 Join 1 2 4 6 1 2 5 1 2 4 1 2 5 1 2 6   1 4 5 1 4 6 1 5 6    Vertical list of item 4 Vertical list of item 5 Vertical list of item 6 Join Join  support support support Generation 3 Generation 4  Figure 4 Complete intersection in support counting Figure 5 Thread dispatching across computation block V E XPERIMENTAL R ESULTS In this section we will compare our GPU implementation with various types of CPU Apriori algorithms A Experimental environment We performed our experiments using a Dell PowerEdge R710 sever connected to a Tesla S1070 GPU server with four Tesla T10 GPUs, although we currently use only one GPU.  Detailed information of tested implementation is listed in Table 1 Table 2 lists the detailed information about the datasets used in the experiments.  Our benchmark datasets are from the Frequent Itemset Mining Repository d in clu d e  one synthetic dataset file from IBM Almaden Quest research group, T40I10D100K, two dataset files from UCI dataset and PUMSB dataset: chess and pumsb, and one dataset file from Karolien Geurts containing anonymized traffic accident data: accidents 
587 
592 


T ABLE 1T ESTED FREQUENT ITEM MINING ALGORITHMS Algorithm Platform GPApriori Single thread GPU+ single thread CPU CPU_TEST Single thread CPU Borgelt Apriori Single thread CPU Bodon Apriori Single thread CPU Gothel Apriori Single thread CPU T ABLE 2E XPERIMENTAL DATASETS Dataset #Item Avg.length #Trans Type T40I10D100K 942 40 92,113 Synthetic pumsb 2,113 74 49,046 Real chess 75 37 3196 Real accidents 468 34 340,183 Real Figure 6 shows the detailed performance comparison Each of our performance results are listed as a speed up relative to performance given by the Borgelt implementation.Borgelt Apriori is one of the most recently developed and state-of-the-art implementations of the Apriori algorithm The comparison of GPApriori and CPU_TEST shows the degree of acceleration our GPU implementation achieves compared with equivalent CPU code.  On the smaller dataset chess, the GPU version can achieve a 10X speed up, while on a the larger dataset accident, the speed up ranges from 50X to 80X.  In general, the performance scales with the size of the dataset Figure 6 also shows the comparison between GPApriori and the other three Apriori algorithms \(Borgelt Apriori Bodon Apriori and Gothel Apriori\Both Bodon and Borgelt utilize the vertical tidset while Gothel uses the horizontal representation.  We show only in 6\(a\e performance of Gothel algorithm because it performs very slowly on the other three datasets Experimental results show that GPApriori outperforms Borgelt Apriori on most of the moderate sized datasets with 4X-10X speed up and on a large dataset accident, the speed up ratio can reach up to 80X Figure 6\(a Figure 6\(b 
588 
593 


Figure 6\(c Figure 6\(d Figure 6  Time performance comparison of Apriori algorithms on selected datasets: T40I10D100K  6\(a\, pumsb 6\(b\, chess 6\(c\ and accident 6\(d VI C ONCLUSION AND F UTURE W ORK We present a GPU parallel Apriori algorithm GPApriori\PApriori utilizes trie-based candidate set vertical data layout and bit set representation of vertical transaction lists.  The support counting procedure is optimized for GPU execution. The experimental results show that compared with state-of-the-art single threaded Apriori algorithm, the GPU version achieves one to two order magnitude in speed up Future work on the research includes how to parallelize other FIM algorithm such as FPGrowth and Eclat on GPU as well as devise a load-balanced computation model across CPU/GPU platform and GPU cluster VII R EFERENCES 1  R  A g ra w a l a n d H  Ma nn i l a  Fast Discovery of Association Rules in Advances in Knowledge Discovery and Data Mining 1996. p. 307-328   R  A gra w a l a n d R  Srik an t  Fast algorithm for mining association rules in VLDB 1994.  p. 487-499 3   M. J  Z a ki an d K  G o uda Fast Vertical Mining Using Diffsets in Proc. SIGKDD 2003.  p. 326-335 4  J Ha n  H Pe i   a nd Y Yin   Mining Frequent Patterns without Candidate Generation in SIGMOD 2000.  p. 1-12 5   N  G o v i ndar a ju a n d M. Z a ki  Advances in Frequent Itemset Mining Implementations in FIMI 2003 6 F   B o d on  A Trie-based APRIORI Implementation for Mining Frequent Item Sequences in OSDM 2005. p. 56-65 7  C Bo r g e l t Efficient Implementations of Apriori and Eclat in Proc. FIMI 2003 8   M. Z a ki an d S  P a r t has ar at hy  New Algorithms for Fast Discovery of Association Rules in KDD 1997. p. 283-296 9  N V idi a Data Parallel Algorithm in CUDA SDK Available from: http://developer.download.nvidia.com   Frequent Itemset Mining Dataset Repository Available from http://fimi.ua.ac.be/data 
589 
594 


Dataset  of cores ms on  cores ms 1 core Kosarak 8 1551 4 1586 2881 2 1997 Webdocs 8 299153 4 357679 891565 2 482111 Nytimes 8 443119 4 524553 1313698 2 689058 Wikipedia 8 27526403 4 35397110 93477243 2 53795313 Table II E XPERIMENTS RAN ON AN I NTEL X EON E5570 2.93 GH Z EQUIPPED WITH 23 GB OF RAM THE OS IS GNU/L INUX  KERNEL VERSION 2.6.18 T IMES ARE GIVEN IN MILLISECONDS  ms  T HE NUMBER OF BUCKETS IS 003 2 20   J Han J Pei Y  Y in and R Mao Mining frequent patterns without candidate generation A frequent-pattern tree approach Data Min Knowl Discov  vol 8 no 1 pp 53 87 2004  J S P ark M.-S Chen and P  S Y u  An ef fecti v e hash-based algorithm for mining association rules SIGMOD Record  vol 24 no 2 pp 175Ö186 Jun 1995  A Sa v asere E Omiecinski and S B Na v athe  An ef cient algorithm for mining association rules in large databases in VLDB  1995 pp 432Ö444  G S Manku and R Motw ani  Approximate frequenc y counts over data streams in VLDB 02  Morgan Kaufmann Publishers 2002 pp 346Ö357  N Jiang and L Gruenw ald Research issues in data stream association rule mining SIGMOD Record  vol 35 no 1 pp 14Ö19 2006  Y  Zhu and D Shasha Statstream Statistical monitoring of thousands of data streams in real time in VLDB  2002 pp 358Ö369  C Bor gelt Recursion pruning for the apriori algorithm  in IEEE ICDM Workshop on Frequent Itemset Mining Implementations  2004  A Campagna and R P agh On nding similar items in a stream of transactions in ICDM Workshops  2010 pp 121 128  J Misra and D Gries Finding repeated elements  Sci Comput Program  vol 2 no 2 pp 143Ö152 1982  E D Demaine A L  opez-Ortiz and J I Munro Frequency estimation of internet packet streams with limited space in ESA 2002  2002 pp 348Ö360  R M Karp S Shenk er  and C H P apadimitriou  A simple algorithm for nding frequent elements in streams and bags ACM Trans Database Syst  vol 28 pp 51Ö55 2003  A Metw ally  D Agra w al and A E Abbadi Ef cient computation of frequent and top-k elements in data streams in ICDT  pp 398Ö412  G Cormode and S Muthukrishnan Summarizing and mining skewed data streams in SIAM International Conference on Data Mining  2005  J X Y u Z Chong H Lu Z Zhang and A Zhou  A false negative approach to mining frequent itemsets from high speed transactional data streams Inf Sci  vol 176 no 14 pp 1986Ö2015 2006  M Charikar  K Chen and M F arach-Colton Finding frequent items in data streams Theor Comput Sci  vol 312 no 1 pp 3Ö15 2004  E Ab usland and M Mark o vics Implementing and e v aluating a sampling-based approach to association mining on mapreduce Masterês thesis IT University of Copenhagen 2011  R R Amossen A Campagna and R P agh Better size estimation for sparse matrix products in APPROXÖRANDOM 2010  ser Lecture Notes in Computer Science vol 6302 Springer 2010 pp 406Ö419 
150 


 286 


T. Filali Ansary, F. Fratani, E. Garcia, G. Lavou, D. Lichau, F. Preteux J. Ricard, B. Savage, J.P. Vandeborre, T. Zaharia. SEMANTIC-3D COMPRESSION, INDEXATION ET TATOUAGE DE DONNES 3D Rseau National de Recherche en Tlcommunications \(RNRT 2002 4] T.Zaharia F.Prteux, Descripteurs de forme : Etude compare des approches 3D et 2D/3D 3D versus 2D/3D Shape Descriptors: A Comparative study 5] T.F.Ansary J.P.Vandeborre M.Daoudi, Recherche de modles 3D de pices mcaniques base sur les moments de Zernike 6] A. Khothanzad, Y. H. Hong, Invariant image recognition by Zernike moments, IEEE Trans. Pattern Anal. Match. Intell.,12 \(5 1990 7] Agrawal R., Imielinski T., Swani A. \(1993 between sets of items in large databases. In : Proceedings of the ACM SIGMOD Conference on Management of Data, Washington DC, USA 8] Hbrail G., Lechevallier Y. \(2003 In : Govaert G. Analyse des donnes. Ed. Lavoisier, Paris, pp 323-355 9] T.F.Ansary J.P.Vandeborre M.Daoudi, une approche baysinne pour lindexation de modles 3D base sur les vues caractristiques 10] Ansary, T. F.   Daoudi, M.   Vandeborre, J.-P. A Bayesian 3-D Search Engine Using Adaptive Views Clustering, IEEE Transactions on Multimedia, 2007 11] Ansary, T.F.   Vandeborre, J.-P.   Mahmoudi, S.   Daoudi, M. A Bayesian framework for 3D models retrieval based on characteristic views, 3D Data Processing, Visualization and Transmission, 2004 3DPVT 2004. Proceedings. 2nd International Symposium Publication Date: 6-9 Sept. 2004 12] Agrawal R., Srikant R., Fast algorithms for mining association rules in larges databases. In Proceeding of the 20th international conference on Very Large Dada Bases \(VLDB94 September 1994 13] U. Fayyad, G.Piatetsky-Shapiro, and Padhraic Smyth, From Data Mining toKnowledge Discovery in Databases, American Association for Artificial Intelligence. All rights reserved. 0738-4602-1996 14] S.Lallich, O.Teytaud,  valuation et validation de l'intrt des rgles d'association 15] Osada, R., Funkhouser, T., Chazelle, B. et Dobkin, D. \(\( Matching 3D Models with Shape Distributions International Conference on Shape Modeling & Applications \(SMI 01 pages 154168. IEEE Computer Society,Washington, DC, Etat-Unis 2001 16] W.Y. Kim et Y.S. Kim. A region-based shape descriptor using Zernike 


moments. Signal Processing : Image Communication, 16 :95100, 2000 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



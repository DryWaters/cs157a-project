Characterizing the Efficiency of Data Deduplication for  \nBig Data Storage Management \nRuijin Zhou, Ming Liu Tao Li \nUniversity of Florida \nGainesville, Florida, USA \n{zhourj, mingliu} @ufl.edu, taoli@ece.ufl.edu \n nAbstractThe demand for data storage and processing is \nincreasing at a rapid speed in the big data era. Such a \ntremendous amount of data pushes the limit on storage \ncapacity and on the storage network. A significant portion of \nthe dataset in big data workloads is redundant. As a result, \ndeduplication technology, which removes replicas, becomes an \nattractive solution to save disk space and traffic in a big data \nenvironment However, the overhead of extra CPU \ncomputation \(hash indexing should be considered. Therefore, the net effect of \nusing deduplication for big data workloads needs to be nexamined. To this end, we characterize the redundancy of \ntypical big data workloads to justify the need for deduplication. \nWe analyze and characterize the performance and energy \nimpact brought by deduplication under various big data \nenvironments. In our experiments, we identify three sources of \nredundancy in big data workloads: 1 elaborate on the advantages and disadvantages of different \ndeduplication layers, locations, and granularities. In addition, \nwe uncover the relation between energy overhead and the \ndegree of redundancy Furthermore, we investigate the \ndeduplication efficiency in an SSD environment for big data \nworkloads nKeywords: Big Data, Deduplication, Storage Management \nI. INTRODUCTION \nMore than 2.5 quintillion bytes of data are generated \nevery day. 90% of the total data has been created just in the \npast few years alone. To contain such a massive amount of \ndata, storage continues to grow at an explosive rate \(52% per \nyear 1][14]. By the end of 2015, the size of the total \ngenerated data will surpass 7.9 zettabytes \(ZB number \nis expected to reach 35 ZB in 2020, which has proven to be \ntoo conservative [2][15].  \nThe big data era is here and it is more than just a matter \nof data size. Big data also represents the increasing ncomplexity of the data handling process. Instead of sitting in \none archive storage, data is now typically distributed among \ndifferent locations. Worse, 80% of generated data is claimed \nto be unstructured [3 Hadoop [8] is emerging as the most \npopular big data platform to manage and structure data for \nfurther analysis. However, the replication mechanism of \nHadoop generates a lot of duplicate data, which occupy both ndisk space and network bandwidth. Moreover, Hadoop is \nincreasingly being built on top of a virtualization layer, \nwhich further yields redundancy within and across virtual \nmachine disk images [26][27][28 Redundancy in big data \nworkloads becomes even higher in the case of 1 VMs and 2  in data centers. This technology eliminates \nredundancy by removing data blocks with identical content nDeduplication is not only used in backups and archives, but \nalso increasingly adopted in primary workloads 4][5]. The \nbenefits of deduplication are 1 buying storage devices and \n2 more attention to deduplication \nbecause there are many replicas in the data outsourced to the \ncloud \(e.g 75% of data are redundant based on a survey [6 nHadoop platform. As a result, more companies are \nresearching deduplication technology, and it has become a ncommon practice in cloud storage environments. \nDeduplication seems to be a suitable solution for data nexplosion in the big data era by 1 2 introduces \noverhead to the system. For example, hash indexing needs \nbe performed for every IO request to identify duplicates, \nwhich results in longer IO response time. In addition, extra \nCPU power is required to calculate the hash values in each \nIO request, which leads to higher energy consumption. Since \nthe volume of IO requests is enormous and increasing in big \ndata workloads, the overall performance and energy \nefficiency under different deduplication configurations is \nworthwhile to be studied thoroughly. Towards this end, we nfirst justify the need for deduplication by measuring the \ndeduplication ratio \(input/output size big data \nworkloads. We characterize the performance impact under \nvarious deduplication configurations namely deduplication \nlayer \(global versus local metadata \nversus data deduplication granularity. In addition, we \nstudy the energy impact for workloads with different IO \nbehaviors and degrees of redundancy. Moreover, we \nconsider an emerging storage medium \(solid state drive or \nSSD our storage environment.  \nThe following are the key observations we made: \n• Big data workloads have redundancy. On average, \n44% of the active data set in our big data workloads is \nredundant. Deploying an additional VM yields 97% \n98978-1-4799-055-3/13/$31.00 ©2013 IEEE\nmore redundant data. Using a replication mechanism in \nthe Hadoop distributed file system \(HDFS node \ncontains 25% more redundant data than the name node.  \n• Deduplication helps workloads utilize more disk 


nthroughput \(3X higher when deduplication is on in our \nexperiment nperformance improvement. However, due to the \noverhead of hash indexing, performance can degrade \nby 161% for some benchmarks in an extreme case.  \n• Extra hash computation on the CPU leads to additional \npower consumption \(around 10 7 level of redundancy, the overall energy can \nbe saved \(by 43% in our experiment reduces workload execution time. There \nis a strong correlation between energy impact and the \ndegree of redundancy.  \n• In a hybrid SSD/HDD environment, deduplication can \nimprove the system performance \(by up to 17% in our \nexperiment ncosts performance and energy overhead \(about 5% and \n6% respectively experimental results and \nconfiguring deduplication in different ways, we derive and \nhighlight the following insights and design implications for \ndata deduplication in a big data storage environment:  \n• The Performance impact of deduplication is \ndetermined by both the benefit of avoiding redundant \ndisk traffic and the overhead of hash indexing.  \n• Local deduplication can leverage parallelism to hide \nhashing overhead and maintain data availability. \nNevertheless, it cannot remove all redundant disk \naccesses. Global deduplication can eliminate redundant \ndisk accesses. However, it has high hashing overhead \nand reduces data availability n• Deduplication on the name node \(metadata nbecause it has less data. However, it also saves less \ndisk traffic. Deduplication on data nodes \(data nremoves more redundant disk accesses but has high \nhashing overhead. Deduplication on metadata yields \nbetter performance if the degree of redundancy in the \ndata set is low. \n• Fine-grained deduplication avoids more disk traffic but \nleads to higher hashing overhead than coarse-grained \ndeduplication. Coupling fine granularity with local \ndeduplication can exploit more redundant disk accesses \nand hide hash overhead. Using coarse granularity in \nglobal deduplication can help lower hashing overhead. \n• Since SSD has higher IO performance than HDD, \ndeduplication yields less benefit of reducing disk \ntraffic in SSD than in HDD. In a hybrid SSD and HDD \nstorage environment, only if the SSD ratio is low can \ndeduplication improve performance nThe rest of this paper is organized as follows: Section II \ndescribes the background and motivation for this work. \nSection III explains the evaluation methodology. Section IV \npresents and analyzes the experimental results. Section V \ndiscusses deduplication efficiency in an SSD storage \nenvironment. Section VI concludes this paper.  \nII. BACKGROUNDS AND MOTIVATION \nBig data is defined as any attribute that challenges the nconstraints of a system’s capability or business need [7]. \nThere are a lot of big data examples: Amazon runs the \nworld’s three largest Linux databases \(7.8TB, 18.5TB, and \n24.7TB operations and \nqueries from more than half a million third-party sellers and \nWalmart’s transaction database contains more than 2.5 \npetabytes of data. As the volume of data grows from \nterabytes \(TB ZB  center owners, have to pay additional \nmoney to purchase extra hard drives to contain such big \ndata.  At the age when data is exploding, the cost of storage \nstands out in a company’s budget.  \nWhat is worse, big data is more than just a matter of data \nsize. It also involves the way we deal with the data. IBM \nclaims that 80 of data captured today is unstructured, \nincluding climate information gathered by sensors, posts on \nsocial media websites, cell phone GPS signals, and online \ntransaction records. In order to manage and structure those \ndata, Hadoop [8] is emerging as a core platform for big data \napplications. Hadoop implements a computational paradigm \nnamed MapReduce, where data and application are divided \ninto small fragments and distributed among different nodes. \nFor the purpose of data availability, Hadoop Distributed File \nSystem HDFS nWorse, each node in Hadoop is usually a virtual machine \nwith a virtual disk image, which has high redundancy. The \ndata for big data workloads is big not only because the \nuseful and identical data is big but also because the \nredundancy is very high. A large amount of redundant data \ncosts undesired disk traffic and greedy demand for storage \ncapacity. \nDeduplication technology [22] has been researched for \nabout a decade now and widely adopted in backup and \narchive storage. By comparing the hash value of data blocks, \nit identifies and removes duplicated data blocks so that the \nstorage space is saved. Recently, deduplication has started to \nemerge in primary storage systems, which also have a \nsignificant amount of redundant data [4]. In primary storage \nsystems, hash computation and comparison are performed in \neach IO request. Once the data is identified as redundant, the \nIO request will not be issued. Instead, a pointer is created to \n99\nthe actual data. By doing so, IO traffic is reduced and IO \nperformance is improved [19][20].  \nThere are two types of deduplication: inline and offline. \nSeveral studies [4][9][10] shed light on the advantages and \ndisadvantages of these two schemes. The offline scheme, \nwhich performs deduplication after the data is saved on hard 


ndrives, is used to save disk space on archival storage. The \ninline scheme performs deduplication before the data is \nissued so that both disk traffic and space are saved. In this \npaper, we use inline deduplication Additionally, where to \nimplement deduplication is also debatable. It can be \nimplemented at the HDFS level or virtualization level. Since \nthe redundant data within the VM disk images cannot be \ndetected by HDFS, we believe it is better to apply \ndeduplication at the virtualization level. Currently, ZFS [11] \nand Opendedup 12] support deduplication functionality for \nVM disk images. In this paper, we select ZFS as our inline ndeduplication tool. \nUsing deduplication in the big data storage system seems \nto be attractive because: 1 deduplication scheme can help \nreduce a large amount of redundant data generated by big \ndata workloads; 2 disk IO traffic can be significantly \nreduced so that the whole system can gain much better \nperformance nHowever, deduplication also introduces overhead to the \nsystem, namely, 1 each IO \nrequest, and 2 requests result in \nhigher overhead in both performance and power. \nPerformance impact is determined by both the benefit of \nsaving disk traffic and the overhead of hash indexing. \nEnergy impact is determined by power overhead of hash \ncomputation and workload execution time.  \nWorkloads have various IO behaviors and different ndegrees of redundancy, which will largely affect their \nsensitivity on disk traffic and hash indexing. Once the \nbenefit of reducing disk IO traffic and the overhead of hash \nindexing changes, workload performance becomes less \npredictable, which further leads to undetermined energy \nconsumption. Apart from saving space the efficiency of \ndeduplication for big data storage management is still \nlargely unknown. To reveal the performance and energy \nimpact introduced by deduplication, this paper thoroughly \ncharacterizes the efficiency of deduplication under various \nbig data workloads with different configurations.   \nIII EVALUATION METHODOLOGY \nA. Experimental Setup \nWe evaluate the workload performance and CPU \noverhead on a Dell PowerEdge rack, which is equipped with \nfour 1U PowerEdge R610 servers and two 2U PowerEdge \nR710 servers. Each server is assembled with two 2.4GHz \nquad-core Intel Xeon processors, 24GB of RAM and one \n160GB local hard drive. The 2U servers, which have six \nadditional 1TB hard drives and four 240GB SSDs, are npresented as the storage server to hold the large dataset. All \nservers are connected to an in-rack private switch \(Dell \nPowerConnect 6224 Figure 1. We install \nXen 4.2.1 with Linux kernel 3.0.0-12 to support \nvirtualization. We deploy ZFS on Linux 11] to support \ndeduplication functionality. Software iSCSI is setup to \nexpose disks in the storage server to the compute server. We \nboot up a maximum of 10 VMs for Hadoop slave nodes. For \neach VM, we assign 2 vCPUs, 8GB RAM, 40GB local hard \ndrives and one 500GB ZFS volume as the data drive. Inside \nthe virtual machine, we use Ubuntu 12.04 as the guest \noperating system and Hadoop 1.0.4 as our big data platform. \nTo avoid memory exceptions from Hadoop, we increase the \nJava heap size to 2GB. In addition, to avoid background jobs \nin the operating system, we use a ZFS volume as the data \ndisk to hold data generated by Hadoop Therefore, the \ndeduplication will only apply to Hadoop workloads. To \nmeasure the energy and power consumption, we connect a \nWatts up? [21] meter to the power supply to obtain the \npower trace during workload execution.  \n \n \nFigure 1. Overview of experimental setup \n \nB. Workload Execution Scenarios \nOn top of the Hadoop platform, we run several typical \nbig data applications including web search, machine \nlearning analytical query, and sorting. HiBench benchmark \nsuite [13], which is provided by Intel, includes a wide range \nof Hadoop applications, namely PageRank, Nutch Indexing, \nBayesian Classification \(Bayes Clustering, Hive, \nSort, Terasort, and Enhanced DFSIO. The workloads are \nsummarized in Table 1. By tuning the parameters, we \nchange total data size from 0.5TB to 5TB, within which the \nactive dataset size ranges from 1GB to 100GB. Note that \nEnhanced DFSIO is an IO micro benchmark that reports IO \nthroughput. For other benchmarks, we use execution time to \nindicate the performance. \nTable 2 summarizes all workload and deduplication \nconfigurations we considered in this paper. From a workload \nperspective, big data means the data is very large and \ngrowing. Therefore, we consider the following three types of \ndata growth: 1 Deploying more VMs in the Hadoop \nplatform, which usually happens when more computation \nVirtualization Layer\nPhysical Storage Pool\nPhysical Machines Layer\nVM VM VM VM\nOS\nHDD HDD HDD SSD SSD\nOS OS OS\nZFS Volumes\nZVOL1 ZVOL2 ZVOLn...\n.........\n...\n...\n...\niSCSI\n100\npower is needed. 2 which \nusually occurs when more input data is gathered. 3 used to \nguarantee higher data availability. We also consider \ncompression technology [17], which slows down the speed \nof data growth. From a deduplication point of view, we \nconsider three aspects: deduplication layer global versus \nlocal metadata versus data deduplication means that \nall VM disk images are assigned to one ZFS pool. Thus, all \nredundant data blocks can be observed by the deduplication \nmechanism. Local deduplication means each VM disk image \nis assigned to 


one ZFS pool. Deduplication for each VM is \nhandled separately by different ZFS processes. For metadata ndeduplication, we only apply deduplication on the name \nnode, while we apply deduplication on data nodes for data \ndeduplication. The deduplication granularity is also tunable \nby changing the record size in ZFS. In our experiments, we \nuse 1K to 128K as our granularities. We also consider SSDs \nin our storage environment. We assign more virtual machine \ndisk images on to the SSD to increase the ratio of SSDs in \nthe Hadoop platform n \nTable 1. Workload summary \nCategory Benchmarks Tunable Parameters \nWeb Search \nPageRank Pages nNutchindexing Pages \nMachine \nLearning \nBayesian Classification Pages, class \nKmeans Clustering Samples samples per \ninput file, dimensions \nAnalytical \nQuery \nHive  Universities, pages \nMicro-\nbenchmarks \nSort Data size \nTerasort Data size \nEnhanced DFSIO \nNumber of read files, \nread file size, number \nof write files write file \nsize \n \nTable 2. Execution scenarios \nWorkload Configurations \nScenarios Description \nDeploy more VMs Deploy more hadoop nodes  \nExpand active data set Expand input dataset \nReplicas Increase/decrease replicas in HDFS \nCompression Turn on/off compression in HiBench \nDeduplication Configurations \nGlobal/Local nDeduplication \nGlobal: all VMs in one ZFS pool \nLocal: one VM in one ZFS pool \nMetadata/Data \nDeduplication nMetadata: deduplication on name node \nData: deduplication on data nodes \nGranularity Change record size in ZFS \(1K –128K as the ratio between \nthe sizes of data before and after deduplication is applied. A \nlarger value of the deduplication ratio indicates a higher \nlevel of redundancy. ZFS computes the deduplication ratio \nonline while a workload is running. Thus, in this case, \ndeduplication ratio is equal to the total bytes that are issued \nto the ZFS pool divided by the total bytes that are actually \nissued to the disks. In this paper, we use the deduplication \nratio reported by ZFS. \nThroughput is defined as the size of data that can be ndelivered within a certain period. By using deduplication, \nthe replicas on the network will be removed which is \nexpected to increase available disk bandwidth for the \nworkloads. So, we use throughput reported by Enhanced \nDFSIO to measure the traffic difference between \ndeduplication when it is on and off.  \nProgram execution time is used to measure the \nperformance of big data workloads. Although IO behavior is \nthe focus in this paper, CPU and memory are also important \nin big data workloads. Thus, it is fair to use program nexecution time to indicate the overall performance. By \nobserving and comparing the execution time before and after \nusing deduplication, we can see how much impact \ndeduplication introduces to the workloads. \nCPU overhead is obtained by monitoring CPU usage of \nthe ZFS process during workload execution. Note that ZFS \nhas other functions \(e.g. data transaction management, IO \npipeline, etc Therefore, \nCPU usage for ZFS is non-zero even when the deduplication \nfunction is turned off.  \nThe power consumption trace is gathered by the Watts \nup? meter, which measures both voltage and current on the \npower cord. Watts up? computes the power based on these \ntwo data series. We further multiply the value of average npower consumption by the total execution time to obtain the \naverage energy consumption for workloads. \nIV EFFICIENCY ANALYSIS FOR DEDUPLICATION IN BIG \nDATA ENVIRONMENT \nA. Redundancy Analysis \nThree behaviors in big data workloads will inevitably \nyield redundancy: 1 and 3 nodes to provide more computation power. Since each \nnode is a virtual machine, the number of virtual disk images \nincreases when we increase the number of nodes. Within \neach disk image, there is a large percentage of redundant \ndata: empty data blocks and similar operating system files. \nFigure 2 shows the deduplication ratio prior to running all \nHadoop benchmarks The deduplication ratio increases from \n70X to 220X when we deploy more VMs. Even within a \nsingle virtual image, there is 97% redundant data \(due to \nempty blocks and similar files deployed in the Hadoop environment. In \nthis case, applying deduplication can save a lot of space. \nAnother attribute of big data workloads is their large and \nincreasing volume of dataset. Figure 3 shows the n101\ndeduplication ratio of the dataset of our benchmarks on a \nsingle node. As can be seen, different benchmarks have \ndifferent deduplication ratios, which means the levels of \nredundancy are different. This is true in the real world. Some \napplications \(e.g. Kmeans and Sort redundancy becomes higher as the size of \nthe dataset increases; some applications have low \nredundancy and they always generate different data as the \ndataset increases, which is similar to Terasort in our \nbenchmark suite. Therefore, the correlation between dataset \nsize and the level of redundancy is not strong. However, on naverage, 44% of the active dataset in big data workloads is \nredundant. \nSome well-designed workloads incorporate a \ncompression technique directly in their code with the goal of \nsacrificing a certain degree of performance to save disk \nspace. In this case, the deduplication ratio will be near 1. \nHere, we intentionally add compression in the Kmeans \nbenchmark to see how compression affects the deduplication \nratio. Figure 4 


shows that the deduplication ratio on a \ncompressed dataset is 50% less than that on an \nuncompressed dataset The reasons are 1 duplicates; 2 nsource of duplicates.  \nAlthough compression technique can lower the \npossibility of duplicated data blocks Hadoop, as well as \nother distributed big data platforms, will inevitable generate \na large amount of duplicates because of replication schemes. \nTo guarantee the availability of data blocks, Hadoop \nduplicates data blocks and distributes them to different data \nnodes. The default number of replicas is three, which can nalso be changed by the user to adapt to their specific \nsituation. The higher the number of the replicas, the better \nthe availability. In Figure 5, we increase the number of \nreplicas from 1 to 6. We find that as the number of replicas \nincreases, the deduplication ratio will increase across all \ndifferent input datasets. On average, adding one more replica \nintroduces 19% redundant data as shown in Figure 5. In the \ndefault setting every data block in HDFS will be copied 3 \ntimes and distributed to different nodes. The correlation \nbetween the number of replicas and the degree of \nredundancy is very strong. Therefore, applying \ndeduplication to Hadoop workloads can save a lot of \nredundant disk traffic and space, although the availability \nissue should be taken care of.  \nBy further investigating into the Hadoop structure, we \nfind that Hadoop uses the name node to store all the \nmetadata \(indexing files Figure 6, we apply deduplication \nseparately on the name node and data nodes. As can be seen, \nin most cases data nodes have the larger amount of \nduplicates. On average, data nodes have 25% more \nredundant data than the name node. Considering the replicas \nin HDFS, when the dataset keeps increasing, the duplicates \nin data nodes will increase at a much faster speed than the \nname node. However, in some benchmarks \(e.g. Terasort nand Bayes name node \nstores metadata, which impacts the IO performance, the idea \nof using deduplication on the name node to reduce disk \naccess and improve performance is worthwhile to be studied. \nFrom the disk space point of view, data nodes are better \nplaces to apply deduplication than the name node.  \nTo summarize, big data workloads have a high level of \nredundancy originating from: 1 number of replicas, and 3 nredundancy for some workloads. For the Hadoop platform, \nthe data nodes have more redundancy than the name node. \nSince redundancy is inevitable in big data workloads, the \ndeduplication technique is valuable for a big data storage \nenvironment.  \n \n  \nFigure 2. Deduplication ratio when \ndeploying more nodes  \nFigure 3 Deduplication ratio when expanding \nactive dataset \nFigure 4. Deduplication ratio when \ncompression is on/off on Kmeans ratio when \ndeduplication on name node/data node \nFigure 7. Throughput when deduplication \nis on/off \(reported by Enhanced DFSIO n\n\n\f\n\f\f\n\n\n\n\n 


Sequences in prehistoric remains,” J. Anthropological Inst.\nGreat Britain and Ireland, vol. 29, pp. 295–301 1899.\n[13] J. Czekanowski, “Zur differentialdiagnose der neandertalgruppe,” Korre-\nspondenzblatt der Deutschen Gesellschaft fr Anthropologie, Ethnologie\nund Urgeschichte, vol. 40, pp. 44–47, 1909.\n[14] L. Wilkinson and M Friendly, “The history of the cluster heat map,”\nThe American Statistician, vol. 63, no. 2, pp. 179–184 2009.\n[15] R. C. Prim, “Shortest connection networks and some generalizations,”\nBell System Technical Journal vol. 36, pp. 1389–1401, 1957.\n[16] T. C. Havens, J. C. Bezdek, J. M. Keller, M. Popescu, and J. M. Huband,\n“Is VAT really single linkage in disguise?” Ann. Math. Artif. Intell.,\nvol. 55, no. 3-4, pp. 237–251, 2009.\n[17 T. C. Havens, J. C. Bezdek, J. M. Keller, and M. Popescu, “Dunn?´s\ncluster validity index as a contrast measure of VAT image,” in Proc.\nICPR, Tampa, FL, December 2008.\n[18] J. Dunn, “A fuzzy relative of the ISODATA process and its use in\ndetecting compact well-separated clusters,” J. of Cybernetics, vol. 3,\nno. 3, pp 32–57, 1974.\n[19] C. D. Manning, P. Raghavan, and H. Schutze, Introduction to Informa-\ntion Retrieval Cambridge University Press, 2008.\n[20] R. Chitta, R. Jin, and A. K. Jain, “Efficient kernel clustering using\nrandom fourier features,” in Int. Conf. Data Mining, 2012.\n[21] D. Arthur and S. Vassilvitskii k-means++: The advantages of careful\nseeding,” in Proc. SODA, 2007, pp. 1027–1035.\n401\n 


absorption. Journal of Medicinal Chemistry,\n44\(12  interpretable bayesian classi?cation\nmodel for prediction of herg liability. ChemMedChem 1\(3  genetic algorithm: a method for developing classi?cation\nstructureactivity relationships. Journal of Chemical Information and\nComputer Sciences, 43\(6  O’Brien, and Donald F. Weaver. A\ncomparison of methods for modeling quantitative structureactivity re-\nlationships. Journal of Medicinal Chemistry, 47\(22  and Vithal M. Kulkarni. Three-dimensional quantitative\nstructureactivity relationship \(qsar mapping of cytochrome\np-45014dm inhibiting azole antifungal agents1. Journal of Chemical\nInformation and Computer Sciences, 39\(2  Ramesh Panchagnula.\nFunctional role of p-glycoprotein in limiting intestinal absorption of\ndrugs: contribution of passive permeability to p-glycoprotein mediated\nef?ux transport. Molecular Pharmaceutics, 2\(1 PMID:\n15804173.\n[59] Daniel F. Veber, Stephen R. Johnson, Hung-Yuan Cheng, Brian R.\nSmith, Keith W. Ward, and Kenneth D. Kopple. Molecular properties\nthat in?uence the oral bioavailability of drug candidates. Journal of\nMedicinal Chemistry, 45\(12  Wang, and\nStephen H. Bryant. Pubchem: a public information system for analyzing\nbioactivities of small molecules. Nucleic Acids Research, 2009.\n[61] Matthew D. Wessel, Peter C. Jurs, John W. Tolan, and Steven M.\nMuskal. Prediction of human intestinal absorption of drug compounds\nfrom molecular structure. Journal of Chemical Information and Com-\nputer Sciences, 38\(4  Bonham, Fredrik Ax, Anders Hall-\nberg, Hans Lennerns, and Anders Karln. Correlation of human jejunal\npermeability \(in vivo multivariate data analysis approach. Journal of\nMedicinal Chemistry, 41\(25  Yazdanian, Susan L. Glynn, James L. Wright, and Amale Hawi.\nCorrelating partitioning and caco-2 cell permeability of structurally\ndiverse small molecular weight compounds. Pharmaceutical Research,\n15:1490–1494 1998. 10.1023/A:1011930411574.\n[64] Shiyin Yee. In vitro permeability across caco-2 cells \(colonic can\npredict in vivo \(small intestinal 1997. 10.1023/A:1012102522787.\n[65] Katsumi Yoshida and Tomoko Niwa. Quantitative structureactivity\nrelationship studies on inhibition of herg potassium channels. Journal of\nChemical Information and Modeling, 46\(3  Le, Anne Hersey, Chris N.\nLuscombe, Gordon Beck, Brad Sherborne, and Ian Cooper. Rate-\nlimited steps of human oral absorption and qsar studies. Pharmaceutical\nResearch, 19:1446–1457, 2002. 10.1023/A:1020444330011.\n42\n 


between the MSL flight computer and the Electra-\nLite UHF Transceiver that resulted in constraints on nallowable command data product size and development of a \ncomplex buffer management system to avoid truncating \ndownlink frames.  While operational workarounds were \nultimately identified, these idiosyncrasies resulted in more \ncomplex ground processes and delayed other critical relay \ntests.  Future missions should ensure early and thorough \ndocumentation and validation of the end-to-end relay data \npath. \nVerification Validation \(V&V including during the cruise phase of the mission.  \nWhile these were addressed prior to arrival at Mars, and nactual surface operations have proceeded smoothly, it would \nhave been desirable to identify these issues earlier.  The \nchallenge here, which is common to the previous \nexperiences with MER and PHX, is that the testing timeline \nis dictated by the lander mission’s V&V test program and \ntestbed accessibility.  The Mars Exploration Program may \nneed to establish more formal guidelines for the scope and \nschedule of testing related to verification and validation of \nrelay services, and ensure that all missions develop their test nschedules and corresponding resource profiles to meet those \nguidelines. \nEnd-to-End Relay Testbeds:  The fidelity of the end-to-end \ntestbeds for relay system testing can play a significant role \nin the overall success of the V&V test campaign.  For the \nMSL-MRO link, both the orbiter and lander projects had \nhigh fidelity spacecraft testbeds resident at JPL, with \nEngineering Models of the Electra and Electra-Lite ntransceivers, and with flight-like representations of the \nspacecraft Command & Data Handling \(C&DH subsystem.  \nWhile these testbeds were located at separate sites within \nthe JPL campus, fiber optic links supported signal flow \nbetween them, as well as integration of a high-fidelity link \nchannel simulator capable of emulating realistic time \nvariation of link amplitude, frequency, and delay, enabling \nthorough end-to-end data flow testing over a range of flight-\nlike signal conditions.  For ODY and MEX, however, each \norbiter project had only a portable test set available at JPL to \nsupport cross-project testing with MSL, each with a flight-\nlike UHF transceiver but with lower fidelity representations \nof the orbiter C&DH.  This limited the scope of ground \ntesting possible on the MSL-ODY and MSL-MEX links.  \nThis, combined with some non-flight-like aspects of the \nODY test set that were discovered late in the V&V test \ncampaign, resulted in the deferral of full validation and use \nof the MSL-ODY forward link capability until well after \nlanding.  The conclusions here are that high-fidelity testbeds \nincrease the robustness of end-to-end relay testing; when \nprogrammatic considerations limit the test hardware fidelity, \nit is essential to clearly document and assess any non-flight-\nlike aspects of the testbed infrastructure. \nElectromagnetic Interference:  Uncertainty in the MRO nEMI environment resulted in significant concern prior to \nMSL arrival as to whether Curiosity would be able to \nachieve the desired 250 Mb/sol data return via the MRO \nrelay path.  This resulted in a large amount of MRO flight \nand ground testing to attempt to better quantify the EMI \nimpacts as a function of Electra return link frequency.  It \nalso drove the need for a lengthy commissioning phase \nduring the first few months of MSL surface operations, to \ncarefully monitor performance as each MRO science \ninstrument was powered on Electra’s frequency-agility \nturned out to be an important tool in mitigating the EMI \nimpacts.  In hindsight earlier and more thorough flight \ntesting could have provided more confidence in the \npredicted MRO relay performance; however, such testing \nwould have required interruption of ongoing MRO science \nobservations Ultimately, future missions will want to \naddress EMI issues earlier in the spacecraft/instrument \ndevelopment cycle to identify and mitigate any spurious \nemissions prior to launch. \n6. CONCLUSIONS \nNASA’s ODY and MRO orbiters and ESA’s MEX orbiter \nembody an international network of Mars relay orbiters, \nproviding essential telecommunication services to the Mars \nScience Laboratory mission.  All three orbiters provided ncomplementary coverage of MSL’s EDL, acquiring tracking \nand telemetry data from MSL’s UHF transmission that ncould have provided essential information for fault \nreconstruction had a mission-ending anomaly occurred nduring EDL.  Since landing, ODY and MRO are providing \nthe highest levels of data return yet achieved for a Mars \nlander, with over 45 Gb of Curiosity data returned over the \nfirst 90 sols of the surface mission.  Key to this level of \nperformance are a number of new capabilities in the Electra \nand Electra-Lite UHF Transceivers on MRO and MSL, \nrespectively, including higher data rates, frequency-agile \noperations, and adaptive data rates, as well as the dedication \nof the operations teams on each mission and the MaROS nmultimission relay operations tools and processes \nsupporting them. \n \n   978-1-4673-1813-6/13/$31.00 ©2013 IEEE \n 11 \nACKNOWLEDGMENT \nThe research described in this paper was carried out at the \nJet Propulsion Laboratory, California Institute of \nTechnology, under a contract with the National Aeronautics \nand Space Administration. \nREFERENCES  \n [1] Charles D. Edwards, “Relay Communications for Mars \nExploration,” Int. J Satell. Commun. Network, 25 111-\n145, 2007. \n[2] Olivier Reboud, et al,  “An Interplanetary and Interagency nNetwork - Lander Communications at Mars”, AIAA \nInternational Conference on Spacecraft Operations 


n\(SpaceOps  Network:  UHF Relay Support of \nthe Mars Exploration Rovers by the Mars Global \nSurveyor, Mars Odyssey, and Mars Express Orbiters” \nIAC-04.M.5.07, 55th International Astronautical Congress, \nVancouver, Canada  4-8 Oct 2004. \n[4] “Telecommunications Relay Support of the Mars Phoenix \nLander Mission”, C. Edwards, et al., IEEEAC paper \n#1155, 2010 IEEE Aerospace Conference Proceedings, \n2010. \n[5] Consultative Committee for Space Data Standards \n\(CCSDS 2004. \n [6] Charles D. Edwards, Jr., et al., “The Electra Proximity \nLink Payload for Mars Relay Telecommunications and \nNavigation,” IAC-03-Q.3.A.06, 54th International \nAstronautical Congress, Bremen Germany, 29 September \n– 3 October, 2003. \n[7] E. Satorius, et al., “Chapter 2:  The Electra Radio,” in n“Autonomous Software-Defined Radio Receivers for \nDeep Space Applications nhttp://descanso.jpl.nasa.gov/Monograph/series9/Descanso\n9_Full_rev2.pdf 2006. \n[8] Allard, D. and R. Gladden Mars Relay Operations \nService \(MaROS Network,” \n10.1109/AERO.2012.6187115 , IEEE Aerospace \nConference, Big Sky, MT, 2012. \n [9] J. P. Grotzinger et al., “Mars Science Laboratory Mission \nand Science Investigation,” Space Sci Rev 170:5-56, \n2012. \n[10] A D. Steltzner, et al., “Mars Science Laboratory Entry, \nDescent, and Landing System Overview,” International nPlanetary Probe Workshop, Barcelona, Spain, June 12, \n2010.. \n[11] A. Makovsky, P. Ilott, and J. Taylor Mars Science \nLaboratory Telecommunications System Design”, \nDESCANSO Design and Performance Summary Series nhttp://descanso.jpl.nasa.gov/DPSummary/Descanso14_M\nSL_Telecom.pdf , November, 2009. \n 978-1-4673-1813-6/13/$31.00 ©2013 IEEE \n 12 \n [12] R. P. Kornfeld, et al., "Entry, Descent, and Landing nCommunications for the 2007 Phoenix Mars Lander", \nAIAA Journal of Spacecraft and Rockets, Vol. 45, No. 3 nMay-June 2008. \n [13] Abilleira, F. and J. D. Shidner, “Entry, Descent, and \nLanding Communications for the 2011 Mars Science \nLaboratory,” 23rd International Symposium on Space \nFlight Dynamics, Pasadena, Oct 29-Nov 2, 2012. \n[14] B.C. Schratz, et al., “Telecom Performance and Mission \nDesign during the Entry Descent and Landing of the Mars \nScience Laboratory”, 22nd AIAA/AAS Space Flight \nMechanics Meeting, Kauai, Hawaii February 10–14, \n2013 \(in preparation  IEEE Aerospace Conference #1065, Big Sky, \nMT, March 2004. \n[16] Gladden, R., “Mars Reconnaissance Orbiter The  \nHistory of Supporting the Phoenix Lander”, AIAA \nSPACE 2009 Conference & Exposition, Pasadena, CA, \nSep 14-17, 2009. \nBIOGRAPHIES \nCharles \(Chad nExploration Program and acting \nChief Technologist for the Mars \nExploration Directorate at the Jet nPropulsion Laboratory.  Prior to \nthis current assignment he \nmanaged the research and \ndevelopment program for NASA’s \nDeep Space Network.  He received an A.B. in Physics \nfrom Princeton University and a Ph. D. in Physics from \nthe California Institute of Technology.   \nDavid J. Bell is the supervisor of \nthe Communications Systems & \nOperations group, 337H at the \nJet Propulsion laboratory and \nhas over 30 years experience in \nall aspects of flight and ground \nradio system design including \nmodulation, coding, antennas npropagation and interference \nmitigation. Mr. Bell has published \nnumerous telecom technical \npapers and holds several patents related to antennas and \ncoding systems for telecom operations in difficult \npropagation and signal environments. In addition, Mr. \nBell was the system engineer for all aspects of the \ndevelopment flight build and test of the Electra Software \ndefined radio subsystem that is now flying on the MRO nspacecraft.  \n \nRoy Gladden is the Multimission \nRelay Operations Lead for the \nMars Program Office and the nMultimission Ground Systems and \nServices organization at the Jet \nPropulsion Laboratory.  Prior to \nthis current assignment, he led the \nMission Planning and Sequencing \nTeam for the Mars Reconnaissance Orbiter Project.  He \nreceived both a B.S. and M.S. in Mechanical Engineering \nfrom Utah State University. \n \nPeter Ilott is the Telecom Lead for \nMars Science Laboratory at JPL. \nPeter previously worked on \nPhoenix, and was the UHF relay \nengineer for the MER mission.  \nOther JPL projects include \nOdyssey, MRO, Deep Impact, and nCloud Sat.  Prior to JPL he \nworked for 12 years on \ncommercial spacecraft. Peter \nreceived his BSc in physics, and PhD in Elec. Eng. at \nMcGill University, and his MSc in Plasmas Physics at the \n 978-1-4673-1813-6/13/$31.00 ©2013 IEEE \n 13 \nUniversité de Montréal. \n \nThomas Jedrey received his BS \nin Mathematics from the \nUniversity of Maryland, College \nPark Maryland, in 1979, his \nMA in Probability and Statistics \nfrom the University of Maryland \nin 1982, and his MS in \nElectrical Engineering from the nUniversity of Southern \nCalifornia in 1990.  He is the \nauthor of over thirty papers in the communications nfield.  He has also served as a special editor for the \nInternational Journal of Satellite Communications Mr. \nJedrey has been at the Jet Propulsion Laboratory since \n1986.  He has worked on and managed multiple NASA, \nDOD, and private industry based projects.  He is the \ntechnical lead for the various Electra Software Defined \nRadio developments and was the manager of the JPL \nWireless Communications Group.  The UHF Relay 


ncommunications payload for the Mars Reconnaissance \nOrbiter was developed under his cognizance and he is ncurrently managing the Flight Communications Systems \nSection at JPL, the section responsible for flight ncommunications on the majority of JPL missions. \n \nDan Johnston received a B.S. \nin Aerospace Engineering from \nthe University of Texas in 1984 \nand an MSE from the University \nof Texas in 1989.  Since joining \nJPL in 1989, he has \nparticipated in the development \nand flight operations phases of \nthe Mars Observer and Mars nGlobal Surveyor missions.  \nPrior to joining JPL, he was employed with McDonnell \nDouglas Astronautics in Houston, TX, in support of STS \n\(Shuttle Project Manager \(and as \nadditional duty the Mission Manager nJennifer Maxwell is the Lead \nRelay V&V Engineer on the \nMars Science Laboratory \nProject at the Jet Propulsion \nLaboratory.  Prior to this \ncurrent assignment, she worked \non End-to-End Information \nSystem and Mission System \ntesting on MSL.  Other missions \ninclude the Cassini-Huygens \nMission to Saturn and Titan She received her B.S. in \nAeronautics and Astronautics from Massachusetts \nInstitute of Technology and two M.S. degrees in \nAerospace and Systems Engineering from University of \nSouthern California. \n \nRicardo Mendoza has over 10 \nyears of flight operations \nexperience including Cassini, the \nMars Exploration Rovers, the \nMars Reconnaissance Orbiter \nand the Mars Science \nLaboratory. He earned his \nbachelor’s degree in electrical nengineering from Cal Poly \nPomona in 2001 and his MSEE \nwith an emphasis in microwave communications in 2004 n \nGaylon McSmith\t is currently the \n2001 Mars Odyssey Project \nManager.  McSmith has worked at \nJPL since 1985.  During that nperiod he has additionally worked \non projects such as Galileo, Deep \nSpace One and Outer Planets – \nSolar Probe.  Areas of expertise \ninclude Developmental System \nEngineering, Assembly Test and \nLaunch Operations Payload Integration & Flight \nOperations and Project Management. . \n \nChristopher L. Potts is the Mission nManager for the Mars 2001 Odyssey \nProject at the Jet Propulsion \nLaboratory. He has 28 years of \nexperience at JPL including Deputy \nNavigation Team Chief for the Mars \nExploration Rovers Project and a \ntechnical group supervisor. He \nreceived a B.S. in Aero/Astro \nEngineering from the University of \nIllinois and a M.S. in Aerospace Engineering from the \nUniversity of Southern California.. \n \nBrian Schratz is the lead engineer \nfor the EDL telecommunications \non the Mars Science Laboratory \nmission and a member of JPL's \nCommunications Systems and \nOperations group.    He joined \nJPL three years ago with a \nB.S.E.E. and M.S.E.E. from The nPennsylvania State University. \n \nMazen Shihabi is the operation \nlead for MRO UHF radio. Prior \nJPL assignments included modem \ndesign and modulation algorithm \ndevelopment. Prior to JPL, he \nworked for 10 years in aerospace, \ncellular telecommunications, and \nremote patient monitoring . Dr. \n 978-1-4673-1813-6/13/$31.00 ©2013 IEEE \n 14 \nShihabi is a senior member of IEEE and has published \nseveral technical papers and holds several patents related \nto synchronization algorithms, interference mitigation nand physiological alarm notification systems. He received \na BS and MS from University of Southern California, and \nPhD from University of California at Irvine, all in \nElectrical engineering.  \n \nJeff Srinivasan is currently the \nDeputy Manager for the \nCommunications, Tracking and \nRadar Division at NASA's Jet \nPropulsion Laboratory, where he \nhas worked for 29 years. He \npreviously managed of Flight nCommunications Systems Section \n\(337 nDevelopment Group. In addition, he has provided \nleadership and key contributions to some of JPL's most nchallenging flight implementations. He was one of the \nearly key developers of the BlackJack family of flight GPS \nreceivers for precision tracking and science that flew on \nthe successful GRACE and COSMIC spacecraft launched \nthe early/mid 2000's. More recently he has had key roles \non MSL's CheMin X-ray Source and  Landing Radar \ndevelopment teams and co-led the final push to prepare \nrelay communications for MSL's arrival at Mars He has \nauthored or co-authored more than 30 publications and \nholds a Bachelors degree from Harvard College and a \nMasters degree from USC.. \n \nPhil Varghese currently \nmanages NASA's Mars \nReconnaissance Orbiter \(MRO nMission. MRO provides UHF \ndata relay support to MSL and \nMER. Previously he was Project \nManager for NASA's 2001 Mars \nOdyssey \(ODY nSteve Sanders Stephen S. \nSanders is the Odyssey \nspacecraft team lead at \nLockheed Martin Space Systems nCompany. He has worked on \nOdyssey since 2005 and its relay \nsupport of the Mars Exploration \nRovers Phoenix, and now the \nMars Science Laboratory. His \nprevious Mission Operations \nexperience was on Magellan the Venus Radar Mapper. \nHe holds a B.S. in Computer Science and Applied \nMathematics from Colorado State University and an \nMCIS with Software Engineering emphasis from \nUniversity College at the University of Denver. \n \nMichel Denis is the Spacecraft \nOperations Manager for Mars \nExpress and has covered all phases \nof this ESA science mission from \npreparation through routine \noperation in orbit, including relay \nsupport to the NASA landers on \nMars. He joined the European \nSpace Agency as a flight control \nteam engineer for 


Meteosat, and \nthen worked on Cluster, Huygens and XMM-Newton.   \nBefore joining ESA he was employed in the aerospace \nindustry in France, where he developed embedded \nsoftware systems. He graduated as an engineer in the \nEcole Centrale de Paris, and later obtained a master's \ndegree in Space Engineering. \n \n 


the?Vdeorbit is computed based on a change of\nsemimajor axis from the current circular orbit to an elliptical\norbit that has the perigee at 0km and the apogee at the orbit\naltitude:\n?Vdeorbit,drag = ?V \(r, r RE , r, r 23 semimajor axis from the\ncurrent circular orbit to an elliptical orbit that has the same\nperigee and a slightly higher apogee:\n?Vdeorbit,SRP = ?V \(r, r, r, r + ?h, r 24 are due to the GEO restricted zone, the\n35km are to allow for gravitational perturbations, and the\nremaining margin depends on the magnitude of the effect of\nsolar radiation pressure on the spacecraft \(the larger the ef-\nfect, the larger the margin the spacecraft.\nOnce the ?V has been calculated, it is possible to compute\nthe propellant mass required to satisfy this ?V budget. The\ntool assumes that ?Vinj is performed by the apogee kick\nmotor \(AKM other ?V are performed by the\nADCS subsystem. For each of these propulsion systems, the\npropellant mass can be computed using the rocket equation:\n?Vj = gIsp,j log\nmi\nmf\n\(25 which can be\ndifferent for the AKM and the ADCS subsystem, mi is the\ninitial mass with propellant and mf is the final mass without\nthe propellant.\nAttitude Determination and Control and Propulsion Subsys-\ntem—The mass of the ADCS is mostly given by the mass\nof the sensors and the mass of the actuators. The mass\nof the sensors is driven by the attitude knowledge accuracy\nrequirement acc \(Equation 26 satisfy by the momentum storage h required \(Equation 27 26 27 that acc can vary depending on the architecture, as the\npointing requirements of a high gain antenna, or an optical\npayload, are very different from those of a low gain antenna.\nConcerning the momentum storage h, it is assumed to be\nsized to counter the different disturbance torques produced by\natmospheric drag, gravity gradient, solar radiation pressure,\nor the Earth’s magnetic field. Expressions for these distur-\nbance torques were taken from [25].\nIn addition to sensors and actuators, the ADCS has additional\nmass that can be estimated as a fix fraction of the spacecraft\ndry mass:\nmADCS = 3msen + 4mact + 0.01mdry \(28 subsystem, the mass of the AKM\ncan be estimated from its propellant mass assuming a certain\nmass fraction:\nmAKM =\n\(1 29 structure subsystem\nSubsystem k\nThermal 0.0607\nAvionics 0.0983\nStructure 0.5462\nThermal, avionics, and structure subsystems—The thermal,\navionics, and structure subystems are designed using simple\nparametrics of the form msubsystem = kmpayload. The\nconstans k that are used for each subsystem are summarized\nin Table 8.\nThe mass of the launch adapter mLA = 0.01mdry is added\nto the mass of the spacecraft.\nUpdate spacecraft mass and dimensions—After the first iter-\nation, the dry and wet mass of the spacecraft are updated.\nDimensions are estimated assuming a perfect cube of 100\nkg/m3. The mass and dimensions of the solar panels are\ntaken into account to update the inertial properties of the\nspacecraft, as illustrated in Equation 30:\nLA = 1.5s+ 0.5\n?\nAa\n2\nIz = 0.01mdry\nIx = Iy = Iz + L\n2\naMa \(30 design algorithm is\niterative because several feedback loops appear in the N2\nmatrix showing the dependences between different modules\nin the algorithm. For instance, the mass of the ADCS depends\non the mass of the spacecraft, which obviously depends on the\nmass of the ADCS. Thus, a set of convergence criteria need\nto be defined. The convergence criteria used by the tool are\ndescribed in Equation 31:\n|mdry,i+1 ?mdry,i| < 10kg 31 the current status of the MIT archi-\ntecture study for the SCaN system. The study consists of a\nstakeholder analysis to identify the primary stakeholders and\ntheir needs, and the development of a computational tool to\nexplore the architectural tradespace.\nSeveral interviews have been conducted with experts at\nNASA to elicit the potential requirements on SCaN from\ndifferent user communities.\nThe major architectural decisions to be made by the SCaN\nprogram have been identified and encoded in a mathematical\nmodel. A computational tool has been developed that can\nautomatically enumerate and evaluate thousands of different\nSCaN architectures. This tool contains both a performance\nand a cost model.\nNext Steps\nThe next steps include calibration of the optical link budget\ncalculations, comparisons of the network scheduling calcula-\ntions with historical TDRSS load data, and validation of the\nspacecraft sizing algorithm with real TDRS data. Following\nthe completion of the stakeholder analysis, the tool will be\nbe used to explore the architectural tradespace and identify\na subset of preferred architectures worth studying in more\ndetail. These architectures could then be analyzed in NASA’s\nArchitecture Development Lab \(ADL NNX11AR70G.\nThe authors would also like to thank the Centre de Formacio\nInterdisciplina`ria Superior and the Cellex Foundation for\npartially funding this project.\nREFERENCES\n[1] S. Tsiao, Read you loud and clear! The story of NASA’s\nspaceflight tracking and data network. Washington\nDC: Library of Congress, 2007.\n[2] G. Maral Satellite Communication Systems: systems,\ntechniques and technology, 2009.\n[3] K. Y. Jo, “Satellite 


communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[4] E. Jennings and D. Heckman, “Architecture Modeling\nand Performance Characterization of Space Communi-\ncations and Navigation \( SCaN  R. Borgen, S. Nguyen, J. Segui, T. Stoe-\nnescu, S.-y. Wang, and S. Woo, “Space Communica-\ntions and Navigation SCaN Astronautics, no. August, pp. 1–11,\n2009.\n[6] E. Jennings and D. Heckman, “Performance Charac-\nterization of Space Communications and Navigation\n\(SCaN Mar. 2008.\n[7] J. Alonso and K. Fall, “A Linear Programming For-\nmulation of Flows over Time with Piecewise Constant\nCapacity and Transit Times piecewise constant capacity\nand transit times,” 2003.\n[8] B. L. Murphy High Resolution Satellite Communica-\ntion Simulation,” 2000.\n[9] M. Werner, A. Jahn, E. Lutz, and A Bottcher, “Analysis\nof System Parameters for LEO/ICO-Satellite Commu-\nnication Networks,” 1995.\n[10] T Weilkiens, Systems engineering with SysML/UML:\nmodeling, analysis, design. Heidelberg, Germany: The\nMorgan Kaufmann/OMG Press, 2006.\n[11] M. Rao, S. Ramakrishnan, and C. Dagli, “Modeling and\nSimulation of Net Centric System of Systems Using\nSystems Modeling Language and Colored Petri-nets :\nA Demonstration Using the Global Earth Observation\n14\nSystem of Systems,” Systems Engineering, vol. 11,\nno. 3, pp. 203–220, 2008.\n[12] B. H. Y Koo, W. L. Simmons, and E. F. Crawley, “Al-\ngebra of Systems: A Metalanguage for Model Synthesis\nand Evaluation,” IEEE Transactions on Systems, Man,\nand Cybernetics - Part A: Systems and Humans, vol. 39,\nno. 3 pp. 501–513, May 2009.\n[13] M. Ehrgott and X. Gandibleux, “A Survey and An-\nnotated Bibliography of Multiobjective Combinatorial\nOptimization,” OR Spectrum, vol. 22, no. 4, pp. 425–\n460, Nov. 2000.\n[14] D Selva, “Rule-based system architecting of Earth\nobservation satellite systems,” PhD dissertation Mas-\nsachusetts Institute of Technology, 2012.\n[15] D. Selva and E. F. Crawley, “VASSAR: Value Assess-\nment of System Architectures using Rules,” in Proceed-\nings of the 2013 IEEE Aerospace Conference, Big Sky,\nMontana 2013.\n[16] T. Sutherland, B. Cameron, and E. Crawley, “Program\ngoals for the nasa/noaa earth observation program de-\nrived from a stakeholder value network analysis,” 2012.\n[17] B. Cameron, E. Crawley, G. Loureiro and E. Reben-\ntisch, “Value flow mapping: Using networks to inform\nstakeholder analysis,” Acta Astronautica vol. 62, pp.\n324–333, 2008.\n[18] B. Cameron and Crawley, “Goals for space exploration\nbased on stakeholder network value considerations,”\nActa Astronautica, vol. 68, pp. 2088–2097, 2011.\n[19] D. Selva and E. F Crawley, “Integrated Assessment of\nPackaging Architectures in Earth Observing Programs,”\nin Proceedings of the 2011 IEEE Aerospace Confer-\nence, Big Sky, Montana, 2010.\n[20] O. P. Gupta and C. S. Fish, “Iridium NEXT: A Global\naccess for your sensor needs,” in Proceedings of the\n2010 American Geophysical Union Fall Meeting San\nFrancisco, CA, 2010.\n[21] T. Stoenescu and L. Clare, “Traffic Modeling for\nNASA’s Space Communications and Navigation\n\(SCaN  communications with Internet Pro-\ntocol \(IP Conference, pp. 1–7, Oct. 2009.\n[23] H. Apgar, “Cost Estimating,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 11.\n[24] R. S. Bokulic, C. C. DeBoy, S. W. Enger, J. P. Schnei-\nder and J. K. McDermott, “Spacecraft Subsystems IV\nCommunications and Power,” in Space Mission Engi-\nneering: The new SMAD. Hawthorne, CA: Microcosm,\n2011, ch. 21.\n[25] P. Springmann and O. de Weck, “Parametric scaling\nmodel for nongeosynchronous communications satel-\nlites,” Journal of spacecraft and rockets, vol. 41, no. 3,\npp 472–477, 2004.\nBIOGRAPHY[\nMarc Sanchez is a senior student from\nUniversitat Politecnica de Catalunya\n\(Barcelona, Spain Telecommunications En-\ngineering. His is currently a Visiting\nStudent at the Space System Architecture\nGroup of MIT, focusing his interests in\nrule-based expert systems and how they\ncan be applied to space communications\nnetworks. Prior to his work at MIT, Marc has been a\nsoftware engineer at Sener Ingenieria y Sistemas involved in\nthe development of commercial software FORAN CAD/CAM.\nDr. Daniel Selva received a PhD in\nSpace Systems from MIT in 2012 and\nhe is currently a post-doctoral associate\nin the department of Aeronautics and\nAstronautics at MIT. His research inter-\nests focus on the application of multi-\ndisciplinary optimization and artificial\nintelligence techniques to space systems\nengineering and architecture, in partic-\nular in the context of Earth observa-\ntion missions. Prior to MIT, Daniel worked for four years\nin Kourou \(French Guiana in\noperations concerning the guidance, navigation and control\nsubsystem, and the avionics and ground systems Daniel has\na dual background in electrical engineering and aeronautical\nengineering, with degrees from Universitat Politecnica de\nCatalunya in Barcelona, Spain, and Supaero in Toulouse,\nFrance. He is a 2007 la Caixa fellow, and received the Nortel\nNetworks prize for academic excellence in 2002.\nDr. Bruce Cameron is a Lecturer\nin Engineering Systems at MIT and a\nconsultant on platform strategies. At\nMIT, Dr. Cameron ran the 


MIT Com-\nmonality study, a 16 firm investigation\nof platforming returns. Dr. Cameron’s\ncurrent clients include Fortune 500 firms\nin high tech, aerospace, transportation,\nand consumer goods. Prior to MIT,\nBruce worked as an engagement man-\nager at a management consultancy and as a system engineer\nat MDA Space Systems, and has built hardware currently in\norbit. Dr. Cameron received his undergraduate degree from\nthe University of Toronto, and graduate degrees from MIT.\nDr. Edward F. Crawley received an\nSc.D. in Aerospace Structures from MIT\nin 1981. His early research interests\ncentered on structural dynamics, aeroe-\nlasticity, and the development of actively\ncontrolled and intelligent structures. Re-\ncently, Dr. Crawleys research has fo-\ncused on the domain of the architecture\nand design of complex systems. From\n1996 to 2003 he served as the Depart-\nment Head of Aeronautics and Astronautics at MIT, leading\nthe strategic realignment of the department Dr. Crawley is a\nFellow of the AIAA and the Royal Aeronautical Society \(UK academies of engineering.\n15\nHe is the author of numerous journal publications in the\nAIAA Journal, the ASME Journal, the Journal of Composite\nMaterials, and Acta Astronautica. He received the NASA\nPublic Service Medal Recently, Prof Crawley was one of\nthe ten members of the presidential committee led by Norman\nAugustine to study the future of human spaceflight in the US.\nBernard D. Seery is the Assistant Di-\nrector for Advanced Concepts in the Of-\nfice of the Director at NASA’s Goddard\nSpace Flight Center \(GSFC include assisting the Deputy\nDirector for Science and Technology\nwith development of new mission and\nmeasurement concepts, strategic analy-\nsis, strategy development and investment\nresources prioritization Prior assign-\nments at NASA Headquarters included Deputy for Advanced\nPlanning and Director of the Advanced Planning and In-\ntegration Office \(APIO and Evaluation \(PA&E DAA and Physical Research \(OBPR Directorate, Code 600, at \(GSFC bachelors of science in physics, with emphasis in\nnuclear physics. He then attended the University of Ari-\nzona’s School of Optical Sciences, and obtained a masters\ndegree in Optical Sciences, specializing in nonlinear optical\napproaches to automated alignment and wavefront control\nof a large, electrically-pumped CO2 laser fusion driver. He\ncompleted all the course work for a PhD in Optical Sciences\nin 1979, with emphasis in laser physics and spectroscopy. He\nhas been a staff member in the Laser Fusion Division \(L-\n1 Alamos National Laboratories \(LANL working on innovative infrared laser auto-alignment\nsystems and infrared interferometry for target alignment for\nthe HELIOS 10 kilojoule, eight-beam carbon dioxide laser\nfusion system. In 1979 he joined TRW’s Space and Defense\norganization in Redondo Beach, CA and designed and de-\nveloped several high-power space lasers and sophisticated\nspacecraft electro-optics payloads. He received the TRW\nPrincipal Investigators award for 8 consecutive years.\nDr. Antonios A. Seas is a Study Man-\nager at the Advanced Concept and For-\nmulation Office ACFO Electro-Optics branch where\nhe focused on optical communications\nand the development of laser systems\nfor space applications. Prior to joining\nNASA in 2005 he spent several years in\nthe telecommunication industry developing long haul sub-\nmarine fiber optics systems, and as an Assistant Professor\nat the Bronx Community College. Antonios received his\nundergraduate and graduate degrees from the City College of\nNew York, and his doctoral degree from the Graduate Center\nof the City University of New York. He is also a certified\nProject Management Professional.\n16\n 


1483\nSUB-NYQUIST SAMPLING RATES\nMustafa Al-Ani, University of Westminster, United Kingdom; Bashar Ahmad, University of Cambridge, \nUnited Kingdom; Andrzej Tarczynski University of Westminster, United Kingdom\nTPa-8.10: OPPORTUNISTIC TRANSMITTER SELECTION FOR SELFLESS 1488\nOVERLAY COGNITIVE RADIOS\nMohammad Shaqfeh, Texas A&M University at Qatar, Qatar; Ammar Zafar, King Abdullah University \nof Science and Technology, Saudi Arabia Hussein Alnuweiri, Texas A&M University at Qatar, Qatar; \nMohamed-Slim Alouini, King Abdullah University of Science and Technology, Saudi Arabia\nTPa-8.11: A GAME THEORETIC POWER CONTROL FRAMEWORK FOR 1493\nSPECTRUM SHARING IN COMPETITIVE ENVIRONMENTS\nRaghed El-Bardan, Swastik Brahma, Pramod K. Varshney, Syracuse University, United States\nTPa-8.12: COGNITIVE RADIO TRANSMISSION STRATEGIES FOR PRIMARY ...........................................1498\nERASURE CHANNELS\nAhmed ElSamadouny, University of Texas at Dallas, United States; Mohammed Nafie, Ahmed Sultan, \nNile University Egypt\nTPa-8: RELAYS IN COMMUNICATIONS\nTPa-8.1: OPTIMIZED RECEIVER DESIGN FOR DECODE-AND-FORWARD 1535\nRELAYS USING HIERARCHICAL MODULATION\nTu Nguyen, Broadcom Corporation, United States; Pamela Cosman, Laurence Milstein, University of \nCalifornia, San Diego, United States\nTPa-8.2: OPTIMAL LINEAR-COMBINING RECEIVER FOR 1540\nDECODE-AND-FORWARD RELAYS USING SUPERPOSITION CODING\nTu Nguyen, Broadcom Corporation, United States; Laurence Milstein, University of California, San \nDiego, United States\nTPa-8.3: ALTERNATE RELAYING AND THE DEGREES OF FREEDOM OF 1545\nONE-WAY CELLULAR RELAY NETWORKS\nAya Salah, Amr El-Keyi Mohammed Nafie, Nile University, Egypt\nTPa-8.4: DISTRIBUTED AF BEAMFORMING RELAY NETWORKS UNDER 1550\nTRANSMIT POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon Edwin M. Sawan, Wichita State University, United States; Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nTPa-8.5: JOINT TRANSMIT DESIGN AND NODE SELECTION FOR 1555\nONE-WAY AND TWO-WAY UNTRUSTED RELAY CHANNELS\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.6: WIRELESS PHYSICAL LAYER SECURITY ENHANCEMENT WITH  ..............................................1560\nBUFFER-AIDED RELAYING\nJing Huang, A. Lee Swindlehurst, University of California, Irvine, United States\nTPa-8.7: TRAINING SLOT ALLOCATION FOR MITIGATING ESTIMATION  ................................................1565\nERROR PROPAGATION IN A TWO-HOP RELAYING SYSTEM\nQian Gao, Gang Chen, Yingbo Hua, University of California, Riverside United States\nxxv\nTPa-8.8: TRANSMIT OUTAGE PRE-EQUALIZATION FOR 1570\nAMPLIFY-AND-FORWARD RELAY CHANNELS\nFernando Sanchez, Gerald Matz, Vienna University of Technology, Austria\nTPa-8: ADAPTIVE FILTERING\nTPa-8.1: A GRADIENT-CONTROLLED IMPROVED PROPORTIONATE 1505\nMULTI-DELAY FILTER\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nTPa-8.2: COMPLEX PROPORTIONATE-TYPE AFFINE PROJECTION  ...........................................................1510\nALGORITHMS\nKevin Wagner Naval Research Laboratory, United States; Miloš Doroslovacki, George Washington \nUniversity, United States\nTPa-8.3: RADAR WAVEFORM DESIGN IN ACTIVE COMMUNICATIONS 1515\nCHANNEL\nKevin Shepherd, Ric Romero, Naval Postgraduate School, United States\nTPa-8.4: THE LEAKY LEAST MEAN MIXED NORM ALGORITHM................................................................1520\nMohammed Abdul Nasar, Azzedine Zerguine, King Fahd University of Petroleum & Minerals, Saudi \nArabia\nTPa-8.5: A NEW VARIABLE STEP-SIZE ZERO-POINT ATTRACTING  ...........................................................1524\nPROJECTION ALGORITHM\nJianming Liu, Steven Grant, Missouri University of Science and Technology, United States\nTPa-8.6 RECURSIVE LEAST SQUARES FILTERING UNDER STOCHASTIC 1529\nCOMPUTATIONAL ERRORS\nChandrasekhar Radhakrishnan, Andrew Singer, University of Illinois at Urbana-Champaign, United \nStates\nTPa-8: CELLULAR AND HETEROGENEOUS NETWORKS\nTPa-8.1: DOWNLINK COVERAGE ANALYSIS OF N-TIER 1577\nHETEROGENEOUS CELLULAR NETWORKS BASED ON CLUSTERED STOCHASTIC \nGEOMETRY\nChunlin Chen, Robert Elliott, Witold Krzymien, University of Alberta / Telecommunications Research \nLaboratories, Canada\nTPa-8.2: SYSTEM-LEVEL PERFORMANCE OF THE MIMO-OFDM 1582\nDOWNLINK WITH DENSE SMALL CELL OVERLAYS\nThomas Wirth, Bernd Hofeld, Fraunhofer Heinrich Hertz Institute, Germany\nTPa-8.3: ADAPTIVE HARQ AND SCHEDULING FOR VIDEO OVER LTE......................................................1584\nAvi Rapaport, Weimin 


Liu, Liangping Ma, Gregory S. Sternberg, Ariela J. Zeira, Anantharaman \nBalasubramanian, InterDigital, United States\nTPa-8.4: NOVEL PARTIAL FEEDBACK SCHEMES AND THEIR EVALUATION 1589\nIN AN OFDMA SYSTEM WITH CDF BASED SCHEDULING\nAnh Nguyen University of California, San Diego, United States; Yichao Huang, Qualcomm \nTechnologies, Inc., United States Bhaskar D. Rao, University of California, San Diego, United States\nTPa-8.5: OPPORTUNISTIC THIRD-PARTY BACKHAUL FOR CELLULAR  ...................................................1594\nWIRELESS NETWORKS\nRussell Ford, Changkyu Kim, Sundeep Rangan, Polytechnic Institute of New York University, United \nStates\nTPa-8.6: PROACTIVE USER ASSOCIATION IN WIRELESS SMALL CELL  ...................................................1601\nNETWORKS VIA COLLABORATIVE FILTERING\nFrancesco Pantisano, Joint Research Center, Italy; Mehdi Bennis, University of Oulu Finland; Walid \nSaad, University of Miami, United States; Stefan Valentin, Bell Labs, Alcatel-Lucent, Germany nMérouane Debbah, Supélec, France; Alessio Zappone, Technische Universität Dresden, Germany\nTPa-8.7 INTERFERENCE ANALYSIS OF MULTI-HOP CELLULAR SENSOR 1606\nNETWORKS\nYeashfi Hasan, R. Michael Buehrer, Virginia Polytechnic Institute and State University, United States\nxxvi\nTPb-1: FULL-DUPLEX MIMO COMMUNICATIONS II\nTPb-1.1: DIVERSITY-MULTIPLEXING TRADEOFF ANALYSIS OF MIMO 1613\nRELAY NETWORKS WITH FULL-DUPLEX RELAYS\nQiang Xue University of Oulu, Finland; Anna Pantelidou, Renesas Mobile Europe, Finland; Behnaam \nAazhang, Rice University, United States\nTPb-1.2: ERGODIC MUTUAL INFORMATION OF FULL-DUPLEX MIMO 1618\nRADIOS WITH RESIDUAL SELF-INTERFERENCE\nAli Cagatay Cirik, University of California, Riverside, United States; Yue Rong, Curtin University, \nAustralia; Yingbo Hua, University of California, Riverside, United States\nTPb-1.3: FULL-DUPLEX IN LARGE-SCALE WIRELESS SYSTEMS 1623\nBei Yin, Michael Wu, Christoph Studer Joseph R. Cavallaro, Rice University, United States; Jorma \nLilleberg, Broadcom, United States\nTPb-1.4 FULL-DUPLEX COMMUNICATION VIA ADAPTIVE NULLING......................................................1628\nScott Johnston, Paul Fiore, Massachusetts Institute of Technology, United States\nTPb-1.5: WEIGHTED-SUM-RATE MAXIMIZATION FOR BI-DIRECTIONAL  ...............................................1632\nFULL-DUPLEX MIMO SYSTEMS\nAli Cagatay Cirik, University of California, Riverside, United States; Rui Wang, The Chinese nUniversity of Hong Kong, Hong Kong SAR of China; Yingbo Hua, University of California, Riverside, \nUnited States\nTPb-2: PHY PERFORMANCE ABSTRACTION TECHNIQUES\nTPb-2.1: STOCHASTIC DYNAMIC MODELS IN PHY ABSTRACTION 1639\nFrancesc Rey, Josep Sala-Alvarez, Technical University of Catalonia, Spain\nTPb-2.2: ON SCALABILITY, ROBUSTNESS AND ACCURACY OF PHYSICAL 1644\nLAYER ABSTRACTION FOR LARGE-SCALE SYSTEM LEVEL EVALUATIONS OF LTE \nNETWORKS\nFlorian Kaltenberger, Imran Latif, Raymond Knopp, Eurecom, France\nTPb-2.3: LINK ADAPTATION IN MIMO-OFDM WITH PRACTICAL 1649\nIMPAIRMENTS\nAlberto Rico-Alvarino University of Vigo, Spain; Robert W. Heath, Jr., University of Texas at Austin, \nUnited States\nTPb-2.4 DIGITAL PRE-DISTORTION OF RADIO FREQUENCY 1654\nFRONT-END IMPAIRMENTS IN THE DESIGN OF SPECTRALLY AGILE MULTICARRIER \nTRANSMISSION \nZhu Fu, Alexander Wyglinski, Worcester Polytechnic Institute United States\nTPb-2.5: SYSTEM-LEVEL INTERFACES AND PERFORMANCE EVALUATION 1659\nMETHODOLOGY FOR 5G PHYSICAL LAYER BASED ON NON-ORTHOGONAL nWAVEFORMS\nGerhard Wunder, Martin Kasparick, Fraunhofer Heinrich Hertz Institute, Germany; Stephan Ten \nBrink University of Stuttgart, Germany; Frank Schaich, Thorsten Wild, Yejian Chen, Bell Labs, \nAlcatel-Lucent Germany; Ivan Gaspar, Nicola Michailow, Gerhard Fettweis, Technische Universität \nDresden, Germany; Dimitri Ktenas, Nicolas Cassiau, Commissariat à l’énergie atomique et aux \nénergies alternatives, France; Marcin Dryjanski, Kamil Sorokosz, Slawomir Pietrzyk, IS-Wireless, \nPoland; Bertalan Eged, National Instruments Hungary\nTPb-3: LOW-DIMENSIONAL SIGNAL MODELS\nTPb-3.1: NEAREST SUBSPACE CLASSIFICATION WITH MISSING DATA 1667\nYuejie Chi, The Ohio State University, United States\nTPb-3.2: REFLECTIONS ON SAMPLING-FILTERS FOR COMPRESSIVE 1672\nSENSING AND FINITE-INNOVATIONS-RATE MODELS\nP. P Vaidyanathan, Srikanth Tenneti, California Institute of Technology, United States\nTPb-3.3: IDENTIFIABILITY BOUNDS FOR BILINEAR INVERSE 1677\nPROBLEMS\nSunav Choudhary, Urbashi Mitra, University of Southern California, United States\nTPb-3.4: LOAD FORECASTING VIA LOW RANK AND SPARSE 


MATRIX  ...................................................1682\nFACTORIZATION\nSeung-Jun Kim, Georgios B Giannakis, University of Minnesota, United States\nxxvii\nTPb-3.5: SEMI-BLIND SOURCE SEPARATION VIA SPARSE 1687\nREPRESENTATIONS AND ONLINE DICTIONARY LEARNING\nSirisha Rambhatla, Jarvis Haupt, University of Minnesota - Twin Cities, United States\nTPb-4: LOCATION-AWARE NETWORKING\nTPb-4.1: ROBUST LINK SCHEDULING WITH CHANNEL ESTIMATION 1695\nAND LOCATION INFORMATION\nSrikar Muppirisetty, Rocco Di Taranto, Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.2: SIMULTANEOUS ROUTING AND POWER ALLOCATION USING  .................................................1700\nLOCATION INFORMATION\nRocco Di Taranto Henk Wymeersch, Chalmers University of Technology, Sweden\nTPb-4.3: LOCATION AWARE TRAINING SCHEME FOR D2D NETWORKS ..................................................1705\nDaoud Burghal, Andreas F. Molisch, University of Southern California, United States\nTPb-4.4: A COOPERATIVE HIGH-ACCURACY LOCALIZATION ALGORITHM 1709\nFOR IMPROVED ROAD WORKERS’ SAFETY\nSankalp Dayal, Adam Mortazavi, Khanh H. Huynh, University of California, Santa Barbara, United \nStates; Ramez L. Gerges California Department of Transportation, United States; John J. Shynk, \nUniversity of California, Santa Barbara, United States\nTPb-4.5: REAL-TIME ENERGY STORAGE MANAGEMENT WITH 1714\nRENEWABLE ENERGY OF ARBITRARY GENERATION DYNAMICS\nTianyi Li, Min Dong, University of Ontario Institute of Technology, Canada\nTPb-5: ANALYSIS OF COMPLEX BIOLOGICAL SYSTEMS AND OMICS DATA II\nTPb-5.2: STATISTICAL VALIDATION OF PARAMETRIC APPROXIMATIONS TO 1721\nTHE MASTER EQUATION\nGarrett Jenkinson, John Goutsias, The Johns Hopkins University, United States\nTPb-5.4: A MESSAGE-PASSING ALGORITHM FOR HAPLOTYPE ASSEMBLY 1726\nZrinka Puljiz, Haris Vikalo, University of Texas at Austin United States\nTPb-6: TARGET TRACKING I\nTPb-6.1: TRACK STATE AUGMENTATION FOR ESTIMATION OF 1733\nPROBABILITY OF DETECTION IN MULTISTATIC SONAR DATA\nEvan Hanusa, David Krout, University of Washington, United States\nTPb-6.2: HYPOTHESIS STRUCTURE IN ENHANCED 1738\nMULTIPLE-HYPOTHESIS TRACKING\nStefano Coraluppi, Craig Carthel, Compunetix Inc., United States; Marco Guerriero, SAIRA/FAR nAMERICAS Inc., United States\nTPb-6.3: SPLINE PROBABILITY HYPOTHESIS DENSITY FILTER FOR 1743\nNONLINEAR MANEUVERING TARGET TRACKING\nRajiv Sithravel, Xin Chen, McMaster University, Canada; Mike McDonald, Defence Research and \nDevelopment Canada Canada; Thia Kirubarajan, McMaster University, Canada\nTPb-6.4: PERFORMANCE ANALYSIS OF THE CONVERTED RANGE RATE  ...............................................1751\nAND POSITION LINEAR KALMAN FILTER\nSteven Bordonaro Naval Undersea Research Center, United States; Peter Willett, Yaakov Bar-Shalom, \nUniversity of Connecticut United States\nTPb-6.5: MAP-PF MULTITARGET TRACKING WITH PROPAGATION 1756\nMODELING UNCERTAINTIES\nKristine Bell, Robert Zarnich, Metron, United States\nTPb-7: MACHINE LEARNING AND STATISTICAL SIGNAL PROCESSING II\nTPb-7.1 FORWARD/BACKWARD STATE AND MODEL PARAMETER 1763\nESTIMATION FOR CONTINUUM-STATE HIDDEN MARKOV MODELS \(CHMM States\nxxviii\nTPb-7.2: LOW-RANK KERNEL LEARNING FOR ELECTRICITY MARKET 1768\nINFERENCE\nVassilis Kekatos, Yu Zhang, Georgios B Giannakis, University of Minnesota, United States\nTPb-7.3: HIERARCHICAL CLUSTERING METHODS AND ALGORITHMS 1773\nFOR ASYMMETRIC NETWORKS\nGunnar Carlsson, Stanford University, United States; Facundo Mémoli, University of Adelaide, \nAustralia; Alejandro Ribeiro, Santiago Segarra, University of Pennsylvania, United States\nTPb-7.5: ACHIEVING COMPLETE LEARNING IN MULTI-ARMED BANDIT 1778\nPROBLEMS\nSattar Vakili, Qing Zhao, University of California, Davis, United States\nTPb-8: DESIGN AUTOMATION\nTPb-8.1: MPMAP: A HIGH LEVEL SYNTHESIS AND MAPPING TOOL FOR  ................................................1785\nMPSOCS\nAmr Hussien, Ahmed M. Eltawil University of California, Irvine, United States; Rahul Amin, Jim \nMartin, Clemson University, United States\nTPb-8.2: SOFTWARE TOOL FOR FPGA BASED MIMO RADAR APPLICATIONS 1792\nAmin Jarrah, Mohsin M. Jamali, University of Toledo, United States\nTPb-8.3: MULTI-CLOCK DOMAIN OPTIMIZATION FOR 1796\nRECONFIGURABLE ARCHITECTURES IN HIGH-LEVEL DATAFLOW APPLICATIONS\nSimone Casale-Brunet, Endri Bezati, Claudio Alberti, Marco 


Mattavelli, École Polytechnique Fédérale \nde Lausanne \(EPFL Milano, Italy; Jörn Janneck, Lund \nUniversity, Sweden\nTPb-8.4: ACTOR CLASSIFICATION USING ACTOR MACHINES 1801\nGustav Cedersjö, Jörn Janneck, Lund University, Sweden\nTPb-8.5: SYSTEMS DESIGN SPACE EXPLORATION BY SERIAL DATAFLOW 1805\nPROGRAM EXECUTIONS\nSimone Casale-Brunet, Marco Mattavelli Claudio Alberti, École Polytechnique Fédérale de Lausanne \n\(EPFL Sweden\nTPb-8.7: REAL-TIME RADAR SIGNAL PROCESSING ON MASSIVELY 1810\nPARALLEL PROCESSOR ARRAYS\nZain Ul-Abdin, Halmstad University, Sweden; Anders Åhlander, Saab AB, Sweden; Bertil Svensson, \nHalmstad University, Sweden\nTPb-8.8 ALGORITHM AND ARCHITECTURE CO-DESIGN OF MIXTURE  ..................................................1815\nOF GAUSSIAN \(MOG States; Robert Bushey, Analog Devices Inc., \nUnited States; Gunar Schirner Schirner, Northeastern University United States\nTPb-8: MULTIUSER MIMO SYSTEMS\nTPb-8.1: MULTI-USER MIMO SCHEDULING IN THE FOURTH 1855\nGENERATION CELLULAR UPLINK\nNarayan Prasad, NEC Laboratories America, Inc., United States; Honghai Zhang, Google, United \nStates; Hao Zhu University of Illinois at Urbana-Champaign, United States; Sampath Rangarajan, \nNEC Laboratories America Inc., United States\nTPb-8.2: OPTIMAL DOF REGION OF THE TWO-USER MISO-BC WITH 1860\nGENERAL ALTERNATING CSIT\nJinyuan Chen, Petros Elia Eurecom, France\nTPb-8.3: EXPLOITING SPATIAL SPECTRUM HOLES IN MULTIUSER 1865\nMIMO SYSTEMS\nFeeby Salib, Karim Seddik, American University in Cairo, Egypt\nTPb-8.4: DEGREES OF FREEDOM ACHIEVED USING SUBSPACE 1869\nALIGNMENT CHAINS FOR THREE-CELL NETWORKS\nGokul Sridharan, Wei Yu, University of Toronto, Canada\nTPb-8.5: INTERFERENCE ALIGNMENT FOR MISO BROADCAST  ...............................................................1875\nCHANNELS UNDER JAMMING ATTACKS\nSaiDhiraj Amuru, Ravi Tandon, R. Michael Buehrer, T. Charles Clancy, Virginia Tech, United States\nxxix\nTPb-8.6: PERFORMANCE STUDY OF MRC AND IRC WEIGHTS IN 1880\nLTE/LTE-A SYSTEMS WITH INTERFERENCE MANAGEMENT\nThomas Svantesson, ArrayComm, United States\nTPb-8.8: A SYSTEM-LEVEL STUDY ON MULTI-USER MIMO 1885\nTRANSMISSION FOR DENSE FDD NETWORKS\nLars Thiele, Martin Kurras, Kai Börner, Thomas Haustein, Fraunhofer HHI, Germany\nTPb-8.9 DIVERSITY-MULTIPLEXING TRADEOFF OF MIMO LINEAR 1890\nPRECODING\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nTPb-8: ELECTROPHYSIOLOGY AND BRAIN IMAGING\nTPb-8.1: JOINT COMPRESSION OF NEURAL ACTION POTENTIALS AND 1823\nLOCAL FIELD POTENTIALS\nSebastian Schmale, Benjamin Knoop, Janpeter Hoeffmann, Dagmar Peters-Drolshagen, Steffen Paul, \nUniversity of Bremen, Germany\nTPb-8.2 REDUCING THE EFFECT OF CORRELATED BRAIN SOURCES IN  ...............................................1828\nMEG USING A LINEARLY CONSTRAINED SPATIAL FILTER BASED ON MINIMUM \nNORM\nJosé Alfonso Sánchez De Lucio, David M Halliday, University of York, United Kingdom\nTPb-8.3: ONLINE BAYESIAN CHANGE POINT DETECTION ALGORITHMS 1833\nFOR SEGMENTATION OF EPILEPTIC ACTIVITY\nRakesh Malladi, Rice Unviersity, United States; Giridhar P Kalamangalam, University of Texas Health \nScience Center, United States Behnaam Aazhang, Rice Unviersity, United States\nTPb-8.4: SPIKING NEURAL NETWORKS BASED ON LIF WITH LATENCY 1838\nSIMULATION AND SYNCHRONIZATION EFFECTS\nGian Carlo Cardarilli, Alessandro Cristini, Marco Re, Mario Salerno, Gianluca Susi, University of \nRome Tor Vergata Italy\nTPb-8.5: TIME-FREQUENCY ANALYSIS OF BRAIN ELECTRICAL SIGNALS 1843\nFOR BEHAVIOUR RECOGNITION IN PATIENTS WITH PARKINSON’S DISEASE\nHuaiguang Jiang, Jun Jason Zhang, University of Denver, United States; Adam Hebb, Colorado nNeurological Institute, United States; Mohammad H. Mahoor, University of Denver, United States\nTPb-8.7: A MEASURE OF CONNECTIVITY IN THE PRESENCE OF 1848\nCROSSTALK\nSergul Aydore, Syed Ashrafulla Anand Joshi, Richard M Leahy, University of Southern California, \nUnited States\nWAa-1: MIMO INTERFERENCE MANAGEMENT\nWAa-1.1: DEGREES OF FREEDOM FOR THE CONSTANT MIMO 1897\nINTERFERENCE CHANNEL WITH COMP TRANSMISSION\nCraig Wilson, Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United 


States\nWAa-1.2: DYNAMIC INTERFERENCE MANAGEMENT 1902\nAly El Gamal Venugopal V. Veeravalli, University of Illinois at Urbana-Champaign, United States\nWAa-1.3: A MUD/RATE SELECTION TOOL FOR COGNITIVE RADIOS IN  ..................................................1907\nPACKET BASED ASYNCHRONOUS GAUSSIAN MULTIPLE ACCESS CHANNELS\nPrabahan Basu, Rachel Learned, MIT Lincoln Laboratory, United States\nWAa-1.4: PRECODER DESIGN FOR FRACTIONAL INTERFERENCE 1912\nALIGNMENT\nHari Ram Balakrishnan, Giridhar K Indian Institute of Technology Madras, India\nWAa-2: OFDM\nWAa-2.1: MIMO-OFDM OUTAGE CHANNEL CAPACITY WITH PRACTICAL  .............................................1919\nIMPERFECT CSI\nMarko Kocic, MIT Lincoln Laboratory, United States; Nicholas Chang, Applied Communication \nSciences, United States; Matthew Ferreira MIT Lincoln Laboratory, United States\nxxx\nWAa-2.2: BIASED ESTIMATION OF SYMBOL TIMING OFFSET IN OFDM 1924\nSYSTEMS\nRohan Ramlall, University of California, Irvine United States\nWAa-2.3: A FACTOR-GRAPH APPROACH TO JOINT OFDM CHANNEL 1929\nESTIMATION AND DECODING IN IMPULSIVE NOISE CHANNELS\nMarcel Nassar, University of Texas at Austin, United States; Philip Schniter, The Ohio State University, \nUnited States; Brian Evans, University of Texas at Austin, United States\nWAa-2.4: WIDELY LINEAR DATA ESTIMATION FOR UNIQUE WORD  ........................................................1934\nOFDM\nMario Huemer, Alexander Onic, Christian Hofbauer, Stefan Trampitsch, Johannes Kepler University \nLinz Austria\nWAa-3: ADAPTIVE FILTERING\nWAa-3.1: A GRADIENT-CONTROLLED PROPORTIONATE TECHNIQUE FOR 1941\nACOUSTIC ECHO CANCELLATION\nJie Yang, Texas Instruments United States; Gerald Sobelman, University of Minnesota, United States\nWAa-3.2: INTERFERENCE IDENTIFICATION IN CELLULAR NETWORKS  .................................................1946\nVIA ADAPTIVE PROJECTED SUBGRADIENT METHODS\nKonstantin Oltmann, Renato L. G. Cavalcante, Slawomir Stanczak, Martin Kasparick, Fraunhofer \nHeirinch Hertz Institute, Germany\nWAa-3.3: A RECONSIDERATION OF IMPROVED PNLMS ALGORITHM 1951\nFROM METRIC COMBINING VIEWPOINT\nOsamu Toda, Masahiro Yukawa, Keio University, Japan\nWAa-3.4: DETECTION PERFORMANCE OF MATCHED TRANSMIT 1956\nWAVEFORM FOR MOVING EXTENDED TARGETS\nRic Romero, Naval Postgraduate School, United States\nWAa-4: RELAYING AND COOPERATION\nWAa-4.1: TWO-WAY AMPLIFY-AND-FORWARD RELAY STRATEGIES  .......................................................1963\nUNDER RELAY POWER CONSTRAINT\nKanghee Lee, Hyuck M. Kwon, Edwin M. Sawan, Wichita State University, United States Hyuncheol \nPark, Korea Advanced Institute of Science and Technology, Republic of Korea\nWAa-4.2: GAUSSIAN INTERFERING RELAY CHANNELS...............................................................................1968\nHieu T. Do, Tobias J. Oechtering, Mikael Skoglund, KTH Royal Institute of Technology, Sweden; Mai \nVu, Tufts University, United States\nWAa-4.3: THROUGHPUT IMPROVEMENTS FOR CELLULAR SYSTEMS 1973\nWITH DEVICE-TO-DEVICE COMMUNICATIONS\nPhuongBang Nguyen, Bhaskar D. Rao, University of California, San Diego, United States\nWAa-4.4: COOPERATIVE SIMULTANEOUS LOCALIZATION AND  ...............................................................1978\nSYNCHRONIZATION: A DISTRIBUTED HYBRID MESSAGE PASSING ALGORITHM\nBernhard Etzlinger, Johannes Kepler University, Austria; Florian Meyer, Vienna University of \nTechnology, Austria; Andreas Springer, Johannes Kepler University, Austria; Franz Hlawatsch, Vienna \nUniversity of Technology, Austria; Henk Wymeersch, Chalmers University of Technology Sweden\nWAa-5: IMAGE ANALYSIS AND PROCESSING\nWAa-5.1: MULTISCALE AM-FM IMAGE RECONSTRUCTIONS BASED ON 1985\nELASTIC NET REGRESSION AND GABOR FILTERBANKS\nIoannis Constantinou, University of Cyprus, Cyprus; Marios Pattichis, University of New Mexico, \nUnited States Constantinos Pattichis, University of Cyprus, Cyprus\nWAa-5.2: COLORIZATION BASED ON PIECEWISE AUTOREGRESSIVE 1990\nMODEL\nYasuhiro Nakajima, Takashi Ueno, Taichi Yoshida, Masaaki Ikehara, Keio University, Japan\nWAa-5.3: IMAGE DENOISING BY ADAPTIVE DIRECTIONAL 1995\nLIFTING-BASED DISCRETE WAVELET TRANSFORM AND QUANTIZATION\nNaoki Furuhashi, Azusa Oota, Taichi Yoshida, Masaaki Ikehara, Keio University Japan\nxxxi\nWAa-5.4: INTRODUCING DIVERSITY TO NORMALIZED CROSS 2000\nCORRELATION FOR DENSE IMAGE REGISTRATION\nNafise Barzigar, Aminmohammad Roozgard, Pramode Verma, Samuel Cheng, University of Oklahoma nUnited States\nWAa-6: MULTI-SENSOR SIGNAL PROCESSING\nWAa-6.1: WHY DOES DIRECT-MUSIC ON SPARSE-ARRAYS WORK 2007\nP. P Vaidyanathan, Piya Pal, California 


Institute of Technology, United States\nWAa-6.2: ASYMPTOTICALLY OPTIMAL TRUNCATED HYPOTHESIS TEST 2012\nFOR A LARGE SENSOR NETWORK DESCRIBED BY A MULTIVARIATE GAUSSIAN \nDISTRIBUTION\nJiangfan Zhang, Rick Blum, Lehigh University, United States\nWAa-6.3: A JOINT LOCALIZATION AND SYNCHRONIZATION TECHNIQUE  ............................................2017\nUSING TIME OF ARRIVAL AT MULTIPLE ANTENNA RECEIVERS\nSiamak Yousefi, Xiao-Wen Chang, Benoit Champagne, McGill University Canada\nWAa-6.4: REDUCING THE FRACTIONAL RANK OF INTERFERENCE WITH 2022\nSPACE-TIME-FREQUENCY ADAPTIVE BEAMFORMING\nShawn Kraut, Adam R. Margetts, MIT Lincoln Laboratory, United States; Daniel Bliss, Arizona State \nUniversity, United States\nWAa-7: COMMUNICATION SYSTEM DESIGN\nWAa-7.1: IMPLEMENTATION OF SELECTIVE PACKET DESTRUCTION ON 2029\nWIRELESS OPEN-ACCESS RESEARCH PLATFORM\nStephen Hughes Bosheng Zhou, Roger Woods, Queen’s University Belfast, United Kingdom; Alan \nMarshall, Unievrsity of Liverpool, United Kingdom\nWAa-7.2: EFFICIENT ERROR-AWARE POWER MANAGEMENT FOR 2034\nMEMORY DOMINATED OFDM SYSTEMS\nMuhammad S Khairy, Ahmed M. Eltawil, Fadi J. Kurdahi, University of California, Irvine, United \nStates; Amin Khajeh Intel labs, United States\nWAa-7.3: FPGA IMPLEMENTATION OF A MESSAGE-PASSING OFDM 2041\nRECEIVER FOR IMPULSIVE NOISE CHANNELS\nKarl Nieman, University of Texas at Austin, United States; Marcel Nassar, Samsung Information \nSystems America United States; Jing Lin, Brian Evans, University of Texas at Austin, United States\nWAa-7.4: MOBILE TRANSMITTER DIGITAL PREDISTORTION:  ...................................................................2046\nFEASIBILITY ANALYSIS, ALGORITHMS AND DESIGN EXPLORATION\nMahmoud Abdelaziz, Tampere University of Technology, Finland Amanullah Ghazi, University of \nOulu, Finland; Lauri Anttila, Tampere University of Technology, Finland; Jani Boutellier, University of \nOulu, Finland; Toni Lähteensuo, Tampere University of Technology, Finland; Xiaojia Lu, University of \nOulu, Finland; Joseph R. Cavallaro, Rice University, United States; Shuvra Bhattacharyya University \nof Maryland, United States; Markku Juntti, University of Oulu, Finland; Mikko Valkama, Tampere nUniversity of Technology, Finland\nWAb-1: MIMO PROCESSING\nWAb-1.1: MMSE RECEIVE FILTERING FOR PRECODED MIMO SYSTEMS .................................................2057\nAhmed Mehana, Samsung Electronics, Co., Ltd United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-1.2: COVERAGE IN DENSE MILLIMETER WAVE CELLULAR  ............................................................2062\nNETWORKS\nTianyang Bai, Robert W. Heath, Jr., The University of Texas at Austin, United States\nWAb-1.3: LINEAR PRECODING FOR MIMO WITH LDPC CODING AND  .....................................................2067\nREDUCED RECEIVER COMPLEXITY\nThomas Ketseoglou, California State University, Pomona, United States; Ender Ayanoglu, University nof California, Irvine, United States\nxxxii\nWAb-1.4: OPTIMAL PILOT BEAM PATTERN DESIGN FOR MASSIVE MIMO 2072\nSYSTEMS\nSong Noh, Michael D. Zoltowski, Purdue University United States; Youngchul Sung, Korea Advanced \nInstitute of Science and Technology, Republic of Korea; David J. Love, Purdue University, United \nStates\nWAb-2: ADVANCES IN CODING AND DECODING\nWAb-2.1: EFFICIENTLY ENCODABLE NON-BINARY GENERALIZED LDPC  .............................................2079\nCODES\nNicholas Chang Applied Communication Sciences, United States; Marko Kocic, MIT Lincoln \nLaboratory, United States\nWAb-2.2 PRACTICAL NON-BINARY RATELESS CODES FOR WIRELESS 2084\nCHANNELS\nDavid Romero, Massachusetts Institute of Technology, United States; Nicholas Chang, Applied \nCommunication Sciences, United States; Adam R. Margetts Massachusetts Institute of Technology, \nUnited States\nWAb-2.3: ON THE OPTIMALITY OF POLAR CODES FOR THE 2089\nDETERMINISTIC WIRETAP CHANNE\nAli Fakoorian, A. Lee Swindlehurst, University of California, Irvine, United States\nWAb-2.4: DELAY-OPTIMAL STREAMING CODES UNDER 2094\nSOURCE-CHANNEL RATE MISMATCH\nPratik Patil, Ahmed Badr, Ashish Khisti, University of Toronto, Canada; Wai-Tian Tan Hewlett-\nPackard Labs, United States\nWAb-3: DETECTION\nWAb-3.1: ASYNCHRONOUS SIGNAL DETECTION IN 2103\nFREQUENCY-SELECTIVE NON-GAUSSIAN CHANNELS\nSaiDhiraj Amuru, Daniel Jakubisin, R. Michael Buehrer, Virginia Tech, United States Claudio da \nSilva, Samsung Electronics, Co., Ltd., United States\nWAb-3.2: AN INFORMATION THEORETIC CHARACTERIZATION OF THE  ................................................2108\nCHANNEL SHORTENING RECEIVER\nFredrik Rusek, Ove Edfors, Lund University, Sweden\nWAb-3.3: ITERATIVE MMSE-SIC RECEIVER WITH LOW-COMPLEXITY  ...................................................2113\nSOFT SYMBOL AND RESIDUAL INTERFERENCE ESTIMATIONS\nGuosen Yue, Narayan Prasad, Sampath Rangarajan, NEC Laboratories America, Inc., United 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



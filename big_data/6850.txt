Defin ing Architecture Components of the Big Data Ecosystem   nl-NL Yuri Demchenko, Cees de Laat  System and Network Engineering Group  University of Amsterdam  Amsterdam, The Netherlands  e mail y.demchenko, C.T.A.M.deLaat uva.nl   en-GB Peter Membrey  Hong Kong Polytechnic U niversity  Hong Kong SAR, China  e mail cspmembrey@comp.polyu.edu.hk    Abstract 000 Big Data are becoming a new technology focus both in science and in industry  and motivate  technology shift to data  centric architecture and operational models  There is a vital need to define the basic 
information/semantic models architecture components and operational models that together comprise a so called Big Data Ecosystem This paper discusses a nature of Big Data that may originate from different scientific industry and social activity domains and proposes improved Big Data definiti on that includes the following parts   Big Data properties  also called Big Data 5V Volume, Velocity, Variety, Value and Veracity data models and structures, data analytics   infrastructure and security  The paper discusses paradigm change from traditional host or service based to data centric architecture and operational model s  in Big Data The Big Data Architecture F ramew ork BDAF is proposed t o a ddress all aspects of the Big Data Ecosystem 
 and  includes the following components Big Data Infrastructure Big Data Analytics Data structures and models Big Data Lifecycle Management, Big Data Security. The paper analyses req uirements to and provides suggestions how the mentioned above components can address the main Big Data c hallenges The presented work intends to provide a consolidated  view of the Big Data  phenomena and related challenges to modern technologies   and initia te wide discussion  Keywords  Big Data  Technology  Big Data Ecosystem Big Data Architecture Framework  BDAF  Big  Data Infrastructure  B DI Big  Data Lifecycle Management B DLM Cloud based Big Data 
Infrastructure Service s   I  I NTRODUCTION  Big Data   also  referred to as Data Intensive T echnologies   are becoming a new technology trend in science, industry and business [1, 2, 3   B ig  Dat a a r e b ec o m in g  r ela te d  t o  alm o s t all  aspects of human activity from just recording events to research design, production an d digit al services or products delivery  to the final consumer Current technologies such as Cloud Computing and ubiquitous network connectivity provide a platform for automation of all processes in data collection storing, processing and visualization    The goal of our research at current stage  is to understand the nature of Big Data their main features trends and new possibilities in Big Data technologies development, identify the 
security issues and problems related to the specific Big Data properties and based on this to review architecture models and propose a consistent approach to defining the Big Data architecture/solutions to resolve existing challenges and known issues/problems  In this paper we continue with the Big Data definition and enhanc e the definition given in 3   that includes the 5V Big Data properties   Volume Variety Velocity Value Veracity and suggest other dimensions for Big Data analysis and taxonomy in particular comparing and contrasting Big Data technologies in e Science  industry, business, social media, healthcare   With a long tradition of working with constantly increasing volume of data, modern e Science can offer industry the scientific analysis methods, while industry can bring advanced and fast developing 
Big Data t echnologies and tools to science and wider public    In Big Data d ata are  rather a 000 fuel 000  that 000 powers 000  the whole complex of technical facilities and infrastructure components built around a specific data origin and their  target use. We will call it a Big Data Ecosystem BDE By defining BDE we contrast its data centric character to traditional definition of the architecture that is more applicable for facility or service centric technologies  W e discuss the major architecture components that together co nstitute the Big Data Ecosystem: 5V Big Data properties, Data Models and Structures, Big Data Infrastructure Big Data lifecycle management or data transformation flow Big Data Security Infrastructure 
  There are not many academic papers related to Big Data; in most cases they are focused on some component  technology e.g Data Analytics or Machine Learning or solution that reflect only a small part of the whole problem area. The same relates to the Big Data definition that would provide a conceptual ba sis for the further technology development. There is no well established terminology in this area Current ly this problem is targeted by the recently established NIST Big Data Working Group NBD WG 4  that meets at weekly basis in subgroups focused on Bi g Data definition Big Data Reference Architecture Big Data Requirements Big Data Security  The authors are actively contributing  to  the NBD WG and have 
presented the approach and ideas proposed/discussed in this paper at one of NBD WG virtual meetings 5   We will refer to the NBD WG discussions and documents in many places along this paper to support our ideas or illustrate alternative approach   The paper is organised as follows Section II investigates different Big Data origin domains and target use and based on this proposes a new extended/improved Big Data definition as the main component of the Big Data Ecosystem  Section I II  analyses the paradigm change in Big Data and Data Intensive technologies  Section IV proposes the Big Data Architecture Fram ework that combines all the major components of the Big 978-1-4799-5158-1/14/$31.00 ©2014 IEEE 104 


Data Ecosystem  The section also briefly discusses Big Data Management issues and required Big Data structures Section V provides suggestions about building Big Data Infrastructure and specifically B ig Data Analytics components Section VII refers to other works related to defining Big Data architecture and its components   The paper conclude s  with the summary and suggestions for further research  II  B IG D ATA D EFIN I TION AND A NALYSIS  A  Big Data Nature and A p plication D omains  000:\000H\000\003 000R\000E\000V\000H\000U\000Y\000H\000\003 000W\000K\000D\000W\000\003 000%\000L\000J\000\003 000'\000D\000W\000D\000\003 000³\000U\000H\000Y\000R\000O\000X\000W\000L\000R\000Q\000´\000\003 000L\000V\000\003 000K\000D\000S\000S\000H\000Q\000L\000Q\000J\000\003 000L\000Q\000\003 different human activity domains empowered by significant growth of the computer power ubiquitous availability of computing and storage resources increase of digital content producti on  mobility  This creates a variety of the Big Data origin and usage domains   Table 1 lists the main Big Data origin domains and targeted use or application, which are not exhausting and are presented to illustrate a need for detailed analysis of these as pects We refer to the discussion in 5  p r esen ted  b y  t h e a u th o r s  at NBDWG about  relations between these two dimensions to indicate  the ir dependence  We can assume high relevance of Big Data to business   this  actually explains the current strong interest t o Big Data from business which is actually becoming the main driving force in this technology domain   T ABLE 1  B IG D ATA ORIGIN AND TARGE T USE DOMAINS  Big Data Origin  Big Data Target Use  1  Science  2  Telecom  3  Industry  4  Business  5  Living Environment Cities  6  Social media and networks  7  Healthcare   a  Scientific discovery  b  New technologies  c  Manufacturing, process control, transport  d  Personal services campaigns  e  Living environment support  f  Healthcare support   Science has been traditionally dealing with challenges to handle large volume of data in complex scientific research experiments involving also wide cooperation among distributed groups of individual scientists and research organizations. Scientific resea rch typically includes collection of data in passive observation or active experiments which aim to verify one or another scientific hypothesis Scientific research and discovery methods are typically based on the initial hypothesis and a model which can b e refined based on the collected data. The refined model may lead to a new more advanced and precise experiment and/or the previous data re evaluation The future Scientific Data and Big Data Infrastructure  SDI/BDI   needs to support all data handling oper ations and processes providing also access to data and to facilities to collaborating researchers. Besides traditional access control and data security issues, security services need to ensure secure and trusted environment for researcher to conduct their research   I n business, p rivate companie s will not typically share data or expertise When dealing with data companies will intend always to keep control over their information assets. They may use shared third party facilities like clouds or specialists  instruments but special measures need to be taken to ensure workspace safety and data protection including input/output data sanitization   Big Data in industry are related to controlling complex technological processes and objects or facilities Modern  computer aided manufacturing produces huge amount of data which are in general need to be stored or retained to allow effective quality control or diagnostics in case of failure or crash Similarly to e Science in many industrial applications/scenarios t here is a need for collaboration or interaction of many workers and technologists   Big Data rise is tightly connected to social data revolution that both provided initial motivation for developing large scale services, global infrastructure and high perfo rmance analytical tools, and produces huge amount of data on their own  Social network are widely used for collecting personal information and providing better profiled personal services staring from personal search advice to targeted advertisements and pr ecisely targeted campaigns   We accept the proposed analysis is not exhaustive and can be e xtended and detailed but we use it to illustrate a need for  a more detailed research in this area   B  5V of   Big Data  000'\000H\000V\000S\000L\000W\000H\000\003\000W\000K\000H\000\003\000³\000%\000L\000J\000\003\000'\000D\000W\000D\000´\000\003\000E\000H\000F\000D\000P\000H\000\003\000D\000\003\000Q\000H\000Z\000\003\000E\000X word, the re  is no consistent definition of  Big Data, nor detailed analysis of this new emerging technology Most discussions until now have been  going in blogosphere where active contributors have generally converged on the most important features a nd incentives of  the Big Data [6  7 8     We refer to our recent paper [3  w h er e w e s u m m ar ized  t h e  existing at that time discussions and proposed the Big Data definition as having the following 5V properties Volume Velocity Variety that constitute native/original Big D ata properties and Value and Veracity as acquired as a result of data initial classification and processing in the context of a specific process or model   To provide background  for discussion, we quote here few definitions by leading experts and consulti ng companies We start with the IDC definition of Big Data   rather strict and c onservative   A new generation of technologies and architectures designed to economically extract value from very large volumes of a wide variety of data by enabling high velocity capture, discovery, and/or analysis   9      105 


It can be complemented with more simple definition by Jason Bloombe rg   8 000@\000\035\000\003 000³\000%\000L\000J\000\003 000'\000D\000W\000D  a massive volume of both structured and unstructured data that is so large that it's difficult to process using t raditional database and software techniques 000\021\000´\000\003 This is also in accordance with the definition given by Jim Gray in his seminal book [1 0    We concur with the Gartner definition of Big Data that is 000W\000H\000U\000P\000H\000G\000\003 000D\000V\000\003 000\026\000\003 000S\000D\000U\000W\000V\000\003 000G\000H\000I\000L\000Q\000L\000W\000L\000R\000Q\000\035\000\003 000³\000%\000L\000J\000\003 000G\000D\000W\000D\000\003 000L\000V\000\003 000K\000L\000J\000K volume high velocity and high variety information assets that demand cost effective innovative forms of information processing for 000H\000Q\000K\000D\000Q\000F\000H\000G\000\003 000L\000Q\000V\000L\000J\000K\000W\000\003 000D\000Q\000G\000\003 000G\000H\000F\000L\000V\000L\000R\000Q\000\003 000P\000D\000N\000L\000Q\000J\000\021\000´\000\003 11 12  Further analysis of the Big Data use cases, in particular those discussed by NBD WG [4  reveals other aspects and Big Data features   During the Big Data lifecycle e ach stage of the data transformation or processing changes the data set  content state and consequently may change enrich  the data model I n many cases there is a need to link ori ginal data and processed data keeping referral integrity \(see more discussion about this in the following sections   This motivates other  Big Data feature s  Dynamicity  or Variability   and L inkage or referral integrity Dynamicity/Variability reflects th e fact that data are in cons tan t change and may have a definite state   besides commonly defined as data in move, in rest or being processed Supporting t h ese  data properly will require scalable provenance models and tools incorporating also data  integrity  and confidentiality   C  From 5V to 5 Parts Big Data Definition  It is obvious that current Big Data definition addresses only three bas ic Big Data properties Volume, Velocity, Variety \(so called 3V\ and related technology components To improve and extend the Big Data definition as a  new techno lo gy, we need to find a way to reflect its all important features and provide a guidance/basis for further technology development  We can refer to  one of the best example of  the Cloud Computing definition 18  that ha s been given by NIST in 2008 and actually sh aped the current cloud industry    We propose a Big Data definition as having five parts that group the main Big Data features and related infrastructure components   1\ Big Data Properties: 5V  000x  Volume, Variety Velocity, Value, Veracity  000x  Additionally: Data Dynamicity \(Variability  and Linkage   2\ New Data Models  000x  Data linking, provenance and referral integrity  000x  Data Lifecycle and Variability Evolution   3\ New Analytics  000x  Real time/streaming analytics interactive a nd machine learning analytics   4\ New Infrastructure and Tools  000x  Cloud based infrastructure  s torage n etwork  high performance computing  000x  Heterogeneous multi provider services integration  000x  New Data Centric \(multi stakeholder\ service models  000x  New Data Centric s ecurity models for trusted infrastructure and data processing and storage   5 Source and Target  that are important aspect sometimes defining data types and data structures e.g raw data data streams, correlated data  000x  High velocity/speed data capture from variety of sensors and data sources  000x  Data delivery to different visualisation and actionable systems and consumers  000x  Full digitised input and output ubiquitous sensor networks, full digital control   To reflect the major  Big Data features  and ecosystem comp onents we can summarise t hem in a  form of the i mproved Gartner definition   000 Big Data Data Intensive Technologies are targeting to process high volume high velocity high variety data sets/assets to extract intended data value and ensure high veracity  of original data and obtained information that demand cost effective innovative forms of data and information processing analytics for enhanced insight decision making and processes control all of those demand should be supported by\ new data model s \(supporting all data states and stages during the whole data lifecycle\ and new infrastructure services and tools that allow obtaining \(and processing data  from a variety of sources including sensor networks and delivering data in a variety of forms t o different data and information consumers and devices 000  D  Big Data  Ecosystem  Big Data is not just a database or Hadoop  problem although they constitute the core technologies and components for large scale data processing and data analytics  13, 14, 15 It is the whole complex of components to store, process, visualize and deliver results to target applications Actually Big Data is 000 a fuel 000  of all data related  processes, source, target, and outcome   All this complex of interrelated components can be defined as the Big Data Ecosystem BDE that deals with the evolving data, models and supporting  infrastructure during the whole Big Data lifecycle  In the following we will provide more details about our vision of the BDE  III  P ARADIGM CHANGE IN B IG D A TA AND D ATA I NTESIVE S CIENCE AND T ECHNOLOGIES   The recent advancements in the general ICT  Cloud Computing  and B ig D ata technologies facilitate the paradigm change in modern e Science and industry that is characterized by the following features  3, 16   000x  Tr ansformation of all processes events and products into digital form by means of multi dimensional multi faceted 106 


measurements monitoring and control; digitising existing artifacts and other content  000x  Automation of all data production consumption  and manag ement processes including data collection storing classification, indexing and other components of the general data curation and provenance   000x  Possibility to re use and repurpose the initial data sets for new and secondary data analysis  based on the model improvement  000x  Global data availability and access over the network for cooperative group of researchers  or technologists including wide public access to scientific or production data  000x  Existence of necessary infrastructure components and management tools tha t a llow fast infrastructure  and services composition adaptation and provisioning on demand for specific research projects and tasks  000x  Advanced security and access control technologies that ensure secure operation of the complex research and production infr astructures and allow creating trusted secure environment for cooperating groups of  researchers and technology specialists   The following are additional factors that will create new challenges and motivate both general and security paradigms c hange in Big Data ecosystem   000x  Virtualization can improve security of data processing 000H\000Q\000Y\000L\000U\000R\000Q\000P\000H\000Q\000W\000\003\000E\000X\000W\000\003\000F\000D\000Q\000Q\000R\000W\000\003\000V\000R\000O\000Y\000H\000\003\000G\000D\000W\000D\000\003\000V\000H\000F\000X\000U\000L\000W\000\\\000\003\000³\000L\000Q\000\003\000U\000H\000V\000W\000´\000\021  000x  Mobility of the different components of the typical data infrastructure: sensors or data source, data consumer, and data themselve s \(original data and staged/evolutional data This in its own cause the following problems  o  On demand infrastructure services provisioning  o  Inter domain context communication  000x  Big Data aggregation that may involve data from different administrative/logical d omains and evolutionally changing data structures \(also semantically different  000x  Policy granularity: Big Data may have complex structure and require different and high granular policies for their access control and handling   The future Big Data  Infrastru cture \(BDI should support the whole data lifecycle and explore the benefit of the data storage/preservation aggregation and provenance in a large scale and during long/unlimited period of time. Important is that this infrastructure must ensure data secur ity integrity confidentiality availability and accountability and data ownership protection With current practice that assumes data access, use by different user groups and in general processing on the third party facilities/datacenters there shoul d be a possibility to enforce data/dataset policy that they can be processed on trusted systems and/or complying other requirements Custom ers must trust the B DI to process their data on B DI facilities and be ensured that their stored research data are pro tected from non authorised access Privacy issues are also arising from distributed remote character of B DI that can span multiple countries with different local policies. This should be provided by the access control and accounting infrastructure which is an important component of the future BDI   3 16  1 7   A  From Big Data to All Data Methaphor  One of difficulties in defining Big Data and setting a common language/vocabulary for Big Data is the different view of the potential stakeholders. For examp le, b ig business and big science a re  arguing how big are big data: is Petabyte a big data 000,\000V\000\003\000\(\000[\000D\000E\000\\\000W\000H\000\003\000D\000\003\000E\000L\000J\000\003\000G\000D\000W\000D\000"\000\003\000:\000K\000L\000O\000H\000\003\000V\000P\000D\000O\000O\000H\000U\000\003\000E\000X\000V\000L\000Q\000H\000V\000V\000H\000V\000\003\000D\000Q\000G\000\003\000³\000O\000R\000Q\000J 000W\000D\000O\000H\000´\000\003 science 8 000@\000\003\000\013\000L\000\021\000H\000\021\000\017\000\003\000W\000K\000D\000W\000\003\000G\000R\000H\000V\000Q\000¶\000W\000\003\000J\000H\000Q\000H\000U\000D\000W\000H\000\003\000K\000X\000J\000H\000\003\000D\000P\000R\000X\000Q\000W\000\003\000R\000I\000\003\000G\000D\000W\000D\000\014\000\003\000P\000D\000\\\000\003 conclude that they will never becom e Big Data players  and all this hype is not for them    I n this respect, it is important to look at the current Big Data related trends in general and investigate/analyse what are the components of the Big Data ecosystem and how they impact the present I C T  infrastructure changes in first place, and how these changes will affect other IT domains and applications   Following the trend in some Big Data analytics domain to collect and analyse all available data all data that can be collected\, we can extend it 000W\000R\000\003\000W\000K\000H\000\003\000I\000R\000O\000O\000R\000Z\000L\000Q\000J\000\003\000P\000H\000W\000D\000S\000K\000R\000U\000\035\000\003\000³\000\\000R\000P\000\003 Big Data to All 000'\000D\000W\000D\000´\000\021\000\003\000,\000W\000\003\000L\000V\000\003\000G\000H\000S\000L\000F\000W\000H\000G\000\003\000L\000Q\000\003\000\\000L\000J\000X\000U\000H\000\003\000\024\000\003\000W\000K\000D\000W\000\003\000L\000O\000O\000X\000V\000W\000U\000D\000W\000H\000V\000\003 000W\000K\000D\000W\000\003 000W\000K\000H\000\003 000W\000U\000D\000G\000L\000W\000L\000R\000Q\000D\000O\000\003 000G\000L\000O\000H\000P\000P\000D\000\003 000³\000P\000R\000Y\000H\000\003 000G\000D\000W\000D\000\003 000W\000R\000\003 000F\000R\000P\000S\000X\000W\000L\000Q\000J\000\003 000R\000U\000\003 000F\000R\000P\000S\000X\000W\000L\000Q\000J\000\003\000W\000R\000\003\000G\000D\000W\000D\000´\000\003\000L\000V\000\003\000Q\000R\000W\000\003\000Y\000D\000O\000L\000G\000\003\000L\000Q\000\003\000W\000K\000L\000V\000\003\000F\000D\000V\000H\000\017\000\003\000D\000Q\000G\000\003\000Z\000H\000\003\000U\000H\000D\000O\000O\000\\\000\003\000Q\000H\000H\000G\000\003 to look at the future Big Data/All Data processing model and infrastructure differently   All Data infrastructure will need to adopt generically dist ributed storage and computing, a complex of functionalities which we depicted as Data Bus will provide all complex functionality to exchange data distribute and synchronise processes, and many other functions that should cope with the continuous data production, processing and consumption     Figure 1. From Big Data to All Data  Metaphor   B  Moving to Data Centric Models and Technologies  C urren t IT and communication technologies are OS/system based and host/service centric what means that all communication or processing are bound to host/computer that runs application software. This is especially related to security services  that use server/host  based PKI certificates  and security protocols The administrative and security domains are the key concepts, around which the services and protocols are built. A domain provides a context for establishing security context and trust relation This creates a number of problems when data 107 


payload or session context are moved from one system to another or between domains or operated in a distributed manner   Big Data will require different data centric operational models and protocols what is especially important  in situation when  the object or event related data will go through a number of transformations and become even more distributed, between traditional security domains The same relates to the current federated access control model that is based on  the cross administrative and security domains identities and policy management   When moving to generically distributed data centric models additional research are needed to address the following issues  000x  Maintaining  semantic and referral integrity in par ticular to support data provenance  000x  Data location, search, access  000x  Data integrity and identifiability referral integrity  000x  Data security and data centric access control  encryption enforced and attribute based access  000x  Data ownership p ersonally identified d ata, privacy, opacity  000x  Trusted virtualisation platform  data centric trust bootstrapping  IV  P ROP OSED B IG D ATA A RCHITECTURE F RAM EWORK  Discussion above motivates a need for a new approach to the definition of the Big Data Ecosystem that would address the major c hallenges related to the Big Data properties and component technologies   In this section we propose the Big Data Architecture Framework \(BDAF that would support the extended Big Data definition given in section II.C and support the main components and pr ocesses in the Big Data Ecosystem \(BDE We base our BDAF definition on industry best practices and our experience in defining architectures for new technologies in particular NIST Cloud Computing Reference Architecture \(CCRA\ [18   Intercloud Architectu re Framework ICAF by authors 19   recent documents  by the NIST Big Data Working Group [4   in particular initial Big Data Reference  Architecture 20  or  Big Data technology Roadmap  21   We also refer to other related architecture definitions: Informati on as a Service  by Open Data Center Alliance 22   T MF  B ig  Dat a  A n aly tics  A r ch it ec t u r e  23   IBM Business Analytics and Optimisation  Reference Architecture [24 LexisNexis HPCC Systems [25    The propose d  definition of the Big Data Architecture Framework  summarises majority of the known to us research and discussions in this area. The proposed BDAF comprises of the following 5 components that address different aspects of the Big Data Ecosystem and Big Data definition aspects  which we consider to some exte nt orthogonal  and complementary    1\ Data Models, Structures, Types  000x  Data formats, non relational, file systems, etc  2\ Big Data Management  000x  Big Data Lifecycle \(Management  000x  Big Data transformation/staging  000x  Provenance, Curation Archiving  3\ Big Data Analytics and Tools  000x  Big Data Applications  000x  Target use, presentation, visualisation  4\ Big Data Infrastructure \(BDI  000x  Storage Compute High Performance Computing Network  000x  Sensor network, target/actionable devices  000x  Big Data Operational support  5\ Big Data  Security  000x  Data security in rest in move trusted processing environments   To simply validate the consistency of the proposed definition we can look how the proposed components are related to each other. This is illustrated in Table 2 that shows what archit ecture component is used or required by another component   T ABLE 3   I NTERRELATION BETWEEN  BDAF  COMPONENTS  Col n   Used  By   Row: Re q s This  Data Models  Data Mngnt  Lifecycle  BD Infra  Operat  BD Analytics  Big Data Security  Data Models           Data Mngnt   Lifecycle           BD Infra str  Operat ion           BD Analytics           Big Data Security            The proposed BDAF definition is rather technical and infrastructure focused and actually reflecting the technology oriented stakeholders The further research on the BDAF definition should analyse the interests and messages related to different stakeholder groups in Big Data, in particular we will be looking for contribution from the data archives provid ers and libraries who are expected to play a renewed role in the BDE  26    A  Data Models and Structures  Different stages of the Big Data transformation will require different data structures models and formats including also a possibility to process both structured and unstructured data   27      The following d ata types can be defined according to current NBDWG discussions  28    a\ data described via a formal data model  b\ data described via a formalized grammar  c\ data described via a standard format  d arbitrary textual or binary data   Figure 2 illustrates the Big Data structures, models and their linkage at different processing stages. We can admit that data structures and correspondingly models may be different at different data processing stages how ever in many cases it is important to keep linkage between data    We can look closer at the scientific data types their transformation and related requirements where we have long time experience Emergence of computer aided research 108 


methods is transformin g the way research is done and scientific data are used. The following types of scientific data are defined 16   000x  Raw data collected from observation and from experiment according to an initial research model  000x  Structured data and datasets that went through data filtering and processing \(supporting some particular formal model  000x  Published data that supports one or another scientific hypothesis, research result or statement  000x  Data linked to publications to support the wide research consolidation, integrat ion, and openness        Figure 2 Big Data structures models and their linkage  at different processing stages    Once the data is published it is essential to allow other scientists to be able to validate and reproduce the data that they are interested  in and possibly contribute with new results Capturing information about the processes involved in transformation from raw data up until the generation of published data becomes an important aspect of scientific data management. Scientific data provenanc e becomes an issue that also needs to be taken into consideration by Big Data providers  29       Another aspect to take into consideration is to guarantee reusability of published data within the scientific community Understanding semantic s  of the publishe d data becomes an important issue to allow for reusability and this had been traditionally been done manually However as we anticipate unprecedented scale of published data that will be generated in Big Data Science attaching clear data semantic become s a necessary condition for efficient reuse of published data Learning from best practices in semantic web community on how to provide a reusable published data will be one of consideration that will be addressed by BDI SDI   Big data are typically distri buted both on the collection side and on the processing/access side data need to be collected sometimes in a time sensitive way or with other environmental attributes\, distributed and/or replicated. Linking distributed data is one of the problems to be addressed by Big Data structures and underlying infrastructure   We can mention as the main motivation the European 000&\000R\000P\000P\000L\000V\000V\000L\000R\000Q\000¶\000V\000\003 000L\000Q\000L\000W\000L\000D\000W\000L\000Y\000H\000\003 000W\000R\000\003 000V\000X\000S\000S\000R\000U\000W\000\003 0002\000S\000H\000Q\000\003 000$\000F\000F\000H\000V\000V\000\003 000W\000R\000\003 000V\000F\000L\000H\000Q\000W\000L\000I\000L\000F\000\003 data from publicly funded projects that suggests introduction of the following mechanisms to allow linking publications and data  30  31    000x  PID  persistent data ID  000x  ORCID 000  Open Researcher and Contributor Identifier 32   B  Data Management and  Big Data Lifecycle  With the digital technologies proliferation into all aspects of business activities, the industry and business are entering a new playground where they need to use scientific methods to benefit from the new opportunities to collect and mine data for desirable information such as market prediction customer behavior predictions  social groups activity predictions etc N umerous blog articles  6 3 3  and industry papers 3 4  3 5  suggest that the Big Data technologies need to adopt scientific discovery methods that include iterative model improvement and collection  of improved dat a  re use of collected data  with improved model     Figure 3  Big Data Lifecycle  in Big Data Ecosystem   We refer to the Scientific Data Lifecycle Management model described in our earlier paper 3 16  an d  w as a  s u b jec t f o r  detailed research in another work [36  th at  r ef le cts  c o m p lex  an d  iterative process of the scientific research that includes a number of consequent stages: research project or experiment planning data collection data processing publishing research results discussion, feedback; archiving \(or discarding   The required new approach to data management and process ing in Big Data industry  is reflected in the Big  Data Lifecycle Management B DLM\ model \(see Figure 3  proposed as a result of analysis of the existing practices in different scientific communities  and industry technology domains    New B DLM requires data storage and preservation at all stages what should allow data re use/re purposing and secondary research analytics  on the processed data and published results. However, this is possible only if the full data identification cross reference and linkage are implemented in B DI. Data int egrity, access control and accountability must be support ed during the whole data lifecycle. Data curation is an 109 


important component of the discussed B DLM and must also be done in a secure and trustworthy way  V  B IG D ATA I NFRASTRUCTURE BDI  Figure 4 provide s a general view on the Big Data infrastructure that includes the general infrastructure for general data management, typically cloud based, and Big Data Analytics part that will require high performance computing clusters  which in their own turn will req uire high performance low latency network    General BDI services and components include  000x  Big Data Management tools  000x  Registries, indexing/search, semantics, namespaces  000x  Security infrastructure \(access control, policy enforcement confidentiality, trust, availa bility, privacy  000x  Collaborative environment \(groups management     Figure 4   General Big Data Infrastructure functional components   We define Federated Access and Delivery Infrastructure FADI as an important component of the general BDI that interconnects different components of the cloud/Intercloud based infrastructure combining dedicated network connectivity provisioning and federated access control [19, 37   A  B ig Data Analytics Infrastructure  Besides the general c loud base infrastructure services storage compute infrastructure/VM management  the following specific applications and services will be required to support Big Data and other  data centric applications  23, 24, 38  wh ich we will commonly refer to as Big Data Analytics Infrastructure \(BDAI  000x  Cluster services  000x  Hadoop related services and tools  000x  Specialist data analytics tools logs events data mining etc  000x  Databases/Servers SQL, NoSQL  000x  MPP \(Massively Parallel Processing  databases     Figure 5   Big Data Analytics Infrastructure components   Big Data analytics tools are currently offered by the major cloud services providers such as: Amazon Elastic MapReduce and Dynamo 39   Mi c r o s o f t  A zu r e H DI n s ig h t   4 0    IBM Big Data Analytics  41   Sc ala b l e  Had o o p  an d  d a ta  an aly tics  to o ls  service s are offered by few companies that position themselves as Big Data companies such as Cloudera, [42  an d  f ew  o th er s  43   VI  C LOUD B AS ED I NFRASTRUCTURE S ERVICES FOR B DI  Figure 6  illustrates the typical e Science or enterprise collaborative infrastructure that  is created on demand and includes enterprise proprietary and cloud based computing and storage resources, instruments, control and monitoring system visualization system, and users represented by user clients and typically residing in real or virtual cam puses   The main goal of the enterprise or scientific infrastructure is to support the enterprise or scientific workflow and operational procedures related to processes monitoring and data processing Cloud technologies simplify the building of such infras tructure and provision it on demand. Figure 6 illustrates how an example enterprise or scientific workflow can be mapped to cloud based services and later on deployed and operated as an instant inter cloud infrastructure It contains cloud infrastructure s egments IaaS VR3 VR5 and PaaS VR6 VR7 separate virtualised resources or services \(VR1, VR2\, two interacting campuses A and B, and interconnecting them network infrastructure that in many cases may need to use dedicated network links for guaranteed p erformance   Efficient operation of such infrastructure will require both overall infrastructure management and individual services and infrastructure segments to interact between themselves This task is typically out of scope of the existing cloud service  provider models but will be required to support perceived benefits of the future e SDI. These topics are a subject of another research we did on the InterCloud Architecture Framework [19 37    110 


  Figure 6 From scientific workflow to cloud based infrastructure  VII  R ELATED WORK  There are not many academic papers related to the definition of the Big Data Architecture or its components Due to the specifics of this paper that intends to explore a new emerging technology domain   we have widely researched  both currently existing publications related to the Big Data technology and research papers and best practices documents from other domains that could contribute to the definition of the proposed Big Data Architecture Framework. A  number of publications  standards, and industry best practices have been  mentioned and cited in this paper. Here we just mention these works that we consider as a foundation for our work The authors actively contribute to the NIST Big Data Working Group that provide s  a good forum for discussion but have plans to produce initial set of the draft document s  only by the end of September 2013 The following publications contribute to the research on the Big Data Architecture  NIST Cloud Computing Reference Architecture CC RA 18   B ig  Data  E co s y s te m  A r ch itect u r e definition by Microsoft [20   B ig  Data  tech n o lo g y  a n al y s is  b y  G.Mazzaferro [21     We also refer to other related architecture definitions Information as a Service  by Open Data Center Alliance [22   TMF Big Data A nalytics Architecture 23   IBM Business Analytics and Optimisation  Reference Architecture 24   LexisNexis HPCC Systems [25   VIII  F UTURE R ESEARCH AND D EVELOPMENT  The future research and development will include further Big Data definition initially presented in this paper  At this stage we attempt ed to summarise and re think some widely used definition s  related to Big Data, further research will require more formal approach and taxonomy of the general Big Data use cases in different Big Data origin and target domains also analyzing different stakeholder groups    The authors will extend their research into defining the Big Data Security Framework with the specific focus on data centric security that should allow secure data storage transfer and processing in di stributed data storage and processing infrastructure   The authors  are  also looking into defining data structures for high performance streaming applications and developing new types of disk based stream oriented data bases, continuing the work started fro m the authors work on CakeDB  database  4 4    The authors will continue contributing to the NIST Big Data WG targeting both goal s  to propose own approach and to validate it against the industry standardisation process   Another target research direction is d efining a Common Body of Knowledge \(CBK\ in Big Data to provide a basis for a consistent curriculum development. This work and related to the Big Data metadata procedures and protocols definition is planned to be contributed to the Research Data Alliance RDA   4 5     The authors believe that the presented paper will contribute  toward the definition of the Big Data Architecture Framework and provide a basis for wider discussion to define a new research and technology domain   en-GB A CKNOWLEDGEMENTS  This work is supported by the FP7 EU funded project s  GN3plus and EUBrazil Cloud Connect The authors also express acknowledgement to the members of the Big Data Interest Group at the University of Amsterdam for contribution to the discussion on Big Data Ar chitecture framework and provided valuable advices regarding use cases, suggested technology use and basic operational models  R EFERENCES  1  Global Research Data Infrastructures: Towards a 10 year vision for global research data infrastructures Final Roadm ap March 2012  O nline  Available  http://www.grdi2020.eu/Repository/FileScaricati/6bdc07fb b21d 4b90 81d4 d909fdb96b87.pdf  2  Riding the wave: How Europe can gain from the rising tide of scientific data Final report of the High Level Expert Group on Scientific Data October 2010   O nline   Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/hlg sdi report.pdf  3  Y.Demchenko  P Membrey, P  Grosso, C   de Laat 000 Addressing Big Data Issues in Scientific Data Infrastructure  000  in First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 Int  Conf   on Collaboration Technologies and Systems CTS 2013 May 20 24, 2013, San Diego, California, USA  4  NIST Big Data Working Group NBD WG   O nline  Available  http://bigdatawg.nist.gov/home.php  5  Definting Big Data Architetcure Framework Outcome of the Brainstorming Session at the University of Amsterdam 17 July 2013 Present ed  at  NBD WG 24 July 2013  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0055_v1_7 606723276.pdf  6  Reflections on Big Data Data Science and Related Subjects Blog by Irving Wladawsky Berger  online  Available http://blog.irvingwb.com blog/2013/01/reflections on big data data science and related subjects.html  7  E Dumbill, What is big data? An introduction to the big data landscape  O nline  Available  http://strata.oreilly.com/2012/01/what is big data.html  8  The Big Data Long Tail  Blog post by Jason Bloomberg   Jan uary  17, 2013  O nline  Available  http://www.devx.com/blog/the big data lon g tail.html  111 


9  J  Gantz and David Reinsel   Extracting Value from Chaos  IDC IVIEW June 2011   O nline  Available  http://www.emc.com/collateral/analyst reports/idc extracting value from chaos ar.pdf  10  The Fourth Paradigm Data Intensive Scientific Discovery Edite d by Tony Hey Stewart Tansley and Kristin Tolle  Microsoft Corporation October 2009 ISBN 978 0 9825442 0 4  O nline  Available  http://research.microsoft.com/en us/collaboration/fourthparadigm  11  Big Data defintion Gartner Inc  O nline  Available  http://www.gartner.com/it glossary/big data  12  S.Sicular 000 Gartner's Big Data Definition Consists of Three Parts, Not to Be Confused with Three "V"s 000  Gartner, Inc. 27 March 2013   O nline  Available  http://www.forbes.com/sites/gartnergroup/2013/03/27 gartners big data definition consists of three parts not to be confused with three vs  13  J Layton  000 The Top of the Big Data Stack: Database Applications 000  July 27 2012  O nline  Available  http://www.enterprisestorageforum.com/storage management/the top of the big data stack database applications.html  14  Explore big data analytics and Hadoop  O nline  Available  http://www.ibm.com/developerworks/training/kp/os kp hadoop  15  A Bloom 7 Myths on Big Data Avoiding Bad Hadoop and Cloud Analytics Decisions April 22 2013  O nline  Available  htt p://blogs.vmware.com/vfabric/2013/04/myths about running hadoop in a virtualized environment.html  16  European Union. A Study on Authentication and Authorisation Platforms For Scientific Resources in Europe Brussels  European Commission 2012. Final Report Contributing author. Internal identification SMART Nr 2011/0056  O nline  Available  Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/aaa study final report.pdf  17  Y Demchenko  P.Membrey C.Ngo C de Laat D.Gordijenko  Big Security for Big Data: A ddressing Security Challenges for the Big Data Infrastructure Proc  0006\000H\000F\000X\000U\000H\000\003\000'\000D\000W\000D\000\003\0000\000D\000Q\000D\000J\000H\000P\000H\000Q\000W\000\003\000\013\0006\000'\0000\000¶\000\024\000\026\000\014\000\003\000:\000R\000U\000N\000V\000K\000R\000S\000\021\000\003\0003\000D\000U\000W\000\003 of VLDB2013 conference, 26 30 August 213, Trento, Italy  18  NIST SP 500 292 Cloud Computing Reference Architecture v1.0  O nline  Available  http://colla borate.nist.gov/twiki cloud computing/pub/CloudComputing/ReferenceArchitectureTaxonomy/NIS T_SP_500 292_ _090611.pdf  19  Y Demchenko  M Makkes R.Strijkers C.Ngo C de Laat Intercloud Architecture Framework for Heterogeneous Multi Provider Cloud based Inf rastructure Services Provisioning, The International Journal of Next Generation Computing \(IJNGC\, Volume 4, Issue 2, July 2013  20  NIST Big Data Reference Architecture  NBD WG NIST   O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0226_v10_1554566513.docx  21  NIST Big Data T echnology Roadmap  NBD WG  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0087_v8_1456721868.docx  22  Open Data Center Alliance Master Usage model Information as a Service Rev 1.0  O nline  Available  http://www.opendatacenteralliance.org/docs  Information_as_a_S ervice_Master_Usage_Model_Rev1.0.pdf  23  TR202 Big Data Analytics Reference Model  TMF Document Version 1.9, April 2013  24  IBM GBS Business Analytics and Optimisation 2011 IBM  2013   O nline  Available  https://www.ibm.com/developerworks  mydeveloperworks  files/basic/anonymous/api/library 48d92427 47d3 4e75 b54c b6acfbd608c0/document/aa78f77c 0d57 4f41 a923 50e5c6374b6d/media&ei=yrknUbjMNM_liwKQhoCQBQ&usg=AFQjC NF_Xu6aifcAhlF4266xXNhKfKaTLw&sig2=j8JiFV_md5DnzfQl0spVr g&bvm=bv.42768644,d.cGE  25  A.M Middleton  HPCC Systems Introduction to HPCC High Performance  Computer Cluster LexisNexis Risk Solutions LexiNexis  May 24, 2011  26  Bierauge M Keeping Up With Big Data American Library Association  2013   O nline  Available  http://www.ala.org/acrl/publications/keeping_up_with/big_data  27  Unstructured Data Mana gement Hitachi Data System  2013  online  http://www.hds.com/solutions/it strategies/unstructured data management.html  28  NIST Big Data WG discussion  O nline  Available  http://bigdatawg.nist.gov/home.php  29  D.Koopa, et al 000 A Provenance Based Infrastructure to Support the Life Cycle of  Executable Papers 000  in International Conference on Computational Science  ICCS 2011   O nline  Available  http://vgc.poly.edu/~juliana/pub/vistrails executable paper.pdf  30  Open Access: Opportunities and Challenges. European Commission for UNESCO  O nline  Available  http://ec.europa.eu/research/science society/document_library/pdf_06/open access handbook_en.pdf  31  OpenAIR 000  Open Access Infrastructure for Research in Europe  O nline  Available  http://www.openaire.eu  32  Open Researcher and Contributor ID online  h t t p    a b o u t  o r c i d  o rg  33  Roundup of Big Data Pundits' Predictions for 2013. Blog post by David Pittman January 18 2013   O nline  Available http://www.ibmbigdatahub.com/blog/roundup big data pundits predictions 2013  34  The Forrester Wave: Big Data Predictive Analytics Solutions, Q1 2013 Mike Gualtieri January 13 2013  O nline  Available  http://www.forrester.com/pimages/rws/reprints/document/85601/oid/1 LTEQDI  35  Big data: The next frontier for innovation, competition, and producti vity May 2011 McKinsey Global Institute  O nline  Available  http://www.mckinsey.com/insights/business_technology/big_data_the_n ext_frontier_for_innovation  36  Data Lifecycle Models and Concepts  O nline  Available  http://wgiss.ceos.org/dsig/whitepapers/Data%20Lifecycle%20Models 2 0and%20Concepts%20v8.docx  37  M Makkes  C  Ngo Y  Demchenko R  Strijkers R  Meijer C   de Laat 000 Defining Intercloud Federation Framework for Multi provider Cloud Services Integration 000  in The Fourth International Conference on Cloud Computing GRIDs and Virtua lization CLOUD COMPUTING 2013  May 27  June 1, 2013,Valencia, Spain  38  M Turk   A chart of the big data ecosystem take 2 online  http://mattturck.com/2012/10/15/a chart of the big data ecosystem take 2  39  Amazon Big Data  O nline Available   http://aws.amazon com/big data  40  Microsoft Azure Big Data Microsoft   2013  O nline  Available  http://www.windowsazure.com/en us/home/scenarios/big data  41  IBM Big Data Analytics  IBM 2 o 13   O nline  Available  http://www 01.ibm.com/software/data/infosphere/bigdata analytics.html  42  Cloudera Impala Big Data Platform   O nline  Available  http://www.cloudera.com/content/cloudera/en/home.html  43  10 hot big data startups to watch in 2013  10 January 2013  O nline  Available  http://beautifuldata.net/2013/01/10 hot big data startups to watch in 2013  44  P Membrey K  C.C. Chan, Y  Demchenko, A Disk B ased Stream Oriented Approach For Storing Big Data I n First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 International Conference on Collaboration Technologies and Systems \(CTS 2013\, May 20 24, 2013  San Diego, California, USA  45  Research Data Alliance  RDA  O nline  Available  http://rd alliance.org   112 


Size of Largeincrease The reasons are twofold Firstly when increases according to the node selection scheme to construct decrease There are two reasons Firstly when the memory size increases the stop condition for graph contraction is easier to be satis\336ed since more nodes can 336t in memory Secondly when the memory size increases the costs of the external sorts in both graph contraction and graph expansion phases decrease  Average Degree Number of Largeincreases the time and I/O consumptions for both increases the number of iterations in graph contraction increases This is because when number of edges increases the cost to sort and scan edges in each iteration increases thus more time and I/Os are consumed in each iteration                                     2 4 1 u E  V v E    u v  G  V E M V M V K G V V M KB Range 25M,50M,100M,150M,200M 2,3,4,5,6 200M,300M,400M,500M,600M 400K 8K 20,30,40,50,60 30,40,50,60,70 10K to in the operator in line 4 both in line 4 and augmented in all nodes in in line 5-7 VIII P ERFORMANCE S TUDIES In this section we conduct experimental studies by comparing four external algorithms for is the number of bytes to keep a node in memory We set the max time cost to be 24 hours If a test does not stop in the time limit we will denote it using until all nodes form an to Size of Small The results are shown in Fig 7\(a and Fig 7\(b for time and I/O costs respectively When the memory size increases the time and I/O costs for both 100M 400M 40 1 1 50 TABLE I R ANGE AND D EFAULT V ALUE FOR P ARAMETERS Parameter in all cases since more nodes/edges are removed in each iteration in Operator  operator speci\336es a unique total order among all nodes in the graph operator in line 9 when generating algorithm needs to hold and and and and and used in introduced in 26  w h i ch is cu r r e n tly th e m o s t I O ef 336cien t sem i e x t er n a l algorithm for and  Secondly when and out out out out out out out Fig.6\(a and Fig 6\(b show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20 to 100 respectively v G v G v G v G v G v G v G v G v G v G v G v G v G v G 002 212 327 327  002 002 327 327 327 327 327       2 cannot stop in the time limit even if the graph contains only 20 of the edges When Size of 8 our e x t e rnal cont ract i on-e xpans i o n b as ed algorithm Algorithm 2 and our algorithm by applying the optimization techniques introduced in Section VII in new edges are added into In Algorithm 3 in order to make use of the new s The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6 A synthetic graph is generated as follows We construct a graph computation namely the external contraction based 13 t he e x t e rnal DFS based by randomly selecting all nodes in SCC SCC SCC SCC SCC SCC  we apply the algorithm computation The  Finally additional random nodes and edges are added to the graph The parameters for synthetic datasets and their default values are shown in Table VIII outperforms 1PB 1PB since it cannot stop in all cases Memory Size need to be computed in Ext Ext Ext Ext EM Ext EM Ext Ext Ext Ext Ext Ext Ext Ext    3  002  For the semi-external algorithm  In our experiments we use a real large web graph and several synthetic datasets The real web graph is WEBSPAM-UK2007 4  which consists of 105,896,555 web4 barcelona.research.yahoo.net/webspam/datasets/uk2007/links   4H   8H   12H   16H   20H   24H   INF   20   40   60   80   100   Time\(hour Ext-SCC-Op   Ext-SCC                           DFS-SCC                 Largein in in in in in in 2 plus one disk block in the main memory that is Size of MassiveNumber of Massive\(a Time Vary Memory   1M   2M   3M   4M   5M   6M   7M   8M   INF   400M   600M   800M   1G   Number of I/Os Ext-SCC-Op   Ext-SCC                       DFS-SCC               iff one of the following three conditions holds 1 b I/Os Vary Memory Fig 7 WEBSPAM-UK2007 Varying Memory Size pages in 114,529 hosts in the UK domain The graph contains 105,895,908 nodes and 3,738,733,568 edges with the average degree 35 per node For synthetic data we generate 3 different kinds of datasets denoted Massive.The 4K,6K,8K,10K,12K 6K,8K,10K,12K,14K u w u G u G u G u G u G u G u G  For any  containing different sizes of and Small 327     V i i i i i d d d i i De\036nition 7.1 DFS Op Op Op Op Op Op 217 before adding  The default memory size is  In our experiments we do not show the results of  thus more iterations are needed according to the stop condition of graph contraction in 327 Semi add Datasets Exp-1 Performance on WEBSPAM-UK2007 in Algorithm 3 more nodes will be selected in id id 200K,300K,400K,500K,600K as follows DFS SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  By considering  All the algorithms are implemented using Visual C 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP The disk block size is  according to Theorem 5.3 nodes with small degrees are removed when constructing 256 400   256 400 Default INF 327 deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg  4 w V V E V G V G   u  v V G G E E E E G where can be further reduced We rede\336ne the operator Number of SmallD M s s s i i i i i i i 1 1 1 1 1 1 u>v 4  Secondly using operator  and for each removed node  s 336rst Then we add edges among the nodes in an  We vary the memory size from                     a Time Vary Graph Size   1M   2M   3M   4M   5M   6M   7M   8M   INF   20   40   60   80   100   Number of I/Os Ext-SCC-Op   Ext-SCC                           DFS-SCC                 b I/Os Vary Graph Size Fig 6 WEBSPAM-UK2007 Varying Graph Size Percent   4H   8H   12H   16H   20H   24H   INF   400M   600M   800M   1G   Time\(hour Ext-SCC-Op   Ext-SCC                       DFS-SCC               


SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC increases the time and I/O costs for both dataset dataset The results for both Largedatasets are similar to those in the Massive When either the average   800 105 895 908 8  256  847 200 600 25 200 50 12 30 70 f I/Os SmallTo test the synthetic data we vary the memory size M   K  M M M M M M M M M M D D D D K s s s of nodes from 2 to 6 The time and I/O costs on Largedo not have signi\336cant impact on the ef\336ciency of our algorithms as long as by 20 on average for both time and I/O consumptions Fig 8\(c and Fig 8\(d show the results on Large 1 1 4  the costs for both d I/Os Vary Degree   c Time Vary Degree   25 327         Size and G M G M V V V V V V V K E G Wevary the node size decrease sharply The reason is that in order to process the graph using in all test cases to to is smaller the decrease rate is larger This is because when is smaller more iterations are needed for both to  and the time and I/O costs are shown in Fig 9\(a and Fig 9\(b respectively When to to respectively Fig 9\(g and Fig 9\(h show the time and I/O costs when varying the number of 4   s and and and and and and and and Wevary the average degree Size   Size   Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os 2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 8H   12H   16H   20H   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1M   2M   3M   4M   5M   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   4H   6H   8H   10H   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   1.2M   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 e Time Small,andwhen increase This is because when n in Synthetic Data in Synthetic Data DFS DFS DFS Exp-5 Vary Op Op Op Op Op Op Op Op Op Op Op Op Ext  The time and I/O costs on Massiveare shown in Fig 9\(c and Fig 9\(d respectively When decrease When f I/Os Vary Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext  V  V Number in Synthetic Data c Time Large\(a Time Vary e Time Vary cannot stop in limited time in all cases Similar to the results on the real dataset in Fig 7 when dataset and Fig 8\(e and Fig 8\(f show the results on Smallconsume less than 1 hour increases the time and I/O consumptions for both consumes more than 20 hours while both are the number of nodes and the number of edges of the graph As a result the size of memory is needed thus when the memory size is dataset are shown in Fig 8\(a and Fig 8\(b respectively dataset and this is true for all the remaining test cases when varying other parameters in synthetic data In the following due to the lack of space we only show the test results on the Large and in the graph contraction phase the contraction rate decreases when the number of iterations increases since the graph becomes denser with larger number of iterations is larger and the cost on each iteration to scan and   Exp-4 Vary Average Degree in Synthetic Data from from increases the time and I/O consumptions for both and the number of outperforms outperforms cannot stop within the time limit when outperforms in all cases When the memory increases from increases the time and I/O costs for both When a Time Massive\(b I/Os Massiveis larger is larger the gap between is larger This is because when number of edges is larger more edges can be pruned by the edge reduction techniques used in increases the number of edges increases As a result more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size size increases or the number of are not in\337uenced much As anal yzed in Section VII the key factors that in\337uence the cost of Num   Num Fig 9 Synthetic Data Largecan be directly applied on the original graph to output all                       Fig 8 Synthetic Data Vary Memory Size outperforms  and Smallincrease This is because the stop condition for graph contraction is harder to be satis\336ed when  sort nodes/edges is larger when   Fig 9\(e and Fig 9\(f show the time and I/O costs when varying the average no iteration is needed and size from SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC 1H   4H   200K   1H   200K   1H   200K   sfrom b I/Os Vary g Time Vary h I/Os Vary        218 d I/Os LargeSemi Semi Exp-2 Vary Memory Size Exp-3 Vary Node Size   


are 336xed This also explains why the results in the three datasets Massiveis a primitive operation in directed graph exploration which has been studied for both internal memory model and external memory model In the internal memory model strongly connected components of a directed graph can be computed in s for a directed graph with the assumption that the nodes of the graph cannot reside entirely in memory We overcome the de\336ciencies of the existing external    sort sort computation algorithms and propose a new two-phase algorithm with graph contraction followed by graph expansion We analyze the I/O cost of our approach and show that our algorithm can signi\336cantly reduce the number of random I/Os We propose techniques to further reduce the I/O cost of our algorithm and con\336rm the I/O ef\336ciency of our approaches using extensive experiments on both real and synthetic web scale graphs The work was supported by grant of the Research Grants Council of the Hong Kong SAR China No 418512 R EFERENCES  J  A bello A  L  Buchs baum  a nd J  W e s t brook A f unctional a pproach to external graph algorithms s of a graph Zhang et al 26 i mpro v e s uch a n a l gori t h m by constructing and maintaining a special in-memory spanning tree of the graph The semi-external algorithms 23 an d  2 6  are introduced in details in Section III Other than the problem of 336nding time based on DFS 12  A naive way to externalize the internal DFS algorithm requires s Such an algorithm may end up an in\336nite loop and cannot compute all  33\(2 2001  H  Y ildir im  V  C haoji and M  J  Z aki Grail Scalable reachability index for large graphs s repeatedly until the graph 336ts in memory then an internal memory algorithm is used to 336nd the 336nal sor DFS tree on external directed graphs several problems in the external memory model are studied in the literature Dementiev et al 14 p ro vi de an i m pl ement a t i o n o f a n e xt ernal m emory minimum spanning tree algorithm based on the ideas of 22 which performs extremely well in practice even though theoretically inferior to the algorithms of 1   1 0   A jw an i e t al 4 6  propos e i mpl e ment at i ons of e x t e rnal undi rect ed breadth-\336rst search algorithm with the idea from 18 Ul rich Meyer et al 20 21  19  des i gn and i mpl e ment pract i c al I/O-ef\336cient single source shortest paths algorithm on general undirected sparse graphs Surveys about designing I/O ef\336cient algorithms for massive graphs can be found at 24 5  X C ONCLUSIONS In this paper we study I/O ef\336cient algorithms to 336nd all  3\(1 2010  J  Hellings  G  H  F letcher  and H  H averkort Ef\336cient external-memory bisimulation on dags In  3\(1 2010  Z  Z h ang J  X Y u  L  Q in L  C hang a nd X L i n I/O e f 336 cient Computing sccs in massive graphs In scan by maintaining the list of nodes that should not be traversed using tournament trees 17 and b uf fered repos i t o ry t rees 8  respectively Despite their theoretical guarantees these algorithms are considered impractic al for general directed graphs that encountered in real applications Cosgaya-Lozano and Zeh 13 p res e nt a c ont ract i o n b as ed al gori t h m w hi ch cont ract s V M E B V B 2 are similar as stated in Exp-2 IX R ELATED W ORK Finding strongly connected components of a directed graph V G V G E G E V E E V E  14\(1 1985  T  H  Cor m en C  S tein R  L  R i v es t and C  E  L eis e r s on  2003  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths with unbounded edge lengths In s Both DFS based algorithm 8 and c ont ract i o n b as ed algorithm 13 a re i n t roduced i n det a i l s i n S e ct i o n III In addition to external algorithms there are semi-external algorithms for ACM Comput Surv Introduction to Algorithms IFIP TCS         Proc of ESA\22202 Proc of ESA\22206 SIAM J Comput Commun ACM Proc of SIGMOD\22213  32\(3 2002 2 A  A ggar w a l a nd J  S  V itter  T h e i nput/output com p le xity of s o r ting and related problems  31\(9 1988  A  V  A ho J  E  Hopcroft a nd J  D Ullm an I/Os Chiang et al 10 propos e a n a l gori t h m with I/O complexity  Addison-Wesley 1983 4 D  A jw ani R D e m e ntie v  and U  M e y er  A com putational s tudy of external-memory bfs algorithms In  2006  D  A jw ani a nd U Me yer   6\(1 2011  A  L  Buchs baum  M  H  G oldw a sser S Venkatasubramanian and J Westbrook On external memory graph traversal In  2002  J  S  V itter  E x ter n al m e m o r y algor ithm s and d ata s tr uctur e s   2007 7 E  A ngel R Cam p igotto a nd C L a f o r e s t  A nalys i s a nd com p ar is on of three algorithms for the vertex cover problem on large graphs with low memory capacities  1995  N  Chiba a nd T  N i s h izeki A r bor icity and s ubgr aph lis ting algor ithm s   2009  R Dem e ntie v  P  Sanders  D  S chultes  and J  F  S ibe y n E ngineering an external memory minimum spanning tree algorithm In  2012  V  K u m a r a nd E  J  Schw abe Im pro v e d a lgorithm s and d ata s tructures for solving graph problems in external memory In  2002  U  M e yer a nd V  O s ipo v  D es ign a nd im plem entation o f a pr actical i/o-ef\336cient shortest paths algorithm In  2009  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths In  2006  J  F  S i be yn E x ter n al connected com p onents  I n  2013 A CKNOWLEDGMENT  Algorithmic Operations Research          267        and computation which assume that all nodes of the graph can 336t in the main memory Sibeyn et al 23 propose a semi-external DFS  which can be used to 336nd all og  pages 457\320468 2012  Y  J  C hiang M T  Goodrich E  F  Gro v e  R  T am as s i a D E  V e ngrof f and J S Vitter External-memory graph algorithms In  Proc of ALENEX\22207 Proc of SIGMOD\22212 Proc of SODA\22295 Proc of SEA\22209 PVLDB Proc of ALENEX\22209 Proc of ESA\22203 PVLDB                    McGraw-Hill 2001  A  Cos g ayaL o zano a nd N  Z e h A h eur i s tic s t r o ng connecti vity algorithm for large graphs In Algorithmica LargeProc of SPAA\22202 G O O O O Algorithmics of Large and Complex Networks Data Structures and Algorithms SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  Later Kumar and Schwabe 17 a nd B u chs b aum e t a l  8  i mprove the I/O complexity to  chapter 1 Design and Engineering of External Memory Traversal Algorithms for General Graphs Springer 2009  D  A jw ani U Me yer  and V  O s i po v  Im pro v e d e xternal m em ory b fs implementation In  2000  J  Cheng Y  K e  S  Chu and C Cheng E f 336 cient p roces s i ng of distance queries in large graphs a vertex cover approach In  2004  W  F a n J  L i  S  M a H W a ng and Y  W u Graph hom om orphis m revisited for graph matching  1996  K Mehlhorn a nd U Me yer  E xtern al-memory breadth-\336rst search with sublinear i/o In  2004  J  F  Sibe yn J  Abello a nd U Me ye r Heuristics for semi-external depth 336rst search on directed graphs In Proc of SWAT\22204  and SmallProc of SODA\22206 Proc of SODA\22200 219 Proc of SPDP\22296 Proc of SIGMOD\22212 


                  


             


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



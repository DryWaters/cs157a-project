 A Conflict-Based Confidence Measure for Associative Classification   Peerapon Vateekul and Mei-Ling Shyu Department of Electrical and Computer Engineering University of Miami Coral Gables, FL 33124, USA E-mail: p.vateekul@umiami.edu, shyu@miami.edu   Abstract  Associative classification has aroused significant attention recently and achieved promising results. In the rule ranking process, the confidence measure is usually used to sort the class association rules \(CARs\. However it may be not good enough for a classification task due to a low discrimination power to instances in the other classes. In this paper, we propose a novel conflict-based confidence measure with an interleaving ranking strategy for re-ranking CARs in an associative classification framework, which better captures the conflict between a rule and a training data instance. In the experiments, the traditional confidence measure and our proposed conflict-based confidence measure with the interleaving ranking strategy are applied as the primary sorting criterion for CARs. The experimental results show that the proposed associative classification framework achieves promising classification accuracy with the use of the conflict-based confidence measure, particularly for an imbalanced data set  1  Introduction In recent years, extensive research has been carried out to integrate classification and association rule discovery 1 w h ich ar e two of t h e m o st  i m p o rtan t res ea rch ar ea s  in data mining [4, 8, 9, 11 Su ch an  i n tegr ated  app r o ach  is called Associative Classification \(AC that can produce more efficient and accurate classifiers than some of the traditional classification techniques. Moreover, the generated classifiers in the form of class association rules CARs\whose consequent part is a class label, are more comprehensive than some statistical classifiers such as Naïve BaYes. Some classifiers based on AC have been proposed such as CAEP    CBA 6   an d   e s e algorit h m s rank the generated CARs  using a confidence measure According to the majority of AC algorithms, the rule ranking process plays an important role in the classification process since the accuracy is affected directly to the order of CARs. However, the confidence measure has some limitations [10 Thus, i n the  past f e w years, various measures have been proposed such as Interest I also known as lift nviction V relation  000I  IS d etc. [1 Howev er   all o f these  measures still have some drawbacks and are mainly designed for association rule discovery task, not for classification tasks. Furthermore, for a classification task the confidence measure may be not good enough due to a low discrimination power to the instances in the other classes. The reason is that a confidence measure is defined using a frequency count of the exact matched instances on a training data set. On a space of distribution it is possible that a high confidence rule can be close to many instances in different classes. Thus, this rule has a possibility to misclassify instances in different classes on a testing data set In this paper, we propose a novel conflict-based confidence measure for ranking CARs in an associative classification framework, which better captures the conflict between a rule and a training instance. It quantifies the amount of conflict that a rule possesses with respect to all instances belonging to different classes in the data set. Moreover, we also propose an interleaving  ranking strategy that can improve performance of CARs on both balance and imbalance data sets This paper is organized as follows. In Section 2, the associative classification approach is discussed. The overview of our proposed framework is described in Section 3. Then, we show the details of our proposed conflict-based confidence measure in Section 4. In Section 5, we present experimental results. Finally, we conclude our study in Section 6  2  Associative Classification Associative classification \(AC\ is a data mining technique that integrates classification with association rule mining \(ARM\ind the rules from classification benchmarks. A generated rule for classification, called class association rule” \(CAR\s an implication of the form of X 000 c where itemset X is non-empty subset of all possible items in the database X  000  I, I={i 1 i 2 i n  where n is the number of itemsets, and c is a class identifier c 000 c 1 c 2 c m  where m is the number of classes. Let a rule itemset be a pair X, c containing the itemset X and a class label c The rules are discovered in a training data set of transactions D t The strength of a rule R can be measured in terms of its support sup\(R nd IEEE IRI 2008, July 13-15, 2008, Las Vegas, Nevada, USA 978-1-4244-2660-7/08/$25.00 ©2008 IEEE 256 


confidence conf\(R The support of R is the percentage of the instances in D t satisfying the rule antecedent and having class label c as shown in Equation 1. The confidence of R is the percentage of instances in D t  satisfying the rule antecedent that also have the class label c as shown in Equation 2  sup cXPR 000  1      sup sup  XcP XP cXP X R Rconf 000 \000 \000  2 Referring to the support and confidence constraints the rule X 000 c is a class association rule if the following two conditions are satisfied sup\(X 000 c 000 minsup  minimum support threshold\ and conf\(X 000 c 000 minconf  minimum confidence threshold\. To find all CARs, many algorithms are commonly decomposed into three major processes: rule generation, rule selection, and classification. First, the rule generation process extracts all CARs that satisfy both minimum support and minimum confidence thresholds from the training data set. Second, the rule selection process applies the pruning techniques to select a small subset of high-quality CARs and builds an accurate model of the training data set Finally, the classification process is used to classify an unseen data instance  3  The Proposed Interleaving Conflict-Based Associative Classification Framework Figure 1 shows the system architecture of our proposed framework. The main contribution of our proposed framework is that the proposed conflict-based confidence measure is used to rank the generated rules instead of the traditional confidence measure. We will describe the concept and calculation of our proposed measure in Section 4. As can be seen from Figure 1, our proposed framework consists of four modules, namely Rule Generator, Rule Re-ranking, Model Evaluation, and Classification The rule generator module generates the class association rules \(CARs\ from the training data. Based on the original Apriori algorithm e ge nerated CARs depend on the minimum support and minimum confidence thresholds. One of our main objectives is to demonstrate that the CARs ranked by the conflict-based confidence measure improve the classification accuracy over those ranked by the traditional confidence measure We, therefore, aim to generate all possible rules by setting a low minimum support \(5% in this study\. In order to compare the ranking method, the minimum confidence threshold is set to 0 In the rule re-ranking module, the whole set of generated CARs are sorted based on our proposed conflict-based confidence measure instead of the traditional confidence measure. In addition, the interleaving strategy is adopted, which gives a better result in both balanced and imbalanced data sets. This is motivated by the observations that the number of rules for the majority class \(e.g., negative class\ is usually much larger than the number of rules for the other class \(e.g positive class\ for an imbalanced data set, and the rules for the negative class are most likely on the top of the sorted rule set. Consequently, classification accuracy of the positive class drops due to misclassifications. Our empirical studies showed that the interleaving ordered rule set achieves the better performance than the traditional ordered rule set. The interleaving strategy is as follows. First, we categorize the generated CARs by each class. Second, for each class, we sort the generated CARs based on our proposed conflict-based confidence measure. Finally, we interleave the CARs for each class that have the same rank to create the final rule set       As will be explained in Section 4.1, the conflict-based confidence measure directly depends on the 001 value  called the closeness threshold model evaluation module aims to adaptively find the most suitable 001 value based on the characteristics of each data set. In order to find the best 001 value, an initial 001 value, the maximum 001 value, and an increment parameter are pre-defined. We start with the initial 001 value for model evaluation based on the accuracy \(i.e., F1 measure\ of the generated CARs For each iteration, we increase the 001 value using the increment parameter until reaching the maximum 001 value 1\ Rule Generator Class Association Rules \(CARs 2\Re-ranking Training Data 3\ Evaluation Testing Data CARs + Accuracy 4\ Classification Class Prediction   001 values 1 to 10 Pick the best 001 value Fi g ure 1. S y stem architecture of the proposed interleaving conflict-based associative classification framework 257 


Finally, we choose the generated CARs with the 001 value which gives the best accuracy The last module is classification that is used to classify a testing data instance. There are many constraints to classify a testing data instance based on the generated CARs, such as the first matched rule and the majority class of the k-top matched rules. In this paper, the classification module is based on the first matched rule constraint since it is simple and fast. Moreover, it is suitable for comparing the accuracy between CARs ranked by the tradition confidence measure and our conflict-based confidence measure  4  Our Proposed Conflict-Based Confidence Measure The proposed conflict-based confidence measure \(cfbconf is based on a novel way of defining the conflict between a rule and a training data instance. It quantifies the amount of conflict that a rule possesses with respect to all instances belonging to different classes in the data set   4.1  A conflict measure for a rule A conflict measure between a given rule and a training data instance is defined under the following three assumptions Assumption 1 The conflict between a given rule and the instances belonging to different classes should be high. In the contrast, there is no conflict between the given rule and any instance belonging to the same class Assumption 2 If the classes of a given rule and an instance are different, and all the feature-value pairs in the antecedent of the rule are identical to those features in that instance, the conflict is the highest Assumption 3 If the classes of a given rule and the instance are different, and all the feature-value pairs in the antecedent of the rule are different from those features in that instance, there is no conflict \(the lowest Table 1 shows an example of three data instances in class C 2 showing only the values of those features \(i.e f 1 f 3  f 4 f 6 peared in the antecedent of rule \(i.e  f 1 Y  f 3 Y f 4 N f 6 N  000 C 1  1 1 r denotes the first rule of class C 1 and  f 4 N means that the value of f 4 in the rule is N The conflict between 1 1 r and all data instances in C 2 should be high. Data instance 2 1 T gives the highest conflict to 1 1 r because it misclassifies this data instance. While there is no conflict to data instance 2 3 T  1 1 r can classify this data instance correctly. Though data instance 2 2 T will not be misclassified by 1 1 r this data instance is considered to be close to the rule because the values of features f 1 f 4   and f 6 are the same From the aforementioned assumptions, we propose a function to calculate the conflict between the given rule and the training data instance with the following characteristics a  The conflict should be a decreasing function of the distance between the rule and the training data instance in an unmatched class b  The conflict should be an increasing function of the amount of conflict between the class labels  Table 1. The example data instances in class C 2   f 1  f 3  f 4  f 6 Class 2 1 T  Y Y N N C 2  2 2 T Y N N N C 2  2 3 T N N Y Y C 2   We apply the Manhattan distance as shown in Equation 3 to analyze the distance between the j th  feature of the given rule  k l r of class k and the training data instance   k i T in class k   k   000 k   k l F and i F be the set of features appeared in the antecedent of rule  k l r and the corresponding features in training data instance   k i T  respectively. We can calculate the normalized distance   i k l FFDis   by dividing the total number of features in the antecedent of the rule \(as shown in Equation 4    otherwise 1 identicalarevalue featurethe whenever 0 000 000 000 000 j d  3    1  l N j j i k l NdFFDis l 000y 000 000 000 000 000 000 000 000 000 000 000 000 000  4  The proposed conflict measure between the given rule  k l r and the training data instance   k i T is calculated by referring to Characteristics \(a\ and \(b\d their distance is calculated using Equation 5. Since we consider only the conflict of the rule to all data instances of the unmatched classes, the conflict is 0 if their classes are identical 000\013\000\014 000\013\000\014   1 or  identical\ are classes if\(\(their  ,0  different  are classes their if ,\,\(1  2   000 000 000 000 000 000\037 000\020 000 000D 000D i k l i k l il FFDis FFDis conflict  5 Moreover, we only consider the conflict of the rule and close data instances of unmatched classes, due to alleviating the effect of noisy data in the training data. We define the 001 value as a closeness threshold to prune all non-close data instances The constraint is that the conflict of the data instance whose distance to the given rule is larger than 000D 1 is not considered. Thus, the conflict variation is primarily dependent on the 001 value. The 258 


larger 001 value is assigned, the more number of instances are pruned. From the example in Table 1, when the 001 value is 3, the conflict between rule 1 1 r and data instance 2 1 T is 1 since its distance to the rule is 0. For data instance 2 2 T its distance to the rule is 0.25 and its conflict to 1 1 r is 0.0625. The conflict to data instance 2 3 T is 0 because its distance to 1 1 r is 1, which is greater than 0.33 \(1/3 Since the most suitable 001 value varies from the characteristics of a data set, the model evaluation module in our proposed framework in Section 3 aims to find this value adaptively. There are three pre-defined values in this module which are the initial and maximum 001 values and the increment parameter. For the maximum 001 value we always set it to the number of features in the data set The reason is best demonstrated by the following example. If the number of features is 4 and the assigned maximum 001 value is 4, we will consider only the data instances whose distance to the rule is less than 0.25 \(1/4 In the case of the data instance whose values of three features are matched and the value of one feature is not matched to the rule, we won’t calculate the conflict of this data instance since their distance is 0.25. It means that we consider only the exact matched data instance whose distance is 0. In our experiments, we set the maximum 001 value to 10 since there are 10 features in the experimental data set. For the other pre-defined values, we set the initial 001 value to 1 and the increment parameter is also set to 1  4.2  The proposed conflict-based confidence measure Now we consider a conflict-based confidence measure of a rule defined in a way that it would take the close data instances into account. If a rule is not good, there will be a significant number of close data instances which belong to different classes and there will probably be a larger number of conflicting data instances. Consequently, the assigned confidence will be reduced significantly. Based on this fact, we propose a function that calculates a conflict-based confidence of each rule  k l r as shown in Equation 6, where N TC is the total number of classes. We average the conflict measures for each data instance in the unmatched classes by dividing the number of all data instances in the different classes. Then, the average conflict measure is used as a penalty score minus from the maximum confidence value which is 1. From the example in Table 1, if there are only three data instances of the unmatched classes in the database, the conflict-based confidence of the rule 1 1 r is 3 0625.001 1 000\016\000\016 000\020 0.6458 1  1          TC ki k i CCT il k l Nk CCT Conflict Confidence ki k i 000 \000\005 000 000 000 000 000 000 000z 000\005 000\020\000 000 000 000 000 000 000 000 000z\000\005 6  5  Experimental Results In this section, we aim to evaluate the proposed conflict-based confidence measure with respect to the classification accuracy. Three performance evaluation metrics used are precision, recall, and F1 values as shown in Equations 7, 8, and 9. Let TP, FP and FN be the numbers of true positive, false positive, and false negative, respectively. The F1 measure is considered as a more suitable performance metrics than precision and recall values individually, since it is the harmonic mean of precision and recall values   Precision FP T P TP 000\016 000  7    Recall FNTP TP 000\016 000  8   Recall Precision Recall Precision 2 1F 000\016 000u 000u 000  9   Experiments were run on a 3.00 GHz Pentium 4 CPU with 1GB of RAM running under Windows Command Processor. The data set used is the bank.arff data set available at [7 o nly nom ina l data an d belongs to two classes \(YES and NO\. Moreover, we used this data set to generate balanced and imbalanced data sets as shown in Table 2. We used the whole bank.arff as a balanced data set and randomly removed some of data instances belonging to Class Yes to generate an imbalanced data set. For each data set, we also randomly separated data into two sets used for training and testing  Table 2. The details of experimental data sets Data Set Class Total Training Testing Balanced YES 274 183 91 NO 326 217 109 TOTAL 600 400 200 Imbalanced YES 40 27 13 NO 326 217 109 TOTAL 366 244 122  5.1  The effect of various 001 values Since the conflict variation is primarily dependent on the 001 value, this experiment aims to decide the most suitable 001 value for each data set adaptively based on the characteristics of the data set. In our experiments, for each data set, ten 001 values ranging from 1 to 10 with an increment by 1 are used. Figure 2 shows that the average F1 values on various 001 values of the first-fold experiments on both balanced and imbalanced training data sets. Both graphs increase to the highest peak decrease, and then converge to steady classification 259 


accuracy. As can be seen from this figure, we can conclude that the difference in accuracy can be large with respect to the different 001 values. In Figure 2, the best 001 values of the first-fold classification models on the balanced and imbalanced training data sets are 4 and 3 respectively  Figure 2. Average F1 values on various 001 values of the first-fold experiments on both balanced and imbalanced training data sets 5.2  Performance comparison on a balanced testing data set In this experiment, we intend to compare the classification accuracy on precision, recall, and F1 among the CARs ranked by the traditional confidence measure conf and the proposed conflict-based confidence measure based on the interleaving ordering strategy interleaving cfb-conf To make the experimental results more convincing, 10-fold cross validation is used. For each run, referring to the previous experiment, we have to find the most suitable 001 value for the generated CARs in the model evaluation module Table 3 shows the 10-fold cross validation comparison performance between the aforementioned methods on a balanced data set for Classes Yes and No and their average values as well as the standard deviation values \(in parentheses\s expected, the performance of the interleaving conflict-based associative classification framework can achieve better results of all performance evaluation measures on all classes with lower standard deviation values, comparing to the performance of the traditional confidence measure. Figure 3 demonstrates the bar chart that illustrates the average performance evaluation. According to this figure, we can conclude that the overall performance of CARs ranked by our proposed conflict-based confidence measure is better than that of the rules ranked by the traditional confidence measure  5.3  Performance comparison on an imbalanced testing data set We also conducted an experiment on an imbalanced training data set  Table 4 shows the comparison performance between the aforementioned methods on an imbalanced testing data set for Classes Yes and No  and their average values as well as the standard deviation values \(in parentheses\gure 4 shows the overall performance comparison between the aforementioned two rule ranking strategies. As can be seen from this figure the performance of the precision, recall, and F1 values of the CARs ranked by the traditional confidence measure are very bad, since all rules totally misclassify the instances of Class Yes the non-majority class\. Since it cannot classify the instances of Class Yes for all 10 runs, the evaluation measures \(Precision, Recall and F1 for each run are equal. Thus, the standard deviations \(SD of these measures are 0. In contrast, the experimental results of those ranked by our proposed interleaving conflict-based confidence measure show better performance  Table 3. Performance comparison of 10-fold cross validation between conf & interleaving cfb-conf methods on a balanced testing data set Class Measures Eval Conf 000r SD Interleaving Cfb-Conf 000r SD Precision\(YES 83.28 000r 3.96 000r 2.86 Yes Recall \(YES 75.71 000r 4.29 000r 3.14 F1\(YES 79.18 000r 2.21 000r 1.58 Precision \(NO 81.21 000r 2.44 000r 1.97 No Recall \(NO 87.06 000r 4.16 000r 3.33 F1\(NO 83.96 000r 1.92 000r 1.57 Precision \(Avg 82.25  000r 2.09 83.87  000r 1.47  AVG Recall \(Avg 81.39  000r 1.92 83.30  000r 1.46  F1 \(Avg 81.81  000r 1.97 83.83  000r 1.46    Figure 3. Average precision, recall, and F1 values of 10-fold cross validation between conf & interleaving cfb-conf on a balanced testing data set 6  Conclusion In this paper, we propose an interleaving conflictbased associative classification \(AC\framework However, the traditional confidence measure which is used by most of the AC algorithms in the ranking process has a low discrimination power. To address this issue, a new confidence measure called conflict-based 260 


confidence measure is proposed which applies a distance function to find a conflict between a rule and all training data instances belonging to different classes in the training data set. Moreover, our proposed framework incorporates an interleaving ordering strategy in ranking the rules. The experimental results show that the CARs ranked by our proposed conflict-based confidence measure achieve a better performance than those ranked by the traditional confidence measure in both balanced and imbalanced data sets  Table 4. Performance comparison of 10-fold cross validation between conf & interleaving cfb-conf methods on an imbalanced testing data set Class Measures Eval Conf 000r SD Interleaving Cfb-Conf 000r SD Precision\(YES 0.00 000r 0.00\1.09 000r 0.47 Yes Recall \(YES 0.00 000r 0.00\23 000r 10.38 F1\(YES 0.00 000r 0.00\70 000r 0.94 Precision \(NO 89.34 000r 0.00\81 000r 5.54 No Recall \(NO 100.00 000r 0.00\ 14.77 000r 7.80 F1\(NO 94.37 000r 0.00\70 000r 10.90 Precision \(Avg 44.67  000r 0.00 52.45  000r 2.98  AVG Recall \(Avg 50.00  000r 0.00 52.00  000r 2.25  F1 \(Avg 47.19  000r 0.00 52.22  000r 2.57    Figure 4. Average precision, recall, and F1 values of 10-fold cross validation between conf & interleaving cfb-conf on an imbalanced testing data set 7  References  1 R A g rawal and R. Srika n t F ast Al gorith m s  for Mining Association Rules Proceedings of the 20 th  International Conference on Very Large Databases 1994 pp. 487-499  2 R. Ag r aw al, T. I m ie l insk i., and A. Sw a m i  M ining  association rules between sets of items in large databases Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data  Washington, DC, 1993, pp. 207-216   Don g X  Zhan g L W o ng and J. Li  C AEP  Classification by Aggregating Emerging Patterns Proc Second Int’l Conf. Discovery Science \(DS’99 Dec. 1999 pp. 30-42   u echaiyas a k, M.L Shy u  an d S.-C. Chen  Identifying Topics for Web Documents through Fuzzy Association Learning International Journal of Computational Intelligence and Applications \(IJCIA  Special Issue on Internet-Based Intelligent Systems September 2002, vol. 2, no. 3, pp. 277-285    Li J Han and J   Pei   C MA R A ccur a te and  Efficient Classification Based on Multiple ClassAssociation Rules Proc IEEE Int’l Conf. Data Mining ICDM’01 Washington, DC, Nov. 2001, pp. 369-376    W Hsu, an d Y. Ma Integ r ating Class if i ca tion and Association Rule Mining Proc. Fourth Int’l Conf Knowledge Discovery and Data Mining \(KDD’98 New York, Aug. 1998, pp. 80-86   a s h er   h ttp   m aya.cs.dep au l.ed u Classes   Ect584/Weka/classify.html,” School of CTI, DePaul University, 2005   L  Sh yu S.C  Chen an d S.H. Rubin St o chasti c  Clustering for Organizing Distributed Information Source IEEE Transactions on Systems, Man and Cybernetics Part B, vol. 34, no. 5, October 2004, pp 2035-2047   basing ha, J Zhang, K Pr e m aratne, M.-L  Shyu, M. Kubat, and K.K.R.G.K. Hewawasam Using Association Rules for Classification from Databases Having Class Label Ambiguities: A Belief Theoretic Method Edited by T.Y. Lin, Y. Xie, A. Wasilewska, and C.-J. Liau, Data Mining: Foundations and Practice, pp 523-546, Springer-Verlag, 2008, ISBN 978-3-540-784876  10 P.-N Tan, M St einbach and V. Ku m ar Introduction to Data Mining Addison Wesley; US Ed Edition May 2005, Chapter6, Section 6.7 pp. 370-786  11  F T h abtah   C ha l lenges and I n terest ing Resear c h  Directions in Associative Classification Sixth IEEE International Conference on Data Mining-Workshops ICDMW’06 Dec 2006, pp. 785-792  12 K. W ang, S. Z h ou, an d Y. He G r o w i ng  D ecisio n  Trees on Support-Less Association Rules Proc. Sixth ACM SIGKDD Int’l Conf. Knowledge Discovery and Data Mining \(SIGKDD’00 Boston, Massachusetts  Aug 2000, pp.265-269 261 


 Kluwer Academic Publishers Springer, New York 1st edition, 2001 14  S c h e f f e r   T   F i n d i n g  A s s o c i a t i o n  Ru l e s  t h a t  T r a de Support Optimally Against Confidence th The Elements of Statistical Learning self_care_guide/Urogenital/Postate%20Cancer.pdf  Accessed, 25 August, 2008 11  A g r a w a l   R  T   I m i e l i n s k i     A   S w a m i   M i n i n g  association rules between sets of items in large databases, In Proceedings of the 1993 ACM SIGMOD international conference on Management of data  The Netherlands 42 2001 61-95  Ordonez C Association rule discovery with the train and test approach for heart disease predictio n 207\226 216 12 001 13  H a s t i e   T    R  T i b s h i r a n i     J  H   F r i e d m a n   Proceedings of the 5th European Conference on Principles and Practice of Knowlege Discovery in Databases\(PKDD'01 IEEE Transactions on Information Technology in Biomedicine, 10\(2\, 2006. 334 \226 343 001 Freiburg, Germany : SpringerVerlag, 2001. 424-435 15  F l a c h   P  A     L a c h i c h e   N   Co n f i r m a t i o n g u i d e d  discovery of first-order rules with Tertius 10  P h a r m a c y   h t t p    w w w  p h a r m a c y  g o v  m y    


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79–88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221–230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221–230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89–98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35–45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178–187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46–55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133–142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23–34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192–201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49–62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316–325 2007  T  Zimmermann and P  W eißgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2–6 May 2004  T  Zimmermann P  W eißgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563–572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 



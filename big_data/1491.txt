On Some Fuzzy Extensions of Association Rules Patrick Bosc Olivier Pivert IRISA/ENSSAT Technopole Anticipa BP 447 22305 Lannion Cedex France bosc@enssat.fr pivert@enSsat.fr Abstract This paper discusses the semantics of two fuzzy exten sions of the classical concept of an association rule Both extensions are based on the aggregation of sufficiently close data into hzzy sets by means of user-defined fuzzy partitions of the domains thus leading to fizzy generalized association rules. The first approach is based on fuzzy cardinalities 
whereas the second one relies on gradual rules. The issue related to the evaluation of the validity of such rules is discussed and the principles of two discovery algorithms are outlined 1 Introduction During the last years, the number and volume of data bases have tremendously increased and the need for extracting some condensed information has received attention. The related research area, called knowledge discovery in databases KDD or data mining aims at the discovery of useful information from large collections of data. The discovered knowledge can be rules describing properties of data frequently occurring patterns clusterings of 
the objects in the database, etc. Among the recent works, a great deal of attention has been paid to the discovery of a specific type of rules called association rules  13 Association rules are of the type when the properties A and B are satisfied in the data then property C is also satisfied Let us give a simple formalization of the problem 2 Definition 1 Given a schema R  A  A of attri butes with domain 0 I and a relation r over R 
an association rule about r is an expression of the form: X a B where X E R and B E R  X The intuitive meaning of the rule is that if a row of the matrix r has a I in each column of X then the row tends to have a 1 also in column B This semantics is captured by the measures of fiequency and confidence Given W s R we denote by sup\(W r the frequency of W 
in r the fraction of rows that have a 1 in each column of W The frequency of the rule X 3 B in r is defined to be sup\(X U B r and the confidence of the rule is sup\(X U B r X r In the discovery of association rules, the task is to find all rules X B such that the frequency of the rule is at least a given threshold o and the confidence of the rule is at least another threshold 8 
In other words one wants to obtain rules that are sufficiently frequent and valid Many works related to the discovery of association rules aim at optimizing the process \(see for instance 3,4 561 However, another line of research consists in investi gating the extent to which it is possible to generalize the notion of an association rule in order to capture a richer range of properties As already stated by R Yager 7 the use of fizzy logic seems particularly interesting in the context of knowledge discovery inasmuch as it allows to express 
properties about the current content of a database as statements of the natural language, thus providing knowledge that can be easily understood by nonexperts in this paper, we describe two fuzzy extensions of the notion of an association rule First in Section 2 the principles underlying these fuzzy extensions are defined and we point out the semantic characteristics of the corresponding fuzzy properties The issue related to the discovery of such fuzzy association rules is dealt with in Sections 3 and 4 2 Two Fuzzy Extensions of Association Rules The starting point is to aggregate sufficiently close 
data into fuzzy sets on the basis of fuzzy partitions which are meaningful for a user Another key idea is to view fuzzy sets as a way for describing the different possible labellings that can be made by a user for borderline data Each partition is ordered and a fuzzy set say A can only overlap with its predecessor Ai and its successor Ai when they exist Moreover for each partition we assume Vu A,\(u  1 Thus for a given U in Page 1104 


an attribute domain it either fully belongs to a fuzzy set Ai or partially belongs to two successive fuzzy sets the sum of its two membership degrees being 1 lt is worth noticing that the principle consisting in i the data by means of a more general vocabulary and ii\trying to discover properties in the rewrited database has also been advocated in a nonfuzzy context For instance in SI the authors use a hierarchy of Boolean concepts in order to rewrite a relation so as to discover different types of rules see also 9 IO Nevertheless, the fact of using linguistic labels i.e fuzzy sets more flexikde to rewrite the data allows to discover more robust rules The key point with a fuzzy partition is that the borderline data are taken into account in each of the two classes which decreases the sensitivity to the boundaries 2.1 Notations Let R be a nonfuzzy relation involving attributes 4 23 C  We assume that the user is interested in possible association rules involving a given subset of attributes We only consider the projection of R on this subset and for notational simplicity we use a 3 element subset of attributes say A B and C in the following which is sufficiently general for discussing the main issues Let 3 b ck denote a tuple of R restricted to attri butes A 3 and C Let Dm D Dc be the atlribute domains We assume that each domain is equipped with a fuzzy partition A Al  Ad B 132  Bnb C C2  C respectively 2.2 Extended Association Rules Based on Fuzzy This approach corresponds to a straightfclrward extension of the usual definition of an association rule Its principle is the following the validity of the nile 4 A 3 a B depends on the number of tuples which are A on the one hand and on the number of tuples which are A and B on the other hand Cardinalities For instance using scalar cardinalities 113  the validity of the rule A A 3 B 9 can be defined as which is nothing but a straightforward extension of the usual definition of the confidence Remark 1 As in the usual nonfuzzy case the term rule may be considered improper inasmuch as a pro perty modeled this way is not based on an implication It is worth noticing that such a property does not model any constraint on the %values, and as such it does not induce any canonical notion of exception Remark 2 In accordance with the linguistic nature of such an extended association rule it is also possible to interpret the notion of validity in a flexible way which corresponds to introduce some tolerance and consider that a rule can be seen as perfectly valid even though the ratio \(confidence\above is strictly less than 1 The association rule obtained is then a fuzzy quantified proposition of the form most of the tuples of R that are A are also B The general principle described above has been advocated by Yager 7 and more recently by Kacprzyk 1121 In this type of approach a degree of validity for an extended association rule is computed as the degree of membership of a scalar relative cardinality to a fuzzy quantifier An alternative solution is to compute the degree of validity by means of an ordered weighted average OWA modeling the fuzzy quantifier, but the principle is basically the same The use of scalar cardinality which amounts to the addition of membership degrees counts a collection of several elements with small membership grades whose sum is 1 as equivalent to one element with full membership for instance this might be debatable or even misleading from a user point of view In  131 it is rather suggested to use fuzzy cardinalities This is also the choice that we make here and the corresponding approach is detailed in section 3 2.3 Extended Association Rules Based on Gradual A statement of the form A A f B B stating that tuples that rewrite A on 4 also rewrite B on B can also be interpreted in the context of gradual rules  141 in order to express a constraint on the value for each tuple in the database The extended association rule then means for any tuple t the more t.A is A the more t.B is BSI i.e Rules where 3f denotes a fuzzy implication Remark. There exists a connection between this notion of an extended association rule and that of an extended functional dependency Such a rule is actually 0-7803-7078-3/0V$l0~00 C IEEE Page 1105 


equivalent to a functional dependency where a change of granularity has been applied to the domains  151 In this case especially it makes sense to introduce some tolerance by replacing the underlying universal quantifier  interpreted as a minimum  with a fizzy one such as most of It can be indeed desirable to limit the effect of noise  and of exceptions in general  by neglecting \(at least partly the bad" tuples i.e the tuples t such that the truth degree of p4\(t.A  pBJt is very low Let us also notice that the effect of an exception upon the overall validity of the rule depends strongly on the implication used It is parti cularly drastic if the implication is such that a 3 0  0 as it is the case with Rescher-Gaines implication a b  1 if b L a 0 otherwise Gadel implication a 3 b  1 if a 2 b b otherwise\and Goguen implication \(a 3 b  1 if a 2 b b/a otherwise An algorithm aiming at discovering extended association rules based on Rescher-Gaines implication is described in section 4 3 Discovery of Extended Association Rules Based on Fuzzy Cardinalities 3.1 The Aggregation Procedure From R \(restricted to A B 6 we build a new relation  for R summarized in a two main steps procedure which is now described The idea is to perform a kind of information compression 3.1.1 The Labelling Step For each tuple ai b ck we replace it by one or several tuples of fuzzy sets A B C subject to the constraint Thus a bj ck may be replaced by one tuple A B C if all the three degrees of membership are equal to 1 or by several up to 23  8 in case one or several of the element\(s in the tuple belong to two fuuy sets For instance if Ar\(ai  1 B,\(bj  0.8 B,+,\(bj  0.2 c+l\(ck  0.6 ct\(ck  0.4 we give birth to the tuples A 0.8/Bs 0.6/Ct-r A O.2/Bs+1 0.6/C,.1 A O.2/Bs+1 0.4/Ct A 0.8/BS O.4/Ct where we keep track of the membership degrees A stands for UA This corresponds to all the possible readings of the tuple a bj ck in terms of the vocabulary provided by the fuzzy partitions In a data mining context it is not necessary to store the summarized relation  The only additional data that have to be stored are the hzzy cardinalities whose computation is described in the following subsection 3.1.2 Fusion Step and Computation of Fuzzy We want to know how many tuples from R are A are B are C are A and B  are A and B and C and this for all the fuzzy labels In order to have a more accurate representation of the relation fuzzy cardinalities are used instead of scalar ones It is then necessary to compute the different cardinalities related to each linguistic label and to the diverse conjunctive combinations of these labels Cardinalities All the tuples of the form x/A y/B dC which are identical with respect to the three labels A B and C are fused into one tuple A B C of q At the same time we compute the cardinalities FAr FB Fc F&Bs FArC FBsc FA$,c is a hzzy set defined on the integers 0 1  which represents the fuzzy number of tuples which are somewhat A resp B C A and B A and C B and C A and B and C and which are fused into the considered tuple for all the combinations of labels appearing in at least one tuple FB,Ct FA where FA resp FB FC FA,B of Each cardinality is computed in an incremental way see  131 It is of the form O/O    O/n-1  l/n  hl/\(n+l    hk/\(n+k  O/\(n+k+l   with 1  hl 1  2 hk  I  0 and n 2 0 k 1 0 Let us recall that this expression represents a cardinality that possibly equals n to degree 1 and possibly equals n+k to degree h.k see e.g  161 Let us notice that the maximum number of tuples that can be obtained in  is na  nb  nc i.e the product of the numbers of labels appearing in the considered partitions Thus the summarized relation can be significantly smaller than the original relation R for large relations 3.2 Computing the Validity of Rules In this approach, we assume that the user gives the at tributes 4 E or C that he/she wants to appear in the discovered rules The objective is then to find all the rules of the form most of the tuples of R that are A are also B The number FG of tuples of R which are 0-7803-7078-3/0l/!$l0.00 C lEEE Page 1106 


A and B as well as the number FAr of tuples which are A have been computed in the preceding step. The frequency of the rule denoted by FRA,Bs is a relative cardinality that corresponds to the fuzzy proportion of tuples in R which are A and B It is obtained by changing FAr  1/0    l/n    hi\(n+i   into FRheS  I/\(n/K    n+i   where K lis the number of tuples in R Conceming the degree of validity of the rule several approaches can be thought of for instance  by analogy with the nonfizzy case and with the ap proach based on scalar cardinality of fuzzy sets it is possible to compute the quotient p  FqB  Fh see  171 This quotient corresponds to the confidence of the rule The validity of the rule can then be defmled as the necessity of the fuzzy event "most of relativdy to the possibility distribution p It is equal to minu support\(p C4nost\(u 1  P\(U which is nothing but the inclusion degree of p in the quantifier most of This validity evaluates the extent to which the fuzzy proportion p is close to 1 in the sense of the fuzzy quantifier\However this quotient of two hzzy numbers can lead to a too imprecise result An alternative solution is to use a constrained division in order to get a more accurate result This issue would necessitate a more detailed discu.ssion that cannot be included here  to evaluate the extent in terms of a necessity de,gee to which FAal is close to i.e not much smaller than FA Now let us say a few words about the complexity of the process The discovery process involves i one ex haustive scan of the relation ii the computation of the fuzzy cardinalities for all the combinations of Labels appearing in at least one tuple of the summarized relation iii the computation of the validity degrees associated to all the possible rules The main problem relates to the second point For instance with three attributes each attribute being associated with a hzzy partition including five labels the maximum number of tizzy cardinalities to be computed is equal to 215 This is still reasonable but obviously an increase in the number of attributes and labels results in a combinatorial growth that cannot be neglected Thus the design of optimization techniques is a matter of great importance that should be dealt with in future works An alternative solution would be to build a matrix of membership degrees \(one row corresponding to a tuple in the original relation and to look for frequent combinations of labels by means of an algorithm including pruning criteria as it is done in the nonfuzzy case before evaluating the possible rules associated to each frequent set of labels Then it would not be necessary to compute all the fuzzy cardinalities, but only some of them. Such a technique is proposed in  181 for the discovery of rules based on scalar cardinalities 4 Discovery of Extended Association Rules Based on Gradual Rules 4.1 Principle Here the objective is the extraction of graded rules of the form which are based on a fuzzy implication Zf More generally the left part of the rule can be composed of a conjonction of pairs x X where x denotes an attribute and Xi is a linguistic label belonging to the fuzzy partition defined on the domain of X An algorithm aimed at discovering such extended association rules based on Rescher-Gaines implication nongraded in this case\has been proposed in 19 In this case, the validity of the rule above is equal to where a aRG b  1 if b L a 0 otherwise The algorithm is just outlined here for the sake of brevity The extraction algorithm is based on an iteration over tuples t of the relation R involved It defines a minimal set S of rules which are valid on R i.e whose truth value is 1 Contrary to the approach based on cardinalities it does not involve a preliminary labelling step the different satisfaction degrees related to a given tuple are computed at the time this tuple is accessed Roughly the algorithm starts from an empty set S and the tuples t of relation R are successively processed The invariant of the loop is from S it is possible to obtain any rule which is valid on already processed tuples The progression consists in computing the set S made of rules which are valid for t and to merge S and S to obtain the new set S The algorithm obtained has a linear complexity with respect to the number of tuples 0-7803-7078-3/Ol/$l0.00 C IEEE Page 1107 


The main advantage of using both Rescher-Gaines implication and the universal quantifier is that the cardinality of the set of rules remains limited a rule is discarded as soon as it is violated by a tuple In the case of a multivalued implication there is no such notion of violation unless a satisfaction threshold attached to the validity degrees of the rules is used The situation is even worse when a fuzzy quantifier is used instead of the universal one because then a threshold cannot be applied to the rules before the scan of the relation is complete. As a matter of fact, no rule can be discarded before all the tuples have been accessed, unless it is possible to find some heuristics allowing to conclude that the truth degree of a proposition such as Q X B are A where Q denotes a fuzzy quantifier X denotes a set of tuples and A and B denote fuzzy predicates cannot be greater than a given threshold as soon as a sufficient number of sufficiently bad tuples have been accessed This question should be studied in future works Let us also notice that as for the rules based on cardinalities, an altemative solution would be to build a matrix of satisfaction degrees one row for each tuple and to compute first the frequent set of labels as it is done in the nonfuzzy case but this would necessitate to i introduce a threshold on the cardinalities attached to the antecedent parts of the rules, ii find some efficient pruning criteria analogous to those used in a nonfuzzy context 4.2 Informativeness of the Rules A difficulty stems from the definition of an implica tion which is true even if the antecedent is false In other words, a rule can be valid only because no tuple of the relation fulfills its condition Two criteria seem particularly important to evaluate the informativeness of a rule The first one concerns the amount of tuples which support this rule i.e the tuples which more or less fulfill the condition part of this rule Rules which are supported by only a very small amount of tuples can be considered as rules modeling exceptional or unusual situations  The second criterion concems the level of support as sociated to a given rule. Actually, the number of tuples which support each rule is not a sufficient information Indeed, a rule can be supported by a large amount of tuples but their membership degrees to the condition part of this rule can be rather low which means that there is no ypicaf tuple for this rule in the database In conclusion the informativeness of a rule can be measured by both the number of tuples which support the rule and their degree of support This twofold information can be encoded by means of i a fuzzy cardinality or ii a histogram representing the number of tuples included in each a-cut of the condition part of the rule. Then, an expert can use this histogram or the corresponding fuzzy cardinality to determine the interest of each of the produced rules This can be done as an interactive post-processing added to the mining algorithm Further studies of the notion of informativeness could lead to an automated processing The selection of interesting rules could then be included in the mining algorithm itself 5 Conclusion In this paper, two hzzy extensions of the notion of an association rule have been investigated. Both are based on the use of fuzzy partitions meaninghl for the user defined on the attribute domains The first approach corresponds to a straightforward extension of the usual definition: the validity of a rule depends on the fuzzy number of tuples which support its antecedent part on the one hand, and on the fuzzy number of tuples which support both its parts on the other hand The general form of such an extended as sociation rule is a fuzzy quantified statement of the form most of the tuples which are A are also B An algorithm including two steps is described the first step performs a kind of information compression and computes the fuzzy cardinalities corresponding to the different combinations of fuzzy labels The second step uses these cardinalities in order to evaluate the validity of the different possible rules involving the considered attributes Two definitions of the validity are suggested In the second approach an extended association rule is based on a fuzzy implication and its result may be either truelfalse or in 0 I The semantics of such rules allows to represent gradual properties of the form the more X is A the more Y is B In other words they allow to express constraints on the values taken by the attribute in the conclusion part of the rule depending on the values taken by the attributes in the antecedent part The principle of a discovery algorithm is outlined in the special case where the implication used is Rescher-Gaines one Future works should address the issue of designing efficient algorithms for the discovery of rules based on multivalued implications It would also be of interest to study the extent to which the usual techniques 0-7803-7U78-3/0U$10.00 C IEEE Page 1108 


illustrated for instance by the Apriori algorithm 3 can be adapted in order to discover hzzy association rules such as those described here 6 References Press 1988 I61 D Dubois and H Prade 223Fuzzy cardinality and the modeling of imprecise quantification\224 Fuzzy Sets and Systems 16 1985 pp 199-230 D. Dubois and H Prade Possibility Theory Plenum I71 R Agrawal T Imielinski and A Swami 223 Mining as I81 G Chen Q Wei and E Kerre, \223Fuzzy data mining sociation rules between sets of items in large Discovery of fitzzy generalized association rules\224 databases\224 Proc ACM SIGMOD\22293 1993 pp 207 Recent Issues on Fuzzy Databases G Bordogna and 216 G Pasi eds Physica-Verlag 2000 pp 45-66 H Mannila 223Methods and problems in data mining\224 P Bosc L LiCtard 0 Pivert 223Extended functional Proc ICDT\22297 vol 1 186 of LNCS Springer-Verlag dependencies as a basis for linguistic summaries\224 1997 pp 41-55 Proc. PKDD\22298 1998 pp 255-263 R Agrawal H Mannila R Srikant H Toivonen and A.1 Verkamo 223Fast discovery of association rules\224 Advances in Knowledge Discovery and Data NIining AAA1 Press 1996 pp 307-328 H Mannila and H Toivonen 223Levelwise search and borders of theories in knowledge discovery\224 Data Mining and Knowledge Discovery 1\(3 1997 pp 241 258 R Ng L.V Lakshmanan J Han and A Pang 223Exploratory mining and pruning optimization of constrained association rules\224 Proc ACM N Pasquier Y Bastide R Taouil and L Lakhal 223Eficient mining of association rules using closed itemset lattices\224 Information Systems 24 l 1999 pp R.R Yager 223Database discovery using fuzzy sets\224 Int J oflntefligent Syst 11\(9\1996 pp 691-712 1 Han Y Cai and N Cercone 223Knowledge dis\222covery in databases An attribute-oriented approach\224 Proc 18th VLDB Conference 1992 pp 547-559 J Han and Y Fu 223Discovery of multiple-level asso ciation rules tiom large databases\224 Proc VLDB\22295 R Srikant and R Agrawal 223Mining generalixd as sociation rules\224 Proc VLDB\22295 1995 pp 407-4.19 A De Luca and S Termini 223Definition of non-proba bilistic entropy in the setting of fuzzy set theory\224 Information Control 20 1972 pp 30 1-3 12 J Kacprzyk 223Fuzzy logic for linguistic summarization of databases\224 Proc FUZZ-IEEE 22199 1999 pp 8 13 818 D Dubois and H Prade 223Fuzzy sets in data summaries  Outline of a new approach\224 Proc D Dubois and H Prade 223What are fuzzy rules and how to use them\224 Furzy Sets and Systems 84\(2 P Bosc 0 Pivert and L Ughetto, \223Database mining for the discovery of extended functional dependencies\224 Proc NAFIPS 22299 1999 pp 580-584 I91 SlGMOD\22298 1998 pp 13-24 25-46 1995 pp 420-43 1 IPMU\222OO 2000 pp 1035-1040 1996 pp 169 186 Page 1109 


r 0 5  freq  genid  I 1 C 2   inh  I 1 C 1   inh  I 2 C 2  I 1  I 2  r 0 6  cand  I sum  C    freq  P I  C   Figure 8 Mo died rules that sim ulates m ultiset seman tics in Datalog rules r 5 through r 6 to obtain rules r 0 5 through r 0 6 as sho wn in gure 8 In these rules w eha v e used a system dened function called genid  that returns a unique iden tier ev ery time it is called Notice that the rules r 3 and r 4 in R ULES are the only rules that are recursiv e and that they are safe F urthermore it is imp ortan t that w e main tain a set seman tics while w e complete pro cessing these t w o rules b ecause w e need unique deriv ations of the meet irreducible elemen ts in inh  The mo died system R ULES no w b eha v es as exp ected and computes the correct supp ort for item sets in an y kno wledge base K  including our example kno wledge base T  It is imp ortan t to note here that the articial x w e ha v e prop osed ab o v e to sim ulate m ultiset op eration in set based framew ork through the use of genid  function is not necessary in man y systems including CORAL and RelationLog deductiv e database systems F or example CORAL supp orts m ultiset relations bags through multiset declaration Finally  grouping using set v alued terms are also allo w ed in CORAL and RelationLog 8 Wh y the System W orks The reader ma yha v e noticed that the R ULES system did not rely on generating candidate item sets in the w a y apriori has to Unlik e apriori it also do es not rely on a lev el wise computation Instead it uses a few critical observ ations that man y systems fail to notice 4  W e summarize belo w t w o critical observ ations that w e exploit in our system These observ ations follo w from the formal prop erties of transaction kno wledge bases that w e ha v e presen ted in section 5 and section 2  Item sets that are large can be computed from the database in t w o principal w a ys Either they app ear as transactions in the kno wledge base or they are computable from the transactions as follo ws Item sets in the transaction table that are not related b y a subset sup erset relationship in tersect with eac h other to pro duce in tersection virtual no des in the item set lattice meets These in tersection no des in turn in tersect un til they b ecome me et irr e ducible elements  Only a subset of these in tersection no des will b e large item sets These elemen ts can b e generated from the kno wledge base b y computing the least xp oin t of the pairwise in tersection of the elemen ts in the transaction kno wledge base Hence there is no need to generate 4 Zaki and sev eral others also ha v e made similar observ ations in their w ork on closed sets and concept lattices But there are imp ortan t dierences b et w een our observ ations and the manner in whic h w e utilize these observ ations His observ ations and tec hniques rely on a searc h based algorithm for CHARM 25 whic h is essen tial in order to compute the so called closed sets and th us ha v e to b e completely pro cedural an y candidate item sets articially as the w a y apriori do es  All other p ossible item sets are either not large item sets or are redundan t and can b e computed from the other large item sets found in the t w o t yp es of sets computed as ab o v e These observ ations can be in tuitiv ely understo o d from the example belo w Consider another kno wledge base T as sho wn in gure 9 tr ans  t 1 a   tr ans  t 1 b   tr ans  t 1 c   tr ans  t 2 a   tr ans  t 2 b   tr ans  t 2 d   tr ans  t 3 d   tr ans  t 3 e   tr ans  t 4 a   tr ans  t 4 c   tr ans  t 4 d   tr ans  t 5 a   tr ans  t 5 b   tr ans  t 5 c   Figure 9 A new kno wledge base T  Application of rules r 1 and r 3 will pro duce the gr oup and inh facts sho wn in gure 10 group  t 1  f a b c g   inh  f a b c g  40  group  t 2  f a b d g   inh  f a b d g  20  group  t 3  f d e g   inh  f d e g  20  group  t 4  f a c d g   inh  f a c d g  20  group  t 5  f a b c g   Figure 10 Execution trace of T  F ollo wing the con v en tions of lattice building in previous sections w e construct the K mapping in gure 11 for the item set lattice corresp onding to the example kno wledge base T in gure 9 Notice that in gure 11 no de ab 0 3 is an in tersection of no des abc 2 2 and abd 1 1 whic h inherits the transaction coun t of all its ancestors 2 from abc and 1 from abd  to record its total coun t as 3 Notice that its transaction coun t is still zero as it is a virtual no de not app earing in T and becauseitw as created through an in tersection Recall that the total coun t of a virtual no de cannot b e less than an yof its paren ts from whic hitw as created In fact it is alw a ys higher than its paren ts coun t refer to lemma 5.2  de 1 1 ac 0 3  acd 1 1 ad 0 2  0 3 c  0 2 d                     abc 2 2 abd 1 1 0 bd 0 1 cd 0 1 ab 0 3 null 5 0 0 3 b 0 1 e 0 4 a bc 2 acd 1 1 ad 0 2 0 3 c 0 2 d transaction nodes Intersection of transaction nodes Redundant nodes Meet irreducible element l-envelope 40 l-envelope 60 Figure 11 K mapping of the kno wledge base T  F urthermore the in tersection of the transaction no des abc 2 2  abd 1 1 and acd 1 1 could not cross the lev el of 2 item sets i.e ab  ac and ad  as in tersections alw a ys pro duce the meet alw a ys the largest p ossible common subset of 7 


the paren ts In particular the in tersection of these three no des cannot yield a 0 4  T o pro duce a 0 4  w e need to tak e another round of in tersection of the new in tersection no des pro duced in the rst round from T  It turns out that a 0 4 is a meet irreducible elemen tinthe K mapping of T  and hence no further in tersection in v olving a 0 4 is required In general w e need to compute the least xp oin t of the pairwise in tersection pro cess to compute all the in tersection no des and stop only when the set generated at the nal stage are all meet irreducible elemen ts Suc h a least xp oin t computation will only generate no des ab  ac  ad  a and d with abd and acd actually in the rst round In particular the least xp oin t will nev er compute the no des with b  c and bc as sho wn under the so called l-en v elop e in gure 11 Recall that ev ery no de under this en v elop e is a large item set Consequen tly  the l-en v elop e in this example assumes a 40 supp ort for large item sets But notice that the no de b 0 3 has an iden tical total coun t with one of its non-redundan t paren t ab 0 3  Hence b 0 3 is a redundan tnode and th us not computing or generating this no de do es not result in the loss of an y information b ecause w e can infer b 0 3 from ab 0 3  in case w e need to Since w e do not ha v e to generate the redundan t large item sets the R ULES systems w orks just ne But if w e wish to create all the large item sets similar to apriori w e m ust add another rule to ac hiev e this goal as w e do not explicitly compute them as a view d lar ge  The addition of the follo wing rule whic hessen tially copies the coun tof a large item set I to all its subsets X if X do es not exist as a large item set already  will do the tric k r 9  d lar g e  X C   lar g e  I C  X  I  lar g e  X C 2  There is a subtle issue that w e w ould lik e to poin t out here Consider the K mapping sho wn in gure 12 corresp onding to another kno wledge base T not sho wn from whic h w e ha v e remo v ed all the redundan t no des and sho wn only the transaction and in tersection virtual no des A t a rst glance one ma y think that it is p ossible to compute the total coun t of no des or item sets in a lev el wise manner and sa v e time b y not redoing certain computations F or example consider computing the total coun t of no de abc and recall that initially  the no de abc will read as abc 2 0  Assume that w e compute abc 2 3 from abc 2 0 and abcd 1 1 b y adding the total coun tof abc and abcd  Recall that abc 2 0 re\015ects the fact that abc app ears t wice in the database whereas abc 2 3 represen ts the fact that abc app ears t wice as a database transaction and app ears once 3-2=1 as a sub item in another transaction i.e abcd Let us assume for a momen t that w e compute the total coun t of ev ery no de in this fashion starting from no de abcd in a lev el wise fashion  compute the total coun tof eac hnode b y adding the total coun ts of all its paren ts No w for the third lev el from the top to compute the no de coun ts for ac  w e add the total coun tof its paren ts 3+2 giving 5 But as can b e seen from the gure coun t 5 is not really accurate This discrepancy resulted b ecause w e added total coun ts of paren ts instead of the transaction coun ts of ancestors to compute the total coun t of the no de ac  Notice that the coun t corresp onding to ac in abcd w as accoun ted for t wice in no de ac via t w o distinct branc hes as sho wn Similarly ifw e con tin ue with the same sc heme w e will compute a 0 11 for no de a instead of a 0 5 whic h in realit y is the correct total coun tfor a  1 ac 1 ac a 1 a 1 a 1 a 1 a 1                  abd 1 2 null 5 0 0 5 a 1 1 abcd abc 2 3 acd 1 2 ab 0 4 ac 0 4 ad 0 3 Figure 12 K mapping of a new database T sho wing incorrect inheritance of transaction coun t if total coun t of paren ts are used to compute total coun toflo w er lev el no des instead of transaction coun t Our rule system w ork ed correctly b ecause w e either inherited the transaction coun ts in the fr e q rules from a no de that is related via subset-sup erset relationship or b y rst generating the in tersection no de once initializing the transaction coun t to zero rule r 4   and using this in tersection no de to inherit the transaction coun ts whic h no w is in a subset-sup erset relationship with its ancestors Finally  w e added the transaction coun ts with a grouping op eration follo w ed b y a coun t op eration whic hb y denition is the total coun tfor an ynode 8.1 Breaking the Barrier of Pro ceduralit y W ew ould lik e to highligh t here that the three observ ations w e ha v e made early in this section w ere critical in dev eloping a mo del theoretic and declarativ ec haracterization of the large item set computing pro cess as it did not dep end on pro cedural concepts suc h as candidate generation The observ ation that w e only need to generate and test the intersection no des help ed us visualize the pro cess as a sort of Cartesian pro duct of the kno wledge base with itself and compare eac h transaction tuple with the other tuples in the kno wledge base and see if they w ere unrelated b y subsetsup erset relationships Recall that suc h pairs are p oten tial con tributors to an in tersection no de The least xp oin tof the in tersection pro cess help ed b ecause w e kno w that w e ha v e computed all the meet irreducible elemen ts b y no w and no other in tersection no des exists There are sev eral w orks that ha v ein v estigated the issue of declarativ e asso ciation rule mining using SQL 7  23  19  16  11 Most of these w orks sp ecially 23  19 attempt to sim ulate apriori in SQL giving rise to a complicated and a wkw ard metho d They do not exploit the inheren t declarativ e prop erties of transaction databases as w eha v e iden tied in this pap er The inheren t pro ceduralit yoftheir prop osed expressions app ears to be a ma jor b ottlenec k While it is ob viously p ossible to dev elop op erators that hide the complexit y of these expressions the system nonetheless is a wkw ard unnatural and pro cedural whic h ma y ha v e eciency related dra wbac ks F urthermore b y sp ecifying the seman tics in pro cedural terms they compromise the query optimization asp ects of the system The reason for this loss of opp ortunit y is the fact that the pro cess has already b een co ded in to the declarativit y of SQL and th us database system m ust no w consider only lo cal optimization 8 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



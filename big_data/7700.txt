Vasileios Kagklis Giannis Tzimas Vassilios S Verykios 
Computer Engineering  Informatics Department University of Patras 26500 Patras Greece Email kagklis@ceid.upatras.gr Computer  Informatics Engineering Department Technological Educational Institute of Western Greece 30020 Antirio Greece Email tzimas@teimes.gr School of Science  Technology Hellenic Open University 
An Integer Linear Programming Scheme to Sanitize Sensitive Frequent Itemsets 
26335 Patras Greece Email verykios@eap.gr 
Athanasios K Tsakalidis 
Computer Engineering  Informatics Department University of Patras 26500 Patras Greece Email tsak@ceid.upatras.gr 
In this paper we propose a novel approach to address the frequent itemset hiding problem by formulating it as an integer linear program ILP The solution of the ILP points out the transactions that need to be sanitized in order to achieve the hiding of the sensitive frequent itemsets while the impact on other non-sensitive itemsets is minimized We 
Abstract 
present a novel heuristic approach to calculate the coefìcients of the objective function of the ILP while at the same time we minimize the side effects introduced by the hiding process We also propose a sanitization algorithm that performs the hiding on the selected transactions Finally we evaluate the proposed method on real datasets and we compare the results of the newly proposed method with those of other state of the art approaches 
Privacy preserving data mining frequent sensitive itemset hiding integer linear programming 
Keywords 
I I NTRODUCTION Privacy preserving data mining PPDM 2 is the scientiìc eld that investigates techniques to preserve the privacy of data and patterns A classiìcation of PPDM techniques can be found in Kno wledge hiding 4 a subìeld of PPDM aims at preserving the sensitive patterns included in the data that are going to be published Knowledge hiding is usually obtained by a process known in the literature as the data sanitization process As a result of this process sensitive knowledge can no longer be inferred while the utility of the database is maintained as much as possible 
We focus on knowledge hiding in the context of frequent itemset mining The set of frequent itemsets are usually sought during the rst phase in a signiìcant number of data mining techniques Therefore if the frequent itemsets associated with sensitive information are hidden the loss of privacy of this sensitive information is prevented The technique that we propose falls in the category of frequent itemset hiding techniques that are based on the creation of a linear program The solution of the linear program determines the changes that must be made in the database so as to accomplish the hiding of the sensitive 
frequent itemsets In the work of Kagklis et al it is presented a taxonomy of linear programming techniques used for hiding The rest of the paper is organized as follows Section II provides an overview of the related work In Section III we state the speciìc problem and give all the necessary background In Section IV we present the ILP formulation the heuristic for calculating the coefìcients and the proposed sanitization method In Section V we demonstrate the experimental results of the proposed methods in comparison with previous related works Finally Section VI concludes 
our work II R ELATED W ORK Clifton and Marks are among the rst researchers who deal with privacy preservation issues in the eld of data mining and propose data-obscure techniques in order to prevent sensitive patterns from being discovered Later Atallah et al mak e tw o concrete and signiìcant contributions Firstly they prove that the optimal solution of the frequent itemset hiding problem is NP-hard and secondly they propose a greedy heuristic algorithm that turns 1ês into 0ês in the database in order to hide the sensitive patterns 
Sun and Yu introduce a greedy border based approach for hiding sensitive frequent itemsets They propose a heuristic algorithm that takes advantage of the housekeeping between maximally non-sensitive and minimally sensitive frequent itemsets giving an accurate and efìcient hiding solution Moustakides et al rely on the border re vision theory presented in to b uild an algorithm that implements the maxmin criterion Basically the algorithm hides 
  
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 772 
2014 IEEE 26th International Conference on Tools with Artificial Intelligence 1082-3409/14 $31.00 © 2014 IEEE DOI 10.1109/ICTAI.2014.119 771 


002 
  002   002   003    002  003  002  004 005 004 006  002 002  004  004 007   005 002 002 010 003   002      
n m i i i D D D D min min D min min D D m min min i i i min min D min i 
1 2 1 2 1 2 
freq minf minf freq minf SS SS SS SS 
A Deìnitions sensitive itemsets B Problem Description A Linear Programming Formulation B Heuristic Coefìcient Computation 
I i i   i I X I k k D T T T T T X X T X D 002 X X D X D X 002 X  D X D X D D X 002 X 002 002 D F F X I X S S F F X F Y S X Y S F S S S X S Y S X Y F F F F X Y I,X Y 002 X 002 Y D T T   T 002 S F 002 D S D 002 S v c T S D S 002 X 002 v D 002 
sensitive itemsets by eliminating items in such a way that the side effects to the minimum support itemsets in the positive border are minimized The results are of similar accuracy but they are produced in a much more efìcient way than the results in the original border-based algorithm Menon et al were the rst to introduce an inte ger linear programming formulation of the frequent itemset hiding problem The solution of the ILP indicates which transactions need to be sanitized in order to conceal the sensitive patterns The sanitization process is executed separately and independently of the linear programming solution III D EFINITIONS AND P ROBLEM D ESCRIPTION Let be a set of items Any nonempty subset of   is called an itemset An itemset consisting of items is called a itemset Let be a set of transactions where each transaction is considered to be an itemset A transaction contains an itemset  if and only if  The support count of an itemset in  denoted as  is deìned as the number of transactions containing in  whilst the frequency of an itemset in  denoted as  is the fraction of transactions that support itemset in  An itemset is large or frequent in  if and only if its frequency in is at least equal to the minimum frequency threshold  Equivalently is frequent if and only if  where  The set of all frequent itemsets denoted as  is deìned by  Frequent itemsets that the data curator wants to conceal are called and are denoted as  where  Additionally the set of all the sensitive itemsets and their supersets in is denoted as  where and  Given the set of sensitive itemsets wedeìne the set of minimal sensitive itemsets  that is given by  The revised set of frequent itemsets denoted as isgivenby  By its deìnition the revised set of frequent itemsets is the ideal set of itemsets that would still remain frequent after hiding the sensitive itemsets The ideal case is when only the sensitive itemsets and their supersets are concealed It is desirable for sensitive itemsets to get concealed while their supersets are inevitably concealed due to the antimonotonicity property of support  Given a database  a minimum support count threshold  and a set of sensitive frequent itemsets  the frequent itemset hiding problem involves reducing the support of the sensitive itemsets below  by sanitizing selected transactions in database  so that itemsets in cannot be mined from the sanitized database  In other words we want to conceal the itemsets in  whilst having the minimum impact on the utility of the database IV P ROPOSED M ETHOD In this section we describe the proposed method Firstly we present the formulation used to model the frequent itemset hiding problem We start from the method proposed by Leloglu et al by referring to it as the Coef cient-Based Max-Accuracy CBMA method that builds on the method in referred to as the Max-Accurac y MA method W e use a problem formulation similar to this presented for the CBMA method which comprises an improvement over the one used in the presentation of the MA method Next we introduce a new heuristic for calculating the coefìcients of the objective function We will refer to the proposed technique as the Heuristic Coefìcient-Based Approach HCBA Finally we present the proposed sanitization method The frequent itemset hiding problem is modeled with the ILP shown in Fig 1 Each variable and coefìcient corresponds to a transaction  whilst each constraint corresponds to a sensitive itemset in  A constraint contains a variable if the corresponding sensitive itemset is supported by the corresponding transaction The linear system has variables and constraints Equation 1 is the objective function of the ILP that minimizes the number of transactions sanitized Equation 2 dictates that more than transactions supporting each sensitive itemset have to be sanitized in order to conceal all sensitive itemsets Equation 3 imposes that the variables can only take binary values The solution of the linear program indicates which transactions need to be sanitized The coefìcients can be viewed as the cost of selecting speciìc transactions for sanitization The objective of the ILP is to minimize the total cost while achieving zero hiding failure Assigning a different cost to a different transaction can have a great impact on the set of transactions selected for sanitization and consequently on the quality of the sanitized database  For the CBMA method the value of a coefìcient is equal to the number of non-sensitive frequent itemsets that would stop being supported if the corresponding transaction is sanitized by using Algorithm 1 The sanitization of a transaction is accomplished by removing the item contained by most of the sensitive itemsets supported by the corresponding transaction If the value of a coefìcient is high it means that the number of affected non-sensitive frequent itemsets 
002 002 002 
                        
773 
773 
773 
773 
773 
773 
773 
773 
772 


i j i i i 
003  005 004 004  005 004 011       003   005 004      004 011 012 do  004  004  005    004  004        005 004   002 
i T D i i i,j X T D i D j min j min i i i i i i j i j i i X S X j 002 D i i i i i i i i i i i X E D i i i i i j i i j j i i i i i i i i i i i i min i i i 
1 2 3 Figure 1 The ILP Formulation supported by the corresponding transaction would be also high after the sanitization In the proposed heuristic the coefìcient computation is based not only on how many non-sensitive frequent itemsets but also on how much these itemsets are affected by the sanitization process For a transaction  let us deìne the set of non-sensitive frequent itemsets that would stop being supported and refer to it as  This set represents the set of affected non-sensitive frequent itemsets that will be sanitized if transaction is sanitized using Algorithm 2 Although for two transactions and with  might hold this does not guarantee that they are equally prone to introducing side effects One of them might support more itemsets with frequencies closer to the frequency threshold that are more likely to become infrequent Therefore a different cost should be assigned to each one of these transactions We present a heuristic that attempts to capture how many non-sensitive frequent itemsets in are likely to become infrequent For this purpose we deìne a new parameter  which is calculated as follows Let be the item to be removed according to the sanitization Algorithm 2 For each iteration in the block lines 3 22 of Algorithm 2 the currently maximum frequency itemset among the sensitive ones in  containing item  is identiìed Then the value of this parameter is given by 4 Basically this parameter quantiìes the difference between the maximum frequency among itemsets in and the frequency threshold  We use it to estimate which itemsets in  that contain the items to be eliminated might become infrequent after transaction is sanitized Among the affected non-sensitive frequent itemsets in  there are itemsets that if their frequencies is decreased by  they would become infrequent We will refer to this set of itemsets as endangered itemsets and denote their set as  Note that  However a tie could still occur if two or more transactions have equal and set sizes To break ties we use an additional parameter which we call the pricing parameter  which is given by 5 Algorithm 1 Intelligent Sanitization Algorithm 1 for transactions is to be sanitized do all sensitive itemsets supported by transaction items j in item The lower the frequencies of the endangered itemsets in a transaction are the higher the value of the pricing parameter is The coefìcients for our HCBA method are given by 6 In simple words a higher cost is given to transactions with non-sensitive frequent itemsets that are likely to become infrequent Because even with the endangered itemsets it is not enough to always break ties an additional pricing among the endangered itemsets is considered C Improved Sanitization Algorithm In Section IV-A a way for accurately selecting which transactions should be sanitized was presented Nevertheless no hiding has taken place on the database yet To conceal the sensitive itemsets a sanitization method needs to be applied The MA and CBMA methods use the so-called Intelligent Sanitization Process shown in Algorithm 1 to sanitize the selected transactions According to the intelligent sanitization algorithm if two or more items have the same maximum support count in  the sanitization process picks randomly the item to be removed For example if only one sensitive itemset is supported by transaction  all items have the same support count in and an item is picked randomly Based on this observation we propose an enhanced version of the intelligent sanitization process which uses a series of criteria to break any number of ties that may occur The proposed sanitization method is presented in Algorithm 2 It follows the same steps as the intelligent sanitization algorithm lines 4 8 but deals with almost any possible tie that might occur For each transaction chosen for sanitization the set of sensitive itemsets supported by this transaction is identiìed Then the item that appears in most itemsets in is selected If a tie occurs among items then the item contained in the fewest itemsets of the revised frequent set supported by this transaction line s 9 15 is removed If a tie occurs again the item with maximum frequency is eliminated lines 16 18 Lastly if two or more items made it so far then an item is selected randomly to be removed After item is selected that should be eliminated the sensitive itemsets containing item are removed from  This process is repeated until is left empty 
2 identify 3 while 4 calculate 5 remove 6 update 7 end while 8 end for 
003 004 003 005 004 006 006 003 004  007 010 011 003 004 006 006 006 006 006 
c v    v 002 X 002  X S v   i T D T A T T T i j A A A j S j X  S A T A E A E  T D A E P X  T D T S T S f X S j X  T j f S S X S j X c A D E P  i   D  S T S T S S j S F j j S S 
003 003 003 004 005 002 
min s t Thr Thr argmax freq minf minf Thr freq argmax 
  1 0 1        1          log  1  
   2 
774 
774 
774 
774 
774 
774 
774 
774 
773 


002 002 002 002 003 
004 011 012  004  004  005     005      005  004  002 002 005 004     004      004      004  004       003     
006 006 006 004 006 004 006 004 006 002 004 002 004 002 002 002 002 002 002 
argmax numf numf argmax argmin argmin argmax freq IL freq freq freq SE 
Improved Sanitization Algorithm 1 transactions  is to be sanitized all sensitive itemsets supported by transaction items j in items j in item items j in weight item item V E XPERIMENTS AND R ESULTS We evaluated the proposed method on real datasets using different parameters such as the number/size of sensitive itemsets to hide In this section we also present the datasets used with their special characteristics the selected parameters and the experimental results Our code was implemented in Python We used the PyFIM extension module by Christian Borgelt to ef ciently mine the set of frequent itemsets All experiments were conducted on a PC running Windows 7 with an Intel Core i5 3.20 GHz processor The integer linear programs were solved using IBM ILOG CPLEX 12.6 All datasets used for evaluation are publicly available in the FIMI repository http://ìmi.ua.ac.be/data The BMS1 and BMS2 datasets contain stream data from the Blue Martini Software Inc and were used for the KDD Cup 2000 The retail dataset is a mark et bask et dataset from an anonymous Belgian store reported in The kosarak dataset was provided by Ferenc Bodon and contains anonymized click-stream data of a Hungarian online news portal A Evaluation Methodology We evaluated our proposed method HCBA and compared the results with the MA and the CBMA methods by using metrics such as the number of side effects introduced the percentage of information loss and the execution time Information loss is the ratio between the sum of the absolute differences in the frequencies of frequent itemsets in the sanitized database and the sum of all the frequencies of itemsets in the original database 7 The number of side effects SE introduced by the application of the sanitization process can be measured by  where is the number of itemsets in the revised set of frequent itemsets  whilst is the number of itemsets in the set of frequent itemsets mined from the sanitized database  We point out that the time needed for any preprocessing related to sparsity frequent itemset mining and calculation of the metrics is not included in the execution time as it equally applies to all techniques regardless of the used algorithm B Experimental Results In Table I the number of side effects SE the time and the information loss performances are given for hiding 10 20 and 50 sensitive itemsets on real datasets If we examine the result table carefully it is deduced that in almost all of the cases the proposed method outperforms the previous works in terms of the side effects introduced and of the information loss As far as the time complexity is concerned there is an increase in the execution time which is explained by the additional operations required in order to calculate the coefìcients However the overhead is not prohibitive Observe that the execution time increases linearly with respect to the number of sensitive itemsets Lastly it is also assumed that memory required by CPLEX to solve the integer programs is available Exploiting the sparsity of the constraint matrix passed in CPLEX plays a major role In most cases a low percentage of transactions support sensitive itemsets This is equivalent to solving a problem with a fairly reduced size compared to the original VI C ONCLUSIONS In this paper we presented a novel approach to minimize both side effects and information loss when hiding sensitive itemsets in transactional databases The proposed solution has a good quality while maintaining a decent level of scalability The frequent itemset hiding problem is modeled by using integer linear programming A heuristic is introduced so as to further exploit the coefìcients of the objective function An improved sanitization approach is also exhibited Finally we conduct several experiments and compare the proposed method with previously published relative works For the evaluation different performance metrics were used 
T D T S T S f Y S j Y  T j f f f  T j f C j f f  T g Y F j Y T  j C w w g j w j C w w j w M j C w w j j S S Y S j Y D D X X X  F,F F F F F F F D 
002 006 006 002 002 002 002 
Algorithm 2 for do identify while do calculate calculate calculate if then remove else identify calculate update calculate if then remove else identify remove end if end if update end while end for 
i i i i i j i i j j j j i j j j j i j i j j j j C j j j j C j j j j M D i i i X F D D X F D 
     1         1                  0 
2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 
775 
775 
775 
775 
775 
775 
775 
775 
774 


SIGMOD Conference Proceedings of the 20th Annual International Cryptology Conference on Advances in Cryptology CRYPTO 00 Proceedings of the 9th Australasian Data Mining Conference AusDM 11 Proceedings of the IEEE International Conference on Privacy Security and Data Mining CRPIT 14 Proceedings of the 2nd ACM Conference on Data and Application Security and Privacy CODASPY 12 Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery Proceedings of the 4th International Conference on Web Intelligence Mining and Semantics WIMS 14 In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery Proceedings of the 1999 Workshop on Knowledge and Data Engineering Exchange KDEX 99 JCSE Data Knowledge Engineering Information Systems Research eKNOW2014 The 6th International Conference on Information Process and Knowledge Management Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery IBM ILOG CPLEX Userês Manual v12.6 SIGKDD Explor Newsl Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD 99 Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations FIMI 03 
 Sensitive itemsets Max-Accuracy Coefìcient-Based Max-Accuracy Heuristic Coefìcient-Based Approach SE Time sec Inf Loss  SE Time sec Inf Loss  SE Time sec Inf Loss  BMS1 48 10 1426 0.96 9.6 390 1.91 2.5 352 2.78 2.4 20 3256 0.92 22.1 545 2.38 3.8 444 3.27 3.1 50 4927 1.47 35.6 1408 4.48 10.3 1286 6.53 9.3 BMS2 39 10 12965 5.11 12.5 6403 20.67 7.8 6304 52.03 7.6 20 49835 6.24 41.9 18084 38.67 19.0 17564 114.42 18.5 50 57251 11.25 54.8 32975 78.05 35.6 32131 150.15 34.1 retail 44 10 130 1.73 0.6 53 7.72 0.2 31 12.27 0.2 20 293 2.1 1.5 150 12.68 0.8 75 23.78 0.5 50 754 3.1 3.6 331 28.19 1.9 108 51.73 0.9 retai 88 10 72 1.78 1.1 33 6.0 0.6 5 10.35 0.3 20 195 1.84 2.6 76 10.05 1.3 21 17.55 0.7 50 384 2.46 5.3 186 19.92 3.3 108 34.88 2.3 kosarak 4,950 10 288 0.67 14.3 66 38.92 4.8 43 75.84 3.6 20 531 1.82 27.2 199 69.97 13.0 133 120.43 9.6 50 560 4.21 29.3 257 103.97 16.0 211 157.1 13.6 R EFERENCES  R Agra w al and R Srikant Pri v ac y-preserving data mining  in 
 2000 pp 439Ö450  Y  Lindell and B Pinkas Pri v ac y preserving data mining  in  vol 1880 2000 pp 36Ö54  R Li D de Vries and J Roddick Bands of pri v ac y preserving objectives Classiìcation of PPDM strategies in  vol 121 2011 pp 137Ö152  T  Johnsten and V  V  Ragha v an  A methodology for hiding knowledge in databases in  vol 14 2002 pp 9Ö17  M Askari R Saf a vi-Naini and K Bark er   An information theoretic privacy and utility measure for data sanitization mechanisms in  2012 pp 283Ö294  V  S V erykios  Association rule hiding methods   vol 3 no 1 pp 28Ö36 2013  V  Kagklis V  S V erykios G Tzimas and A K Tsakalidis Knowledge sanitization on the web in  2014 pp 4:1Ö11  C Clifton and D Marks Security and pri v ac y implications of data mining in  1996 pp 15Ö19  M Atallah E Bertino A Elmagarmid M Ibrahim and V S Verykios Disclosure limitation of sensitive rules  pp 45Ö52 1999  X Sun and P  S Y u Hiding sensiti v e frequent itemsets by a border-based approach  vol 1 no 1 pp 74Ö94 2007  G V  Moustakides and V  S V erykios  A maxmin approach for hiding frequent itemsets  vol 65 no 1 pp 75Ö89 2008  S Menon S Sarkar  and S Mukherjee Maximizing accuracy of shared databases when concealing sensitive patterns  vol 16 no 3 pp 256Ö270 2005  E Leloglu T  A ya v  and B Er genc Coef cient-based e xact approach for frequent itemset hiding in  2014 pp 124Ö130  C Bor gelt Frequent item set mining   vol 2 no 6 pp 437Ö456 2012    R K oha vi C E Brodle y  B Frasca L Mason and Z Zheng Kdd-cup 2000 organizers report Peeling the onion  vol 2 no 2 pp 86Ö93 2000  T  Brijs G Swinnen K V anhoof and G W ets Using association rules for product assortment decisions A case study in  1999 pp 254Ö260  F  Bodon  A f ast APRIORI implementation  in  vol 90 2003 pp 56  65 
002 
Table I Experimental results for the datasets Database  
min 
776 
776 
776 
776 
776 
776 
776 
776 
775 


                       


VI Tanbeer, S. K., Ahmed, C. F., Jeong, B.-S., & Lee, Y.-K, \215Sliding window-based frequent pattern mining over data streams,\216 Information Sciences, 179\(22\, pp. 3843\2053865, 2009 9 Chang, J., & Lee, W. S, \215Finding recently frequent itemsets adaptively over online transactional data streams,\216 Information Systems, 31\(8\, pp. 849\205869, 2006 4 Agrawal, R., & Srikant, R, \215Fast algorithms for mining association rules,\216 In Proc. VLDB int. conf. very large databases \(pp. 487\205 499\, 1994 3 Tsai, P. S. M, \215Mining frequent itemsets in data streams using the weighted sliding window model,\216 Expert Systems with Applications, 36\(9\, pp. 11617\20511625, 2009  minimum change threshold Y. Chi, H. Wang, P. S. Yu and R. R. Muntz. Catch the moment maintaining closed frequent itemsets over a data stream sliding window. In KAIS, 10\(3\: pp. 265-294, 2006 6 V. kumar, S. satapathy, \215A review on algorithms for mining frequent itemsets over data stream,\216 in ijarcsse V3 I4, 2013 8 CONCLUSION AND FUTURE WORK  Considering the continuousness of a data stream, the traditional methods or techniques for finding frequent itemsets in conventional data mining methodology may not be valid in a data stream. This is because we cannot consider whole data and must identify when a data becomes obsolete or invalid As the old information of a data stream may be no longer useful or possibly invalid at present.  In order to support various requirements of mining data stream, the mining window or the interesting recent range of a data stream needs not to be defined static but must be flexible. Based on this range, a data mining method can be able to identify when a transactions becomes stale or needs to be disregarded  In this paper, we have investigated the problem of mining frequent itemset over data stream using flexible size sliding window model and proposed a new algorithm for this problem. The size of sliding window is adaptively adjusted based on the amount of observed concept change in the underlying properties of incoming data stream. The size of window enlarges or increase when there is no significant amount of change observed. While the window size reduced or decrease when there is considerable amount of concept change or significant change in set of frequent itemsets occurs Based on the value of given by user, the size of window is being controlled. After every pane insertion the set of frequent itemsets are updated and value of concept change is calculated. If the value exceeds the given minimum change threshold the window gets smaller by deleting all the obsolete information before a point defined called checkmark  Experimental results shows that our algorithm tracks the concept change efficiently while mining data stream and is more adaptive to recent frequent itemsets than fixed size sliding window models or time fading window models. For the future work, we are trying to enhance the performance by using fuzzy sets for minimum change threshold value so that the values like low, medium, high and very high instead of certain value between ranges of 0 to 1 R EFERENCES  1                    H. Li, S. Lee, and M. Shan, \215An Efficient Algorithm for Mining Frequent Itemsets over the Entire History of Data Streams\216, In Proc. of First International Workshop on Knowledge Discovery in Data Streams, 2004  F. Nori, M. Deypir, M. Sadreddini, \215A sliding window based algorithm for frequent closed itemset mining over data streams\216 journal of system and software, 2012  Zaki, M. \(2000\. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12\(3\, 372\205 390  Woo H. J., & Lee, W. S. \(2009\. estMax: Tracing maximal frequent item sets instantly over online transactional data streams IEEE Transactions on Knowledge and Data Engineering, 21\(10 1418\2051431  Mozafari B, Thakkar H, Zaniolo C, \215Verifying and mining patterns from large windows over data streams,\216 In Proc. Int. conf. ICDE pp. 179-188, 2008  Koh, J.- L., & Lin, C.- Y, \215Concept shift detection for frequent itemsets from sliding window over data streams\216, lecture notes in computer science: Database systems for advanced applications \(pp 334\205348\ DASFAA Int. Workshops, Springer-Verlag.2009  Han, J., Cheng, H., Xin, D., & Yan, X. Frequent pattern mining Current status and future directions. Data Mining and Knowledge Discovery, 15\(1\, pp.  55\20586, 2007 5 C. Giannella, J. Han, J. Pei, X. Yan, and P. S. Yu. Mining frequent patterns in data streams at multiple time granularities. In Kargupta et al.: Data Mining: Next Generation Challenges and Future Directions, MIT/AAAI Press, 2004 7 2014 IEEE International Advance Computing Conference IACC 510 J. H. Chang and W. S. Lee. estWin: Adaptively Monitoring the Recent Change of Frequent Itemsets over Online Data Streams. In Proc. of CIKM, 2003  J. Yu, Z. Chong, H. Lu, and A. Zhou. False Positive or False Negative: Mining Frequent Itemsets from High Speed Transactional Data Streams. In Proc. of VLDB, 2004      Aggarwal, C, \215A framework for diagnosing changes in evolving data streams,\216 In Proc. ACM SIGMOD int. conf. on management of data \(pp. 575\205586\ 2003 2 Manku, G. S., & Motwani, R. Approximate frequency counts over data streams. In Proc. VLDB int. conf. very large databases \(pp 346\205357\ 2002  


002 
                          
R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. VLDB, pages 487Ö499, 1994 2 R. J. Bayardo, Jr. Efficiently mining long patterns from databases SIGMOD Rec., pages 85Ö93, 1998 3 M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. Data Min. and Knowl. Disc., pages 343Ö373, 1997 4 J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. In Proc. OSDI. USENIX Association, 2004 5 Apache hadoop. http://hadoop.apache.org/, 2013 6 Jiawei Han and Micheline Kamber. Data Mining, Concepts and Techniques. Morgan Kaufmann, 2001 7 M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley M. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82, EECS Department University of California, Berkeley, Jul 2011 8 M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica Spark: Cluster Computing with Working Sets. In HotCloud, 2010 9 J. Han, J. Pei, and Y. Yin: Mining Frequent Patterns without Candidate Generation. In: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29\(2\:1-12, 2000 10 M. J. Zaki. Parallel and distributed association mining: A survey IEEE Concurrency, pages 14Ö25, 1999 11 J. Li, Y. Liu, W.-k. Liao, and A. Choudhary. Parallel data mining algorithms for association rules and clustering. In Intl. Conf. on Management of Data, 2008 12 E. Ozkural, B. Ucar, and C. Aykanat. Parallel frequent item set mining with selective item replication. IEEE Trans. Parallel Distrib Syst., pages 1632Ö1640, 2011 13 B.-H. Park and H. Kargupta. Distributed data mining: Algorithms systems, and applications. 2002 14 L. Zeng, L. Li, L. Duan, K. Lu, Z. Shi, M. Wang, W. Wu, and P. Luo Distributed data mining: a survey. Information Technology and Management, pages 403Ö409, 2012 15 Li L. & Zhang M. \(2011\. The Strategy of Mining Association Rule Based on Cloud Computing. Proceeding of the 2011 International Conference on Business Computing and Global Informatization BCGIN è11\. Washington, DC, USA, IEEE: 475- 478 16 Li N., Zeng L., He Q. & Shi Z. \(2012\. Parallel Implementation of Apriori Algorithm Based on MapReduce. Proc. of the 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing SNPD è12\. Kyoto, IEEE: 236 Ö 241 17 Lin M., Lee P. & Hsueh S. \(2012\. Apriori-based Frequent Itemset Mining Algorithms on MapReduce. Proc. of the 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC è12\. New York, NY, USA, ACM: Article No. 76 18 Yang X.Y., Liu Z. & Fu Y. \(2010\. MapReduce as a Programming Model for Association Rules Algorithm on Hadoop. Proc. of the 3rd International Conference on Information Sciences and Interaction Sciences \(ICIS è10\. Chengdu, China, IEEE: 99 Ö 102 19 S. Hammoud. MapReduce Network Enabled Algorithms for Classification Based on Association Rules. Thesis, 2011 20 Synthetic Data Generation Code for Associations and Sequential Patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources/index.shtml 21 C.L. Blake and C.J. Merz. UCI Repository of Machine Learning Databases. Dept. of Information and Computer Science, University of California at Irvine, CA, USA. 1998 http://www.ics.uci.edu/mlearn/MLRepository.html 22 HadoopApriori. https://github.com/solitaryreaper/HadoopApriori 2 3 H.V. Nguyen, E. Muller, K. Bohm. 4S: Scalable Subspace Search Schema Overcoming Traditional Apriori Processing. 2013 IEEE International Conference on Big Data. 2013 24 S. Moens, E. Aksehirli and Goethals. Frequent Itemset Mining for Big Data. University Antwerpen, Belgium. 2013 IEEE International Conference on Big Data. 2013 25 Y. Bu et al . HaLoop: E cient iterative data processing on large clusters. Proceedings of the VLDB Endowment, 3\(1-2\:285Ö296 2010 26 Frequent itemset mining dataset repository. http://fimi.us.ac.be/data 2004   
002 
Our experiments show that YAFIM is about 18 faster than Apriori algorithms implemented in MapReduce framework Furthermore, we can achieve a better performance in both sizeup and speedup for different datasets. In addition, we also evaluated YAFIM for medical application and revealed that YAFIM outperforms MRApriori about 25 speedup  A CKNOWLEDGMENT  This work is funded in part by China NSF Grants \(No 61223003\, and the USA Intel Labs University Research Program R EFERENCES  1 
002 
1671 



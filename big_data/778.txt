Using Graphics Processors for Parallelizing Hash-based Data Carving  Sylvain Collange ELIAUS University of Perpignan  sylvain.collange@univ-perp.fr Yoginder S. Dandass Mississippi State University yogi@cse.msstate.edu  Marc Daumas ELIAUS University of Perpignan  marc.daumas@univ-perp.fr David Defour ELIAUS University of Perpignan  david.defour@univ-perp.fr   Abstract  The ability to detect fragments of deleted image files 
and to reconstruct these image files from all available fragments on disk is a key activity in the field of digital forensics. Although reconstruction of image files from the file fragments on disk can be accomplished by simply comparing the content of sectors on disk with the content of known files, this brute-force approach can be time consuming This paper presents results from research into the use of Graphics Processing Units \(GPUs\ in detecting specific image file byte patterns in disk clusters Unique identifying pattern for each disk sector is compared against patterns in known images. A pattern match indicates the potential presence of an image and flags the disk sector for further in-depth examination to 
confirm the match. The GP U-based implementation outperforms the software implementation by a significant margin  1. Introduction  Discovering known illicit material on digital storage devices is a key component of a digital forensic investigation. Given a large disk that is the subject of a forensic investigation, the basic problem in reconstructing deleted files from fragmented clusters is determining which file clusters contain data from files of interest and the order in which the fragments need to 
be assembled in order to construct the complete file Using existing data carving techniques and tools, it is typically difficult to recover remaining fragments of deleted illicit files whose file system metadata and file headers have been overwritten by newer files. Often after a file has been deleted, the file system data structures that map the file s content onto clusters on the disk are also reused and cannot be exploited to reconstruct the deleted file. Therefore, tools that reconstruct files \(or partial files\y examining 
individual disk clusters \(or sectors\mportant to forensic investigators A sector-based scan can be used to locate those sectors whose content matches those of sectors from known illicit files. However, brute-force sector-bysector comparison is prohibitive in terms of time required.  Techniques that compute and compare hashbased signatures of sectors in order to filter out those sectors that do not produce the same signatures as sectors from known illicit files are required for accelerating the process The approach described in this paper is to extract 
hashes i.e distinct signatures\ of sectors from master files i.e known files that are the subject of investigation\.  These signatures are compared with the signatures of the sectors on the disk.  When there are millions of master file sectors and millions of disk sectors, a brute-force software-based sequential matching approach takes a large amount of time This paper presents an approach that uses Graphics Processing Units \(GPUs\ implement parallel pattern 
matching engines that can significantly speedup the search process.  Minimizing the time required to search disk drives is important in situations where investigators have only a short amount of time to scan a disk drive.  For example at border crossings and at airports, travelers may only have a short time between connections and law enforcement agencies need to detect evidence of contraband files as quickly as possible.  Therefore, it is imperative that the forensic scanning be performed expeditiously.  High throughput 
also becomes essential when the technology described in this article is applied to the monitoring of network traffic, for example in the inspection of traffic going through a digital subscriber line access multiplexer or a cable-modem termination system with a GPU based sn at perf orm s h a s h ed bas e d data carv ing   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


The remainder of the paper is organized as follows Section 2 provides background on hashing, hash-based data carving, GPUs, and related work.  Section 3 describes the technical approach, and Section 4 describes the experiments and discusses experimental results.  Section 5 concludes with a summary of findings and a discussion of avenues for future research  2. Background  File systems typically store files in clusters of contiguous sectors on disks.  For example, in its default configuration, the Windows XP file system NTFS, allocates space for files in increments of eight contiguous sectors.  Each sector is 512 bytes, making each cluster 4096 bytes i.e 4KB\.  There is no guarantee that consecutive clusters belonging to a file will be stored contiguously. When the file system needs to allocate one or more clusters to a file, it allocates clusters from the free space i.e the set of clusters that are not currently allocated to other files Over time, after several cycles of adding and deleting files, the disk s free space becomes fragmented.  This fragmentation causes the file system to scatter the content of new files over several non-contiguous clusters When a file is deleted, the file system typically marks the file s clusters as being available for reuse but does not zeroize  i.e clear\ the content.  Therefore unless a cluster that previously belonged to a deleted file has been overwritten by the contents of another file, it is possible to recover the content of the cluster Furthermore, in the event that the cluster belonging to the deleted file is allocated to a new file that only overwrites the first few sectors in the cluster, the remaining file fragment data can be examined using the sector signature analysis technique described in this paper.  If the file system data structures that map the deleted file s content onto clusters on the disk have not been reused, then the content of deleted files can be recovered relatively easily.  Once this file system metadata is overwritten by new files, the recovery of the remaining data fragments becomes more difficult However, sector signature matching can be applied to any sectors that have not been overwritten by new files NTFS stores small files \(less than 900 bytes\ in the master file table \(MFT\he MFT is the file system metadata storage area that contains the file s directory information.  Therefore, these small files will not be aligned to disk sector boundaries.  However, most files of interest typically range from several kilobytes to gigabytes and are stored on clusters separately from the MFT.  Therefore, these large files are guaranteed to be aligned on 512-byte sector boundaries  2.1. Cryptographic and Polynomial Hashing  The MD5 hashing algorithm intended for digital signature applications was described by Rivest in 1992  du ces a 128bit 16by te h a sh  f r o m data  up to \(2 64 1\n length.  The algorithm pads the input data in order to ensure that the input length is divisible by 512 and proceeds to compute the hash by iteratively processing the input in terms of 512-bit blocks.  Although, a number of cryptographic weaknesses have been demonstrated for MD5, it remains an effective hashing algorithm because a small change in input results in significantly large change in the output hash.  Therefore, MD5 is a good candidate for developing signatures for sectors The SHA-1 hashing algorithm was published as FIPS PUB 180-1 in 1995 and was revised in 2002 as FIPS PUB 180.  S H A 1 pro du ces 160bi t 20byte\ash from data up to \(2 64 1\th.  As with the MD5 algorithm, SHA-1 also pads the input data in order to ensure that the input length is divisible by 512 and proceeds to compute the hash by iteratively processing the input in terms of 512-bit blocks Cryptographic weaknesses have also been reported for SHA-1.  However, SHA-1 remains a good candidate for producing sector signatures The design of MD5 and SHA-1 algorithms focuses on cryptographic quality, not on facilitating high-speed execution.  For example, both algorithms require padding of the input data with a string of zero bits and a 64-bit value containing the original bit-length of the data such that the bit-length of the padded data is divisible by 512 bits.  This initial padding is performed regardless of the length of the original data block However, this initial padding step is not essential for generating signatures of sectors because sectors have a fixed length of 4096 bits.  The padding operation will essentially append a block of 512 bits that does not vary based on the content of the block, and therefore makes no contribution towards producing noncolliding hashes Additionally, the MD5 and SHA-1 algorithms specify long sequences of operations that cannot be fully parallelized.  This limits the improvements in performance that can be achieved via parallelization of implementations though we could obtain sufficient parallelism on GPUs by operating concurrently on different pieces of data as reported in this work SHA-1 is also widely used for password based cryptography. For example PKCS#5 version 2.0 introduced by RSA Laboratories generally uses 4000 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


iterations of the SHA-1 function to generate an encrypted password from a password and a salt value This standard is used in Windows password and file encryption, WPA wireless network encryption and many other applications CRC32 is a checksum value typically used to validate the correctness of stored data or data transmitted over a network [4 CRC3 2 is co m p uted  by dividing the input data by the generator polynomial x 32  x 26  x 23  x 22  x 16  x 12  x 11  x 10  x 8  x 7  x 5   x 4  x 2  x 1, using modulo-2 arithmetic. In modulo-2 arithmetic, addition and subtraction resembles the exclusive-or operation \(carry processing is not required\he 32-bit \(4-byte\mainder of the division operation is the CRC32 value.  CRC64 produces a 64-bit \(8-byte\hecksum value using the generator polynomial x 64  x 4  x 3  x 1.   CRC32 and CRC64 can be used for identification purposes although they are intended for detecting accidental modification of data but not for detecting deliberate modifications A number of fast hardware implementations for the  d S HA1 [6] h a v e been des c ribed in t h e  literature.  CRC32 and CRC64 implementations can be found on many modern hardware devices that support high-speed serial I/O channels.  Hardware implementations have the advantage of computing the hashes at significantly faster rates than possible by software implementations  2.2. Simpler Hashes  The two major problems with cryptographic and CRC hashes are the large number of operations required to compute each iteration of the hashing operation and accessing the hash table \(for table-based iterations\when the table is too large to fit in the processor s cache memory.  The cryptographic hashes are complex because they need to be irreversible.  Fast software implementations of CRC typically require table lookups.  Implementing tables requires access to large areas of memory that reduce the performance as this table is randomly accessed.  Furthermore processor caches are of no use and may even slow down the search.  A performance breakdown occurs as soon as the lookup tables become too large to fit completely within cache memory djb2 and sdbm  w o has h i n g al g o rithm s t h at  operate with no lookup table and do not significantly increase the number of hash collisions in our tests.  The djb2 algorithm, first described by Danier Bernstien in newsgroup comp.lang.c is expressed using the following equation      1  where hash i is the hash value at the i th iteration and s i is the input character at iteration i note 5381 is the hash initialization value before the first iteration is computed\he sdbm algorithm is used in the SDBM and open source database management software, and is expressed using the following equation      2  Implementations of djb2 and sdbm hashing are fast in GPUs because only one multiplication and one addition is required.  Furthermore, only the current hash value and the next input character need to be maintained in memory, thereby, minimizing storage requirement. Conversely, these hashes are more sensitive to the number of hash collisions as they increase the ratio of memory access over arithmetic operations  2.3. Data Carving Using Hashes  Dandass et al describe results of a case study in which the SHA1, MD5, CRC64, and CRC32 hashes for over 528 million sectors extracted from over 433 thousand files of different types were analyz Particular emphasis was placed on characterizing the viability of using hashes to uniquely identify sectors from JPEG and MD5 files. The results of this study show that MD5 and SHA1 produced no false positive indications. Furthermore, the occurrence of false positives was relatively low for CRC32 and CRC64 Additionally, the smaller size of the CRC32 and CRC64 hashes as compared with SHA1 and MD5 means that a smaller memory capacity is needed in order to deploy a database of hashes of sectors from known contraband files.  Reducing memory capacity is an important consideration for the development of a commercially viable forensic took for scanning disks Dandass also reports on the results of using disk cluster signatures for detecting contraband data on an FPGA-based platform H o w e v e r, an FP G A b as ed implementation provides high-performance at a high cost because FPGAs are expensive.  Conversely, GPUs are relatively inexpensive commodity hardware typically found on all workstations and now on high end laptops for agile law enforcement teams Roussev et al describe techniques for using the djb2 hash function for computing similarity scores for detecting content in files that may be similar to each othe h ey als o pres e n t  res u lt s  f r o m ca s e stu d ie s parallelizing forensics tools e.g Scalpel\or execution on GPUs  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


2.4. Graphics Processors  Graphics hardware has been evolving rapidly over the past several years.  Initially, graphics hardware was dedicated to accelerating graphics rendering functionality.  Recently, significant developments have made GPUs capable of performing all kinds of generalpurpose computations h is sectio n provides a description of the evolution and capabilities of GPUs Original graphics accelerator cards were specialpurpose hardware accelerators for graphics programming interfaces such as OpenGL and DirectX These programming interfaces are used for describing scenes from geometrical objects located by vertices An image consisting of pixels is rendered using the vertex data.  In order to accelerate performance, image rendering functionality is implemented in hardware in the original GPUs as shown in Figure 1 More recently, operations performed on vertices and pixels have become more flexible through the use of programmable vertex and pixel units called shaders  Although vertex and pixel shaders are used for performing different kinds of operations, they share a number of features and offer similar functionality    Figure 1: Organization of early GPUs   Hardware implementing vertex and pixel shaders include memory units e.g texture access units computational units e.g multiply and accumulator units\nd specialized hardware e.g special function evaluators\ order to efficiently exploit data parallelism, GPUs include a large number of replicated copies of these units  GPUs handle high latency instructions that perform memory accesses by supporting the concurrent execution of thousands of threads The DirectX 10 standard and compatible hardware provide a unified architecture where vertex and pixel shaders share the same instruction set and processing units.  It has been implemented in hardware since the release of the NVidia GeForce 8 and AMD-ATI Radeon HD 2000 generations. An example of such architectures is depicted in Figure 2    Figure 2: Organization of NVidia G80   In this figure it can be seen that the GPU has its own memory which is usually an order of magnitude faster than system memory.  The graphic processor is shown as a set of single-instruction multiple-data SIMD\s.  Each SIMD block consists of numerous processing elements \(PEs\t each clock cycle, all the PEs in a block execute the same instruction in a sequence of instructions, but operate on different data These SIMD blocks incorporate a variety of different types of storage such as a set of registers for each PE, memory blocks shared by all the PEs in a SIMD block, constant memory, and read-only texture memory. In addition, the PEs can also read or write global memory available on the graphics card SIMD blocks also integrate a variety of computational units in order to implement the functionality offered by the shaders.  These include general computation units with embedded multiplyaccumulators, texturing and filtering units, and a dedicated unit to evaluate mathematical functions e.g  sine, cosine, reciprocal, and reciprocal square root rasterization units, Z-culling units, and interpolation units These units can handle integer and floating point arithmetic and there is no overhead associated with mixing both types of operations.  Each SIMD block in Cull/Clip/Setup Rasterization Fragment pixel crossbar Shared L2 texture Cache Pixel Shader Vertex Shader Z-compare & Blend Memory partition Memory partition Memory partition Memory partition GDDR 3 128 Mo GDDR 3 128 Mo GDDR 3 128 Mo GDDR 3 128 Mo Z-Cull Command & data fetch SIMD unit SIMD unit SIMD unit Controler Graphic memory Interface CPU System memory Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


the GeForce 8 is able to execute a set of 32 floating point additions, multiplications, multiply-andaccumulate or integer additions, bitwise operations compares, or evaluate the minimum or maximum of 2 numbers in 4 clock cycles.  As there is no 32-bit integer multiplication in hardware, evaluating such an operation requires 16 clock cycles for a set Figure 3 depicts the NVidia GeForce 8800 GTX This GPU contains 16 SIMD blocks and each SIMD block is composed of 8 PEs and 2 units to evaluate general functions.  It also contains a 768 MB global memory with a peak bandwidth of 103 GB/s which is more than 10 times the available bandwidth between the CPU and the system memory    Figure 3: SIMD unit of NVidia G80    Figure 4: Organization AMD-ATI R600 cluster   Figure 4 depicts the AMD-ATI Radeon HD 2900 XT.  It contains 4 SIMD blocks, each composed of 16 PEs, capable of performing 5 different instructions simultaneously In order to optimize performance, programmers must observe the following two constraints in programming style imposed by the SIMD execution model 1  Memory contention is minimized by maximizing the use of certain optimized memory access patterns i.e coalesced or broadcast accesses described below depending on the kind of memory being accessed i.e shared, constant, or global 2  Control flow should be the same for all the execution contexts within a SIMD block and divergence of conditional constructs among PEs of the same SIMD block should be minimized The first constraint restricts the available memory access patterns based on the type of memory being accessed.  There are two primary types of optimized memory access patterns available Coalesced accesses arise from grouping read or write accesses made to consecutive address.  For example, if PE 0 requests a read at address n PE 1 requests a read at address n 1 and so on, then all reads are performed simultaneously Broadcast accesses arise when all the PEs in an SIMD block read the same address The GeForce 8, for example, has a shared constant memory accessible in broadcast mode only, a global memory accessible with coalescing \(with additional alignment constraints\, and a shared memory that allows coalesced, broadcast, and other patterns Memory accesses that do not match these patterns are replaced with as many serial accesses as necessary resulting in decreased performance The second constraint means that all PEs in a SIMD block essentially execute the same program synchronously.  A jump instruction is executed as a parallel jump only when all the execution contexts follow the same path within a SIMD block, as seen in Figure 5    Figure 5: Execution of a jump instruction when all PEs follow the same path     Figure 6: Execution of a jump instruction when some PEs do not follow the same path  Register banc Instructions dispatch Operand handling Operand handling MAD MAD MAD MAD Interface Interface Slow clock Fast clock MAD MAD MAD MAD SFU SFU MAD MAD MAD MAD SFU Branchemen t MAD MAD MAD MAD SFU Branchemen t MAD MAD MAD MAD SFU Branchemen t MAD MAD MAD MAD SFU Branchemen t MAD MAD MAD MAD SFU Branchemen t MAD MAD MAD MAD SFU Branch 16 clusters SIMD X 4 VLIW x 5 bank Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


 If any of the branches diverge i.e at least one branch within the SIMD block takes a different path becomes necessary to execute both branches \(in blue and purple in Figure 6\ the conditional construct and a mask is applied in order to inhibit writing the results where the condition does not apply \(shown in red This mechanism of executing both branches in a conditional construct is called predication Some SIMD architectures, including GPUs, are able to dynamically determine at runtime whether a SIMD block can execute only one side of the branch or if it is necessary to execute both sides of the branch and use predication to obtain the final result for all the individual PEs  3. Data Carving Using GPUs  The research presented in this paper explores the feasibility of using the parallelism offered by GPUs to accelerate the detection of sectors from contraband files using sector-level hashes.  This application is able to inspect several disk drives simultaneously and asynchronously from each other because computers often contain more than one disk; additionally disks from different computers can be inspected independently Because accessing data in memory is time consuming, CPU implementations need to operate in a threaded manner to hide latency.  This implementation instead, uses the ability of GPU to hide memory latency in order to perform an initial filter operation that eliminates sectors from consideration that do not match the signature of sectors from known contraband files.  This section describes the architecture of the implementation and describes the various data flow optimizations undertaken in order to maximize performance  3.1. Application Architecture  The overall architecture of the system is described in Figure 7.  Sector contents are transferred from the disk drives to the CPU main memory in a two-stage pipelined process using a double-buffered  implementation for each disk drive.  In double buffering, a pair of buffers h 2 k  h 2 k 1 in host memory are used in order to optimize throughput of disk k  Initially, one disk drive transfers the content of a group of sectors into h 2 k After this transfer completes, the buffer is marked as ready and the host CPU schedules the simultaneous transfer of the content of another group of sectors from disk k into h 2 k 1  Meanwhile, ready buffers in CPU memory are transferred to GPU memory following a round robin pattern.  As soon as one buffer h i is completely transferred to GPU it is tagged as free and a transfer is initiated from the appropriate disk to bring more data into main memory The transfer of data from CPU to GPU also uses a pair of buffers g 0  g 1 and the processing of the data by the GPU is overlapped with the data transfer operations.  While the data is being transferred into g 0  the GPU processes data in g 1 and similarly when data is being transferred into g 1 the GPU processes data in g 0 Overlapping the two data transfer operations with the processing at the GPU and performing simultaneously on different hard drives provide significant performance gains over a naïve sequential implementation.  Yet, using pairs of buffers imposes a nominal increase in memory requirements   Figure 7: Architecture of the sector-based signature matching system  On the GPU, the database of signatures of sectors from known contraband files is organized into hash tables S 0   7.  Each hash table S contains signatures corresponding to sector in the clusters found on disk drives \(note that in this research, clusters are assumed to have the default size of eight sectors The hash table S is constructed by successively computing and inserting the hash-based signature of all sectors at position in clusters of known contraband files that are to be detected.  The signature is inserted into the hash table at the location l determined by the w least significant bits in the signature.  If there is a  Memor y CPU GPU  Graphics Memory GPU equipped workstation or laptop PCIe h 0  h 1  g 0  g 1  h 2  h 3  h 4  SATA, PATA and USB drives under investigation possibly seized from different machines Round robin transfer of ready buffers to GPU h 5  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


hash collision linear probing is used to find an alternative location.  Using linear probing, the candidate location for insertion of hash signature h into the hash table is given by the following expression      3  where c is the number of collisions that have occurred previously when attempting to insert this hash signature and LSB w  x ents the w least significant bits of x  At the GPU, signatures of several sectors are computed concurrently and are then looked up in the appropriate hash table.  If a matching signature is found, the GPU alerts the host CPU, enabling confirmation e.g by performing a byte-for-byte comparison of the suspect sector and the known contraband sector with the matching signature  3.2. Signature Computation on the GPU  Sectors are transferred from the host system s main memory into GPU main memory and stored contiguously in buffers g 0 and g 1 as shown in figure 8 GPU main memory is external to the GPU chip and needs to be accessed in constrained access patterns in order to improve performance.  Straightforward implementations in which threads simultaneously read sector data at offset 0, 1, 2, etc. from main GPU memory results in poor performance because all threads access the same memory bank simultaneously leading to memory access contention  Sector 0  0 1 2  14  15 Sector 1  0 1 2  14  15 Sector 2  0 1 2  14  15   Sector 14  0 1 2  14  15 Sector 15  0 1 2  14  15    Figure 8: Sectors are stored at contiguous addresses in GPU main memory  In order to accelerate the performance of signature generation and matching, 16x16 blocks of 32-bit words are rearranged in the GPU local memory as depicted in Figure 9 for the first block.  This significantly improves the throughput of main GPU memory accesses h reads  are or g a n i zed in  coh o rts of 16  First, the 16 threads in a cohort read 16 successive 32bit words i.e a 512 bit span\rom one single sector into an on-chip shared memory buffer. The on-chip shared memory is organized in a columnar manner in hardware such that successive words appear in different banks.  The 16 threads can simultaneously access the memory provided that the threads access different banks as shown in Figure 9.  Note that the read operation is a coalesced memory access to main GPU memory and the write operation takes place in parallel for all the 16 threads.  These operations are repeated 16 times until 512-bit portions of 16 sectors have been uploaded to the shared on-chip memory buffer  Sector 0  0 1 2  14  15 Sector 1  15 0 1  13  14 Sector 2  14 15 0  12  13     Sector 14  2 3 4  0  1 Sector 15  1 2 3  15  0  Figure 9: Data are first rearranged in GPU shared memory by group of 16x16 words  The cohort of 16 threads computes the partial signature from the first 512 bits of data from 16 sectors  i.e thread q in the cohort computes the signature for sector q This process is repeated eight times as the threads fetch more data from the 16 sectors and continue the computation of partial signatures until complete signatures of the 16 sectors have been computed Each of the 16 threads next performs a hash table lookup of the signatures in the set of hash tables in main memory.  Linear probing is used in order to resolve collisions.  Essentially, if the entry at the location indicated by the computed hash value is occupied by a non-null signature that does not match the computed signature, the thread looks at the next location.  This process continues until the signature is found in the hash table or a null entry is found.  When the signature is found in the hash table, this indicates a positive match.  Conversely, if a null hash table entry is found first, this indicates that the signature does not exist in the table of signatures of known contraband sectors After writing information about positive matches to a memory buffer where the host CPU can access the match indications, the cohort of threads begins transferring and processing the next set of 16 sectors from main GPU memory In order to fully exploit the parallelism available in modern GPUs, the implementation allows several such Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


cohorts to be executed in parallel. The exact number of cohorts that can be executed simultaneously depends on the platform used for executing the system.  For the hardware used in the experiments reported in this paper, the best performance is achieved with eight cohorts.  However, this number is expected to vary with future generations of GPUs  4. Experimental Results  In order to determine the effectiveness of using GPUs for computing and matching hashes, two different sets of experiments were conducted.  The first set of experiments replicates the hash quality experiments conducted by Dandass et al in order to determine the number of collisions resulting from using the signatures based on the djb2 hashing function.  Note that a 64-bit accumulator was used in the djb2 hash computation, resulting in 64-bit wide hashes The second set of experiments measures the execution performance of the sector signature scanning implementation on the Nvidia GeForce 8500 GT GPU and Intel Xeon 5140 2.33 GHz CPU using CRC64- and djb2based signatures.  The CPU-based implementation is sequential while the GPU-based implementation employs 2048 threads i.e 128 cohorts A set of 105,506 unique files consisting of 86,655,112 unique sectors of random data were used in this experiment.  Eight hash tables occupying 32 MB and indexed by the 22 least significant bits of the signature were used for storing the database of known contraband hashes.  The second set of experiments has also been ported to a laptop equipped with a NVidia GeForce 8600M GT.  The performance of the 8600M is slightly higher than the performance of the NVidia GeForce 8400 GT on the workstation  4.1. Hash Collisions Using djb2  Only 32 of the djb2 hashes from these sectors collided with the djb2 hashes from other sectors i.e  the collision rate was 0.33%\his indicates that djb2 is a relatively good candidate for generating hashbased signatures because the potential number of falsepositive indications is small. Although fewer files were used in this experiment that those used by Dandass et al based on the evidence of other research and the 64bit width of the hash, it is anticipated that djb2 will perform well in general  4.2. System Performance on the GPU   Figures 10 and 11 compare the performance of various GPU-based implementations and a CPU-based implementation using CRC64 function for signature generation.  The X-axis represents the occupancy of the hash table and the Y-axis represents the throughput of the implementation in megabytes per second.  The CPU-based implementation has the lowest performance as expected because of its sequential nature   Figure 10: CRC64-based implementation on NVidia GeForce 9800 GX2    Figure 11: CRC64-based implementation on an NVidia GT 200 engineering sample  Three GPU-based implementations are plotted in increasing order of performance 1  Data in a virtual disk drive in memory /dev/shm  for this implementation, the files to be examined are placed on a virtual disk drive memory in order to eliminate the effects of the relatively slow disk I/O 2  Data in main memory in this implementation the data is placed in the workstation s main  100 1000 10000 100000 45 50 55 60 65 70 75 80 85 90 95 Throughput \(MB/s Hashtable occupancy GPU, Unix read on /dev shm GPU, data in main memory GPU, data in graphics memory CPU 100 1000 10000 100000 45 50 55 60 65 70 75 80 85 90 95 Throughput \(MB/s Hashtable occupancy GPU, Unix read on /dev shm GPU, data in main memory GPU, data in graphics memory CPU Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


memory in order to eliminate the overhead from the file I/O subsystem 3  Data in graphics memory in this implementation the sector data is assumed to be in main GPU memory in order to eliminate the overhead of all data transfer operations i.e this is a measure of raw GPU performance  These plots clearly show that the large-scale parallelism available on the GPU enables the fast execution of signature generation and matching However, I/O is a significant bottleneck Performance decreases with increasing hash table occupancy because of the increasing number of linear probing operations required. However, even with 90 hash table occupancy, throughput is over 1700 MB/s when file system and disk I/O overheads are not considered. When file system I/O is included, the GPU s performance remains at 675 MB/s at up to 90 hash table occupancy Figure 12 plots the performance of the djb2 based implementation. This implementation has slightly better performance because the djb2 hash function is simpler to compute than CRC64 on GPUs.  Note that for the higher hash-table occupancies, the linear probe functionality imposes a significant overhead.  In his FPGA-based implementation, Dandass used a binary search mechanism; this may be a feasible alternative to use in implementations with high hash-table occupancy    Figure 12 djb2 based implementation on NVidia GeForce 8500 GT  For CRC64 and djb2, the GPU implementation always performs better than the CPU implementation Several factors contribute to this performance differential.  First, GPUs have much higher computational power than CPU.  Although the CPU implementation used in these experiments is not optimized \(because one iteration of CRC64 takes 17 cycles per byte whereas the implementation by Sarwate takes 6.67 cycles per byte e h a v e a 13-f old improvement in performance between the GPU and CPU implementations.  Additionally, with big hash tables that do not fit entirely in CPU cache, the data cache of the CPU adds extra cycles to access data located in main memory on a bus shared with all active processes.  Conversely, in the GPU implementation the hash table is entirely located in high bandwidth graphics memory dedicated to the GPU that is directly accessed without any intervening cache.  In addition the threaded GPU implementation is naturally better at hiding access data latency These results show that it is feasible to design an implementation with the computational capacity to simultaneously scan up about six separate disk drives each transferring data a peak rate of over 100 MB/s.  In the future, it may be possible to improve peak performance by eliminating certain OS overheads incurred for transferring data between the disk and the host.  However, in the implementation utilizing a single disk drive, throughput is limited to 55MB/s \(this is essentially, the sustained data rate of the disk drive used in the experimental platform  5. Conclusions and Future Work  This paper presents a GPU-based approach for rapidly scanning the content of sectors of disks in order to look for fragments of possibly deleted image files Hash-based signatures of disk sectors are compared with signatures of sectors from known contraband files and matches are flagged for further investigation Although the fundamental file fragment signature scanning techniques presented here can be implemented using conventional software techniques the rapidly increasing storage capacity of disk drives is necessitating the development of faster alternatives Experimental results reported in this paper demonstrate the viability of using GPU technology for scanning hard disks for fragments of known image files.  GPUs are a commodity item and are found in most modern workstations and in high end laptops This means that the relatively inexpensive parallel processing capabilities of the GPU can be readily utilized in an ordinary workstation platform or in nomad applications, without requiring costly FPGA hardware used in prior research Near term future research will focus on improving the performance of the signature matching codes on the GPU and on overlapping disk I/O with GPU I/O and GPU processing in order to minimize latency.  Clearly reading an entire disk drive at peak data transfer capacity can take a long time e.g the Seagate  0 2000 4000 6000 8000 10000 12000 14000 45 50 55 60 65 70 75 80 85 90 95 Throughput \(MB/s Hashtable occupancy GPU, Unix read on /dev/shm GPU, data in main memory GPU, data in graphics memory CPU Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


Barracuda 7200.11 500GB disk drive will take approximately one hour and twenty minutes to read using the peak sustained data rate of 105 MB/s Therefore, future research will also focus on developing techniques for determining those areas on disk that are likely to contain prohibited data e.g  using file system metadata\This will enable a focused search of disk drives given small windows of investigation time Longer term research will focus on developing a workstation- and a laptop-based platform incorporating a high-end GPU that will scan for signatures of known contraband files for several disk drives simultaneously and will allow the operator to dynamically attach disk drives using USB, PATA, and SATA interfaces.  This capability will enable the inspection without requiring the system to be power cycled in order to remove or attach new drives.  The authors are working with a startup company in France with the goal of developing such a platform The computing power exhibited by GPUs in this work opens new perspectives on inspections that were long thought to be unreachable.  For example, the GPU implementations described in this paper are able to process every 64-byte fragment aligned on 32-bit boundaries in disks at a sustained rate of about 500 MB/s.  Law enforcement agencies can therefore search for small images and logos embedded in documents and files in archives provided they are aligned to 32-bit boundaries  6. Acknowledgements  This work is supported in part by NSF Cyber Trust grant SCI-0430354 and in part by donations of software and hardware by NVidia and AMD.  The work was partially performed while Yoginder S Dandass visited the University of Perpignan Via Domitia as an invited professor, supported, in part, by the French Région Languedoc-Roussillon.  The authors also express their gratitude to inspectors from the Direction de la Surveillance du Territoire, the French counter-intelligence and homeland security agency  7. References  1  N-F. Huang, H-W. Hung, S-H. Lai, Y-M. Chu, and WY. Tsai A GPU-Based Multiple-Pattern Matching Algorithm for Network Intrusion Detection Systems in 22nd International Conference on Advanced Information Networking and Applications 2008  2  R. L. Rivest The MD5 Message Digest Algorithm  Internet RFC 131, 1992, retrieved January 18, 2008 from http://people.csail.mit.edu/rivest/Rivest-MD5.txt  3  NIST-ITL Secure Hash Standard \(SHS 2002 Retrieved January 18, 2008 from http://csrc.nist.gov/publications/fips/fips180-2/fips1802.pdf  4  D. V. Sarwate Computation of Cyclic Redundancy Checks via Table Look-Up  Communications of the ACM 31\(8\1988  5  Y. S. Dandass, N. J. Necaise, and S. R. Thomas An Empirical Analysis of Disk Sector Hashes for Data Carving  Journal of Digital Forensic Practice 2\(2 2008  6  J. Deepakumara, H. M. Heys, and R. Venkatesan FPGA implementation of MD5 hash algorithm in Proceedings of the Canadian Conference on Electrical and Computer Engineering 2001  7  V. Roussev, G. G. Rich ard III, and L Marziale Multiresolution similarity hashing  Digital Investigation  4\(S1\ 2007  8  Y. S. Dandass Hardware-assisted Scanning for Signature Patterns in Image File Fragments in Proceedings of the 40 th Hawaii International Conference on System Sciences 2007  9  L. Marzialea, G. G. Richard III, and V. Roussev Massive threading: Using GPUs to increase the performance of digital forensics tools 4\(S1\, 2007  10  S. Collange, M. Daumas and D. Defour Line-by-line spectroscopic simulations on graphics processing units  Computer Physics Communications 178\(2\2008  11  E. Lindholm, J. Nickolls, S. Oberman, and J. Montrym NVidia Tesla: A unified graphics and computing architecture  IEEE Micro 28\(2  12  M. E. Kounavis and F. L. Berry Novel Table LookupBased Algorithms for High Performance CRC Generation  IEEE Transaction on Computers 20 May 2008  13  A. P. Kakarountas, H. Michail, A. Milidonis C. E. Goutis, and G. Theodoridis High-Speed FPGA Implementation of Secure Hash Algorithm for IPSec and VPN Applications  Journal of Supercomputing  37\(2 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


This figure presents the data flow through main blocks that can be used a few times and special blocks that must execute only particular functions Here also Configurator of chain and Sequences library for WiMAX/UMTS modules are equipped First one is responsible for right construction of next processing path and second one stores necessary number of elements After signal verification system is reconfigured according to input data and with using the chosen protocol type The OUTPUT connects to radio link and then signal must be transmitted over one of six channel types And at the reception side we configure the receiver in relation to transmitted mode 5 HARDWARE PLATFORM SELECTION Current technologies in a hardware environment allow to test our system in real-time implementation There are a couple of DSP based platforms that can be selected for validation from Lyrtech Inc the Small Form Factor SFF Software Communication Architecture SCA Development the Small Form Factor SFF Softwaredefined Radio SDR Development Platform the Small Form Factor SFF Software-defined Radio SDR Evaluation Module 20 All these platforms are based on TMS320DM6446 DMP SoC from Texas Instruments 21 For the proposed SDR based system we chose the SFFSDR Evaluation board see Figure 13 as far as this platform supports WiMAX technology model based design tools accelerating prototyping implementation of all protocols layers for complete radio stacking extra boards operates with 297MHz ARM926EJ-s RISC CPU and 594MHz C64x DSP in sense of power management this module has MSP430 MCU Due to an availability of Virtex-4 SX35 FPGA from Xilinx 22 this module can perform implementation of full modem processing functions that is very important feature in meaning of multi-protocol architecture of our system We are able to vary our requirements to each protocol inside the same hardware structure Figure 13 SFF SDR development platform by Lyrtech 6 PROTOTYPING THE WiMAX/UMTS SYSTEM The WiMAX/UMTS system is implemented in high-level language as C with the class library The main accent was done on the correct form of the signal processing sequence The path for WiMAX or UMTS signal is determined in the beginning and system should verify its entity leads the system in a relevant direction The main goal of this software implementation is to check how our system can handle the input signal sequence The simulation was carried out for following parameters for each subsystem For UMTS we consider transport block with 1280 bits size frame size is 2400 bits channelization code with 16 chips sequence For WiMAX we generate the bit block is equal to 1280 bits however during channel coding operation this block is divided on turbo coding block that include 384 bits The size of turbo coding block forms from the block determination corresponding modulation type and number of subchannels During software verification we obtained that our proposed model can separate different paths subject to a type of an inter sequence in the software environment The framework of our WiMAX/UMTS system went through one scenario step and now we are directed to an extension of this model For the more detailed system visualization we integrate our C code modules into MATLAB library by means of proper dynamic linking libraries dll compiled by using the MATLAB C compiler Each block can be formed with extended parameters Modules with C code configurate the system work in a host This host implementation will present a prototype This prototype will help to analyze future real-time hardware implementation MATLAB prototype can also provide debugging of real system the result of real system must be equal to our MATLAB prototype Next step of the work development and verification is to implement it into the hardware platform based on DSP DSP based platform allows to organize signal processing in a digital presentation that serves SDR based part of our general system 7 CONCLUSIONS AND FUTURE WORK In this paper we considered the framework of WiMAX/UMTS baseband level system for mobile device in UL transmission direction We presented the different signal processing structures based on OFDM and WCDMA physical layer procedures Our research work is mainly devoted to developing the approach of seamless switching between different subsystems that can be realized by SDR technology implementation To this end we proposed a possible solution to allow coexistence of different data transmission technologies 11 


The position of SDR blocks in common UMTS/WiMAX architecture for mobile terminal was shown in this paper We presented the different blocks of each subsystem and have identified three blocks which can be implemented as common SDR blocks These blocks include channel coding module interleaver module and data mapping module We also demonstrated the work of our system in the software environment Next steps of the UMTS/WiMAX system development are preparation of the specification and implementation of all possible scenarios Each scenario will include particular blocks parameters and common description of main blocks But we have to be carefully in case of main blocks description because there are a plenty of features 8 ACKNOWLEDGMENTS We gratefully acknowledge the company Arslogica that kindly provided us the hardware support for our experimental studies 9 REFERENCES 1 A Samukic UMTS Universal Mobile Telecommunications System development of standards for the third generation Proc of 1998 IEEE GLOBECOM Conf Sydney AUS Nov 8-12 1998 vol.4 pp.19761983 2 N Fourty T Val P Fraisse and J.-J Mercier Comparative analysis of new high data rate wireless communication technologies From Wi-Fi to WiMAX Proc of the IEEE Autonomic and Autonomous Systems and International Conf on Networking and Services ICAS-ICNS 05 Oct 23-28 2005 pp.66-66 3 M Komara SDR Architecture Ideally Suited for Evolving 802.16 WiMAX AirNet Communications SDR Forum Exhibition 2004 4 I Held 0 Klein A Chen C.-Y Huang and V Ma Receiver Architecture and Performance of WLAN Cellular Multi-Mode and Multi-Standard Mobile Terminals Proc of 2004 IEEE VTC Fall Conf Los Angeles CA Sept 26-29 2004 vol 3 pp 2248 2253 5 IEEE Standard for Local and Metropolitan Area Networks Part 16 Air Interface for Fixed Broadband Wireless Access Systems 2004 6 R Weigel and L Maurer  D Pimingsdorfer A Springer RF Transceiver Architectures for W-CDMA Systems Like UMTS State of the Art and Future Trends Proc of the Intern Symp on Acoustic Wave Devices for Future Mobile Communication Systems Chiba JP March 5-7 2001 pp 25-34 7 P-W Fu and K.C Chen A Programmable Transceiver Structure of Multi-rate OFDM-CDMA for Wireless Multimedia Communications Proc of 2001 IEEE Vehicular Technology Conf VTC-Fall 2001 Atlantic City NJ Oct.7-11 2001 vol 3 pp 1942-1946 8 L Zhigang L Wei Z Yan G Wei A Multi-standard SDR Base Band Platform Proc of 2003 International Conference on Computer Networks and Mobile Computing Shanghai PRC Oct 20-23 2003 pp 461 464 9 C Moy A A Kountouris L Rambaud and P Le Corre  Full Digital IF UMTS Transceiver for Future Software Radio Systems  Proc of ERSA 01 Conf Las Vegas NV June 25-28 2001 10 3GPP TS 25.201 Physical layer general description 11 K.R Santhi and G.S Kumaran Migration to 4 G Mobile IP based Solutions Proc of International Conference on Internet and Web Applications and Services/Advanced International Conference Feb 2006 pp 76 76 12 S Zhu M Song Y Li J Song and F Ren Simulation platform of WCDMA based on software defined radio Proc of 2nd ACM International Conference on Mobile Technology Applications and Systems Nov 2005 pp 1-5 13 L Ma and D Jia The Competition and Cooperation of WiMAX WLAN and 3G Proc of 2nd International Conference on Mobile Technology Applications and Systems Nov 2005 pp 15 14 J Mitola III Software Radio Architecture ObjectOriented Approaches to Wireless Systems new ed Wiley New York 2004 15 R Seungwan 0 Donsung S Gyungchul and K Han Perspective of the next generation mobile communications and services Proc of IEEE 2004 Int Symp on Personal Indoor and Mobile Radio Communications PIMRC 2004 Barcelona SP 5-8 Sept 2004 vol.1 pp 643-647 16 E Biglieri Coding for Wireless Channels  Springer New York 2005 12 


17 3GPP TS 25.212 Multiplexing and channel coding FDD 18 IEEE Standard for Local and metropolitan area networks Part 16 Air Interface for Fixed and Mobile Broadband Wireless Access Systems Amendment 2 Physical and Medium Access Control Layers for Combined Fixed and Mobile Operation in Licensed Bands and Corrigendum 1 2006 pp 0_1 822 19 3GPP TS 25.211 Physical channels and mapping of transport channels onto physical channels FDD 20 Data sheet from Lyrtech Inc http available at htp c hwwkneopusff _.l/p.s/lrtehs _sr d21]D ateforomTdf 21 Data sheet from Texas Instruments http available at 22 Data sheet from Xilinx http available at httll/www.xilinx.com 23 L Hanzo W Webb and T Keller Singleand Multicarrier Quadrature Amplitude Modulation  Wiley New York 2000 titled Wireless and Satellite Communications  The research interests of Dr Sacchi are mainly focused on wideband mobile and satellite transmission systems based on space time andfrequency diversity multi-user receivers based on non conventional techniques neural networks genetic algorithms higher-order statistics-based receivers etc cross-layer PHY-MAC design and high-frequency broadband satellite communications He is currently local coordinator for University of Trento of research projects dealing with reconfigurable communication platforms based on MIMO techniques and space-time signal processing ICONA project funded by MIUR and with exploitation of W-band for broadband satellite communications WA VE programs funded by ASI Claudio Sacchi is author and co-author of more than 50 papers published in international journals and conferences and reviewer for international journals and magazines IEEE Transactions on Communications IEEE Transactions on Wireless Communications IEEE Communications Letters IEEE Transactions on Aerospace and Electronic Systems Electronics Letters Wireless Networks IEEE Communications Magazine etc Dr Sacchi is member of the Organizing Committees and Technical Program Committees of international conferences like ICIP ICC GLOBECOM ACM-MOBIMEDIA etc Claudio Sacchi is member of IEEE M'01 SM'07 BIOGRAPHIES Olga Zlydareva is a PhD student of the University of Trento Italy She obtained her Master degree in Design Electronics Systems with specialization in High Radio Frequency Devices from MATI Moscow State Aviation Technological University named after KE Tsiolkovsky Moscow Russia Her research interests have oriented on the Software Defined Radio Technology Wireless Technologies Cellular Technologies Tunable devices Multi-standard systems Multi-protocol systems Physical layer of mobile devices Reconfigurability and Reprogramming of mobile devices The recent research focuses on the development of the baseband level of multistandard mobile devices based on SDR technology Claudio Sacchi was born in Genoa Italy in 1965 He obtained the Laurea degree in Electronic Engineering and the Ph.D in Space Science and Engineering at the University of Genoa Italy Since August 2002 Dr Sacchi has been holding aposition as assistant professor at the Faculty of Engineering of the University of Trento Italy In 2004 he was appointed by the Department of Information and Communication Technology of the University of Trento as leader of the Research Program 13 


  14  Figure 5:  Site B1 Terrain horizon ma sk with 1 degree azimuth spacing  Figure 6:  Site B1 Terrain horizon mask with 1 de gree azimuth spacing, in e quatorial coordinates 


  15  Figure 7: Lunar South Pole Solar Illumination Yearly Average  Figure 8:  Lunar South Pole DTE Visibility Yearly Average 


  16  Figure 9: Lunar North Pole Sola r Illumination Yearly Average  Figure 10:  Lunar North Pole D TE Visibility Yearly Average 


  17  Figure 11: Site A1 Elevation Topography  Figure 12: Site A1 Yearly Average Solar Illumination and DTE visibility, Medium Resolution 


  18   Figure 13:  Site LB Te rrain Horizon Mask  Figure 14:  Theory and Computed values of Average Yearly Solar Illumination 


  19  Figure 15:  Theory and Computed values of Average Yearly DTE Communication  Figure 16:  Heliostat Mirror Design to Eliminate Cable Wrap 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



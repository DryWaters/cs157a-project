 1 Autonomous Identification and Quantification of Chemical Species with VCAM for use Onboard the ISS Benjamin Bornstein, Seungwon Lee, Luke Mandrake, Brian Bue Jet Propulsion Laboratory California Institute of Technology 4800 Oak Gove Drive Pasadena, CA  91109 818-393-5349, 818-393-7720, 818-354-1705 ben.bornstein, seungwon.lee, luke.mandrake, brian.bue}@jpl.nasa.gov  Abstract The Vehicle Cabin Atmosphere Monitor VCAM\ instrument is designed to autonomously detect and identify trace organic species in the International Space Station \(ISS\cabin air and monitor changes in species concentrations over time afte r chemical events.  The physical instrument is comprised of two subsystems.  The 
first subsystem is a preconcentrator gas chromatograph PCGC\ical analytes in time, based on compound specific properties such as molecular weight The second subsystem is a Mass Spectrometer \(MS\ch measures the abundance of ionized analytes, separated in the GC phase, at specific mass-to-charge ratios.  The VCAM PCGC/MS produces a time-series of mass fractionation patterns, indicative of the chemical compounds present, which is used for subsequent compound detection identification, and quantification In order to autonomously identify and quantify chemical species from the PGGC/MS data VCAM employs a variant of the de-facto industry standard Automated Mass Spectral Deconvolution and Identification System \(AMDIS 
algorithm developed by the National Institute of Standards and Technology \(NIST\ AMDIS was chosen first for its superior performance, when compared to a neural network classifier developed in-house and a proprietary, third-party commercial algorithm, and second for its reputation within the mass spectrometry community.  In this paper we provide an overview of AMDIS, including GC peak identification and spectral matching, as well our variations and additions to the core algorithm for performing mass calibration beforehand and species quantification afterward.  We also discuss some of the cha llenges faced creating an independent implementation of AMDIS for delivery to 
VCAM flight software.  Testing our algorithm, both individual components and in its entirety, was a particularly challenging, as the VCAM instrument was still in development and only periodically able to produce validation datasets 12  1  1 1-4244-1488-1/08 25.00 ©2008 IEEE 2 IEEEAC paper #1327, Version 8, Updated December 14, 2007 T ABLE OF C ONTENTS  1  I NTRODUCTION  1 
 2  S YSTEM O VERVIEW  1  3  M ASS C ALIBRATION  2  4  GC  P EAK F INDING  3  5  C OMPOUND I DENTIFICATION  5  6  
C OMPOUND Q UANTIFICATION  6  7  I NITIAL R ESULTS  6  8  C ONCLUSION  6  R EFERENCES  7  B IOGRAPHY  7  1  I NTRODUCTION  The Vehicle Cabin Atmosphere Monitor \(VCAM 
instrument is designed to autonomously detect and identify trace organic species in the International Space Station ISS\onitor changes in species concentrations over time after chemical physical instrument is comprised of two subsystems.  The first subsystem is a preconcentrator gas chromatograph PCGC\ical analytes in time, based on compound specific properties such as molecular weight The second subsystem is a Mass Spectrometer \(MS\ch measures the abundance of ionized analytes, separated in the GC phase, at specific mass    The VCAM PCGC/MS produces a time-series of mass fractionation patterns, indicative of the chemical compounds present, which is used for subsequent compound detection 
identification, and quantification 2  S YSTEM O VERVIEW  The VCAM Data Analysis Software \(DASW\ transforms a series of raw ion counts from a GC/MS instrument run into a list of chemical compound identifications and quantifications.  At a high-level, the data analysis software has four major components: mass calibration, GC peak finding, compound identification, and compound quantification \(Figure 1  


 2  NIST A MDIS VC A M Da t a An a ly s i s Compound Quantification GC Peak Finding Compound Identification Mass Calibration Figure 1: A block diagram illustrating the four major co mponents of the VCAM DASW and information flow among them 3  M ASS C ALIBRATION  The mass calibration routine maps raw instrument channel numbers to corresponding atomic mass units for later use in GC peak finding and MS spectral matching \(compound identification\ The algorithm aligns ion counts integrated over time with the two earliest high-intensity channels with the expected mass positions of major constituents nitrogen N 2 at 28 AMU\gen \(O 2 at 32 AMU\ater peaks with calibration gases acetone \(CH 3 COCH 3  fluorobenzene \(C 6 H 5 when available\s a mass-channel least squares fit.  As a sanity check, an approximate mass-channel mapping is derived from the Mathieu equati by usi ng param e t e r val u es obt ai ned from the VCAM RF ramp hardwa re registers.  A detailed description of this procedure is follows We compute a total ion chromatogram \(TIC\from the mass spectra by summing ion counts over mass channels for each scan time TIC  scan   I  scan  channel  channel   Then we smooth the TIC by averaging over adjacent neighbor scans using a window of size three J  scan   I  scan  1  I  scan   I  scan  1 3  From the smoothed TIC, we calculate the overall noise factor \(N f f the data.  The noise factor is identical to that performed by NIST AM   Scans are di vi ded i n t o  12 channel segments and the mean of each segment is computed.  Within each segmen t, the number of times the data, taken in pairs, “cross” the mean is counted.  If the number of crossings is larger than six, the segment is marked as nominal background. The median of the difference between a segment’s ion counts and the average ion count present in the nominal background segments is taken. Call the median of the difference md\(segment median of md\(segment\s the noise factor of the total ion chromatogram If a noise factor cannot be computed, the whole total ion chromatogram is treated as a single elution peak. Once the noise factor is found, elution peaks are located using J\(scan and N f  Candidate mass peaks above background are chosen such that their width is at l east seven channels and the preliminary peak height is greater than the threshold given by the noise fact  S  N  where S  J  peak   J  background  N  5 N f J  peak   If no elution peaks are found, the entire total ion chromatogram is treated as a single elution peak When only one elution peak is present \(including the case that the total chromatogram is treated as one elution peak the peak is assumed to be air.  When multiple elution peaks are found, the first peak is treated as an air peak and the remaining peaks are treated as potential acetone peaks Next we find channel peaks of each TIC elution peak Channel peaks are found as follows. First compute the mass spectrum of one elution peak I  channel   I  scan  channel  scan  left limit of thepeak scan  right limit of thepeak   Second, find the width of the largest channel peak. The largest channel peak’s width is defined as the channel range within which the ion count keeps descending as it goes away from the largest peak. Half of the largest channel peak width is used as the threshold of the peak width to find other channel peaks. If an ion count of a given channel is 


 3 the largest within the threshold range \(channel threshold_width, channel + threshold_width\the channel is considered a channel peak For the air \(N 2 and O 2 tion peak, we then identify the two largest channel peaks \(c hannel A and channel B\ and assign them masses 28 and 32. The smaller channel number is assigned mass 28 and the larger channel number is assigned mass 32. Using the two channel-mass pairs channel B, 32\nd the linear equation for the relationship between channel number and mass charge \(m/z We refine this initial fit by applying the mass-channel linear equation to other channel peaks. In particular we find the channel peaks \(channel C and channel D closest to atmosphere major constituent calibration masses for argon \(40 AMU\O 2 44 AMU channel B, 32 channel D, 44\t to a linear equation for the relationship between channel number and mass charge \(m/z mass  a  channel  b  With a four-point channel-mass calibration, we search for acetone.  For each of the poten tial acetone elution peaks the two largest channels are identified \(channel E, channel F and assigned calibration mass 43 and 58. We record two channel-mass pairs: \(channel E channel F, 58 By combining the two channe l-mass pairs from the acetone peak with the four channel-ma ss pairs from the air peak we obtain a six channel-mass pair linear fit.   Finally, we asses the quality of the fit If only an air peak was found, we use the linear equation from the air elution peak to estimate the error of each calibration mass \(28, 32, 40, and 44\ If both an air peak and a potential elution peak are used in the mass calibration use the linear equation from the two elution peaks to estimate the error of each calibration mass \(28, 32, 40, 43 44, 58 E rro r  m   m   a  channe l  b   If the maximum error is smaller than 0.5 AMU, the mass calibration is considered successful.  For compound identification, masses are binned to a resolution of 1 AMU to allow matching of mass fractionation patterns to those in the NIST Spectral Library A m a ss calibration error greater than 0.5 AMU results in incorrect mass patterns and results poor identification performance 4  GC  P EAK F INDING  Gas Chromatograph \(GC\ peak finding is performed according to the NIST Automated Mass Spectral Deconvolution and Identification System \(AMDIS algorithm  The VCAM GC/MS unit produces data as a 2D grid of ion counts with axes representing discretized elution time vs mass to charge ratio in units of AMU per fundamental electron charge \(Figure 2  Figure 2: An overhead view of a VCAM GC/MS image color-coded according to ion count.  Notice the persistent nitrogen and oxygen mass lines present throughout the GC/MS run It is customary to refer to the m/z ratio simply as “mass and assume units of AMU despite this not being precisely correct if multiple ionizations are possible. Multiple ionizations permit apparent fr actional “masses” to appear and the scanning resolution the VCAM MS sensor effectively detects sub-AMU accuracy. However, as the identification library we intend to use [6, 10 h a s o n l y b een  recorded to integer AMU/z accur acy, our first step is to sum all bins such that our resolution along the mass axis only measures integer values of AMU/z. In our case, this results in mass channels ranging from 20 to 400. We have considered, as a means of increasing identification accuracy, using the full mass charge resolution of the device; however, this would entail the manual creation of a compound identification library either in very controlled reliable conditions using highly standard equipment.  In our case, the labor required for such an approach was beyond the scope of our project, and thus we instead sacrificed subinteger mass accuracy. With our data in this format, the AMDIS identification met i s t h en broken i n t o  four main algorithms: noise analysis, time peak identification, processing identified peaks into potential compound spectra, and finally matching these potential compounds against the library standards. In the coming description, we will be working individually with mass channel data as well as TIC, which is merely the summation of all ion counts across all channels \(Figure 3 Channel Number Time \(sec 


 4   Figure 3: Ion counts vs. time summed over all mass channels \(TIC\on the horizontal This plot can be viewed as a vertical slice of Figure 2 Where TIC may pick up weak el ution events present across many channels but relatively weak in each, it may miss activity in only one or two channels that would be quite apparent in a channel-by-c hannel approach. Thus, both 380 individual mass channels and the TIC signal are used in all analysis below. The original AMDIS method includes details to estimate a “lowest sensitivity” for GC./MS instruments, such as anything less than five ion counts will be truncated to zero; however, the VCAM MS sensor accurately measures even si ngle ion counts and thus no such logic was required for our AMDIS adaptation Noise Analysis AMDIS depends crucially on the concept of accurate recognition of peaks of ion counts in time.  Determination of a peak's veracity, however, depends critically on the relative size of the potential p eak versus the ambient noise in the measured signal.  Thus we require an estimate of this noise in some meaningful unit.  We define a “noise factor N f as the mean fluctuation of a “calm” \(no elution event region of our grid divided by the square root of the mean signal. To calculate this va lue, we break each channel's signal \(including TIC as one such channel\ into segments of 12 time samples.  Each segment is then examined to count the number of times its signal crosses its mean value.  If that number is less than 4, the segment is rejected as likely having an elution event or instrument instability occurring For each accepted segment, we then compute mean signal  mean signal  mean signal    This yields a distribution of candidate noise estimates.  The median of these noise estimates is then calculated, yielding our final noise factor \(N f e are now ready to define the significance of any particular peak relative to this noise estimate.  This procedure must be done once per dataset and may fail if there are no regions of sufficiently “flat” signal such as if there is insufficient lead or lag time surrounding elution events Temporal Peak Identification For each channel, we now scan for any significant peaks For each local maxima, we begin expanding a surrounding local window.  This expansion occurs to the left \(earlier time\and right \(later time\ndependently.  A maximum size of 12 time samples is permitted in either direction.  Our estimate for the noise of this particular window is N f x sqrt\(smallest_signal\where the smallest signal is for this window only.  We then begin to expand, sample by sample our window about the central peak.  If the signal rises five times the previous noise estimate above the lowest signal thus seen within the expanding window, we determine we have left the influence of the current peak and stop expansion.  If the difference between the current signal and the peak signal has become mo re than 95% of the peak's height relative to the window's lowest signal, we determine we have captured the entire peak and stop expansion Finally, if we encounter two sequential zero signal samples we conclude the elution event must be over and stop expansion.  Thus, utilizing these three conditions, we now have a window bracketing the current local signal maxima Note that these windows can and usually do overlap one another in noisy samples. Typical GC/MS time profiles have sharper onset rise and a smoother, longer decay tail and thus these windows are usually asymmetric about the central peak Within this window, we now calculate three basic peak parameters: the relative peak height, a precision estimate of the true peak height in time, and the maximum sharpness of the peak.  Relative peak hei ght is a somewhat ornate calculation wherein we first fit a line to the lowest sample left and right of the peak in the window and subtract this out as our first initial guess at bias and instrument drift.  We then fit a second line through all of the lowest half points within the window.  The relative height is then determined by the absolute peak height minus this second baseline plus the mean relative height of the two samples to the immediate left and right of the main peak, divided by the noise estimate of the peak given simply as N f x sqrt\(peak_absolute_signal\.  The second peak parameter of precise location in time is determined by performing a parabolic fit to the peak maxima and its two nearest neighbors.  Finally, the maximum sharpness is the maximum of the following quantity calculated for all t within the window of interest sharpness  t   signal  t peak   signal  t   t  t peak   N f signal  t peak    This sharpness maxima is found independently for the left and right windows relative to the central peak, and the final reported sharpness is the sum of both.  Armed with these Time  sec   Total Ion Count 


 5 three parameters, we may now judge the peak to be of interest or not.  If the relative peak sharpness is not at least two for the TIC or three for individual channels, the peak is rejected as too broad.  Likewise the peak is rejected if the relative height fails the following where min_height is 12 for TIC and three for individual channels relative _ peak _ height  tota l _ p ea k _ width  4.0 total _ window _ size  min_height   This process generates hundreds to thousands of validated peaks for a typical dataset We are now faced with packaging these peaks into coherent groupings of candidate compounds for comparison using their elution times and peak shapes as guides Compound Packaging The problem of identifying a group of peaks as part of a single candidate compound is twofold: first we must determine which peaks go together, and second whether two extremely close potential compounds are in fact two overlapping coelutions or a single noisy elution.  To do this we define a grid ten times as dense in time as our sample data. Running through all peaks previously validated from individual channels or the TIC, we add to each of these bins any peak's sharpness whose precise maximizing time estimated by the parabolic fit above\ls within said bin We also keep track of the “dom inant” peak w ithin each bin namely that peak which posse sses the greatest sharpness Once this dense grid is formed with sums of sharpness within, we walk the grid un til we find a bin with nonzero value.  If this bin's value is not larger than bins within two to the left and right, the bin is rejected as a potential compound elution as not being robust enough compared to nearby potential elutions.  Next we form the nearby_sum of all bins within two to the left and right.  From this value, we calculate an estimated width over which this bin must be the dominant event to be considered a compound elution.  This time width \(in bin number\s given by the max\(2 int\(150/nearby_sum\his bin's value is greater than any other bin within this time width to the left and right, it is accepted as a compound elution at the precise time represented by this bin For each compound elution time accepted above, we walk the entire list of peaks found in the peakfinding step. Any peak which a\s within the time width window given above of the current elution time, and b\alized height at least 75% of the dominant peak for this bin, we add as belonging to this elution event. Once our list of peaks is complete for each compound elution, we add together the original signals of every contributing peak within the window of this elution event to obtain a representative “model” of this particular elution. This model, baseline removed, will be then used to determine the mass spectrum actually reported to the identification step This is done by performing a least squares fit of the form mass _ channel _ signal  b  m  1,2,3,4,5   c  model   where b is an overall ignored signal bias, m is an ignored linear trend attributed to device drift within a single elution time, and c is the actual contribution of this mass channel to the elution event \(the value of interest\Finally, various flags can be added to this particular mass channel's contributing peak indicating it has a small signal/noise ratio background peak\ore than two zero counts are present within the signal window \(could be spurious noise spike the fit error using the compound model is too large \(badly modeled peak may not actually be part of this elution These flags penalize individual peak s in the last step, that of compound identification 5  C OMPOUND I DENTIFICATION  Compound identification \(MS spectral matching\is performed according to the NIST AMDIS algorithm [7, 5   We now have a list of potentially dozens of elution times \(to one tenth sample time accuracy\associated of mass channel peaks and relative amplitudes, in addition to flags describing hazardous character istics. To identify an extracted elution, each eluti on must be matched against entries of known compounds within a pre-existing library The “match factor” that describes how well a candidate compound matches a library compound is formed via the summation of the dot product of mass spectra peaks in the candidate compound with the library entry to which it is being compared, weighted by th e square of the mass at each channel, and penalized by any associated flags match _ factor library  peak unknown  m m mass _ channels   peak library  m  flag m  m 2  Heavier masses are more significan t as they represent larger and hence more unique\olecular fragments thus bearing greater identification potential. Unfortunately, the VCAM instrument’s current sensitivity decreases with larger mass which makes the precise weighting a matter of debate and research. For each elution time event we now have a list of match factors \(approximate likelihood within the spectral library. The library compound with the highest match factor is reported as the best possible match and its match factor is provided so the user may have some estimate of trustworthiness 


 6 6  C OMPOUND Q UANTIFICATION  Compound quantification analysis reports the concentration in parts-per-million\co mpounds that have been identified by the NIST AMDIS spectral matching algorithm VCAM project scientists Ara Chutjian, Murray Darrah, and John MacAskill provided the compound quantification method.  To quantify compound concentration, first the total ion count under an elution peak \(signal\ is found.  Second this ion count is compared against a concentration curve one for each compound to be quantified\to arrive at the total compound concentration. Concentration curves are determined empirically, on the ground, with the VCAM development and protoflight units.  The family of concentration curves is parameterized by two constants  and llows signal    concentration    Transforming the concentra tion curve to log-log space yields constants a and b and the total concentration log concentration   a log signal   b  7  I NITIAL R ESULTS  A major challenge in verifying the VCAM DASW identification and quantification algorithms has centered on the dearth of data currently available for testing.  The VCAM instrument is still under active development and detailed and dedicated com pound testing has only recently become the scientist and instrument team’s highest priority Table 1 presents a snapshot of all data analysis identification results on all readily available compounds circa March 2006, the last time compounds for run through the instrument for hardware detection and software identification testing.  In come cases, the data analysis algorithms performed well and in others, greater accuracy is certainly desired.  With th e exception of acetone however none of compounds were present in large enough numbers to provide meaningful accuracy statistics.  At the time of this paper, the VCAM team has successfully uncovered and recovered from several instrument contaminations events that were hindering compound detection by the hardware and also confounding data analysis software.  Compound testing has begun in earnest and we fully expect the data analysis software will meet VCAM mission accuracy requirements 100 5 5 toluene 100 3 3 pentane 67 3 2 heptane 67 3 2 benzene 30 10 3 2-propanol 83 6 5 1-butanol 40 5 2 methanol 42 19 8 ethanol 75 4 3 dichloromethane 90 80 72 acetone 100 1 1 acetaldehyde Accuracy  Total Samples Correct Sample   Table 1: A snapshot of data analysis and identification rate results on all readily available compounds circa March 2006 8  C ONCLUSION  We presented our variant of the de-facto industry standard Automated Mass Spectral Deconvolution and Identification System \(AMDIS\gorithm developed by the National Institute of Standards a nd Technology \(NIST\VCAM employs AMDIS to autonomously identify and quantify chemical species from PCGC/MS data.  In addition to stock AMDIS peak-finding and spectral matching, we augmented the AMDIS method with mass calibration on the front-end and compound quantification on the back-end.   Analysis results on initial laboratory datasets are promising, but more testing is required A CKNOWLEDGEMENTS  The research described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration.  We thank the VCAM project scientists Ara Chutjian \(PI Murray Darrah \(Co-I Kidd, John MacAskill, Dan Fry Erge Edu-Fry, and VCAM flight software leads Vance H aemmerle and Mike Girard for their many insights and valuable contributions to this work 


 7 R EFERENCES   A. Chutjian, et al Ove rview of the Vehicle Cabin Atmosphere Monitor, a Miniature Gas Chromatograph/Mass Spectrometer for Trace Contamination Monitoring on the ISS and CEV Proceedings of the 37th In ternational Conference on Environmental Systems SAE Technical Paper Series paper number 2007-01-3150   R   G Drom ey  M   J. St efi k T. C  R i ndfl e i s ch, and A. M   Duffield, “Extraction of Mass Spectra Free of Background and Neighboring Component Contributions from GC/MS Data,” Journal of Analytical Chemistry, Vol. 48\(9\1368 1375, 1976   D L Jan, “Envi ronm ent a l M oni t o ri ng Inst rum e nt s Usi ng ISS as a Testbed for Exploration Proceedings of the 2007 IEEE Aerospace Conference Big Sky, Montana March 2007   R   E M a rch An Int r oduct i on t o Quadrupol e Ion Trap Mass Spectrometry Journal of the American Society of Mass Spectrometry Vol. 32, 351–369, 1997 5 S.E Stein   Estim atin g Pro b a b ilities o f Co rrect Identification from Results of Mass Spectral Library Searches Journal of the American Society of Mass Spectrometry Vol. 5, 316–323, 1994   S E St ei n and D. R  Scot t  Opt i m i zat i on and Test i ng of Mass Spectral Library Search Algorithms for Compound Identification Journal of the American Society of Mass Spectrometry Vol. 5, 859–866, 1994   S. E. St ei n, “An Int e grat ed M e t hod for Spect rum  Extraction and Compound Identification from GC/MS Data Journal of the American Society of Mass Spectrometry Vol. 10, 770–781, 1999   H. Zhou, M  L. Hom e r, A. V. Shevade, and M   A R y an Nonlinear Least-Squares Based Method for Identifying and Quantifying Single and Mixed Contaminants in Air with an Electronic Nose Proceedings of the 2005 IEEE Sensors  Conference ISSN 1424-8220   NIST Aut o m a t e d M a ss Spect ral  Deconvol ut i on and Identification System \(AMDIS http://chemdata.nist.gov/mass-spc/amdis   NIST/EPA/NIH M a ss Spectral Library  NIST 05  ASCII Version, http://www.nist.gov/data/nist1.htm B IOGRAPHY  Ben Bornstein is a senior member of the Machine Learning and Instrument Autonomy group at the Jet Propulsion Laboratory in Pasadena, CA.  He is the lead engineer for VCAM data analysis and its flight software implementation.  Ben enjoys bringing machine learning techniques and considerable hacking \(programming\ skills to bear to solve problems in geology, remote sensing, bioinformatics, and systems biology.  He has designed and implemented software systems for several Caltech bi ology labs, the Institute for Genomics and Bioinformatics \(IGB\ at UC Irvine, USC Children’s Hospital, and JPL’s Mars Exploration Rover MER\ project.  He is also the inventor of and lead developer for LIBSBML, an ope n-source library for the Systems Biology Markup Language SBML\.  Ben received a B.Sc. in Computer Science from the University of Minnesota Duluth in 1999 and is pursuing a M.Sc. in Computer Science at the Uni versity of Southern California  Seungwon Lee  is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is involved in projects developing flight instrument software for Vehicle Cabin Atmosphere Monitor and conducting research on materials modeling and simulation, nonlinear dynamics control, spectral retrieval data reduction, global optimization parallel computing, and advanced numerical algorithms She received her Ph.D. in Ph ysics from the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University  Luke  Mandrake is a member of the Machine Learning and Instrument Autonomy group at the Jet Propulsion Laboratory in Pasadena, CA. He is involved in the application of machine learning techniques to current research endeavors with various Earth-sensing satellite systems and particularly enjoys building and studying computational models of natural systems. Luke 


 8 received his PhD. and M.S in computational plasma physics from UCLA and his B.S. in engineering physics from the University of Arizona  Brian Bue is a research programmer in the Machine Learning and Instrument Autonomy group at the Jet Propulsion Laboratory, where he participates in projects involving software and algorithm development for Earth and planetary science data analysis.   In the past, he has done research in computational geomorphology, automated terrain analysis planetary image processing and sc ientific visualization. He received a M.S. from Purdue University in Computer Science, and Bachelor’s degrees from Augsburg College in Computer Science and Mathematics. He is currently pursing a Ph.D. in Electrical and Computer Engineering at Rice University  


  9 throughput about 15 In Fig.12 \(f\raffic for four channels is about 300 % and throughput for those channels is about 15 %.  This result shows that the congestion on each channel decreased by increasing the number of R smc channels and this mitigated the log-on rush phenomenon considerably as shown in Fig.7 Advantages and Disadvantages of Each Method Asymmetric Use of R smc Channel 227One of the advantages is that it is effective for a channel rate of 600 bps without increasing the number of channels.  Another is that it can be realized just by modifying the GES software without modifying any avionics software.  Since the modification of avionics software involves much difficulty, we consider this method to be the best alternative at present Increase of Channel Rate 227One of the advantages is that the number of required channels can be decreased.  Another is that the period required for a log-on can be the shortest compared to the other two methods.  The disadvantage is that some modification of GES and avionics software is required.  This method should be considered for realization in the future Increase of Number of Channel 227One of the advantages is that it is effective for a channel rate of 600 bps.  Another is that it can be realized very easily by increasing the number of channels.  The disadvantage is that, since frequency allocation is limited in general, it may not be possible to increase the number of channels 6  C ONCLUSIONS  In this paper, we descri bed the log-on rush phenomenon which may occur in the event of a GES or satellite failure in aeronautical satellite communi cation and possible methods to mitigate the phenomenon.  We showed as an example that it takes more than 5000 s for all 500 AES to complete a log-on for a typical channel configuration Then, we considered three methods of mitigation and analyzed the effectiveness of these by a series of simulations.  The first method was the asymmetric use of R smc channels.  We showed that the phenomenon can be almost completely prevented by choosing an adequate channel configuration without changing the channel rate and without increasing the number of R smc channels.  The second was the increase of channel rate of R smc channels We showed that the phenomenon can be prevented by this method using a smaller number of channels and that the time required for all AES to complete a log on can be reduced compared to the previous method.  The third was the increase in the number of R smc channels.  This is a straightforward method.  We showed that it is also effective to mitigate the phenomenon without increasing the channel rate.  But, the number of channels may not be increased freely, because frequency resources are limited We consider that the asymmetric use of R smc channel is the best alternative to mitigate the log-on rush phenomenon at present. The increase of channel rate will be a prospective measure to be realized in the fu ture.  It is also conceivable that these two measures could be combined to improve logon performance further The time for hundreds of AES to complete a log-on is still more than 1000 s even with the asymmetric use of R smc  channel.  This value is still very large and should be reduced.  Since only one P smc channel can be used per GES according to the AMSS SARPs, throughput of P smc channel is limited and this causes a very long time for log-on completion.  The reduction of the time is a problem that should be solved next A CKNOWLEDGEMENT  We would like to thank everyone concerned at INMARSAT Corporation, Japan Civil Aviation Bureau and Japan Radio Air Navigation Systems Association for their cooperation R EFERENCES    Al an Schust e r B ruce, Per Nokeby 223Log-on Issues\224, FANS Satcom Improvement Team 2 nd meeting in Paris, Oct 2007 2 n au tical Mo b ile Satellite Serv ices Stan d ard s and Recommended Practices   INM A RSAT: INM A RSAT AERONAUTICAL SYSTEM DEFINITION MANUAL\224, 2000  Y.Sum i y a A.Ishi de  223A St udy of Log-on R u sh usi ng Aeronautical Satellite Communication Simulator\224, The 2007 IEICE General Conference, Mar. 2007 \(Japanese only B IOGRAPHY  Yasuto Sumiya was born in Sapporo Japan.   He received the B.S. degree in 1993 from the University of Hokkaido, Japan Since 1993, he has been with the Electronic Navigation Research Institute, Ministry of Transport Tokyo, Japan.   Since 2001, he has been with the Electronic Navigation Research Institute, Independent Administrative Institution.   He has been engaged in research on Aeronautical Satellite Communication System  


  10 Airborne Collision Avoidance System and Enhanced Vision System  Akira Ishide was born in Tokyo Japan.  He received the B.S. degree in 1971 from the Tokyo Institute of Technology, Tokyo, Japan.   Since 1971, he has been with the Electronic Navigation Research Institute, Ministry of Transport Tokyo, Japan.   He received the Ph D. in 1996 from the Tokyo Institute of Technology, Tokyo, Japan Since 2001, he has been with the Electronic Navigation Research Institute, Independent Administrative Institution He has been engaged in research on Aeronautical Satellite Communication System, Array Antenna System, and so on 


Alan Little is the MEDLI Project Manager at NASA's Langley Research Center He previously served on a variety of earth remote sensing missions and recently served as the NASA-CNES interface manager and the payload assembly integration and test manager on the joint NASAICNES CALIPSO Mission that was launched in April 2006 He has a MS in Optics from the University of Rochester Neil Cheatwood earned B.S MS and Ph.D degrees in aerospace engineering from NC State University He has played key roles in a number of NASA's planetary atmospheric flight programs and is a nationally recognized expert in aerosciences and flight mechanics for planetary entry systems He is currently serving as the Hypersonics Project Scientist for the Fundamental Aeronautics Program with NASA's ARMD Dr Cheatwood is also the Principle Investigator for the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI project In recent years he led NASA LaRC efforts to develop inflatable aeroshell technologies He served as CoInvestigator to Claude Graves of NASA JSC on the NASA ESMD ESR&T Inflatable Aeroshell and TPS Development IA TD Project He served as the Principle Investigator for NASA LaRCs Inflatable Reentry Vehicle Experiment IRVE as well as the follow-on Program to Advance Inflatable Decelerators for Atmospheric Entry PAI-DAE Dr Cheatwood was responsible for aerodynamic databases of Stardust Mars Microprobe Genesis and Mars Exploration Rovers He has also contributed to the Mars Global Surveyor and Mars Sample Return flight projects Dr Cheatwood is an AIAA Associate Fellow and the principle author or co-author of 60 technical publications in the fields of fluid dynamics atmospheric entry and systems engineering Jeff Herath serves as the Lead Systems Engineer and Chief Engineer for the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI He also serves as the Assistant Head of the Atmospheric Flight and Entry Systems Branch AFESB to plan direct and coordinate Branch activities in the areas offlight and entry systems research and development Mr Herath previously was the Acting Assistant Branch Head for Electronic Systems and served as the branch leadfor new business activities proposals and their development He was also the Principal Investigator PI for the Radiation Tolerant Intelligent Memory Stack RTIMS Project which successfully developed and demonstrated an in-flight reconfigurable radiation tolerant stacked memory array He co-founded Vianix LC a company developing and licensing voice compression technology and served as its Chief Technology Officer He developed the company's voice compression technology and was responsible for all research  development engineering personnel and production efforts He has 6 patents As Manager of Hardware Development at Arc Second Inc he designed and built a unique laser based three-dimensional positioning system which opened new markets for the company At E-Systems he successfully completed several military avionics programs and payload that were classified and consisted of system box and board level designs Michelle Munk has been a NASA employee for nearly 20 years first at the Johnson Space Center then at the Langley Research Center She has been involved in Mars advanced mission studies for many years both robotic and human contributing interplanetary trajectory analysis and entry and descent analysis She has managed the delivery of International Space Station hardware and was on the Mars Odyssey aerobraking operations team In 2002 Ms Munk accepted a detail assignment to become the Lead Engineer for Aerocapture Technology Development under In-Space Propulsion at Marshall Space Flight Center She managed the technical work of ISP Aerocapture for nearly 5 years before becoming the Project Area Manager and returning to Langley in 2007 Ms Munk is also a subsystem leadfor the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI project and contributes to other NASA projects developing entry system technologies She has a BSAE from Virginia Tech and completed graduate coursework at the University of Houston Frank Novak is an Assistant Branch Head for Remote Sensing Flight Systems Branch RSFSB at the NASA Langley Research Center LaRC in Hampton VA He serves as the MEDLI Subsystem Manager for the Sensor Support Electronics SSE system Mr Novak has over 20 years of experience in the design development and test of spaceflight electronics He served as the lead development manager for the EVA IR Camera Project lead engineer for the visible imager for the GIFTS project lead electronics engineer for the pointing spectrometer for the Mars ARES project lead integration and test engineer for the SAGE III project and lead engineer for the interface adaptor module for SAGE III He earned a BS in Physics from Christopher Newport University in 1999 11 


Ed Martinez is a Project Manager/Lead Scientist/Project Engineer with 20 years experience in the aerospace and electromechanical field He is responsible for leading the Thermal Protection System TPS instrumentation programs for the NASA Ames Research Center As Project Manager he simultaneously managed multiple teams of scientists engineers and engineering technicians responsible for TPS projects including test analysis and technology advancement As Lead Scientist he was engaged in the characterization and operations of the world's largest shock tube This facility produced simultaneous overpressure and thermal environments at shock speeds up to Mach 5 As a Project Engineer his experience included project initiation coordination and providing design and instrument criteria for operating multi-100 million dollar DoD facilities Mr Martinez also managed data handling performed analysis reporting of test results and maintained technical proficiency in shockwave phenomenology 12 


  13 B IOGRAPHY  Brian Paczkowski is currently the Deputy Section Manager of the Planning and Execution Section within the Systems and Software Division at JPL. Prior to that he spent 9 years as the Cassini Science Planning Manager responsible for the development and implementation of the Science Operations Plan. Prior to Cassini, he was the Science Planning and Operations Team Chief for the Galileo Mission to Jupiter. He has also been involved with the pre-launch development of the science instruments on Galileo, Comet Rendezvous and Asteroid Flyby \(CRAF\ and Cassini missions. He has a BS in Astronomy from Villanova University and did graduate studies in Astronomy at Ohio State University  Barbara Larsen  is the Mission Operations System Engineer for the Cassini Mission. She is also on the science planning staff and previously worked in system engineering for the Mission Sequence Subsystem. She has a MS in Mathematics from California State University Long Beach and a BS in Mathematics from USC Trina Ray  is currently the Titan Orbiter Science Team \(TOST\ co-chair and the Science System Engineer for the Project Scientist for Cassini. She has been working on the Cassini Mission since before launch as an instrument operations lead for the Radio Science Team, and then as part of the Science Planning Team supporting Titan integrati on and sequence development She has a MS in Astronomy from San Diego State University and a BS in Physics, Astronomy option from CSUN  


  14  


 15 Fourier transform spectrometers at the Internationa l Scientific Station of the Jungfraujoch Switzerland  for atmospheric measurements and at the Institute of Astrophysics in Liège for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engin eer and participated in all the MkIV campaigns since th en \(one DC-8 campaign 19 balloon campaigns Dr J.-F Bla vier obtained his Ph.D in Physics from the University o f Liège in July 1998 Paula Pingree is a Senior Engineer in the Instruments and Science Data Systems Division at JPL She has been involved in the design integration test and operation of several JPL flight projects most recently Deep Impact DI She has worked on the Tunable Laser Spectrometer development for the 2009 Mars Rover and is presently the Electronics CogE for the Juno Mission s Microwave Radiometer She also enjoys research and technology development for Smart Payloads in her s pare time Paula has a Bachelor of Engineering degree i n Electrical Engineering from Stevens Institute of Te chnology in Hoboken, NJ, and an MSEE degree from California State University Northridge.  She is a member of IEEE 


 16  A High Capacity Solid Sate Recorder \(HC-SSR\is suggested using devices predicated to be available for each decade.   The design is robu st and easily implemented using conservative design and manufacturing techniques D EFINITIONS  rad radiation absorbed dose\:   the dose causing 0.01 joule of energy to be absorbed per kilogram of matter.   As the absorption is greatly affected by the molecular structure of the material, citations should al so indicate the material as a subscript to the term 223rad\224, as in rad Si indicating Silicon equivalency.  For the purposes of this paper, radiation equivalency always assumes Silicon For completeness, it should be noted that System International replaced the \223rad\224 with the unit Gr ay \(Gy\nd having an equivalency of 100 rads = 1 Gy [27 How e v e r   the use of rads, kilorads, megarads remains in the industry vernacular and is used in this document Moore\222s Law Named after Fairchild Semiconductor technologist Gordon Moore, Moore\222s law was derived from empirical data which shows that the dimensions of basic memory cells will shrink by approximately 50% of the previous value every 30 to 36 months.  It is Moore\222s Law more or less, that forms the backbone of the ITRS examinations for memory devices A DDITIONAL M ATERIAL  Standard Dose Rates for Various Orbits and Missions per year Earth    LEO  100 rad \(protons  MEO  100 krad \(protons electrons  GEO  1 krad \(electrons  Transfer Orbit  10 krad \(protons electrons Mars     Surface  2 krad \(electrons  Orbit  5 krad \(protons  Transit  5 krad \(protons Jovian     Transfer  100 Mrad \(protons electrons A CKNOWLEDGEMENT  The research described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration.   The Author thanks the many who guided the concept and offered support all along the way.   With special thanks to fellow-JPL\222ers Gary Noreen who provided funding\nd Taher Daud who provided editing ad-hoc extraordinaire  R EFERENCES    G M o o r e C r a m m i ng m o re C o m pone nt s o n t o  Integrated Circuits Electronics vol. 38, no. 8, April 1965 2 G M o ore, "No Expo n e n tial is Forev er: B u t 223Forever\224 Can Be Delayed Digest of Technical Papers, International Solid State Circuits Conference pp. 1.1-1 thru 1.1-19, 2003  S eagate Tec hnology Com p any. Seagate Tec hnical Corporation. [Onlin http://www.seagate.com/docs/pdf/marrketing/Article _Perpendicular_Recording.pdf   B l u R ay Di sc Ass o ci at i on  2 00 5 M a rc h B l u-R a y  Disc Technical Papers  J Vel e v K  D B e l a shche n ko  an d et _al   2 0 0 7  October\ MSREC - University of Nebraska Onlin http://www.mrsec.unl.edu/research/nuggets/nugget_2 6.shtml  6 R Katti, "Honeywell Rad i atio n Hard en ed  No nVolatile Memory \(MRAM\ Product Development in Proceedings, IEEE No n-Volatile Memory Technology Symposium Orlando, 2004, pp. L2:1-15 7 S aif u n  Sem ico n d u c tor  2 008 NV M Techno log y  Over http://www.saifun.com/content.asp?id=113  


 17    J. Ta usc h  S. T y son a n d T T a i r ba nks  Multigenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in NSREC Radiation Effects Workshop Honolulu, 2007, pp. 189-193 9  Semico n du c to r In du str y A s sociatio n SIA  2 008   August\ Home. [Online  www.itrs.net  1  S. Ty s o n P ri v a t e C o m m uni que Tra n sEl  Semiconductor, Albuquerque, NM, 2008 1  T. M i k o l a ji c k  and C U Pi n n o w  2 00 8 N o vem b er Indo-German Winter Academy, 2008, Course 3 Onlin http://www.leb.eei.unierlangen.de/winterakadem ie/2008/courses/course3_ material/futureMemory/Mikolajick_TheFutureofNV M.pdf   BAE System s North Am erica, [Data Sheet Microcircuit, CMOS, 3.3V, NVRAM 8406746, April 28, 2008, Rev A 1  N Ha dda d a n d T Scot t  A da pt i n g C o m m erci al  Electronics to the Natura lly Occurring Radiation Environment," in IEEE Nuclear and Space Radiation Effects Conference Short Course Tucson, 1994, pp iv-14 1  D. R  R o t h a n d et _al S EU a n d TI D Test i n g of t h e Samsung 128 Mbit and the Toshiba 256 Mbit flash memory," in Radiation Effects Data Workshop  Reno, 2000 1  F. I r o m and D N guy e n  S i n gl e E v ent  Ef fe ct  Characterization of High Density Commercial NAND and NOR Nonvolatile Flash Memories Honolulu, 2007 1  C Ha fer M  L a hey a n d et _al R adi a t i o n H a rd ness  Characterization of a 130nm Technology," in Proceedings IEEE Nuclea r and Space Radiation Effects Conference Honolulu, 2007 17  T. R O l dh am J. Fr iend lich  an d et_ a l, "TID  an d SEE Response of an Advanced Samsung 4Gb NAND Flash Memory," , Honolulu, 2007  R. C. Lac o e C MOS Scaling, Desi gn Princi ples a n d Hardening-by-Design Methodologies," in Nuclear and Space Radiation Effects Conference Short Course Notebook Monterey, 1993, pp. II-1 thru II142 1 J. Pat t e rs o n a n d S  Gue rt i n   E m e rgi ng S E F I M o des and SEE Testing for Highly-Scaled NAND FLASH Devices," in Proceedings 2005 Non-Volatile Memory Technology Symposium vol. CD-ROM, Dallas, TX 2005, pp. G-3, Session G ; Paper 3 2 J. Ta usc h  S. T y son a n d T F a i rba nks  Mulitgenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in Honolulu Radaition Effects Data Workshop, NSREC, 2007, pp. 189-193 2 M Janai  B Ei t a n A Sha p pi r I B l o o m and G  Cohen, "Data Retention Reliability Model of NROM Nonvolatile Memory Products IEEE Transactions on Device and Materials Reliability vol. 4, no. 3, pp 404-415, September 2004 2 D N g uy en a n d F I r o m Tot al Io ni zi n g  Do se \(T ID  Tests on Non-Volatile Memories: Flash and MRAM," in 2007 IEEE Radiation Effects Workshop  vol. 0, Honolulu, 2007, pp. 194-198  G. Noree n  a n d et_al L ow Cost Deep Space Hybrid Optical/RF Communications Architecture," , Big Sky, Montana, 2009, Pre-print 2 T. Sasa da a n d S. I c hi kawa  A p p l i cat i o n o f  Sol i d  State Recorders to Spacecraft," in Proceedings, 54th International Astronautical Cogress Bremen, 2003 2 H Ka nek o  E rr or C o nt r o l C odi ng f o r  Semiconductor Memory Systems in the Space Radiation Environment," in Proceedings, 20th IEEE International Symposium in Defect and Fault Tolerance in VLSI Systems, DFT2005 Monterey 2005 2 T. Sasa da a n d H Ka nek o  D evel o p m e nt an d Evaluation of Test Circuit for Spotty Byte Error Control Codes," in Proceedings, 57th International 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



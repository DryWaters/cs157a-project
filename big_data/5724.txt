Abstract 
mshtern,bsimmons,msmit,mlitoiu yorku.ca 
  
Toward an Ecosystem for Precision Sharing of Segmented Big Data 
As the amount of data created and stored by organizations continues to increase attention is turning to extracting knowledge from that raw data including making some data available outside of the organization to enable crowd analytics The adoption of the MapReduce paradigm has made processing Big Data more accessible but is still limited to data that is currently available often only within an organization Finegrained control over what information is shared outside an organization is difìcult to achieve with Big Data particularly in 
Mark Shtern Bradley Simmons Michael Smit and Marin Litoiu York University Canada 
the MapReduce model We introduce a novel approach to sharing that enables ne-grained control over what data is shared Users submit analytics tasks that run on infrastructure near the actual data reducing network bottlenecks Organizations allow access to a logical version of their data created at runtime by ltering and transforming the actual data without creating storage-intensive stale copies and resellers can further segment or augment this data to provide added value to analytics tasks A loosely-coupled ecosystem driven by web services allows for discovery and sharing with a exible secure environment that limits the knowledge those running analytics need to have about the actual provider of the data We describe a proof-of-concept implementation of the various components required to realize this ecosystem and present a set of experiments to demonstrate feasibility showing 
advantageous performance versus storage trade-offs 
I I NTRODUCTION We are living through the most rapid acceleration of data generation in history 90 of the worldês data has only come into existence since 2010 1  Buried within the vast and ever-expanding store of data is valuable information This value cuts across disparate domains including the biological and life sciences 2 where cures for disease are being unravelled from the immense quantities of gathered genomic data the physical sciences where our understanding of reality is being pieced together at research centers worldwide e.g CERN and the business domain where companies like 
 
Keywords access control big data cloud hadoop MapReduce 
Google Amazon and Facebook seek to monetize every byte of user data to which they gain access The more people who have access to this data the more thoroughly it can be explored and hence the more value can be derived from it accessibility is one of ve key attributes of data described by While this is apparent to man y Internet companies e.g Yahoo has made their indices available to the public through Yahoo Boss 2  it is only beginning to permeate into the general publicês consciousness For example the City of Toronto has made much of the data it collects available online 3  In this work we focus on data accessibility and sharing 1 http://www.viawest.com/sites/default/ìles/asset/document/ViaWest 
IT Inìrmity Infographic.pdf 2 developer.yahoo.com/boss 3 http://toronto.ca/open through the creation of an ecosystem MapReduce is a typical method for e xtracting useful information from large data sets An open source implementation of MapReduce called Hadoop 4 has become the de-facto standard for Big Data processing While there have been many recent improvements in the security posture of Hadoop more work remains to be done and there is ongoing work on this topic 7 In this paper we introduce the which is realized as a marketplace for Big Data sharing on 
DaasPatcher ecosystem 
the cloud This ecosystem enables and facilitates an enhanced data-as-a-service eDaaS In an eDaaS a provider offers data and the consumer consumes this data by providing code that runs on a provided infrastructure that is local to the data This provides the consumer with seamless online access to data they would not otherwise have access to without requiring the provider to produce stale copies of data and send them over networks not yet ready for Big Data scale data transport Each provider in the DaasPatcher ecosystem may determine what data they are willing to share with various types of clients Clients are differentiated according to various attributes that they possess The data offerings are advertised within the marketplace Each deìned data offering is generated at runtime by the provider running its internal Map referred to 
as a Modifying Map on the Big Data passing the results transparently to a customerês MapReduce program This allows enforcement of the providerês access control policy without additional storage requirements but also allows the sale and distribution of 
of the data for example providing access to data from certain years certain sources or certain users without actually creating copies of the data This approach encourages client adoption and participation as it simply requires them to work within the standard MapReduce paradigm A further beneìt of this approach is that data is decoupled from the view that is provided to the client This affords the provider complete freedom with regard to how and what data is stored  presented i.e dynamic constraints can be applied on the y 
segments 
The major technical contributions of this paper are as follows we propose an approach to facilitate data sharing that build upon Hadoop that that offers beneìts in four main areas the protection of private or conìdential information the segmentation of a large data set based on various dimensions of the data the ability to abstract the format of the data shared from the underlying data representations and a novel process referred to as 
 This approach implements a form of data sharing i.e need-to-share in which the data provider is not required to have knowledge about who the data consumer 4 http://hadoop.apache.org 
chaining 
2013 IEEE Sixth International Conference on Cloud Computing 978-0-7695-5028-2/13 $26.00 © 2013 IEEE DOI 10.1109/CLOUD.2013.131 335 


will be A prototype was built and experiments were run that demonstrate the beneìts of this approach The remainder of the paper is organized as follows Section II describes our approach in more detail introducing the roles and responsibilities of each participant and the overall ecosystem Section III describes a proof-of-concept implementation and a set of feasibility experiments demonstrating our approach in action accepting MapReduce jobs to be run on a Hadoop cluster Section IV discusses extension opportunities and future work We describe the related work in Section V before concluding the paper Section VI II O VERVIEW Our approach allows to run MapReduce MR jobs on some portion of a s Big Data while affording the data provider total ne-grained control over access to each piece of data and allowing run-time transformation of the data This run-time mediation is provided by preìxing the userês MapReduce job with an additional Map step a MapMapReduce or MMR job where the provider can implement access control data segmentation and/or data transformation This can also control Map tasks at a low-level including measuring or limiting execution time The data analyst is one interested in performing analytics tasks on large-scale data in the cloud a task of signiìcant interest  perhaps for pro viding services to end users 10 A data provider may choose to delegate the actual processing to an  which stores a copy of the data on an infrastructure separate from the data providerês production environment but updates with sufìcient frequency to be considered perpetually current For example Twitter has delegated most public access of all Tweets to three certiìed providers 5  A data provider may also keep such a copy inhouse or it may be acceptable to allow outside access to a single copy of the data Weêll use the term to refer to an entity responsible for accepting and running MapReduce jobs regardless of the actual ownership of the data The data provider begins by assessing their Big Data and which portions of it are to be made available outside their organization 6  The size and scope of the portions can be determined entirely  or can be determined only at run-time based on information provided by the user These logical partitions of the physical data are called  There are three primary motivations for establishing restricted subsets of the data for access 1 Some information within the provider may be appropriate to share with most users other information may be shared only with one type of user and the remaining information may never be appropriate to share For example Twitter might be willing to provide access to analyze Tweets but only public ones and might include some user data with each Tweet but not physical email or IP addresses This decision could be made  Twitter may allow access to more information if the data analyst provides valid credentials giving them access to some private Tweets a decision that could be made at run-time 5 https://dev.twitter.com/programs/twitter-certiìed-products/products 6 Our approach can also be employed within an organization in which case this text might read available outside business units with complete access 2 Not all users need or even desire access to all available information and not all users can afford access to a complete data set The data provider can provide useful and marketable subsets of the data For example Twitter might provide a segment including only Tweets from Europe or only Tweets from a given month A provider sharing stock trade data with millisecond accuracy might provide segments per exchange or per market sector or per year This would provide access to Big Data at affordable rates to data analysts unable to afford the complete dataset or the infrastructure to store/process even a segment of the dataset These segments could be deìned  A segment could be deìned at run-time to support custom segments or to allow pay-as-you go i.e access is allowed only until prepurchased credits are consumed 3 Related to access control in some cases the provider may wish to share only a transformed version of their data  perhaps de-identiìed for privacy reasons or changed to a different data structure For example a data provider may not wish to reveal a proprietary compact binary representation of data and provide instead a JSON-encoded string Transformations are deìned  but can be applied selectively at run-time  for example searching text strings for patterns that resemble phone numbers and obscuring the numbers The provider deìnes their data sources and implements a Modifying Map for each and provides information about all available data sources including what data is provided which Interface the userês Map must implement including the format and data type of the incoming data the approximate size of the data etc through a web service API All user interaction happens through this API and never directly through Hadoop or HDFS The web service is speciìed to be the same across all providers allowing easy integration The data analyst implements the prescribed Interface and submits their compiled code to the providerês web service along with any required parameters They monitor the status of their job or retrieve the results through the same web service The user can run their own client for communicating with the web service or use a client offered through a Software-as-aService SaaS delivery model where they submit and monitor jobs through a user interface with the actual communication handled behind-the-scenes These two scenarios are shown as solid green and dashed red lines in Fig 1 The provider packages the submitted code as a JAR le with their Modifying Map and other supporting code and executes the MMR job They respond to requests for progress by querying the Hadoop JobTracker and returning a response They respond to requests for results by verifying successful job completion then streaming the results from HDFS This basic user-provider interaction is augmented with  While providers have the ability to offer unlimited segmentation and transformation of data they may prefer to focus on their core competencies using this approach only to provide access control and privacy protection to the data they are sharing Resellers may establish relationships with providers and sell access to the providerês infrastructure 
data analysts data provider Modifying Map infrastructure provider provider a priori data sources a priori a priori a priori A Resellers resellers 
Access control Segmentation Transformation  abstraction 
336 


map map\(key value out reporter 
 
Provider  Reseller Reseller User map map map 
Fig 1 Various paths along which a MapReduce job can be submitted to a provider Top envelopes depict resellers wrapping the submitted MapReduce job with an additional Modifying Map which lters data before it reaches the submitted MapReduce job accepting MR jobs from users and running them on the provider A reseller could offer additional segmentation or transformation to produce value-added data sets or smaller more affordable data sets In the Twitter example one reseller might segment Tweets by estimated household income based on geographic information another might augment Tweets with a popularity metric a third might sell subsets of the overall data set where only Tweets mentioning politics or certain products are included An data analyst could choose one of these smaller data sets to reduce costs Resellers can be chained together in theoretically unlimited series for example a fourth reseller might sell segmented access to the rst resellerês Tweet+Income data set by income tax bracket Fig 1 shows four paths involving one or two resellers in the dotted blue and long-dashed orange lines To achieve this second and third and th layer of runtime data mediation resellers add their own Modifying Maps between the providerês Modifying Map and the userês Map Because the data provider is the sole arbiter of which data is passed to the reseller and the reseller then decides which data is sent to the user each participant retains the control they need Fig 2 shows a sequence diagram illustrating the sequence of calls if any provider or reseller determines the consumer of their service should not have access to a given data record the Map code is never invoked Each invocation may transform the data from the original key-value pair provided to the providerês map method A reseller offers the same API as all the providers allowing users to move among resellers and providers freely Incoming compiled Map code is augmented with the resellerês Modifying Map then passed to the next reseller in the chain or the provider via their API Requests for status updates or results are similarly passed on and the result returned to the requester A reseller adds value as an intermediary by further segmenting or augmenting data from the provider In some cases the reseller may host their own infrastructure acquire data from multiple providers and run MR jobs directly on their infrastructure where this data is aggregated ltered or otherwise combined and transformed For example a reseller might offer a data set of users and social trust scores with data from multiple providers collected Fig 2 Within the running MapReduce job starting from the provider each participantês map task checks to see if the next participant has access to a given data record before invoking the next method into a local Hadoop instance that accepts MR jobs from users In this case they appear to the data analyst as the provider and function as a provider when receiving jobs for their own data sources When they run jobs to acquire copies of the data from providers they behave like data analysts They may also function as a normal reseller accepting MR jobs for submission to the provider Managing these multiple roles is the responsibility of the reseller throughout this text when we refer to providers we include Enhanced Resellers when in their provider role and likewise for reseller and user roles Considering only the two previous sections our approach allows for users having established relationships to a reseller and/or a provider to submit MR jobs to a provider optionally via a reseller This is sufìcient for public data where the provider only supplies information that they are willing to made public In this section we describe an approach to Attribute-based Access Control ABAC which when combined with the features of the web service offered by each provider/reseller facilitates a larger ecosystem for sharing public semi-private and private data sets with veriìed users In the DaaSpatcher Ecosystem users can discover available 
Map Reduce     Modifying Map      Modifying Map  Modifying Map 
   
n 
Application  Infrastructure Provider Data Provider  SaaS Application  Reseller     Reseller   
Enhanced Resellers B The DaaSPatcher Ecosystem 
337 


data sources and submit jobs to them easily and providers can authorize users to run MR jobs without knowing all of the details about the user or having an established relationship In our approach to ABAC a user registers with a central service for convenience we call this the a distributed reliable service They can add attributes to their account by simply adding them user-signed attributes or by requesting that a third-party recognized by the marketplace provide validated attributes Potential authorities include Facebook Twitter or Google accounts through OpenID Verisign or PKI trust establishment regimes companies that hold records on individuals like Equifax or other organizations Each authority can assign the user an attribute in the authorityês namespace and sign it with their key They can optionally include metadata with each attribute specifying their level of conìdence in the accuracy of the provided attribute When a provider publishes information about a data source to the marketplace they include two sets of attributes The rst attribute set is used to specify what attributes must be submitted in order for the provider to verify access to a particular data source The provider would determine this set based on their level of trust for each authorityês attributes for example some might nd the presence of a Facebook account sufìcient proof that the user is over the age of thirteen while others would require additional evidence The user  or the reseller on their behalf  includes these required attributes in their request and the provider compares the value of the attributes to their requirements This requires established trust agreements among the resellers and involved providers a small-scale solution would be off-line informal trust agreements at a larger scale a framework for establishing or negotiating trust can be employed e.g A pro vider may register as an authority and require attributes only they can assign which would allow them to control the mechanisms for authorizing users more completely The second attribute set is used to specify what attributes a user must have in order to view metadata about a particular data source The marketplace is responsible for enforcing this limit Users are informed of the attributes required and the resellers involved in the chain for any data source to which they wish to submit MapReduce jobs They have the opportunity to acquire the additional attributes from authorities if required or to choose an alternative data source They will not see the providerês rules simply having the required attributes is not sufìcient to run a MR job For example one attribute might be age as veriìed by a credit card company a user sends this signed attribute to the provider and the provider checks the value against its rules to assess whether the user is authorized to run the submitted MR job on its data source For convenience the marketplace maintains a list of available attributes from all registered authorities Providers can specify a given attribute e.g age from a speciìc authority or from any authority verifying that attribute The marketplace also maintains quality/satisfaction ratings of each provider and reseller which users can use to identify which resellers and providers they might be willing to send their attributes through It may hide certain data sources from users based on its own rules e.g depending on what package the user purchased or on constraints expressed by the provider The marketplace may provide a web interface with which data analysts interact with data providers and authorities it may also build on existing work in the services community regarding automated service discovery III I MPLEMENTATION E XPERIMENTS We authored a proof-of-concept implementation implementing key elements of our approach particularly the ability for a provider to run user code in Hadoop while asserting control on what the user had access to The implementation details of this service-oriented system are available in We conducted a series of experiments to assess the behavior and performance of our implementation to demonstrate the feasibility of our approach Each deìned data source must have an associated Modifying Map that is responsible for both ltering and transforming the data it receives The design pattern for this Modifying Map is based on the Delegation pattern and is central to our approach Recall that Hadoop reads the input data and calls the method of the MapReduce job with data records The method of a ModifyingMap a invokes a method that decides if this data source will provide access to that data element or not and if so executes any transformations on the data and b delegates the processing of any data that comes through the lter to the useror resellersubmitted Map class To achieve the delegation the submitted classes which are in a known location see below are loaded via Java Reîection and their method is invoked This process repeats with the method of all ModifyingMaps being called in order until either a any Modifying Map decides to not provide access to the given data element or b the data analystês method is reached and the actual analytics task is performed A reference implementation of a Modifying Map pattern is supplied to resellers and providers We implemented the Modifying Maps required to produce three data sources A a provider B a reseller and C a second reseller The A Modifying Map lters out all words from the input text except those beginning with the letter a The B Modifying Map modiìes A passing on only words beginning with the letters ab The C Modifying Map also modiìes A but permits words beginning with either ac or c They should not have access to any data values beginning with c this is an attempt to gain illicit access to information We implemented RESTful web services for providers and resellers and a RESTful web service client in the form of a web application offered as a service to users The provider web service receives submitted JAR les and places the submitted code in a predeìned location in its own JAR le Constraining requesters to use a speciìed package name as the base for all of their code prevents users from supplanting the providerês code or standard libraries It then uses the Hadoop client to submit jobs to a remote Hadoop cluster It is backed by a standard relational database which maintains metadata about the data source the ModifyingMap and Filter with all supporting code what user attributes are required the location of the source data set in HDFS and the submitted jobs unique IDs the identity of the submitter the HDFS location of the results the Hadoop job ID Status requests return one of rejected 
marketplace authority A Implementation 
map map filter map map map 
338 


pending executing or completed Also supported is a tracker request which returns a modiìed version of the HTML page produced by the JobTracker for the named Hadoop job To answer requests for results the service reads from the remote HDFS drive and streams them to the user a small buffer is used to avoid loading the entire result le into memory The reseller web service also adds the submitted binary code to its own JAR le corresponding to the given job ID then consults a backing relational database to nd out to which provider or reseller this data source corresponds It invokes the API of the next participant in the chain Requests for status trackers or results are handled by similar lookups the request of the response from the next participant the receipt of that response and the return to the original requester Though this introduces overhead at each level of redirection such requests are infrequent and do not impact the MR job The marketplace is a software-as-a-service RESTful client that offers a web interface Users register and provide the attributes of email address veriìed via a conìrmation email and resident country self-validated The marketplace associates permission to access various data sources with groups i.e the subscription package and users are assigned to groups based on their attributes with administrator intervention Users see a list of data sources to which they have access and may submit jobs track job status view job trackers and download job results The focus of the implementation was to fully explore data segmentation data transformation and chaining some elements of our approach to ABAC such as providerside veriìcation of user attributes and the distributed authority infrastructure are not yet implemented To represent the data analyst we created a basic WordCount MR job based on standard Hadoop examples that can be packaged in a jar le and submitted to a reseller or provider In the rst experiment we submitted the Wordcount MapReduce job through the reseller and provider APIs and examined the results returned by the API Though we tested various combinations of particular interest is the reseller C that attempted to access data outside of what the provider was offering A We expected that the results produced by the reseller C will still be a strict subset of the provider A In the second experiment we examined performance After running the Wordcount MapReduce job on the provider directly we submitted the same map-reduce job via the reseller and provider APIs that are providing access to data ltered by Modifying Maps A B and C We repeated each MapReduce job 5 times then compared the average processing time for each type of MapReduce job We used the JobTracker web user interface to track job progress on the Hadoop cluster and record processing time We hypothesized that performance would not degrade some ltering overhead is to be expected and the entire data le must be read for all scenarios but the reduce phase should proceed more quickly In the third experiment we examined the separation of the participating entities Fictional users Alice Bob and Charlie each submitted a MapReduce task to respectively the providerês API A and two reseller APIs B and C We monitored the jobs from the standpoint of all three users the reseller and provider in particular what information about the running jobs was available to each party We expected each user would see only their jobs and would not be able to infer meaningful information from the results provided We used Cloudera Manager free edition to install Hadoop on nine Amazon EC2 instances 7 running Ubuntu 12.04.1 LTS The version of Hadoop installed is Clouderaês build CDH 4.1.3 with the   and services conìgured with all default Cloudera settings Cloudera Manager chose one node to be the NameNode JobTracker and Zookeeper server all nodes including the master participated as both data nodes and task nodes One slot was conìgured per core and therefore per node The resulting HDFS virtual drive was 3.37 TB with a NameNode max heap size of approximately 200 MB Cloudera Manager by default selects the FairScheduler which allows multiple jobs to run simultaneously rather than the FIFO scheduler that is the Hadoop default We used a dataset consisting of Apache Software Foundation email archives from the last decade After remo ving much of the non-text data and aggregating the per-month les into larger les the dataset was 42 GB in 105 les This sizing was chosen to demonstrate our approach on a relatively large dataset while still allowing for multiple iterations of all experiments within a reasonable time the ability of Hadoop to process many terabytes of data is not in question in these experiments The total data processed across all experiments exceeded 1 TB Our user reseller and provider API implementations were deployed to web servers the user code to Rackspace 512 MB 8  and the reseller and provider to Amazon EC2 t1.micro 9  The provider web server was connected to the Hadoop cluster and authorized to read a speciìc HDFS directory and launch MapReduce jobs In all of the experiments 385 map tasks and a single reduce task were created All of the map tasks ran on node-local data After performing the  we both manually and programmatically examined the results to verify only the data available to each data source was present in the results le There were no words in the results that should not have been in the input data In particular although Reseller C strove to provide words beginning with ac and c it returned exclusively words beginning with ac as it only had access 7 An m1.medium instance is approximately 80 of a Intel\(R Xeon\(R E5507  2.27GHz processor 3.7GB of RAM with 400 GB of instance storage and an on-demand price of 0.130 per hour for Linux instances in the US East region 8 The rst generation 512 MB instance is named after the amount of RAM available Each is guaranteed 3.1 of each of four virtual CPUs backed by quad-core AMD Opteron 2GHz processors and can burst up to 100 of each core when capacity is available They are provisioned for 40Mbps network connections and with 20 GB of storage 9 A t1.micro instance offers short periodic bursts up to a single core Xeon processor no sustained CPU usage and 613 MB RAM 
B Experiment Design C Experiment Environment D Results rst experiment 
m1.medium hdfs mapreduce zookeeper 
339 


004 002 
002\003\004\005\006 
002\003\004\005 003\006\007\005 003\010\006\005 010\011\010\010\005 006\005 012\006\006\005 011\006\006\006\005 011\012\006\006\005 010\006\006\006\005 010\012\006\006\005 
Fig 5 CPU utilization of the Hadoop cluster and the reseller during the multi-job scenario a subset However this would increase storage overhead a signiìcant concern with Big Data would have the potential for a rapidly growing number of copies and would introduce consistency/staleness problems keeping all copies up to date Additionally this would effectively require resellers to maintain their own copies of the data sources they offer which would reduce the reward a reseller receives for participating in the system by adding value With regards to the second experiment we note the significant improvement in time to completion i.e approximately one third the time to completion of the Hadoop jobs using the DaaSPatcher ecosystem We infer that this speedup is related to the fact that the Modifying Map is acting as a lter and hence is reducing the total amount of processing required for the various jobs offsetting any incidental overhead This implies that Modifying Maps may also be used to help a provider improve the throughput of their Hadoop cluster For the third experiment the primary statistic available to each participant was the progress of the map and reduce tasks this statistic is visualized in Fig 4 as measured at a point in time 22 minutes into the experiment but through the 
Fig 3 The average time across ve runs to complete a MapReduce job comparing a normal MR job to using Modifying Maps to data that had already passed the providerês Modifying Map A which removed all words other than those starting with a The average processing times and standard deviations from the multiple runs conducted in the are shown in Fig 3 The ltered/transformed MapReduces surpassed our expectations for performance consistently completing in approximately one-third the time of the unìltered MapReduce 11-13 minutes versus over 35 minutes We expected the reading of the information from HDFS to be a larger factor in overall processing time Transferring the results to the end user was not included in the time calculations though we do note that transmitting the result of the MapReduce would be substantially faster than transmitting the complete data set the jobs sent produced results that ranged in size from 4 MB B to 200 MB A compared to 42,000 MB for the raw data Similarly a post-processing approach modifying the results of the reduce would still be left with substantial processing the unìltered MapReduce produced a 5,000 MB results le In the  we assessed the separation of the various roles in our implementation Fig 4 shows a visualization of what each participant viewed each user was aware only of their job and the site to which they submitted it the reseller was aware only of the two jobs submitted to them and the provider was aware of all three jobs but did not know about the original submitter We examined the CPU usage of the resellerês web host and the providerês Hadoop cluster during this experiment Fig 5 We veriìed that other than some low CPU usage at the beginning of the job as it was launched and the users checked the job status more frequently the reseller machine was idle while the Hadoop cluster averaged 100 CPU utilization for over 30 minutes This demonstrates that these jobs were effectively transferred to the data provider as designed Another possible approach to segmented data sharing would be to create multiple copies of the data in the segments or with the transformations required and provide access directly to these subsets This would remove the need to reread the entire data set for an MR job that will process only 
002 003 003 003 003 003 002 003 003 003 
007 002\003 
002\003 004\003 005\003 006\007\003\010\011\012\013\014\015\003 016\014\017\007\020\021\022\003 
002 003\004\005\006\007\010\011 
002\003\004\005 006 
003 003\004\005\006\007\010\004\011\012 003 013 023 014 003 
002 003 002 003 
002\003 004\005 
006\013\005 010\006\013\005 007\006\013\005 006\013\005 006\013\005 011\006\006\013\005 006\013\005 010\006\013\005 007\006\013\005 006\013\005 006\013\005 011\006\006\013\005 
014\005 015\014\005 016\014\005 017\014\005 020\014\005 021\014\014\005 021\022\023\021\014\005 021\022\023\015\014\005 021\022\023\024\014\005 021\022\023\016\014\005 021\022\023\025\014\005 015\014\023\014\014\005 015\014\023\021\014\005 026 002\003\003\002 027\005 004\005 026\030\005 004\006\007\005\005\010 005 031 003 032\026\030 002 027\005\033\034 011 005 
a The providerês view b The resellerês view c Aliceês view d Bobês view e Charlieês view Fig 4 The jobs visible to each participant in the data sharing environment when multiple jobs are running shown is the map/reduce progress for each job after approximately 30 minutes 
002\003\004\005 006\005\007\005\002\002\005\010 006\005\007\005\002\002\005\010 011\012 
second experiment third experiment E Discussion 
340 


tracker feature they could also access the counters provided by Hadoop By measuring the number of simultaneous map tasks executing the user could infer the relative load on the server  but only if they knew the exact size and conìguration of the cluster which by design of this ecosystem would typically not be the case However by assessing the number of map tasks that ran data-local and comparing that to the number of tasks executing simultaneously information could be gleaned about the capacity of the cluster This information is no longer included in the tracker It is worth noting that the Hadoop cluster used Amazon spot instances which allows users to bid on unused capacity and pay only the prevailing market price We paid 013/hr for each instance or a total cost of 1.17 for the 10 hours of processing time required while these experiments ran Had this been run using on-demand instance it would have resulted in a cost an order of magnitude higher e.g 11.70 IV O BSERVATIONS AND T HOUGHTS G OING F ORWARD This represents a known challenge when dealing with ABAC While there has been work done that addresses this issue 16 in our approach we require attributes be speciìed under authority namespaces in order to prevent attribute collisions This refers to the development environment of the client to be utilized during the development phase of their MapReduce program There are two possible approaches to building this environment 1 A small i.e 1 GB dataset could be supplied to the clients local system for them to work on A problem with this approach is that once data is released it can not be recovered A second problem is that the developer must have a working version of Hadoop deployed 2 The provider  reseller could provide a working development environment to the client that includes an installed Hadoop/data as a virtual machine image which they could run as an instance and upon which they could practice A problem with this approach is designing a bundle that can be used only for a limited period of time This represents a possible avenue of future work A potential security concern exists in the running of untrusted client code on a providerês system Future work will explore the potential for running the submitted code in a sandboxed environment prior to executing on the live system Additionally Hadoop 2x 10 has introduced several security that will also help to mitigate this concern While the current work did not focus on the veriìcation of Modifying Maps this is a crucial aspect with regards to the integrity of the DaaSPatcher ecosystem In the current model the provider/reseller is completely responsible to verify the correctness of their Modifying Maps We intend to explore applying model driven techniques to ensure the correctness of these maps as a part of our future work Installing deploying and conìguring a Hadoop cluster ranges from very complicated to reasonably 10 http://hadoop.apache.org/docs/current easy One of the main aspects that determines this level of complexity is the personês prior experience working with such a system By removing the need to perform all administrative tasks and by virtue of the simpliìed interface i.e a high-level GUI rather than complex CLI commands the studentês focus can remain solely on the logic of the MapReduce program they are constructing allowing them to develop their skills and understanding immediately Further because we can deploy different Modifying Maps to each student there is no worry about cheating on assignment material etc A key driver of the DaaSPatcher ecosystem design is the fact that it is built on the cloud The ability of applications to scale dynamically in accordance with their elasticity policyês i.e in response to changing demands/workloads is critical when designing infrastructure for unpredictable numbers of users with undeìned requirements To enable an organization to extend a Hadoop cluster to the public cloud we could use a Modifying Map to selectively copy data to the public Hadoop cluster Other Modifying Maps can be annotated and partitioned as in mo ving those that can run in the public cloud to the new public Hadoop cluster V R ELATED W ORK The Clark-Wilson integrity model deìnes a set of nine i.e ve certiìcation C1-C5 and four enforcement E1-E4 rules that ensure the integrity of data Four main elements are deìned a Constrained Data Item CDI an Unconstrained Data Item UDI Integrity Veriìcation Procedure IVP and Transformation Procedure TP upon which these rules are speciìed Our framework borrows conceptually in many ways from this model  For example we follow C5 during data entry and publishing phases Speciìcally when data is rst uploaded to a providers HDFS can be considered as a UDI The procedure that facilitates its upload can be seen as a TP and the nal data store is seen as a certiìed CDI Alternatively in the case of a reseller publishing a data source from provider this is also the case in that prior to publication the data is seen as a UDI Then upon veriìcation of its signature via a TP it is certiìed as a CDI Other examples follow a similar pattern Previous work has observ ed the ef fecti v eness of using ABAC on the Internet The ABAC approach to access control focuses on the attributes of both subjects and objects and uses these to deìne who may act on what avoiding the need for explicit knowledge of the various entities Our speciìed ecosystem takes advantage of ABAC allowing for dynamic Modifying Map selection Singhal et al present a frame w ork that addresses issues of security implicit when collaborating and sharing resources across a multi-cloud We considered similar issues in the design of the DaaSpatcher ecosystem notably mechanisms for maintaining attribute privacy and for security delegation Airavat is a system that assures high de grees of security and privacy for MapReduce problems through its use of mandatory access control i.e SELinux and differential privacy While we nd this work inventive and we share the same main objective i.e privacy/sharing of data our approach differs in several key ways First we do not require 
Attribute Management Client Development Environment Veriìcation of Client Maps Veriìcation of Modifying Map Educational Tool Elasticity Hybrid clouds 
341 


labelling of data Second while we limit the possible map functions supplied to any particular individual we do not prevent a user from utilizing any mapper or reducer which they compose Third our approach in no way modiìes any component of the Hadoop MapReduce framework lesystem or the Java virtual machine Finally we support the standard MapReduce programming model Adopters of Hadoop in industry recognize the need to improve the security capabilities of Hadoop e.g A spectrum of solutions and approaches are currently being explored One interesting approach in v olv es the inclusion of hooks  callbacks at points in MapReduce to facilitate various types of ne and coarse grained control With interest in Big Data rapidly expanding it is crucial that comprehensive security solutions be introduced to address things like complex and distributed node management open communication channels etc The AERIE architecture 26 of fers a highly scalable secure and comprehensive adaptive multi-cloud application management framework within which a Big Data stack can be run with little or no modiìcation in a secure fashion VI C ONCLUSION In this paper we introduce the DaaSpatcher ecosystem a methodology for secure segmented Big Data sharing on the cloud Modifying Maps are the kernel of our solution and allow the provider to enforce their data access policy and assure data privacy unencumbered by direct knowledge of their clients while also seamlessly splitting Big Data into shareable saleable segments Resellers are added to augment the model and facilitate complex chains of propagated rights without compromising the integrity of the providerês data sharing policy An implementation of the main components of this marketplace was developed and results of experiments presented to demonstrate the beneìts and functionality of this novel approach to Big Data sharing on the cloud A CKNOWLEDGMENT This research was supported by IBM Centres for Advanced Studies CAS the Natural Sciences and Engineering Council of Canada NSERC under the Smart Applications on Virtual Infrastructure SAVI Research Network and the Ontario Research Fund under the Connected Vehicles and Smart Transportation partnership R EFERENCES  S V ijayakumar  A Bhar ga vi U Praseeda and S Ahamed Optimizing sequence alignment in cloud using hadoop and mpp database in 
 june 2012 pp 819Ö827  E W altz 1000 genomes on amazon s cloud   vol 30 no 5 pp 376Ö376 2012  S T oor  R T oebbick e M Resines and S Holmgren In v estigating an open source cloud storage infrastructure for CERN-speciìc data analysis in  2012 pp 84Ö88  A Barua D Mani and R Mukherjee Measuring the b usiness impacts of effective data Chapter one of a three-part study The University of Texas at Austin Sponsored by Sybase Tech Rep 2010  J Dean and S Ghema w at MapReduce simpliìed data processing on large clusters  vol 51 no 1 pp 107Ö113 2008  O OêMalle y  K Zhang S Radia R Marti and C Harrell Hadoop security design Yahoo Inc Tech Rep 2009  I Ro y  S T  Setty  A Kilzer  V  Shmatik o v  and E W itchel  Aira v at Security and privacy for MapReduce in  USENIX Association 2010 pp 20Ö20  A Cuzzocrea I.-Y  Song and K C Da vis  Analytics o v er lar ge-scale multidimensional data the big data revolution in  ser DOLAP 11 New York NY USA ACM 2011 pp 101Ö104  I K onstantinou E Angelou D Tsoumak os and N K oziris Distributed indexing of web scale datasets for the cloud in  ser MDAC 10 New York NY USA ACM 2010 pp 1Ö6  H V ashishtha M Smit and E Stroulia Migrating a le g ac y web-based document-analysis application to Hadoop and HBase An experience report in  IGI Global 2012 pp 226Ö247  T  Priebe W  Dobmeier  and N Kamprath Supporting attrib ute-based access control with ontologies in  IEEE 2006 pp 465Ö472  C H Y e w and H Lutìyya  A middle w are-based approach to supporting trust-based service selection in  2011 pp 407Ö414  M Rambold H Kasinger  F  Lautenbacher  and B Bauer  T o w ards autonomic service discovery in  IEEE Computer Society 2009 pp 192Ö201  M Smit B Simmons M Shtern and M Litoiu Enabling an enhanced data-as-a-service ecosystem in  2013 To Appear  G Ingersoll Apache Softw are F oundation public mail archi v es  A v ailable via http://aws.amazon.com/datasets/7791434387204566 original source http://mail-archives.apache.org/mod mbox August 2011  A H Karp H Haury  and M H Da vis From AB A C to ZB A C The evolution of access control models HP Laboratories Tech Rep HPL2009-30 2009  S Sendall and W  K ozaczynski Model transformation the heart and soul of model-driven software development  vol 20 no 5 pp 42  45 2003  H Ghanbari B Simmons M Litoiu and G Iszlai Exploring alternative approaches to implement an elasticity policy in  2011 pp 716Ö723  M Smit M Shtern B Simmons and M Litoiu P artitioning applications for hybrid and federated clouds in  2012 pp 27Ö41  D D Clark and D W ilson  A comparison of commercial and military computer security policies in  April 1987  M Singhal S Chandrasekhar  T  Ge R Sandhu R Krishnan G.-J Ahn and E Bertino Collaboration in multicloud computing environments Framework and security issues  vol 46 no 2 pp 76Ö84 2013  S Saklikar  Embedding security and trust primiti v es within map reduce http://www.emc-china.com/rsaconference/2012/en/download php?pdf le=TC-2003 EN.pdf 2012  A McAfee and E Brynjolfsson Big data The management re v olution  vol 90 no 10 pp 60Ö128 2012  Securosis Securing big data Security recommendations for Hadoop and NoSQL environments Tech Rep 2012 last accessed February 19 2013 at https://securosis.com/assets/library/reports/SecuringBigData FINAL.pdf  M Shtern B Simmons M Smit and M Litoiu  An architecture for overlaying private clouds on public providers in  2012 pp 371Ö377   Na vigating the cloud with a MAP  in To Appear 2013 
Cloud Computing CLOUD 2012 IEEE 5th International Conference on Nat Biotech Networking Architecture and Storage NAS 2012 IEEE 7th International Conference on Commun ACM Proceedings of the 7th USENIX conference on Networked systems design and implementation Proceedings of the ACM 14th international workshop on Data Warehousing and OLAP Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud Migrating Legacy Applications Challenges in Service Oriented Architecture and Cloud Computing Environments The First International Conference on Availability Reliability and Security Integrated Network Management IM 2011 IFIP/IEEE International Symposium on Services Computing IEEE International Conference on IEEE Congress on Services Cloud Cup Software IEEE Cloud Computing CLOUD 2011 IEEE International Conference on CASCON 12 Proceedings of the 2012 conference of the Center for Advanced Studies on collaborative research Proceedings of the 1987 Symposium on Security and Privacy Computer Harvard business review 8th International Conference on Network and Service Management CNSM 2012 Las Vegas USA 13th IFIP/IEEE International Symposium on Integrated Network Management IM 
342 


  enabled, the Flight System is returned to i d begin downlinking  accumulated engin e camera frames from the file system via t Once all products are downlinked and a fin a made, the 28V power is removed from the the Flight System activities. Figure 8 sho w in-the-life timeline which includes so m assumptions about the durations required t o tasks  4  ISS  I NTERFACE  The ISS interface is multifaceted and i n connections, software, and communicati o teams at the various NASA centers. I f interfaces are considered, a number of a s significant influences on a project, directl y throughout its lifecycle may be missed G interface can be thought of as having thre interaction: programmatic, technical, a n remaining of this section provides a disc u them Programmatic Interface For over 11 years, the International Space ISSP\ has continuously maintained a hu m low Earth orbit with constant operation a around the globe.  After 14 years of co visiting vehicles and integration of 390 me t qualified equipment, the ISS is the larg e created in space. Supporting such a m a requires a daunting number of engineers, to thousands In 2011 STS-134 delivered the A Spectrometer to the ISS marking the en d States\222 p rimary assembly phase of the ISS completion the ISSP has undergone a sw e from an assembly centric organization to a one. Supporting this new focus, the ISS P amongst 15 primary offices representing t h expertise. OPALS\222 primary five offices o shown Figure 9 The Research and Integration Office \(OZ h responsibilities for managing and interfaci n like OPALS.  Systems engineers with b r Figure 8: Day-in-thelife activities a r 9 d le state and can e ering logs and t he ISS RF link a l health check is payload, ending w s a typical daym e conservative o perform various n cludes physical o n with all the f only technical s pects that exert y and indirectly G enerally the ISS e e major areas of n d safety. The u ssion of each of Station Program m an presence in al support from nstruction, 140 t ric tons of space e st outpost ever assive operation o taling well in the A lpha Magnetic d of the United Following this e eping transition a payload centric P is now divided h e breadth of ISS o f interactio n are h olds the primary n g with payloads r oad experiences reside within this office to expertl y the rest of the program. On an as-n e and Integration Office has aided d with over 300 individuals across 30 Despite well planned standardizati o human interface between payload is necessary to facilitate the excha n hundreds of engineers and t h specifications Technical Interface The Station\222s massive supporting o support its technical complexit y complexity can amount to 694 across 11 disciplines.  These disci p electrical, command and da t environmental, materials, marking astronaut and software interfaces To both standardize and simplify a connections are provided by a Flig h Mechanism \(FRAM\lighted come in many sizes and varieties cargo or instrument they support Express Pallet Adapter \(ExPA The physical interface occurs i n translation, and operation. The fi OPALS integrated into the trunk o stack ascending to orbit.  The lau n r e scheduled and performed relative to the beginning o Figure 9: Simplified org chart o JSC offices that OPALS has int e points in its lif e y direct payloads through e eded basis, the Research d irect OPALS interaction supporting teams o n and documentation, a d evelopers and the ISSP n ge of information across h ousands of pages of o rganizatio n is scaled to y For payloads, this interface requirements p lines include structural t a handling, thermal maintainability, robotic a ll physical interfaces and h t Releasable Attachment in Figure 10. FRAMs to suit the need of the OPALS has chosen an n three phases: launch rst of these phases has f a Falcon 9 and Dragon n ch on which OPALS is  o f a Demonstration  o f the primary ISS and e racted with at various e cycle 


  manifested will mark the third SpaceX flig h Commercial Resupply \(CRS\tract and m first SpaceX CRS flight extensively red e external cargo.  These modifications inclu d updated Falcon 9 \(v1.1\nd a Drago n providing a suite of launch characteris t vibro-acoustic environmental ones, which characterized.  Since the OPALS Syste m Review \(SRR\ early 2010, the ongoin g of these interfaces has led to a net change o ISS requirements and essentially 100% c h Dragon requirements, including updates deletions Following a successful berth with the IS S phase to OPALS\222 operational destina t Utilizing the capable Mobile Servicing S y the Mobile Berthing System, Special P u Manipulator \(SPDM\d Space S Manipulator System \(SSRMS\ic operators on the ground will extract O berthed Dragon and again mate OPALS\222 F R to a powerp roviding element \(the E n Replacement Unit Temporary Platform o SPDM.  After a nearly two-day roboti c SPDM will again install OPALS onto FRAM, this time at its intended operation a nadir, port side-facing ELC 1 FRAM 8 correctly utilize these robotic componen t Figure 11: OPALS orientatio n 10 h t under NASA\222s m ore notably, the e signed to carry d e a significantly n block upgrade t ics, particularly are not yet fully m Requirements g characterization o f 37% of the 694 h ange of the 117 additions and S the translation t ion can begin y ste m 227including u rpose Dexterous S tation Robotic elements\227ISS PALS from the R AM underbelly n hanced Orbital o r EOTP\ the c translation the another Passive a l location on the Figure 11 t s, 222 interface requirements are provided, the verified by use of a certified s t performed, OPALS will be the firs t type of robotic transfer In the event of a robotic continge n astronauts to intervene and ac c transfer towards final installation o standardized FRAM handholds o n could manipulate OPALS if the n interface is made possible wit implications for OPALS, though o p as orientation and timing, do ex i contingency crew member intera c Figure 10: The FRAM provides a the LV, the robotic arm and th e  n relative to the ISS at its operational location on EL C majority of which are t andard FRAM.  When t payload to undergo this n cy, capabilities exist for c omplish the remaining o f OPALS.  By using the n the ExPA, astronauts n eed were to arise. This h out additional design p erational concerns, such i st.  To implement this c tion, up to 2 weeks of a common interface for e ISS mounting points C 1, FRAM 8 


  unallocated planning would be required Finally, in the third interface phase, the O P installed and ready to operate on its ELC w its full suite of interfaces available. They i n avionics and software interfaces, which operations to commence OPALS will be the first payload installed o Even with a standardized specification means many questions, capabilities, and i addressed for the first time in p arallel w development and in collaboration with I engineers Safety Interface JPL engineers regularly design complex sent far into space never to interact wi t launch.  As a result, the human safety c o OPALS responded to have introduced n e every aspect of the design.   This experie n only learning how to navigate the pro approval from the technical experts on th e Review Panel \(PSRP\ the design, but solve engineering problems from a safety p not compromising technical goals The formal interaction between the pay l such as the OPALS project, and the PSRP series of Flight Safety Reviews \(FSRs  reviews the project and the panel iden t hazards created b y the payload and dec controls to keep those hazards from causi n either personnel or the ISS.   A safety submitted 45 days prior to a formal FSR review and comment. The submission i s presentation and hazard report walk-thro u takes a full day or two as all safety concer n are discussed and addressed The first meeting with the PSRP was a which focused on identifying applicab verifying that the appropriate requirem e referenced.  OPALS started at a time whe Figure 12: OPALS project milestones re l 11 P ALS FS will be w here it will have n clude electrical will enable full o n this new ELC a new interface i ssues have been w ith the OPALS I SS and SpaceX systems that are t h humans after o nsiderations that e w challenges in n ce involved not cess of gaining e Payload Safety also learning to p erspective while l oad developers occurs through a   th es e t ify all potential ide on a set of n g any damage to data package is for the PSRP to s followed by a u gh, which often n s and comments Phase 0 review le hazards and e nts were being n documentation was transitioning from shuttle req u documents so the initial meeting which standards are applicable to t h initial hazard assessment with th e some potential hazards the proj e Additionally, it helped guide th e choices that later could have sno w would have been difficult to progressed toward the more formal OPALS\222 Phase 1 review was s e project\222s PDR and reflected a fair time leading up to this review the p class 4 laser that required the h classification \(catastrophic\and i controls for all possible operation a the safety review OPALS discuss e with various members of the PRS P design approaches for controls r hazards from actualizing.  These meetings were essential leading i n the design then required minimal c h 1 review. This preparation had t h developing a strong relationship b members and the OPALS team The Phase 2 review typically fol l Design Review \(CDR\OPAL S formal technical interchange meeti n to review its hazards and solid i method of controlling them. With identified and most of the contro l debate, the Phase 2 review covere d testing and the supporting doc u p articularly strong focus on veri avionics and the hazard controls computer system controls a haz a Control System \(CBCS\trix m outlines the requirements for that meets the requirements, and the demonstrate complian h e into the high-level software archite level registers and memory man a reviewed by the Computer Safety l ative to the safety milestones outlined in NSTS 13830 and Data Submittal Requirements u irements to ISS-specific focused on establishing h e OPALS payload.   The e PSRP helped identify e c t had not considered e project\222s early design w balled into hazards that change as the design Phase 1 review e veral months after the l y mature design. In the p rojec t settled on using a h ighest level of hazard i dentified a number of a l scenarios.   Going into e d these choices in depth P to identify options and r equired to prevent the earlier discussions and n to the formal review as h anges to pass the Phase h e additional benefit of b etwee n the safety panel l ows a projec t 222s Critical S however, requested a n g \(TIM\with the PSRP i fy concurrence on the the hazard sources well l s requi r ing little further d the details of hardware u mentation and had a fication of the OPALS it governs.   When a a rd, a Computer Based m ust be developed that syste m the design that verifications planned to completed matrix delves cture as well as the lowa gement. This system is Panel \(CSP\ and if the Payload Safety Review 


  12 panel chair agrees with the approach he or she recommends it for approval to the PSRP. After many tweaks and focused discussion outside of the full PSRP the OPALS CBCS matrix was approved for Phase 2 As Phase 3 approaches, all agreed-to verifications of hazard controls must be performed, documented, and submitted Any deviations from the agreed-to verifications must be documented and approved by members of the PSRP In addition to the Flight Safety Reviews \(FSRs\und Safety Review schedule is also negotiated and a package is submitted.  This process is very similar to the PSRP one, but the scope of the hazards is limited to ground operations at the launch and processing facilities The key to successfully passing the FSRs has been constant early, and open communication with the PSRP. It has allowed for the quick identification of hazards and it has prevented the project from locking itself into designs that either could have adversely impacted safety or could have made compliance significantly more difficult. The PSRP and everyone involved in the safety side of the interface have shown great flexibility in allowing OPALS design freedom to ensure its mission success while enforcing a high standard for the safety of the ISS and those inhabiting it 5  D RIVERS   C ONSTRAINTS  AND R ESULTING I MPLEMENTATION  OPALS is no exception when it comes to facing the typical challenges that most space flight projects have to overcome throughout their lifecycle. Cost and schedule always seem insufficient. The workforce is sometimes stretched thin. All these challenges create constraints, end up driving the decision-making process and inescapably shape the final product. There are, however, many aspects that set OPALS apart from the average space borne instrument, and they too came with their own drivers and constraints Overall, the drivers and constraints can be classified as internal and external, with each category further divided into process- or technically-flavored This section is dedicated to examples, spanning each of those categories, of drivers and constraints that have in one way or another influenced the implementation of the project Internal, Process-Derived Drivers and Constraints The aspects falling under this section refer to those whose common denominator is the internally-mandated JPL process. The most influential and prevailing of these processes are documented in the JPL Design Principles and JPL Flight Project Practices. These documents provide guidelines on everything from cost, schedule reserves and technical margins to the pedigree of the parts and components used by the flight article and the level of documentation required Class D 227The biggest impact on the project, second only to the stringent cost cap, was the decision to implement it as a Class D payload risk classification per NASA NPR 8705.4 This decision was less of a constraint than it was a driver and it ultimately gave the project more flexibility in making decisions. The ramifications of this decision are many including the risk posture of the project in parts selection sparing philosophy, hardware handling requirements qualification program, fault protection, and extent of formal verification of requirements Early on in its lifecycle, the project sought to define the Class D implementation approach within the guidelines set by NASA procedural requirements. Specifically the project was allowed to 200  Build one proto-flight model with limited engineering models \(EMs\he only subsystem to have a full EM is the avionics. Other EMs include the acquisition camera one motor driver, and the in-house developed power board 200  Limit parts sparing to long-lead items only. The project only purchased one spare actuator and a few of the avionics cards. There are no spares for the laser, power board, camera, or any structural components 200  Use COTS hardware wherever possible. This aspect is discussed in further detail in a subsequent section 200  Forgo radiation or parts support. The extensive usage of COTS components implies, to a large extent, the absence of radiation susceptibility data, along with other environmental information. Thus, as early as the Mission Concept Review, the project and its stakeholders have accepted the potential missionending risk of unrecoverable single event upsets 200  Limit hardware and software Quality Assurance prior to system level integration and test. Typically, HQA/SQA involvement begins early in subsystem development well in advance of system I&T 200  Limit flight tech support to final torqueing and high risk procedures. The philosophy here is similar to the HQA/SQA involvement Requirements and V&V\227 Likely the most unglamorous aspect of producing a space-wo rthy payload is developing the set of requirements that govern its function and behavior. While Class-D status does not give the project a pass on developing requirements, it can shape the way the process is conducted and the extent to which requirements are developed For example, higher-class projects typically develop requirements down to level five or six, and bin them in dozens, if not hundreds of sets or modules. By contrast OPALS currently only has 782 requirements spread over 33 modules, with none of them containing more than 105 items. Of the 694 ISS requirements only 376 are applicable to OPALS, accounting for 48% of the total OPALS set Similarly, of the 117 launch vehicle requirements, only 58 are levied on OPALS. This means that the project has only 


  348 project-specific requirements that it in t verify. Figure 13 breaks down the requirements, including ISS and launc h residing at the various levels OPALS, however, is no poster child f development as it fell into the same trap t h projects\227regardless of size and risk verification and validation \(V&V\ time: it unnecessary requirements At CDR time OPALS realized that requirements it was signing up to verify d and testing, totaling almost 1300 \(796 OP A LV\, had become unmanageable give n schedule and cost-to-go. Shortly there a embarked on a months-long, projectevaluating its requirement set with the go a down to those that it couldn\222t justify not ve r By the time the Test Readiness Review c a later, the project had achieved an overall r Table 2\n the number of items it dee m verification Once again leveraging its Class D status from JPL management, the project decided 796 requirements it had written on itself 227 the ISS and launch vehicle ones\227 p rovide d others when it came to verification D explicitly verify a requirement meant one o f 1  The statement was deemed to be, in of a requirement and more of proced u on how something was to be done less of an instruction on how well s work and more of a documentatio n Without engaging in a detailed sem a the project changed the status of thes e requirement to policy. This meant t h still had to be implemented, but it di formally verified Figure 13: Two-thirds of the 782 OPAL S reside at the level 4 FS subsystem level the ISS and launch vehicle requi r 13 t ends to formally distribution of h vehicle ones f or requirements h at cripples many posture\227come developed many the number of d uring integration A LS + 529 ISS n the remaining a fter, the team wide effort of a l of trimming it r ifying explicitly a me nine months r eduction of 37 m ed important for and with bu y in that some of the 227 which excludes d less value than D eciding not to f two things some cases, less u ral specification while in others omething had to n on the design a ntics discussion e statements from h at the statement i d not have to be 2  The statement remained a r e not be explicitly verified at t written as the state-ofp r a Instead, its verification wou l parent at a higher level was order for a requirement to be a higher level it had to meet o criteria 200  It is enveloped by a larg e at a higher level; e.g flowdown, such as mass 200  Functionality/performan c higher level test\(s\ A N requirement will be app level tests. Put another cannot be verified at a h i meet that requirement w o in higher level test, the n requirement cannot be m o This process was a very time-int e number of individuals on the te thought to have saved the project a s and money in Phase D when the m a takes place There were, however, two excepti o applied to externally-levied IS S requirements, and those requirem e safety standards to be followed It is important to point out that the 421 requirements which were e v verification via this process shoul d but rather that the mission risk o f  one the project was willing t o underperformance of the system higher level testing. In doing so h had to accept an increased cost p roblems that might have been ca u caught until later during syste m significantly more expensive to fix S requirements These include r ements Table 2: Reduction achieved bet w number of requirements needi n Set  CDR  L1  1  L2 \(all  283  L3 \(all  216  L4 GS  66  L4 FS IRDs  158  L4 FS STR  188  L4 FS FSW  167  L4 FS Other  218  OPALS TOTAL  1296  ISS Total  468  LV Total  59  e quirement, but it would t he level at which it was a ctice usually dictates d become implicit if its successfully verified. In allowed to be verified at o ne of the following two e r \221capstone\222 requirement part of an allocation pointing budgets e can be rolled into N D failure to meet the arent in higher, syste m way, if a requirement i gher level OR failure to o uld not become apparent n the verification of that o ved to a higher level e nsive one for a limited am, but it is generally s a whole significant time a jority of the V&V effort o ns to this process which S and launch vehicle e nts which specified the argument is not that the v entually descoped from d not have been written f not verifying them was o accep t because any would be identified in h owever, the project also and schedule risk that u ght earlier, would not be m I&T when they are  w een CDR and TRR in n g explicit verification TRR  Change  1  0  230  19  138  36  28  58  61  61  101  46  109  35  158  28  823  37  411  12  39  34  


  Internal, TechnicallyD erived Drivers and C Equally instrumental in shaping the outco m were those decisions that were driven b aspects over which the project had decisio n In the same way that certain policy de c subsequent ones \(see Class D\ techni c a cascading effect throughout the design, p a Flight System COTS Usage\227 The most clear and pervas i the decision to utilize COTS parts whereve of the early conceptual architecture and des i was inherited from aircraftb orne syste m operated by JPL as recently as 2011.  In a n cost and complexity, the use of COTS c considered an attract ive option for the avio n risk of latent failure and unfamiliarity w i was essentially traded against the extrem e short lead times made possible by orderin g While the FS would evolve over time t o custom JPLb uilt boards and compon e implementation has left an indelible mark o n Traditional spacecraft and instrument elect r on strong conductive coupling to a temp e interface to maintain safe operat i Ruggedization is also common practi reliability in the vibration- and r a environments of launch and low-Ear t p ractices, however, are often impractical o r with COTS avionics, where the cost o ruggedizing for flight would surely dwar f components themselves. The OP A implementation, for example, comprises a and electrical components that are desi g forced-convection cooling in a r o environment. They have relatively little or Figure 14: Cross-sectional view of fligh t container showing arrangement of c 14 C onstraints m e of the project b y the technical n making control c isions impacted c al decisions had a rticularly for the i ve example was e r possible. Much i gn of the project m s designed and n effort to reduce c omponents was nics design \226 the i th the hardware e ly low cost and g 223off-the-shelf.\224 o include several e nts, the COTS n the FS design r onics boxes rely e rature-controlled i ng conditions ce to improve a diation-intensive t h orbit. These r even impossible o f modifying or f the cost of the A LS avionics series of boards g ned to receive o o m temperature no tolerance for extreme temperature, humidity, o r thus present significant technical c thermal control The ISS in particular poses an ad d and constraints owing to the n a payloads are installed and opera t docking at the ISS, OPALS is rem o SpaceX Dragon trunk.  During thi s p oints throughout the subsequent r o attach site on ELC1, the FS must a loss of power for up to six h architecture is therefore built maintaining a \223laboratory envi operations.  The flight avionics su b critical components like the l a distribution circuitry, is conta i cylindrical enclosure that maintai n environment throughout the nomin a highlighted in Figure 14, 120mm D found in everyday desktop compu t the air across the avionics compon e heat exchanger assembly.  By rec fashion, waste heat is transferre d avionics boards and components, t h and into the heat exchanger where i external radiator.  Further, the loss from a loss of electrical power to effective means of insulating the loss during said periods \226 gas c dominant, though negligible, mod e microgravity environment p rovi d natural convection The decoupling of heat transfer structural interfaces renders stan d finite volume heat transfer c necessitates an iterative anal y CAD/CAE and computational flui d to solve for characteristics of the fl u of the OPALS avionics enclosure  envisioned a cuboid structure wit h heated air from the electronics assembly.  Early rounds of CFD a n unacceptable pressure losses in t h turning and relatively narrow cro s the duct.  Over time, the iterate d streamline the flow path, result i b etween the fans and heat exchan cable routing to eliminate as ma n main flow path as possible. This i t results in a design that is com p cheaper to analyze, as well as more build. Figure 16 shows a velocity final design The relatively severe vibration e launch vehicle posed yet another avionics \226 most of which do  t system sealed c omponents r vacuum operation, and hallenges in maintaining d itional set of challenges a ture in which external t ed.  Upon arrival and o ved robotically from the s process, and at various o botic transfer to its final a ccommodate a complete h ours. The OPALS FS around creating and r onment\224 for nominal b system, along with other a ser diode and power i ned within a sealed n s a 1-atmosphere \(STP a l life of the payload.  As D C fans, not unlike those t ers, drive circulation of e nts and through a ducted irculating the air in this d convectively from the h rough the air mass flow i t is then conducted to an of circulation that resul t s the payload provides an flight system from heat c onduction becomes the e of heat transfer, as the d es no mechanism for paths from traditional d ard finite element and c odes ineffective, and y sis process between d dynamics \(CFD u id flow.  Early concepts  Figure 15\or example h a long duct to transfer to the heat exchanger n alysis, however, showed h e flow due to repeated s s-sectional areas within d design has evolved to i ng in a single \223turn\224 g er, and optimization of n y obstr u ctions from the t erative process naturally p utationally simpler and practical to fabricate and map of fluid flow in the e nvironment within the challenge for the COTS not even ship with a 


  15 manufacturer specification for vibration tolerance.  To deal with this issue, the rigid tray assembly that houses the avionics and fans is mounted on a system of wire-rope isolators designed to dampen random vibrations within the specific frequency spectra produced by the launch vehicle These isolators protect delicate solder joints and other nonrugged components from being torn apart by launch loads Further, in much the same way as the loss of circulation during power outages provides a natural means of insulation against heat loss, the wire rope isolator system\222s poor thermal conductivity also impedes conduction to the outer structure of the sealed container External, Process-Derived Drivers and Constraints While many decisions were internally motivated by the JPL processes and the OPALS paradigm, a significant number also came via the ISS and launch vehicle interfaces, both programmatically and technically As one might anticipate, the ISS interface in particular impacted the OPALS day-to-day operations as well as the design features it implemented. The most clear example of this aspect came via the over 400 requirements imposed by the ISS program on the OPALS payload, followed by the V&V process mandated to demonstrate compliance Requirements 227As one of the first payloads to negotiate both the ISS and Dragon interfaces, OPALS has been routinely involved in technical changes beginning and ending with its interface requirements.  A considerable ongoing effort within OPALS and its partners has been to solidify the understanding of the requirements levied When OPALS began in 2009, the Dragon had neither flown nor been fully designed.  This was best represented in the miniscule 16 provided requirements that were largely placeholders for what would  become the Dragon\222s interface specification.  At that point, expectations were that OPALS would be completed well before its Dragon flight. This schedule disconnect led to a considerable technical disconnect In order to proceed with OPALS development despite the lack of a full set of design requirements assumptions had to be made in three key areas: power, connectivity, and the launch environment.  The first question of power came about for an obvious reason: OPALS has thermally sensitive optics and commercial equipment, and these components need heater power to be kept warm in space.  Without requirements on Dragon power provisions, the project\222s first assumption was that the thermal control hardware designed for the on-orbit ISS environment would also prove valid during a Dragon ascent.  After exhaustive integrated thermal analysis, this assumption, and the resulting engineering implementation, has proven to be valid, and an additional 12 pages of requirements and supporting data now reflect this interface design After requirements were negotiated and an agreement was reached to provide sufficient thermal power during ascent the question remained of how this power would be routed into the OPALS payload.  To direct the efforts towards a solution of connectivity, OPALS turned to the JAXA H-II Transfer Vehicle \(HTV\d Space Shuttle designs that powered FRAM-based payloads similar to OPALS.  These additional carrier requirements allowed several connectivity options and it was thus taken to be a valid assumption that the Dragon team could design around OPALS\222 desired cabling pin assignments.  The OPALS design was thus submitted to SpaceX and, as this was the first request for a specific option, the OPALS connectivity solution has become the primary power distribution option amongst external Dragon cargo requirements The project\222s greatest challenge, however, was the need to design the FS prior to receiving any validated launch  Figure 15: Early design of the sealed container did not optimize component pl acement or airflow  Figure 16: CFD analysis led to a new component layout that allowed for more efficient heat removal 


  16 loading requirements.  To address this, OPALS began with JPL and NASA\222s extensive historical data on expected launch loads, amended with ample margin and overlaid with standard levels on workmanship. The resulting crude spectrum was then supplied to the ISS and SpaceX dynamics teams who over the course of several months helped refine test plans to a conservative but agreeable level, which again proved to be valid \(and indeed conservative\via integrated analysis and testing. At the time of this writing OPALS had successfully completed vibration testing Lastly, the project has dealt with the uncertainty that comes via requirements variability from the ISS interface. Since OPALS began, 37% of the 694 ISS interface requirements have changed. Even though only 376 of them are applicable to OPALS, the project has had to maintain cognizance in this regard over the full set.  Despite the fact that the ISS is an operational facility and many components have been flying in orbit for several years, both OPALS and the ISSP are still learning about the function and performance of these components.  As such, there have been ample updates to the electrical and robotic interface requirement segments These requirement changes are executed methodically in a thoroughly reviewed manner.  After internal ISS coordination, pending requirement updates are quickly disseminated amongst payload developers.  After external review by existing and prospective payloads, signatures are requested and requirements are enacted V&V 227Verification and Validation includes the final work done to certify both that the payload meets the word of the requirements, and that it performs the intended function 55% of OPALS\222 requirements to be verified are provided by its external interfaces, including the ISS and Dragon Though verified along with all other project requirements these interface requirements demand a different balance of focus.  As these requirements are provided by external entities they are managed outside of JPL and subject to external verification.  OPALS, therefore, has no formal validation program for these requirements beyond ongoing interface systems engineering diligence.  While this externalized approach minimizes internal efforts, it simultaneously increases verification  overhead Verification of each external interface requirement falls under the cognizance of an external Discipline Engineer DE\d the OPALS verification program is built around this external approval process, which is diagramed in Figure 17.  These external engineers represent the external hardware expertise necessary to ultimately understand validate and approve all interactions with their hardware.  It is important to note that these engineers support a multitude of projects across geographic boundaries, and their ability to provide dedicated attention to OPALS is attenuated by the breath of the projects they support Internal to OPALS, an abundance of verification data is generated for these DEs in the verification of the 452 external requirements.  The planning, technical coordination, and direction of this work is coordinated between the OPALS External Interface Engineer and the cognizant engineers within OPALS. As data and plans have been generated over years of interaction among these organizations, it is incumbent upon the EIE to ensure internal consistency and remedy problems across evolving interfaces External, Technically-Derived Drivers and Constraints The ISS-imposed requirements provide the specification for the physical interface to the station, and, via the PSRP process, also provide direction on meeting the safety considerations that come with the Class A status of the ISS This section will highlight how technical specifications from the ISS impacted aspects of the OPALS design Mass & Power Budgets 227Most payloads will find the ISS allocation for mass and 28V operational power to be quite generous at 490 lbs. \(excluding the top half of the FRAM\227 the ExPA plate\d 504 watts, respectively. The ISS also provides 750 watts on a 120V operational line and an additional 300 watts of power on a 120V heater line Expected to come in under 400 lbs., OPALS fits well within its mass allocation. In fact, at no point in its development did the OPALS mass margin\227calculated as \(AllocationCBE\llocation\227fall below 15%, and since CDR it has been hovering around 30%. The 28V ops power margin has been even more generous, hovering at or above 60% for much of the projects lifecycle, while the 120V ops and 120V heater lines have seen equally generous margins of over 60% and 70 %, respectively In space, mass and power are drivers more often than not For OPALS the opposite has been the case, to the point where the excess allocations has been used to solve problems in other areas. One such example has been the  Figure 17:  The OPALS ISS requirement verification process is built around th e ISS approval process 


  design of our gimbal. At nearly 70 lbs., th e to be severely overdesigned for the 3 lb supports. However, the need for such a b forced by the early selection of the actuat o long-lead items and had to be large enou g the optical head in the absence of launch lo time, by the yet unknown design of the opt under certain configurations, could have b e lbs. Knowing that mass would likely not p roject was thus able to save cost by avo the mass of the gimbal while at t accommodating an unknown optical hea d lack of launch locks The power draw of the electronics was concern since one of the benefits of havin g is that their power draw is well known a n fluctuate greatly over time. If there was o n p ower draw required more active manage m 120V heater line which is shared by the IS S launch vehicle, of which the latter had si stringent and fluctuating requirements Designing to a Class A Interface 227Of all t h interface, the safety-related ones likely impact on the OPALS design. There are features that owe their existence to the nee d the two-fault tolerant design against cat a mandated by the PSRP. The payload h a combination of three hardware and softwar each of the two catastrophic hazards that w e the inadvertent usage of the 2.5 watt clas s shining the laser outside of its approved a r The hardstops limiting the travel of each a x constitute two of the inhibits required to pr e Via a negotiation process with the PSRP, t h upon the area around the ISS where it wo u Figure 18: OPALS Field of Regard \(red  Motion \(yellow\ver the O C station 17 e gimbal appears optical head it b eefy design was o rs\227which  were g h to immobilize cks\227and, at that ical head, which e en well over 10 be an issue, the iding optimizing t he same time d design and the even less of a g COTS avionics n d is unlikely to n e area where the m ent was on the S and the SpaceX gnificantly more h e aspects of the had the largest a number of FS d to comply with a strophic failures a d to include a e inhibits against e re identified: \(1 s 4 laser, and \(2 r ea of operations x is of the gimbal e vent the latter h e project agreed u ld be allowed to p oint the laser, referred to as the From this not-to-exceed area, the p allocation to allow for uncertai manufacturing. Using these derate gimbal to keep the laser within Figure 18\ela t nadir\he ROM extends from a p in the gimbal azimuth axis  approximately 1 373 to 38 373 in the crosstrack\erally speaking range limits the length of each pas s while the size of the elevation frequently a pass occurs. This is mission success is at odds with m yield to it. Were it not for the ne e operation of the laser due to safet y would have enjoyed longer and m o improving its chances of meeting it s In addition to the hardstops, meeti n mandate requires that the des i microswitches, two relays, soft w p rotection, and operational const r with the Huntsville Operations Sup p and function of these inhibits were d MOS Interface 227The main drive r implementation was the availabili t operations tools, processes, and in fr payloads. Although drivers are so m negative impact on development opposite was true. The OPALS leverage existing capabilities as mu development of new tools and proc e Several remote operations tools ar e from MSFC and JSC for telemet r management, schedule viewing, tel e over-IP. Table 3 details the a v function. The OPALS MOS has i tools with only a minor amou n required. Given the wide array of t responsibilities of OPALS MOS simplified to development of the ephemeris processing, generati o generation of telemetry and comm a decision-making and execution  analysis In addition to tools, OPALS has al s great deal in the area of operati o depicts the interface support pr o Marshall Space Flight Center and Directorate \(MOD\e Johnso n  general, MOD handles the overall with tasks including crew operat i orbital reboosts, docking activiti e MOD defines its interface with O P Rules that govern power, attitu d restrictions on payload activity T   and Range of C TL ground Field of Regard \(FOR r oject further derated the n ties in modeling and d values it designed the the expected Range of t ive to the ISS +Z axis p proximately -34 373 to +73 373   alongtrack\d from gimbal elevation axis the size of the azimuth s over the ground station range determines how a clear example of how m ission safety and must e d to restrict the area of y considerations, OPALS o re frequent passes, thus s level one requirement  n g the two-fault tolerance i gn also include four w are ar m fire command r aints to be coordinated p ort Center. The purpose d iscussed in sectio n 3  r for the OPALS MOS t y of significant existing fr astructure for ISS-based m etimes seen as having a in this case quite the MOS has attempted to u ch as possible to avoid e sses and thus save cost e available free of charge r y processing, command e metry query, and voicev ailable tools and their i ncorporated all of these n t of tool configuration t ools available, the prime development has been operations concept, ISS o n of file products a nd databases, operations  and troubleshooting s o been able to leverage a o ns processes. Figure 19 o vided by the POIC at the Mission Operations Space Flight Cente r In ISS platform operations i ons, robotic operations e s, and attitude control P ALS via a set of Flight d e, trajectory, and crew T he POIC, on the other 


  hand, provides the infrastructure to commands and file products to the paylo a infrastructure to receive and relay real-tim e the payload. The agreements between the POIC to ensure proper operation, m monitoring of the payload are docume n Regulations. In addition, the POIC maintai n p rocess for planning payload activities a n those activities into the larger ISS schedule Activity planning and scheduling begins 8 launch and continues up to 7 days before t h it is included in the ISS Short Term Pl OPALS operations are time critica l commanding by members of the POIC O will be designated with priority over activities in the STP. During real-time Payload Operations Director at the PO I interface for the OPALS payload and provi d inputs for activity coordination with t h Director. The expectations of the payload d it will provide a clear set of science object i set of data and planning requirements need e those objectives. For OPALS, these documented in the OPALS Ops Conce p delivered to the POIC and MOD 18 mo n anticipated launch date. It is also expected operations team will submit a formal t r participate in training exercises with the P other ISS payloads. The POIC offers two f l activities: scenario training and simulation t Scenario training exercises MOS execu t specific processes while simulation trainin g familiarity with ISS interfaces, coordinatio n MOD entities, and decision-making in t h anomalies. The scenario activity resembles operational readiness test \(ORT\ in Table 3: Existing operations t o Tool Operations F Telescience Resource Kit \(TReK Telemetry Proc e Telemetry Disp l Telemetry Data b Command Man a Command Data b Enhanced HOSC System \(EHS Telemetry Que r Database Sync h HOSC Networ k Internet Voice-over-IP IVoDS Voice Loops Payload Information Management System PIMS File Transfer Operations Cha n On-board Short Term Plan Viewer \(OSTPV ISS Schedule V 18 relay real-time a d as well as the e telemetry from payload and the m aintenance, and n ted as Payload n s a well-defined n d incorporating  8 months before h e activity, when an \(STP\ince l and require O PALS activities conflicting ISS operations, the I C is the prime d es the necessary h e MOD Flight d eveloper are that i ves along with a ed to accomplish prod u cts were p t document and n ths prior to the that the payload r aining plan and P OIC, MOD, and l avors of training t raining t ion of payloadg exercises MOS n with POIC and h e event of ISS what is called an the JPL flight development process, while the si m to the ISS program due to the diversity of the ISSP interfaces. F members are available on conso l OPALS MOS in a flight-like oper a role of the Flight MOS and Grou n react appropriately to nominal and relayed by the POIC over the voic e expected to obey all Flight Rules a in the execution of their acti v p roficiency with all operations pr o OPALS and external \(e.g. ISS 6  C ONCLUS I The development of the flight payl o two factors: \(1\ interfacing with th e sense and a programmatic one, an d as a Class D risk classification payl o The ISS physical interface provide d but one that was greatly facilit a standardized FRAM and by the g e allocations. The latter have afford e flexibility in making design decis i the expense of the still generous m a Operating on the ISS also mean t facility and of the astronauts it ho s all other considerations. As such O in a series of inhibits to provide t w catastrophic hazards identified despite being a Class D payloa d typically affords significantly mo r project\222s risk posture for mission s u on safety. The ISS-driven pro c scrutinizes this aspect can be d a navigate it, projects need to pla n significant impacts in both tech n areas, while keeping in close c PSRP The internal decision to implemen t p ayload also had significant impli c led to the widespread use of CO T o ols F unctions e ssing l ay b ase Build a gement b ase Build r y h ronization k Access n ge Requests iewer Figure 19: OPALS cross-agenc y m ulation activity is unique sheer complexity and or both exercises, POIC l e to interface with the a tional environment.  The n d MOS teams will be to off-nominal notifications e loop. The teams will be a nd Payload Regulations v ities and demonstrate o cesses, both internal to I ONS  o ad was largely driven by e ISS, both in a physical d 2\ng implemented o ad d a significant constraint a ted by the use of the e nerous mass and power e d the project significant i ons that reduced cost at a ss and power margins t that the safety of the s ts took precedence over O PALS has had to design w o fault tolerance for all This limitation comes d a classification which r e latitude in defining a u ccess but has no bearing c ess that oversees and a unting. To successfully n and accommodate for n ical and programmatic ommunication with the t the project as a Class D c ations for the design. It S components, which in  y operations interfaces 


  19 turn lead to a design that required forced convective cooling and vibration dampening, both uncommon for modern-day space payloads. Furthermore, it allowed the project flexibility in tailoring its verification and validation program for non-ISS requirements to save cost and schedule The focus of space-borne instruments is usually on the flight articles, which in the case of OPALS is the FRAM-based payload to be externally installed on the ISS. However most, if not all, projects must also develop a ground infrastructure to support the operations of the flight asset For OPALS, despite being more akin to an instrument than a spacecraft, that was certainly the case as significant development was required for both the optical ground station to enable the transmissi on of a beacon and receipt of the optical downlink for the former, and for the MOS to support commanding and telemetry The use of the OCTL facility in California greatly reduced the amount of development required to receive and process the optical downlink, and to transmit the beacon needed by the FS to locate the ground station. The development was thus restricted to the optics needed to condition the light beam for processing by the hardware receiver and the software decoder The design of the MOS was, by and large, dictated by the interface to the ISS\222s expansive payloads operations infrastructure located at Ma rshall Space Flight Center Because the interface was already mature and well understood, the project\222s efforts were primarily focused on ensuring compatibility rather than developing its own capability. The savings afforded by leveraging the existence of the already operating infrastructure cannot be understated A CKNOWLEDGEMENTS  The authors express their gratitude to the entire OPALS team for their dedication and hard work, and to the mentors that have guided the team on a path to success. The authors acknowledge all of the OPALS team members, whose technical contributions made the writing of the paper possible.   The work described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration R EFERENCES    J  C e s a r o n e  D  S   A b ra h a m s  S  S h am b a y a ti  a n d J   Rush, \223Deep space communications, visions trends and prospects,\224  In Proc. Int. Conf. Space Opt. Syst. Appl  Santa Monica, CA, May 11\22613, 2011, pp. 412\226425  m ati 223 S pecial s ec tion guest editorial: free space optical communications.\224 Opt. Eng 0001 51\(3\031201-1-031201-1 doi:10.1117/1.OE.51.3.031201 3 Hen n i g er, an d O. W ilf ert A n i n tro d u ctio n to f r ee space optical communications Radioengineering 19.2 pp. 203-212, 2010 4 Risk Classification for NASA Payloads NASA Procedural Requirements NPR 8705.4, 2008  P h aeton Early C a reer Hire Dev e lop m ent P r og ram  R. M Jones, J. Lim. 2012. Jet Propulsion Laboratory California Institute of Technology. 19 Oct. 2012 http://phaeton.jpl.nasa.gov/internal/index.cfm 6 ard  B  So lish  M. Seib ert, K. Kilb rid e  S. Do n g   and T. Coffee. \223Bridging the Generation Gap : A Rapid Early Career Hire Training Program,\224 in AIAA Space 2008 Conference pp. 1-13   B i s w a s H. He mm ati S. P i azzolla, B  Mois ion  K  Birnbaum, and K. Quirk, \223Deep-space Optical Terminals DOT\ms Engineering.\224 IPN Progress Rep. 42183. Nov. 15, 2010  Hem m a ti A B i s w as I.B D j o r d j ev ic  D eepS pace Optical Communications: Future Perspectives and Applications," in Proceedings of the IEEE  vol.99 no.11, 2011, pp.2020-2039 9 Lucke, Robert L., et al. "Hyperspectral Imager for the Coastal Ocean: instrument description and first images Applied Optics 50.11 \(2011\ 1501-1516 10 M  C o r s o n  D  K o r w a n  R  L u c k e  W  S n y d e r  C   Davis, "The Hyperspectral Imager for the Coastal Ocean HICO\ the International Space Station," in IGARSS 2008 pp.IV-101-IV-104  T e les c ien ce R e s o u r ce K i t J. Onken. 2012. Marshall Space Flight Center. <http://trek.msfc.nasa.gov 12  Payload Safety Review and Data Submittal Requirements National Space Transportation System NSTS 13830, 1998 13 Computer-Based Control System Safety Requirements  Space Station Program SSP 50038, 1995 B IOGRAPHIES  Bogdan Oaida is the Project Systems Engineer for OPALS. He received a B.S.E. in Aerospace Engineering in 2007 and a M.Eng in Space Engineering in 2008, both from The University of Michigan. Since joining JPL in 2008, Bogdan has also worked on a number of Earth-sensing mission proposals and has participated in several TeamX studies JPL\222s concurrent engineering environment 


  Matt Abrahamson i s Operations Lead for received a B.S E ngineering With Technology in 2006 a A eronautics and Astro n both from MIT. He L aboratory Fellow from since joining J PL has worked on flight o p EPOXI, Stardust-NExT, Juno, and Daw n mission navigator  Robert Witoff is the I S Systems Engineer for received a B.S E ngineering from the Colorado at Boulder i p ursuing a Masters in S o E ngineering at Stanford A pigy Inc, Robert joine d has additionally worked on the Daw n Interplanetary missions J essica Bowles Martin e and Mission Assuranc e OPALS. She receive d  E lectrical Engineering Science and B.S. in Co m Studies in 2003 at th e I nstitute of Technolog y earned a M.Eng in Elec Engineering from Johns Hopkins Universi t J PL in 2008, she has held various ro l radiation testing for Juno, research in N A Parts Packaging program, and an ISS b a assembled telescope project  Daniel Zayas is the T h both OPALS and t h L aboratory, a planne d Condensate experime n I nternational Space received B.S. degrees E ngineering and Physic s A erospace Engineerin g M assachusetts Institute of Technology.  H e contributed to a number of planetary m including JUNO and the Mars Science L a Curiosity   20 s the Mission OPALS. He in Aerospace Information a nd a M.S. in n autics in 2008 was a Draper 2006-2008 and p erations for the n projects as a S S and Dragon OPALS.  He in Aerospace University of i n 2009 and is o ftware Systems  After founding d JPL where he n and Rosetta e z is the Safety e Manager for d a B.S.E. in and Computer m parative Media e Massachusetts y In 2006 she trical Computer t y. After joining l es working on A SAs Electronic a sed robotically h ermal Lead for h e Cold Atom d Bose-Einstein n t aboard the Station.  He in Aerospace s and a M.S. in g all from the e has previously m issions at JPL a boratory rover 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



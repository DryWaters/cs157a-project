 An Efficient Agent based Framework for Distributed Medical Databases Revised August 2011  W. A. Atteya 1 Keshav Dahal 2 and M. Alamgir Hossain 3   1,2 School of Computing, Informatics and Media, Bradford University, United Kingdom 3 School of Computing, Engineering and Information Sciences, Northumbria University, United Kingdom  Abstract—Many algorithms have been proposed for the discovery of association rules. The efficiency of these algorithms needs to be improved to handle real-world large datasets Specifically, for data stored in heter ogeneous and geographically distributed hea 
lthcare centers. This efficiency can be determined mainly by three factors. The way candidates are generated, the way their supports ar e counted and the data structure used. Most papers focus on the first and the second factors while few focus on the underlying da ta structures. In this paper, we present a distributed Multi-Agent based algorithm for mining association rules in distributed environments. The distributed MAS algorithm uses Bit vector data structure that was proved to have better performance in centralized environments. The algorithm is implemented in the context of Multi-Agent systems and complies with global communication standard Foundation for Intellig ent Physical Agents \(FIPA\The distribut ed Multi-Agent based algorithm with its new 
data structure improves implementations reported in the literature that were based on Apriori. The algorithm has better perform ance over Apriori-like algorithms  Index Terms Association Rules, Distributed Data Mining, Multi-Agent System  I  I NTRODUCTION  Finding frequent itemsets is one of the most important data mining research fields. The problem was first presented in [1  with another extension in [2 a in alg o rith m  Aprio r i, h a d an impact on other data mining techniques as well Association rules and frequent itemsets mining became a widely research area, and hence most researchers have tried to present faster algorithms. Many of these algorithms were 
Apriori-based or Apriori extensions. Most association rule algorithms use hash-trees extensively to speed up the search for itemsets. Those who adopted Apriori strategy tended to adopt the whole set of procedures and data structures as well Recently, algorithms have been proposed to increase the efficiency of these algorithms to improve real-world large datasets. Some algorithms focu sed on the way candidates are generated. Others focused on the way their supports are counted. Few researchers have focused on the underlying data structure used which was a hash tree in case of Apriori-based algorithms. Park et al. [3 has i nve nt e d a wel l  kn ow n  technique called DHP \(Direct Hashing and Pruning\ and was enhanced in [4  DH P u s es a has h t ech ni q u e t h at m a kes i t  very  
efficient for the generation of candidate itemsets, in particular for the large two-itemsets and employs effective pruning techniques. The reduction of the number of generated candidates greatly improves the performance of the whole process. However, Park used this hashing technique to mine association rules in centralized database Bodon ha s dem onst r at ed t h at a Trie data structure outperforms hash-trees. Tries appeared to offer simpler and scalable algorithms which turned out to be faster. Bodon has implemented Apriori association rule mining algorithm using Trie data structure rather than Hash Tree. Further publication 6 ed th at th e d a ta structu r e Trie appeared to be faster than the original algorith 
m. Bodon has extended his implementation for mining itemset sequences in [7  M a ny  other researchers have adopted the Trie structure to mine association rules on centra lized databa 9 Recently, a novel approach by Dong has presented a very effective algorithm named as B itTableFI [10 Th e algorith m uses a special data structure BitTable horizontally and vertically to compress database for quick candidate itemsets generation and support count, respectively. Dong has proven that this data structure is faster than the hash tree used by Apriori. Results were obtained by applying the BitTable data structure on two synthetic centrali zed datasets is one of the extensions that is based on this technique In this paper, we present 
an efficient distributed MAS algorithm. The efficiency of the algorithm is obtained by modifying the data structure used and the way candidates are generated and counted. The rest of the paper is organized as follows. The next section describes the proposed distributed BitTable Multi-Agent based algorithm. Section 3 describes the implementation of the proposed algorithm on a real world distributed medical databases. The algorithm analysis and evaluation are presented in Section 4. The last section presents the conclusion and the future work II  D ISTRIBUTED B IT T ABLE M ULTI A GENT 
A SSOCIATION R ULES M INING A LGORITHM  In earlier work, we have pr esented an enhancement for Apriori algorithm using a simpler data structure [12 Th e algorithm was implemented on centralized database. Previous work has extended the basic concepts of Apriori like algorithms to work in distributed environments using cooperative Multi-Agents [13 Th e p a rallelism o f th e candidate generation and the support count processes among these distributed agents helped in decreasing the time needed for the whole mining process. The previously proposed 


 algorithm was implemented on distributed medical databases 1 fo r patie n t diagn o stic sy st em regarding Inflammation of urinary bladder and Nephritis of renal pelvis origin diseases The proposed algorithm improved the diagnostic knowledge and discovered the diseases based on the minimum number of effective tests, thus, provid ed accurate medical decisions based on cost effective tr eatments. The constructed Knowledge base could predict th e existence or the absence of the diseases, thus improving the patient medical service In this section, we present the distributed BMAS algorithm which combines the best of different association rules algorithms and techniques in order to achieve the best performance and execution time. The proposed algorithm combines the association rules as a data mining technique, the Multi-Agents to decrease the time needed for the candidate generation and the support count processes a n d t h e BitTable data structure that was proved to be a very efficient data structure for mining frequent itemset  15   Databases with this structure are very compressed and can be easily fit in memory at local sites. Moreover, it has a great effect on the performance in the candidate generation phase and the support counting which are considered the most lengthy processes in the frequent itemsets generation algorithms. However, Dong has implemented his BitTableFI algorithm on centralized database only. For some reasons which were not clearly stated in the paper, the BitTableFI algorithm constructs the frequent itemsets BitTable data structure after the frequent 2-itemsets are generated. We believe that constructing the frequent itemsets BitTableFI from the first iteration will increase the performance of the candidate generation and counting for the first and the second itemsets. Consequently, this will have a good impact on the algorithm performance. The proposed algorithm can be described as follows 1. The proposed algorithm is based on the distributed MultiAgent based algorithm described in [1 w h i c h was bas e d on  Apriori like algorithms 2. The proposed algorithm uses the BitTable data structure in [7 stead  o f th e p r ev iously i m p l e m en t e d d a ta stru cture in 1   3. Unlike the BitTableFI algorithm, the proposed algorithm constructs the Bit-Table data structure before the first iteration 4. Unlike the BitTableFI algorithm which was implemented on two synthetic centralized datasets, the proposed algorithm together with the BitTableFI al gorithm are to be implemented and tested on five distributed real world benchmark datasets 5. The distributed Multi-Agent based algorithm complies with the global standards in communication between agents namely the FIPA, thus enabling the ability for cooperating with other standard agents also the future extension for the proposed model A  The Database Conversion Algorithm This section describes how local databases are converted before the first iteration into the BitTable format instead of the Apriori format. Every item is checked for existence in the transaction. If the item exists, the item is replaced with 1 otherwise it is replaced with 0. For instance if we have the items ABCDE and the transaction ACD, the result transactional bitvector will be: 10110. This format is called the bitvector representation for the transaction. The conversion of the database into the BitTables format is described in details in Algorithm 1 Let I = {i1, i2, ………. in} be a finite set of items and D be a dataset containing N transactions, where each transaction t  D is a list of distinct items t = {i1,i2, ……. ij } where ij I \(1 j t|\each transaction can be identified by a distinct identifier tid  Algorithm 1 Transaction conversion into bit vectors \(local agents 1 begin 2  Let {I} = the finite set of all items {i 1 i 2 I n   3 For  every item i j in the set of items {I} where  \(1 j n do  4 If i j   i k where i k  t ={i 1 i 2 i  t  i k  I, \(1 k t then  5  t b itvecto r 1  6  Else 7  t b itvecto r 0  8 End I f  9 Next  10  Output the database transactional bit vector t b itvecto r   11 End   B  The Distributed BitTable MAS Algorithm This section presents the proposed distributed BitTable Multi-Agent association rules algorithm. The algorithm consists of three types of co operative agents that work together to achieve the required goals. The first kind of agents is the Interface Agent. This agent can cooperate with the human and accepts the user required support. The second kind of agents is the local agents which are distributed at local sites for generating the candidate itemset. The third kind of agents is the main agent which has a gl obal view of all local agents and is responsible for the candidate generation process. All agents work together to achieve the required association rules mining goal. The proposed algorithm is compliant to the Foundation for Intelligent Physical Agents standard The proposed algorithm and the message negotiation between agents are described as follows 1  The Interface Agent accepts the support from the user 2  The Interface Agent sends the required support to the main agent 3  Main Agent sends a "propose performative" FIPA message to Local Agents   Propose  sender \(agent-identifier :name main_agent receiver \(set \(agent-identifier :name local_agent content "Start mining with support = minsupp reply-with start_mining_proposal 4  Local Agents reply with an "agree performative" to Main Agent as follows  Agree  sender \(agent-identifier :name local_agent receiver \(set \(agent-identifier :name main_agent 


 content "proposal approved and mining started at k=1" :in-reply-to start_mining_proposal 5  Each Local Agent starts counting the local supports for all 1- candidate itemsets in its local database according to its local number of records Algorithm 2 explains the counting process in details  6  Local Agent replies with "inform performative" to Main Agent as follows  Inform  sender \(agent-identifier :name local_agent receiver \(set \(agent-identifier :name main_agent content "finished counting candidate 1-itemsets 7  Main Agent compares the summation of the local supports sent from all agen ts for 1-candidate itemsets with the min support supplied by the user 8  Main Agent finds the 1-large itemsets and save it in the database in the list of frequent itemsets 9  Main Agent sends an "Inform performative" FIPA message to Local Agents  Inform sender \(agent-identifier :name main_agent receiver \(set \(agent-identifier :name local_agent content "frequent itemsets at k=1 are successfully generated 10  Main Agent generates the k-candidate itemsets Candidate generation pr ocess is explained in details in algorithm 3  11  Main Agent sends the generated k-candidate itemsets to all local agents 12  Main Agent sends a "Request performative" FIPA message to all Local Agents as follows  Request  sender \(agent-identifier :name main_agent receiver \(set \(agent-identifier :name local_agent content "candidate itemsets are generated at iteration K, please count the support reply-with iteration_k 13  Each Local Agent calculates the k-candidate itemsets in its local databases This can be explained in details in algorithm 4  14  Local Agents send an "Inform performative" FIPA message to Main Agent  Inform  sender \(agent-identifier :name local_agent receiver \(set \(agent-identifier :name main_agent content "finished counting candidate itemsets for the current iteration K in-reply-to iteration_k 15  The Main Agent considers any k-candidate itemset as frequent if the summation of all local supports for this itemset from all local agents is greater than the min global support 16  Frequent itemsets are saved in the central database in the list of k-frequent itemsets while small itemsets are not considered in the next iteration 17  15 tive and finish when there are no more k+1 candidate itemsets 18  Main Agent sends an "Inform performative" message to all Local Agent   Inform  sender \(agent-identifier :name main_agent receiver \(set \(agent-identifier :name local_agent content "Finished mining of frequent itemsets 19  Main Agent sends all frequent itemsets to Interface Agent for representation  C  The Proposed Algorithm at the First Iteration The generation of candidate itemsets and the large itemsets counting in the early iterations \(k=1 and 2\ are usually the most time consuming processes for the overall association rules mining process. Unlike the BitFI algorithm, we apply the BitTableFI data structure starting from the first phase. This has significantly reduced time needed for the first two iterations and has resolved the performance bottleneck. The algorithm is implemented by local agents at local sites Algorithm 2 presents how the 1-frequent itemsets are counted by local agents  Algorithm 2 Counting the 1-frequent itemsets \(local agents 1  begin 2   For  every item bit vector Ib i in the items bit table do  3 Loop on every transaction in the database 4    Perform BitWise AND operation with t b itvector  5 I f Ib i AND t  b itvecto r Ib i  then  6   Increment the support\(Ib i  7 End I f  8 End Loop  9 I f total support \(Ib i minsupp then  10   Add Ib i to set of large itemsets Lb 1  11   End  i f  12   Next  13  Output set of 1-Frequent itemsets 14  End   D  The Proposed Algorithm at the K-Iteration When the itemsets are counted by the local agents, they are sent to the main agent which generates the k-frequent itemset and the \(k+1\ candidate itemsets for the next iteration. The algorithm for \(k+1\idate itemsets generation at k iteration is described in Algorithm 3  Algorithm 3 candidate k+1itemsets generation \(main agent 1  begin 2 For every frequent k-itemset bit vector F i bitvector in the set of frequent itemsets bit table\(F b k  do  3   Get the Mid of F i bitvector set of items with the last bit = 1 change to 0 4 Loop on frequent k-itemsets F j bitvector where \(i+1 j  number of frequent k-itemsets 5    Perform BitWise AND operation with F j b itvector  6  I f Mid of F i b itvecto r AND F j b itvecto r Mid of F i b itvecto r  then  7   Generate Candidate k-itemset bit vector C k+1 bitvector  F i b itvecto r OR F j b itvector  8 Add C k+1 bitvector to the set of candidate k+1itemsets bit table \(Cb k+1    9  End I f  10 End Loop   11 Next  12  Output set of Candidate k+1itemsets bit table \(Cb k+1    13  End  


 The generated candidate itemsets are sent to local agents The supports of these candidate itemsets are counted by local agents at every local site and are sent to the main agent Algorithm 4 explains the counting process for the k-candidate itemsets. The main agent sums the supports counted by all agents. Itemsets whose total support are greater than or equal to the minimum support are cons idered as large itemsets and are considered for the next iterations. Itemsets whose total supports are less than the minimum supports are not considered for the next iterations  Algorithm 4 Counting the k-frequent itemsets \(local agents 1  begin 2 For every candidate k-itemset bit vector C i bitvector in the candidates bit table \(C k  do  3 Loop on every transaction in the database 4    Perform BitWise AND operation with t  b itvector  5 I f C i b itvecto r AND t  b itvecto r C i b itvecto r then 6   Increment the support\(C i b itvecto r  7 End I f  8 End Loop 9 I f total support \(C i b itvecto r minsupp 10 Add C i b itvecto r to set of large itemsets Lb k  11 End i f  12 Next  13  Output set of k-Frequent itemsets 14  End  III  APPLYING THE PROPOSED A LGORITHM ON MEDICAL DATABASE  Inflammatory lesions of urinary bladder and kidneys exist in 3 - 5% of the population. Women suffer more often due to anatomic peculiarities of their urogenital system. There are conditions to transfer adjacently the bacterial contamination from vagina. Pregnancy is also a factor due to compression of urethra by the fetus and retention of urine. By advancing of age and appearance of prostate adenoma in some males infections of urinary bladder and kidney become more frequent in them. Nephrolithiasis is also the reason for development of inflammatory of urinary bladder and kidneys When the inflammatory process has covered the kidneys, the status of patients is significantly damaged, and it is possible to develop more severe complications like inflammation of adjacent tissues or acute renal fa ilure [16 It is n ecessary to  carry out many examinations for the patients under investigation. These examinations may be costly and time consuming. Our goal is to construct a model that can discover the effective minimum number of tests to identify the previously mentioned diseases. Moreover, the model should use the constructed knowledge base to help doctors in future prediction thus saving time and effort which is very critical for the patients A  Data structure and data variables The medical data used by the proposed multi-agent based algorithm contains instances for patients symptoms related to the diseases Inflammation of urinary bladder and Nephritis of renal pelvis origin. These symptoms are Burn or itch of urethra and swell for its outlet, Lumbar pain, Micturition pains, Occurrence of nausea and Urine pushing \(continuous need for urination\. The columns of Table 1 represent these symptoms and diseases in the same order. We should note that although the algorithm was implemented on specific parameters of the medical data for the previously mentioned disease, but it can be applied on different other items representing other symptoms or tests for the patient medical records. Data was distributed in two hospitals as follows. One hospital has 99960 medical records while the other has 71400 medical records, with total of medical records to be mined 171,360 medical records. Data of each hospital was loaded into a data warehouse. After ensuring that data is not volatile missing values which was about 8% of the total amount of data were removed from the data warehouse. There was some data preprocessing for the initial data before the implementation of the proposed algorithm  TABLE  1  DATA  SAMPLES  FOR  THE  MEDICAL  DATA  AFTER  BEING  PREPROCESSED  TO  THE  APRIORI  LIKE  FORMAT TID BURN LUMB MICT NAUSEA PUSH INF NEPH 1 No Yes No No  No No No 2 Yes No Yes No Yes Yes No 3 No Yes No No  No No No 4 Yes No Yes No Yes Yes No 5 No Yes No No  No No No  B  Rules generation The algorithm was implemented many times on the same data using different values for the support and the confidence Increasing the value of the conf idence led to a small number of generated rules. On the other side, decreasing the value of the confidence lead to a huge nu mber of rules, some of them were not relevant and were not interesting. Many researches were done to eliminate the huge number of redundant [1 and  non interesting [18  asso ciatio n ru les. Alth oug h we d i d no t tackle this problem as it is out of our scope in this paper, yet we have found that the best confidence for our medical data was 80%. Table 2 describes some of the medical rules generated by rule agent in the proposed multi-agent based system at confidence = 80  TABLE  2 SAMPLE OF THE GENERATED MEDICAL RULES  AT CONFIDENCE 80 Ant  Cons. Confidence A-D-E X 100 D-E-L W 100 L-U Z 100 M-U Y 100 C-X Y 80 C-E-X Y 80  C  Justification of the generated rules Association rules generated by the Rule agent are stored in the knowledge base in the form  Antecedent Itemset Consequent Itemset With Confidence = c    


 We have selected some of the generated rules in the knowledge base for illustration as follows 1. L-U Z IF Lumbar pain AND Urine pushing \(continuous need for urination THEN Nephritis of renal pelvis origin WITH CONFIDENCE 100  2. M-U Y IF Micturition pains AND Urine pushing \(continuous need for urination THEN Inflammation of urinary bladder WITH CONFIDENCE 100  3. D-E-L W IF No Micturition pains AND No Occurrence of nausea AND Lumbar pain THEN No Inflammation of urinary bladder WITH CONFIDENCE 100  4. A-D-E X IF No Burn /itch of urethra AND No swell for its outlet AND No Micturition pains AND No Occurrence of nausea THEN No Nephritis of renal pelvis origin WITH CONFIDENCE 100  D  Testing the performance of the algorithms The experiments included the implementation and testing of four algorithms on two distributed real world medical databases for the inflammation of urinary bladder disease Two of the algorithms were cen  and BT 1  h e ot h e r two al go rithm s were distrib u ted \(M AS 1 3  and our proposed distributed BitTable Multi-Agent based algorithm BMAS\. The test bed used was windows XP, Intel Pentium IV processor, 2 gigs ram. Figure 1 presents the implementation of the four algorithms at five different supports with total of 20 readings  Figure 1 Implementation of the algorithms on Inflamation of Urinary Bladder Database at different supports IV  A LGORITHM A NALYSIS AND E VALUATION  This section presents the performance evaluation of the system. The system is also ev aluated from the technical and the medical point of views  A  Performance Evaluation From Figure 1 we can observe the following 1. In case of the centralized algorithms, BT algorithm with the BitTableFI data structure outperforms PEA algorithm 2. In case of the distributed algorithms, the proposed BMAS with the BitTableFI data structure outperforms the previously implemented algorithm MAS 3. The distributed algorithms BMAS and MAS outperform the centralized algorithms BT and PEA 4. The proposed distributed algorithm BMAS outperforms BT, PEA and MAS algorithms. Moreover, the time difference increases when the mini mum support decreases  The performance of BMAS has been achieved due to the following reasons 1. The use of the Bitwise And/Or operation to generate candidate itemsets based on BitTable data structure which was proved to be greatly faster than the traditional item comparing method used in many Apriori-like algorithms [6   2. The highly compressed BitTable database constructed which helps in quick counting for the support of the candidate itemsets using the Bitwise “And” operation 3. The construction of the BitTable data structure before the first iteration 4. The use of the distributed Multi-Agents which decrease the time needed for candidate generation and support counting From Figure 1 we deduce that the time needed for mining frequent itemsets using the proposed distributed BitTable Multi-Agent based algorithm \(BMAS\an that needed by other algorithms  B  From the technical point of view 1  The model is compliant To FIPA The model complies with the Foundation for Intelligent Physical Agents \(FIPA\ global standards described in the next section. It also combines different techniques, like multi-agent systems, association rules as a data mining and the distributed medical databases 2  The model agents satisfy the MAS properties During the implementation of the multi-agent based model on the distributed medical databases, the model agents achieved the agent properties in which each agent in the model individually exhibited the autonomous behavior. On the other side all agents have presented a coherent behavior when communicating with each other  C  From the medical point of view From the medical point of view, the model presents a generic platform for multi-agent systems and provides contributions for the medical data distributed over different 


 departments in a hospital or different distributed hospitals These contributions can be listed as follows 1  The model is an accumulating knowledge base association rule The model has constructed a knowledge base containing many interesting rules that can be very useful for medical experts. This knowledge base architecture can improve the system real time response by identifying some basic features that indicated the presence or th e absence of the disease, for 2 lp to identify the presence of the Inflammation of urinary bl adder AND Nephritis of renal pelvis origin respectively based on the minimal number of symptoms/tests for the patient, thus reducing time to identify the disease and reducing cost for doing other tests On the other side, rules \(3\ and \(4\dentify some basic features that indicate the absen ce of the disease, which means that if these symptoms do not exist, there is no need for further patient examinations for other symptoms or tests 2  The model as a medical diagnostic platform The model has presented a diagnostic platform that can help in investigating patients diagnosis based on symptoms or tests done in different hospitals or within the hospital departments 3  The model can be used for disease predication Based on the rules generated, the model can help doctors in the early prediction for the existence or the absence of the disease based on the previously discovered association rules 4  The model is a cost effective method Due to the early prediction f eature of the model described above. This led to minimize th e number of tests needed by the doctors, thus minimizing the ef fort, the cost and the time needed for the patients to do other tests or to be checked for other symptoms V  C ONCLUSION  The efficiency of association rules algorithms needs to be improved to handle real world large datasets. To increase the overall efficiency of the associa tion rule mining, we presented a distributed Multi-Agent based algorithm to enhance the three main factors affecting the overall efficiency. First, to improve the way candidates are generated, our distributed algorithm is based on BitTable data structure which has a better performance in the candidate generation phase. Second, to improve the way by which candidate supports are counted, we have implemented distributed agents in local sites that help in the counting process. Third, the implemented BitTable data structure helps in compressing the database thus can easily fit in memory at local sites. The BitTable data structure was implemented before the first iteration and not like the BitTableFI algorithm after the second iteration. This had a great impact on the algorithm performance. The distributed BitTable Multi-Agent based algorithm complies with the global standards in communication between agents, namely the FIPA, thus enabling the ability for cooperating with other standard agents also the futu re extension for the proposed model. Unlike the BitTableFI algorithm which was tested on synthetic centralized datasets, the performance of algorithms were measured against two distributed medical databases for the Inflammation of urinary bladder and the Nephritis of renal pelvis origin diseases. The im plementation can provide many benefits from the medical point of views. These benefits are the extraction of medical rules that helps in identifying the minimum effective number of tests and the prediction of the existence or the absence of the diseases for patients. The proposed system also improves the diagnostic knowledge for the doctors. The distributed BitTable Multi-Agent based algorithm has proved to have a better performance and execution time VI  R EFERENCES   R  A g r a wa l et al Mining association rules between sets of items in large databases ACM SIGMOD Record vol. 22, pp. 207-216, 1993   R. Agraw a l and R Srikant Fast algorithms for mining association rules in large Databases," presented at the Proceedings of the 20th International Conference on Very Large Data Bases, 1994  J  P a r k et al An effective hash-based algorithm for mining association rules ACM SIGMOD Record vol. 24, p. 186, 1995  J  P a r k et al Using a hash-based method with transaction trimming for mining association rules Knowledge and Data Engineering, IEEE Transactions on vol. 9, pp. 813-825, 2002   F Bodon and L  R ny ai T r i e: An alternative data structure for data mining algorithms Mathematical and Computer Modelling vol. 38 pp. 739-751, 2003   F Bodon  A fast apr i or i im ple m entation  in Proceedings of the IEEE ICDM Workshop on Frequent It emset Mining Implementations FIMI’03 2003   F Bodon  A tr ie-based APRI OR I implementation fo r mining frequent item sequences," 2005, p. 65   Y W oon and E  L i m   A  suppor tor d e red trie for fast frequent itemset discovery IEEE Transactions on Knowledge and Data Engineering vol. 16, p. 875, 2004   F Bodon  S ur pr is ing r e sults of tr ieb ased FI M algor ithm s   in In Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI’04    J Dong and M  Han  B itT ableFI  An efficient mining frequent itemsets algorithm Knowledge-Based Systems vol. 20, pp. 329-335, 2007  W   Song et al Index-BitTableFI: An improved algorithm for mining frequent itemsets Knowledge-Based Systems vol. 21, pp. 507-513 2008   M   M   Fakhr y  and W  A  Attey a  A n E nhanced Algor ith m for M i ning Asociation Rules," presented at th e First International Conference on Intelligent Computing and Informatio n Systems, Cairo, Egypt, 2002  W   A  Attey a et al Multi-Agent Association Rules Mining in Distributed Databases," in 15th World Conference on Soft Computing in Industrial Applications \(WSC15 2010  W   A  Attey a et al Multi-agent system for ea rly prediction of urinary bladder inflammation disease," in Intelligent Systems Design and Applications \(ISDA\, 2010 10th International Conference on 2010, pp 539-544   M   Z a ki   S calable algor ith m s for ass o ciation m i ning   Knowledge and Data Engineering, IEEE Transactions on vol. 12, pp. 372-390, 2002  NKUD IC June 2006 National Kidney and Urologic Diseases Information Clearinghouse:Prostate Enlargement Available http://kidney.niddk.nih.gov/kudiseases/pubs/prostateenlargement  accessed on 10/06/2010   M  J. Z A KI M ining NonRedundant Association Rules Data Mining and Knowledge Discovery 2004   Y Xu and Y Li  M ining for  Useful Association Rules Using the ATMS," presented at the International Conference on Computational Intelligence for Modelling, Control a nd Automation, and International Conference on Intelligen t Agents, Web Technologies and Internet Commerce \(CIMCA-IAWTIC’05\, 2005   


Jr.u T  u .' ,- JIT. v j . .Al.Low Al H igh connection - ? :i:ld:e connection Low connection T:TineDe.lay N ,Tetalnum beref attnbutes o ,JudgementNode ,Proressng Node Current Consequent Fig. 3. Basic structure of class association rule mining using Generalized GNP A route with the fixed number of n attributes\(user-defined starting from the processing node is used as the possible an tecedent parts, and it is combined with the current consequent class to generate the candidate rules All the items of the consequent part are placed in Conse quent Table\(CT  individuals are evolved to extract the class association rules for each class of the attributes, respectively, i.e., for each traffic volume level of each section of the road networks, and this procedure is repeated for all the consequent items When extracting the rules, the basic procedure is like the following: firstly, the processing node randomly moves to the connecting another judgement node from the current judge ment node one after another. Then, a candidate rule of length neuser-defined candidate rule will be checked according to the database The basic checking process is shown in Fig.4, it starts from database tuple 0000, check whether attribute Ai is Middle at 0000 and whether attribute A2 is Low at 0002, . . .  , likewise if the condition is satisfied, increase the corresponding count otherwise, start the same checking process from the next time point 0001 checking whether attribute Ai is Middle at 0001 and whether attribute A2 is Low at 0003, . . .  , likewise, and get the final counts after studying all the records of the database which is the one turn of checking for the candidate rules In Fig.4, N is the total number of the searches, and a, band 2251 c are the number of searches moving to AI\(Mid Low and A3\(Mid the count c corresponds to the count for the whole candidate 


rule, the count a and b can be used for the sub candidate rules The measurements of candidate rules are calculated by these numbers After one turn of the database searching, the support confidence and chi-squared value can be calculated for the candidate rules and sub candidate rules. If the criteria are higher than their thresholds, then the time transitions and its sub time transitions become association rules and will be stored in a rule pool during the generations r 0000 0001 0002 0003 0004 0005 0006 0007 Ml M\\ -:1!"1 _   ,Low __ ,M Idle b &/c H:gh AJ CurrentConseguent T= 2  T= 2 A c Middle   I H L M L M L L L M lMj  HI M L L r-- L ""'\(M1. H M \\LJ. L ......... M M M M --CM H H L C Fig. 4. Two dimensional searching method 


D. Extraction of Rules Using the counts obtained by searching mechanisms, the support, confidence and chi-squared value can be calculated considering both the antecedent and consequent part of the candidate rules. Now, the important association rules are defined as the ones which satisfy the minimum chi-squared support and confidence value, i.e., X;'in' sUPmin and con!min respectively. Only the important association rules can be con sidered as interesting and stored in the rule pool The rules which contain more than Nthre kinds of attributes are the so called mUltiple rules, where Nthre is a user defined threshold. This is added to increase the diversity of the evolution process and the proposed method regards the rules containing many different kinds of attributes as important ones in addition to the conventional interests The interesting rules will not only be stored in the rule pool together but also be validated according to a different database, which is the validating database. As a result, both the conventional criteria of the association rules and the validation accuracy rates will be considered in the rule extraction phase thus the evolution concentrates on extracting more general rules which adapt to real-time traffic databases and avoid the over-fitting to training database during the evolution process For each interesting rule r, the validation accuracy is defined as follows where Da\(r tecedent part of rule r D\(r After the validation of the interesting rules generated by a GNP individual, their validation accuracies will be taken into the fitness value, hence can guide the evolution to generate GNP individuals which can extract more general rules adapt able to real-time databases Therefore, the fitness function of the GNP individual is now defined as F = L {x2\(r r nante\(r rER anew\(r r The symbols are as follows R : set of suffixes of important associatIOn rules which satisfy the importance requirements of chi-squared 


support and confidence value X2 \(r nante \(r rule r anew \(r r ule r is new anew = 0, otherwise amult \(r amult, if rule r has more than amult\(r 0, otherwise x2\(r r r r r cerned with the importance, accuracy, complexity, novelty and diversity of rule r, respectively From the fitness function, it can be seen that GNP indi viduals are defined as a tool to pick up candidate rules, and the proposed method does not aim at obtaining the optimal individuals, but extracting rules as many as possible. So, the individuals which can obtain many new rules with multiple attributes will have high fitness values In each generation, GNP individuals are replaced with the new ones by the selection policy and other genetic opera tions. Four kinds of genetic operators are used, i.e., uniform crossover, mutation for functions, mutation for connections and time delays of judgement nodes, respectively Classification Firstly, classify the extracted association rules in the pool into consequent classes. Every attribute has three consequent classes, i.e., attribute Ai is classified into the following conse quent classes, Ai\(Low Mid High Then, the association rules in each class are used to study whether the testing data satisfy the antecedent items. The testing data are called satisfied if they satisfy the antecedent items of the rules 2252 Unlike the validation process, the following partial match ing strategy is carried out for calculating the matching of rule r and testing data where Nk\(d, r in the antecedent part of rule r in class k 


Nk\(r r in class k The ratio of the number of satisfied rules to the total number of rules for every class is calculated considering confidence matching degree and validation accuracy, and the testing data is classified into the class whose ratio is the highest. The concrete process is like the following 1 in class k 2 Creditk = L confidence\(r Mk\(r r rERk where, a is weight of the prediction accuracy 3 Creditk Scorek T l  ota k where, Totalk is the total number of rules in class k that is, the fixed number of Nf in this paper 4 becomes the winner for the consequent attribute Ac, e.g if Ac \(Low into Low IV. S IMULAT ION In this section, the effectiveness and efficiency of the proposed methods are studied by traffic simulations. Unlike other methods in the traffic prediction of recent years, the proposed methods not only aim at predicting the traffic jam on a specific section of the road networks, but also interested in providing the whole traffic prediction for all of the interesting sections on the road networks so that the navigation system can refer to this kind of information for the calculation of the optimal route of the road networks A. Simulator Real-time simulator SOUND/4U, which is a fully customizable macroscopic free-flow traffic simulator aiming at providing efficient traffic control and management of the urban-level large scale traffic network, has been used. The SOUND/4U simulates the real-time traffic volume and trav eling speed of vehicles on the VICS[15] systems based on 


input OD\(Origin/Destination The simulation is carried out using the traffic network of Kurosaki in Kitakyusyu, Japan. As shown in Fig.5, the road model is based on the real traffic network and there are a TABLE J IJ PARAMETER SETTING FOR SIMULATION Items Values Number of sections 7941 N umber of intersections 4243 Number of traffic lights 142 Data collection interval I \(minute Total execution time 2\(hr Number of 00 points 20 Number of 00 pairs 100 Routing algorithm Logit Route Choice Logit parameter 1.0 Fig. 5. Road model used in simulations huge number of sections on the traffic network. The traffic conditions are shown in the Table III The real-time traffic volume of section s, represents as T\( s at the current time point is calculated like T\(s Nr\(s s s Cs x Ls The symbols are as follows Ls: The length of section s Cs: The capacity of section s, e.g., for sections with one lane Cs = 1, for sections with two lanes section Cs = 2 likewise Nr\(s the last time point Nin \(s sections at the current time point Nout\(s sections at the current time point After the calculation of real-time traffic volume T\( s each section, Nin\(user-defined chosen as the interesting section, here in the simulation Nin = 500 sections with heavier traffic volumes were selected and their corresponding traffic volume at every time point were discretized to LowlMiddle/High 2253 


Judging by common sense, the High threshold is defined as follows: for sections with one lane , if there exist 2 or more cars in 10 meters, then it is a High volume situation. On the other hand, the middle threshold is defined as follows: for sections with one lane, if there exist more than 1, and less than 2 cars in 10 meters, it is a Middle volume situation. The remains will be discretized to Low traffic volume situation The cars are randomly generated based on the values of the pre-defined OD\(OringinJDestination for every OD pair is changing during the execution as shown in Fig.6 lY l Jl .? 15 co ? 10 Xl 5 Q O .r:: 0 o 50 100  150 T:in e 4n ilutes Fig. 6. Change of OriginiDestination values in simulations B. Simulation Result The parameter setting of the proposed data mining during the evolution is shown in Table IV. The total number of rules stored in the rule pool is shown in Fig.7. Each round has the same number of generations of 50 and the chosen set size for AAM is 100[14 TABLE IV PARAMETER SETTING FOR EVOLUTION Items Values Number of judgment nodes 100 Number of processing nodes 10 N umber of attributes 500 Number of consequents 1500 Number of time points 120 Minimum confidence value 0.9 Minimum chi-squared value 6.63 Minimum support value 0.05 40000 Ul 35000 !Il " 30000 '" .... "0 25000 20000 ? '" 15000 j9 10000 0 5000 E 


r r  r r l o 100 200 300 400 500 ROlU1ds Fig. 7. Total number of rules extracted In order to check the effectiveness of the extracted rules we tested the classification accuracy of the proposed method using the classifier with competition The average prediction accuracy is shown in Table V. The accuracy is defined in the following: if the traffic prediction result of the section at time t is "Low" and the real traffic of this section at time t is exactly "Low", then the accuracy is 100%. The low/middle/high accuracy means the accuracy when the real traffic is low/middle/high, respectively Table V shows that the method with Accuracy Validation can improve the overall accuracy than the method without Accuracy Validation. The Middle volume of the traffic network can not be predicted accurately because the middle situations do not appear frequently enough to generate an enough number of association rules TABLE V AVERAGE PREDICTION ACCURACY FOR TESTING DATABASE Method Prediction Accuracy Overall Low Middle High With Accuracy Validation 84.82 85.84 57.71 89.71 Without Accuracy Validation 82.64 83.57 56.57 87.13 Longer step prediction is explored by studying the 2-step, 3step and 4-step prediction, where n-step means the prediction of the traffic volume at n time points later. It's results are shown in Fig. 8. It is shown from Fig.8 that the prediction accuracy decreases as the number of prediction step increases but the increase of the number of steps does not affect the overall accuracy so much, so the proposed method can do relative stable prediction even if the number of prediction steps Increases The ratio of the usable rules to the total number of rules in each prediction step is shown in Fig.9, which describes that 


how the number of the usable rules for prediction decreases by the increase of the prediction steps, considering the condition that the time delay between the antecedent part and consequent part should be bigger or equal to the prediction step. In another word, as the prediction step increases, the number of the usable rules decreases 86 if G 84 82 80 f-------?-""":__---------1 0:: 78 r-------------">.-======---1 :? 76 -------------------j 74 72 4 n-6tep I?w ihAcCUlacyValiiarnn -w ihoutAcCUlacyValiiarnn I Fig. 8. Overall accuracy for 2-step, 3-step and 4-step prediction The proposed method cannot extract all the rules meeting the given definition of importance since it uses the fixed 2254 120 II 100 80 "'<Ie o 60 ?? ? 0: 40 20 0 N Step Fig. 9. Average percentage of usable rules for each prediction step number of rules for each class of the consequent attributes but the result shows that the ability to extract important rules is sufficient enough for the purposes. The mechanism of Accuracy Validation shows more stable performances as shown in Fig. 8 V. CONCLUSION In this paper, an association rule mining method using GNP with Accuracy Validation mechanism has been proposed. It is clarified from simulations that the proposed method can extract important time-related association rules for each class of the consequent attributes efficiently. What's more important is that these rules can be used to decide to which class the time related data belong accurately. From simulations, we have also 


found that the proposed method can be used in traffic volume prediction problems. Further improvements of the proposed method is studied in terms of applying the proposed method to real world navigation systems REFERENCES I Vehicle Routing and Congestion Predictions for Real-time Driver Guid ance, Transportation Research Records, 1408, Transportation Research Board, Washington D.C., pp. 66-74, 1993 2 October 17, 1989 3 network predictions, In Proc. of the Conference of Canadian Society of Civil Engineers, Sherbrooke, Quebec, June, pp. 331-339, 1997 4 dynamic traffic networks with joint route and departure time choice. In Proc. of the 84th Annual Meeting of the Transportation Research Board Washington, DC., 2005 5 Springer, 2002 6 Related Sequential Association Rule Mining and Traffic Prediction", In Proc. of the IEEE Congress on Evolutionary Computation 2009, 2009/5 7 gorithm: Genetic Network Programming\(GNP Reinforcement Learning", Evolutionary Computation, MIT press, Vol. IS No.3, pp.369-398, 2007 8 Multiagent Models Based on Symbiosis", IEEE Trans. on Syst., Man and Cybernetics - Part B -, Vol.36, No.1, pp.179-193, 2006 9 Deck Elevator Group Supervisory Control System Using Genetic Network Programming, IEEE Trans. on Systems, Man and Cybernetics, Part C, Vol 38, No. 4, pp. 535-550, 200817 10 University of Michigan Press, 1975 11] D. E. Goldberg, Genetic Algorithm in search, optimization and machine learning, Addison -Wesley, 1989 12 means of natural selection, Cambridge, Mass., MIT Press, 1992 13 Programs, Cambridge, Mass.: MIT Press, 1994 


14 Association Rules Mining with Attribute Accumulation Mechanism and its Application to Traffic Prediction", Journal of Advanced Computational Intelligence and Intelligent Informatics, Vol. 12, No. 5, pp. 467-478 200817 15 Information and Communication System", Vehicle Navigation and Infor mation Systems Conference, 1993 2255 


intend to expand this work to involve some interesting features in each stage prediction and evaluate it on many datasets   REFERENCES  1] F. Ricardo, N. Ana, M. Paula, B. Gleidson, R. Fabiano ODE: Ontology-based software Development Environment, Proceedings of the IX Argentine Congress on Computer Science, pp. 1124-1135, 2003 2] E. Mendes, B. A. Kitchenham. Further comparison of cross-company and within-company effort estimation models for Web applications. In: Proc. 10th IEEE International Software Metrics Symposium, Chicago USA, pp.348-357, 2004 3] B. Boehm, R. Valerdi. Achievements and Challenges in Software Resource Estimation, Proceedings of ICSE 06 Shanghai, China, pp. 74-83,  2006 4] K. Molokken, M. Jorgensen. A review of software surveys on software effort estimation, Proceedings of International Symposium on Empirical Software Engineering \(ISESE 2003 5] M. Jorgensen, K. Molokken-Ostvold. How large are software cost overruns? A review of the 1994 CHAOS report, Information and Software Technology, Vol. 48 issue 4. PP. 297-301, 2006 6] X. Huanga, D. Hob, J. Rena, L. F. Capretz. Improving the COCOMO model using a neuro-Fuzzy approach Applied Soft Computing, Vol.7, issue 1, pp. 29-40, 2007 7] L. Briand, T. Langley, I. Wieczorek. A replicated assessment and comparison of common software cost modeling techniques, Proceedings of the 22nd international conference on Software Engineering, 2000 8] S.-J Huang, N. H. Chiu. Optimization of analogy weights by genetic algorithm for software effort estimation Information and Software Technology, Vol. 48, issue 11 pp. 1034-1045, 2006 9] Z. Xu, T. M. Khoshgoftaar. Identification of Fuzzy models of software cost estimation, Fuzzy Sets and Systems, Vol. 145, issue 1, pp. 141-163, 2004 10] R. Pressman. Software Engineering: practitioner 


approaches, McGraw Hill, London, 2004 11] M. Boraso, C. Montangero, H. Sedhi. Software cost estimation: an experimental study of model performance Universita di Pisa, Italy, 1996 12] Y. Wang, Q. Song, J. Shen., 2007. Grey Learning Based Software Stage-Effort Estimation. International Conference on Machine Learning and Cybernetics, pp 1470-1475, 2007 13] S. G. MacDonell, M. J. Shepperd. Using prior-phase effort records for re-estimation during software projects Ninth International, Software Metrics Symposium, pp 73- 86, 2003 14] M .C Ohlsson, C. Wohlin. An Empirical Study of Effort Estimation during Project Execution, Sixth International Software Metrics Symposium \(METRICS'99 1999 15] N. H. Chiu,,S. J. Huang.  The adjusted analogy-based software effort estimation based on similarity distances Journal of Systems and Software, Vol. 80, issue 4, pp 628-640, 2007 16] P. Sentas, L. Angelis, I. Stamelos, G.  Bleris. Software productivity and effort prediction with ordinal regression Information and Software Technology, Vol. 47, issue 1 pp. 17-29, 2005 17] E. Mendes, N. Mosley. Comparing effort prediction models for Web design and authoring using boxplots Australian Computer Science Communications,  Vol. 23 Issue 1, pp. 125-133, 2001 18] E. Mendes, N. Mosley, I. Watson. A comparison of casebased reasoning approaches, Proceedings of the 11th international conference on World Wide Web, pp. 272280, 2002 19] Q. Zhao, S. S. Bhowmick. Association Rule Mining: A Survey  http://citeseer.ist.psu.edu/734613.html, 2003 20] S. Morisak, A. Monden, H. Tamada. An Extension of association rule mining for software engineering data repositories, Information Science Technical Report NAIST, 2006 21] Q. Song, M. Shepperd.  M. Cartwright, C. Mair. Software defect association mining and defect correction effort prediction, IEEE transaction on software engineering Vol. 32, No.2, pp. 69-82, 2006 


22] R. Agrawal, T. Amielinski, A. Swami. Mining association rule between sets of items in large databases Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 207-216, 1993 23] M-J. Huang, Y-L. Tsou, S-C. Lee.  Integrating Fuzzy data mining and Fuzzy artificial neural networks for discovering implicit knowledge, J. Knowledge-Based Systems, Vol.19 \(6 24] ISBSG International Software Benchmarking standards Group, Data repository release 10, Site http://www.isbsg.org, 2007 25] L. Zadeh. Toward a theory of Fuzzy information granulation and its centrality in human reasoning and Fuzzy logic. J. Fuzzy sets and Systems 90, pp. 111-127 1997 26] I. H. Witten, E. Frank. Data Mining: Practical machine learning tools and techniques, 2nd Edition, Morgan Kaufmann, San Francisco, 2005   256 


encountering a related term, i.e. IC\(c e intuition behind the use of the negative likelihood is that the more probable a term to appear, the less information it conveys. All these features show that Jiangs measure tends to be more general and more appropriate for evaluating nontaxonomically related terms. Indeed, a high score of the relatedness measures suggests a strong relationship between terms Nevertheless, all relatedness measures have limitations because they assume that all the semantic content of a particular term is modeled by semantic links in WordNet Consequently, in many situations, truly related terms obtain a low scores even though their belongings to a certain category of tags, e.g., jargon tags Additionally, when measuring the quality of an automatically knowledge acquisition results, the typical measures used in Information Retrieval are Recall, Precision and F-Measure. However, computing Recall and F-Measure requires the availability of a Gold Standard. Hence, we will only compute the Precision which speci?es to which extent the non-taxonomic relationships is extracted correctly. In this case, the ratio between the correctly extracted relations i.e., their relatedness measures is greater than or equal to a minimum threshold, and the whole number of extracted ones is computed. Thus, we have Precision Total correctly selected entities Total selected entities 12 http://search.cpan.org/dist/WordNet-Similarity 13 A term refers to a tag subject or a tag object C. Evaluation of non-taxonomic relationships Only a percentage of the full set of non-taxonomic relationships \(89 is caused by the presence of non standard terms which are not contained in WordNet and, in consequence, cannot be evaluated using WordNet-based relatedness measures. Fig. 5 depicts the evaluation results of the extracted non-taxonomic relationships against their relatedness measures High relatedness score \(88 17% of the extracted relationships, as most of terms are strongly related with respect WordNet Null Scores were obtained for 5% of the extracted 


relationships. Analyzing this case in more detail, we have observed that the poor score is caused in many situations by the way in which Jiangs distance metric works. This latter completely depends on the distance between two terms based on the number of edges found on the path between them in WordNet. In consequence this measure returns a value that does not fully represent reality. For example, on the one hand, Jiangs distance metric returns a null value for the relationship between insurance and car, even though the ?rst is a commonly related to the second, i.e., car involved insurance Finally with a minimal Jiangs distance metric threshold, set to 46%, the computed precision of correctly extracted relationships candidates is equal to 68.8 An example of extracted non-taxonomic relationships is depicted in Table V where each relation describes the subject tag, e.g., tool, the predicate, e.g is being developed within, and the object tag, e.g mesh. Fig. 4 represent a fragment output of the extracted ontological structure where each concept de?nes a set of similar and synonym tags and labels, i.e., mentions has been, revealed, caused and is created with describe the predicates of the non-taxonomic relationships between terms Due to the limitations observed by the automatic evaluation procedure and the lack of gold standards containing non-taxonomic relationships, we have examined the extracted non-taxonomic relationships from a linguistic point 377 Top space      distance     quad great     groovy nifty caused address      addresses extension      quotation   reference  references extensions        referenz     source      refrence sources    rfrences    quotations research    search     searching searchs open-source     open_source 


opensource linux aim     design     designer      designers patern    project     patterns     projekte projects web+design    web_design webdesign internet       internetbs net          web network      networking networks      web discussion     news       password word      words community      communities is_created_with mentions revealed has_been Figure 4. A fragment output of the extracted ontological structure of view. This qualitative evaluation can bring some interesting insights about the kind of results one can expect Invalid relations are extracted: Even though a relation such as music cities skill is considered as correct one since tag subject, tag object and predicate are correctly extracted. From a semantic point of view, this relation has no meaning. Hence, a higher precision is expected Figure 5. Summary of non-taxonomic evaluation measure Table V EXAMPLES OF EXTRACTED NON TAXONOMIC RELATIONSHIPS Subject Predicate Object search has been reference reference mentions search tool is being developed within mesh security added encoding search revealed reference java provides library by performing the sense analysis on complete relations An ambiguity in the extracted predicates between terms is observed: Hence, same relations are redundant since they use a synonym predicates between terms, e.g java provides library and java yields library. Thus we expect that the redundancy removal within extracted relations will be of bene?t for the improvement of the 


obtained results VI. CONCLUSION AND FUTURE WORK The extraction of non-taxonomic relationships from folksonomies is to the best of our knowledge is the least tackled task within ontology building from folksonomy. This is why there is a need of novel and general purpose approaches covering the full process of learning relationships. In this paper, we introduced a new approach called NONTAXFOLKS that starts by pre-processing tags aiming at getting a set of frequent tagsets corresponding to an agreed representation Then, they are used to retrieve related tags using external resources such as WordNet. Thanks to the particular structure of triadic concepts, it allows grouping semantically related tags by considering the semantic relatedness embodied in the different frequencies of co-occurences among users, resources and tags in the folksonomy. Thereafter we introduced an algorithm called NTREXTRACTION for extracting non-taxonomic relationships between pair of tags picked from the triadic concepts. In summary, our approach uses several well known techniques \(such as formal concept analysis or association rule discovering the social bookmaring environnement in order to propose a new way of extracting labeled non-taxonomic relationships between tags. Currently, we are investigating the following topic concerning the discovered predicates between two terms. Indeed, in order to avoid relationships redundancy and thus a redundancy in the builded ontology. One can try to classify them into prede?ned semantic classes, detect synonyms, inverses, etc. A standard classi?cation of verbs could be used for this purpose, adding additional information about the semantic content, e.g., senses, verb types, thematic roles, etc., of predicates relationships 378 REFERENCES 1] J. Pan, S. Taylor, and E. Thomas, Reducing ambiguity in tagging systems with folksonomy search expansion, in Proceedings of the 6th Annual European Semantic Web Conference \(ESWC2009 2] V. S. M. Kavalec, A. Maedche, Discovery of lexical entries for non-taxonomic relations in ontology learning, in Proceedings of the SOFSEM 2004, LNCS, vol. 2932, 2004, pp 249256 


3] L. Specia and E. Motta, Integrating folksonomies with the semantic web, in Proceedings of the 4th European Semantic Web Conference \(ESWC 2007 Innsbruck, Austria, vol. 4519, June 2007, pp. 624639 4] P. Mika, Ontologies are us: A uni?ed model of social networks and semantics, in Proceedings of the 4th International Semantic Web Conference \(ISWC2005 3729, Galway, Ireland, June 2005, pp. 522536 5] P. Schmitz, Inducing ontology from ?ickr tags, in Proceedings of the Workshop on Collaborative Tagging \(WWW 2006 Edinburgh, Scotland, May 2006 6] M. Zhou, S. Bao, X. Wu, and Y. Yu, An unsupervised model for exploring hierarchical semantics from social annotations, in Proceedings of the 6th International Semantic Web Conference and 2nd Asian Semantic Web Conference ISWC/ASWC2007 Korea, vol. 4825, November 2006, pp. 673686 7] C. Schmitz, A. Hotho, R. Jaschke, and G. Stumme, Mining association rules in folksonomies, in Proceedings of the 10th IFCS Conference \(IFCS 2006 2006, pp. 261270 8] A. Hotho, A. Maedche, S. Staab, and V. Zacharias, On knowledgeable unsupervised text mining, in Proceedings of Text Mining Workshop, Physica-Verlag, 2003, pp. 131152 9] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme, Information retrieval in folksonomies: Search and ranking, in The Semantic Web: Research and Applications, vol. 4011 Springer, 2006, pp. 411426 10] F. Lehmann and R. Wille, A triadic approach to formal concept analysis, in Proceedings of the 3rd International Conference on Conceptual Structures: Applications, Implementation and Theory. Springer-Verlag, 1995, pp. 3243 11] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G.Stumme Discovering shared conceptualizations in folksonomies Web Semantics: Science, Services and Agents on the World Wide Web, vol. 6, pp. 3853, 2008 12] A. Mathes, Folksonomies - cooperative classi?cation and communication through shared metadata, Graduate School of Library and Information Science, University of Illinois Urbana-Champaign, Tech. Rep. LIS590CMC, December 2004 13] H. Lin, J. Davis, and Y. Zhou, An integrated approach 


to extracting ontological structures from folksonomies, in Proceedings of the 6th European Semantic Web Conference ESWC 2009 vol. 5554, 2009, pp. 654668 14] M. Szomszor, H. Alani, K. OHara, and N. Shadbolt, Semantic modelling of user interests based on cross-folksonomy, in Proceedings of the 7th International Semantic Web Conference \(ISWC 2008 15] G.Begelman, P. Keller, and F.Smadja, Automated tag clustering: Improving search and exploration in the tag space, in Proceedings of the the Collaborative Web Tagging Workshop WWW 2006 16] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G. Stumme TRIAS - an algorithm for mining iceberg tri-lattices, in Procedings of the 6th IEEE International Conference on Data Mining, \(ICDM 2006 2006, pp. 907911 17] C. Borgelt, Ef?cient implementation of APRIORI and ECLAT, in FIMI, COEUR Workshop Proceedings, COEURWS.org, vol. 126, 2003 18] J. Tang, H. Leung, Q. Luo, D. Chen, and J. Gong, Towards ontology learning from folksonomies, in Proceedings of the 21st international jont conference on Arti?cal intelligence IJCAI 2009 20892094 19] L. Ding, T. Finin, A. Joshi, R. Pan, R. Cost, Y. Peng P. Reddivari, V. Doshi, and J. Sachs, Swoogle: A search and metadata engine for the semantic web, in Proceedings of the 13th ACM Conference on Information and Knowledge Management, ACM Press, 2004, pp. 652659 20] A. Hliaoutakis, G. Varelas, E. Voutsakis, E. Petrakis, and E. E Milios, Information retrieval by semantic similarity, International Journal on Semantic Web and Information Systems IJSWIS 21] G. Pirro, M. Ruffolo, and D. Talia, Secco: On building semantic links in peer to peer networks, Journal on Data Semantics XII, LNCS 5480, pp. 136, 2009 22] C. Meilicke, H. Stuckenschmidt, and A. Tamilin, Repairing ontology mappings, in Proceedings of the International Conference AAAI 2007, Vancouver, British Columbia, Canada 2007, pp. 14081413 23] S. Ravi and M. Rada, Unsupervised graph-based word sense 


disambiguation using measures of word semantic similarity in Proceedings of the International Conference ICSC 2007 Irvine, California, USA, 2007 24] H. G. A. Budanitsky, Semantic distance in wordnet: an experimental application oriented evaluation of ?ve measures in Proceedings of the International Conference NACCL 2001 Pittsburgh, Pennsylvania, USA, 2007, pp. 2934 25] J. Jiang and D. Conrath, Semantic similarity based on corpus statistics and lexical taxonomy, in Proceedings of the International Conference ROCLING X, 1997 379 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



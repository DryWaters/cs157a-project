An Efficient Private FIM On Hadoop MapReduce Trupti V. Kenekar Computer Engineering Department G.H.Raisoni Institute of Engi neering and Technology Pune, India trukenekar@gmail.com Prof.A.R.Dani Computer Engineering Department G.H.Raisoni Institute of Engi neering and Technology Pune, India ardani_123@rediffmail.com  Abstract The frequent item sets can provide valuable business and economic insights. It can be also be useful for research purposes. Privacy is also important for rapidly growing of unstructured non-numeric data whic h is referred as Big Data In mining this data objective is to handle such data sets efficiently and preserve privacy in case suc 
h large dataset contains sensitive information. Differential privacy is used to protect sensitive information of individual when data released. Proposed system uses non-numeric dataset. Proposed system performs initial processing on non-numeric dataset and finds frequent itemset Work is done for applicability of FIM techniques on MapReduce platform. Map Reduce is used to implement the parallelization of FP-growth algorithm, thereby improving the overall performance of FIM. The exp erimental results show that our proposed system is feasible and valid with good speedup and higher mining efficiency, and can meet the rapidly growing needs of frequent itemset mining fo r massive small files dataset Keywords— frequent itemset mining; differential privacy non-numeric dataset, Map Reduce I   I NTRODUCTION 
 Recently, developments in various areas such as technology science, user habits, businesses, etc. gave rise to creation and storage of massive amounts of data, so mining of such a big data has become more important for both businesses and academics. Already from the start, Frequent Itemset Mining FIM\been a vital part of data analysis and data mining FIM attempts to extract informati on from databases based on frequently occurring events, or a set of events. The events which occur frequently and satisfying   user defined minimum frequency threshold are referred as frequent itemset. Various techniques have been invented to mine databases for frequent events. These techniques work well in practice on general datasets In data mining, freque nt itemset mining is most important 
problem. The most widely used method to find frequent itemset are Apriori and FP-Growth. Apriori algorithm which generates candidate set for mining frequent patterns and FPGrowth which mine frequent patterns without candidate generation. In frequent itemset mining algorithm, we take input as a dataset which contains of the transactions by a group of individuals, and al gorithm output gives frequent itemsets. This can create privacy concern in case data set contains sensitive data —how can we be confident that publishing the frequent itemsets in the dataset does not reveal private information about the i ndividuals whose data is being 
studied? This problem is compounded by the fact that we may not even know what data the individuals would like to protect nor what background informa tion might be possessed by an adversar These com p oundi ng factors are exactly the one s addressed by differential privacy c h guara ntees that the existence of an individual’s data in a dataset does not reveal much about that individual In view of that, this paper explores the possibility of developing differentially private frequent itemset mining algorithms 
The existing system is considering the problem of tradeoff between utility and privacy in designing a differentially private FIM algor ithm. The existing system does not deal with non-numeric data set. Privacy is also important for non-numeric dataset lik e health care data To solve this problem, proposed system uses PFP growth algorithm on non-numeric dataset As non-numeric data also increasing rapidly to deal with such large dataset we develop a time efficient differentially private FIM algorithm using Hadoop Map reduce. The processing of large data is made possible by using Map Reduce Proposed system has two phase preprocessing phase and mining phase. In preprocessing 
smart splitting method [1 s ed t o tran sfo r m th e d a tabase  which improves utility and privacy trade off and this preprocessing is performed only ones. In mining phase offset of information loss by splitting, a run time estimation method used to estimate actual support of itemset in original dataset and dynamic reduction method reduce amount of noise added to guarantee privacy duri   II  RELATED WORK  Many algorithms have been proposed for mining frequent itemset among these FP-growth and Apriori are most useful FP-Growth algorithm is faster The author C.Dw introduced ne w conce p t for achieving privacy called differen tial privacy. This new measure 
captures the risk to indivi dual record. The privacy problem occurred by involving in a data base. This technique used in various papers and it has been proved that it can achieve desired level of privacy. This measure can be useful in many cases where we need to achieve accurate information while satisfying the privacy of indi vidual can be provided while simultaneously ensuring ve ry high levels of privacy L. Bonomi and Xiong proposed 4  authors propose d  algorithm for frequent sequential patterns which privately mining together prefixes and substring patterns  2016 International Conference on Automatic Control and Dynamic Optimization Techniques \(ICACDOT I nternational Institute of Information Technology \(I²IT 978-1-5090-2080-5/16/$31.00 ©2016 IEEE 72 


 we specify the limit for length of transaction which ultimately improves utility-privacy tradeoff. Author proposed di fferentially private frequent itemset mining using Apriori algorithm by truncating transaction approach N. Li, W. Qardaji, D. Su, and perform ed  frequent itemset mining on tran sactional databases while satisfying differential privacy Author proposed PrivBasis approach. In this paper, basis se ts notation is used. Basis set is constructed privately and used it to find most frequent itemsets The property of basis set state that if itemset having frequency greater than basis is a subset of some basis. The result shows this approach works well for transactional database    authors introduced a framew ork for association rule mining from transactions containing of categorical items .for preserving privacy uniform randomization is used. To limit privacy breach author proposed classes of randomization operators. Formulae are also derived for support and its variance which recover itemset support from randomized dataset. They apply this algorithm on real dataset and present experimental result In author introduced Map Reduce Apriori algorithm based on hadoop map reduce referred as MRApriori. They have also implemented one phase and k-phase algorithm and compare it with MRApriori algorithm. Their experimental result shows that MRApriori is work well than existing onephase and k-phase algorith m on Hadoop-Map Reduce programming model on hadoop platform W.K.Wong, D.W. Cheung, E. Hung, B. Kao, and N Mamoulis [13 ate that frequent item s ets m i n i ng using association rule mining is expensive task. If we outsource this task then it became less costly and less computational resources are required .In some cases mining may give inaccurate results due to human error or if a service providers can’t be completely trusted or are malicious. So to overcome the problem of database integr ity author introduced audit environment. This audit environment has two methods database transformation method and result verification method This gives accuracy of mining result. The main technique used in this environment is an artificial itemset planting \(AIP technique. Authors show guaran tee about the correctness of verification method. This technique is operational and efficient III  K EY CONCEPTS  In this section, key concepts such as differential privacy sensitivity, smart splitting and run time estimation are discussed with help of mathematical expression  1  Differential Privacy Differential Privacy is important concept which provides strong theoretical guarantees about preserving privacy of individual data and has been used by many researchers We have used PFP algorithm for finding private frequent item set which has satisfied differential privacy defined   2  Sensitivity Sensitivity is defined as if gi ven q count queries Q, for any neighboring databases D, D    Q = max ||Q \(D\– Q \(D 1  For all D, D differ in at most one element  3  Sm In this, transactions should be split rather than truncated. That is, we transform the database by dividing long transactions into multiple subsets \(i.e., su b-transactions\each of which meets the maximal length constraint. Here, we have performed weighted splitting operation. In weighted splitting operation transaction T is divided in subset of transaction such as  and weight is assigned to each transaction and it is checked if the length of each transaction satisfies the given length constraint  4  Run Time Estimation Run time Estima m e thod is pe rf or m e d in two st eps  based on the noisy support of an itemset in transformed database, first actual support in transformed database is estimated and then second furthe r its actual support in original database is computed IV  P ROPOSED SYSTEM  To find frequent itemset from big data and maintain privacy for such unstructured non-numeric data is challenging task. Here we propose an efficient proce ss, namely used Hadoop, for parallel processing on high utility item sets  Hadoop Map Reduce can be app lied to significantly larger datasets than traditional servers can handle – a large server farm can use MapReduce to sort a petabyte of data in only a few hours. The parallelism also offers some possibility of recovering from partial failure of servers or storage during the operation: if one mapper or reducer fails, the work can be rescheduled – assuming the input data is still available  In many applications there is need to process unstructured non-numeric data for that we need to find frequent itemset. Our propose system deals with such situation by performing frequent itemset mining on non-numeric dataset which is in the form of text or string. Basically we are applying the algorithm on non-numeric dataset Our main contribution is we are performing preprocessing on non-numeric dataset and converting that dataset into numeric so we can construct compact data structure named FP-tree for that dataset and we are extracting frequent itemset directly form FP-tree.  To improve performance Map Reduce is used In first stage we perform preprocessing on non-numeric dataset. In this step non numeric data is preprocessed using Hadoop Map Reduce and different Text Mining techniques Proposed system algorithm and architecture for preprocessing is discussed in next section 73 


A  Algorithm For Proposed System In this section, we have implemented our work using following algorithms that are defined below  1  Algorithm for preprocessing non-numeric dataset Input Nonnumeric dataset   D Step 1 take dataset D= {pt1, pt2, pt3  ptn Step2 apply extract word process EWi for D and extract words Step 3 For each EWi Stop Word SWi\ =EWi Stop word elimination process Stemming Si\ = SWi find exact word Step 4 For each Si Freq_Count WCi\ = Si for the total no. of occu rrences of each Stem Return Si Step 5: Tokens Si\ will be passed to system Step 6 word categoriz ation and selection End  Output Tokens, count \(i.e. .word, count  We apply this algorithm to non numeric dataset. For example take iPhone dataset which is large review data and we perform stop word, to st emming these operations on dataset and we get tokens \(words\uch as screen, display camera, size and other related features on the basis of that user select the iPhone and their occurrences i.e. count. In the next steps we finds items and store it into transformed dataset means now we have numeric dataset  that dataset it is send as input to actual PFP algorithm and finally we get private frequent itemset as output 2  FP growth Algorithm After implementation of preprocessing algorithm on nonnumeric dataset we performed frequent itemset mining using FP growth algorithm Input database D; the minimum support count threshold min sup Method 1  First we scan the database D once then the set of frequent items F and their support counts are found Then, support coun t of F is sorted in descending order as L, the list of frequent items 2  Second, create the root of an FP-tree, and tag it as null 3  The FP-tree is mined by calling FP growth \(FP tree null\, which is implemented using method FP growth\(Tree  Output The complete set of frequent patterns  3  PFP Growth algorithm We are using PFP growth algorithm defined in providing privacy for non-numeric dataset. PFP algorithm consists of two phases preprocessing phase and mining phase In preprocessing phase smart transaction splitting technique is used for dividing long transaction into multiple subtransactions to improve utility In mining phase information loss due to splitting transaction is computed using run time estimation method  B  Architecture of proposed system The proposed system is specia lly designed for the large data System manages to deal with large data with the help of Hadoop. System Architecture of proposed system is shown below   Fig1.System Architecture  In first stage of project we are taking non-numeric dataset in form of text file and then we apply preprocessing algorithm on it as defined above. In Second stage, after converting nonnumeric to numeric and finding support or count for each word PFP algorithm has been applied on it to find private frequent item set Our proposed system consists of two phase preprocessing phase and mining phase so we are taking non-numeric dataset as input and passing it to preprocessing phase. In preprocessing phase, we comput e maximum length constraint enforced in the database. In this, smart splitting method is applied to transformed database. We are also assigning privacy budget then we add noise to support of item. The prepossessing phase is implemented only once. In mining phase, for specified threshold we privately find frequent itemsets. Run time estimation and dynamic reduction methods are also used in this phase to improve result quality. Privacy 74 


budget is divided into five portion In preprocessing  are used and in mining phase   All processing is done in parallel using hadoop map reduce which process large unstructu red non-numeric dataset in less time. After completion of these two phases we get the private frequent itemset C  Dataset In the experiments publicly availab le real dataset are used We worked on both dataset numer ic and non-numeric dataset Our input dataset must be in tex t file. Initially we had worked on numeric dataset. We used Retail Dataset and Accid e nt  num eric dataset, iPhone Dataset and Book  er ic dataset an d som e publicly available text mining dataset as non-numeric dataset Following table shows Non-numeric Dataset used for analysis TABLE I Dataset Dataset Type Description Retail  Numeric datase t  Contains  transactions and Items Accident Numeric datase t  Contains transactions and Items iPhone Review Non-numeric Dataset Contains review for iPhones produc t Book Review Non-numeric Dataset Include b ook reviews  D  Experiment  Setup First, we implement PFP algorithm for numeric dataset in JAVA. We conduct all experiments on PC with Intel\(R\Core Tm\ 2 Duo.  Then we take non-numeric dataset as input and apply text mining techniques to covert it in numeric, extract frequent word   and its count so we can implement same PFP algorithm on it to find private frequent itemset All algorithm implement parallel using MapReduce  V  RESULT  A result of  the proposed system  is shown by comparing existing system performance. The first graph shows result for frequent itemset mining by cons idering different threshold values and the second graph shows when frequent itemset mining for non-numeric dataset implemented on hadoop map reduce  A  Graph for frequent itemset mining  In this, we use F-score measure for generating graphs the formula for calculating f-score and generated graph is shown below   Fig.6 The graph is created for frequent itemset mining in which Xaxis shows different threshold values and Y-axis shows F-score calculated. Result has been taken on various threshold values and calculated f-score for output frequent item sets   eas ure t h e utility of generated frequent itemset defined as follow  F-score   Where precision |U p  U c  U p recall |U p  U c  U c U p is the frequent itemsets generated by a private algorithm and U c is the actual frequent itemsets [1   B  Graph for frequent itemset generation time  Here, comparison graph for frequent item set mining on hadoop and without hadoop is shown below    Fig. 5 Graph for FIM on Hadoop an d without Hadoop In graph X Axis shows different threshold values and Y-axis shows time in milliseconds  CONCULSION  In this paper we have proposed differentially private frequent item set mining using map reduce to minimize the time required for privately mining large dataset. Map Reduce is used here which can handle huge size dataset without any problem. Existing systems pe rform private FP-growth for numeric dataset. As privacy is essential for non-numeric data so the proposed syst em considered the differentially private FIM algorithm for non-numeric dataset which can achieve good utility and good privacy  0 0.2 0.4 0.6 0.8 1 1.2 0.015 0.02 0.025 0.03 Exisitng Algorithm Proposed Algorithm 0 5000 10000 15000 20000 25000 0.015 0.02 0.025 Without Hadoop With Hadoop 75 


A C KNOWLEDGMENT  We would like to thanks all researchers for making their resources available. We would like to thanks to all the faculty members and Department of Computer Engineering GHRIET Pune, India for the guidance and cooperation R EFERENCES   1  Sen Su, Shengzhi Xu, Xiang Cheng, Zhengyi Li, and Fangchun Yang,“Differentially Private Frequent Itemset Mining via Transaction Splitting”, IEEE Transaction Vol.27, NO. 7, July 2015 2  C. Dwork, “Differential privacy”, in Proc. Int. Colloquium Automata, Languages Pr ogramm., pp.112, 2006 3  C. Zeng, J. F. Naughton, and J.-Y. Cai, “On differentially private frequent itemset mining,” Proc. VLDB Endowment, vol. 6, no. 1 pp. 25–36, 2012  4  L. Bonomi and L. Xiong, “A two-phase algorithm for mining sequential patterns with differential privacy”, in Proc. 22nd ACM Conf. Inf. Knowl. Manage., pp. 269278, 2013 5  N. Li, W. Qardaji, D. Su, and J. Cao, “Privbasis: Frequent itemset mining with differential privacy”, Proc. VLDB Endowment, Vol 5,No. 11, pp. 13401351, 2012 6  V.Singh and B.Saini, “ An Eff ective Tokenization Algorithm For Informatmtion Retrival System”, in First International Conference on Data Mining ,2014 7  E. Shen and T. Yu, “Mining frequent graph patterns with differential privacy”, in Proc. 12 th ACM SIGKDD Int. Conf Knowl. Discovery Data Mining, pp. 545553, 2013 8  R. Chen, G. Acs, and C. Castelluccia,“Differentially private sequential data publication via variable-length n-grams”, in Proc ACM Conf. Comput. Commun. Security, pp. 638649, 2012 9  A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke, “Privacy preserving mining of association rules”, in Proc. 8th ACM SIGKDD Int. Conf. Knowl. Disc overy Data Mining, pp. 217228 2002 10  O.YAHYA, O. HEGAZY and E. EZAT,” An Efficient Implementation of Apriori Algorithm Based on Hadoop MapReduce Model”, in International Journal of Reviews in Computing, 2012 11  X. Zhang, X. Meng, and R. Chen,“Differentially private setvalued data release against incremental updates”, in Proc. 18th Int. Conf Database Syst. Adv. Appl., pp. 392406, 2013 12  R. Chen, B. C. M. Fung, and B C. Desai, “Differentially private transit data publication:A case study on the montreal transportation system”, in Proc. 18th ACM SIGKDD Int. Conf.Knowl. Discovery Data Mining, pp. 213221, 2012 13  W. K. Wong, D. W. Cheung, E Hung, B. Kao, and N. Mamoulis Security in outsourcing of association rule mining,” in Proc. 33 rd  Int. Conf. Very Large Data Bases, 2007, pp. 111–122 14  W. K. Wong, D. W. Cheung, E Hung, B. Kao, and N. Mamoulis An audit environment for outsourcing of frequent itemset mining,” Proc. VLDB Endowment, vol. 2, no. 1, pp. 1162–1173 2009 15  A. Ghosh, T. Roughgarden, and M. Sundararajan, “Universally utility-maximizing privacy mechanisms”,SIAM J. Comput.,vol 41, no. 6, pp. 16731693, 2012 16  J. Vaidya and C. Clifton, “Privacy preserving association rule mining in vertically partitioned data”, in Proc. 8th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 639644, 2002 17  M. Kantarcioglu and C. Clifton Privacy-preserving distributed mining of association rules on horizontally partitioned data”, IEEE Trans. Knowl. Data Eng., Vol. 16, No. 9, pp. 10261037,Sep. 2004 18  Maurizio Atzori, F. Bonchi, F. Giannotti, and D. Pedreschi Anonymity preserving pattern discovery”, VLDB J., Vol. 17, No 4, pp. 703727, 2008 19   C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to sensitivity in private data analysis”, in Proc. 3rd Conf Theory Cryptography, pp. 265284, 2006 20  R. Chen, N. Mohammed, B. C. M Fung, B. C. Desai, and L Xiong, “Publishing set-valued data via differential privacy”, in Proc. Int. Conf. Very Large Data Bases, pp. 10871098, 2011 21  L. Sweeney, “k-anonymity: A model for protecting privacy”,Int. J Uncertainity Fuzziness Knowl.-Base Syst., Vol. 10, No. 5, pp 557570, 2002 22  J. Han, J. Pei, and Y. Yin,“M ining frequent patterns without candidate generation”, in Proc.ACM SIGMOD Int. Conf. Manage Data, pp. 112, 2000 23  A.Machanavajjhala,J.Gehrke,D.Kifer,andM. Venkitasubramaniam l-diversity: Privacy beyond k-anonymity,” in Proc. 22nd Int Conf. Data Eng., 2006 24  R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta,“Discovering frequent patterns in sensitive data”, in Proc. 16th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 503512, 2010 25  R.Agrawal and R.Shrikant ,”Fast algorithm for mining association rules”,in Proc.20 th Int.Conf.VLDB,1994 26  Frequent itemset mining dataset re http:// fimi.ua.ac.be/data, 2004 27  Frequent itemset mining Review Available http://jmcauley.ucsd.edu/data/amazon/links.html, 2016  76 


 Fig 7.4  T25I10D10K Dataset min sup=10 V  A PRIORI ON F LINK  In this section we use Apriori implementation on Flink platform to solve the commun ity detection problem. Finding communities in graph is one of the most important problems in graph mining. Size of graphs is growing too fast these days that single machine algorithms are not capable to handle such huge graph datasets. For example,  Facebook has over one million users and still growing at an impressive rate Therefore, finding communities in graph with one million nodes is not efficient with a single machine algorithm. There is a need of highly parallel dist ributed computing algorithms to handle such huge graphs   A E D C G F B  Graph 1. Social media user graph  Fig 8. \(a\tional Dataset for Graph 1 \(b\ms with total count \(c\nt items after Phase1 We used Apace Flink to provide a highly parallel computing environment for mining graph dataset for community detection. Flink support graph and iterative computing natively so it will be best for algorithm like Apriori. Finding communities in huge graphs is one of most challenging problems in graph mining. A community can be detected by finding possible c liques of various length in given graph. Apriori is one of best algo rithms to find cliques in such huge graphs. To find a clique of length n, we have to find frequent patterns of length n with minimum support n. For example, we have to find communities in graph 1 given below. We can easily make a transactional dataset for a undirected graph like Graph 1 by using its matrix representation Figure 8\(a\hows the transactional dataset for Graph 1 Every node in graph is taken as transaction ID and node with all its adjacent nodes is itemset for that node  Fig 9. \(a\ pairs after iteration 2 \(b\r iteration 3 \(c\sult after iteration 4 Apriori takes this transactio nal data as input and produces results as shown in  Figure 8\(b\er combining all occurrences of every item. Figure 8\(c\hows the singleton frequent items which have total count more than minimum support. Phase 1 of Flink based Apriori completes at Figure 8\(c  Fig 10. Using Flink based Apriori to find communities in large Dataset of BMS Candidate set is generated from singleton frequent items and total count for every itemset in candidate set is evaluated at 2nd iteration of Flink base d Apriori. Itemset having total count more than minimum support are marked as frequent figure 9\(a\Same procedure is repeated for iteration 3 and iteration 4. Figure 9\(b\and figure 9\(c\hows results for 2016 Intl. Conference on Advances in Computing, Communications and Informatics \(ICACCI 744 


iteration 3 and iteration 4 respectively. From results we can easily find out different possible cliques. An itemset of size 3 is frequent only if its all three nodes having an edge between them and an itemset of size 4 will be frequent if all four nodes have an edge between each other and so on. Therefore, max cliques possible for a set of nodes can be classified as a community. For example, graph 1 have 2 communities ABCD and EFG A large dataset of BMS web n al yzed by usi n g Flink based Apriori to find communities \(Figure 10 dataset contain many months click-stream data from two famous e-commerce web sites. Each transaction of these datasets is a web session consisting of all the products detail pages viewed in that particular session. Here every product page can be seen as a node of graph and a community will represent products pages which are traversed together. Flink based Apriori takes few minutes to analyze such a huge dataset with 77,532 transactions. The 2nd iteration is one of the most time and space consum ing iteration for distributed Apriori algorithm due to generation of a huge candidate set for singletone frequent items. For example, for 10 4 frequent singletons, it will generate nearly 10 8 candidate pairs. To map such a huge number of candidate pairs for every transaction is very time consuming. To gain further insite, it will be interesting to explore more datasets  VI  C ONCLUSION  A Flink based distributed Apriori is implemented to mine frequent patterns from huge graphs and large datasets. It uses basic Apriori theorem that an itemset is frequent only if all its non-empty sunset are frequent It is implemented on Apache Flink platform which provides it highly parallel and distributed computing environmen t. Flink is best suited for Apriori because Apache Flink ha ve native support for iterative computation and Apriori is iterative algorithm. Flink's pipelined architecture allow us to start a new iteration of Apriori as soon as partial results of earlier iteration are present. Delta iteration functionality of Flink makes Apriori highly parallel and effective algorithm for huge datasets Apriori is used to find co mmunities in huge graphs. In Summary, we have presented an implementation of Apriori on Flink and tested it with different datasets. We showed that Flink based Apriori is capable of handling huge graphs and large transactional datasets easily R EFERENCES  1  Anna L. Buczak and Christopher M. Gifford, “ Fuzzy Association Rule Mining for Community Crime Pattern Discovery,” In ISI-KDD 2010 ACM, USA, 2010 2  Apache hadoop. http://hadoop.apache.org/2013 3  Datasets. http://www.philippe-fournierviger.com/spmf/index.php?link datasets.php 4  FIMI Datasets. http://fimi.ua.ac.be/data 5  Hongjian Qiu, Rong Gu, Chunfeng Yuan and Yihua Huang, “YAFIM: A Parallel Frequent Itemset Mining Algorithm with Spark,” In 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops, 2014 6  Honglie Yu, Jun Wen and Hongmei Wang, “An Improved Apriori Algorithm Based On the Boolean Matrix and Hadoop,” In Int. Conf. on Advanced in Control Engineering and Information Science \(CEIS 2011 pp. 1827-1831 7  J. Dean and S. Ghemawat, “MapReduce: Simplified data processing on large clusters,” In Proc. OSDI. USENIX Association, 2004 8  J. Han, H. Pei and Y. Yin, “Mining Frequent Patterns without Candidate Generation,” In Proc. Conf. on th e Management of Data \(SIGMOD’00 Dallas, TX\ACM Press, New York, NY, USA 2000 9  Jian Guo, “Research on Improved Apriori Algorithm Based on Coding and MapReduce,” In 10 th Web Information System and Application Conference 2013, pp. 294-299 10  Lan Vu and Gita Alaghband, “Novel Parallel Method for Mining Frequent Patterns on Multi-core Shared Memory Systems,” In ACM conf Denver USA, 2013, pp. 49-54 11  Latifur Khan, Mamoun Awad and Bhavani Thuraisingham, “A new intrusion detection system using support vector machines and hierarchical clustering,” In VLDB Journal 2007 2007, pp. 507-521 12  Li N.,  Zeng L., He Q. & Shi Z, “Parallel Implementation of Apriori Algorithm Based on MapReduce,” In Proc. 13th ACIS Int. Conf Software Engineering, Artificial Intelligence, Networking and Parallel Distributed Computing \(SNPD ‘12 Kyoto, IEEE, 2012, pp. 236 241 13  Lin M., Lee P. & Hsueh S, “Apriori-based Frequent Itemset Mining Algorithms on MapReduce,” In Proc. 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC 12 ACM: Article No. 76, 2012 14  Lingjuan Li, Min Zhang. The Strategy of Mining Association Rule Based on Cloud Computing. In Proc. 2011 Int. Conf. Business Computing and Global Informatization \(BCGIN ‘11 DC, USA, IEEE 2011, pp. 475-478 15  Matei Zaharia, Mosharaf Chowdhury, Michael J. Franklin, Scott Shenker, Ion Stoica, “Spark: Cluster Computing with Working Sets,” In Proc. 2nd USENIX conf. on Hot topics in cloud computing, USENIX Association Berkeley, CA, USA, 2010 16  Mohammed J. Zaki, Srinivasan Parthasarathy, Mitsunori Ogihara and Wei Li, “New algorithms for fast discovery of association rules Technical Report 651, Computer Science Department, University of Rochester, Rochester, NY 14627. 1997 17  Ning Li, Li Zang, Qing He and Zhongzhi Shi, “Parallel Implementation of Apriori Algorithm Based on MapReduce,” In Int. Journal of Networked and Distributed Computing Vol. 1, No. 2 \(April 2013 89-96 18  R. Agrawal and R. Srikant, “Fast Algorithms for Mining Association Rules in Large Databases,” Research Report RJ9839, IBM Almaden Research Center, SanJose, California, June 1994 19  R. Agrawal and R. Srikant, “Fast algorithms for mining association rules,” In Proc. VLDB Santiago, Chile, 1994, pp. 487–499 20  Sanjay Rathee, ManoharKaul and ArtiKashyap, “ R-Apriori: An efficient Apriori based Algorithm on Spark,” In Proc. 24th Conference on Information Retrieval and Knowledge Management\(CIKM 2015 PIKM'15, Oct, 2015@ACM. doi: 10.1145/2809890.2809893 21  Tong Wang , Cynthia Rudin, Daniel Wagner and Rich Sevieri Learning to Detect Patterns of Crim e,” In Springer , MIT, USA, 2013 22  Apache Flink: https://flink.apache.org 23  Yang X.Y., Liu Z. & Fu Y., “MapReduce as a Programming Model for Association Rules Algorithm on Hadoop,” In Proc. 3rd Int.l Conf. on Information Sciences and Interaction Sciences \(ICIS ‘10 Chengdu China, IEEE, 2010, pp. 99 – 102 24  Yeal Amsterdamer Yeal Grossman,Tova Milo and Pierre Senellart Crowd Mining,” In SIGMOD'13, USA, 2013 25  Yeal Amsterdamer, Yeal Grossman, Tova Milo and Pierre Senellart CrowdMiner: Mining association Rules from the crowd,” In Proceedings of VLDB Endowment, 2013 26  Zahra Farzanyar and Nick Cercone, “Efiicient Mining of Frequent Itemsets in Social Network Data based on Mapreduce Framework,” In 2013 IEEE/ACM International Conference on Advances in Social Network Analysis and Mining 2013, pp. 1183-1188  2016 Intl. Conference on Advances in Computing, Communications and Informatics \(ICACCI 745 


    Fig. 8. Comparative Analysis Classification Algorithms V  CONCLUSION Associative Classification techniques are used to make better decision in critical situations. The proposed associative classification called as Classification of microarray gene expression data using associative classification and gene expression intervals used to clas sify the gene expression with gene intervals in affected gene expression. The experimental results are carried out by using the gene expression of breast cancer. The associative classification on gene expression data obtained the best prediction and accuracy of the classification result. The proposed algorithm was tested with two class and multi class data sets. The classification algorithm was compared with the classical classification algorithms such as Linear Discriminant Analysis, SVM, and Decision Tree. After the comparison of traditional classification algorithms, as per the view of possible error rates the Associative Classification algorithm is best for biological data. The results of this work are used to drug designer for cancer diseases. The proposed algorithm works on gene expression data. In future, it will be implemented on hadoop and big data mining for biological data VI  R EFERENCES  1   Morgan Kaufmann Publishers Elsevier 2002 2   Second Edition PicasetOy Helsinki, 2005 3  Nagata, K., Washio, T., Kawahara, Y. and Unami, A  prediction from toxicogenomic data based on class association rule  ELSEVIER journal Toxicology Reports, vol.41, no.10 pp. 1133-1142, 2014 4  Garcia, S., Luengo, J., Sáez, J. A., López, V. and Herrera, F survey of discretization techniques: Taxonomy and empirical  Knowledge and Data Engineering, IEEE Transactions vol. 25, no.4, pp.734-750, 2013 5  Alves,R., Rodriguez.B.D.S and Aguilar. R.J.S  analysis: a survey of frequent pattern mining from gene expression  Briefings in Bioinformatics 2009, vol.2, no.2, pp.210-224 6   Miner: Maximal Confident Association Rules Miner Algorithm for Up/Down Applied Mathematics and Information Sciences vol.8 no.2, pp.799-809, 2014 7    BMC Bioinformatics vol.19, no.1, pp.7986, 2003 8  Snousy, A. M. B., El-Deeb, H. M., Badran, K. and Al Khlil, I. A  based classification algorithms on cancer  Egyptian Informatics Journal vol.12 no.2 pp.73-82. 2011 9  Refaeilzadeh, P., Tang, L. and Liu, H   Encyclopedia of database systems, Springer US pp. 532-538 2009   R. Agrawal and R. Srikant, Fast Algorithms for Mining Association Rules Proceedings of the 20th Int. Conf. on Very Large Data Bases VLDB94\,475486, Santiago de Chile, Chile 1994   Alagukumar, S., and Lawrance R., "A Selective Analysis of Microarray Data Using Association Rule Mining Procedia Computer Science Vol.47, pp.3-12, 2015 doi:10.1016/j.procs.2015.03.177   Alagukumar  Cancer Data Analysis Using Frequent Pattern Mining and Gene  International Journal of Computer Applications ISSN 0975 8887, no.1, pp.9-14, June 2015   Pasquier, N., Bastide, Y., Taouil, R., & Lakhal, L Pruning closed itemset lattices for association rules  In BDA'1998 international conference on Advanced Databases pp. 177-196. 1998   Giugno R, Pulvirenti A, Cascione L, Pigola G, Ferro A MIDClass: Microarray Data Classification by Association Rules and Gene Expression Intervals. Tang H, ed. PLoS ONE 2013;8\(8\:e69873. doi:10.1371/journal.pone.0069873   http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1379   Wang, Zuncai, et al. "The prognostic biomarkers HOXB13 IL17BR, and CHDH are regulated by estrogen in breast cancer Clinical Cancer Research 13.21 pp. 6327-6334, 2005    cancer progression and host polymorphisms in the chemokine system: role of the macrophage chemoattractant protein-1 \(mcp 2518 g allele Clinical Chemistry 51: 452 5.2005   Dash, Rajashree, Rajib Lochan Paramguru, and Rasmita Dash Comparative analysis of supervised and unsupervised discretization techniques." International Journal of Advances in Science and Technology 2.3 \(2011\: 29-37   0 10 20 30 40 50 60 70 80 90 100 LDA SVM Decision Tree CACGE Accuracy and Error rate Classification Algorithms Accuracy Error Rate 


on items contained in each item group When the number of pivots increases the entire database is split into a ner granularity and the number of partitions increase correspondingly Such a ne granularity leads to a reduction in distance computation among transactions On the other hand when the pivot number k continues growing the number of transactions mapped into one hash bucket signiÞcantly increases thereby leading to a large candidate-object set and high shufßing cost see Figs 3b and 3c Consequently the overall execution time is optimized when k is 60 for both algorithms see Fig 3a 6.2 Minimum Support Recall that minimum support plays an important role in mining frequent itemsets We increase minimum support thresholds from 0.0005 to 0.0025 percent with an increment of 0.0005 percent to evaluate the impact of minimum support on FiDoop-DP The other parameters are the same as those for the previous experiments Fig 4a shows that the execution times of FiDoop-DP and Pfp decrease when the minimum support is increasing Intuitively a small minimum support leads to an increasing number of frequent 1-itemsets and transactions which have to be scanned and transmitted Table 2 illustrates the size of frequent 1-itemsets stored in FList and the number of nal output records of the two parallel solutions under various minimum-support values Fig 4a reveals that regardless of the minimum-support value FiDoop-DP is superior to Pfp in terms of running time Two reasons make this performance trend expected First FiDoop-DP optimizes the partitioning process by placing transactions with a high similarity into one group rather than randomly and evenly grouping the transaction Fig 4b conÞrms that FiDoop-DPÕs shufßing cost is signiÞcantly lower than that of Pfp thanks to optimal data partitions offered by FiDoop-DP Second this grouping strategy in FiDoop-DP minimizes the number of transactions for each GList under the premise of data completeness which leads to reducing mining load for each Reducer The grouping strategy of FiDoop-DP introduces computing overhead including signature-matrix calculation and hashing each band into a bucket Nevertheless such small overhead is offset by the performance gains in the shufßing and reduce phases Fig 4a also shows that the performance improvement of FiDoop-DP over Pfp is widened when the minimum support increases This performance gap between FiDoop-DP and Pfp is reasonable because pushing minimum support up in FiDoop-DP lters out an increased number of frequent 1-itemsets which in turn shortens the transaction partitioning cost Small transactions simplify the correlation analysis among the transactions thus small transactions are less likely to have a large number of duplications in their partitions As a result the number of duplicated transactions to be transmitted among the partitions is signiÞcantly reduced which allows FiDoop-DP to deliver better performance than Pfp 6.3 Data Characteristic In this group of experiments we respectively evaluate the impact of dimensionality and data correlation on the performance of FiDoop-DP and Pfp by changing the parameters in the process of generating the datasets using the IBM Quest Market-Basket Synthetic Data Generator 6.3.1 Dimensionality The average transaction length directly determines the dimensions of a test data We conÞgure the average transaction length to 10 40 60 and 85 to generate T10I4D 130 blocks T40I10D 128 blocks T60I10D 135 blocks T85I10D 133 blocks datasets respectively In this experiment we measure the impacts of dimensions on the performance of FiDoop-DP and Pfp on the 8-node Hadoop cluster The experimental results plotted in Fig 5a clearly indicate that an increasing number of dimensions signiÞcantly raises the running times of FiDoop-DP and Pfp This is because increasing the number of dimensions increases the number of groups thus the amount of data transmission sharply goes up as seen in Fig 5b The performance improvements of FiDoop-DP over Pfp is diminishing when the dimensionality increases from 10 to 85 For example FiDoop-DP offers an improvement of 29.4 percent when the dimensionality is set to 10 the improvement drops to 5.2 percent when the number of dimensions becomes 85 In what follows we argue that FiDoop-DP is inherently losing the power of reducing the number of redundant transactions in high-dimensional data When a dataset has a low dimensionality FiDoop-DP tends to build partitions Fig 4 Impact of minimum support on FiDoop-DP and Pfp TABLE 2 The Size of FList and the Number of Final Output Records Under Various Minimum-Support Values minsupport 0.0005 0.001 0.0015 0.002 0.0025 FList 14.69k 11.6k 9.71k 6.89k 5.51k OutRecords 745 588 465 348 278 XUN ET AL FIDOOP-DP DATA PARTITIONING IN FREQUENT ITEMSET MINING ON HADOOP CLUSTERS 109 


each of which has distinct characteristics compared with the other partitions Such distinct features among the partitions allow FiDoop-DP to efÞciently reduce the number of redundant transactions In contrast a dataset with high dimensionality has a long average transaction length therefore data partitions produced by FiDoop-DP have no distinct discrepancy Redundant transactions are likely to be formed for partitions that lack distinct characteristics Consequently the beneÞt offered by FiDoop-DP for highdimensional datasets becomes insigniÞcant 6.3.2 Data Correlation We set the correlation among transactions i.e corr to 0.15 0.25 0.35 0.45 0.55 0.65 and 0.75 to measure the impacts of data correlation on the performance of the two algorithms on the 8-node Hadoop cluster The Number of Pivots is set to 60 see also Section 6.1 The experimental results plotted in Fig 5c clearly indicate that FiDoop-DP is more sensitive to data correlation than Pfp This performance trend motivates us to investigate the correlation-related data partition strategy Pfp conducts default data partition based on equal-size item group without taking into account the characteristics of the datasets However FiDoop-DP judiciously groups items with high correlation into one group and clustering similar transactions together In this way the number of redundant transactions kept on multiple nodes is substantially reduced Consequently FiDoop-DP is conducive to cutting back both data transmission trafÞc and computing load As can be seen from Fig 5c there is an optimum balance point for data correlation degree to tune FiDoop-DP performance e.g 0.35 in Fig 5c If data correlation is too small Fidoop-DP will degenerate into random partition schema On the contrary it is difÞcult to divide items into relatively independent groups when data correlation is high meaning that an excessive number of duplicated transactions have to be transferred to multiple nodes Thus a high data correlation leads to redundant transactions formed for partitions thereby increasing network and computing loads 6.4 Speedup Now we are positioned to evaluate the speedup performance of FiDoop-DP and Pfp by increasing the number of data nodes in our Hadoop cluster from 4 to 24 The T40I10D 128 blocks dataset is applied to drive the speedup analysis of the these algorithms Fig 6 reveals the speedups of FiDoop-DP a nd Pfp as a function of the number of data nodes The experimental results illustrated in Fig 6a show that the speedups of FiDoop-DP and Pfp linearly scale up with the increasing number of data nodes Such a speedup trend can be attributed to the fact that increasing the number of data nodes under a xed input data size inevitably 1 reduces the amount of itemsets being handled by each node and 2 increases communication overhead among mappers and reducers Fig 6a shows that FiDoop-DP is better than Pfp in terms of the speedup efÞciency For instance the FiDoop-DP improves the speedup efÞciency of Pfp by up to 11.2 percent with an average of 6.1 percent This trend suggests FiDoopDP improves the speedup efÞciency of Pfp in large-scale The speedup efÞciencies drop when the Hadoop cluster scales up For example the speedup efÞciencies of FiDoopDP and Pfp on the 4-node cluster are 0.970 and 0.995 respectively These two speedup efÞciencies become 0.746 and 0.800 on the 24-node cluster Such a speedup-efÞciency trend is driven by the cost of shufßing intermediate results which sharply goes up when the number of data nodes scales up Although the overall computing capacity is improved by increasing the number of nodes the cost of synchronization and communication among data nodes tends to offset the gain in computing capacity For example the results plotted in Fig 6b conÞrm that the shufßing cost Fig 5 Impacts of data characteristics on FiDoop-DP and Pfp Fig 6 The speedup performance and shufßing cost of FiDoop-DP and Pfp 110 IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS VOL 28 NO 1 JANUARY 2017 


is linearly increasing when computing nodes are scaled from 4 to 24 Furthermore the shufßing cost of Pfp is larger than that of FiDoop-DP 6.5 Scalability In this group of experiments we evaluate the scalability of FiDoop-DP and Pfp when the size of input dataset dramatically grows Fig 7 shows the running times of the algorithms when we scale up the size of the T40I10D data series Figs 7a and 7b demonstrate the performance of FiDoop-DP processing various datasets on 8-node and 24-node clusters respectively Fig 7 clearly reveals that the overall execution times of FiDoop-DP and Pfp go up when the input data size is sharply enlarged The parallel mining process is slowed down by the excessive data amount that has to be scanned twice The increased dataset size leads to long scanning time Interestingly FiDoop-DP exhibits a better scalability than Pfp Recall that see also from Algorithm 1 the second MapReduce job compresses an initial transaction database into a signature matrix which is dealt by the subsequent process The compress ratio is high when the input data size is large thereby shortening the subsequent processing time Furthermore Fidoop-DP lowers the network trafÞc induced by the random grouping strategy in Pfp In summary the scalability of FiDoop-DP is higher than that of Pfp when it comes to parallel mining of an enormous amount of data 7R ELATED W ORK 7.1 Data Partitioning in MapReduce Partitioning in databases has been widely studied for both single system servers e.g and distributed storage systems e.g BigTable PNUTS[31 The existing approaches typically produce possible ranges or hash partitions which are then evaluated using heuristics and cost models These schemes offer limited support for OLTP workloads or query analysis in the context of the popular MapReduce programming model In this study we focus on the data partitioning issue in MapReduce High scalability is one of the most important design goals for MapReduce applications Unfortunately the partitioning techniques in existing MapReduce platforms e.g Hadoop are in their infancy leading to serious performance problems Recently a handful of data partitioning schemes have been proposed in the MapReduce platforms Xie et al  developed a data placement management mechanism for heterogeneous Hadoop clusters Their mechanism partitions data fragments to nodes in accordance to the nodes processing speed measured by computing ratios In addition Xie et al  designed a data redistribution algorithm in HDFS to address the data-skew issue imposed by dynamic data insertions and deletions CoHadoop is a H a d oop s lightweight extension which is designed to identify relateddataÞlesfollowedbyamodiÞeddataplacement policy to co-locate copies of those related les in the same server CoHadoop considers the relevance among les that is CoHadoop is an optimization of HaDoop for multiple les A key assumption of the MapReduce programming model is that mappers are completely independent of one another Vernica et al  broke such an assumption by introducing an asynchronous communication channel among mappers T his c hannel e nables the m appers to see global states managed in metadata Such situationaware mappers SAMs can enable MapReduce to exibly partition the inputs Apart from this adaptive sampling and partitioning were proposed to produce balanced partitions for the reducers by sampling mapper outputs and making use of obtained statistics Graph and hypergraph partitioning have been used to guide data partitioning in parallel computing Graph-based partitioning schemes capture data relationships For example Ke et al applied a graphic-execution-plan graph EPG to perform cost estimation and optimization by analyzing various properties of both data and computation Their estimation module coupled with the cost model estimate the runtime cost of each vertex in an EPG which represents the overall runtime cost a data partitioning plan is determined by a cost optimization module Liroz-Gistau et al proposed the MR-Part technique which partitions all input tuples producing the same intermediate key co-located in the same chunk Such a partitioning approach minimizes data transmission among mappers and reducers in the shufße phase The approach captures the relationships between input tuples and intermediate keys by monitoring the execution of representative workload Then based on these relationships their approach applies a min-cut k-way graph partitioning algorithm thereby partitioning and assigning the tuples to appropriate fragments by modeling the workload with a hyper graph In doing so subsequent MapReduce jobs take full advantage of data locality in the reduce phase Their partitioning strategy suffers from adverse initialization overhead Fig 7 The scalability of FiDoop-DP and Pfp when the size of input dataset increases XUN ET AL FIDOOP-DP DATA PARTITIONING IN FREQUENT ITEMSET MINING ON HADOOP CLUSTERS 111 


7.2 Application-Aware Data Partitioning Various efÞcient data partitioning strategies have been proposed to improve the performance of parallel computing systems For example Kirsten et al  developed two general partitioning strategies for generating entity match tasks to avoid memory bottlenecks and load imbalances Taking into account the characteristics of input data Aridhi et al proposed a novel density-based data partitioning technique for approximate large-scale frequent subgraph mining to balance computational load among a collection of machines Kotoulas et al built a data distribution mechanism based on clustering in elastic regions Traditional term-based partitioning has limited scalability due to the existence of very skewed frequency distributions among terms Load-balanced distributed clustering across networks and local clustering are introduced to improve the chance that triples with a same key are collocated These selforganizing approaches need no data analysis or upfront parameter adjustments in a priori Lu et al studied k nearest neighbor join using MapReduce in which a data partitioning approach was designed to reduce both shufßing and computational costs In LuÕs study objects are divided into partitions using a Voronoi diagram with carefully selected pivots Then data partitions i.e Voronoi cells are clustered into groups only if distances between them are restricted by a speciÞc bound In this way their approach can answer the k-nearest-neighbour join queries by simply checking object pairs within each group FIM for data-intensive applications over computing clusters has received a growing attention efÞcient data partitioning strategies have been proposed to improve the performance of parallel FIM algorithms A MapReducebased Apriori algorithm is designed to incorporate a new dynamic partitioning and distributing data method to improve mining performance This method divides input data into relatively small splits to provide exibility for improved load-balance performance Moreover the master node doesnÕt distribute all the data once rather the rest data are distributed based on dynamically changing workload and computing capability weight of each node Similarly Jumbo adopted a dynamic partition assignment technology enabling each task to process more than one partition Thus these partitions can be dynamically reassigned to different tasks to improve the load balancing performance of Pfp Uthayopas et al  investigated I/O and execution scheduling strategies to balance data processing load thereby enhancing the utilization of a multi-core cluster system supporting association-rule mining In order to pick a winning strategy in terms of data-blocks assignment Uthayopas et al incorporated three basic placement policies namely the round robin range and random placement Their approach ignores data characteristics during the course of mining association rules 8F URTHER D ISCUSSIONS In this study we investigated the data partitioning issues in parallel FIM We focused on MapReduce-based parallel FPtree algorithms in particular we studied how to partition and distribute a large dataset across data nodes of a Hadoop cluster to reduce network and computing loads We argue that the general idea of FiDoop-DP proposed in this study can be extended to other FIM algorithms like Apriori running on Hadoop clusters Apriori-based parallel FIM algorithms can be classiÞed into two camps namely count distribution and data distribution  For the count distribution camp each node in a cluster calculates local support counts of all candidate itemsets Then the global support counts of the candidates are computed by exchanging the local support counts For the data distribution camp each node only keeps the support counts of a subset of all candidates Each node is responsible for delivering its local database partition to all the other processors to compute support counts In general the data distribution schemes have higher communication overhead than the count distribution ones whereas the data distribution schemes have lower synchronization overhead than its competitor Regardless of the count distribution or data distribution approaches the communication and synchronization cost induce adverse impacts on the performance of parallel mining algorithms The basic idea of Fidoop-DPÑgrouping highly relevant transactions into a partition allows the parallel algorithms to exploit correlations among transactions in database to cut communication and synchronization overhead among Hadoop nodes 9C ONCLUSIONS A ND F UTURE W ORK To mitigate high communication and reduce computing cost in MapReduce-based FIM algorithms we developed FiDoop-DP which exploits correlation among transactions to partition a large dataset across data nodes in a Hadoop cluster FiDoop-DP is able to 1 partition transactions with high similarity together and 2 group highly correlated frequent items into a list One of the salient features of FiDoopDP lies in its capability of lowering network trafÞc and computing load through reducing the number of redundant transactions which are transmitted among Hadoop nodes FiDoop-DP applies the Voronoi diagram-based data partitioning technique to accomplish data partition in which LSH is incorporated to offer an analysis of correlation among transactions At the heart of FiDoop-DP is the second MapReduce job which 1 partitions a large database to form a complete dataset for item groups and 2 conducts FP-Growth processing in parallel on local partitions to generate all frequent patterns Our experimental results reveal that FiDoop-DP signiÞcantly improves the FIM performance of the existing Pfp solution by up to 31 percent with an average of 18 percent We introduced in this study a similarity metric to facilitate data-aware partitioning As a future research direction we will apply this metric to investigate advanced loadbalancing strategies on a heterogeneous Hadoop cluster In one of our earlier studies see for details we addressed the data-placement issue in heterogeneous Hadoop clusters where data are placed across nodes in a way that each node has a balanced data processing load Our data placement scheme can balance the amount of data stored in heterogeneous nodes to achieve improved data-processing performance Such a scheme implemented at the level of Hadoop distributed le system HDFS is unaware of correlations among application data To further improve load balancing 112 IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS VOL 28 NO 1 JANUARY 2017 


mechanisms implemented in HDFS we plan to integrate FiDoop-DP with a data-placement mechanism in HDFS on heterogeneous clusters In addition to performance issues energy efÞciency of parallel FIM systems will be an intriguing research direction A CKNOWLEDGMENTS The work in this paper was in part supported by the National Natural Science Foundation of P.R China No.61272263 No.61572343 Xiao QinÕs work was supported by the U.S National Science Foundation under Grants CCF-0845257 CAREER The authors would also like to thank Mojen Lau for proof-reading R EFERENCES  M J Zaki Parallel and distribu ted associat ion mining A survey IEEE Concurrency  vol 7 no 4 pp 14Ð25 Oct 1999  I Pramudiono and M Kitsuregawa  Fp-tax Tree structure based generalized association rule mining in Proc 9th ACM SIGMOD Workshop Res Issues Data Mining Knowl Discovery  2004 pp 60Ð63  J De an a n d S Gh e ma wa t M ap re du ce  S i mp l i e d da ta pr o ce s si n g on large clusters ACM Commun  vol 51 no 1 pp 107Ð113 2008  S Sakr A Liu and A G Fayoumi The family of mapred uce and large-scale data processing systems ACM Comput Surveys  vol 46 no 1 p 11 2013  M.-Y Lin P.-Y Lee and S.-C Hsueh Apriori-based frequent itemset mining algorithms on mapreduce in Proc 6th Int Conf Ubiquitous Inform Manag Commun  2012 pp 76:1Ð76:8  X Li n  Mr a pr io ri  As so ci a ti o n ru le s a lg o ri th m ba se d on mapreduce in Proc IEEE 5th Int Conf Softw Eng Serv Sci  2014 pp 141Ð144  L Zhou Z Zhong J Chang J Li J Huang and S Feng Balanced parallel FP-growth with mapreduce in Proc IEEE Youth Conf Inform Comput Telecommun  2010 pp 243Ð246  S Hong Z Huaxuan C Shiping and H Chunyan The study of improved FP-growth algorithm in mapreduce in Proc 1st Int Workshop Cloud Comput Inform Security  2013 pp 250Ð253  M Riondato  J A DeBrabant R Fonseca and E Upfal Parma A parallel randomized algorithm for approximate association rules mining in mapreduce in Proc 21st ACM Int Conf Informa Knowl Manag  2012 pp 85Ð94  C Lam Hadoop in Action  Greenwich USA Manning Publications Co 2010  H Li Y Wang D Zhang M Zhang and E Y Chang PFP Parallel FP-growth for query recommendation in Proc ACM Conf Recommender Syst  2008 pp 107Ð114  C Curino E Jones Y Zhang and S Madden Schism A workload-driven approach to database replication and partitioning Proc VLDB Endowment  vol 3 no 1-2 pp 48Ð57 2010  P Uthayop as and N Benjamas Impact of i/o and execution scheduling strategies on large scale parallel data mining J Next Generation Inform Technol  vol 5 no 1 p 78 2014  I  P r a m u d i o n o a n d M  K i t s u r e g a w a  P a r a l l e l F P g r o w t h o n P C cluster in Proc.Adv.Knowl.DiscoveryDataMining  2003 pp 467Ð473  Y Xun J Zhang and X Qin Fidoop Parallel mining of frequent itemsets using mapreduce IEEE Trans Syst Man Cybern Syst  vol 46 no 3 pp 313Ð325 Mar 2016 doi 10.1109 TSMC.2015.2437327  S Owen R Anil T Dunning and E Friedman Mahout Action  Greenwich USA Manning 2011  D Borthakur  Hdfs architecture guide HADOOP APACHE PROJECT Available  http://hadoop.apache.org/common/docs current/hdfs design.pdf 2008  M Zaharia M Chowdhury M J Franklin  S Shenker and I Stoica Spark Cluster computing with working sets in Proc 2nd USENIX Conf Hot Topics Cloud Comput  2010 p 10  W Lu Y Shen S Chen and B C Ooi EfÞcient proces sing of k nearest neighbor joins using mapreduce Proc VLDB Endowment  vol 5 no 10 pp 1016Ð1027 2012  T Kanung o D M Mount N S Netanya hu C D Piatko R Silverman and A Y Wu An efÞcient k-means clustering algorithm Analysis and implementation IEEE Trans Pattern Anal Mach Intell  vol 24 no 7 pp 881Ð892 Jul 2002  A K Jain Data clustering 50 years beyond k-means Pattern Recog Lett  vol 31 no 8 pp 651Ð666 2010  D Arthur and S Vassilvitskii  k-means  The advantages of careful seeding in Proc 18th Annu ACM-SIAM Symp Discr Algorithms  2007 pp 1027Ð1035  J Leskovec A Rajaraman and J D Ullman Mining Massive Datasets  Cambridge U.K Cambridge Univ Press 2014  A Stupar  S Mich el and R Schen kel Rankred uceÐpr ocessin g k-nearest neighbor queries on top of mapreduce in Proc 8th Workshop Large-Scale Distrib Syst Informa Retrieval  2010 pp 13Ð18  B Bahmani A Goel and R Shinde EfÞcient distributed locality sensitive hashing in Proc 21st ACM Int Conf Inform Knowl Manag  2012 pp 2174Ð2178  R Panigrahy Entropy based nearest neighbor search in high dimensions in Proc 17th Annu ACM-SIAM Symp Discr Algorithm  2006 pp 1186Ð1195  A Z Broder M Charikar  A M Frieze and M Mitzenma cher Min-wise independent permutations J Comput Syst Sci  vol 60 no 3 pp 630Ð659 2000  L Cristofor ARtool Association rule mining algorit hms and tools 2006  S Agrawal V Narasayya  and B Yang Integrating vertical and horizontal partitioning into automated physical database design in Proc ACM SIGMOD Int Conf Manag Data  2004 pp 359Ð370  F Chang J Dean S Ghema wat W Hsieh D Wallach  M  Burrows T Chandra A Fikes and R Gruber Bigtable A distributed structured data storage system in Proc 7th Symp Operating Syst Des Implementation  2006 pp 305Ð314  B F Cooper R Ramakrishn an U Srivastava A Silberstein P Bohannon H.-A Jacobsen N Puz D Weaver and R Yerneni Pnuts Yahoo!Õs hosted data serving platform Proc VLDB Endowment  vol 1 no 2 pp 1277Ð1288 2008  J Xie and X Qin The 19th heterogenei ty in computing workshop HCW 2010 in Proc IEEE Int Symp Parallel Distrib Process Workshops Phd Forum  Apr 2010 pp 1Ð5  M Y Eltabakh Y Tian F  Ozcan R Gemulla A Krettek and J McPherson Cohadoop Flexible data placement and its exploitation in hadoop Proc VLDB Endowment  vol 4 no 9 pp 575 585 2011  R Vernica A Balmin K S Beyer and V Ercegovac Adaptive mapreduce using situation-aware mappers in Proc 15th Int Conf Extending Database Technol  2012 pp 420Ð431  Q Ke V Prabhakar an Y Xie Y Yu J Wu and J Yang Optimizing data partitioning for data-parallel computing uS Patent App 13/325,049 Dec 13 2011  M Liroz-Gis tau R Akbarinia D Agrawal E Pacitti  and P Valduriez Data partitioning for minimizing transferred data in mapreduce in Proc 6th Int Conf Data Manag Cloud Grid P2P Syst  2013 pp 1Ð12  T Kirsten L Kolb M Hartung A Gro H K  opcke and E Rahm Data partitioning for parallel entity matching Proc VLDB Endowment  vol 3 no 2 pp 1Ð8 2010  S Kotoulas E Oren and F Van Harmelen Mind the data skew Distributed inferencing by speeddating in elastic regions in Proc 19th Int Conf World Wide Web  2010 pp 531Ð540  L Li and M Zhang The strategy of mining associat ion rule based on cloud computing in Proc Int Conf Bus Comput Global Inform  2011 pp 475Ð478  S Groot K Goda and M Kitsuregawa  Towards improv ed load balancing for data intensive distributed computing in Proc ACM Symp Appl Comput  2011 pp 139Ð146  M Z Ashra D Taniar and K Smith ODAM An optimiz ed distributed association rule mining algorithm IEEE Distrib Syst Online  vol 5 no 3 p 1 Mar 2004 Yaling Xun is currently a doctoral student at Taiyuan University of Science and Technology She is currently a lecturer in the School of Computer Science and Technology Taiyuan University of Science and Technology Her research interests include data mining and parallel computing XUN ET AL FIDOOP-DP DATA PARTITIONING IN FREQUENT ITEMSET MINING ON HADOOP CLUSTERS 113 


Jifu Zhang received the BS and MS degrees in computer science and technology from the Hefei University of Tchnology China and the PhD degree in pattern recognition and intelligence systems from the Beijing Institute of Technology in 1983 1989 and 2005 respectively He is currently a professor in the School of Computer Science and Technology TYUST His research interests include data mining parallel and distributed computing and artiÞcial intelligence Xiao Qin received the PhD degree in computer science from the University of Nebraska-Lincoln in 2004 He is currently a professor in the Department of Computer Science and Software Engineering Auburn University His research interests include parallel and distributed systems storage systems fault tolerance real-time systems and performance evaluation He received the U.S NSF Computing Processes and Artifacts Award and the NSF Computer System Research Award in 2007 and the NSF CAREER Award in 2009 He is a senior member of the IEEE Xujun Zhao received the MS degree in computer science and technology in 2005 from the Taiyuan University of Technology China He is currently working toward the PhD degree at Taiyuan University of Science and Technology His research interests include data mining and parallel computing  For more information on this or any other computing topic please visit our Digital Library at www.computer.org/publications/dlib 114 IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS VOL 28 NO 1 JANUARY 2017 



A Data Stream Mining System Hetal Thakkar Barzan Mozafari University of California at Los Angeles  hthakkar barzan zaniolo  cs.ucla.edu Carlo Zaniolo Abstract On-line data stream mining has attracted much research interest but systems that can be used as a workbench for online mining have not been researched since they pose many difﬁcult research challenges The proposed system addresses these challenges by an architecture based on three main technical advances i introduction of new constructs and synoptic data structures whereby complex KDD queries can be easily expressed and efﬁciently supported ii an integrated library of mining algorithms that are fast  light enough to be effective on data streams and iii support for Mining Model De nition Language MMDL that allows users to deﬁne new mining algorithms as a set of tasks and ows Thus the proposed system provides an extensible workbench for online mining which is beyond the existing proposals for even static mining 1 Introduction On-line data stream mining plays a key role in growing number of real-world applications including network trafﬁc monitoring intrusion detection web click-stream analysis and credit card fraud detection Thus many research projects have recently focused o n designing fast mining algorithms whereby massive data streams can be mined with real-time response 10 4 13 7  S i m i l a rl y  man y res earch projects have also focused on managing the data streams generated from these applications 9 1 6 H o w e v e r  t h e problem of supporting mining algorithms in such systems has so far not received much research attention 12 This situation seems unusual since the need for a mining system for static data mining was immediately recognized 8 and has lead to systems such as Weka 5 a nd OLE D B f or DM 11  F u r th er m o r e  s tatic m i n i n g alg o r ith m s can also be written in procedural language using a cache mining approach that makes little use of DBMS essentials However online mining tasks cannot be deployed as stand-alone algorithms since they require many DSMS essentials such as I/O buffering windows synopses load shedding etc Clearly KDD researchers and practitioners would rather concentrate on the complexities of data mining tasks and avoid the complexities of managing data streams by letting the mining system handle them In short while mining systems are a matter of convenience for stored data they are a matter of critical necessity for data streams Thus this demo presents the SMM system namely Stream Mill Miner which is speciﬁcally designed to address this critical necessity Building such a syst em raises difﬁcult research issues which SMM solves through an architecture based on three main technical advances as follows  Extending recently developed DSMSs which are currently designed to only support simple queries to express complex mining queries  Integrating a library of mining algorithms that are fast  light enough to be effective on data streams and  Supporting a higher level mining language namely Mining Model Deﬁnition L anguage MMDL which allows deﬁnition of mining models that encapsulate related mining tasks and mining ows for ease-of-use and extensibility Thus SMM extends an existing DSMS namely Stream Mill with user-friendly high-level mining models that are implemented with a powerful SQL-based continuous query language namely Expressive Stream Language ESL ESL is an extension of SQL based on User Deﬁned Aggregates UDAs Therefore this demo presents the following key features and methods of SMM  Mining models and their use for online classiﬁcation clustering and association rule mining  Generic support for advanced meta concepts to improve accuracy of classiﬁers e.g ensembles and  Deﬁnition of mining algorithms consisting of multiple processing steps as mining ows in MMDL 2 High-Level Mining Models An on-line data stream mining system should allow the user to i deﬁne new mining models and ii uniformly invoke diverse set of built-in and user-deﬁned mining algorithms Existing solutions for static data mining do not allow i and simply focus on ii which results in a close system However online mining systems must provide an open framework since new on-line mining algorithms are constantly being proposed 10  S MM achi e v e s bot h o f t hes e goals via supporting MMDL as we discuss next SMM allows the user to deﬁne new mining models by specifying the tasks that are associated with the model For instance most classiﬁers will consist of two tasks learning and predicting whereas association rule mining consists of nding frequent patterns and deriving rules from them and so on Furthermore data cleaning and post-analysis steps can also be speciﬁed as tasks Finally the analyst 
2008 IEEE International Conference on Data Mining Workshops 978-0-7695-3503-6/08 $25.00 © 2008 IEEE DOI 10.1109/ICDM.Workshops.2008.94 987 
2008 IEEE International Conference on Data Mining Workshops 978-0-7695-3503-6/08 $25.00 © 2008 IEEE DOI 10.1109/ICDMW.2008.133 987 


can specify mining ows that connect these tasks to implement complex mining process such as ensemble based methods 13 4 T he model d eﬁnition speciﬁes the tables that are shared by different tasks of the model Thus different instances of the model will work on separate instances of these tables but the tasks of the same model instance share these tables Additionally the model deﬁnition associates a UDA with each individual task of the model as discussedinSection3 Example 1 deﬁnes a simple Naive Bayesian Classiﬁer NBC and creates an instance of this model type in MMDL In Example 1 the UDAs associated with the Learn and Classify tasks are LearnNaiveBayesian omitted due to space constraints and ClassifyNaiveBayesian Example 3 respectively Thus MMDL allows the users to create arbitrary mining models and instantiate them uniformly Once a mining model instance is created the user can then invoke different tasks of the model with a consistent syntax For instance Example 2 invokes the Learn task of the NBC instance created in Example 1 N ote we omit the discussion of the formal syntax here due to space constraints Example 1 Deﬁning A ModelType for an NBC CREATE MODEL TYPE NaiveBayesianClassiﬁer  SHAREDTABLES DescriptorTbl Learn  UDA LearnNaiveBayesian WINDOW TRUE  PARTABLES  PARAMETERS   Classify  UDA ClassifyNaiveBayesian WINDOW TRUE  PARTABLES  PARAMETERS     CREATE MODEL INSTANCE NaiveBayesianInstance AS NaiveBayesianClassiﬁer Example 2 Invoking the Learn task of the NBC Instance RUN NaiveBayesianInstance.Learn WITH TrainingSet In Example 2 the TrainingSet isassumedtohavethe same schema as expected by the UDA associated with the Learn task–the system checks this automatically Furthermore the RUN statement allows an additional USING clause to specify the par ameters required by the mining task The USING clause is omitted in Example 2 since there are no additional parameters However advanced mining algorithms can be customized with the USING clause as seen in Section 4 Next we discuss generic implementation of UDAs that are associated with these mining tasks 3 On-line Mining in SMM We use Na ve Bayesian Classiﬁer NBC as an example to explain generic implementation of on-line mining algorithms in SMM Before we move to data streams let us rst consider the situation where we want to learn an NBC over a static table such as that of Table 1 RID Outlook Temp Humidity Wind Play 1 Sunny Hot High Weak No 2 Sunny Hot High Strong Yes 3 Overcast Hot High Weak Yes       Table 1 The relation PlayTennis RID Column Value Dec 1 1 Sunny No 1 2 Hot No 1 3 High No 1 4 Weak No 2 1 Sunny Yes 2 2 Hot Yes 2 3 High Yes 2 4 Strong Yes     Table 2 Verticalized PlayTennis Relation Building an NBC from a table like this containing the training tuples only requires counting i the total number of tuples ii the number of t uples belonging to each class and iii the number of tuples belonging to each class for each column value pair This is also known as the descriptive phase These counts can be obtained with a set of SQL queries one for each attribute and they are stored in a table whereby the probability of the Yes and No decision for a new tuple is then obtained via simple mathematical computations However  repeating the computation of counts for each attribute is inefﬁcient and requires writing different queries for tables having different number of columns This problem is addressed by assuring genericity in SMM 3.1 Genericity Genericity is an important property provided by systems such as Weka and OLE DB for DM which allow their mining algorithms to be applied over arbitrary tables 12  Thus SMM also supports genericity via an approach similar to Weka namely verticalization SMM verticalizes input tuples into column/value pairs e.g the rst two tuples in Table 1 are represented by the eight tuples shown in Table 2 This verticalization is realized in SMM by user-deﬁned table functions Therefore tuples of any arbitrary schema are converted into this vertical format and processed through UDAs which specify arbitrarily complex tasks Thus we next discuss the support for these UDAs 3.2 UDAs Let’s assume that instead of a static table we want to classify a stream of tuples In this case a continuous query would be required to classify the incoming tuples However simple continuous queries are not enough to express many complex mining tasks Thus SMM supports UDAs and windows/slides over UDAs to express these complex 
988 
988 


queries efﬁciently Therefore the ClassifyNaiveBayesian UDA given in Example 3 classiﬁes test tuples based on the DescriptorTbl  built in the descriptive phase Example 3 NB Classiﬁcation Aggregate DescriptorTbl\(Col INT Val INT Dec INT  Count REAL  AGGREGATE ClassifyNaiveBayesian\(col INT  val CHAR\(10  CHAR\(3  TABLE pred\(dec INT tot REAL  INITIALIZE   INSERT INTO pred SELECT Dec abs\(log\(Count+1 FROM DescriptorTbl  ITERATE  UPDATE pred p SET tot  tot  SELECT abs\(log\(Count+1 FROM DescriptorTbl WHERE Val  val AND Col  col AND Dec  p.dec  TERMINATE  INSERT INTO RETURN SELECT p.dec FROM pred p WHERE NOT EXIST  SELECT  FROM pred p1 WHERE p1.tot  p.tot OR p1.tot  p.tot AND p1.dec  p.dec   The ClassifyNaiveBayesian UDA Example 3 sums up the probabilities of each outcome up on arrival of each vertical tuple in the INITIALIZE and ITERATE states These states essentially maintain a sum for each value-dec combination The TERMINATE state determines the most likely outcome based on the maintained sums  We note that the computation presented in ClassifyNaiveBayesian UDA is blocking since it only returns the outcome up on seeing the end of the stream in the TERMINATE state Therefore this UDA cannot be applied directly over data streams Therefore SMM extends standard SQL:2003 windows over UDAs as opposed to just built-in aggregates to convert the blocking UDAs to non-blocking ones Thus the ClassifyNaiveBayesian UDA is invoked as follows SELECT ClassifyNaiveBayesian\(Col Val OVER ROWS 4 PRECEDING SLIDE 5 FROM VerticalStream The ROWS 4 PRECEDING clause represents a window of 5 tuples including the current tuple Furthermore the SLIDE 5 clause instructs SMM to return results every 5 tuples In general such windows allow invocation of blocking UDAs over streams since the execution is constrained over the speciﬁed window The queries like the one above are called tumbling window queries since the slide size is greater than or equal to the window size  I n s uch cas es  SMM repeats the following computation over each tumbling window uniformly across arbitrary UDAs SMM executes INITIALIZE for the rst tuple ITERATE for the next window size 1 tuples and then TERMINATE since we reached the end of the window This processing is repeated from the next slide size window size tuples Thus in this case after INITIALIZE ITERATE is executed 4 times followed by TERMINATE The processing is then repeated from the next tuple since slide size  window size Therefore UDAs along with windows and slides naturally integrate online prediction Now we consider the case where the training set is also streaming A similar solution based on UDAs can be applied in this case which will enable the classiﬁer to continuously learn new concepts that appear in the training stream However the classiﬁer should also forget the old concepts which may reduce the accuracy of the classiﬁer Therefore a windowed approach is more suitable i.e a classiﬁer should be differentially maintained over a window of the training stream Indeed in data streams many functions similarly need to be computed differentially i.e without recomputing everything upon arrival/expiration of a tuple Therefore SMM allows the users to deﬁne windowed version of their UDAs where differential computation is declaratively speciﬁed via an additional EXPIRE state which is invoked onc e for each tuple expiring out of the window Due to space constraints we omit the detailed discussion of the windowed UDA that differentially maintains the statistics for an NBC using the EXPIRE clause Indeed UDAs along with different kinds of windows over them provide a great source of power and exibility to SMM Therefore the user can deﬁne arbitrarily complex mining models and support them with UDAs 4 New algorithms and methods While many on-line mining algorithms are integrated in SMM we only discuss Association Rule Mining ARM and ensemble based methods here due to space constraints 4.1 Association Rule Mining ARM The rst major task for ARM is the identiﬁcation of frequent patterns which has been the focus of many research efforts For instance the SWIM algorithm 10 d if f e r e n tially maintains frequent patterns over a large sliding window SWIM uses FP-tree data structure to compute/store frequent patterns whose frequencies are monitored with a fast veriﬁer i.e an algorithm based on conditional counting see 10 f o r d e n itio n o f veriﬁcation  An on-line mining system must integrate such new and advanced mining algorithms For instance Calders et al 3 propos ed an approach to incorporate ARM in relational databases through virtual mining views This approach proposed that a mining system should provide a set of mining views for ARM and that the system executes appropriate mining methods when these views are queried SMM adopts a similar appro ach that deﬁnes a built-in mining model for ARM as shown in Example 4 The model is again composed of two tasks one for frequent patterns mining and another for determining association rules from the set of frequent patterns Therefore these tasks represent a mining ow which can also be deﬁned in the mining 
989 
989 


model e.g ARMFlow in Example 4 Each mining ow has an input stream and an output stream INSTREAM and OUTSTREAM  respectively The analyst speciﬁes how the tasks of a mining model interconnect via intermediate streams e.g FrequentPatterns stream Other tasks such as cleaning and post-analysis can also be added to such ows Thus naive users do not require in-depth knowledge of each task and can simply invoke a mining ow that represents the complete mining process Example 4 ModelType for Association Rule Mining CREATE MODEL TYPE AssociationRuleMiner  SHAREDTABLES Sets FrequentItemsets  UDA FindFrequentItemsets WINDOW TRUE  PARTABLES FreqParams PARAMETERS support Int   AssociationRule  UDA FindAssociationRules WINDOW TRUE  PARTABLES AssocParams PARAMETERS conﬁdence Real   Flow ARMFlow  CREATE STREAM FrequentPatterns AS RUN FrequentItemsets ON INSTREAM  INSERT INTO OUTSTREAM RUN AssociationRules ON FrequentPatterns USING conﬁdence  0.60    CREATE MODEL INSTANCE AssociationRuleMinerInst AS AssociationRuleMiner In this case the UDAs associated with these tasks are implemented externally in C/C which enables integration of advanced algorithms such as SWIM The overhead of this integration is negligible based on our experiments 4.2 Ensemble Based Methods A core issue in online data mining is concept drift/shifts which are caused by the changes in the data distribution or underlying concept The problem has been studied in detail by 13 4 7 and e ns embl e b as ed met hods are p ropos ed as an effective solution These techniques essentially learn an ensemble of classiﬁers and use their accuracy on the training stream to improve the accura cy of nal classiﬁcation over the testing stream Thus it is imperative that such techniques are integrated in an on-line mining system SMM generically supports such techniques i.e these techniques can be applied over any arbitrary classiﬁer such as NBC decision tree classiﬁer etc Analysts can essentially deﬁne mining ows similar to the one deﬁned in Example 4 5 SMM Architecture SMM employs a client-server architecture where multiple clients may be connected to a single server The client simply sends user commands to the server The sever consists of 3 main components I/O scheduler IOS Query Scheduler QS and the compiler The IOS communicates with the clients and the data sources The QS is responsible for concurrently executing the queries Finally the compiler compiles user deﬁned entities such as UDAs queries run task statements etc to C/C code that is executable Figure 1 SMM Architecture 6Conclusion In this demo we will show a data stream mining system that goes beyond the existing solutions for even static mining by providing an extensible mining workbench We will also demonstrate integration of user deﬁned mining algorithms including advanced algorithms such as SWIM ensemble based methods etc in SMM using MMDL References 1 A  A r a su S  B ab u and J  W i dom C Q L  A l a nguage f o r c ontinuous queries over streams and relations In DBPL  2003 2 Y  B ai  H  T hakkar  C  L uo H  W a ng and C  Z ani o l o  A dat a stream language and system designed for power and extensibility In CIKM  2006 3 T  C a l d e rs B  G o e th a l s a n d A  P ra d o  In te g r a tin g p a tte rn mining in relational databases In PKDD  2006 4 F  C hu and C  Z ani o l o  F ast a nd l i ght boost i n g f or adapt i v e mining of data streams In PAKDD  volume 3056 2004  W eka 3  d at a m i n i n g w i t h open s ource machi n e l earni ng software in java http://www.cs.waikato.ac.nz 6 D  A badi et al  A ur or a A n e w model a nd ar chi t ect ur e f or data stream management VLDB Journal  2003 7 G eor g e F or man T ackl i n g c oncept d r i f t by t e mpor al i nductive transfer In SIGIR  pages 252–259 2006 8 T omasz I mi el i n ski a nd H e i kki Manni l a  A dat a base per s pective on knowledge discovery Commun ACM  1996 9 Y anN ei L a w  H a i xun W a ng and C ar l o Z a ni ol o D a t a models and query language for data streams In VLDB  2004  B Mozaf ari  H T h akkar  and C  Z ani o l o  V eri f yi ng and m i n ing frequent patterns from large windows over data streams In ICDE  2008 11 Z T a n g a n d e t a l Bu ild in g d a t a m in in g s o l u tio n s with OLE DB for DM and XML analysis SIGMOD Record  2005  H T h akkar  B Mozaf ari  and C  Z ani o l o  D esi gni ng an i n ductive data stream management system the stream mill experiences In Scalable Stream Processing Systems  2008  H  W a ng and e t a l  Mi ni ng concept dr i f t i n g d at a s t r eams using ensemble classiﬁers In SIGKDD  2003 
990 
990 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008 th em th is will b e v e ry help fu l to tar g et th e po ten tial  custom ers quickly   Last b u t  not l east  i m prope r cr oss s e l l i ng m a y l ead t o  antipathy of c u stom ers and lo wer cu sto m er 222 s satisfaction an d lo yalty [1 1  Hen ce, th e tar g et cu sto m ers an d  sale time  m u st b e co n s id ered carefu l ly wh en  u s i n g cro ss selling   Acco r d i n g t o t h e out put  of t h i s pape r  t h e i n t e rsect i on res u l t  of decisi on tre e and as sociatio n rule a n alysis is a reas ona ble t a r g et cu st om er g r o u p w h e n i m pl em ent i ng c r oss sel l i ng i s i n  the initial pha se. By that way  the success cha n ce of your cro s s sellin g wou l d b e greatly i m p r o v e d   Wh en m o v i ng to th e gradu a l ex ecu tio n of cro s s sellin g  t h e poten tial u s ers can be ext e nde d b a sed o n t h e u n i o n anal y s i s  resul t w h i c h c a n provi de m o re chance for t h e cross sel l i ng pol i c y   5.  Concl u si ons The precondition of successful cross selling is t o  id en tify t h e cro s s selling op portun ity In th is pap e r   we p r op o s e an inn o v a tiv e ap pro ach t o fo recast cro ss sellin g  o ppo rt u n ities in teleco mm u n icatio n s i n du stry b a sed  o n  com b ination of decision tree and a ssoci ation rule. T h e  prese n t e d a p pr oach i n v o l v es  t w o dat a m i ning t o ol s  o n e  i s  decision tree  to disc over t h e cha r acteristics of W A P us ers  an d th e o t h e r is asso ciation ru le, to i d en tify n e w serv ice or n e w serv ices mix wh ich is related to W A P  Su b s equ e n tly  th e com b i n at i on a n al y s i s of t h es e t w o t o ol s w a s pr o pos ed f o r id en tifying th e cro s s sellin g op portun ity The actu a l d a ta was u s ed to v a lid at e th e ef fectiv en ess of th e pro p o s ed app r o a ch and the res u lts showed t h at this a p proach can great ly im prove t h e accuracy rate of forec a sting and help t e l ecom m uni cat i ons ve nd or s m a ke cross sel l i ng p o l i c i e s ef fectively   References 1  Ezawa K. J. and Norton, S W., \223C onst r ucting b a yesian n e twork s to pred ict u n c o llectib le telecomm unica tions accounts 224 IEEE E xpe rt, Vol. 11 No. 5, pp.45-51, Oct  1996 2   Berson  A Smith S. and Th earling   K., Bu ild ing Data Min i n g  App licatio n s fo r C R M, McGraw-Hill New York, NY, 2000 3   Kapp ert, C. B. an d  Om ta, S W  F., \223Neural n e twork s  and b u si nes s  m odel i n g 212 a n ap pl i cat i o n of ne ural  m o d e lin g tech n i q u e s to pro s p ect p r ofilin g in t h e t e l ecom m uni cat i ons i n dust r y 224 P r oce e di ngs  of t h e 3 0 th Hawaii In tern atio n a l C o nferen ce on System Scien ces V o l. 5   pp 46 5 473 1 997  B e r r y  M J. A  an d Lino ff  G., Data Min i ng Techn i qu es Fo r Mark eting  Sales, an d Cu sto m er Supp or t, Jo hn  W iley & Son s  In c., N e w  Y o rk  1997 4 Kam kura W A Ram a swam i, S.N., and Sriv astav a   R.K., \223App lyin g laten t trait an alysis in th e ev alu a tion of p r os pect s f o r c r osssel l i ng of fi na nci a l  ser v i ces\224  In tern ation a l Jo urn a l of Research in Mark et in g  No 8 pp. 329-349, 1991  5   Paas, L Ku i j len  T., \223Acqu i sitio n p a ttern  an alysis for recogn izin g cro ss-sell opp ortu n ities in the fin a n c ial  services sector\224, J o urnal of Targeting, M easurem ent  and Anal y s i s for M a rket i ng, No. 3, pp. 230-240, 2001 6  Kn ott, A   Hay e s  A  a n d Neslin  S  A   223Nex t produ ct-to b u y m o dels for cro ss-sellin g ap p lication s 224, Jo urn a l o f  In teractiv e Mark et in g  Vo l 16   No. 3, pp. 59-75, 2002  7   Harrison T An sell, J., \223C u s to m e r reten t io n i n the in sur a n c e industr y: u s ing  surv iv al an alysis to  p r ed ict cro s s-selling o ppo rt u n ities\224 Jo urn a l o f  Finan c ial  Servi ces M a rket i ng, No. 3, pp. 229-239, 2002   8   H ugh es, and Ar thu r M., \223Str a t egi c dat a base m a rket i ng\224   Probus Publ i s hi ng, C h i cago, 1994 9   Agrawal, R an d R. Sri k an t, \223Fast algo rith m s for m i ni ng ass o ci at i on r u l e s\224 I n  Pr ocee di n g s of t h e 2 0 th  VLDB C onference, Sant i a go, C h i l e 1994   1 0   Sun Baoh ong, Sh i b o Li, an d Cath erin e Zhou  223\221Ada p tive\222 learning a n d \221proa c tive\222 custom er rel a t i ons hi p m a nagem e nt 224, Jou r nal of Int e ract i v e  M a rket i ng, No. 20, pp. 82-96, 2006  1 1  Ak q u ra M   T an d K Sri n ivasan. \223Cust o mer intim acy an d cro s s-sellin g strateg y 224 Man a g e m e n t Scien ce, Vo l 51, No.6, pp. 1007-1012, 2005     181 1 


F 1  10 F 2  11 F 3  12 F 4  13 P 1 P 2 P 3 P 4 P 16 P 15 P 14 P 13 F 5  14 F 6  15 F 7  16 F 8  17 P 5 P 6 P 7 P 8 P 12 P 11 P 10 P 9 Figure 5 Two rows mesh processors communication topology P 1 P 2 P 3 P 5 P 6 P 7 P 8 P 9 P 11 P 13 P 14 P 15 P 16 P 10 P 4 P 12 Figure 6 Mixture of chain and hypercube processor P i  p 2 p and so on Thus in order to transfer a part of its work the procesor P i needs a direct link-up to the processors P i 2 k p k 011 0  The architecture from Figure 6 provides a chanel for every comunication implied by the work spliting step 5 Conclusion and Future Work The idea of our new FIM parallel algorithm differs fundamentally of the well known Apriori algorithm Our algorithm determines step by step the frequent itemsets by enlarging the interval to which the individual items belong to unlike the Apriori algorithm at the beginning of every step increases the dimension of the new frequent itemsets by 1 Our algorithm uses a communication pattern known before algorithm start This is a very important issue because it allows hardware implementation for the processors communication pattern Another major advantage is that the set of the transactions can be distributed to processors prior to the beginning of the analysis In order to compare our algorithm with other FIM algorithms we will use a MPI framework which is in the nal stage of implementation At the end a grid service for association rule discovery problems will be carried out The processors workload allocation can still be improved This is one of the future objectives The distribution of the transactions between the processors will be also in focus 6 ACKNOWLEDGEMENT The Excellence Research Program through grant 74 CEEX-II03/31.07.2006  Academic Grid for Complex Applications GRAI has supported the research for this paper References  R  A gra w al and R Srikant F ast A lgorithms for Mining Association Rules in Large Databases Proceedings of the 20th International Conference on Very Large Data Bases  Santiago Chile September 1994 pp 487–499  M C raus A ne w a lgorithm f or association r ule d isco very Proceedings of the 9th International Symposium on Automatic Control and Computer Science Iasi,Romania November 2007  A Das A W K Ng and Y  K W oon Rapid a ssociation rule mining Proceedings of the tenth international conference on Information and knowledge management  ACM Press 2001 pp 474-481  J  Han J Pei and Y  Y i n Mining frequent patterns without candidate generations Proceedings of the International Conference on Management of Data ACMSIGMOD 2000  J S P ark M.S Chen and P  S Y u  An e f f ecti v e hash based algorithm for mining association rules Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data  M J Carey and D A Schneider Eds San Jose California 1995 pp 175186  A S a v esere E Omiecinski and S Na v a the An ef cient algorithm for mining association rules in large databases Proceedings of 20th International Conference on VLDB  1995  T  Shintani and M Kitsure g a w a Hash Based P arallel Algorithms for Mining Association Rules Proceedings of the 4th International Conference on Parallel and Distributed Information Systems PDIS 96 1996  P N T an M Steinbach and V  K u mar  Introduction to data mining  Addison Wesley 2005  M.J Z aki P arallel and Distrib u ted D ata Mining A Sur vey IEEE Concurrency Journal  7\(4 
170 


 Kluwer Academic Publishers Springer, New York 1st edition, 2001 14  S c h e f f e r   T   F i n d i n g  A s s o c i a t i o n  Ru l e s  t h a t  T r a de Support Optimally Against Confidence th The Elements of Statistical Learning self_care_guide/Urogenital/Postate%20Cancer.pdf  Accessed, 25 August, 2008 11  A g r a w a l   R  T   I m i e l i n s k i     A   S w a m i   M i n i n g  association rules between sets of items in large databases, In Proceedings of the 1993 ACM SIGMOD international conference on Management of data  The Netherlands 42 2001 61-95  Ordonez C Association rule discovery with the train and test approach for heart disease predictio n 207\226 216 12 001 13  H a s t i e   T    R  T i b s h i r a n i     J  H   F r i e d m a n   Proceedings of the 5th European Conference on Principles and Practice of Knowlege Discovery in Databases\(PKDD'01 IEEE Transactions on Information Technology in Biomedicine, 10\(2\, 2006. 334 \226 343 001 Freiburg, Germany : SpringerVerlag, 2001. 424-435 15  F l a c h   P  A     L a c h i c h e   N   Co n f i r m a t i o n g u i d e d  discovery of first-order rules with Tertius 10  P h a r m a c y   h t t p    w w w  p h a r m a c y  g o v  m y    


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 



2011 3 rd Conference on Data Mining and Optimization \(DMO  28-29 June 2011, Selangor, Malaysia   978-1-61284-212-7/11/$26.00\2512011 IEEE   An Efficient Mining of Transactional Data Using Graph-based Technique  Wael Ahmad AlZoubi, Khairuddin Omar, Azuraliza Abu Bakar Center for Artificial Intelligence Technology Faculty of Computer and Information Technology University Kebangsaan Malaysia Wael.alzoubi@yahoo.com, ko@ftsm.ukm.my, aab@ftsm.ukm.my 
  Abstract 
226 Mining association rules is an essential task for 
knowledge discovery. Past transaction data can be analyzed to discover customer behaviors such that the quality of business decision can be improved. The approach of mining association rules focuses on discovering large itemsets, which are groups of items that appear together in an adequate number of transactions. In this paper, we propose a graph-based approach DGARM\ generate Boolean association rules from a large database of customer transactions. This approach scans the database once to construct an association graph and then traverses the graph to generate all large itemsets. Practical 
evaluations show that the proposed algorithm outperforms other algorithms which need to make multiple passes over the database Keywords: Apriori, clustering, graph, rule mining I  INTRODUCTION  Data mining has high applicability in the retail industry. The effective management of business is extensively dependent on the quality of its decision making. Therefore, it is important to improve the quality of business decisions by analyzing past transaction data to discover customer purchasing behaviors. In order to support this analysis, a sufficient amount of transactions needs to be collected and 
stored in a database [1 Ea ch tran sac tio n i n th e d a tab a s e  consists of the items purchased in the transaction besides other information like transaction date and time, customer name, quantity, price, and other information. All what was taken in consideration is the set of items bought together in a transaction. Because the amount of these transactions\222 data can be very large, an efficient algorithm needs to be designed for discovering useful information from these huge transactional datasets.Mining frequent itemsets and association rules is a popular and well researched method for discovering interesting relations between variables in large databases s s o ci at i o n ru l e s  f i rs t  i n t rodu ced i n 1993 [3   
are used to identify relationships among a set of items in a database. These relationships are not based on inherent properties of the data themselves, but rather based on cooccurrence of the data items. Association rules are used to discover the relationships, and potential associations, of items or attributes among huge data h es e r u l e s can be  effective in uncovering unknown relationships, providing results that can be the basis of forecast and decision. They have proven to be very useful tools for an enterprise as it strives to improve its competitiveness and prosperity [4  Association rule mining in relational database management systems generally transforms the database into \(TID, item 
rules mining \(ARM problem is an NP Hard probl em because finding all frequent itemsets \(FIs\ng a minimum support results in a search space of 2 
m 
Any association rule will hold if its support and confidence are equal to or greater than the user specifi ed minimum support \(S\d confidence \(C association 
format, where TID stands for a unique transaction identifier and item stands for different items purchased by the customers. There will be multiple entries for a given transaction ID, because one transaction ID indicates purchase of one particular customer and a customer can purchase as many items as he/ she want which is exponential in 
where 
m 
as the consequent must be considered, ARM is computationally and I/O intensive. The number of rules grows exponentially with the number 
of items. Because data is increasing in terms of the dimensions \(number of items\ize \(number of transactions\he ma in attributes needed in an ARM algorithm is the ability to handle massive data stores Traditional algorithms cannot provide such this ability, in terms of the data dimension, size, or runtime performance 
m X 
is the number of itemsets fi nal s t ep i nvol ves gene rat i n g  strong rules having a minimum confidence from the frequent itemsets. It also includes generating and testing the confidence of all rules. Since each subset of 
for such large databases This paper proposes a new algorithm called \(DGARM\that employs both graph and clustering techniques to discover association rules. The graph technique reduces the database scans, while the clustering technique eliminates some candidate itemsets that cannot be frequent 
 on the proposed algorithm is presented. In Section 5 the analysis of the results is presented  
The rest of this paper is organized as follows. In Section 2 we provide an overview of work related to the association rule mining problem. In Section 3 we discuss the proposed DGARM. In Section 4, an example 


The proposed algorithm \(DGARM\ has two main advantages: one is the reduction of the database scans and the other is the elimination of candidate    978-1-61284-212-7/11/$26.00\2512011 IEEE    II  RELATED  WORK  Agrawal and Srikant proposed the Apriori association rule algorithm A p riori dis c overed m ean i n g f u l ite m s et s a n d  constructed association rules within large databases, but the generation of candidate itemsets needs to perform contrasts against the whole database, level by level, in the process of creating association rules. Performance is considerably affected, as the database is repeatedly scanned to contrast each candidate itemset with the database. After Agrawal et al. proposed the Apriori association rule, most association rules researchers have used Apriori-like candidate generation approaches, all of these methods focus on reducing the number of candidate itemsets, and therefore reducing the number of database scans. Han r op os ed a n o v e l  frequent-pattern tree \(FP-tree\tructure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and developed an efficient FP-tree based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent-pattern mining methods. Tsay and Chiang ed an ef f i ci e n t  cluster based association rule mining method \(CBAR\ for discovering the large itemsets, and the main characteristics are the following. CBAR only requires a single scan of the transaction database, followed by contrasts with the partial cluster tables. According to Tsay and Chiang, CBAR didn\222t only prune considerable amounts of data that leads to reducing the time needed to perform data scans and requiring less contrast, but also ensured the correctness of the mined results. The CBAR employed some efficient cluster tables to represent database D by a single scan of the database followed by contrasts with the partial cluster tables. Figure 1 gives the algorithmic form of CBAR                     III  DYNAMIC  GRAPH  OPTIMIZATION  AND  RULE  MINING  PROBLEM   itemsets of order 3 and above. Figure 2 presents an overview of DGARM algorithm steps, where k t j j M th transaction and 002 BV j is not less than the user-specified minimu m support, a directed edge from item i to item j is created. Also itemset i  j e 2-itemset is the total number of transactions        Figure 1: CBAR needs the contrasts with only partial cluster tables [4   A graphb ased approach to generate various types o f association rules from a large database of custome r transactions had been p ropos T h i s approach s can s  t h e database once to construct an association graph and the n traverses the graph to generate all large itemsets. The association graph construction \(AGC\ algorithm had bee n applied to construct an association graph to generate primitive association patterns [8  The AGC algorithm was described as following: For ever y two large items i and j such that i  j if the number of 1s i n bit vector of item i BV i t vector of item j BV j  BV i  is the 


DGARM\(int minsup G  F  k Ck = Gen-Candidate\(F k-1  for all transactions t do c.count F   c  c.count minsu p Answer F k  Build-Graph\(graph G, transaction t for each item i 003 004 005 005 005 005 005 006 004  C 1 set of all items for all transactions t    978-1-61284-212-7/11/$26.00\2512011 IEEE   t  do Construct a clustering table Scan the dataset only once Build undirected labeled graph  between items in t j  Let j 1  j  j 1  j  M  G = U G t  Merging all sub-graphs  No Figure 2: DGARM Steps The DGARM for mining association rules is presented in figure 3. The algorithm scans the database once to build a graph of items and a clustering-table. This scan is enough to find frequent 1-itemsets and frequent 2-itemsets. There is no need to generate candidate 2-itemsets and hence no need to scan the database to discover frequent 2-itemsets. After that DGARM works iteratively starting from frequent n the sense that frequent itemsets that are discovered in one iteration will be used as the basis to generate candidate itemsets in the next iteration. As will be described later, the candidate generation step is similar to that in the Apriori algorithm but here we employ clustering technique to eliminate some infrequent candidate itemsets                    k 1 t k k F 2 D  do C t subset\(C k t for all candidate c D  do Build-Graph\(G, t Cluster\(t, length\(t GraphFrequent\(G for \(k = 3 C 2-itemsets   C 


E[G minsup F F minsup F F t  do Clustering-table[i][n GraphFrequent\(graph G for each vertex v    978-1-61284-212-7/11/$26.00\2512011 IEEE   007 G2 e T3  A,C,D f\G  G1 007 G2 007 G3 V If \(count[v 005 003 007 005 005 003 005 003  do If \(count[e 1 1 2 2 t  do E[G V[G V[G i Count[i] = 1 for each 2-subset itemset e  e  Count[e] = 1 if \(there are similar vertices and edges Merge\(vertices and edges Cluster\(transaction t, int n for each item i   v  for each ed g e e   e   The Build-Graph algorithm build a complete undirected graph G  V  E sing all transaction in the database Initially, the graph G is the subgraph of the first transaction For each transaction t in the database, the algorithm build a complete undirected subgraph G t  V t  E t where V t is the set of all items in t and E t is the set of all edges between every 2subset itemsets in t A counter is associated with each vertex or edge that stores the occurrences of that vertex or edge and is initialized to 1. After building the subgraph G t a new version of graph G is created by merging G and G t If there are any similar vertices and edges between G t and G their counters are summed up. Figure 4 shows an example of three transactions and their sub graphs             G = G 1  G = G 2  Merging process G G  G 3  a\ \(b c d\ \(e Final graph f Figure 3: DGARM algorithm  A  1 A  1 D  1 B  2 C  2 2 1 1 1 1 1 A  1 D  1 C  1 1 1 1 A  2  D  2  B  2  C  3  2 2 1 1 2 2 D  1 B  1 C  1 1 1 1 1 1 1 B  1 C  1 1 1 A  1  D  1  B  2  C  2  11 1 1 1 Figure 4: \(a\ T1= {A, B, C, D}              \(b\ T2 = {B, C}               \(c\ Merging T1 and T2 d G  G1 003 007 007 007 


c if \( Test-Cluster\(a, k then return false return true Test-Cluster\(item a, int k Sum = 0 for 2],p 005 Gen-Candidate\(frequent set F F F 2]=q 1]<q 1  p[1], \205, p[k-1],q[k-1 If Not-Prune F k-1  Add to C k  Else delete  Not-Prune\(candidate itemset c, frequent set Fk-1 for all k-1-subset s c  do if \(s F k-1  return false for all item a  to do sum = sum + clustering-table   return sum  Figure 6: Gen candidate algorithm  1 do If\(p[1]=q[1], \205, p    978-1-61284-212-7/11/$26.00\2512011 IEEE   After all transactions have been read, the graph is built Vertices' counters hold the supports of the corresponding items. Edges' counters on the other hand hold the supports of the corresponding 2-subset itemsets. Finally, the function Graph-Frequent searches the graph to find frequent 1itemsets and frequent 2-itemsets. The function GraphFrequent traverses each vertex and edge in the graph, if the counter of a vertex is greater than or equal the minimum support then the corresponding item is inserted into the set of frequent 1-itemsets F 1 and if the counter of an edge is greater than or equal the minimum support then the corresponding 2-subset itemset is inserted into the set of frequent 2-itemsets F 2 In the clustering step, each transaction is clustered to the k th cluster, where the length of a transaction is k Meanwhile, a clustering table is built to count the occurrences of each item in each cluster. Figure 5 shows the clustering-table through reading the first three transactions shown in figure 4. Subsequently, the clusteringtable will be used in the candidate generation   01 A B C D   02 A B    03 A C D    C 1  C 2  C 3  C 4   C 1  C 2  C 3  C 4   C 1  C 2  C 3  C 4   A 0 0 0 1  A 0 1 0 1 A 0 1 1 1  B 0 0 0 1  B 0 1 0 1 B 0 1 0 1  C 0 0 0 1  C 0 0 0 1 C 0 0 1 1  D 0 0 0 1  D 0 0 0 1 D 0 0 1 1  a b c Figure 5: The clustering-table of \(a\ T1= {A, B, C, D} \(b\ T2 = {A, B} \(c\ T3 = {A, C, D     The Gen Candidate function takes as argument F k 1 the set of frequent k 1-itemsets, and returns the set of all candidate k itemsets. The function performs two steps, namely join step and prune step \(figure  6\. In the join step, two different k 1itemsets are joined to generate k itemset if their first k 2 items are common. In the prune step, two tests are performed. In the first test, all candidate itemsets, that have k 1-subset which is not in frequent k 1-itemsets, are deleted. In the second test, all candidate itemsets, that have an item such that the sum of occurrences of that item in cluster k to cluster m is less than the minimum support, are deleted                                                        C 1 is the cluster of length 1-transactions C 2 is the cluster of length 2-transactions; and so on 005 005 005 q k p k k k k k k c c c c i k m a i   005 1  for all itemset 1 do for all itemset 


   978-1-61284-212-7/11/$26.00\2512011 IEEE    IV  ASSOCIATION  RULE  GENERATION Once the frequent itemsets have been found, generating interesting association rules is a straightforward step Interesting association rules are the ones that satisfy the minimum support and the minimum confidence. The computing of support and confidence was mentioned in equation 1 and 2 in section 1. Figure 7 shows the algorithm for association rules generation              V  EXPERIMENTS This section introduces a comparison between our proposed DGARM algorithm and some association rules algorithms using different synthetic datasets. The association rules algorithms that we used in the comparison are Apriori [3 a nd F P gr o w t h  7 T he e xpe ri m e nt s w e r e  run on Pentium IV computer with a clock rate of 1600 MHz and 256 Mbytes of main memory. The dataset used in experiments is retail real dataset [9 t h a t  c o nsi s t s  o f 93438 transactions with an average size of 10. The size of the dataset is 1.5 MB Figure 8 shows the execution time of DGARM algorithm on retail dataset with different support thresholds. As the minimum support decreases, the execution time of DGARM increases due to an increase in the total number of candidate and frequent itemsets. The dataset used was T10I4D65K          Figure 9 shows the execution time of DGARM algorithm with different number of database transactions at min-sup  0.01%. As shown, the execution time scales quite linearly with the number of transactions from 9000 to 90000 To assess the performance of the clustering technique that aims to eliminate some candidate itemsets that cannot be frequent, we present in table 1 the number of candidate itemsets, the number of pruned candidate itemsets using our clustering technique, and the number of infrequent itemsets at each database pass, where minsup = 0.01               f s f support\(s support\(f minconf Add "s Generate-Rule\(float minconf for all frequent itemset do for all nonempty subset of do If f-s Figure 8: Execution time for DGARM at different minimum supports  Figure 9: Execution time for DGARM using different datasets sizes Fi g ure 7: Generate rule al g orith m 


   978-1-61284-212-7/11/$26.00\2512011 IEEE      As shown in table 1, the clustering technique deletes some candidate itemsets in database passes 3, 4 and 5. For example in pass 5, quarter of the candidate itemsets are deleted without being examined in the next pass A comparison between the proposed DGARM algorithm Apriori algorithm an d F P g row t h alg o rith m 7] h a d be e n  made using synthetic datasets  We used four synthetic datasets that were generated as described in [9  T h es e sy n t h e tic d a tase ts a r e w i d e ly u s ed f o r  evaluating association rules algorithms. Table 2 shows the names and descriptions of parameters used to generate the different datasets. For the four datasets used in the experiments N was set to 1000 and |L| was set to 2000       Figure 10 and figure 11 respectively show the execution time for the first two synthetic datasets T10I4D65K and T10I4D100K, respectively. It is easy to see that DGARM and FP-growth beat Apriori for all minimum supports. FP-growth is comparable with DGARM as the minimum support increases, but it scales much better than DGARM as the minimum support goes down because the number as well as the length of frequent itemsets increases dramatically               However, when we decrease the minimum support furthermore, FP-growth turns to be faster than DGARM. The reason behind this is that reducing the minimum support will produce a large number of frequent itemsets that requires DGARM to scan the database many times. Carrying out more experiments shows that the execution time using the synthetic dataset T40I10D100K. From this figure and as the minimum support reduces, one can notice that both FP-growth and Apriori algorithm are slower than DGARM. The reason behind this is that as the minimum support decreases the number of frequent itemsets increase. Thus, FP-tree has much more distinct itemsets and leads to larger FP-tree. Also, the running memory requirement of FP-growth is a mixture of the main memory and secondary memory. It has been noticed that the usage of the secondary memory degrades the performance of FP-growth VI  CONCLUSION Through the experiments, we have seen that the performance of the proposed DGARM algorithm is better than Apriori algorithm, especially, when the minimum support is reduced Also, extensive experiments have shown that a better Pass of candidate itemsets of pruned itemsets \(clustering technique of infrequent itemsets 1 199175 220 178170 2 19856 560 7593 3 3977 220 931 4 347 0 40 5 4 0 4  D Number of transactions  T  Average size of transactions  I  Average size of maximal potentially large itemsets  L  Number of maximal potentially large itemsets N Number of items T ABLE 2  P ARAMETERS  T ABLE 1  N UMBER OF ITEMSETS AT EACH DATABASE PASS Figure 11: Execution time using \(T10I4D100K\ synthetic dataset  Figure 10: Execution time using \(T10I4D65K\ synthetic dataset 


   978-1-61284-212-7/11/$26.00\2512011 IEEE   performance can be achieved than FP-growth, especially when the size of database is large  ACKNOWLEDGEMENT  This work has been supported by 01-01-02-SF0598 VII  REFERENCES  1  Show-Jane Yen and Arbee L.P. Chen. A Graph-Based Approach for Discovering Various Types of Association Rules. IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING VOL. 13, NO. 5, SEPTEMBER/OCTOBER 2001, pp. 839 \226 845 2  Petra Perner \(Ed.\. Advances in data mining, Medical Applications, ECommerce, Marketing, and Theoretical Aspects, Book. 8th industrial Conference, ICDM 2008, Leipzig, Germany, July 2008, p 192 3  R. Agrawal, R. Srikant, Fast algorithm for mining association rules in large databases, Proceedings of 1994 International Conference on VLDB, 1994 pp. 487\226499 4  Yuh-Jiuan Tsay, Jiunn-Yann Chiang. CBAR: an efficient method for mining association rules. Knowledge-Based Systems 18 \(2005\105 5  Peter P. Wakabi-Waiswa and Venansius Baryamureeba. Extraction of Interesting Association Rules Using Genetic Algorithms. International Journal of Computing and ICT Research, Vol. 2, No. 1, pp. 26 \226 33 6  Michael Hahsler Bettina Gr\374n Kurt Hornik. Introduction to arules - A computational environment for mining association rules and frequent item sets. Journal of Statistical Software. October 2005, Volume 14 Issue 15 7  Jiawei Han ,  Jian Pei ,  Yiwen Yin ,  Runying Mao. Mining Frequent Patterns without  Candidate Generation: A Frequent-Pattern Tree Approach. Data Mining and Knowledge Discovery, 8, 53\22687, 2004 8  S.J. Yen and A.L.P. Chen, An Efficient Approach to Discovery Knowledge from Large Databases, Proc. IEEE/ACM Int'l Conf. Parallel and Distributed Information Systems, pp. 8-18, 1996 9  Frequent itemset mining dataset repository. Available from URL http://fimi.cs.helsinki.fi/data/ 2010 10  Wael AlZoubi, Khairuddin Omar, Azuraliza Abu Bakar. Scalable and Efficient Technique for Mining Association Rules. 2009 International Conference on Electrical Engineering and Informatics. 5-7 August 2009 Selangor, Malaysia, pp. 36 41    


moments. Signal Processing : Image Communication, 16 :95100, 2000 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



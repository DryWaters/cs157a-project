html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Mining  Multi-Level Associations with Fuzzy Hierarchies Rafal A. Angryk  Department of Computer Science Montana State University Bozeman, MT 59717-3880, USA angryk@cs.montana.edu Frederick E. Petry EECS Department Tulane University New Orleans, LA 70118, USA fep@eecs.tulane.edu Abstract  In this paper we investigate application of fuzzy concept hierarchies to mining multi-level knowledge from large datasets via a well-known Attribute-Oriented Induction approach [1]. We analyze in detail the original process of fuzzy hierarchical induction and extend it with two new characteristics which improve applicability of the original approach to scientific data mining. These are a consistency of our fuzzy induction model, and an approximate drilling-down technique allowing a user to retrieve estimated explanations of the generated abstract concept. An application to discovery of multi-level association rules from environmental data stored in a Toxic Release Inventory is presented I. INTRODUCTION The need for generalization mechanisms has been proven to be a critical factor for many data mining tasks To efficiently analyze voluminous data sets, which are currently stored in databases of almost all companies, it is often necessary to start from pruning and reducing of the size of these repositories Decision makers are usually not interested in timeconsuming extraction of technical details \(i.e. serial numbers, time of transactions with precision in seconds detailed GPS locations, etc databases. Instead, they want to obtain knowledge at a certain level of abstraction, as dictated by their professional goals or by the character of the analyzed dataset. At the same time, the data conceptually represent information at multiple levels . For instance, an item, represented by a bar code: 040101000 is a Milky Way Bar, which is a Chocolate Bar, pertaining to a Snack, or even a Food group, etc Attribute-Oriented Induction \(AOI  compression of the original set of data into a generalized relation to provide data analysts with concise and summarative information about the original, massive set of task-relevant data. The AOI process employs background knowledge represented in the form of concept hierarchies, separately declared for each of the attributes in the analyzed database table  Work partially supported by NASA Grant Consortium Award No. M166-05-Z3184 Induction of the original relation is performed onestep at a time on an attribute-by-attribute basis. The method has rather straightforward character [1 1 2 derived attributes. An attribute can be removed if it has a large set of distinct values and no generalization hierarchy for the attribute is available or if the abstract concepts are reflected by other attributes in the initial relation \(e.g. one can remove attribute City if it is followed by State attribute generalized if a concept hierarchy for them has been defined 3 at the particular abstraction level their respective counts. New attribute COUNT has to be added to the relation, to keep track of original records 


added to the relation, to keep track of original records which are gradually merged during the transformation of attribute values from one level of abstraction to another. Value stored in the COUNT column reflects the number of original records merged together into a generalized tuple 4 generalized Additional data mining algorithms can be further applied on this relation The hierarchical character of AOI provides analysts with ability to view the original information at multiple levels of abstraction, allowing them to progressively discover interesting data concentration points. In contrast to the flat summarization a gradual process of attribute-oriented induction through concept hierarchies allows detailed tracking of all records, and can lead to the discovery of interesting patterns among data at the lowest abstraction level of their occurrence. In the AOI approach the tuples, which initially \(at a low level of abstraction support assigned to eliminate seldom occurring regularities, rather than being dropped, are gradually further aggregated and so given a chance to reach a meaningful count at a higher abstraction level. Such an approach improves accuracy of generalization, since now only those records that are truly infrequent at  each of the abstraction levels are eliminated from further analysis 0-7803-9158-6/05/$20.00  2005 IEEE. The 2005 IEEE International Conference on Fuzzy Systems785 I I. BACKGROUND The idea of applying concept trees to generalize database records for data mining purposes was proposed by Han [1-4] and developed further by other researchers 5-6]. Recently, Hsu [7] extended the basic AOI algorithm for generalization of numeric values. The majority of the mentioned work focuses on attributeoriented induction with utilization of crisp concept hierarchies \(i.e. trees have only one direct abstract to which it fully belongs However, regular concept trees, due to their crisp character, are simply not the best representation for usually complex dependencies occurring in the attribute domains. Recently several independent groups of researchers have investigated applications of a fuzzy concept hierarchy to AOI. Lee and Kim [8] used fuzzy ISA hierarchies, from the area of data modeling, to generalize database records to more abstract concepts Lee [9] applied fuzzy generalization hierarchies to mine generalized fuzzy quantitative association rules. Cubero Medina, Pons, and Vila [10] presented fuzzy gradual rules for data summarization. Raschia, and Mouaddib 11] implemented the SaintEtiq system for data summarization through extended concept hierarchies Fig. 1. Example of Fuzzy concept hierarchy for achromatic color domain \(originally  a set of continuous attribute values  Fuzzy concept hierarchies \(Figure 1 capture human approaches to induction. Trivi al examples supporting this conclusion can be found everywhere, e.g. how to generalize three colors, such as black, gray and white to two abstract terms: dark, light or to which continent should we assign the Russian Federation , taking under consideration a fact that almost one fourth of this country lies west of the Urals In fuzzy concept hierarchies, lower -level concepts can belong to more than one descriptor placed on the directly higher level of abstraction Unfortunately, none of the above-mentioned fuzzy induction models focuses on guarant eeing the preservation of exact dependencies among low-level original 


original descriptors I I I. FUZZY CONCEPT HIERARCHIES FOR THE ATTRIBUTE-ORIENTED INDUCTION The main difference between a crisp concept hierarchy and a fuzzy one is the type of generalization relation between the concept and its direct abstract these structures are capable of modeling. In crisp hierarchies each lower-level concept is fully assigned to only one direct abstract, and a single abstract can have many direct specializers. In fuzzy concept hierarchies a generalization relation is allowed to have a many-tomany character; a single lower-level concept can have multiple abstracts at the next abstraction level, related to each of these concepts to a different extent Our fuzzy concept hierarchy is an augmented rooted tree structure. Each link l  in the fuzzy concept hierarchy is a bottom -up directed arc \(edge two nodes \(i.e. concepts to it. Such a structure reflects a fuzzy induction triple ck, ck+1, 1kk cc k and ck+1 are endpoints of l and 1kkcc +?  represents the strength of conviction that the lower-level concept ck \(a source of l qualified as concept ck+1\(a target of l generalization process moves to the next abstraction level. During AOFI the value of 1kk cc +?  dictates what fraction of a vote, representing original attribute values generalized already to the concept ck, is propagated to its higher-level representation ck+1 IV. C ONSISTENCY OF VOTE PROPAGATION AND COMPLETENESS OF THE MODEL Other approaches to the attribute-oriented fuzzy generalization do not concentrate on precise and consistent preservation of all original dependencies among the data at each level of induction. It limits their usage in many data mining projects, which perform exhaustive analysis of scientific data. To guarantee exactness of the data summarization via AOFI we need to preserve the number of original tuples and the relation between them in the identical proportions at each level of abstraction. In other words, to provide a consistent AOFI we need to assure that each record from the original database relation will be counted exactly once at each of the levels of the AOI hierarchy We call this an exact vote propagation dilemma, which follows the vote propagation for crisp AOI This problem can be resolved by preservation of completeness in an AOFI model. The fuzzy generalization hierarchy is complete and consistent when for all adjacent hierarchy levels, Ck and WHITISH GRAYISH BLACKISH LIGHT 1.0 0.50.5 1.0 ANY 1.01.0 DARK 1.0 0.3 0.7 1.00.7 0.3 1.0 0 1 4 A B ST R A C TI O N 


N L EV EL 2 3 WHITE LIGHTGRAY DARK GRAY BLACKGRAY 1.0  The 2005 IEEE International Conference on Fuzzy Systems786 Ck+1\(where Ck+1 is a direct abstraction level of Ck following relationship is satisfied 0.1 1 1 1      k k j k C j cc 11, ++ ?? kkjkk CcCc       \(1 In other words, the sum of weights assigned to the links leaving any single node in a fuzzy concept hierarchy needs to be 1.0 for completeness of the AOFI model Preservation of the above property prevents any attribute value \(or its abstract or less than once at each step of the attribute-oriented fuzzy induction \(i.e. consistency a set of abstracts concepts at each level of hierarchy will cover all of the attribute values that occurred in the original dataset \(i.e. completeness of the model are guaranteed to not lose correct count of the number of tuples when generalizing their attribute values Such normalized representation of uncertainty which is a common element of many generalization processes, should not be confused with representation of probabilistic dependencies. First of all, fuzzy concept hierarchies do not reflect probabilities with which lower-level concepts may be assigned to their direct abstracts  the hierarchies  reflect actual degrees with which the lower-level concepts belong to the generalized terms \(allowing for more adequate reflection of natural human reasoning only purpose of hierarchy normalization in our approach is to assure accurate representation of original tuples during the AOI process.  Formally, each concept hierarchy \(also the un -normalized one perform consistent and completeAOI. Normalization of hierarchy can be performed via simple normalization of membership values in all outgoing links for every concept placed in the hierarchy V. DRILLING DOWN FUZZY CONCEPT HIERARCHIES TO PROVIDE EXPLANATIONS  OF ABSTRACT CONCEPTS Since generalized tuples, which reached their count value above the minimal support threshold, may appear at multiple levels of abstraction, a data analyst may want to drill down the definition of each of the reported generalized descriptors. This can be achieved by recursive extraction of lower -level components of the abstract concept 


abstract concept To obtain an explanation of what is behind a particular abstract concept, which characterizes a significant part of original data set generalized to the related abstraction level, we backtrack the components lower-level concepts so through the analysis of the induction paths, which were activated during AOFI and led to the particular abstract. In general, such an explanation can be either 1 knowledge \(only knowledge about activated generalization paths from concept hierarchy is utilized or have \(2 distribution-based character \(when we preserve the count of votes grouped at each node during the AOI process  descending memberships  which are derived from the original \(i.e. ascending the concept hierarchies and used during the AOFI The second approach has a more comprehensive character but requires more time for computations and considerably larger memory for preservation of all intermediate data tables, generated during the AOI process. These characteristics make it inapplicable for mining very large databases Approximate explanations are based only on the concept hierarchies and the generalized output table requiring much less memory than the original, massive dataset Using a concept hierarchy, we can explain each abstract concept by tracking down its members to the 0abstraction level \(original attribute values the descriptor Any contains two concepts Light and Dark. Since both of these descriptors have identical ascending membership degrees, presented in the links of the hierarchy, we would intuitively conclude that they both characterize their direct generalizer equally therefore Any = {Light 2 1 ; Dark 2 1 Derivation of the descending memberships from fuzzy concept hierarchies has a straightforward character Each concept kic  in the fuzzy hierarchy can be explained by a set of its direct specializers \(i.e. a subset of Ck-1 allow consistent representation for the fuzzy abstract class kic . So now we can provide the explanation for each abstract class as follows     111 1 1       kkk jk j k i k j k i kk 


i CjCcccc cCc nOfExplanatio 2 where       1 1 1 1 1 k k i k j k i k j k j k i C j cc cc cc   3 and 0kh &gt;? , where h is the height of the fuzzy concept hierarchy In other words, we explain each abstract concept by providing the set of its direct specializers, and the degrees of their  descending memberships  reflecting the knowledge -based participation \(contribution these terms in the final abstract  s construction Drilling down further in Figure 1, based on the distribution of bottom-up membership values in the The 2005 IEEE International Conference on Fuzzy Systems787 hierarchy links, we can explain Light as {Whitish 3 2 Grayish 3 1 } and consequently Dark as {Grayish 3 1 Blackish 3 2 }. We can then provide the user with a more detailed definition of the abstract concept Any: Any Light 2 1 ; Dark 2 1 Whitish 3 2 Grayish 3 1  2 1 


1  Grayish 3 1 ; Blackish 3 2 2 1 To make this explanation clearer we can merge overlapping components. To preserve completeness of the derived definition we applied the sum operator over the algebraic product when merging all overlapping concepts: Any = {Whitish 3 2  2 1 Grayish 3 1  2 1 3 1  2 1 3 2  2 1 Whitish 3 1 ; Grayish 3 1 ; Blackish 3 1 So we can see that the approximated explanation of abstracts, via drilling down fuzzy concept hierarchies has a transitive character. If we explain concept ck with the subset of Ck-1, and then each of the elements from this set with the concepts from the set Ck-2, then ck can be also fully explained by the merger of definitions based on the set Ck-2 This approach to explanation of abstract concepts has a rather trivial character when none of the abstract  s components \(direct specializers count of the votes greater than the given generalization threshold \(denoted further as T separate entity in the generalized relation. However, in the other case, we have to make certain that the concepts that reached a significant count at the lower level of abstraction \(and were already placed in the final generalized relation higher-level concepts. Otherwise the explanations would have a confusing character, since the client could be under impression that the same tuples are reported and counted abstraction. We have to remember that final users of data mining applications are decisions makers who, in contrasts to experts and data analysts, usually do not have time to gather detailed knowledge about techniques which were applied to generalize the data Therefore the last equation should include the restriction lt;?1kjc      \(4 where T is the threshold value representing the minimal value of COUNT which is recognized by the client as significant aggregation of original data \(e.g.  one may wish all generalized tuples which describe more than T 


wish all generalized tuples which describe more than T 5% of the original dataset to be reported separately in the output relation number of original data records generalized to the abstract concept 1?kjc This property assures that each lower-level concept employed in derivation of a hierarchical explanation was not separately reported in the final generalized relation VI. EXTRACTION OF MULTI-LEVEL ASSOCIATIONS FROM T OXIC RELEASE INVENTORY DATA A data-mining task, for which we have chosen to empirically test the AOFI method, was to provide a concise and exact summary of toluene emission in the air of Louisiana in 2001 \(the most current dataset provided by U.S. Environmental Protection Agency We have chosen this particular toxin since it is a chemical most commonly reported to the Toxics Release Inventory [13] by the local industrial facilities Toxics Release Inventory \(TRI database, which has been created under the Emergency Planning and Community Right-t o-Know Act \(EPCRA in 1986. The 2001 TRI dataset contains information on releases of approximately 650 toxic chemicals. The data was gathered from over 21,000 manufacturing facilities located within the US When performing our method over the dataset we concentrate our analysis on three main aspects: \(1 Localization of the toluene emitters \(i.e. discovery of regions in Louisiana which have high air emission of the chemical 2 state \(i.e. estimation of the toxicity level in different regions of Louisiana 3 responsible for the local toxification \(i.e. types of businesses which are emitting toluene in the air of Louisiana i.e. Standard Industry Code TABLE 1. Number of concepts at each abstraction level for each of the generalized attributes ABS_ LEVEL FACILITY_LO CALIZATION SIC_CODE TOTAL_AIR_ EMISSION 0-level 62 cities 30 original codes continous range 1-level 35 parishes 21 3-dig. groups 8 fuzzy clusters 2-level 5 regions 10 2-dig. groups 3 fuzzy clusters 3-level 2 parts 7 industry grps 1 concept 4-level 1 concept 1 concept The 2005 IEEE International Conference on Fuzzy Systems788 Fig. 2. Fuzzy concept hierarchy for generalization of FACILITY_LOCALIZATION Figure 2 represents fuzzy generalization hierarchy for generalization of facilities  localizations based on Louisiana geography. Similar hierarchies were defined by experts for the remaining two attributes, before the AOFI was performed The number of abstract descriptors at each level of concept hierarchies for the analyzed TRI dataset is presented in Table 1. The second row of this table reflects PreGeneralization [1], where attribute values are transformed to the concepts placed at the leaves of the concept hierarchies. Since this phase is performed without an increase of abstraction level \(denoted as 0abstraction level in Table 1 the leaves of the concept hierarchies are actually the original attribute values As with regular AOI, we are able to extract separate generalization paths for each attribute value from the concept hierarchies. However the fuzzy generalization paths can not be implemented in the form of lists but 


paths can not be implemented in the form of lists but need to be represented in the form of trees As in the crisp  approach, we are allowed to order steps of generalization according to our preferences Each stage of AOI can be characterized by  a vector representing the current abstraction level for each of the generalized attributes, where the order of its elements reflects the order of attributes in the generalized relation. In our example, since we generalize three columns of the table including task relevant data, we can describe PreGeneralization as \(0 0, 0 are at the 0-abstraction level. So the final possible stage \(all attribute values in each column are characterized by a single, most general concept vector \(4, 4, 3 FACILITY_LOCALIZATION and SIC_CODE are generalized to the 4th level of abstraction, and the last attribute, i.e. TOTAL_AIR_EMISSION, is abstracted to the 3rd level \(all these levels ar e final, since they reflect roots of the utilized concept hierarchies The final, generalized relation, which provides the user with information about only significant clusters of data at the abstract level, is presented in the Table 2 Each of the generated tuples can be interpreted as a conjunctive rule, characterizing release of toluene in Louisiana \(i.e. the tuples stored in the initial relation Obviously, the order of AOFI steps could reflect different data mining goals. Since we were particularly interested in analyzing what types of facilities release toluene into the air in Louisiana we decided to generalize the SIC codes as late as possible TABLE 2. Generalized \(output release in Louisiana AOFI stage FACILITY_LO CALIZATION SIC TOTAL_AIR_ EMISSION COUNT 1 5 Cajun Country 5169 Below &amp; about 603 4.52 2 5 Crossroads 5171 Below &amp; about 603 4.45 3 5 Plantation Country 286- Below &amp; about 603 5.10 4 6 Cajun Country 286- Low 7.39 5 7 Cajun Country 28-- Low 5.33 6 7 Plantation Country 28-- Low 9.61 7 7 Plantation Country 28-- Medium 5.26 8 8 South 29-- Low 5.98 9 8 South 29-- Medium 7.05 10 8 South 34-- Medium 4.69 11 8 South 51-- Low 10.02 12 10 LA 28-- Any 9.12 13 10 LA 29-- Any 5.14 14 11 LA 3--- Any 10.76 15 12 LA Any Any 5.54 When mapping generated abstract tuples into characteristic rules at a common level of abstraction with quantitative information about support of these BOSSIER L A SPORTSMAN'S PARADISE SOUTHNORTH CALDWELL CROSSROADS RAPIDES BEAUREGARD ST. JAMES CAJUN COUNTRY ASSUMPTION  0.20.8 


0.20.8 0.75 0.25 0.9 0.1 City 1 City 2 City ... City ... City ... City 1.0 1.01.01.0 1.0 1.0 1.0 1.0 1.0 0.9 NATCHITOCHES 0.90.1 0.4 0.60.1 1.0 1.0 1.0 A B ST R A C TI O N L EV EL 1 2 3 4 0 The 2005 IEEE International Conference on Fuzzy Systems789 characteristics, we must ensure preservation of the distribution of COUNT according to the background knowledge as reflected in the fuzzy concept hierarchies For instance, if we are particularly interested in the business sector classified by government as 51  i.e Wholesale Trade of the Non-durable Goods merge the 1st,  2nd and 11th record of the generalized relation to build the following characteristic rule South? Cajun Country? Crossroads 51--? 5169 5171 Low ? Below and about 603 This rule can be further simplified to the form South ? Crossroads abstract description of 18.99% \(i.e 4.52%+4.45%+10.02 records. However if we want to transform this characterization to a more general form, such as: South 51-- ? Low , we have to remember that according to the fuzzy concept hierarchy presented in the Figure 2 only 25%  of the Crossroads country lies in the southern Louisiana, therefore in this generalization a summarization of the COUNT values needs to be appropriately modified 10.02% + 4.52% + 0.25*4.45%  = 15.65 Now we can conclude that almost 19% of facilities which officially reported a release of toluene into the air of Louisiana, are the wholesale traders of nondurable goods and that over 82% of them \(i.e 15.65 / 18.99 = 0.8241 part of the state. All these  51-type  facilities released only low amounts of toluene VI I. CONCLUSIONS In this paper we first introduced a consistent model of fuzzy induction and then applied it to mine generalized association rules  from environmental data In addition, we presented how the generated results can be explained to users via extraction of their approximate definitions There are many aspects by which we may judge the technique presented here. The ordinary \(crisp will usually perform with higher computational efficiency then AOFI. However utilization of fuzzy 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



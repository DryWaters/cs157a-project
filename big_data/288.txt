Fast Parallel Association Rule Mining Without Candidacy Generation Osmar R ZaYane Mohammad El-Hajj Paul Lu University of Alberta Edmonton Alberta, Canada  zaiane, mohammad, paullu} @cs.ualberta.ca Abstract In this paper we introduce a new parallel algorithm MLFPT Multiple Local Frequent Pattern Tree I l for parallel mining of frequent patterns bused on FP-growth mining, that uses only two full I/O scans of the database eliminating the needfor generating the candidate items, and distributing the work fairly among processors We have de 
vised partitioning strategies at different stages of the mining process to achieve near optimal balancing between proces sors We have successfully tested our algorithm on datasets larger than 50 million transactions 1 Introduction Association rule mining algorithms currently proposed in the literature are not sufficient for extremely large datasets and new solutions still have to be found In par ticular there is a need for algorithms that do not depend on high computation and repeated I/O scans Parallelization is a viable solution However distributing and balancing the mining tasks between the 
processors without jeopardizing the global solution is not trivial The problem of mining as sociation rules over market basket analysis was introduced in l Association rules are not limited to market basket analysis but the analysis of sales or what is known as bas ket data is the typical application often used for illustration The problem consists of finding associations between items or itemsets in transactional data The data could be retail sales in the form of customer transactions or even medi cal images 12 
Association rules have been shown to be useful for other applications such as recommender systems diagnosis decision support, telecommunication, etc This association-mining task can be broken into two steps A step for finding all frequent k-itemsets known for its associ ated extreme 1/0 and a straightforward step for generating confident rules from the frequent itemsets 1.1 Related Work Several algorithms have been proposed in the literature to address the problem of mining association rules One of the key algorithms which seems to be the most pop ular in many applications for enumerating frequent 
item sets is the apriori algorithm 3 the foundation of most known algorithms whether sequential or parallel Park et al have proposed the Dynamic Hashing and Pruning al gorithm DHP 9 However the trimming and the pruning properties caused some problems that made it impractical in many cases  131 The partitioning algorithm proposed in 5 reduced the I/O cost dramatically  However, this method has problems in cases of high dimensional itemsets, and it also suffers from the high false positives of frequent items FP-growth was recently 
proposed by Han et al 8 This algorithm creates a relatively compact tree-structure that al leviates the multi-scan problem and improves the candidate itemset generation The algorithm requires only two full I/O scans for the dataset. Our approach presented in this paper is based on this idea In spite of the significance of the asso ciation rule mining and in particular the generation of fre quent itemsets, few advances have been made on paralleliz ing association rule mining algorithms 6 21 Most of the work on parallelizing association rules mining on Shared 
memory MultiProcessor SMP architecture was based on apriori-like algorithms Parthasarathy et al IO have written an excellent re cent survey on parallel association rule mining with shared memory architecture covering most trends, challenges and approaches adopted for parallel data mining All ap proaches spelled out and compared in this extensive sur vey are apriori-based These methods not only require re peated scans of the dataset they also generate extremely large numbers of candidate sets easily approaching lo3 candidates in common cases 7 1.2 Contribution In this paper we introduce a new parallel association 
rules mining algorithm MLFPT which is based on the FP growth algorithm 8 We have implemented this algorithm on a 64 processor SGI 2400 Origin machine where all ex periments were tested using high dimensionality data that are of a factor of hundreds of thousands of items and trans actional sizes that range in tens of gigabytes A special opti mization step is added to achieve better load balancing with 0-7695-1 119-8/01 17.00 0 2001 IEEE 665 


the goal of distributing the work fairly among processors for the mining process 2 Multiple Local Parallel Trees The MLFPT approach we propose consists of two main stages Stage one is the construction of the parallel frequent pattern trees one for each processor\and stage two is the actual mining of these data structures, much like the FP growth algorithm However in order to avoid false neg atives where locally infrequent itemsets are pruned inad vertently while they are frequent globally we need global counters Though global counters necessitate locking mech anisms for mutual exclusion that would add significant overhead and waiting time Our approach with interlinked local counters avoids the need for locking Thus we evade the famous ping-pong problem in parallel programs 2.1 Construction of the Multiple Local Parallel Trees The goal of this stage is to build the compact data struc tures called Multiple Local Parallel Trees MLPT\This construction is done in two phases where each phase re quires a full VO scan for the dataset A first initial scan of the database identifies the frequent I-itemsets In order to enumerate the frequent items effi ciently we divide the datasets among the available proces sors Each processor is given an approximately equal num ber of transactions to read and analyze As a result the dataset is split in p equal sizes Each processor locally enu merates the items appearing in the transactions at hand Af ter enumeration of local occurences  a global count is nec essary to identify the frequent items This count is done in parallel where each processor is allocated an equal number of items to sum their local supports into global count Fi nally in a sequential phase infrequent items with a support less than the support threshold are weeded out and the re maining frequent items are sorted by their frequency This list is organized in a table, called header table where the items and their respective global support are stored along with pointers to the first occurrence of the item in each fre quent pattern tree Phase 2 would construct a frequent pat tern tree for each available processor Phase 2 of constructing the MLPT structures is the ac tual building of the individual local trees This phase re quires a second complete I/O scan from the dataset where each processor reads the same number of transactions as in the first phase Using these transactions each proces sor builds its own frequent pattern tree that starts with a null root For each transaction read by a processor only the set of frequent items present in the header table is collected and sorted in descending order according to their frequency I IlD Item Bough1 I RweamrNumher 1 A B C D E B D A E G A.8,F.G.D B F D G K 6 A.B.F.G.D A R.M K.0 8 B.F G.A D  1\2222 9 A B.F.M.V Table 1 Transactional database example Lep 4 S1ep 1 Step I Figure 1 Steps of phase 1 These sorted transaction items are used in constructing the local FP-Trees as follows for the first item on the sorted transactional dataset check if it exists as one of the children of the root If it exists then increment the support for this node Otherwise add a new node for this item as a child for the root node with 1 as support Then consider the cur rent item node as the newly temporary root and repeat the same procedure with the next item on the sorted transaction During the process of adding any new item-node to a given this item-node in the tree and its entry in the global header table corresponding to processor p The header table holds as many pointers per item as there are available processors For illustration we use an example with the transactions shown in Table 1 Let the number of available processors be 3 and the minimum support threshold set to 4 The four steps in phase 1 are shown in Figure 1 and Figure 2 shows the result of the tree building process. For the sake of sim plicity only links from the items A and B are drawn from the header table local FP-Tree of a processorp a link is maintained between 2.2 Mining Parallel Frequent items using MLPT Trees Building the trees in the first stage is not a final goal but a means with the purpose of uncovering all frequent patterns without resorting to additional scans of the data The min ing process starts with a bottom up traversal of the nodes on the MLPT structures where each processor mines fairly equal amounts of nodes The distribution of this traversal work is predefined by a relatively small sequential step that precedes the mining process This step sums the global sup 666 


Figure 2 Phase 2 of the construction of the MLPT structure G ports for all items and divides them by the number of pro cessors to find the average number of occurrences that ought to be traversed by each processor If A is this found average this sequential step goes over the sorted list of items by their respective support and assigns items consecutively for each processors until the cumulated support is equal or greater than the average A At this stage all frequent pattern trees are shared by all processors The task of the processors once assigned some items is to generate what is called a conditional pattern base starting from their respective items in the header table A conditional pattern base is a list of items that occur before a certain item in the frequent pattern tree up to the root of that tree in addition to the minimum support of all the item supports along the list Since an item cannot only occur in many trees but also in many branches of the same tree many conditional pattern bases could be generated for the same item. Merging all these conditional pattern bases of the same item yields the frequent string a string also called conditional FP-Tree that contains fre quent itemsets and their support in the presence of a given item The merge is based on the items in the patterns and all the supports of the same items are added up in the same manner as in 8 If the support of an item is less than the minimum support threshold it is not added in the frequent string Table 2 gives all conditional bases and conditional FP Trees generated from the example in Table 1 iF I D I 8 I i F 2 D:2 A.2,8:2 Fi,D!i.FJ:I Fl,Dl,A:l.B:i Di.B:i 8:6 D.6 F5 A:4jIG 3 Experimental Results A shared memory SGI Origin 2400 with 64 processors was used to conduct the experiments We used synthetic transactional databases generated using the IBM Quest syn thetic data generator 4 The sizes of the input databases vary from I million transactions to 50 million using dimen sions that are multiples of hundreds of thousands Each Items I Conditional Pattern Base I CondiUolul FP-Tm I I 1D:I.A:I.B:II I 1 DZ A:2 8:2 D I B\222Ij A:I 8 A.2 8:2 8.7 ASJID A\222l 8 I j 8\22221 Table 2 Conditional Pattern Bases and the Conditional FPtrees mining process I  wthout U0 Adjusternent With VO Adjusternent I I 1 proc 4proc 8proc 16proc 32proc 48proc 64proc Number of Processars Figure 3 Comparison of execution time for 5 million transactions with and without I/O ad justement of these transactions has at least 12 items preceded by a unique transactional ID The largest dataset is in the order 10 Gbytes In our experiments we studied the MLFPT algorithm with 4,8 16,32,48 and 64 processors and compared it to its sequential version The sequential version was of course implemented without the summation phase and with only one tree Speedup measures the performance of parallel ex ecution compared to the sequential execution S  TIIT where S is the speedup achieved with p processors TI is the sequential execution time and Tp is the execution time using p processors I/O access is normally of an 223embarrassingly parallel\224 nature For instance when data is stored on parallel disks with dedicated channels twice as many processors should read twice as much data In other words with appropriate hardware if it takes t time for one processor to read some data it should take t/p for p processors to cover the same data Since our parallel machine had a sequential disk with one 667 


shared head to assess the real speedup of MLFPT which does 2 VO scans of the data regardless of the number of processors we adjusted the I/O time assuming an \223embar rassingly parallel\224 I/O access In our results we decided to adjust the VO time of our algorithm as follows The VO time for parallel execution was estimated using the YO time for sequential execution divided by the number of processors used For instance if using p processors the total execution time is T and the isolated I/O time is t the execution time with U0 adjusted is calculated TI  T  t  S/p where S is the isolated I/O time for a sequential execution In other words we replaced the 2 scans I/O time recorded with the expected real parallel I/O time Due to the space limitation we will only present figure 3 that depicts the significant time reduction with the increase of processors when mining 5 million transactions MLFPT operations are divided into two stages where most of the computation in the MLFPT algorithm is done during building the MLPT trees and then mining them Building the frequent pattern trees which utilize most of the processing time is shown to be of 223embarrassingly parallel\224 nature and this indeed was the reason for the several-fold improvements achieved as we increased the number of pro cessors in our experiments This is due to the fact that the work is evenly partitioned among the processors and each unit of work is completely independent of each other where each processor builds a sub-tree representing its partition of transactions There is no ping-pong effect where processors are waiting for each other Our experiments have shown that this creation and min ing is almost linearly proportional to the number of pro cessors and the size of the transactional datasets where the speedup of the MLFPT algorithm increases as the problem size increases These results suggest that the MLFPT algo rithm would achieve speedups for extremely large datasets as well 4 Conclusion and Future Work In this paper we have introduced an efficient parallel implementation of an FP-Tree-based association rule min ing algorithm and have proposed a solution for load bal ancing among processors and resource sharing with min imum mutual-exclusion locking We have discussed our experiments with this new parallel algorithm MLFPT for mining frequent patterns without candidate generation The MLFPT algorithm overcomes the major drawbacks of par allel association rule mining algorithms derived from apri ori in particular the need for k I/O passes over the data Our experiments showed that with I/O adjusted the MLFPT algorithm could achieve an encouraging many-fold speedup improvement The implementation of our algorithm and the experi ments conducted were on a shared memory and shared hard drive architecture We have recently acquired a cluster with 8 dual processor nodes and we plan to investigate the same approach with shared nothing architecture and devise a new protocol for sharing global resources while minimizing the message passing overhead We are in the process of experi menting our algorithms with up to 1 billion transactions References I R Agrawal T Imielinski and A Swami Mining associa tion rules between sets of items in large databases In P roc 1993 ACM-SICMOD Int Conj Management of Data pages 207-216 Washington D.C May 1993 2 R. Agrawal and J C Shafer Parallel mining of association rules: Design, implementation and experience IEEE Trans Knowledge and Data Engineering 8:962-969 1996 3 R Agrawal and R Srikant Fast algorithms for mining as sociation rules In Proc 1994 Int Con5 Ven Large Data Bases pages 487-499 Santiago Chile September 1994 4 1 Almaden Quest synthetic data generation code http://www.almaden.ibm.com/cs/quest/syndata.html 5 S Brin R Motwani J D Ullman and S.Tsur Dynamic itemset counting and implication rules for market basket data In Proc 1997 ACM-SIGMOD Int Con Management of Data pages 255-264 Tucson, Arizona May 1997 6 D Cheung J Han V Ng A Fu and Y Fu A fast dis tributed algorithm for mining association rules In Proc 1996 Int Con5 Parallel and Distributed Information Sys tems pages 3 1-44 Miami Beach Florida Dec 1996 7 J Han and M Kamber Data Mining Concepts and Tech niques Morgan Kaufmann 2001 8 J Han J Pei and Y Yin Mining frequent patterns without candidate generation In ACM-SIGMOD Dallas 2000 9 J Park M Chen and P Yu An effective hash-based al gorithm for mining association rules In Proc 1995 ACM SIGMOD Int Con Management of Data pages 175-1 86 San Jose, CA May 1995 IO S Parthasarathy M J Zaki and M Ogihara Parallel data mining for association rules on shared-memory sys tems Knowledge and Information Systems An Interna tional Journal 3 l 1-29 February 2001 111 0 R Zaiane M El-Hajj and P Lu Fast paral lel association rule mining without candidacy genera tion Technical Report TR01-12 Department of Com puting Science University of Alberta Canada August 200 1 ftp://ftp.cs.ualberta.ca/pub/TechReports/2OO l/TROl 121 0 R Zai\222ane J Han and H Zhu Mining recurrent items in multimedia with progressive resolution refinement In Int Conj on Data Engineering ICDE\2222000 pages 461-470 San Diego CA February 2000  131 M J Zaki Parallel and distributed association mining A survey IEEE Concurrency Special Issue on Parallel Mech anismsfor Data Mining 7\(4 14-25 December 1999 12/TROI  12.pdf 668 


Proposition 6.1 Y is a derived attribute of B iff Y is exten sion functionally depended EFD on B By definition the occurrence of an extension function ally dependency EFD means there is an attribute trans formation f  Dom\(B x  Dom\(Bk  Dom\(Y such that f\(B\(v  Y\(v V v E V By definition Y  f\(B B    Bk this completes our arguments Table 4 illustrates the notion of EFD and attribute transfor mations Table 4 An Attribute Transformation in K 6.2 Feature Extractions and Constructions Feature extractions and constructions in intensional view are much harder to describe formally since features repre sent human view and their mathematical relations have to be set up for all possible instances consistently We will take extensional view the view from data's prospect Let us examine some assertions in traditional view\from 25 All new constructed features are defined in terms of original features  and Feature extraction is a process that extracts a set of new features from the orig inal features through some functional mapping." By taking the data view it is easy to see both assertions imply that the new constructed feature is a function functional mapping of old features Note that Let A  A   A be the attributes before the ex tractions or constructions and A   A be the new attributes From the analysis above the new attributes fea tures are functions of old ones we have f  Dom\(A x   x Dmn\(A i Do~\(A From the analysis on Section 6.1 4"+k is a derived at tribute of A We summarize the analysis in Proposition 6.2 The features constructed from classical feature extractions and constructions are derived attributes in extension view 6.3 Derived Attributes in the Canonical Model From Proposition 5.2.1 K is isomorphic to the canoni cal model CK So there is a corresponding Table 4 in the canonical model In other words there is a map V/Bk x  x V/Bk  V/\(Bi n  n Bk i V/YE This map between quotient sets implies a refinements in the partitions thatis,Y~isacoarseningofBE  B'n  nBk So we have the following Proposition 6.3 Y is a derived attribute of B iff YE is a coarsening of BE  B n    B where Y E A and BCA 7 Granular Data Model of Relation Lattice In this section we modify Lee's work At the beginning of Section 3.2 we have recalled the observation of [29 71 that any subset of A induces a partition on V the pan tion induced by A is denoted by QJ The power set ZA is Boolean algebra and hence a lattice where meet and join operations are the union and intersection of the A respec tively Let A\(V be the set of all partitions on V equiv alence relations A\(V forms a lattice where meet is the intersection of equivalence relations and join is the union where the union denoted by UjQ is the smallest coars ening of all Qj,j  1,2   A\(V is called the partition lattice Recall the convention all attributes are non-isomorphic attributes Hence all equivalence relations are distinct see Section 3.1 Next proposition is due to Lee Proposition 7.1 There is a map 8  2A  A\(V that respects the meet but not the join operations Lee called the image Im8 the relation lattice and observe that 1 The join in Imb is different from that of A\(V 2 So Imb is a subset hut not a snhlattice of A\(V Such an embedding is an unnatural one but Lee focused his efforts on it he established many connections between database concepts and lattice theory However we will in stead take a natural embedding Definition 1.2 The smallest lattice generated by Imb by abuse of language is called the \(Lin's relation lattice de noted by L\(Q This definition will not cause confusing. since we will not use Lee's notion at all The difference between L\(Q and ImO is that former contains all the join of distinct attributes The pair V L\(Q is the granular data model of the Lin's relation lattice It should be clear 286 


Delinition 1.3 The high frequency q-patterns of V Q V q is the high frequency patterns of length one in V ImO and is a subset of the high frequency patterns of length one in V L\(Q 8 Universal Model  Capture the invisibles The smallest lattice denoted by L'\(Q that consists of all coarsening of L\(Q is called the complete relation lat tice MainTheorem8.1 L*\(Q of the canonical model Proof 1 Let P E L*\(Q that is P is coarser than some Qj1 n _ n Qjk We will show it is a derived attribute The coarsening implies a map on their respective quotient sets y  V/Qj x VlQj  VlQjk  V/\(Qj n Qjz   Qjh  VIP In terms of relational notations, that is y  Dm\(Qj x   x Dom\(Qj t Dm\(P Using the notations of functional dependency we have equivalence relations are attributes of the canonical model P g\(~jl,~Jz...,Qjk So g as a map between attributes is an attribute transfor mation. Hence P is a derived attribute 2 Let P be a derived attribute of CK That is there is an attribute transformation Dom\(Qj x _._ x Dm\(Qjk t D~L\(P As CK is the canonical model it can be re-expressed in terms of quotient sets f  VIQ x  x VlQj i VIP Observe that VlQjl x _ x VlQjk  V/\(Q n  n Qjk so the existence off implies that P is coarser than Qj n  nQjk BydefinitionPisanelementinL'\(Q Q.E.D Note that L*\(Q is finite since A\(V is finite The pair V L'\(Q is a granular data model, and its relation format UK  v  P~L*\(Q is a knowledge representation Its attributes are all the par titions in L*\(Q  which contains all possible derived at tributes of K  V  by the theorem We will not dis tinguish betweenthe granular data model and its realtiion format Definition 8.2 The pair UK  V,L'\(Q is the comple tion of CK  V Q and is called the universal model of K 9 Isomorphic Relations I V I K I S I Business I Birth I CITY 1 TEN TEN Table 5 An Information Table K I V I K 1 S I Weight I Part I Material I Table 6 An Information Table K The two relations, Table 5 6 are isomorphic but their semantics are completely different, one table is about part the other is about suppliers These two relations have Iso morphic association rules 1 Length one TEN TWENTY March SJ LA in Ta ble 5 and IO 20 Screw, Brass, Alloy in Table 6 2 Length two TWENTY MAR Mar SJ TWENTY SJ one Table 5 20 Screw screw Brass ZO Brass Table 6 However they have non-isomorphic interesting rules 1 Table 5 TWEBTY SJ that is the business amount at San Jose is likely 20 millions it is isomorphic to 20 Brass\which is not interesting 2 Table 6 SCREW BRASS that is the screw is most likely made from Brass it is isomorphic to Mar SJ which is not interesting 


10 Conclusions In this paper, we successfully enumerate all possible de rived attributes of a given relation The results seem strik ing however, they are of theoretical nature Even though L   contains a complete list of all attributes, the number is insurmountably large; it is bounded by the Bell number Bn where n is the cardinality of the smallest paniton in L\222\(Q The exhaustive search of association rules on all those attributes are beyond the current reach However by combining the classical techniques of feature selections we may reach new applications. Classical feature selection has focused on the original set of attributes, now with our new result, it seems suggest that the domain of feature selection should he extended to this complete universal set of derived attributes We have tentatively called such a selection back ground knowledge We will report such research in near future Next we would like to remark that the simple ohser vation that isomorphic relations have isomorphic patterns has a strong impact on the meaning of high frequency patterns Isomorphism is a syntactic notion it is highly probable that two isomorphic relations have totally differ ent semantics The patterns mined for one particular ap plication may contain patterns for other applications So relation with some additional structures need to be ex plored 23, 14 15 17 20 21 111 In particular, it implies that \224interesting-ness\224 of association tuples may need extra semantics the mere probability theory based on counting items may not be able to identify them we only give a sim ple example \(Section 9 more research will be reported in near future 11 Elementary Operations In this section, we do not assume the attributes are dis tinct The isomorphism of relations is reflexive, symmetric and transitive so it classifies all relations into equivalence classes we call them isomorphic classes Definition 11.1 H is a simplified information table of K if H is isomorphic to K and only has non-isomorphic at tributes Theorem 11.2 Let H be the simplified information table of K Then the patterns \(large itemsets of K can be obtained from those of H by elementary operations that will be de fined below To prove the Theorem we will set up a lemma in which we assume there are two isomorphic attributes B and B\222 in K that is. degree K  degree H I Let s  Dm\(B t Dom\(B\222 be the isomorphism and b\222  ZJ Let H be the new table in which B\222 has been removed Lemma 11.3. The patterns of K can be generated from those of H by elementary operations namely 1 If b is a large itemset in H then b\222 and \(h b\222 are large in K 2 If a _ b c   is a large itemset in H then a   b\222 c   and a   b b\222 c   are large in K 3 These are the only large itemsets in K The validity of this lemma is rather straightforward: and it provides the critical inductive step for Theorem we ill skip the proof References I R Agrawal T Imielinski and A Swami 224Mining Association Rules Between Sets of Items in Large Databases;\222 in Proceeding of ACM-SIGMOD interna tional Conference on Management of Data pp 207 216, Washington DC, June 1993 2 G Birkhoff and S MacLane A Survey of Modern Al gebra, Macmillan 1977  Richard A Brualdi, Introductory Combinatorics, Pren tice Hall 1992 141 Y.D Cai N Cercone and J Han Attribute-oriented induction in relational databases In Knowledge Dis covery in Databases, pages 213-228 AAAYMIT Press Cambridge. MA, 1991 151 C J Date, C DATE An Introduction to Database Sys 6 A. Barr and E.A Feigenbaum, The handbook of Artifi tems 7th ed Addison-Wesley 2000 cial Intelligence, Willam Kaufrnann 1981 7 T T Lee, \224Algebraic Theory of Relational Databases,\224 The Bell System Technical Journal Val 62 No IO De cember, 1983 pp.3 159-3204 XI T Y Lin, \224Database Mining on Derived Attributes:\222 to appear in the Spring-Verlag Lecture Notes on AI 2002 9 T Y Lin 224Issues in Data Mining,\224 in:the Proceeding of 26th IEEE Internaational Conference on Computer Software and Applications Oxford UK Aug 26-29 2002 IO T Y Lin 224Feature Completion,\224 Communication of IICM \(Institute of Information and Computing Machin ery, Taiwan Val 5 No 2 May 2002 pp 57-62. \(the proceeding for the workshop 224Toward the Foundation on Data Mining\224 in PAKDD2002 May 6,2002 288 


ll Ng R Lakshmanan L.V.S Han 1 and Pang A Exploratory mining and pruning optimizations of con strained associations rules Proceedings of 1998 ACM SIGMOD Conference on Management of Data 13-24 1998  121 T Y Lin 222The Lattice Structure of Database and Min ing Multiple Level Rules.\222\222 Presented in COMPSAC 2001, Chicago Oct 8-12,2001 the exact copy appear 224Feature Transformations and Structure of Attributes:\222 In Data Mining and Knowledge Discovery Theory Tools, and Technology N B. Dasarathy ed Proceed ing of SPIE Vol473O,Orlando,Fl, April 1-5,2002  131 T Y Lin and Tremba\224AttributeTransfonnations for Data Mining I1 Applications to Economic and Stock Market Data:\222 International Journal of Intelligent Sys tems to appear 14 T Y Lin 221 Association Rules in Semantically Rich Relations: Granular Computing Approach\224 JSAI Inter national Workshop on Rough Set Theory and Granular Computing May 20-25 2001 The Post Proceeding is in Lecture note in AI 2253, Springer-Verlag. 2001, pp 380-384 1151 T Y Lin 223Data Mining and Machine Oriented Mod eling A Granular Computing Approach,\224 Journal of Applied Intelligence Kluwer Vol 13 No 2 Septem ber/October,2000,pp.l13-124 I61 T Y Lin 224Attribute Transformations on Numeri cal Databases,\224 Lecture Notes in Artificial Intelligence 1805 Terano Liu Chen eds PAKDD2000 Kyoto Japan,April18-20,2000,181-192 I71 T Y Lin 224Data Mining Granular Computing Ap proach.\224 In Methodologies for Knowledge Discovery and Data Mining Lecture Notes in Artificial Intelli gence 1574, Third Pacific-Asia Conference Beijing April 26-28,1999.24-33 18 T Y Lin, \224Granular Computing on Binary Relations I Data Mining and Neighborhood Systems.\224 In Rough Sets In Knowledge Discovery A Skoworn and L Polkowski eds Springer-Verlag 1998,107-121 1191 T Y Lin 224 Discovering Patterns in Numerical Se quences Using Rough set Theory:\222 In Proceeding of the Third World Multi-conferences on Systemics Cy hernatics and Informatics Vol 5 Computer Science and Engineering Orlando Florida July 31-Aug 4 1999  T Y Lin N Zhong 1 Duong S Ohsuga 224Frame works for Mining Binary Relations in Data.\224 In Rough sets and Current Trends in Computing, Lecture Notes on Artificial Intelligence 1424 A Skoworn and L Polkowski \(eds\Springer-Verlag 1998,387-393 211  T Y Lin and M Hadjimichael, \224Non-Classificatory Generalization in Data Mining;\222 in Proceedings of the 4th Workshop on Rough Sets, Fuzzy Sets and Machine Discovery November 6-8 Tokyo, Japan 1996, 404 411 22 T.Y Lin Eric Louie 224Modeling the Real World for Data Mining: Granular Computing Approach\224 Joint 9th IFSA World Congress and 20th NAFIPS Conference July 25-28, Vancouver, Canada, 2001 23 E Louie,T Y Lin, \224Semantics Oriented Association Rules:\222 In 2002 World Congress of Computational In telligence, Honolulu Hawaii May 12-17, 2002, 956 961 \(paper  5702 24 E Louie and T Y Lin 224Finding Association Rules using Fast Bit Computation: Machine-Oriented Model ing:\222 in Foundations of Intelligent Systems, Z Ras and S Ohsuga eds Lecture Notes in Artificial Intelligence 1932, Springer-Verlag, 2000, pp. 486- 494 ISMISOO Charlotte NC, Oct 11-14,2000  Hiroshi Motoda and Huan Liu 224Feature Selection, Ex traction and Construction:\222 communication of IICM Institute of Information and Computing Machinery Taiwan Vol 5 No 2 May 2002, pp. 67-72. \(proceed ing for the workshop \222Toward the Foundation on Data Mining\224 in PAKDD2002, May 6,2002 26 H Liu and H Motoda 223Feature Transformation and Subset Selection:\222 IEEE Intelligent Systems Vol 13 No 2 March/April, pp.26-28 \(1998 27 H Liu and H Motoda \(eds\Feature Extraction, Con struction and Selection  A Data Mining Perspective Kluwer Academic Publishers \(1998 28 Z Pawlak Rough sets Theoretical Aspects of Rea soning about Data, Kluwer Academic Publishers 1991 29 Z Pawlak, Rough sets International Journal of Infor mation and Computer Science 11 1982, pp. 341-356 30 R Ng L V S Lakshmanan J Han and A Pang 224 Exploratory Mining and Pruning Optimizations of Constrained Associations Rules\222\222 Proc. of 1998 ACM SIGMOD Conf on Management of Data Seattle Washington, June 1998 pp 13-24 289 


 A A A A A A A A B B B B B B B A B A B A B A B AB A B A A A A B B B A B A B A A B B B B A B A B A B A B A B A B A disjoint B A inside B A contains B A equals B A meets B A covered by B A covers B A overlaps B A B A B A B A B A B AB Figure 4 Topology and resolution increase with minimum bounding circles 64Mb of main memory Since the Apriori algorithm uses the number of transactions as support and we wanted to compare our algorithm with Apriori we have implemented MaxOccur and the na\250 021ve with transaction based support MaxOccur1 The second version of MaxOccur MaxOccur2 used the object-based support as presented in Algorithm 3.1 Table 9 shows the average execution times for the four algorithms with different image set sizes and 033 0 0  05 for Apriori 223Na\250 021ve\224 and MaxOccur1 and 0  0035 for MaxOccur2 The results are graphically illustrated in Figure 5 Clearly MaxOccur scales well with both versions treating one thousand images in 1.3 seconds on average regardless of the size of the data set The running time for 002ltering the frequent item-sets with 033 0  the maximum support threshold line 16 of Algorithm 3.1 is negligible since it is done in main memory once the frequent item-sets are determined Moreover the calculation of the total number of items line 4 of Algorithm 3.1 is done during the 002rst scan of the data set and has limited repercussion on the algorithms execution time The major difference between Apriori and MaxOccur is in ascertaining the candidate item-sets and counting their repeated occurrences in the images Obviously MaxOccur discovers more frequent item-sets The na\250 021ve algorithm also 002nds the same frequent item-sets but is visibly capable of less performance in execution time The left graphic in Figure 6 shows the average number of frequent item-sets discovered with the three algorithms Apriori found on average 109 different frequent k-item-sets while MaxOccur1 and Na\250 021ve found 148 on the same data sets and MaxOccur2 found 145 on average The discrepancy between MaxOccur1 and MaxOccur2 is basically due to the different de\002nition of support The price we pay in performance loss with MaxOccur is gained by more frequent item-sets and thus more potentially useful association rules with recurrent items discovered ofimages Apriori Na\250 021ve MaxOccur1 MaxOccur2 10K 6.43 70.91 13.62 13.68 25K 15.66 176.69 32.35 34.11 50K 30.54 359.38 66.07 67.44 75K 44.93 514.33 97.27 101.23 100K 60.75 716.01 130.12 137.81 Table 9 Average execution times in seconds with different number of images 0 100 200 300 400 500 600 700 800 10K 25K 50K 75K 100K Apriori MaxOccur1 MaxOccur2 Na\357ve time images Figure 5 Scale up of the algorithms 6 Discussion and conclusion We have introduced in this paper multimedia association rules based on image content and spatial relationships between visual features in images using coarse to 002ne resolution approach and we have demonstrated the preservation and changes in topological features during resolution re\002nement We have put forth a Progressive Resolution Re\002nement approach for mining visual media at different resolution levels and have presented two algorithms for the discovery of content-based multimedia association rules These rules would be meaningful only in a homogeneous image collection a collection of semantically similar images or received from the same source channel Many improvements could still be added to the multimedia mining process to speed up the discovery or to re\002ne or generalize the discovered results 017 One major enhancement in the performance of the multimedia association rule discovery algorithms is the addition of some restrictions on the rules to be discovered Such restrictions could be given in a metarule form Meta-rule guided mining consists of dis#ofimages 033 0 0  25 0  20 0  15 0  10 0  05 10K 1.43 2.20 2.70 5.06 13.51 25K 2.80 4.78 6.31 11.20 32.35 50K 6.27 9.28 11.59 22.74 66.07 75K 8.24 13.57 17.69 33.94 97.27 100K 11.32 17.63 23.13 46.74 130.12 Table 10 Average execution time in seconds of MaxOccur with different thresholds 


 0 20 40 60 80 100 120 140 160 MaxOccur2 MaxOccur1 Na\357ve Apriori Apriori MaxOccur1 MaxOccur2 Na\357ve F k  Figure 6 Frequent item\255sets found by the dif\255 ferent algorithms covering rules that not only are frequent and con\002dent but also comply with the meta-rule template For example with a meta-rule such as 223 H-Next-to X Y   Colour x red  Overlap Y Z   P  Y Z  224 one need only to 002nd frequent 3-item-sets of the form f HNext-to\(red Y  Overlap Y 003  P  Y 003  g where Y is an attribute value and P a visual descriptor or spatial relationship predicate Obviously such a 002lter would greatly reduce the complexity of the search problem A method for exploiting meta-rules for mining multilevel association rules is given in  017 We have approximated an object in an image to a locale which is an area with a consistent visual feature such as colour Objects in images and videos are obviously more complex In a recent paper 9 re gions and their signatures are used as objects in a similarity retrieval system A computationally ef\002cient way to identify distinct objects in images is however still to be proposed Automatically identifying real objects and using spatial relationships between real objects would reduce the number of rules discovered and make them more signi\002cant for some multimedia applications 017 Object recognition or identi\002cation in image processing and computer vision is a very active research 002eld Accurately identifying an object in a video for example as being an object in itself is a very dif\002cult task We believe that data mining techniques can help in this perspective Multimedia association rules with spatial relationships using the motion vector of locales as a conditional 002lter can be used to discover whether locales moving together in a video sequence are part of the same object with a high con\002dence 017 There are many application domains where multimedia association rules could be applied and should be tested such as global weather analysis and weather forecast medical imaging solar surface activity understanding etc We are investigating the application with Magnetic Resonance Imaging MRI to discover associations between lesioned structures in the brain or between lesions and pathological characteristics Further development and experiments with mining multimedia data will be reported in the future References 1 R  A gr a w al and R  S r i kant  F ast a l gor i t h ms f o r m i n i n g a ssociation rules In Proc VLDB  pages 487\226499 1994 2 M  J  E genhof er  Spatial Query Languages  PhD thesis University of Maine 1989 3 M  J  E genhof er and J  S har ma T opol ogi cal r e l a t i ons between regions in r 2 and z 2 In Advances in Spatial Databases SSD'93  Singapore 1993 4 U  M  F ayyad S  G  D j or go vski  a nd N  W e i r  A ut omat i n g the analysis and cataloging of sky surveys In U Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy editors Advances in Knowledge Discovery and Data Mining  pages 471\226493 AAAI/MIT Press 1996 5 Y  F u a n d J Han  M e ta-ru le-g u i d e d m in in g o f a sso ciatio n rules in relational databases In Proc 1st Int Workshop Integration of Knowledge Discovery with Deductive and ObjectOriented Databases  pages 39\22646 Singapore Dec 1995 6 J  H an an d Y  F u  Disco v e ry o f mu ltip le-le v el asso ciatio n r u l es from large databases In Proc VLDB  pages 420\226431 1995 7 Z  N  L i  O R Z a 250 021ane and Z Tauber Illumination invariance and object model in content-based image and video retrieval Journal of Visual Communication and Image Representation  10\(3\:219\226244 September 1999 8 R  M iller a n d Y  Y a n g  Asso ciatio n r u l es o v e r i n t erv a l d ata In Proc ACM-SIGMOD  pages 452\226461 Tucson 1997 9 A  N atse v  R Rasto g i  a n d K Sh im W ALR U S A s imilar ity retrieval algorithm for image databases In Proc ACMSIGMOD  pages 395\226406 Philadelphia 1999  R Ng L  V  S  L akshmanan J  H an a nd A Pang E x ploratory mining and pruning optimizations of constrained associations rules In Proc ACM-SIGMOD  Seattle 1998 11 R Srik an t a n d R Ag ra w a l M i n i n g q u a n titati v e asso ciatio n rules in large relational tables In Proc ACM-SIGMOD  pages 1\22612 Montreal 1996  P  S t ol or z H  N a kamur a  E  M esr obi an R  M unt z E  S h ek J Santos J Yi K Ng S Chien C Mechoso and J Farrara Fast spatio-temporal data mining of large geophysical datasets In Proc Int Conf on KDD  pages 300\226305 1995  O  R  Z a 250 021ane Resource and Knowledge Discovery from the Internet and Multimedia Repositories  PhD thesis School of Computing Science Simon Fraser University March 1999  O  R  Z a 250 021ane,J.Han,Z.-N.Li,J.Y.Chiang,andS.Chee MultiMediaMiner A system prototype for multimedia data mining In Proc ACM-SIGMOD  Seattle 1998  O  R  Z a 250 021ane J Han Z.-N Li and J Hou Mining multimedia data In CASCON'98 Meeting of Minds  Toronto 1998 


18001  balancing mechanism which requires further investi gation 4.5 Speedup Figure 12 shows the speedup ratio for pass 2 vary ing the number of processors used, 16 32 48 and 64 where the curve is normalized with the 16 processor execution time The minimum support value was set to 0.4 4.5 0.5 1 1 0 I 10 20 30 40 50 60 70 number of mxessors Figure 12 Speedup curve NPA HPA and HPA-ELD attain much higher lin earity than SPA HPA-ELD an extension of HPA for extremely large itemset decomposition further in creases the linearity HPA-ELD attains satisfactory speed up ratio This algorithm just focuses on the item distribution of the transaction file and picks up the extremely frequently occurring items Transferring such items could result in network hot spots HPA-ELD tries not to send such items but to process them locally. Such a small mod ification to the original HPA algorithm could improve the linearity substantially 4.6 Effect of increasing transaction Figure 13 shows the effect of increasing transac tion database sue as the number of transactions is increased from 256,000 to 2 million transactions We used the data set t15.14 The behavior of the results does not change with increased database size The minimum support value was set to 0.4 The num ber of processors is kept at 16 As shown each of the parallel algorithms attains linearity 5 Summary and related work In this paper we proposed four parallel algorithms for mining association rules A summary of the four database size Sizeup 0 I 0 500 loo0 1500 uxw amount of transaction thousands Figure 13 Sizeup curve algorithms is shown in Table 5 In NPA the candi date itemsets are just copied amongst all the proces sors Each processor works on the entire candidate itemsets NPA requires no data transfer when the supports are counted However in the case where the entire candidate itemsets do not fit within the mem ory of a single processor the candidate itemsets are divided and the supports are counted by scanning the transaction database repeatedly Thus Disk 1/0 cost of NPA is high PDM, proposed in 6 is the same as NPA which copies the candidate itemsets among all the processors Disk 1/0 for PDM should be also high The remaining three algorithms SPA HPA and HPA-ELD partition the candidate itemsets over the memory space of all the processors Because it better exploits the total system's memory, disk 1/0 cost is low SPA arbitrarily partitions the candidate itemsets equally among the processors Since each processor broadcasts its local transaction data to all other pro cessors the communication cost is high HPA and HPA-ELD partition the candidate itemsets using a hash function which eliminates the need for transac tion data broadcasting and can reduce the comparison workload significantly HPA-ELD detects frequently occurring itemsets and handles them separately which can reduce the influence of the workload skew 6 Conclusions Since mining association rules requires several scans of the transaction file its computational requirements are too large for a single processor to have a reasonable response time This motivates our research In this paper we proposed four different parallel algorithms for mining association rules on a shared nothing parallel machine and examined their viabil 29 


Table 5 characteristics of algorithms ity through implementation on a 64 node parallel ma chine the Fujitsu AP1000DDV If a single processor can hold all the candidate item sets parallelization is straightforward It is just suf ficient to partition the transaction over the proces sors and for each processor to process the allocated transaction data in parallel We named this algo rithm NPA However when we try to do large scale data mining against a very large transaction file the candidate itemsets become too large to fit within the main memory of a single processor In addition to the size of a transaction file a small minimum support also increases the size of the candidate itemsets As we decrease the minimum support computation time grows rapidly but in many cases we can discover more interesting association rules SPA HPA and HPA-ELD not only partition the transaction file but partition the candidate itemsets among all the processors We implemented these al gorithms on a shard-nothing parallel machine Per formance evaluations show that the best algorithm HPA-ELD attains good linearity on speedup by fully utilizing all the available memory space which is also effective for skew handling At present we are doing the parallelization of mining generalized association rules described in 9 which includes the taxonomy is-a hierarchy Each item belongs to its own class hierarchy In such mining associations between the higher class and the lower class are also examined Thus the candidate itemset space becomes much larger and its computation time also takes even longer than the naive single level association mining Parallel pro cessing is essential for such heavy mining processing Acknowledgments This research is partially supported as a priority research program by ministry of education We would like to thank the F\221ujitsu Parallel Computing Research Center for allowing us to use their APlOOODDV sys tems References l R.Agrawal T.Imielinski and ASwami 223Min ing Association Rules between Sets of Items in Large Databases\224 In Proc of the 1993 ACM SIGMOD International Conference on Manage ment of Data pp207-216 May 1993 2 R.Agrawal and RSrikant 223Fast Algorithms for Mining Association Rules\224 In Proc of the 20th International Conference on Very Large Data Bases pp.487-499 September 1994 3 J.S.Park M.-S.Chen and P.S.Yu 223An Effec tive Hash-Based Algorithm for Mining Associ ation Rules\224 In Proc of the 1995 ACM SIG MOD International Conference on the Manage ment of Data SIGMOD Record Vo1.24 pp.175 186 June 1995 4 H.Mannila H.Toivonen and A.I.Verkamo 223Ef ficient Algorithms for Discovering Association Rules\224 In KDD-94:AAAI Workshop on Knowl edge Discovery in Databases pp.181-192 July 1994 5 A.Savasere, E.Omiecinski and S.Navathe 223An Effective Algorithm for Mining Association Rules in Large Databases\224 In Proc of the 21th International Conference on Very Large Data Bases pp.432-444 September 1995 6 J.S.Park M.-S.Chen and P.S.Yu 223Efficient Parallel Data Mining for Association Rules\224 In Proc of the 4th International Conference on In formation and Knowledge Management pp.31 36 November 1995 7 T.Shintani and M.Kitsuregawa 223Considera tion on Parallelization of Database Mining\224 In Institute of Electronics Information and Com munication Engineering Japan SIG CPS Y95 88 Technical Report Vo1.95 No.47 pp.57-62 December 1995 8 T.Shimizu T.Horie and H.Ishihata 223Perfor mance Evaluation of the APlOOO Effects of message handling broadcast and barrier syn chronization on benchmark performance-\224  In S WO PP 22292 9.2 ARC 95 Information Processing Society of Japan Vo1.92 No.64 1992 9 R.Srikant and R.Agrawal 223Mining Generalized Association Rules\224 In Proc of the 21th Inter national Conference on Very Large Data Bases pp.407-419 September 1995 30 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



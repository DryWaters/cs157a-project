Research on Customer Segmentation in Retailing Based on Clustering Model Zeying Li Dept. of Math and Information Technology Hanshan Normal University Chaozhou China  lizeyld@163.com   Abstract 227Data mining can efficiently deal with the large number of historical and current data, from the database can find some potential, useful and valuable information for the retail stores The paper takes a large retail supermarket as its study object 
use data mining methods to retail enterprise customer segments and then use association rules to different groups of customer and get rules about customer characteristics to make customer characteristic analysis. Finally, give some references to the supermarket's marketing and management work Keywords data mining;clustering analysis; K-means;customer value matrix I    
20 8 0  80 20       II   A  k-means  K-means 1    
K-means    k       n  k    
 212 m l ilil ij cxd 1 2  m   2 1 
002 212  n iS x ji ji cxE  j =1,2,\205\205,k, Sj  cj  
 B    Marcus\(1998 F A  RFM 2           1   
1              D  
C  B  A         3437 978-1-4244-9763-8/11/$26.00 \2512011 IEEE 


III       Transaction    A     basket   Member  AverageAmount  AvgA  TransactionCount TC     1 A  AvgA TC  2  B AvgA TC  3 C  AvgA TC  4 D  AvgA TC       AvgA TC    B      1   AverageAmount TransactionCount  1  1   AverageAmount TransactionCount MIN 0 0 MAX 7272.533 435 MEAN 121.714 24.529    0    TC   TC- TC min TC max TC min  AvgA  AvgA- AvgA min AvgA max AvgA min   TC AvgA  2 2 AvgA TC     AvgA TC     2 TC AvgA    2    K-mean K-mean  K=2  K=2 3 4 5  3  k=4     3 K    3    K=4 K-mean  4  2   4   3438 


 2   AvgA TC  Cluster1 73 Mean = 0.323 SD = 0.238 Mean = 0.681 SD = 0.223   Cluster2 6361 Mean = 0.041 SD = 0.047 Mean = 0.07 SD = 0.053   Cluster3 863 Mean = 0.038 SD = 0.047 Mean = 0.331 SD = 0.124   Cluster4 3697 Mean = 0.498 SD = 0.035 Mean = 0.003 SD = 0.022   SD Standard Deviation  3      k-mean  5    A Cluster-1 73  1   B Cluster-4 3697 33    C  Cluster-3 863  8   D  Cluster-2 6361 58   5  C    1   6  A  1  C  8  8000000  D  D  2   A 7  1 C D 1/7 D     6   7    3   8   A    B   D       8   3439 


IV         A     5  A1[18-2 A 2 23 34  A 3 35 40  A4[41-60  A 5  6 1      Rl, R2, R3, R4 R5, R6 6  S1,S2     A  B C  C  10  70  B    Apriori  9     9   C    A A  19  3  1  A5 \( 61   32.117   2  44.681  R2  R2 3  A 75 8  R2   3 A   Consequent Antecedent Support% Confidence 1 A  A5 32.447 100.0 2 A  R2 44.681 100.0 3 A sex  75.0 100.0 4 A Sex and A5 10.638 100.0 5 A  A3 and sex  21.277 100.0 6 A  A5 and R2 17.553 100.0 7 A  A5 and sex  21.809 100.0 8 A  R2 and sex  34.043 100.0     R2  A5 \(61     B C  D    V           WQ200806   R EFERENCES  1  LIU Qiang; WU Jing-hui , \223Optimizing initial cluster center of K-means algorithm,\224 Information Technology ,2009\(02\: pp. 71-73. \(In Chinese 2  ZHOU Huan, \223The Process of Cluster Customers Based on the RFM Model,\224  Journal of Jinling Institute of Technology. Vol. 24. No 1,2008\(01\ : pp. 33-36. \(In Chinese 3  ZHAO Xiao-yu~1; HUANG Xiao-yuan~1; SUN Fu-quan~2, \223An Optimization Model for Promotion Mix Strategy Based on RFM Analysis,\224 Chinese Journal of Management Science. Vol. 13.  No 1,2005 \(01\ :pp.60-64.\(In Chinese 4  J.Han,M.Kamber,Data Mining Concepts and Techniques, Morgan Kaufmann Publishers,2000 5  Wagner A. Kamakura, Michel Wedel, Fernando de Rosad, Jose Afonso Mazzone. Cross-selling through database marketing: a mixed data factor analyzer for data augmentation and prediction[J I n t e rn  J  of R e s e a r ch in Marketing 20 \(2003\ 45\22665 6  DONG Yin-di, \223Application of Association Rules in Data Mining in the Retail,\224 Journal of Chongqing University of Science and Technology\(Natural Sciences Edition\, Vol. 12.  No. 1,2010 \(02 pp.121-123.\(In Chinese  3440 


consider situations in which query Q imposes a more restrictive set of constraints with respect to a previous query, here denoted with Qi. Item dependent constraint is exploited to simplify the problem of incremental mining. In order to retrieve the desired rules, it suffices to identify the rules in the previous results that satisfy the new constraints. As the results imply, this is not generally true in a situation involving context-dependent constraints. In fact, in the latter case, one needs to carefully update the statistical measures of the rules as well Under the item dependency assumption, whenever a query Qi is found to contain Q, it is rather easy to extract the new results from past ones. It suffices to search in Ri those rules which satisfy the requirements of Q and to copy them verbatim \(along with their support counts proposed for item dependency checks which of the rules in Ri satisfy the constraints in Q and updates R accordingly. It is important to notice that testing TB and TH is a feasible and efficient operation. In fact, since the constraints are item dependent, their evaluation does not require to access the whole possibly huge to access the dimension tables and to check the constraints using the information found therein. Since those tables does usually fit into the main memory or in the DBMS buffer memory, this rarely becomes a demanding operation. In addition, the E constraint is also easily checked by using the statistical measures stored together with the rules in the past result   Fig. 1  Incremental algorithm for item dependency B. Context  Dependent Incremental Algorithm Proceedings of the International Conference on Communication and Computational Intelligence 2010  521  In the context dependent incremental algorithm, construct the result of a new mining query Q starting from a previous result Ri even when the mining constraints are not item dependent The algorithm is best described by considering two separate steps. In the first one, the algorithm reads rules from Ri and builds a data structure which keeps track of them. This structure 


is called as BHF \(Body-Head Forest starting from a previous result set and represent only rules found therein, this corresponds to a first pruning of the search space. Subsequent operations will simply disregard rules that do not appear in it. In the second step, the algorithm considers two relations Tb = { < i,g > | i E IB, g E G, TB is true} and Th = { < i,g > | i E IH, g E G, TH is true Containing the items and the group identifiers \(GIDs satisfy the mining constraints in query Q. Tb and Th are obtained by evaluating the constraints on the fact table. Their role is to keep track of the context in which the item sets appear. In fact, the context dependent constraints require that their validity is checked group by group. The two relations fulfill this purpose. The search space is pruned. In fact, the constraints are evaluated on the database and the items which do not satisfy the mining constraints are removed, once and for all, from the input relations. Finally, the algorithm updates the counters in the BHF data structure accordingly to the item sets found in Tb and Th. The counters are then used to evaluate the statistical measures needed to evaluate whether the constraint E is satisfied   Fig. 2  Incremental algorithm for context dependency  IV. EXPERIMENTAL EVALUATION The experimentation is conducted for the data set of Customer Car Purchase obtained from UCI Repository using Java SDK libraries to prove the efficiency of the incremental update strategy for item set extraction in the mining context On experimenting the Car Purchase data set, the devised java program has been run using parameters with  T = 25, I = 10, N 13, D = 2600, i.e., the average transaction size is 25, the average size of potentially large item sets is 10, the number of distinct items taken for consideration is 13 and the total number of transactions is 2600. Then, this initial table is updated by adding some attributes which provide the details \(and the contextual information We added some item dependent features \(such as category of product and price such as discount and quantity 


have been generated randomly using uniform distributions on the respective domains. A single fact table suffices for the objectives of our experimentation While, in fact, the characteristics of the database instance e.g., total database volume and data distribution determinant in order to study the behavior of mining algorithms, this is not so when we are up to study incremental algorithms. Indeed, as simple complexity considerations point out, the important parameters from the viewpoint of the performance study of incremental algorithms are the selectivity of the mining constraints \(which determine the volume of data to be processed from the given database instance of the previous result set  Fig. 3  Item dependent incremental algorithm \(constraint selectivity Vs execution Fig. 3 reports the performances of the item dependent incremental algorithm \(ID mining constraints changes. The experimentation is carried out for different constraints on the item dependent attributes letting the constraints selectivity vary from 0% to 100% of the total number of items The Fig. 4 presented tests the same algorithm, but it lets vary the number of rules in the previous result set. Again we sampled twenty points \(in the range 0  220 figures report the total amount of time needed by the algorithm to complete In particular, the bars, which represent the single experiments, are divided in two components: the preprocessing time \(spent in querying the database to retrieve Incremental Update Strategy for Indexed Item Set Mining  522  and store in main memory the items that satisfy the constraints needed by the algorithm to read the previous result set and to filter out those rules that do not satisfy the constraints any more Fig. 5 and 6 report the performances of the context dependent CD time, specifying how much time was spent for preprocessing and for the core mining task 


  Fig. 4  Volume of previous result Vs execution time for Item dependent incremental algorithm It is worth noticing, that the CD incremental algorithm performs a greater amount of work with respect to the ID algorithm because the problem it solves is far more complex In fact, in the preprocessing phase the algorithm must retrieve all the group/item pairs satisfying the constraints and access to them in order to build and update the BHF data structure Only then, it can retrieve the results from the BHF structure  Fig. 5  Context dependent constraint selectivity Vs execution The execution times of both algorithms increase almost linearly with the increase of the two parameters \(constraint selectivity and previous results item dependent incremental algorithm runs much faster than its counterpart  Fig. 6  Volume of the previous result Vs execution time Both the algorithms are faster than the IMine algorithm which, is incapable of solving a class of more difficult problems of mining item set extraction from contextdependent constraints. IMine, as the most of the algorithms operates starting from scratch. Hence, comparisons of incremental update strategy with other mining algorithms on the field of context dependent constraints show better performance quantifying to 7% improvement Must be in two column format with a space of 4.22mm 0.17 V. CONCLUSIONS The proposed incremental update approach to constraintbased mining makes use of the information contained in previous results to answer new queries in frequently updating databases. The beneficial factors of the approach are that it uses both the previous results and the mining constraints, in order to reduce the item sets search space. It comprises of item dependent and context dependent constraints for extracting item sets Proposed approach makes a significant usage of available results of previous queries \(if the incremental approach results effective with respect to a conventional execution 


incremental option for a data mining algorithm is of course preferable in an inductive database system, since it allows the exploitation of all the available information in the system in order to speed up the response time The better performance of incremental algorithm depicted in the result section  worked on problems with item and context dependent constraint present a solution for item extraction from frequently updated database. This is done by running first the  Proceedings of the International Conference on Communication and Computational Intelligence 2010  523  mining algorithm of our choice \(on the problem defined by the query but without the context dependent constraints then applying the incremental algorithm on top of it \(with the addition of context dependent constraints whenever the mining constraints select a very small part of the original dataset, proposed incremental update strategy is likely to be very fast and efficient REFERENCES 1]  G. Grahne and J. Zhu, Mining Frequent Itemsets from Secondary Memory, IEEE Intl Conf. Data Mining \(ICDM 04 2]   J. Han, J. Pei, and Y. Yin, Mining Frequent Patterns without Candidate Generation, ACM SIGMOD, 2000 3]  Y.-L. Cheung, Mining Frequent Itemsets without Support Threshold With and without Item Constraints, IEEE Trans. Knowledge and Data Eng., vol. 16, no. 9, pp. 1052-1069, Sept. 2004 4]   G. Cong and B. Liu, Speed-Up Iterative Frequent Itemset Mining with Constraint Changes, IEEE Intl Conf. Data Mining \(ICDM 02 107-114, 2002 5] C.K.-S. Leung, L.V.S. Lakshmanan, and R.T. Ng, Exploiting Succinct Constraints Using FP-Trees, SIGKDD Explorations Newsletter, vol. 4 no. 1, pp. 40-49, 2002 6]  T. Uno, M. Kiyomi, and H. Arimura, LCM ver. 2: Efficient Mining Algorithms for Frequent/Closed/Maximal Itemsets, IEEE ICDM Workshop Frequent Itemset Mining Implementations \(FIMI 7]   J. Pei, J. Han, and L.V.S. Lakshmanan, Pushing Convertible Constraints in Frequent Itemset Mining, Data Mining and Knowledge Discovery, vol. 8, no. 3, pp. 227-252, 2004 8]   M. Botta, J.-F. Boulicaut, C. Masson, and R. Meo, A Comparison 


between Query Languages for the Extraction of Association Rules 9]  E. Baralis, T. Cerquitelli, and S. Chiusano, Index Support for  Frequent Itemset Mining in a Relational DBMS, 21st Intl Conf. Data Eng ICDE 10]   G. Liu, H. Lu, W. Lou, and J.X. Yu, On Computing, Storing and Querying Frequent Patterns, Ninth ACM SIGKDD Intl Conf Knowledge Discovery and Data Mining \(SIGKDD 


frequent, and there is no equal-support pruning in its subsets. So the Bitwise And Operation on binary strings of 0001100011 and 0001100011 is employed. As the result is 0001100011, the support of the itemset {G C, E} is 4, which is equal to {G, C}. E is put into the equal-support set of {G, C}, and does not need to add a new son node. When itemset {C, A, E} is checked, all of its subsets are frequent, and none of them is in the equal-support set. The corresponding two bit strings 0001101111 and 0011101011, are operated by &. The resultant string is 0001101011. The number of 1 in string 0001101011 is 5. So the support of itemset {C, A E} is 5, which is not equal to the support of {C, A}. So a new son node is added to {C, A}. The Trie after generation\(3  5 8 8 G C A E A 4 C 4 E 6 A 6 E 6 E 7 5 E 0001101011 E  Fig. 2. Trie after generation\(3 In generation\(4 therefore, the height of the Trie does not increase. All frequent itemsets are in Fig. 2. In the last step, all frequent itemsets are written out according to the Trie  5. EXPERIMENTAL RESULTS  


The proposed algorithm is tested on all the five datasets prepared by Roberto Bayardo, from UCI and PUMSB datasets. The datasets are available at http://fimi.cs.helsinki.fi. The characteristics of the datasets are shown in Table 6. The first column contains the names of the datasets. The second column shows the number of items contained in each dataset. The third column shows the average length of each transaction and the last column indicates the total number of transactions in each dataset TABLE 6 DATABASE CHARACTERISTICS Datasets Items Avg. length Records mushroom 119 23 8,124 chess 75 37 3,196 pusmsb* 2,088 50.4 49,046 connect 129 43 65,557 pusmsb 2,113 74.0 49,046 In order to illustrate the performance of the proposed algorithm, BitApriori is compared to the fast Apriori implemented in Ferenc [20], and another similar recently published, algorithm Index-BitTableFI proposed by Song [16]. In order to show the efficiency of the pruning technology employed in BitApriori another algorithm BitAprioriNE, which is the same as BitApriori, except that it does not use the special equal-support pruning, is designed. All of the above four algorithms are implemented in C++ and compiled with Microsoft Visual C++ 6.0. The experiments are performed on a Windows XP PC equipped with a Pentium 2.0 GHz CPU and 1.5 GB of RAM memory  For each dataset, a mass of different support thresholds are tested, and the five most important of them are chosen for reporting in this paper. The experimental results are shown in Fig. 3-7. In the figures, the y-coordinate denotes the execution time \(in seconds while x-coordinate denotes the support threshold 0 100 200 300 400 


500 600 0.05 0.06 0.07 0.08 0.09 0.1 0.11 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.3 Execution time comparison on mushroom  0 200 400 600 800 1000 0.45 0.5 0.55 0.6 0.65 0.7 0.75 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.4 Execution time comparison on chess  0 500 1000 1500 2000 2500 3000 3500 4000 0.25 0.3 0.35 0.4 0.45 0.5 0.55 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.5 Execution time comparison on pusmsb 0 1000 


2000 3000 4000 5000 6000 0.65 0.7 0.75 0.8 0.85 0.9 0.95 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.6 Execution time comparison on connect  0 500 1000 1500 2000 2500 0.675 0.725 0.775 0.825 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.7 Execution time comparison on pusmsb  As shown in Fig. 3, BitApriori outperforms all other algorithms, and the dominance is apparent. In this dataset, the special equal-support pruning works efficiently. In Fig. 4, BitAprioriNE beats Apriori and Index-BitTableFI. In Fig. 5, the effectiveness of the proposed algorithm is verified, especially when the minimum support is low. In Fig. 6, BitAprioriWE exhausts the memory when the support threshold is lower than 0.8, but BitApriori does not. That means the special equal-support pruning contributes to save the memory. In Fig. 7, when the threshold is larger than 0.725, Apriori beats the BitApriori. But BitApriori outperforms the Apriori, when the threshold is lower than 0.725  


Apriori does not use the binary string and the special equal-support pruning. The BitTable is employed in Index-BitTableFI, but there is no special equal-support pruning, except for the frequent 2-itemsets BitAprioriNE outperforms Apriori in Fig. 3-5, but not in Fig. 6-7, because of the limitation of memory BitAprioriNE does better than Index-BitTableFI in Fig 4 and Fig. 5. In the mushroom, there is a vast number of equal-support itemsets for frequent 2-itemset. So Index-BitTableFI outperforms BitAprioriNE  On one hand, the special equal-support pruning is a useful technique for improving efficiency. The performance is improved significantly, especially when the databases contain many equal-support itemsets, such as the mushroom. It also reduces memory requirement On the other hand, the technique of binary string in BitApriori improves the efficiency of Apriori. These two techniques combine perfectly in BitApriori. So BitApriori has very good performance. It is the best for all of the five datasets  6. CONCLUSIONS  In this paper, two effective techniques are employed to improve the performance of Apriori, by reducing the cost of candidate generation, and by support counting The two effective techniques are integrated perfectly in BitApriori, and improve the computational efficiency significantly. Experimental results have shown that BitApriori outperforms the fast Apriori and Index-BitTableFI, especially when the minimum support threshold is low  When the database is large, the BitApriori may suffer the problem of memory scarcity. So how to solve the memory problem will be the question addressed in one of our future works. And another work is to improve Bitwise And Operation on the binary string, or replace it by some more effective techniques  REFERENCES 


 1] Agrawal R., T. Imielinski, A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the ACM SIGMOD Conference on Management of Data. pp. 207-216 1993 2] Agrawal R., R. Srikant, Fast algorithms for mining association rules, The International Conference on Very Large Databases, pp. 487-499, 1994 3] Zaki M.J., S. Parthasarathy, M. Ogihara, W. Li New algorithms for fast discovery of association rules, in Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, pp. 283-296, 1997 4] Han J., J. Pei, Y. Yin, Mining frequent patterns without candidate generation," in Proceedings of the 2000 ACM SIGMOD international conference on Management of data, ACM Press, pp. 1-12, 2000 5] Pork J.S., M.S. Chen, P.S. Yu, An effective hash based algorithm for mining association rules, ACM SIGMOD, pp. 175-186, 1995 6] Brin S., R. Motwani, J.D. Ullman, S. Tsur Dynamic itemset counting and implication rules for market basket data, in Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 255264, 1997 7] Brin S., R. Motwani, C. Silverstein, Beyond market baskets: generalizing association rules to correlations, in Proceedings of the ACM SIGMOD International Conference on Management of Data Tuscon, Arizona, pp. 265-276, 1997 8] Toivonen H., Sampling large databases for association rules, in Proceedings of 22nd VLDB Conference, Mumbai, India, pp. 134-145, 1996 9] Savasere A., E. Omiecinski, S.B. Navathe, An efficient algorithm for mining association rules in large databases, in Proceedings of 21th International Conference on Very Large Data Bases VLDB'95 10] Tsay Y.J., J.Y. Chiang, CBAR: an efficient method for mining association rules, Knowledge Based Systems, 18 \(2-3 


11] Liu G., H. Lu, W. Lou, Y. Xu, J.X. Yu, Efficient mining of frequent patterns using ascending frequency ordered prefix-tree, Data Mining Knowledge Discovery, 9 \(3 12] Grahne G., J. Zhu, Fast algorithms for frequent itemset mining using FP-Trees, IEEE Transaction on Knowledge and Data Engineering, 17 \(10 1347-1362, 2005 13] Zaki M.J., Scalable algorithms for association mining, IEEE Transactions on Knowledge and Data Engineering, 12 \(3 14] Zaki M.J., K. Gouda, Fast Vertical Mining Using Diffsets, in Proceedings of the ACM SIGMOD International Conference on Knowledge Discovery and Data Mining, pp. 326-335, 2003 15] Dong J., M. Han, BitTableFI: an efficient mining frequent itemsets algorithm, Knowledge Based Systems, 20 \(4 16] Song W., B.R. Yang, Z.Y. Xu, Index-BitTableFI An improved algorithm for mining frequent itemsets, Knowledge Based Systems, 21 \(6 507-513, 2008 17] Ferenc B., Surprising results of trie-based FIM algorithms, IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'04 CEUR Workshop Proceedings, vol. 90, G. Bart, J.Z Mohammed, and B. Roberto, Eds, Brighton, UK 2004 18] Ferenc B., A Survey on Frequent Itemset Mining Technical Report, Budapest University of Technology and Economic, 2006 19] Bart G., Survey on Frequent Pattern Mining Manuskript, 2002 20] Ferenc B., A fast APRIORI implementation IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'03 USA, 2003  


15] R. Agrawal and R. Srikant, "Fast algorithms for mining association rules in large Databases," presented at the Proceedings of the 20th International Conference on Very Large Data Bases, 1994 16] NKUDIC. \(June, 2006, National Kidney and Urologic Diseases Information Clearinghouse:Prostate Enlargement. Available http://kidney.niddk.nih.gov/kudiseases/pubs/prostateenlargement accessed on 10/06/2010 17] M. J. ZAKI, "Mining Non-Redundant Association Rules," Data Mining and Knowledge Discovery, 2004 18] Y. Xu and Y. Li, "Mining for Useful Association Rules Using the ATMS," presented at the International Conference on Computational Intelligence for Modelling, Control and Automation, and International Conference on Intelligent Agents, Web Technologies and Internet Commerce \(CIMCA-IAWTIC05 544 2010 10th International Conference on Intelligent Systems Design and Applications 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



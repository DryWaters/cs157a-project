Galois  Lattice for Web  Sequential Patterns Mining  Zhennan Zhang 1 Xu Qian 1 Yu Zhao 2  1 School of Mechanical, Electr onic & Information Engineering China University of Mining & Tec hnology \(Beijing\, Beijing , 100083, China 2 Luohe economic Development Zone,Luohe,Henan,462000,China   Abstract  Along with the rapid developme nt of the Internet,Web has become most importmant resource  of information.It is getting more difficult to fa st and accurately find useful information from the gigantic amount of data provided by Web.The Web usage mining is the process inferring valuable knowledge by analyzing users’ access information ,which is of great significance for better managing web sites and further developing good electronic education.In this paper we applied Galois lattice to mine Web sequential access patterns by representing  the paths traversed using graphs.An incremental and efficient mining algorithm was put forward for increasing specific day’ Web log and changing transaction base.Experimental results on reallife data sets demonstrated the effectiveness of the novel algorithm  1. Introduction  The World-Wide-Web has meraged as an important dissemination of information related to a wide range of topics.These huge amounts of data raise a grand challenge,namely, how to turn the web into a more useful information utility  Web mining technique is believed to be one of  methods to strike the useful information from these amounts of data on various web sites.Etzioni  first coined the term Web mining.He gave a definition of Web mining,as the use of data mining techniques to automatically discover and extract information from Web documents and service.Web mining is categorized into three areas of interest based on which part of the web to mine:web content mining,web structure mining and web usage mining  Web usage mining is the application of data mining techniques to large user access logs in order to extract usage patterns  Web usage mining techniques have becomed  important for a number of applications such as web sites design,business and marketing decision support,personalization,usability studies,and network traffic analysis.It includes techniques for discovering association rules,clustering,classification,and sequential patterns mining The  sequential patterns mining in web server log is one of the most important issues in web usage mining.Its target is to find  frequently visited paths which is ordered by time in a web site.The discovery of  sequential patterns allows organizations to predict user visit patterns.It also help in placement of navigation bars and search engines to personalize their navigation by guiding web users to reach their target web pages rapidly. The follwing example shows the kind of  knowledge that can be discovered using the sequential patterns mining technique:starting from Yahoo’s home page,users can locate information on University in China by following either Home 001\027 Education 001\027 Higher Education 001\027 Colleges and Universities 001\027 By Region 001\027 Countries 001\027 China or Home 001\027 Regional 001\027 Countries 001\027 China 001\027 Education 001\027 Higher Education.Thus,a university that wants to attract prospective students can place a navigation bar on any of the pages along the path. The sequential patterns mining inherits the mian idea of association rules mining 5 but it is more sophisticated than the association rules mining.Although a lot of work has been proposed for mining sequential patterns from web server log  including AprioriALL, GSP,PSP,G sequence and graph traversal algorithms,these algorithms have questions:the number of scanning transaction database is large;no sustaining dynamic minimum support value;redundant calculation for building frequent sequences;no incremental algorithm has been reported.In this paper,we will discuss a novell algorithm based on connecting graphs with Galois lattice for mining sequential patterns from web server log to slove four questions above  2. Galois lattice for graphs    2.1. Galois lattice  Galois lattice has been developed during the last twenty years by many researchers.This approach to data analysis is a method for formal representation of conceptual knowledge.Galois lattice starts with the notion of a context defined as follows   Definition 1 A context which  is defined as a triple G,M,I\where G and M are sets while I is a binary 
2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application 978-0-7695-3490-9/08 $25.00 © 2008 IEEE DOI 10.1109/PACIIA.2008.41 102 
2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application 978-0-7695-3490-9/08 $25.00 © 2008 IEEE DOI 10.1109/PACIIA.2008.41 102 
2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application 978-0-7695-3490-9/08 $25.00 © 2008 IEEE DOI 10.1109/PACIIA.2008.41 102 


relation between G and M,i.e.,I  G  M;the elements of G and M are called objects and attributes respectively,and gIm i.e.,\(g,m  I is read:the object g has the attribute m.Frequently used are the following operators are represented by prime X  X  M|gIm for all g  X Y  Y  G|gIm for all  m  Y In the frame of a formal context \(G,M,I\e philosophical view of a concept as a unit of thoughts constituted by its extension and its intension can be formalized by the following definition Definition 2 A pair \(A,B\ is said to be a formal concept of the context \(G,M,I\ A  G, B  M, B  A and A  B\ and B are called the extent and the intent of the concept \(A,B\he set of all concepts of \(G,M,I denoted by B\(G,M,I The most important structure on  B\(G,M,I\ is given by the subconcept-superconcept relation which is defined as follows Definition 3 The concept \(A1,B1\ a subconcept of the concept \(A2,B2\ A1  A2 which is equivalent to B2  B1,\(A2,B2\s then a superconcept of \(A1,B1  2.2. Galois lattice for graphs  To mine for the web frequent access sequences traversed by the users,we can represent the paths traversed using graph.A graph is denoted by G\(V,E,L\,where V is the set of web pages as vertices,E is the set of hypertext links between the web pages traversed by the users as directed edges,and L is the set of labels of the graphs.The vertex set of a graph is denoted by V\(G\,the edge set of a graph is denoted by E\(G\,and each edge is denoted by an ordered pair \(v1,v2\here v1 and v2  V\(G Galois lattice for graph is defined as follows 1  a set of the paths traversed using graphs 2\ set of  graphs where each of them represents a set of objects from the  D is built using a generalization operator   3\ent of D which represents a set of objects from the   4  the order relation G×G true,false}.The order is based on the homomorphism operation.The homomorphism operation is not the same as the subgraph isomorphism,in the homomorphism mapping from G1 to G2, G2 must reflect the vertices and edges from G1 \(i.e.,if v1,v2\resent in G1, it must be present in G2 \ but G2 may have vertices and edges that are not present in G1 i.e.,if  G2 contains \(v1,v3\ight not be present in G1 he homomorphism operation is defined as a mapping f\(v\:G1 G2  such that: f\(v\: V\(G1 V\(G2\d f\(v1\\(v2  E\(G2\d L\(vl\\(f\(vl\his means that the second graph needs to contain all the pairs of related vertices contained in the first graph.For two graphs G1 and G2, G1  G2  iff there is a homomorphism from G1 to G2 5  the generalization operator G×G D for graphs.The result of operator of two graphs  G\(V,E,L G1\(V1,E1,L1  G2\(V2,E2,L2\s defined by L  = L1 L2 V = {v|L\(v\\(v1\\(v2 E  = {\(x,y\|\(v1,v`1  E1 , \(v2,v`2  E2  and L\(x\= L\(v1\\(v2 L\(y\= L\(v`1\\(v`2 By this setting, a concept for graph can be defined as follows: a set of the paths traversed using graphs i.e  a set of  graphs where each of them represents a set of objects from the  i.e. D and a concept C is a pair Ext,Int w h e r e  Int  D   Int  Ext  e  Ext Ext   Ext  Int   Int  ei Obviously  we can prove that    Ext\t.So the pair [Ext,Int a con cept.A l l th e con cepts are oedered by  the superconcept-subconcept relation  c E1  c  [E2 f E2  E1 Also can we prove that  is a partial order The Galois lattice for graphs starts with the creation of an empty lattice.The  is then added to the first level of the lattice.For the rest of the levels,new cioncepts are created using the generalization operator  over pairs of concepts that have alreadly been found in previous steps.The process is followed to create the Galois lattice shown in figure 1 1            2           3             4 a            a            a             b   c            c            b             d   d            b           d             a a          b Figure 1 A Galois lattice example;\(a\ set of the paths using graphs;\(b\Galois lattice obtained from part \(a     a c d   a c b    a b d    b d a  1 ,2  a c    b d  1  2  3  4       
103 
103 
103 


For example,user 1 has accessed web pages a then c and d ; user 2 has accessed web pages a then c and b in figure 1. By using the generalization operator  over user 1 and 2,we can find that user 1 and 2 have accessed web pages a then c  3.Algorithm for sequential patterns mining  Using Galois lattice for graphs ,the mining for web sequential patterns can be accomplished in three steps:extracting maximal forward reference paths from web server log;constructing Galois lattice for graphs from the output of the first step;discovering web closed frequent access sequences based on the result of the second step 1\tracting maximal forward reference paths from web server log In web usage mining, we want to concentrate on the discovery of forward access sequential patterns.In other terms the access paths denoted by graphs need to be ordered,it is not possible have equivalent  graphs in the Galois lattice for graphs,i.e. it does not contain proper retracts.A subgraph G’ of G is a retract of G if there is a homomorphism r:G G’such that r\(v\v for each v  V\(G’\his means that G’ represents the same graph as G even when it has a smaller number of vertices.Figure 2 shows and example of a react       G1                                   G2 Figure 2  Example of a retract: G2 is a retract of G1   Briefly,maximal forward reference \(MFR\ a user access path without backward reference.Backward reference means revisiting a previously visited web pages by the same user access. Backward reference is mainly provided for ease of traveling of not for browsing. We should filter out the effect of backward references.So MRF can be used to solve the problem such that it is a unredundant graph in the user access path. To build Galois lattice for graphs to mine for web  access sequential patterns,we first need to find all the maximal forward references.To find the MFR from the user access transaction,we used the technique described in d the  maximal forward reference algorithm was described in 7 T he fo l l o w i n g i s a n e x a m p l e o f  fi nd i n g ma xi ma l  forward reference from a web user access transaction.From the example,we can find that all MFRs there exist no equivalent  graphs In the frame of the MFR,the web access sequence can be formalized by the following definition               Transaction of a user access A,B,C,D,C,B,E,G,H,G,W,A,O,U,O,V MFRs found ABCD,ABEGH,ABEGW,AOU,AOV Figure 3 A example of discovering maximal forward references  Definition 4 Web access sequence is a time-ordered set of visits.It is defined as s=<id,\(v1, v2, vi vn  where 1 i n,vi.id=s.id, vi.time<vi+1.time and \(v1 v2, vi,….. vn\ a MFR. An access sequence s that consists of k web pages\(k  s also called a ksequence.Then web access sequence database is defined as WAS={ s1, s2, si,….. sn  },where each s  WAS is a web access sequence 2\nstructing Galois lattice for graphs from the output of the first step In Galois lattice analysis,the problem of generating the set of all concepts of a formal context and constructing the diagram graph of the concept lattice has been well studied.Since lattices can grow exponentially large,leading to correspondingly large computational requirements,efficient  algorithms for the construction of concept lattices are of key importance.According to the definition of Galois lattice for graphs,we use a incremental construction algorithm,called AddAtom 8 to generate our algorithm in this paper.Being incremental the algorithm takes as input the lattice Li  produced by the first i objects of the context,inserts the next object g to generate a new lattice Li+1 and uses four sets of concepts:modified concepts generator concepts,new concepts and old concepts in the process of lattice construction.A concept\(C,D  Li+1  is new if D is not an intent of any concept in Li. We call a concept \(A,B   Li  modified concept if B   g\since g has to be added to its ectent in Li+1. Otherwise,B  g B for some concept \(C,D  Li+1. If \(C,D\ a new concept then \(A,B\ called a generator concept of  \(C,D\f not,\(A,B\ old concept.A more detailed discussion can refe  U V H G E D C B A O W D C D C C 
104 
104 
104 


 Algorithm1  Procedure CreateLatticeIncrementally   TopConcept     L:={TopConcept For each g in   ObjectConcept:=AddIntent  g\opConcept,L Add g to the extent of ObjectConcept and all concepts above End for Function  GetMaximalConcept\(intent,Generator_ Concept,L parentIsMaximal:=true While parentIsMaximal parentIsMaximal:=false Parents:=GetParents\(Generator_ Concept,L For each Parent in Parents If  intent  Parent.intent Generator_ Concept:=Parent parentIsMaximal:=true End If End For Return Generator_ Concept  Function  AddIntent\(intent,Generator_ Concept,L Generator_Concept:=GetMaximalConcept intent,Generator_ Concept,L If Generator_ Concept.intent=intent Return Generator_ Concept End If GeneratorParents:=GetParents\(Generator_ Concept,L NewParents   For each Candidate in GeneratorParents If Candidate.intent not  intent Candidate:=AddIntent\(Candidate intent  intent Candidate,L End If AddParent:=true For each Parent in NewParents If Candidate .intent  Parent.intent AddParent:=false Exit For Else If  Parent.intent  Candidate .intent Remove Parent from NewParents End If End For If AddParent Add Candidate to NewParents End If End For NewConcept:={Generator_ Concept.extent,intent L:=L NewConcept Return NewConcept 3\covering web frequent closed access sequence patterns based on the result of the second step In this paper our aim is to detect web frequent closed access sequences.Since frequent closed access sequences include all information of frequent access sequences.We can get all frequent access sequences from frequent closed access sequences.By the means we slove the third question above.For such a task,we require to discover the access sequences in WAS with a support value above or equal to the user-defined minimum support value Definition 5 Let the support value of web access sequence s in WAS={ s1, s2, si,….. sn  } be defined as sup\(s\=|{ s1|s1  s}|/n Given a user-defined minimum support value a sequence s is said to be frequent if the condition sup\(s  a holds.A frequent  access sequence s is called closed if there exists no  supersequence s’ that  have equal support value with the subsequence s In Galois lattice ,the intent for every concept C1=\(A1,B1\d C2=\(A2,B2\ is maximum, i.e. if B2  B1, we can get  B2   B1\ =C1. So we have the following definition in the frame of the Galois lattice for graphs Definition 6 An web access sequence  y that satisfies    y\y  is called web closed access sequence Definition 7   A web frequent closed access sequence is a closed access sequence which is also frequent.That is,it has support value greater than or equal to userdefined minimum support value According  to properties of Galois lattice for graphs and definition 6,we know all members of the Galois lattice for graphs satisfy    y\y ,so that all intents of concepts in the Galois lattice for graphs are web closed access sequences.Furthemore,we can attach frequency information to each concept in the Galois lattice for graphs by means of a function f:C N  such that it returns frequency of extent  for a given concept c  C.Assume there exits a concept c in the Galois lattice for graphs,then sup\(c.Int\\(c\f  where  is bottom concept. In the figure 1 it is concept {[1,2,3  If sup\(c.Int a,then the c.Int is a web frequent closed access sequence,it can be gotten in the process of lattice construction.In the figure 1 we can get two web closed frequent  access sequences a c and b d whose support value are all 50%,if the minimal support value is 30%.Beacuse the information for web frequent closed access sequences stored in Galois lattice for graphs,we can scan web access transaction database once to get all web frequent closed access sequences and purne Galois lattice for graphs when a user-defined minimum support value is changed. By these policies   we  can completely slove  four questions above  
105 
105 
105 


4. Experimentation and conclusions  We have implemented the algorithm described above and used the user access logs from China University of Mining & Technology \(Beijing\’Web Server to carry out our experiment.The user access logs for the web site that were made available to this research contain about 10000 entries from February 10,2008 to March 10,2008 Experimental results demonstrated the effectiveness of the novel algorithm whose average CPU time showed that it had performed quite well as compared to batch alogithm AprioriALL.The chart below shows the running time for our algorithm,as well as AprioriALL algorithm              Figure 4   CPU time for transaction  Theoretically the Apriori-like algorithms need frequently scan transaction database to generate a huge set of candidate patterns,especially when the sequential pattern is long and non-Apriori algorithms have the drawback of recursively store the intermediate patterns which need more I/O work and is time-consuming Theoretically and experimentally,we believe extending Galois lattice for graphs to web sequential patterns mining provides a natural basic for complexity analysis of  web sequential patterns mining.It only need scan web accsss transaction database once to produce frequent closed sequences.In addition to providing the calculation of all frequent closed sequences of a web access transaction database given  a support threshold.As a down-top traversal of the Galois lattice,  it is easy to halt whenever the discovered closures are not frequent in the accss transaction database.In other terms the framework allows us to incrementally update the Galois lattice as new user access transactions arrive  Acknowledgement  We would like to thank School of Mechanical Electronic & Information Engineering, China University of Mining & Technology \(Beijing\ for its contribution in the research.This research has been supported by Key Project of Chinese Ministry of Education under grants NO 107021  References  1  S.K.Madria,S.S.Bhownvick,W.K.Ng,andE.J.Lirn,“Researc h issues in web data mining”,Proccedings of First International Conference on Data Warehousing and Knowledge Discovery, 1999,pp.303-312  2  O.Etzioni,“The World-Wide-Web:Quagmire or gold mining”,Communications  of the ACM,1996,pp.385-392 3  J.Borges and M.Levene, “Data mining of user navigation patterns”, Proccedings of the WEBKDD’99 Workshop on Web Usage Analysis and Us er Profiling,USA,1999,pp.3136 4  B.Mobasher,R.Cooley,and J.Srivastava,“Automatic personalization based on Web usage mining Communications of the ACM,2000,pp.450-457 5  R.Agrawal and R.Srikant,“Fast algorithm for mining association rules”, Proccedings of 1994 International Conference on  very Large Database,Chile,1994,pp.487499 6  R.Wille,“Restructuring lattice theory:An approach based on hierarchies on concepts in ordered sets”,Dordrechtboston:Reidel,1982 7  Ming Syan Chen,Jong Soo Park and Philps Yu,“Efficient data mining for graph traversal patterns”,IEEE Trans on Knowledge and Data Engineering, 1998, pp.209-221 8  Van Der Merwe and Kourie, “AddAtom:an Incremental Algorithm for Construction Concept and Concept Sublattices”,Technica report of the Department of Computer Science,University of Pretoria,South Africal,pp.209-215  0 2 4 6 8 1234 Transaction/2500 Cpu t ime Our algorithm AprioriALL 
106 
106 
106 


Uthurusamy Eds Montreal Canada Volume which items or pages where accessed altogether In 16 a method to classify web site users is proposed Each user session is stored U M Fayyad and in in in in finding May 1996 M USENIX Symposium on Internet Technologies and Systems Amsterdam The Netherlands The Netherlands North\255 Holland Publishing Co 2000 pp 377-386 Online Available http://portal.acm.org!citation.cfm?id=346322 5 R Baeza-Yates Web mining 1999 Online Available citeseer.istpsu.edulpitkow99mining.html 7 Proc 5th Int Con Extending Database Technology EDBT 1 1997 pp 770-777 Online Available citeseer.ist.psu.eduljoachims96webwatcher.html 14 H Lieberman Letizia An agent that assists web browsing in Proceedings of the 2004 IEEE Conference on Cybernetics and Intelligent Systems Proceedings of the First International Conference on Knowledge Discovery and Data Mining KDD-95 order to extract the pattern of navigation by clarifying the criteria of clustering and session selection One of the characteristics of our approach is that it offers a certain tolerance to errors in navigation Indeed we make the assumption that a web surfer can look for his way on the site and consequently borrow alternatives which do not call into question its total course So as not to exclude this course from a group tendency it is necessary that the similarity func\255 tion is able to assimilate courses which seem different The obtained results are satisfactory Tested on several sites and starting from various log files they reveal coherent practices of navigation compared to the contents of the site and to statistics The current prospects relate to the development of recommendation tools the production of models of operators of the type Virtual Net surfer for testing of sites and the retro-design of these same sites REFERENCES 1 Z Baoyao C H Sill and C Kuiyu An intelligent recommender system using sequential web access patterns Baoyao C 26 Dunedin New Zealand 2004 pp 3-4 Online Available http://portal.acm.org!citation.cfm?id=979923 6 J E Pitkow and P Peter Mining longest repeating subsequences to predict world wide web surfing in to Srikant and A Rakesh Mining sequential patterns Generalizations and perfonnance improvements in Fayyad P.-S Gregory and S Padhraic From data mining to knowledge discovery Press 1995 Online Available citeseer.ist.psu.edulmannila95discovering.html 11 into account the order of the pages in each sequence There are also other clustering algorithms based on neural network algorithms but the disadvantage they present is that it is not possible to verify the results or to understand clearly the results VII CONCLUSIONS Although there exist many tools for static analysis of Web site visits the most visited page average time of visit etc there is however less tools which are interested in kinemat\255 ics of navigation which are useful for helping web users Moreover existing approaches which are primarily statistical or neuronal are very often dedicated to a given application and do not make it possible to explain the results obtained and thus to include/understand the noted behaviors We proposed a similarity function Sequences in Perkowitz and E dynamic hypertext linking in M databases Siu and C in in AAAI 0 order to cluster them The clusters obtained with this method do not G G Peter M G Apers Mokrane Bouzeghoub Ed vol 1057 Springer-Verlag 25-29 1996 pp 3-17  Online Available citeseer.istpsu.edularticlelsrikant96mining.html 12 vol 11 no 1 pp 95-107 1999  Online  Available citeseer.ist psu.edu/aggarwaI99caching.html 4 Sarukkai and R R Link prediction and path analysis using markov chains in search engines 2005 Online Available http://www.win.tue.nVpersweb/Camera\255 ready/9-Zhou-full.pdf 8 L Tianyi Web-document prediction and presending using association rule sequential classifiers A Thesis submitted in partial fulfilment of the requirements for the degree of Master of Science Simon Fraser University 2001 Online Available citeseer.ist.psu.edulIiO 1 webdocumenthtml 9 K Sch of Comput Eng Nanyang Technol Univ Singapore 2004 pp 1-3 2 E Cohen and Statistical Methods for Speech Recognition Proceedings of the 9th international World Wide Web conference on Computer networks the international journal of computer and telecommunications netowrking H The Fifth International World W"uJe Web Conference WWW5 Towards adaptive web sites Conceptual framework and case study 2000 Online Available citeseer.comp.nus.edu.sg/326006.htmI 13]\267 J Thorsten F Dayne and M Tom M Web watcher A tour guide for the world wide web in Jacobsen H Garcia-Molina and U Dayal From user access patterns INFOCOM Z Proceedings of the 27th Australasian coriference on Computer science Proceedings of the Workshop on Personalization on the Semantic Web PerSWeb 05 446 As a possible disadvantage our approach presents the following 225 The results can only be real complete sequences It cannot detect patterns if they do not appear at least once together as a sequence without errors of other elements Thus it is not the most appropriate method for finding out individual page frequencies Our method can be considered as a sequential pattern algorithm and as a clustering algorithm One of the famous sequential pattern algorithms is AprioriAll This algorithm is highly effective and gives good results because it eventually extracts all the frequent sequences There may exist the possibility that it returns a sequence that does not really exist 2 2000 pp 854-863 Online Available citeseer.istpsu.edularticlelcohenOOprefetching.html 3 C C Aggarwal W Joel L and F Alvis Mining longest repeating subsequences to predict world wide web surfing vol 17 pp 37-54 1996 Online Available citeseer.ist.psu.edu/fayyad96from.html 10 H Mannila T H and in in in Philip S Caching on the world wide web Haim Prefetching the means for document transfer A new approach for reducing web latency MIT Press 1998 16 T W Yan Knowledge and Data Engineering IJCAl a complete sequence This will not be useful for studying the users behaviour in a computer application Nevertheless the result can be useful for a vector that contains the number of visits for each page and an algorithm is used to find similar vectors  C S Mellish Ed Montreal Quebec Canada Morgan Kaufmann publishers Inc San Mateo CA USA 1995 pp 924-929 Online Available citeseer.istpsu.edu/Iieberman9Sletizia.html 15 F Jelinek Proceedings of the Fourteenth International Joint Conference on ArtifiCial Intelligence lJCAl-95 Ai Magazine as take Y V in U M R R A I Discovering Frequent Episodes M 


Used-for references in the LCSH into holonym/meronym relations in our WKB  In the experiments we assume that each topic comes from an individual user We attempt to evaluate our model in an environment that covers great range of topics However it is not realistic to expect a participant to hold such great range of topics in personal interests Thus for the 50 experimental topics we assume each one coming from an individual user and learn her his personalized ontology An LIR is collected through searching the subject catalogue of Queensland University of Technology QUT Library 3 by using the title of a topic Librarians have assigned title table of content summary and a list of subjects to each information item e.g a book stored in QUT library The assigned subjects are treated as the tags in Web documents that cite the knowledge in the WKB  In order to simplify the experiments we only use the librarian summarized information title table of content and summary to represent an instance in an LIR  All these information can be downloaded from QUT's Web site and are available to the public Once the WKB and an LIR are ready an ontology is learned as described in Section 3.3.1 and personalized as in Section 3.3.2 The user con\002dence rates on the subjects are speci\002ed as in Section 3.3.3 A document d i in the training set is then generated by an instance i  and its support value is determined by support  d i   X s 2 021  i  s 2S sup  s Q  14 where s 2 S in O  Q  are as de\002ned in De\002nition 5 As sup  s Q   0 for s 2 S 000 according to Eq 11 the documents with support  d   0 go to D 000  whereas those with support  d   0 go to D   4.4 Performance Measures The performance of the experimental models are measured by three methods the precision averages at eleven standard recall levels 11SPR the mean average precision MAP and the F 1 Measure They are all based on precision and recall the modern IR evaluation methods The 11SPR is reported suitable for information gathering and is used in TREC evaluations as a performance measuring standard An 11SPR v alue is computed by summing the interpolated precisions at the speci\002ed recall cutoff and then dividing by the number of topics P N i 1 precision 025 N  025  f 0  0  0  1  0  2      1  0 g  15 N is the number of topics and 025 are the cutoff points where the precisions are interpolated At each 025 point an aver3 http://library.qut.edu.au Figure 2 Experimental 11SPR Results age precision value over N topics is calculated These average precisions then link to a curve describing the recallprecision performance The MAP is a stable and discriminating choice in information gathering evaluations and is recommended for measuring general-purpose information gathering methods The average precision for each topic is the mean of the precision obtained after each relevant document is retrieved The MAP for the 50 experimental topics is then the mean of the average precision scores of each of the individual topics in the experiments The MAP re\003ects the performance in a non-interpolated recall-precision fashion F 1 Measure is also well accepted by the information gathering community which is calculated by F 1  2 002 precision 002 recall precision  recall  16 Precision and recall are evenly weighted in F 1 Measure For each topic the macro F 1 Measure averages the precision and recall and then calculates F 1 Measure whereas the micro F 1 Measure calculates the F 1 Measure for each returned result and then averages the F 1 Measure values The greater F 1 values indicate the better performance 5 Results and Discussions The experiments attempt to evaluate our proposed model by comparing to an implementation of mental model We expect that the ONTO model can achieve at least the close performance to the TREC model The experimental 11SPR results are illustrated in Fig 2 At recall point 0.3 the TREC model slightly outperformed the ONTO model but at 0.5 and 0.6 the ONTO model achieved better results than the TREC model subtly At all other points their 11SPR results are just the same For the MAP results shown on Table 1 the ONTO model achieved 0.284 which is just 0.006 below the TREC model 2 
512 
516 


TREC ONTO p-value Macro-FM 0.388 0.386 0.862 Micro-FM 0.356 0.355 0.896 MAP 0.290 0.284 0.484 Table 1 Other Experimental results downgrade For the average macroand microF 1 Measures also shown on Table 1 the TREC model only outperformed the ONTO model by 0.002 0.5 in macro F 1 and 0.001 0.2 in micro F 1  The two models achieved almost the same performance The evaluation result is promising The statistical test is also performed on the experimental results in order to analyze the evaluation's reliability As suggested by we use the Student's Paired T-Test for the signi\002cance test The null hypothesis in our T-Test is that no difference exists in two comparing models When two tests produce substantially low p-value usually  0.05 the null hypothesis can be rejected In contrast when two tests produce high p-value usually  0.1 there is not or just little practical difference between two models The T-Test results are also presented on Table 1 The pvalue s show that there is no evidence of signi\002cant difference between two experimental models as the produced pvalue s are quite high  p-value 0.484\(MAP 0.862\(macroFM and 0.896\(micro-FM far greater than 0.1 Thus we can conclude that in terms of statistics our proposed model has the same performance as the golden TREC model and the evaluation result is reliable The advantage of the TREC model is that the experimental topics and the training sets are generated by the same linguists manually They as users perfectly know their information needs and what they are looking for in the training sets Therefore it is reasonable that the TREC model performed better than the ONTO model as we cannot expect that a computational model could outperform a such perfect manual model However the knowledge contained in TREC model's training sets is well formed for human beings to understand but not for computers The contained knowledge is not mathematically formalized and speci\002ed The ONTO model on the other hand formally speci\002es the user background knowledge and the related semantic relations using the world knowledge base and local instance repositories The mathematic formalizations are ideal for computers to understand This leverages the performance of the ONTO model As a result as shown on Fig 2 and Table 1 the ONTO model achieved almost the same performance as that of the TREC model 6 Conclusions In this paper an ontology-based knowledge IR framework is proposed aiming to discover a user's background knowledge to improve IR performance The framework consists of a user's mental model a querying model a computer model and an ontology model A world knowledge base is used by the computer model to construct an ontology to simulate a user's mental model and the ontology is personalized by using the user's local instance repository The semantic relations of hypernym/hyponym holonym/meronym and synonym are speci\002ed in the ontology model The framework is successfully evaluated by comparing to a manual user model The ontology-based framework is a novel contribution to knowledge engineering and Web information retrieval References   C Buckley and E M Voorhees Evaluating evaluation measure stability In Proc of SIGIR 00  pages 33–40 2000   R M Colomb Information Spaces The Architecture of Cyberspace  Springer 2002   D Dou G Frishkoff J Rong R Frank A Malony and D Tucker Development of neuroelectromagnetic ontologies\(NEMO a framework for mining brainwave ontologies In Proc of KDD 07  pages 270–279 2007   S Gauch J Chaffee and A Pretschner Ontology-based personalized search and browsing Web Intelligence and Agent Systems  1\(3-4 2003   X Jiang and A.-H Tan Mining ontological knowledge from domain-speci\002c text documents In Proc of ICDM 05  pages 665–668 2005   J D King Y Li X Tao and R Nayak Mining World Knowledge for Analysis of Search Engine Content Web Intelligence and Agent Systems  5\(3 2007   D D Lewis Y Yang T G Rose and F Li RCV1 A new benchmark collection for text categorization research Journal of Machine Learning Research  5:361–397 2004   Y Li and N Zhong Mining Ontology for Automatically Acquiring Web User Information Needs IEEE Transactions on Knowledge and Data Engineering  18\(4 2006   H Liu and P Singh ConceptNet a practical commonsense reasoning toolkit BT Technology  22\(4 2004   A D Maedche Ontology Learning for the Semantic Web  Kluwer Academic Publisher 2002   S E Robertson and I Soboroff The TREC 2002 002ltering track report In Text REtrieval Conference  2002   M D Smucker J Allan and B Carterette A Comparison of Statistical Signi\002cance Tests for Information Retrieval Evaluation In Proc of CIKM'07  pages 623–632 2007   X Tao Y Li and R Nayak A knowledge retrieval model using ontology mining and user pro\002ling Integrated Computer-Aided Engineering  15\(4 2008   X Tao Y Li N Zhong and R Nayak Ontology mining for personalzied web information gathering In Proc of WI 07  pages 351–358 2007   T Tran P Cimiano S Rudolph and R Studer Ontologybased interpretation of keywords for semantic search In Proc of the 6th ICSW  pages 523–536 2007   Y Y Yao Y Zeng N Zhong and X Huang Knowedge retrieval KR In Proc of WI 07  pages 729–735 2007 
513 
517 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



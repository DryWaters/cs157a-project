Analyzing Metric Space Indexes What For Invited Paper Gonzalo Navarro 002 Dept of Computer Science University of Chile Santiago Chile gnavarro@dcc.uchile.cl Abstract It has been a long way since the beginnings of metric space searching where people coming from algorithmics tried to apply their background to this new paradigm obtaining variable but especially dif\036cult to explain success or lack of it Since then some has been learned about the speci\036cs of the problem in particular regarding key aspects such as the intrinsic dimensionality that were not well understood in the beginning The inclusion of those aspects in the picture has led 
to the most important developments in the area Similarly researchers have tried to apply asymptotic analysis concepts to understand and predict the performance of the data structures Again it was soon clear that this was insuf\036cient and that the characteristics of the metric space itself could not be neglected Although some progress has been made on understanding concepts such as the curse of dimensionality modern researchers seem to have given up in using asymptotic analysis They rely on experiments or at best in detailed cost models that are good predictors but do not explain why the data structures perform in the way they do In this paper I will argue that this is a big loss Even 
if the predictive capability of asymptotic analysis is poor it constitutes a great tool to unders tand the algorithmic concepts behind the different data structures and gives powerful hints in the design of new ones I will exemplify my view by recollecting what is known on asymptotic analysis of metric indexes and will add some new results I I NTRODUCTION My rst contact with the metric space search problem back in 1997 was a paper by my advisor Ricardo BaezaYates Walter Cunto Udi Manber and Sun Wu about Fixed-Queries Trees FQTs in CPMí94 1 The p aper was about modifying Burkhard-Keller Trees BKTs possibly the oldest data structure for this problem 1973 
In the so-called metric space approach one had a database U of objects belonging to a metric space  X d  where d  X  X 002 R was a distance function satisfying the triangle inequality The objects were black boxes so the only possible action upon them was to compute pairwise distances The goal was to build data structures on U so that later given a query ball  q r  003 X  R  
 one could return all the objects of U within distance r to q This is called a range query Other more sophisticated ones  002  Partially funded by Millennium Institute for Cell Dynamics and Biotechnology ICDB Grant ICM P05-001-F Mideplan Chile such as returning the k nearest neighbors were also of interest The complexity measure was just the number of distance computations as they were supposed to dominate the running time 1 Apart from being such an elegant abstraction of many seemingly unrelated problems what fascinated me about this metric space approach was the algorithmic structure that was 
uncovered Unlike trees for exact searching one had to enter into several branches of these trees which turned the typical O log n  time exact search into an intriguing O  n 003  time search for some 0 004 002 004 1 that depended on the problem in an obscure way This kind of search was not shattering news in the data structures world It was well known in multidimensional data structures 6  f o r e x am p l e Y e t it was deﬁnitely not the classical exact searching using trees There were by then many other data structures designed for metric space searching Most were tree data structures 
of one kind or another 7   8    9    10  11    12  13   14  a nd more t r ees came l at er 14    15  16    17  2 As in any algorithmic development the concern of how to measure the performance was raised Experiments are of course one choice but they have well-known shortcomings cost difﬁculty to extrapolate non-explanatory results etc In this case an extra problem was that results were very different depending on the met ric space considered and that there was not and there is not today agreement on which could be representative metric spaces or how the results in one space could help predict th e performance in others In the early days of computing asymptotic analysis was invented to overcome similar problems It not only gives 
a measure of performance that is basically technologyindependent explanatory extrapolation-friendly and that can be obtained without experiments but also it interacts strongly with the design of the algorithm so that analysis can help improve the design and even suggest radically new solutions not only predict the growth rate of the cost for large inputs 1 Beware this paper is not intended to be a survey on the topic If needed there are exhaustive surveys and books 3 4 5 2 I am mentioning just a sample that includes representatives of the distinct approaches I want to discuss in this paper My recollection is not meant to be complete in any way 
2009 Second International Workshop on Similarity Search and Applications 978-0-7695-3765-8/09 $25.00 © 2009 IEEE DOI 10.1109/SISAP.2009.17 3 
2009 Second International Workshop on Similarity Search and Applications 978-0-7695-3765-8/09 $25.00 © 2009 IEEE DOI 10.1109/SISAP.2009.17 3 
2009 Second International Workshop on Similarity Search and Applications 978-0-7695-3765-8/09 $25.00 © 2009 IEEE DOI 10.1109/SISAP.2009.17 3 


It is not surprising then that researchers tried to apply asymptotic analysis to their met ric space data structures One can see such attempts since the early papers 2 7  8 9 10    1    18  15   I n m y o wn e xperi ence ho we v e r  these attempts to understand how were those structures going to perform asymptotically were almost always poor predictors of the actual performance of the indexes There were too many factors apart from the known imprecision of asymptotic analysis that imp acted performance It is not that the growth rate gures do not show up in the experiments but rather that the constant factors are very hard to predict as they depend in a very complicated way on the structure of each metric space So far the only way to tell which structure will perform better in a given metric space is experimentation Several other researchers in the past seem to have reached a similar conclusion because one can identify a slowly emerging concern about the speciﬁc nature of the metric indexing problem Several papers 19   11  12    13  20   16 s t art e d t o w onder a bout t opi cs t h at s t rongl y i mpact ed performance in practice and to which previous asymptotic analyses were blind such as how to choose the referencepoint objects or why some metric spaces seemed to be intrinsically more difﬁcult to index than others this was to be called the curse of dimensionality Authors like Yianilos and Brin have to be commended for having led the most serious effort I am aware of to combine asymptotic analysis with con cerns that are speciﬁc of metric spaces Their analyses led to the design of data structures such as the Vantage Point Forest 21 w h i c h o f f ers w ors t case asymptotic performance guarantees a very uncommon achievement Still the predictive power of such analyses is very limited From some point researchers seem to have given up and to resort almost exclusively to experiments 12 14    17  Others developed very detailed cost models which were successful in practice to predict performance but they had to be computed on a given instance of the data structure 22  23  T hi s made t hem good t ool s f or t uni ng a d at a s t r uct u re but not to understand the performance of the general idea Asymptotic analysis of metric indexes seems to have been abandoned I have not seen one in SISAP 2008  and by the time of writing this paper I am not aware of any in SISAP 2009  Indeed except for my own extemporaneous attempts 15   16  I d o not remember ha vi ng s een an y o f t hos e asymptotic analyses in this millennium Other types of analyses focusing on understanding the curse of dimensionality have made more progress fortunately An example can be seen in this very same SISAP 24  T hi s t opi c b y i t s el f w oul d deserve a whole separate article so I will not attempt to cover the work that has been done around it My opinion is that having abandoned asymptotic analysis is a great loss It is clear that it is not useful for predicting the actual performance of indexes for comparing indexing methods or for automatic ne-tuning of data structures But I strongly believe that asymptotic analysis is an excellent tool for understanding why the indexes behave in the way they do for guiding the design of new indexes and for understanding in which direction could they be optimized As I understand it today asymptotic analysis does not serve at all as a quantitative tool for predicting performance but rather as a conceptual tool for the design and improvement of metric indexes Questions such as why should a tree be balanced what can I expect from increasing its arity how should the space be partitioned which is the space/time tradeoff of pivots what to expect if the histogram shrinks among many others are conceptual in nature and may lead to the development of new indexing techniques The associated quantitative questions must be answered through experiments or detailed cost models and may lead to practical improvements on the existing data structures Let me now rst try to justify my thesis via a short detour to my own experiences on asymptotic analysis and design of metric indexes Then I will switch to a more mathematical exposition trying to collect what is known on asymptotic analysis of the most typical metric indexing approaches while adding some new results II A N A LGORITHMICIST IN W ONDERLAND Almost simultaneously to my discovery of the area I met Edgar Ch avez a Mexican mathematician doing his PhD on this topic Although my own PhD topic was only marginally related we started to work together in what has turned out to be my longest-lasting collaboration with a colleague We found several early approaches to the problem such as Bisector Trees BSTs 1983 7 V o ronoi T r ees V Ts  1987 8 G e neral i zed H yperpl a ne T r ees G H T s  1991 9 10  V ant a ge-P oi nt T r ees V P T s  1993 9  11   G eometric Near-Neighbor Access Trees GNATs 1995 12  Multi VPTs MVPTs 1997 13  M t rees 1997 14   a nd Vantage-Point Forests VPFs 1999 21  j us t t o n ame t he then-most prominent ones It seemed to be all about trees MTs VPTs MVPTs and VTs were balanced trees BKTs FQTs BSTs GHTs and GNATs were not but the intention of the authors was not to have unbalanced trees rather it was a kind of undesirable effect So this seemed to be a well-behaved branch of classical algorithmics Only VPFs seemed not to t well as they could be been seen as on-purpose unbalanced trees despite that the author preferred to regard them as a forest of balanced trees The more difﬁcult the problem the more and smaller trees were needed to obtain the best performance By then I came across a pretty undecipherable paper by Farag  o Linder and Lugosi 25 w h i c h I f a i l e d t o p ars e aft e r several attempts Fortunately Edgar with more background on that kind of mathematics and enthusiastic about the 
4 
4 
4 


paper preprocessed it for me The paper was about how to optimally choose pivots in a space proving that the best was to form a kind of convex hull around the data points with the pivots Intriguingly it promised O 1 search time which looked as a heresy to me But there was also the old work by Vidal 26  1986 s h o w i n g t he s a me O 1 time in practice yet the constant depended on the characteristics of the metric space After all a single distance computation gives much more information than a binary value so there was no reason for 002\(log n  to be a complexity barrier Thus basic assumptions on trees seemed to be inadequate Most intriguingly about Vidal’s work AESA and the subsequent LAESA 27  1994 w as t h at i t w a s not at al l about data structures There were no trees Distances to some elements were simply tabulated and the most possible information from those distances and the triangle inequality was used to avoid distance computations It had always been said that extra CPU costs apart from computing distances were going to be ignored but this time they meant it In AESA there was O  n  extra CPU time per each new distance computed The core of the technique was about how to choose the next pivot This was a heuristic chosen with some spatial arguments Adding more to the heresy AESA simply stored the 003 n 2  distances among all database objects so the space and preprocessing time was an issue It was clear that the algorithmics were just a part of the story This intriguing duality between the algorithmics and the metric-space speciﬁcs and their poorly understood interrelations motivated Edgar and I to write a survey on the topic in ACM Computing Surveys with our advisors 3 Our  rs t motivation was to understand ourselves what was going on Our second motivation was to collect the many unrelated works that we had found which rediscovered the same ideas in the different application areas Although that once essential survey is now superseded by more modern and comprehensive books 4 5  and t he second motivation is now better addressed with SISAP conference I still believe this survey was an important milestone to warn the algorithmicists or maybe just ourselves that they were missing which was probably the main point Metric space indexing was not much about data structures It was more about storing information on intra-database distances so that at query time one should extract up to the last drop of knowledge from that information in order to save every possible distance computation and pay the cost for the rest The extra CPU time was irrelevant which is admittedly a strong simplifying assumption in practice allowing serious abuse Trees were no more than a convenient way of storing and factoring out partial information on distances and also saving some extra CPU time by the way The main point to design a metric indexing approach was which information to store which distances how much precision etc The curse of dimensionality and the histograms of distances played a central role in explaining why a metric space was harder to search than others and to choose which information was best to store This point of view albeit somewhat extreme was enormously successful It opened the door to us and presumably to others to understanding that the coin had another very important side and that this was not yet another eld where known algorithmic concepts could be directly applied The design of our List of Clusters LC 16 pro v e d t o b e particularly revealing In the LC each cluster has a center and only the distances from the center to its cluster elements are stored that is we store just one short distance per element The search must seque ntially consider each center and discard the cluster or not according to the distance between the query and the center The algorithmic concepts behind the LC were trivial Yet  in high-dimensional spaces the LC was virtually unbeatable  whereas all trees and fancy data structures failed catastrophically Still there was an intriguing aspect The LC could also be seen as an extremely unbalanced MT or VPT This led us back to the beginning The earliest authors strove to achieve balanced trees We had learned that somehow this was not the point Now it turned out that for higher dimensionalities unbalanced trees were preferable Moreover we could see experimentally that the higher the dimensionality the more unbalanced should be the tree that is more and smaller clusters to achieve optimum performance and this optimum performance was worse anyway hence the curse of dimensionality This shed a new light on other data structures such as the VPF We attempted a relatively coarse analysis of LCs to try to explain what was going on 16  which followed the trend of similar earlier attempts 1  11   2 1   Essen tially  th e r e su lt w a s a g a in th e o ld O  n 003  time complexity but now we obtained more insight into the relation between 002 and the properties of the metric space In broad terms our analysis explained the relation between dimensionality and unbalancing in tree data structures somehow hinted but in my opinion not fully exposed by Yianilos 21  I b elie v e th at an aly s is is in d eed in sp ir in g  an d explains in part the interrelation between the algorithmic approach to the problem and the speciﬁcs of metric space searching Again it turned out to be useless for predicting performance or for nding the optimal cluster sizes but it was key to understand the critical point of balancing which we have had in mind in much of our later work I will start the formal part of the paper by reviewing and extending these previous analyses on pivot tables and pivot-based trees 1 11    28  21    3    16  s h o w i n g t hat they apply to a wide class of indexes I will then give new analyses for clustering trees via ball partitioning and via hyperplane partitioning usin g my own previous work on Spatial Approximation Trees SATs as inspiration for the latter 15  Th e a n a ly sis f o r clu s ter s is b r an d n e w in m e tr ic spaces some analogies with previous ones in vector spaces exist 29  t h anks t o B e nj ami n B u s t os for t hi s poi nt er 
5 
5 
5 


III P IVOT T ABLES Possibly the simplest metric data structure is the pivot table Pivots c 1 c k 003 U are chosen and all the distances d  u c i  are stored in a table for all u 003 U  1 004 i 004 k  Upon a range query  q r   q is compared with each c i whichis reported if d  q c i  004 r andany u 003 U such that  d  q c i   d  u c i   r is discarded thanks to the triangle inequality All the rest are directly compared with q  Let us call f  x  the histogram of distances of the metric space If the c i s are chosen at random then f  x  is also the histogram of distances to any c i  Let us call F  x  the accumulated histogram If d  q c i  x which has probability f  x  for a random q  then the probability that c i does not discard a random u 003 U is that of d  u c i  belonging to the interval  x  r x  r  of the histogram Then the probability that a random q 003 X does not discard a random u 003 U is e  002  002 0 f  x    F  x  r   lim z 003 0  F  x  r  z   where 0 004 e 004 1  Note that the larger r or the more concentrated f  x   the closer e to 1 Now if pivots c i are chosen randomly the probability that u is not discarded is e k  and thus the expected cost of the search is T  n  k  ne k  This is where the asymptotic and the engineering analyses differ The latter starts from here to devise methods to choose good pivots 23  o r t o p redi ct t h e p reci s e pi v o t performance 22 from a hi s t ogram of di s t ances  O ur goal is different almost orthogonal We want to understand the general asymptotic behavior of the technique without caring much about the details and constants Interestingly it is possible to achieve logarithmic search time using sufﬁciently many pivots With k 004 log 1 e n  log 1 e ln\(1 e  pivots the expected search time is T  n  log 1 e n  1 ln\(1 e   O log n   where we can note that the constants worsen as e tends to 1 These constants but not the asymptotic behavior depend on the metric space and the search radius In practice however k 004 can be unreachable for memory limitations recall that k 004 also grows as e tends to 1 and thus it might be that we can only pay for k  003 ln n pivots In this case the cost becomes T  n  003 log n  ne 004 ln n  O 003 n 1  004 ln\(1 e  004  which is of the form n 003 for some 0 004 002 004 1 that depends on f  x  on r  and on the available memory Finally if we can afford only a xed number of pivots then the search time is O  n   with a constant depending on k  f  x  and r  In any case note that we will always compare the on average nF  r  elements that must be re turned Our analysis here refers to discarding random elements u  Those close to q are not random and the analysis does not apply to them We will omit mentioning this point again in the next sections Recall that more sophisticated analyses 25 es tablis h t hat the time can indeed be O 1 if the pivots are chosen in a certain way whereas we see that by choosing them at random this is not possible This encourages the quest for good pivot selection methods Yet Farag o et al 2 m a ke some obscure assumptions on the nature of the metric space which are not easy to verify On the other hand some experimental results that seem to verify this constant-time cost are given by Vidal 26 In that cas e ho we v e r  the p i v ots are chosen for each query  which is not possible unless a large number of them or all are indexed An intermediate technique using a large set of pivots and then choosing the best ones for each query is LAESA 27  IV T REES FOR P IVOTS AND R INGS Consider a tree structure such that an element c 003 U is chosen for the root and each child represents a range of distances to c  That is the root has k children T 1 T k  representing ranges  004 i 004 i 1   such that 004 1 0 and 004 k 1   005  Subtree T i will contain all the v 003 U such that d  v c  003  004 i 004 i 1  i.e a ring around c  and will be organized recursively When searching for a ball  q r   q is compared with c and c is reported if d  q c  004 r  Then the search recursively enters each T i such that  d  q c   r d  q c  r  006  004 i 004 i 1  007  010  The others can be discarded thanks to the triangle inequality This general formulation encompasses the essentials of a number of indexes including BKTs MTs FQTs VPTs MVPTs VPFs and LCs If c is chosen at random then the global histogram f  x  is also the histogram of distances to c  Let us call p i  F  004 i 1   F  004 i  the probability that a random element falls within the interval corresponding to subtree T i and q i  F  004 i 1  r   F  004 i  r  011 p i the probability that a search for a random q with radius r must enter subtree T i  Assume for simplicity that the structure maintains recursively the same p i values within the subtrees as in MTs VPTs MVPTs and some variants of LCs Assume further that the q i values remain similar within subtrees that is the histograms f i  x  within subtrees T i are similar to the global histogram 3  Albeit these probabilities are not independent still the expectations commutes with the sum Thus the expected number of distance computations for a random query q 003 X satisﬁes the recurrence T  n 1 005 1 005 i 005 k q i T  p i n  T 1  1  1 whose solution easily veriﬁable by induction is T  n  sn 003  1 s  1  O  n 003  s  005 1 005 i 005 k q i  2 3 This is admittedly a gross simpliﬁcation which ruins the predictive power of the analysis Yet this is useful to derive conceptual conclusions 
6 
6 
6 


where 002 is the solution of the equation 005 1 005 i 005 k q i p 003 i 1  3 It is not hard to see that there is a unique solution for 002  in 0   As 002 moves continuously from 0 to 1 the sum 3 goes from above to below 1 with negative derivative The solution is 0 only if 006 q i 1  which means r 0 i.e exact search unless the histogram is rather particular Actually if r 0 and thus q i  p i  the solution to the recurrence is O log n  as for classical search trees A positive search radius turns an exact into approximate and radically changes the behavior of the scheme In some variants like the FQT the tree root is the same for all the nodes of a given depth thus the root does not necessarily belong to the set and a leaf is formed when a sufﬁciently small number of elements remains in the subtree Those roots are thus better called pivots again and regarded as external to the tree The search cost is on one hand the number of pivots or the height of the tree and on the other the same recurrence 1 without the  1 inthe beginning which accounts for the elements at the reached leaves as these must be compared to the query The former is log 1 p min n where p min min  p 1 p k   whereas the latter is simply n 003  Thus the solution is of the same order the difference in constants favors the FQT which has been veriﬁed experimentally 1 28  N ot e a l s o t hat  e v en us i n g a large number of pivots the cost is not logarithmic as in Section III The reason is that elements are not compared with all the pivots but tree leaves may be formed before the tree height is reached When the tree is forced to have all the leaves at the maximum depth FHQTs 28  t he analys is is similar as with a pivot table Let us now focus on the MVPT which allows several pivots per node say t  To search we compute t distances and then enter into the children corresponding to the intersections of t ranges our query ball intersects Then our recurrence 1 would be as follows T  n  t  005 1 005 i 1 i t 005 k q i 1 q i t T  p i 1 p i t n   4 whose solution is T  n  t  s t  1 n 003  t    s t  1  Again the solution is of the same order but the constant 1 t  s t  1 improves as t grows which recommends again using the maximum t  as in a FQT Again the time drops to logarithmic if we choose sufﬁciently large t 003\(log n   so that q i 1 q i t  O 1  This does not show up in our T  n  because the analysis ignored rounding effects which are irrelevant when t is small enough The central difference betw een trees and pivot tables is that the former guarantee lin ear space whereas the latter may achieve logarithmic time Alternatives such as FQTs and MVPTs are in between they almost always achieve linear space but do not guarantee it and do not achieve logarithmic time but improve the constant factor In general using these trees is justiﬁed only if we have little linear space for the index Partial experiments 13 d o s ugges t t h at using larger t is better than just 2 MVPTs vs VPTs Let us now study the arity of the trees To gain some intuition assume that all p i  p thus k 1 p ndall q i  q  p  005 that is a relatively at histogram with 005 depending on r  Then s  kq and we have a closed form expression for 002 log k  kq   The solution to recurrence 1 is T  n  kq n 1  log k 1 q   1 kq  1  It is illustrative to write the exponent as 002 log k 1  005k   The minimum 002 value as a function of 005  has no closed form expression but it is achieved for larger k that is higher tree arities as r grows and yields also larger values of 002  Thus as the search becomes more difﬁcult a higher-ary tree is more advisable Even if we have to enter more branches to cover the same range we have a higher chance of discarding the few ranges that do not intersect the query ball Again partial experiments 13 s ugges t that using higher arities is convenient for higher dimensions Finally let us consider the problem of balancing Assume we x an arity k  and wonder which is the best partitioning To gain intuition assume again q i  p i  005 for all i  thus we seek to nd the p i values that minimize the 002 that solves 006 p 003 i  p i  005 1  The solution where all p i  p yields the equation kp 003  p  005  k 1  003 1 k  005 1  with solution 002 log k 1 005k   as we have seen If we perturb just two p i values adding and subtracting 006  the new equation is  k  2 p 003  p  005  p  006  003  p  006  005  p  006  003  p  006  005 1  Implicit differentiation reveals that 002 increases as 006 deviates from zero Also intuitively the function is convex even with 005 0  with respect to 002 somoving 006 increases it thus to retain equality to 1 we have to increase 002  This shows that with a at histogram the best is a balanced partition This is not anymore the case on higher dimensions Let us assume now that the histogram corresponds to dimension D thatis F  x  x D  with x 003 0    To simplify further assume k 2 sowewantthe x such that p  F  x  minimizes the 002 that solves F  x  003 F  x  r 1  F  x  003 1  F  x  r   1  We can use implicit differentiation to obtain the optimum 002 as a function of x and r  but again there is no closed-form expression Already low dimensions such as D 2  for retrieving 0.01 of the data set recommend leaving p 1 0  24 of the histogram to the left and p 2 0  76 to the right so as to obtain 002 0  035 Aswelet D grow the analysis recommends more unba lanced partitions to obtain the optimum 002  which is nevertheless higher For example for D 6 it recommends leaving just p 1 6  4  10  5 of the data on the left child to achieve 002 0  522 andfor D 10 it leaves p 1 2  0  10  8 of the data to the left to achieve 002 0  701  If our query returns 1 of the data the suggested partitions are even more unbalanced and the 
7 
7 
7 


achieved 002 sarelarger Although the recommendation makes sense in principle because an unbalanced tree is equivalent to having many pivots per element within linear space we have to take these numeric recommendations with a grain of salt On those extremely unbalanced trees one has a high chance 1 for sufﬁciently large r  of traversing all the right path whose length is log 1 p 2 n  This is much larger than the solution we achieve for T  n   This contradiction is explained again because our general solutio n 2 ignores integer rounding effects which is noticeable wh en there are extremely small probabilities involved This shows once more that although asymptotic models are poor as predictors we can still learn concepts from them such that unbalancing is preferable for higher dimensions We have veriﬁed this fact experimentally 16 V T REES FOR C ENTERS AND C LUSTERS Trees formed by clustering operate differently They choose k centers c 1 c k  with corresponding subtrees T 1 T k  and insert the other elements into those subtrees with some criterion trying that each T i is spatially compact for example each element is inserted into the tree of the c i closest to it Covering radii cr i max u 006 T i d  c i u  are computed for each T i  and the construction proceeds recursively inside each T i  When querying for a ball  q r   q is compared with each c i  reporting it if d  q c i  004 r  and entering recursively into T i if d  q c i  004 cr i  r This description encompasses the BST the M-tree Antipole Trees 17  a nd v a ri ant s of t h e L C  Assume the centers are chosen at random thus p i  F  cr i  is the probability of a ra ndom element falling within the covering radius distance to any c i and q i  F  cr i  r  is that of a query  q r  entering T i  If the cluster balls cover the queriable space it must hold 006 1 005 i 005 k p i 011 1  where equality would hold only if the balls have no intersection which is usually impossible to achieve but can be approached via a good clustering method Assume for simplicity that we structure the subtrees as clusters of roughly similar probability mass so that all p i  p  thus k 011 1 p  Assume further that the arity and relative mass of the clusters is maintained in the subtrees thus the probability mass of a cluster at depth h of the tree is p h  If the elements are inserted at random in any suitable cluster then the expected height of the tree is log 1 p n  If instead we manage to balance the number of elements in the clusters then the height is smaller log k n  Note that the goals of having similar number of elements and having similar masses can be conﬂicting Thus the height h 004 lies between these two values on average At depth h 004 log k n there will be k h clusters whereas this will be at most n for larger h  The probability of the query ball intersecting a cluster at depth h is F  x h  r  where x h is the covering radius at level h thatis F  x h  p h  Thus the overall query cost is T  n  h 002 005 h 1 min n k h  F  F  1  p h  1  r   To gain intuition assume a at histogram in 0,1  so F  x  x  In this case F  F  1  p h  1  r  p h  1  r  and thus T  n  006 h 002 h 1 min n k h  r  p h  1  Inthe unlikely case of a perfect clustering  kp 1 hisis T  n  k log k n  k k  1  n  1 r  In the more likely case kp  1 itis T  n  log k n 005 h 1 k h  p h  1  r  n h 002 005 h log k n 1  p h  1  r   k  n 1  log k 1 p   1 kp  1  k k  1 r  n  1  1  p h 002  log k n 1  p n 1  log k 1 p   h 004  log k n  rn 004 k  1  kp  1  p  n 1  log k 1 p   007 k k  1  h 004  log k n 010 rn Note that rn is in this case the expected output size and thus it corresponds to the part of the cost we do not count as we take it as unavoidable There is however a multiplicative overhead on that part of the cost which improves for larger k making a difference only for small k  actually and for better balanced trees that is those that have about the same number of elements per child The other part of the cost is again of the form O  n 003   and if we take kp as a factor that depends on the amount of overlapping more than on k we have that the exponent improves as k grows  002 log k  kp   while the constant increases The constant also increases if the clusters cover much of th e space which is alleviated also by using more clusters Thus it is clearly advantageous to have a good clustering of the space so that the probability of falling in the overlap of two clusters is minimized which reduces kp  and particularly when the search is more difﬁcult to have children clusters of about the same number of elements so that the tree is more balanced and h 004  log k n is reduced Those are clear design goals in the M-tree for example It is also interesting that the issue of balancing has reappeared now giving advantage to balancing trees managing clusters With respect to the best k  it is in principle better to have alarger k  especially when the search is more difﬁcult In the easier spaces however using a very large k might have a pernicious effect in performance because of the constant k multiplying the O  n 003  term especially if the overlaps are signiﬁcant and thus 1 p is not too far from 1 LCs are a good example showing how the use of a very large k so large that the hierarchy actually disa ppears is indeed convenient 
8 
8 
8 


and higher k is better when the search problem is harder This has been clearly demonstrated by experiments 16 If we wish to generalize to dimension D  F  x  x D  then we have T  n  006 h 002 h 1 min n k h  r  p  h  1 D  D  Since r D  p h  1 004  r  p  h  1 D  D 004 2 D  r D  p h  1  the result is conceptually the same as for D 1  VI T REES FOR H YPERPLANES AND V ORONOI R EGIONS These trees also have centers c 1 c k at each node and the elements are always sent to the subtree of their closest center The difference is that the search for a ball  q r  enters into the subtree T i such that c i is the closest center to q  and also to any T j such that d  q c j   d  q c i  004 2 r  This corresponds to dividing the regions using hyperplanes rather than balls so that the centers induce a Voronoi-like partitioning of the space and is used in VTs GHTs GNATs and SATs Regions do not overlap in this scheme The analysis of the SAT 15 i s u s e ful f or t h i s cas e Let D i  d  q c i  and G i  D i  min D 1 D k  Let g i  x  be the histogram of G i which has mass zero over x 0 nd G i  x  the cumulative function of g i  x   Then the probability g i of entering T i is that of G i 004 2 r thatis g i  G i 2 r   Hence the recurrence for the search cost is T  n  k  005 1 005 i 005 k p i 011 012 T  p i n  005 j 007  i g j T  p j n  013 014  k  005  p i  g i 1  p i  T  p i n   where again p i is the probability of being closer to c i than to any other center and again we have assumed that the g i s stay similar within each cluster The solution is T  n   k  s  1 n 003  k s  1 s 1 005 1 005 i 005 k g i 1  p i   where 002 is the solution of 005 1 005 i 005 k  p i  g i 1  p i  p 003 i 1  It can be seen that for 002 1  this sum is 004 1  as it increases with the g i s and reaches 1 when all g i 1 For 002 0 it is 011 1  as it reaches 1 when all g i 0 As r grows the g i s grow and so does 002  If the partitions are similar so that p i 1 k then 002 log k s  Assume also g i  p i  005 so s 1 k  p  005 1  p 2  1 k  k  1 005  The optimum 002 as a function of k  again has no closed form expression but one can nd it numerically to verify that the best k grows with 005 that is with r and with the dimensionality Another subtler effect is that 005 also depends on k As k grows min D 1 D k  decreases G i increases and g i  G i 2 r  decreases so does 005  Yet note that G i 2 r  011 F 2 r   thus for large enough k G i 2 r  gets close to F 2 r  and this effect is less noticeable Indeed it was already shown with GNATs versus GHTs that using higher arities was beneﬁcial up to some point 12  A lso  SA Ts p e r f o r m b e tter w ith h i g h e r a r ities w h e n the problem is harder 15  Although these trees are not naturally unbalanced balancing is difﬁcult to ensure On the other hand the formulas do not suggest any particular effect in this case With respect to covering similar probability masses with the children of a node we can do as in Section IV and assume all p i  p 1 k and g i  g  except for two which are p  006 and p  006 and g  and g   Writing p  g 1  p  p 1  g  g  we have  k  2 p 003  p 1  g  p  p  006  003  p  006 1  g   g   p  006  003  p  006 1  g   g  1  Noting that  p 1  g  g  is a convex combination with weight 0 004 g 004 1  between p and 1 we have again that this is a convex function of 006  and thus 002 increases as 006 moves away from zero thus balancing the probability masses is better VII C ONCLUSIONS In this paper I have argued that asymptotic analysis of metric spaces although normally hopeless for predicting detailed performance and for ne-tuning data structures is extremely useful to understand why they behave as they do and to give powerful hints in the design of new data structures I have shown how this has aided in my own understanding of the area and have given a number of old and new analytical results that help understand the key concepts of most of the data structures available today As an example I have shown novel analytical arguments in favor of balancing cluste ring trees thus giving an analytical justiﬁcation for balanced data structures such as the M-tree 14 In t hi s s ens e I feel our pre v i ous comment 3  about the convenience of balancing in the case of secondary memory data structures missed the point Balancing the Mtree is good because it is a clust ering tree not because it is in secondary memory Indeed secondary memory is an almost orthogonal issue so all our analyses should apply there I believe the main point for secondary memory is not to design special data structures for that case but to adapt main-memory ones so that the packing of data into blocks is optimized both in the sense of minimizing the w asted space and of trying to put together data that will be likely accessed together so as to minimize the ratio of I/Os versus distances computed A good example of these concerns is our recent design of a secondary-memory SAT in this very same SISAP 30  With respect to the analyses perhaps the least satisfactory aspect of the results is the inability to compare different types of indexing structures In all realistic cases the costs are of the form O  n 003  butthe 002 values depend on many factors including especially th e structure of the metric space Extending these results to be able of comparing across approaches would be a great success for the analysis as it could be able of recommending which approach to use depending on the characteristics of the metric space 
9 
9 
9 


There are several other extensions of the problem I have not considered One is nearest neighbor searching for which the development of a general range-optimal strategy 10  4 l et s one reduce t he anal ys i s t o t h at of range s earchi ng A second is approximate algorithms 31 t hat i s  w h i c h can err in giving the exact answer where a few beautiful analyses exist most notably that of Clarkson 18  I n t hi s case the analyses have focused more on the space than on the asymptotics and it would be interesting to see if some relevant asymptotic results can be proved Finally I believe that dynamic data structures for metric spaces a clearly undeveloped area could demand novel asymptotic analyses and beneﬁt from the resulting suggestions R EFERENCES  R  B aeza-Y a t e s W  Cunt o U Manber  and S  W u P roxi mi t y matching using xed-queries trees in Proc 5th CPM ser LNCS 807 1994 pp 198–212  W  B urkhard and R  K el l er  S ome approaches t o best mat ch le searching CACM  vol 16 no 4 pp 230–236 1973 3 E  C h  avez G Navarro R Baeza-Yates and J Marroqu n Searching in metric spaces ACM Comp Surv  vol 33 no 3 pp 273–321 2001  H  S amet  Foundations of Multidimensional and Metric Data Structures  Morgan Kaufmann 2005 5 P  Z ezul a  G  A mat o  V  D ohnal  and M  B at k o  Similarity Search The Metric Space Approach  ser Advances in Database Systems Springer 2006 vol 32  P  A garw al and J  E ri ckson Geomet r i c range searchi n g and its relatives in Advances in Discrete and Computational Geometry  AMS Press 1999 pp 1–56  I  K al ant a ri and G  M cDonal d   A d at a s t r uct u re and a n algorithm for the nearest point problem IEEE Trans Softw Eng  vol 9 no 5 1983 8 F  D ehne and H  N ol t e mei e r  V or onoi t r ees and c l u st er i n g problems Inf Sys  vol 12 no 2 pp 171–175 1987 9 J  U h l ma n n   I mp le me n tin g m e t ric t re e s to sa tisfy g e n e ra l proximity/similarity queries in Proc Command and Control Symposium  Washington DC 1991 also Code 5570 NRL Memo Report 1991 Naval Research Laboratory 10   S a tisfy in g g e n e r a l p r o x i mity simila rity q u e rie s with metric trees Inf Proc Lett  vol 40 pp 175–179 1991  P  Y i ani l o s Dat a s t r uct u res a nd al gori t h ms for n earest n ei ghbor search in general metric spaces in Proc 4th SODA  1993 pp 311–321  S  B r i n   Near nei ghbor sear ch i n l a r g e m et r i c s paces  i n Proc 21st VLDB  1995 pp 574–584  T  B o zkaya a nd M O z so yogl u D i s t a ncebased i nde xi ng f o r high-dimensional metric spaces in Proc 17th SIGMOD  1997 pp 357–368 Sigmod Record 26\(2  P  Ci acci a M Pat e l l a  a nd P  Z ezul a   M-t r ee an ef  c i e nt access method for similarity search in metric spaces in Proc 23rd VLDB  1997 pp 426–435  G Na v a rro  S earchi n g i n m et ri c s paces by spat i a l a pproxi mation The VLDB Journal  vol 11 no 1 pp 28–46 2002  E  C h  avez and G Navarro A compact space decomposition for effective metric indexing Patt Rec Lett  vol 26 no 9 pp 1363–1376 2005  D  C a nt one A  F er r o  A  P ul vi r e nt i  D  R  R ecuper o  a nd D Shasha Antipole tree indexing to support range search and k-nearest neighbor search in metric spaces IEEE Trans Knowl Data Eng  vol 17 no 4 pp 535–550 2005  K C l ar kson Near est n ei ghbor quer i es i n met r i c spaces  Discr Comp Geom  vol 22 no 1 pp 63–93 1999  M S h api r o T he choi ce of r e f e r e nce poi nt s i n b est mat c h le searching CACM  vol 20 no 5 pp 339–343 1977  B  B u st os G  N a v ar r o  a nd E  C h  avez Pivot selection techniques for proximity searching in metric spaces Patt Rec Lett  vol 24 no 14 pp 2357–2366 2003  P  Y i ani l o s E xcl uded m i ddl e v ant a ge poi nt f o r e st s f or near est neighbor search in DIMACS Implementation Challenge ALENEX  1999  P  Ci acci a M Pat e l l a  a nd P  Z ezul a   A c ost m odel f or similarity queries in metric spaces in Proc 17th PODS  1998 pp 59–68 23 B Bu sto s a n d G  N a v a rro   Pro b a b ilistic p r o x i mity se a r c h algorithms based on compact partitions J Discr Alg vol.2 no 1 pp 115–134 2003 24 I V o ln y a n s k y a n d V  P e s to v   C u r se o f d i me n s io n a lity in pivot-based indexes in Proc 2nd SISAP  2009  A  Far a g  o T Linder and G Lugosi Fast nearest-neighbor search in dissimilarity spaces IEEE Trans Patt Anal Mach Intell  vol 15 no 9 pp 957–962 1993  E  V i dal   A n a l gor i t h m f or  ndi ng near est n ei ghbor s i n  approximately constant average time Patt Rec Lett vol.4 pp 145–157 1986  L  Mi c  o J Oncina and E Vidal A new version of the nearest-neighbor approximating and eliminating search AESA with linear preprocessing-time and memory requirements Patt Rec Lett  vol 15 pp 9–17 1994  R Baeza-Y a t e s a nd G Na v a rro  Fast approxi mat e st ri ng matching in a dictionary in Proc 5th SPIRE  1998 pp 14 22  C  B  ohm A cost model for query processing in high dimensional data spaces ACM Trans Database Systems  vol 25 no 2 pp 129–178 2000  G  N a v a r r o and N  R e y es  D ynami c s pat i a l a ppr oxi mat i o n trees for massive data in Proc 2nd SISAP  2009  M Pat e l l a and P  C i acci a T he man y f acet s o f a pproxi mat e similarity search in Proc 1st SISAP  2008 pp 10–21 
10 
10 
10 


    Figure 11: Accumulated Behavior    7. FXplorer All Paths Algorithm We can consider the various blocks of code as black boxes for the purpose of finding all the possible paths through the code. The only case of interest for this algorithm involves handling IF statements. Thus, for a simple sequence of code  GIVEN: \(a b c a b c  When there is an IF statement we need to return the code sequence for the true case and the code sequence for the false case  GIVEN: \(a b c \(if d e a b c d a b c e  The IF statement can occur anywhere, including the first statement of the code sequence  GIVEN: \(\(if a b a c b c  It can even be the only statement in the code  GIVEN: \(\(if a b a b  Or, in general, the IF statements can be nested within other if statements  if \(if i j\ \(if m n a b d i q a b d j q a b d m q a b d n q a b e i q a b e j q a b e m q a b e n q  So we need a recursive algorithm that walks the code blocks looking for IF statements. When one is found we construct two sequences, one sequence containing the TRUE case and one sequence containing the FALSE case. Within each case we need to recursively search for further IF statements   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


  8. Impact and Direction FX gives software developers a practical means to determine the full functional behavior of programs FXplorer adds three radically new abilities built on the FX knowledge of program behavior  BehaviorCase or Path Quest answers the question What parts of the program are responsible for this part of the final program behavior  BehaviorPath or Connect the Dots answers the question What is the result of following this path  BehaviorHere or Come Here answers the question What parts of the program are involved in reaching this point  Since FX covers all of the behavior of a program we need not worry that some special case has been overlooked.  FXplorer is an example of a new generation of software engineering automation that can capitalize on computed behavior to amplify human capabilities for program understanding and verification against specifications.  As an emerging discipline, FX technology holds promise for engineering correct programs, and FXplorer provides a powerful illustration of how computed behavior can be leveraged to create new engineering capabilities  9. References  1 C ollins, R., W a lton, G He v n e r A a nd L i ng e r R The CERT Function Extraction Experiment: Quantifying FX Impact on Software Comprehension and Verification Technical Note CMU/SEI-2005-TN-047, Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA, 2005 2 G a lla g h e r J.R. L y le  Using Program Slicing in Software Maintenance IEEE Transactions on Software Engineering, Vol. 17, No. 8, pp. 751-761, Aug. 1991 3 H e v ne r, A L i ng e r R., Collins R P l e s z k oc h M P r ow ell, S., and Walton, G The Impact of Function Extraction Technology on Next-Generation Software Engineering Technical Report CMU/SEI-2005-TR-015, Software Engineering Institute, Carnegie Mellon University July 2005 4 L ing e r, R., Mills H., a nd  W itt, B Structured Programming: Theory and Practice Addison-Wesley, Inc., 1979 5 L ing e r, R  a nd P l e s z k oc h M Improving Network System Security with Function Extraction Technology for Automated Calculation of Program Behavior  Proceedings of the 37th Annual Hawaii International Conference on System Science \(HICSS35 Hawaii, IEEE Computer Society Press, Los Alamitos, CA, January 2004 6 L ing e r R P l e s z k oc h, M., Burns L H e v n e r A a nd Walton, G Next-Generation Software Engineering Function Extraction for Computation of Software Behavior  Proceedings of the 40 th Annual Hawaii International Conference on System Sciences \(HICSS40 Hawaii, IEEE Computer Society Press, Los Alamitos, CA January 2007 7 L y l e  J  R., G a lla g h e r  K  B A program decomposition scheme with applications to software modification and testing Proceedings of the 22 th Annual Hawaii International Conference on System Sciences \(HICSS22 Hawaii, IEEE Computer Society Press, Los Alamitos, CA January 1989  8 M ili, A Da ly T P l e s z k oc h, M., a nd Prowell,  S Next-Generation Software Engineering: A Semantic Recognizer Infrastructure for Computing Loop Behavior  Proceedings of Hawaii International Conference on System Sciences \(HICSS41 Hawaii IEEE Computer Society Press, Los Alamitos, CA, 2007  9 P le s z k o c h  M H a us le r, P H e v n e r A a nd L i ng e r R Function-Theoretic Principles of Program Understanding  Proceedings of the 23rd Annual Hawaii International Conference on System Science \(HICSS23 Hawaii  IEEE Computer Society Press, Los Alamitos, CA January 1990  W a lton, G L ong s t a f f  T  a nd L i ng e r R Technology Foundations for Computational Evaluation of Security Attributes Technical Report CMU/SEI-2006-TR-021 Software Engineering Institute, Carnegie Mellon University, D ecembe r 2006     Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


 11 modeling and nonlinear control of flight vehicles, active center of gravity control, etc Lingyu Yang has got his PhD in Navigation, Guidance and Control from Beijing University of Aeronautics and Astronautics, China, 2007. He is currently an assistant instructor in the Department of Automation Science and Electrical Engineering in BUAA. His main field of research is control allocation and flight control of aerospace vehicles. His research interests include integrated control system, m odeling and nonlinear control of flight vehicles, fli ght simulation, etc Gongzhang Shen was born in 1945 in China. Since 1990s, he has been a professor at the Department of Automation Science and Electrical Engineering, Beijing University of Aeronautics and Astronautics, China His research interests include integrated control technology integrated vehicle management system nonlinear modeling, control and simulation of various aerospace vehicles, etc 


DAily SMLS TIROPI TMMS solar 90 243 60 A IIt I  I 1111X   L _~17A Hi FMAMJ ASOND 0.3 1.0 1.5 20 3.0 4.0 5.0 6.0 0 80 9.0 Nunber of observatio  24h Figure 10 Number of observations per each 24 hour period for LEOMAC-P top row and LEOMAC-S bottom row Everywhere in a given color is measured that number of times with lOxIO km horizontal resolution for TROPI TIMS and 50x50 km for SMLS The left three columns show an example for Aug 17 The rightmost column shows the annual variation for the TROPI and TIMS solar measurements where the vertical line is 17 August The number of measurements per 24 hour period for SMLS and TIMS/thermal has only a minor variation throughout the year 1000 km i 100 km 10 km GUobal I Global j Figure 11 Overarching scientific issues that need to be addressed by future atmospheric composition missions and LEOMAC-P LEOMAC-S and GEOMAC horizontal vertical and temporal coverage and resolution For the various measurement objectives L indicates that observations are needed in the lower troposphere U that they are needed in the upper troposphere and S that they are needed in the stratosphere The right end of each horizontal arrow is the required horizontal resolution and the left end is the required coverage The upper end of each vertical arrow is the desired temporal resolution and the lower end is the required resolution 13 


 13 Y. H. Bill Ho is currently a Technical Fellow of Vehicle System/Subsystem Design and Integration of Integrated Systems Western Region Sector Northrop Grumman Corp. He has over 29 years of military aircraft design and technology development experience. He was the program manager and principal investigator of the IFCAHM program and was the NGC Air System PHM lead of the F-35 program. He is experienced in flight control system, thermal management, more-electric aircraft, and PHM system design and development. He has B.S. and M.S. degree in Aeronautical Engineering and certificates of Project Management and System Engineering  Gabriel Tannenbaum is a Senior Project Engineer at Moog Inc, Space and Defense Group. He has over 20 years experience in the design development and integration of complex electro-mechanical actuation systems combined at Moog and Lucas Aerospace. Other areas of his past work include ultrasonic non-destructive test equipment design at TRW and radiation monitoring systems design and integration at Victoreen Inc Gabriel Tannenbaum received his Bachelor of Science degree in Electrical Engineering \(BSEE\ the Technion Israel Institute of Technol ogy. He received his Masters degree in Electrical Engineer ing \(MSEE\ the Ohio State University, and a Masters degree in Business Administration \(MBA\ Ke nt State University  J. B. Schroeder is currently the program manager for the Sentient Adaptive Systems Technologies SAST\egrated Flight Control Actuator Health Management IFC&AHM\s.  He is assigned to the Air Force Research Laboratory Control Systems Development and Applications Branch of the Air Vehicle Directorate at Wright Patters on Air Force Base, Ohio.  Mr Schroeder graduated from the U.S. Air Force Academy with a B.S. degree and completed an MBA at State University of New York, Binghamton.  He has flown B 52 and C 7 aircraft in his active duty assignments with the Air Force.        In the private sector Mr Schroeder has been associated with Honeywell Sperry, General Electric and Aydin Vector Corporations primarily in technical sales and marketing.        Since 1987 he has worked in the Air Vehicle Directorate as a project engineer for, among other programs, Self Repairing Flight Control System, Integrated Prognostics and Health Management with principal responsibility for Flight Contro l Integrated Vehicle Health Management 


Our current implementa tion does not support documents with ìvariable-le ngth arraysî ñ lists of identically structured elements with non-fixed lengths Otherwise identically structured documents with different array lengths are currently considered as having different structure We are currently working on supporting ìvariablelength arraysî to extend the applicability of Structure Encoding. We are also looking at provide similar, but less aggressive, optimization support for schemaconforming documents REFERENCES  Nokia Web Services ñ Helping Operators Mobilize the Internet Http://www.projectliberty.org/resources/whitepapers/W S_Operators_A4_0408.pdf  The SAX Project. http://www.saxproject.org  XML Pull Parsing. http://www.xmlpull.org  W3C Document Object Model http://www.w3.org/DOM  WAP Binary XML Content Format http://www.w3.org/TR/wbxml  Efficiency Structured XML. http://www.esxml.org  VTD-XML. http://vtd-xml.sourceforge.net  XSLTC Documentation. http://xml.apache.org/xalanj/xsltc  kXML. http://www.kxml.org  Liefke, H. and D. Suciu. XMill: An Efficient Compressor for XML Data. In Proc. of the ACM SIGMOD Conference on Management of Data. May 2000  Liu, L., C. Pu, and W. Tang. WebCQ: Detecting and Delivering Information Changes on the Web" In the Proceedings of International Conference on Information and Knowledge Management \(CIKM  The XT XSLT processor http://www.blnz.com/xt/index.html  Sarvega,Inc. http://www.sarvega.com  DataPower Technology, Inc http://www.datapower.com  Rax Content Processor http://www.tarari.com/rax/index.html  The Sarvega XSLT Benchmark Study, Sarvega Inc http://www.sarvega.com/xslt-benchmark.php  XSLTMark http://www.datapower.com/xmldev/xsltmark.html  Eisenhauer, G. and L. K. Daley. Fast Heterogenous Binary Data Interchange. In Proceedings of the 9th Heterogeneous Computing Workshop \(HCW 2000 90-101  Bustamente, F., G. Eisenhauer, K.Schwan, and P Widener. Efficient Wire Formats for High Performance Computing. In Proceedings of High Performance Networking and Computing Conference, 2000 SCí2000  Toshiro Takase, Hisashi Miyashita, Toyotaro Suzumura, and Michiaki Tatsubori, An Adaptive, Fast and Safe XML Parser Based on Byte Sequence Memorization. In Proc. of WWWí2005  XML-RPC. http://www.xmlrpc.com  Open  Mobile Alliance http://www.openmobilealliance.org  RSS 2.0 Specification http://blogs.law.harvard.edu/tech/rss  Open Mobile Alliance http://www.openmobilealliance.org  M ogul, J., F. Douglis, A. Feldm an, and B Krishnamurthy. Potential benefits of deltaencoding and compression for HTTP In Proc SIGCOMMí97 1997  Spring, N. T., and D. W e therall. A protocolindependent technique for eliminating redundant network traffic In Proc. SIGCOMMí00 2000  Chiu, K., and W  Lu. A Com piler-Based Approach to Schema-Specific XML Parsing. In First Internati onal Workshop on High Performance XML Processing, May 2004  Matsa, M., E. Perkins, A. Heifets, M. G.aitatzes Kostoulas, D. Silva, N. Mendelsohn, M. Leger. A high-performance interpretive approach to schema-directed parsing. In Proceedings of the 16th International Conference on World Wide Web, 2007  Noga, M  L., Schott, S., and Lˆwe, W  2002. Lazy  XML processing. In Proceedings of the 2002 ACM Symposium on Document Engineering McLean, Virginia, USA, November 08 - 09 2002\02. ACM, New York, NY  Farf·n, F., V. Hristidis and R. Rangaswam i Beyond Lazy XML Parsing. In Proceedings of the 18th International Conference \(DEXA 200 September 3-7, 2007  
324 


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



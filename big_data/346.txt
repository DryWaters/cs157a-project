Post-processing of Association Rules using Taxonomi es Marcos Aurelio Domingues LIACC-NIAAD 
Universidade do Porto Rua de Ceuta 118 Andar 6 4050-190 Porto Portugal marcos liacc.up.pt http://www.liacc.up.pt AbstractThe Data Mining process enables the end users to analyse understand and use the extracted knowledge in an intelligent system or to support in the decision-making processes However many algorithms used in the process encounter large quantities of patterns complicating the analysis of the patterns This fact occurs with Association Rules a Data Mining technique that 
tries to identify intrinsic patterns in large data sets A method that can help the analysis of the Association Rules is the use of taxonomies in the step of post-processing knowledge In this paper the gART algorithm is proposed which uses taxonomies to generalize Association Rules and the RulEEGAR computational module that enables the analysis of the generalized rules Index Terms-Association Rules Data Mining Post-processing Taxonomies I INTRODUCTION The development of the data storing technologies has increased the data storage capacity of companies Nowadays 
the companies have technology to store detailed information about each realized transaction generating large databases This stored information may help the companies to improve themselves and because of this the companies have sponsored researches and the development of tools to analyse the databases and generate useful information During years manual methods had been used to convert data in knowledge However the use of these methods has become expensive time consuming subjective and non-viable when applied at large databases The problems with the manual methods stimulated the development of processes 
of automatic analysis like the process of Knowledge Discovery in Databases or Data Mining This process is defined as a process of identifying valid novel potentially useful and ultimately understandable patterns in data 1 This process has also been used in several domains of application 2 Although the use of the Data Mining process to identify patterns in large databases has become necessary such process may generate large quantities of patterns Part of these patterns may not be useful for the user The user usually prefers and 
wants few patterns that are interesting Therefore the Solange Oliveira Rezende ICMC 
Universidade de Sao Paulo Av Trabalhador Sao-Carlense 400 C.P 668 13560-970 Sao Carlos SP Brazil solange  icmc.usp.br http://www.icmc.usp.br development of techniques that just provide more interesting patterns is important 3 In the Data Mining process the use of the Association Rules technique may generate large quantities of patterns This technique has caught the attention of companies and research centers 4 Several researches have been developed with this technique and the results are used by the 
companies to improve their businesses insurance policy health policy geo-processing molecular biology 5 6 7 A way to solve the problem of the large quantities of patterns extracted by the Association Rules technique is the use of taxonomies in the step of post-processing knowledge 8 5 9 The taxonomies may be used to prune uninteresting and/or redundant rules patterns 8 In this paper the QA'RT algorithm and the RulEE-GAR computational module is proposed The QARvT algorithm Generalization of Association Rules using Taxonomies uses taxonomies to 
generalize Association Rules The RulEE-GAR computational module uses the 9ARGT algorithm to generalize Association Rules and provides several means to analyze the generalized rules This paper is organized as following first by presenting some selected works second by presenting the Association Rules technique and some general features about the use of taxonomies describing the QA'RT algorithm and the RulEEGAR computational module Finally the results of some experiments realized with the QA'RvT algorithm along with our conclusion are presented II RELATED WORK 
In this section some selected works about generalization and post-processing of Association Rules are presented Srikant and Agrawal 9 introduce the problem of generalized Association Rules using taxonomy They also present a new interest-measure for rules which uses information of the taxonomy Baesens et al 4 situate and motivate the need for a step of post-processing to the Association Rules mining algorithms They give a tentative overview of some of the main postprocessing tasks considering the efforts that have already been reported in the literature 0-7803-9365-1/05/$17.00c2005 IEEE 192 


Liu et al 5 propose a new approach to assist the user in finding interesting rules in particular unexpected rules from a set of discovered Association Rules The technique is characterized by analysing the discovered Association Rules using the user's existing knowledge about the domain and then ranking the discovered rules according to various criteria of interestingness e.g conformity and various types of unexpectedness Alipio et al 10 propose a post-processing methodology and a tool for browsing/visualizing large sets of Association Rules The methodology is based on a set of operators that transform sets of rules into sets of rules allowing focusing on interesting regions of the rules space III ASSOCIATION RULES AND TAXONOMIES The problem of mining Association Rules was introduced in 11 Given a set of transactions where each transaction is a set of literals called items an Association Rule is an expression LHS X RHS The LHS and RHS are respectively the Left Hand Side and the Right Hand Side of the rule defined by distinct sets of items The intuitive meaning of such rule is that transactions in the database which contain the items in LHS tend to also contain the items in RHS Thus the Association Rules are used to find the tendency that allows the user to understand and explore the patterns of behavior of the data An example of such rule might be that 80 of the customers who purchase the Q product also buy the W product Here 80 is called the confidence of the rule The following is a formal statement of the Association Rules 11 Let A  a am be a set of literals called items Let T  T1  Tn be a set of transactions where each transaction Ti C T is a set of items such that Ti C A We say that a transaction Ti contains X a set of some items in A if X C Tj An Association Rule is an implication of the form LHS  RHS where LHS c A RHS c A and LHS n RHS 0 The rule LHS  RHS holds in the transactions set T with confidence conf if conff of the transactions in T that contain LHS also contain RHS The rule LHS  RHS has support sup in the transactions set T if sup of the transactions in T contain LHS U RHS Given a set of transactions T the problem of mining Association Rules is to generate all Association Rules that have support and confidence greater than the user-specified minimum support and minimum confidence respectively The support value represents the number of transactions that contain all the elements in LHS U RHS The confidence value represents the proportion of the number of transactions that contain LHS and RHS in relation to the number of transactions that contain LHS Usually minimum support and minimum confidence values are defined by the user to mine Association Rules High values of minimum support and minimum confidence just generate trivial rules Low values of minimum support and minimum confidence generate large quantities of rules patterns complicating the user's analysis A way of overcoming the difficulties in the analysis of large quantities of Association Rules is the use of taxonomies in the step of post-processing knowledge The use of taxonomies may help the user to identify interesting and useful knowledge in the extracted rules set The taxonomies represent a collective or individual characterization of how the items can be classified hierarchically 8 In Fig 1 an example of a taxonomy is presented where it can be observed that t-shirts are light clothes shorts are light clothes light clothes are a kind of sport clothes sandals are a kind of shoes Fig 1 An example of An example of taxonomy without classification for clothes In the next section the proposed algorithm is described The algorithm uses taxonomies made by the users to generalize Association Rules in the step of knowledge postprocessing 12 The algorithm uses both the types of taxonomies with and without classification IV THE ALGORITHM gAR\247T We analysed the structure of the Association Rules generated by algorithms that do not use taxonomies The results of the analysis show us that it is possible to generalize Association Rules using taxonomies In Fig 3 we show how the Association Rules can be generalized First we changed the items t-shirt and short of the rules short  slipper  cap 193 taxonomy for clothes However there are some taxonomies with difficulties to attribute a name to the class of hierarchical characterization of the items An example of a taxonomy without classification is showed in Fig 2 where there are no specific names for the classes products and products2 Fig 2 


sandal  short  cap sandal  t-shirt  cap and slipper  t-shirt  cap by the item light clothes which represents a generalization This change generated two rules light clothes  slipper  cap and two rules light clothes  sandal  cap Next we pruned the repeated generalized rules maintaining only the two rules light clothes  slipper  cap and light clothes  sandal  cap The two rules generated by the Step 1 Fig 3 were generalized again We changed the items slipper and sandal by the item light shoes which represented another generalization generating two rules light clothes  light shoes  cap Then we pruned the repeated generalized rules again maintaining only one generalized Association Rule light clothes  light shoes  cap Taxbnor y shXort spper  cap sandal  short cap sUpopet   shirt cap Step I  I u'u Geerhli zed R1>es light clothe  shlpperc cap  Lght o|t  tanda caap roand4l lppwr Step 2 light clothes  light shoes cap Fig 3 Generalization of Association Rules using two taxonomies Due to the possibility of generalization of the Association Rules Fig 3 we propose an algorithm to generalize Association Rules The proposed algorithm is illustrated in Fig 4 The proposed algorithm just generalizes one side of the Association Rules LHS or RHS First we grouped the rules represented in the standard syntax defined by 13 in subsets that present equal antecedents or consequents If the algorithm were used to generalize the left hand side of the rules LHS the subsets would be generated using the equals consequents RHS If the algorithm were used to generalize the right hand side of the rules RHS the subsets would be generated using the equal antecedents LHS Next we used the taxonomies to generalize each subset In the final algorithm we ordered lexicographically the items of the generalized rules and then we stored the rules in a set of generalized Association Rules In the final algorithm we also calculated the Contingency Table for each generalized Association Rules because the standard syntax defined by 13 include the rule followed by its Contingency Table The Contingency Table of a rule represents the coverage of the rule with respect to the database used in its mining 14 With the calculation of the Contingency Table we finished the algorithm We called the proposed algorithm of QARvT Generalization of Association Rules using Taxonomies A formal statement of the 9ARGT algorithm is showed in Algorithm 1 Algorithm 1 AR\247T Require A set of Association Rules R a set of taxonomies T a database D and the rules side that will be generalized left hand side antecedent of the rules or right hand side consequent of the rules 1 Rg 0 I/The variable Rg will store the generalized rules set 2 E group-association-rules\(R side H/The parameter side indicates the side that will not be generalized 3 for all subset E C E do 4 generalize-rules\(E T side 5 order-lexicographically E side 6 Rg RgUE 7 end for 8 for all rule r C Rg do 9 if r is a generalized rule then 10 calculate-contingency-table\(r T D 11 end if 12 end for 13 return Rg Return the generalized rules set V THE COMPUTATIONAL MODULE RulEE-GAR In this section we present the RulEE-GAR computational module that provides means to generalize Association Rules and also to analyze the generalized rules 12 The generalization of the Association Rules is realized by the QART algorithm described in the previous section Next we describe the means to analyze the generalized Association Rules In Fig 5 we show the screen of the interface that enables the user to analyze and to explore the generalized rules sets On the screen of the analysis interface of generalized rules Fig 5 there are some spaces where the user puts data to make a query and select a set of generalized rules accompanied or not of several evaluation measures 14 to be analyzed With the query the user chooses the consequents and/or antecedents that must be in the rules selected and also the evaluation measures that must appear together the rules Besides allowing the user to select a set of rules the interface provides four links in the section Downloads to look for and/or download the files The files contain respectively the set of transactional data Data Set the set of source rules Rule Set the set of generalized rules Generalized Rule Set and the set of taxonomies used to generalize the rules Taxonomy Set Besides links for visualization and/or download of the files each generalized Association Rule presents others links that enable the user to explorer information about the generalization of the rule The links are positioned at the left side of the 194 


Txrnomies 1 I I I I I I I I _C6hfl!Iqff,h Tbtt fc Fig 4 The proposed algorithm to generalize Association Rules M 4 DWnloadns i Fig 5 Screen of the analysis interface of generalized Association Rules rules Fig 5 The links are described as following  Expanded Rule It is represented in the interface by the letter E This link enables the user to see the generalized rule in expanded way The generalized items of a rule are changed by the respective specific items  Source Rules It is represented in the interface by the letter S This link enables the user to see the source rules that were generalized  Measures It is represented in the interface by the letter M This link is available only if the user selects the support Sup and/or confidence Cov measures in its query and these measures present values lower than the minimum support and/or minimum confidence values defined to the mining process of the rules set not generalized With this link it is possible to see which generalized rules have support and/or confidence values lower than the minimum support and/or minimum confidence values In Fig 5 we also see that the generalized items in a rule items between parentheses are presented as links These links enable the user to see the source items that were generalized In the analysis interface the user can also store the information selected by the query in a text file VI EXPERIMENTS We realized some experiments using the Q9ART algorithm to demonstrate that the use of taxonomies to generalize large rules sets reduces large quantities of Association Rules and makes easy the analysis of the rules 195 


32668 rules generated using the partition of 1 day  RuleSet 7days 19166 rules generated using the partition of 7 days  RuleSet 14days 16053 rules generated using the partition of 14 days  RuleSet lmonth 21505 rules generated using the partition of 1 month  RuleSet 3months The experiments were realized using a sale database of a Brazilian supermarket The database contained sales data of the recent 3 month We made 4 partitions of the database to realize the experiments The partitions were made using the sale data along of 1 day 7 days 14 days and 1 month To generate the Association Rules we used the implementation of the Apriori algorithm realized by Chistian Borgelt with minimum support value equal 0.5 minimum confidence value equal 0.5 and a maximum number of 5 items by rule The generated rules sets are described as following  RuleSet iday 4got using taxonomies to generalize Association Rules 1Available for downloading at the web site http fu z z y cs uni-magdeburg.de/borgelt/software.html During the experiments some taxonomies were identified without classification in the sets of Association Rules The use of the QARvT algorithm with a taxonomy without classification may generate for example generalized rules like jeans  products  t-shirts This generalized Association Rule is not meaningful for the user because it is difficult to identify the products in products However the rule can the meaningful if it is analyzed using the generalized rules analysis interface of the RulEE-GAR computational module this interface is described in Section V We can use this interface to see the source items that were generalized in the products item and to understand the meaning of the rule Considering this fact we realized some experiments using 3 sets of taxonomies without classification In Fig 7 we present a chart that shows the reduction rates of the 5 sets of rules when we ran the qAR,T algorithm with each set of taxonomies without classification In Fig 7 we call each set of taxonomies without classification of Twc followed by an identification number as for example TwcOl In the experiments realized using the sets of taxonomies without classification we got reduction rates of the Association Rules sets varying from 14,12 to 42,97 0 U 50 48 t 45 A 38 L 35 30 23 to 8 20 15 8%5 Witho jt Two Tw 4 UlbSd 1i rn6tt O ReSt 3HrTh6h Fig Set Jd RueSet j4ays WRuSet lrnohth 7 Reduction rates  RuleSet 3MOhttit Fig 6 Reduction rates got using taxonomies without classification to generalize Association Rules In the realized experiments the sets of taxonomies with and without classification were made by the user Thus others sets of taxonomies may generate reduction rates higher than the rates presented in our experiments mainly whether the sets of taxonomies were made by an expert in the application domain We also realized experiments combining some of the 13 sets of taxonomies that present classification with the 3 sets of taxonomies without classification To do these experiments we combined the 3 sets of taxonomies without classification with 6 sets of taxonomies with classification Of the sets of 196 I Ar  VI 4 w L Z Z11,01 L 19936 rules generated using the whole database 3 months of sale data To realize the experiments we manually made 13 sets of taxonomies through of the analysis of the database and of the 5 sets of generated Association Rules Then we ran the 9AR\247T algorithm combining each set of taxonomies with each set of rules In Fig 6 a chart is presented that shows the reduction rates of the 5 rules sets after running Q9AIT algorithm using the 13 sets of taxonomies to generalize each rules set In Fig 6 the sets of taxonomies are called Tax followed by an identification number as for example TaxOl As it can be observed in Fig 6 the experiments show reduction rates of the sets of Association Rules varying from 3,98 to 18,65 0  RuleStJdays Rul etj4dayl 199 189 179 169 159 149 135 12 119 109 99 59 49 39 2 09 1  i Set of TC xnomes Rul eSet I d 1 rWcO2 TW 3 Sets of Taxonomies without Classification RdleSetld y y Rul 


Rujl6StA3nlohth RuIa-SOt 14days taxonomies with classification we chose 2 sets of taxonomies with the lowest quantity of taxonomies 2 Communications of the classification to generalize Association Rules VII CONCLUSION A problem found in the Data Mining process is the fact that several of the used algorithms generate large quantities of patterns complicating the analysis of the patterns This problem occurs with the Association Rules a Data Mining technique that tries to identify all the patterns in a database The use of taxonomies in the step of knowledge postprocessing to generalize and to prune uninteresting and/or redundant rules may help the user New York NY Brazil 13 E A Melanda Pos-processamento Universidade de Sao pp 27-34 1996 sets of association rules 7 T Semenova M Hegland W Graco and G Williams Effectiveness of mining association rules for identifying trends in large health databases in Workshop on Integrating Data Mining and Knowledge Management ICDM'01 10 A Jorge J Pocas Conference on Very Large Data Bases VLDB J B Bocca M Jarke and C Zaniolo Eds 1994 pp 487-499 Online 2004 masters Thesis Instituto de Ciencias Matematicas unifying view in Proceedings of the Ninth International sets of rules when we run the QART algorithm with each combination of the were made by the user others sets of taxonomies may generate reduction rates higher than the rates presented in our experiments mainly whether the sets were made by experts in the application domain ACKNOWLEDGMENT This work was supported by the Coordenaqio de Aperfeiqoamento de Pessoal de Nfvel Superior CAPES and by the Fundaqio de Amparo a Pesquisa do Estado de Sio Paulo FAPESP Brazil REFERENCES sets of taxonomies with and without classification We call each combination of C followed by an identification number as for example CO 1 The reduction rates presented in Fig 8 varying from 14,61 to 50,11 0 US 539 50 48 451 431 389 35 30 281 25 239 20 1 15 10N 8 59 3 C wr Combinations uleSet eodnt  4-~RulSeot de dados in Sistemas Inteligentes Fundamentos e AplicaCoes S 0 The 2001 e de Computacao Paulo Sao Conference on Knowledge Discovery and Data Mining 2000 pp 2-8 Online Available www.cas.mcmaster.ca/lbruha/kdd2000/kddrep.html Workshop on Inductive Logic Programming ILP-99 S Paula Mineracao Conference on Knowledge Discovery and Data Mining KDD-95 U M Fayyad and R Uthurusamy Eds 1995 pp 275-281 and P Azevedo A post processing environment for browsing large to analyze the generated Association Rules In this paper we proposed the QAR.T algorithm that uses taxonomies to generalize Association Rules We also proposed the RulEE-GAR computational module that uses the QAR\247T algorithm to generalize Association Rules and provides several means to analyse the generalized Association Rules Then we presented the results of some experiments realized to demonstrate that the Q9ART algorithm using sets of taxonomies with and without classification and also combining both may reduce the volume of the sets of Association Rules As the sets of taxonomies Carlos SP Carlos SP in ECML/PKDD'02 1999 pp 174-185 INAI 197 7T Semenova.pdf Access in 11/01/2005 Fig 8 Reduction rates got combining Available citeseer.nj.nec.com 4 B Baesens S Viaene and J Vanthienen Post-processing of association rules in Proceedings of the Special Workshop on PostProcessing The Sixth ACM SIGKDD International 1997 Online Available citeseer.nj.nec.com/srikant95mining.html Brazil 14 N Lavrac P Flach and R Zupan Rule evaluation measures A Rezende Ed vol 1 Barueri SP Editora Manole 2003 pp 307-335 3 A Silberschatz and A Tuzhilin On subjective measures of interestingness in knowledge discovery in Proceedings of the First International spatial association rules for objects with a broad boundary Data  Knowledge Engineering R Agrawal and R Srikant Fast algorithms for mining association rules in Proceedings of Twentieth International Dzeroski and P Flach Eds vol 1634 Springer-Verlag 1 U M Fayyad G Piatetsky-Shapiro and ACM vol 39 no 11 8 J M Adamo Data Mining for Association Rules and Sequential Patterns Springer-Verlag 2001 9 R Srikant and R Agrawal Mining generalized association rules Future Generation Computer Systems vol 13 no 2-3 pp 161-180 sets of taxonomies with median quantity of taxonomies and 2 sets with the highest quantity of taxonomies We got a total of 18 combinations of taxonomies sets In Fig 8 we present a chart that shows the reduction rates of the 5 K Koperski Mining multiple-level de regras de associacao Conference on Data Mining 2001 avaliable in http:Hlcui.unige.ch/lhilario/icdm01/DMKM-Final agrawal94fast.html 12 M A Domingues Generalizacao 1 ionth Rujl6SLt 7days de regras de associacao IEEE International P Smyth The M Bohanec B Kavsek N Lavrac and D Mladenic Eds Helsinki 2002 pp 53-64 11 2 S 0 Rezende J B Pugliesi E A Melanda and M F 5 B Liu W Hsu S Chen and Y Ma Analyzing the subjective interestingness of association rules IEEE Intelligent Systems  their Applications vol 15 no 5 pp 47-55 2000 6 E Clementini P D Felice and vol 34 no 3 pp 251-270 2000 Online Available www.elsevier.comnlocate/datak Workshop on Integrating Aspects of Data Mining Decision Support and MetaLearning 2004 phD Thesis Instituto de Ciencias Matematicas Universidade de Sao KDD process for extracting useful knowledge from volumes of data taxonomies with and without Paulo Sao e de Computacao  


        


     


nature of a k-ary predicate is a k-tuple of types. The signature of a k-ary function is a k + 1-tuple of types involving the types of the parameters and the result of the function. The set of terms of the language is the smallest set that contains the atomic constants and variables, and it is closed under the application of functions. Simple formulae consist of predicates applied to terms and formulae are combinations of atomic formulae through the combination of the connectives   and the quanti?ers Functions and Predicates. Functions and predicates are quite important in the PBMS setting, since the approximation of the data to patterns mapping, usually needs complex functions to be expressed. Functions and predicates can possibly appear both in the formula ?eld and in queries, associating relation names with the pattern structure. We believe that having interpreted functions is the best approach for the PBMS since we would like the formula to be informative to the user and we would like to be able to reason on it Safety andRangeRestriction. The formula is a predicate that we would ideally like to be true for all the data that are mapped to a pattern. Notice that the formula by itself does not contain a logical expression involving the pattern structure schema and the data schema i.e., it is not a query on the relations of the raw data The formula is merely a predicate to be used in queries We would like for example to use it in queries that navigate between the data and the pattern space like the following x | fp\(x where fp is a formula predicate and R is a relation appearing in the Data component. We require that fp is de?ned in such a way that we can construct queries like the previous, which are  safe  Safety is considered in terms of domain independence. Still, we cannot adopt the classical notion of domain independence \(which restricts values to the active domain of the database since even the simple functions can create new values not belonging to the domain of the database fore, we should consider a broader sense of domain independence similar to the one presented in [5, 17, 8 which allows the ?nite application of functions. For example, the n-depth domain independence as suggested in [5] considers domain independence with respect to the active domain closed under n application of functions. This includes the active domain and all the values that can be produced by applying the database functions n times, where n some ?nite integer The easiest way to ensure safety in these terms is to range restrict all variables appearing in a query. To this end, we introduce the where keyword in the formula which facilitates the mapping of the formula predicate free variables to the relation schema that appears in the DataSchema or Data component. More speci?Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE cally, we require that there are no free variables in the fp that are not mapped to the relation of the Data component by the use of thewhere keyword. This restriction guarantees that all the variables appearing in fp are either range restricted or that the system knows how to range restrict them to a ?nite set of values when fp is used in a query Now we can formally de?ne the well-formed formula for the pattern-type De?nition 13 A pattern type formula is of the form fp\(dv, pv 1 where fp \(formula predicate variable names mapped by the where keyword to the rela 


variable names mapped by the where keyword to the relation in DataSchema and pv are variable names that appear in the StructureSchema At instantiation time pv is assigned values of the Structure component and dv is mapped to the relation appearing in Data component. The de?nition for the pattern well-formed formula is now straightforward De?nition 14 A pattern formula is of the form fp\(dv 2 where fp \(formula predicate variablesmapped by thewhere keyword to the relation appearing in Data component From the previous de?nitions the semantics of the where keyword become evident: we impose that the variables of the formula will take values from speci?c relations when the formula predicate is employed in queries Example 2 Let us consider the following formulas 1. f\(x x 2. f\(g\(x x In the ?rst formula variable x is mapped to R using the where keyword, thus the formula is well formed. Keep in mind that the formula predicate by itself is just the part f\(x is not well-formed since y is not mapped via where to any relation, or otherwise range restricted 5. Querying the Pattern Warehouse We de?ne queries to be posed over the pattern warehouse and not individually over its data- or patternbase components. Through this approach, we are able to sustain queries traversing from the pattern to the data space and vice-versa. At the same time, the consistency of the results is guaranteed by the pattern-data mapping De?nition 15 Let PW the set of all possible Pattern Warehouses. A query is a function with signature PW ? PW. Given a query q and a pattern warehouse pw = \(DB,PB D?B, P?B q\(pw DB?, PB   P?B? = ?[D?1, ..., D?m], [P?C1:PT1]?. We assume that tr, tp\(tr ? R1 ? tp ? PC1 tr, tp Note that, similarly to the relational case, the result of a query is always a pattern warehouse containing just one relation and one pattern class. It is also important to point out that, in practice, even if a query always involve both the data and pattern space, operations over patterns are executed in isolation, locally at the PBMS. The reference to the underlying data is activated only on-demand \(whenever the user speci?cally requests so stored intermediate mappings or the formula approximation 5.1. Query operators In this section we introduce query operators that allow basic queries over the the PW . Assuming that DB denotes the set of all possible database instances and PB the set of all possible pattern bases, we consider the following groups of operators  Database operators: they can be applied locally to the DBMS. op : DB ? DB. We denote the set of database operators with OD  Pattern base operators: they can be applied locally to the PBMS. op : PB ? PB. We denote the set of database operators with OP  Cross-over database operators: they involve evaluation on both the DBMS and the PBMS, the result is a database. op : DB  PB ? DB. We denote the set of database operators with OCD  Cross-over pattern base operators: they involve evaluation on both the DBMS and the PBMS, the 


evaluation on both the DBMS and the PBMS, the result is a pattern base. op : DB  PB ? PB. We denote the set of database operators with OCP In the following, we present examples of the last three classes of operators \(database operators coincide with usual relational operators operators, we introduce some examples of predicates de?ned over patterns Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 5.1.1. Pattern predicates We identify two main classes of atomic predicates: predicates over patterns and predicates over pattern components. From those atomic predicates we can then construct complex predicates. In the following, we denote pattern components by using the dot notation. For example, the measure component of a pattern p is denoted by p.Measure Predicates over pattern components. They check properties of speci?c pattern components. Let p1 and p2 be two patterns, possibly selected by some queries. The general form of a predicate over pattern components is t1?t2, where t1 and t2 are path expressions that must de?ne components of patterns p1 and p2, of compatible type and ? must be an operator, de?ned for the type of t1 and t2. For example, if t1 and t2 are integer expressions, then ? can be a disequality operator e.g. one of &lt;,&gt cases  If t1 and t2 are pattern data for patterns p1 and p2, then ? ? {=,?}. t1 = t2 is true if and only if x x ?? p1 ? x ?? p2 and t1 ? t2 is true if and only if ?x x ?? p1 ? x ?? p2  If t1 and t2 are pattern formulas for patterns p1 a n d  p 2   t h e n             t 1    t 2  i s  t r u e  i f  a n d o n l y  i f  t 1    t 2  a n d  t 1    t 2  i s  t r u e  i f  a n d  o n l y  i f  t 1 logically implies t2 Predicates over patterns. We consider the following set of predicates  Identity if they have the same PID, i.e. p1.P ID = p2.P ID  Shallow equality \(=s are shallow equal if their corresponding components \(except for the PID component i.e. p1.Structure = p2.Structure, p1.Source p2.Source, p1.Measure = p2.Measure, and p1.formula = p2.formula. Note that, to check the equality for each component pair, the basic equality operator for the speci?c component type is used  Deep equality \(=d deep equal if their corresponding data are identical, i.e., ?x x ?? p1 ? x ?? p2   S u b s u m p t i o n       A  p a t t e r n  p 1  s u b s u m e s  a  p a t t e r n  p 2   p 1    p 2   i f  t h e y  h a v e  t h e  s a m e  s t r u c ture but p2 represents a smaller set of raw data i.e. p1.Structure = p2.Structure, p1.Source p 2  S o u r c e  a n d  p 1  f o r m u l a    p 2  f o r m u l a  Complex predicates. They are de?ned by applying usual logical connectives to atomic predicates. Thus, if F1 and F2 are predicates, then F1 ? F2,F1 ? F2  F1 are predicates. We make a closed world assumption, thus the calculation of  F is always ?nite 5.1.2. Pattern base operators OP In this subsection, we introduce several operators de?ned over patterns. Some of them, like set-based operators, renaming and selection are quite close to their relational counterparts; nevertheless, some others, like join and projection have signi?cant di?erences Set-based operators. Since classes are sets, usual operators such as union, di?erence and intersection are de 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



A Big Data Framework for u-Healthcare Systems Utilizing Vital Signs 
 Tae-Woong Kim Department of Computer Education Silla University Busan, Korea twkim@silla.ac.kr Sang-Hoon Yi Department of Computer Simulation Inje University Gimhae, Korea yish@inje.ac.kr Kwang-Ho Park Department of Computer Engineering Inje University Gimhae, Korea pa4197@nate.com Hee-Cheol Kim Department of Computer Engineering Inje University Gimhae, Korea heeki@inje.ac.kr  
 
Abstract 
Healthcare systems are evolving from simple medical devices to ubiquitous healthcare systems working at anytime and anywhere. In particular, acquisition and transmission of vital signs from wearable devices with biosensors will be soon realized in our daily lives Interestingly, when vital signs such as Electrocardiogram ECG\ respiration and the motion data are collected and accumulated, they become a kind of big data, which will be eventually a crucial clue for monitoring health in everyday life and preventing from diseases. This paper proposes a big data framework for u-healthcare systems that provide healthcare services based upon the analysis of the big data of 
vital signs. The framework includes methods for provision of real-time services as well as for transmission and analysis of the data. It employs an open standard platform to secure interoperability among the data and different devices. The proposed framework was implemented and tested in terms of the motion data from accelerometers 
Keywords-Accelerometer, big data, biosensors, healthcare interoperability, platform, ubiquitous computing, vital signs 
 
 I NTRODUCTION  A paradigm for healthcare practices gradually shifts from cure to prevention [1  Wi th a d v a n c es  of  communications and of biosensors with wearable devices 
I 
ubiquitous \(u-\ healthcare systems have great potentiality for prevention from and early detection of diseases utilizing vital signs acquired from wearable devices with biosensors such as Electrocardiogram \(ECG\, body temperature, and the like [2, 3  T h ey  w ill als o  h el p pr ed ict  and manage oneês health at anytime and anywhere At first, such u-healthcare systems have to enable acquisition of bio-signals from wearable medical devices They should then graft onto techniques for storing processing and analysing vital signs. There are two kinds of vital signs [4   o n e i s  t h e si gna l s m e a s ur ed  a t a m o m e nt  like body temperature and blood pressure, and the other is 
continuous signals, respiration and ECG. The former is suitable for storing the signals in the database, while the latter in files. In particular, continuous data need to be handled as big data in terms of type and volume of the data. Until now, big data analysis has been centred around text mining including opinion mining and social network analysis [5   What is important is that while the text data are directly analysed using some techniques, the raw data of biosignals should be first interpreted to an understandable level using algorithms. That implies that the bio-signal data need one more stage where the raw data is interpreted 
followed by further analysis of the interpreted or extracted data. For this reason, the big data platform for processing vital signs is to be different from the one for text data While Hadoop is largely used as the platform for text data mining [7 t i s not suffi c i e n t l y po w e r f ul fo r vi t a l si gna l  mining that requires analysis of the vital signals and realtime provision of services Against this problem, we propose a framework on which u-healthcare systems utilizing vital signs can be built, extending the Hadoop platform. The proposed and implemented framework includes transmission of the biosignal data, algorithms extracting features from them standardized data expression, Map/Reduce that analyses 
the data in HDFS [8 an d an  op en  pl atf o rm SOA S erv i ce  Oriented Architecture [9, 10  to  p r ov i d e  se rv ices   The contents of this paper are as follows: we describe big data and vital signs in section 2, and the proposed framework for u-healthcare systems in section 3. We also apply it to the motion data from accelerometers in section 4 II 
B IG D ATA AND V ITAL S IGNS  As the background, this section accounts for the two notions of big data and vital signs briefly, and then explains why vital signs are big data 
 
A 
With rapid growth in usage of various social media and smartphones, different kinds of big data in the form of text are generated, circulated and stored, requesting to mine such big data. Usage of many sensors acquiring the data including RFID has been also expanded, which enables context aware computing in more realistic ways. Further the development of cloud environments that can collect various data streamlines the process of gathering and utilizing customersê personal data and their patterns of 
Big Data 
 
2014 International Symposium on Computer, Consumer and Control 978-1-4799-5277-9/14 $31.00 © 2014 IEEE DOI 10.1109/IS3C.2014.135 494 


   
   
B Vital Signs C Vital Signs as Big Data A Transmission of Vital Signs 
purchasing. In the future, therefore, big data analysis will become a must in firms, institutes, and the society [11    Big data can be defined as dataset which is the notion far beyond collection, management and analysis of the data in traditional database management tools. This is the reason why big data is characterized with 3V \(Volume Velocity, Variety\ [4 Wi t h  n o do ubt  vi t a l  si gna l s  satisfy such characteristics There are various bio-sensors measuring ECG respiration, SpO2, blood pressure, temperature, and even acceleration. Interestingly, there are two kinds of vital signs in relation to how to collect the data. The first type includes temperature and blood pressure, which are collected at a certain moment. This type of vital sign data is regarded as structured data which can be easily stored in the database. The second type is the data that should be acquired with continuous time series, e.g. ECG respiration, and SpO2. Such data is unstructured, which is not adequate to be stored in the database, but in files. The second type is interesting for big data analysis and the primary concern in this paper  Figure 1 Vital signs themselves acquired with continuous time series \(e.g. ECG, respiration\are not an index to understand oneês health, but should be processed to produce more meaningful indexes by algorithmic techniques. To handle suc h unstructured vital signs therefore, the whole framework should contain feature extraction algorithms. Extracted feature values can then be recorded in the database. However, a problem arises that data interoperability is not secured, since different databases have different characteristics, and one must know the database schema. For this reason, the framework that we propose was built to enable representation of the vital sings data as a standardized format HL7 \(Health Level Seven, [1 F o r e x a m p l e  i t h e l p s t o  e xpr e s s  various bio-signal data such as respiration and acceleration, extending HL7 aECG \(annotated ECG standard [13 Bio-signals with time series are big enough and unstructured. For example, when the system gathers ECG signals from one person at 240 Hz \(240 data per second\ it collects 864,000 data per hour. If it gathers such data from 10,000 persons, the amount of the data becomes soon huge III B IG D ATA P LATFORM FOR ANALYSIS OF V ITAL S IGNS  Recently, big data technology has largely taken Hadoop, an open software from Apache. Hadoop enables storage of big data in a distributed environment and parallel processing many server clusters. Hadoop Distributed File System \(HDSF\ distributes and stores files, separating name nodes from data nodes, so that it can serve as fast storage. Map/Reduce is a subproject and a programming model. It is simple but basically parallel and has the processing mechanism in Fig 2 In particular, Hadoop has inadequate aspects for handling unstructured bio-signals. This is because it does not have any solution by itself to the problems like how to collect the signals, weather it contains algorithms to extract features from the raw signal data, and if it provides the user with services real-time Resolving these problems, the platform that we suggest adds algorithms extracting feature values from the raw data of vital signs, a feature storage model and a SOA for real-time services \(See Fig 3  Figure 2 I MPLEMENTATION  This section describes the implementation of the proposed framework for u-healthcare systems utilizing vital signs collected with continuous time series Acceleration data are employed to explain the framework A primary reason for taking them in the study is that these data can be more easily obtained than other data, since accelerometers are embedded in nearly every smartphone When acceleration data from smartphones are transmitted to the server, the framework supports interoperability among different devices, sending the data 
Two types of vital signs: Blood pressure \(collected at a moment, left\, ECG \(collected with continuous time series, right Three characteristics of big data  Figure 3 Extended big data platform for vital signs analysis In this extended platform, vital sign data and the analytic results of them are transmitted with a W3C open standard SOAP messages. The values of features extracted from e.g. accelerometer data such as the moving distance the number of steps and the amount of calorie consumption are represented and stored by HL7-based meta model IV 
  
495 


     
    
B Feature Extraction Algorithms C Storage Model for Vital Signs D Analysis Model E Service Model 
by a W3C RPC \(Remote Procedure Call\odel, SOAP messages Acceleration data consist of x, y, z, three axis values The system can detect oneês motions and steps using these values. Many algorithms are already introduced and wellknown. In this study, we implemented algorithms to detect the number of steps, the moving distance, the amount of calorie consumed, etc. The algorithms extract such feature values from the raw acceleration data, and send them to HL7-based feature value transformation module \(See Fig 3 For the sake of interoperability, the values extracted from the raw data by algorithms are represented on an extended HL7 standard aECG format that can contain semantic information. The raw data is separately stored in HDFS that Hadoop provides. The HL7 aECG model with an XML form originally includes the raw data. However since its amount is huge, its inclusion into the XML document is not wise in terms of performance and inappropriate as big data structure. This is because the raw data is too inadequate to approach it semantically in big data. Therefore, the framework makes it be stored in an independent space Generally, text files are mainly used in Hadoop with some text mining techniques. On the other hand, HL7based XML documents are employed in our work, which implies that the system needs XML parsing. Hadoop basically provides a project enabling programming for text mining, called Map/Reduce, which plays a role to make the data key-value pairs. The framework that we propose supports expression by key-value pairs. Map is used to extract feature values such as the number of steps, distance and the amount of calorie consumption. The framework was also designed to calculate the values required for various services using key-value pairs that Map provides Figure 4 illustrates this process  Figure 4 The resulting values provided by Map/Reduce are transformed to SOAP messages through SOA, and are transmitted to the client program or to the terminal. Here SOA is an open standard platform using W3C standard SOAP messages to call and parse objects between heterogeneous devices, independent of kinds of terminals and of OS. When SOAP messages are parsed, the client program gets a service in which the analysis results are received. The values obtained from the acceleration data are the amount of calorie consumption, a moved distance the number of steps, and the time for exercise V 
Flow of vital signs analysis using Map-Reduce  CONCLUSIONS Our time is an age of data. Techniques for storing representing and mining the vast amount of data that increase exponentially became important. This paper serves as a pioneering research work on a software framework on a special type of big data of vital signs Physiological signals are crucial markers to judge oneês health. However, a problem of current existing technology storing and analyzing vital signs arises due to its dependency on sensors and vendors, since products of each vendor have their own distinct characteristics. This means lack of standardization and interoperability in relation to uhealthcare systems and a difficulty of system integration Further, storage design for vital signs has been very poorly conducted, which eventually causes performance degradation and unreliability of the systems Against these problems, we have proposed a big data framework in this paper. The framework takes the basic Hadoop structure and extends it to make it suitable for handling physiological signals, by designing the method of transmitting vital sign data to the server, of extracting feature values, and extending the data representation model and the real-time service model. It also provides standardized services to secure interoperability. We finally believe that the proposed framework aids the performance and the reliability of a given u-healthcare system. Further by combining it with big data mining techniques, the framework can lay a foundation to provide high quality healthcare services including exercise management chronic disease management and disease prevention utilizing vital signs captured at every moment A CKNOWLEDGMENT  This work is funded by the Korean Ministry of Knowledge Economy \(#10033321 R EFERENCES  1 R. A. Schrenker 003\014 Software Engineering for Future Healthcare and Clinical Systems 003\015 IEEE Computer Society, 39, pp.26-32 2006 2 F. Axisa, P. M. Schmitt, C. Gehin, G. Delhomme, E. McAdams and A. Dittmar, çFlexible technologies and smart clothing for citizen medicine, home healthcare, and disease prevention,é IEEE Transactions on Information Technology in Biomedicine, vol.9\(3 pp.325-336, 2005 3 Pantelopoulos and Nikolaos G, çA survey on wearable sensorBased Systems for health Monitoring and Prognosis,é IEEE Tran Sys. Man and Cybernetics, vol. 40\(1\.1-12, 2010 4 T.W. Kim and H.C. Kim, çA healthcare system as a service in the context of vital signs: Proposing a framework for realizing a model,é Computers and Mathematics with Applications, Vol.64\(5 pp.1324-1332, 2012 
 
496 


5 J. Manyika, M. Chui, B. Brown, çBig data: The next frontier for innovation, competition, and productivity,é  McKinsey Global Institute, pp.15-17, 2011 6 Magoulas, Roger, B. Lori ca, çBig data: Techno logies and techniques for large scale data,é Release 2.0, Nov. 2009 7 ApacheTM Hadoop 005 website. [Onlin v a i la b le  hadoop.apache.org, 2013 8 T. White, çHadoop The Definitive Guide. 2nd Edition,é  O'Reilly Media, pp.41-47, 2009 9 S. Chung, PS Young, J. Nelson, çService-Oriented Software Reengineering: Bertie3 as Web Services,é IEEE Computer Society ICWS'05, pp.1-2, 2005  F. James, H. Smit, çService Oriented Paradigms in Industrial Automation,é IEEE Transactions on Industrial Informatics, pp.6270, 2005  J. Gantz, D. Reinsel, çExtracting Value from Chaos,é IDC IVIEW pp. 6, 2011  Health Level Seven International website. [Online  A v al iabl e   www.hl7.org/about/hl7about.htm, 2013  B. D. Brown, F. Badilini. HL7 aECG Implimentation Guide homepage. [Online A v ail abl e  w w w  h l 7 o r g  20 1 3   
         
497 


      


        


       


                       


9  4  3 2 8   7   3   A B C D @ A B E F G H D I F G H D I   A B C D  J K L M N M K O P Q M P R M M P P O M R K O J K Q M M M M O Q R K M O P K 


O S K S K O S M O L L R K O O Q O N S L R P O P R M S S N S K Q L O L Q Figure 2: True positive impacts for association rules Granger, and the combination of both 75 82%, then remains almost constant. Finally, the precision for the combination of the two techniques starts very high 100%, with, however, few links retrieved to ? 75%, and ?nally rises again to ? 82%. Overall, the combination of both techniques seems to exhibit the best precision/recall compromise, i.e., to start with a very high precision, but then to keep it as high as association rules The complementarity of the two techniques is even more evident when looking at Figure 2, which shows, for di?erent values of top-n, the number of true impacts found by Granger causality \(and not found by association rules association rules \(and not by Granger causality found by both techniques at the same time. This ?gure shows that the intersection between the two techniques is always lower \(from 7 vs 37 and 31 for top-100, up to 25 vs 50 and 56 for top-200 one technique only Finally, Figure 3 shows an excerpt of an impact graph highlighting impact relations identi?ed by association rules plain lines dotted lines bold lines related to Samba authentication \(auth_*.c responsible of handling errors providing requests 


to any connection to the Samba server dling user ids. As it can be noticed, auth_* ?les are strongly coupled, and exhibit dependencies highlighted by both techniques. Changes performed to auth_* ?les immediately impact on reply.c and on uid.c, as shown by relations identi?ed by association rules. Instead, the graph shows that changes are propagated only after a while to error.c: in fact the change impact relation is identi?ed by Granger causality only. For instance, on Aug 8, 2001 both auth_* ?les and reply.c \(revision 1.316 note \(smbd/auth server: Doco we want to use cli nt error here soon smbd/password.c management needs to be updated soon. This happened on Aug 27, 2001 \(commit note: . . . added automatic mapping between dos and nt error codes went a change \(to revision 1.6 The performed study su?ers of some threats to validity In particular, threats to internal validity, as this kind of impact analysis \(Granger test and its combination with as165 Figure 3: Excerpt of impact graph sociation rules signi?cant correlation between a change occurring to a ?le and future changes occurring to other ?les. Our approach is purely statistical, hence there is no guarantee to ensure source code change causality. Also, the study can su?er of threats to external validity, as this is only one, small preliminary study. Further, larger studies are desirable to better assess the performances and the scalability of the proposed approach 4. EMERGING RESEARCH DIRECTIONS Driven by bioinformatics, where the Granger causality test is largely used to derive causal relationships among different elements, such as genes and proteins, we have developed a novel change impact analysis method that uses the Granger causality test to learn impact relationships among software artifacts. The main idea of the method is to infer the mutual dependencies between software artifacts by measuring the statistical con?dence that the time series representing the history of changes of a software artifact can be used to predict the changes of another artifact. The problem is therefore posed as a statistical test, evaluating the quality 


of forecasting of a variable given another one In this paper the method has been compared with the application of association rules [9, 10], and the preliminary results suggest that the Granger causality test can be a viable approach to change impact analysis, as it complements existing approaches. As a matter of fact, while association rules capture co-changes, Granger causality helps learning consequent changes. While not shown in this paper for the sake of space, we have compared the results of the proposed impact analysis method against traditional methods based on static analysis, and also in this case we found that they are able to highlight complementary, yet useful, impact relationships. This opens the way towards an eclectic impact analysis approach that combines existing methods, to overcome the limitation of the individual methods, and provides software engineers with a richer set of information useful to assess the impact of a change There are several directions in which the work presented here can be expanded. Of course, a ?rst direction is the development of further empirical studies to fully understand advantages and limitation of the proposed method, to compare it with other \(traditional and to develop heuristics for improvement The application of Granger causality depends entirely on the appropriate selection of variables. In this paper we have used an impulsive \(0,1 in a snapshot. However, other variables should be explored for example the variation of some metric values. Furthermore, the method could be applied for object-oriented system, considering classes and methods instead of functions We are interested to compare the Granger causality approach against the dynamic Bayesian network inference, which is a well-known approach used to derive causal relationships. Finally, we are investigating the use of information theoretic approaches based on mutual information 5. REFERENCES 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data Washington, D.C., May 26-28, 1993, pages 207216 ACM Press, 1993 


2] R. S. Arnold and S. A. Bohner. Impact analysis towards a framework for comparison. In Proceedings of the Conference on Software Maintenance, ICSM 1993 Montreal, Quebec, Canada, September 1993, pages 292301, 1993 3] G. Canfora and L. Cerulo. Impact analysis by mining software and change request repositories. In 11th IEEE International Symposium on Software Metrics METRICS 2005 page 29. IEEE Computer Society, 2005 4] C. W. J. Granger. Investigating causal relations by econometric models and cross-spectral methods Econometrica, 37\(3 5] J. D. Hamilton. Time Series Analysis. Princeton University Press, January 1994 6] A. Hindle, M. W. Godfrey, and R. C. Holt. Mining recurrent activities: Fourier analysis of change events In 31st International Conference on Software Engineering, ICSE 2009, May 16-24, 2009, Vancouver Canada, Companion Volume, pages 295298, 2009 7] J. Law and G. Rothermel. Whole program path-based dynamic impact analysis. In Proceedings of the 25th International Conference on Software Engineering May 3-10, 2003, Portland, Oregon, USA, pages 308318. IEEE Computer Society, 2003 8] N. D. Mukhopadhyay and S. Chatterjee. Causality and pathway search in microarray time series experiment. Bioinformatics, 23\(4 9] A. T. T. Ying, J. L. Wright, and S. Abrams. Source code that talks: an exploration of Eclipse task comments and their implication to repository mining In Proceedings of the 2005 International Workshop on Mining Software Repositories, MSR 2005, Saint Louis Missouri, USA, May 17, 2005. ACM, 2005 10] T. Zimmermann, P. Weisgerber, S. Diehl, and A. Zeller. Mining version histories to guide software changes. In ICSE 04: Proceedings of the 26th International Conference on Software Engineering pages 563572, 2004 166 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



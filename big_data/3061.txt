Abstrac t Conventional PACS systems are designed based on centralized data repository architecture, for integrity and security reasons. This design is highly sensitive to escalation in number of retrieval and storage operations, which represents a major limitation that reduces the efficiency of PACS used in applications that require repetitive data access e.g. medical education and medical decision support systems. In this work we propose two techniques to overcome this limitation, without changing the PACS architecture. The first one, is based on 
reducing the number of data requests on PACS archiving server using a virtual distributed system; the second one, is based on redistributing data requests over time, using a prediction system. Simulation results show significant improvement in performance up to several orders of magnitude compared to conventional PACS design Keywords PACS, Virtual distributed system, Prediction system Association rule mining  I  I NTRODUCTION  Medical image interpretation relies mainly on experience 
and patient medical history in reaching a correct diagnosis Therefore, there is a growing need for a system that enables storage, fast retrieval and viewing of medical images especially for large sized hospitals and clinics. This system is what was termed Picture Archiving and Communication System \(PACS\pite the tangible significance of PACS it cannot individually offer added-value to health-care services without integrating other medical information systems such as Radiology Information System \(RIS\, Patient Information System \(PIS\and Laboratory Information System \(LIS\he intended integration of different medical systems is called Integrated Medical Information System IMIS\In general, IMIS is designed as a closed system that 
provides services for a limited number of users. Standard IMIS is designed based on centralized data repository architectur h ere m e dical im ag es an d data are u s u a lly  archived in large high-performance servers. One of them is the PACS server that provides all medical image retrieval and storage services for different workstations, where one or more servers are used for all other medical information systems \(PIS, RIS, LIS, etc.\ this centralized architecture when the number of retrieval and storage operations increases, the archiving servers ar e expected to be loaded and become a bottleneck. This made the IMIS play a limited role in medical education, and medical decision support, since both require repetitive data access  In centralized architecture, as shown in figure 1, medical 
images are transferred from different modalities and acquisition workstations to PACS central node, PACS controller and archiving system. Received images in PACS central nodes are stored in archiving system, then the radiologists and clinicians use display workstations to view images. Every viewed image is read from the archiving system, and transferred to requesting display-workstation Even if an image was viewed more than once, it will be read from the archiving system for every request. In case of university hospital, medical students and trainees perform large number of images requests Every request is sent to the PACS central node, and the requested image\(s\ are read from the archiving system. This non-trivial increasing in number of 
images requests increases the load on archiving system Moreover, if the PACS is integrated with other medical images systems, e.g. tele-radiology, or a content based image retrieval CBIR systems, [2  e lo ad o n th e arch iv in g  system will increase dramatically, because such systems require repetitive image reading. Increased load in addition to fact that images’ requests are not uniformly distributed over time, raise the probability of chunk in the system     In this work, we provide a strategy to reduce the effect of number of data requests on the server without modifying the centralization of system architecture. The proposed strategy consists of two techniques. In 
the first technique, the number of data requests is reduced, based on proposed virtual distributed system \(VDS\ the second one, the data requests are redistributed over time using a prediction technique, based on association rule mining. This work concentrates on medical images and videos rather than text because the size of text data can be negligible compared to images and videos. In the beginning of this paper, we shall discuss the traditional design of PACS, as well as the proposed strategy; finally, we will discuss the simulation experiment, and results  Fig. 1: Image transfer directions in conventional PACS AN EFFICIENT STRATEGY FOR PACS  
A. M. Ghanem 2 B. Tawfik 1 and M. I. Owis 1 1 Biomedical Engineering Department, Cairo University, Giza, Egypt 2 Faculty of Information Systems, Suez Canal University, Ismailia, Egypt e-mail: ahmed@optimal-sys.com Images transfer direction PACS Archiving Server Teleradiology CBIR Server Display workstations 


    II. M ETHODOLOGY  The proposed design consists of two systems. The first one is virtual distributed system \(VDS\e second one is prediction system. The main target of VDS is reducing the number of requests on the PACS archiving server, while prediction system redistributes the requests to reduce the probability of system chunks. Any image request is sent to both VDS to retrieve the image, and prediction system to predict the next requested images, and send the predicted requests to VDS with lower priority  A. Virtual distributed system \(VDS  Medical images and data in IMIS must be stored in archiving servers for integrity and reliability reasons Therefore, the number of access times to the secondary storage server cannot be reduced. Meanwhile, there is no restriction to prevent workstations from retrieving the medical images and data from archiving servers, if there are other workstations having an updated copy of the requested data. Several copies of images are temporarily stored in acquisition workstations, or modalities’ workstations, before the images are transferred to the archiving server. Other temporary copies are created by display workstations. The proposed virtual distributed system \(VDS\ses these temporary copies of images, instead of retrieving them from the archiving servers with every data request. As shown in figure 2, the requested images can be read from the archiving server or from any other workstation in the system, if this workstation has a temporary copy from the requested image This technique reduces the number of requests received by the archiving server  The data flow of the proposed VDS can be summarized for both acquisition and image reques ts as follows. First, upon any acquisition 1  The acquisition workstation transfers the image to the main archiving server 2  The display workstation sends its IP and the image ID to an extra-added server \(called the retrieval management server \(IRMS 3  The IRMS stores the image ID and the workstation IP in its database Second, when any workstation \(e.g. workstation A requires retrieving an image 1  It sends an image request to IRMS containing its IP image ID and request priority 2  The IRMS searches for the workstation \(e.g workstation B\, that contains a temporary copy of the requested image 3  The IRMS replies to workstation A with the IP of workstation B then workstation A resends the request to it 4  Subsequently, workstation B, adds the request into its requests’ queue based on its priority. When the request is in the front of queue, workstation B sends the required image to workstation A 5  The image ID, and workstation A IP are stored in IRMS database, since the workstation A now has a copy of the image. If there is no temporally copy of the required image, the IRMS resends the request to the archiving server  There are two issues to be considered while creating the virtual distributed system: \(1\designing the temporary database space on the different workstations, and \(2 designing the IRMS  A.1. Temporary space design  1  The data space that holds the temporary copies must be managed without installing a special database engine for this purpose. It is expensive to install database engines support BLOB data on every workstation; moreover database engine reduces the performance of the workstations since they are not configured to be archiving servers 2  In workstations, temporary data spaces are bounded in size therefore, a mechanism must be devised to replace old image data with new images. Least-recently used strategy \(LRU\ employed to keep the most recently used images, and delete the least used ones, whose space will be used to hold new data Images in temporary data space are managed through a database table that contains image ID, image location in data space, image size, and last access time field, which is used by the LRU strategy. Workstations update the data in IRMS with every operation of addition and/or deletion in the temporary data spaces  A.2. Image retrieval management server \(IRMS  The database tables of IRMS reflect the contents of all temporary data spaces in all workstations to maintain the integrity of the system. Many images may have more than one temporary copy on several workstations Fig. 2: Image transfer directions in the proposed PACS Images transfer direction PACS Archiving Server Teleradiolo gy  CBIR Server Display workstations 


therefore, for a single image ID there may be many workstation IP addresses. When these images are requested, IRMS should reply with IP of the workstation that gives optimal \(or at least sub-optimal\lution according to the conditions of network traffic, and workstations loads. For network traffic, a good \(suboptimal\lution can be obtained from a static network map of workstation, sub-net and different network devices. Optimal solutions can only be obtained from dynamic network traffic monitoring. In our system, we design IRMS, with a solution based on static network map, because of the benefit of using dynamic monitoring over static network map, is trivial compared to the complexity of the dynamic monitoring system  B. Prediction system \(PS  The proposed prediction system \(PS\ is based on association analysis; therefore, we’ll first introduce the association analysis, and then, describe how it is used in the proposed system. Association analysis is concerned with the discovery of association rules, revealing conditions that occur frequently together in a given dataset. Based on the terminology of h e Bool ean A R M i s bri e f l y  des c ri bed as  follows  Let I={i 1 i 2 i n  be a set of n binary literals called items. A transaction T i is a set of items in I  such that T i   I  A database D is a set of transactions. A transaction T i is said to contain a certain set of items itemset C iff C   T i The support of an itemset C  sup\(c is the percentage of transactions that contain C An itemset is considered as frequent one if its support is greater than or equal to minimum support \(user defined value\The association rule is presented in the form A B read A  implies B here A and B are two itemsets, and A   B  The association rule support is the support of an itemset C where C  A U B The rule is frequent iff itemset C is frequent. The confidence in the rule is the conditional probability P\(B|A probability that a transaction contains B  given that it contains A n association rule is considered of interest, if it is frequent, and its confidence is greater than or equal minimum confidence \(user defined value\This form of association analysis discovers the events that frequently occur together in the same transaction, and provides rules based on these events which are called intra-transaction association rules. Another type of association analysis concentrates on the relations between transactions, and provide rule in form if event A happened, event B will occur after x minutes with support s and confidence c  A B \(x,s,c e association rules in this form is called inter-transaction association rules   In the proposed prediction system, association analysis techniques are used to generate inter-transaction association rules, using both data requests performed by each user, and time schedules of operation rooms and image modalities. The resulting rules describe the data requests patterns of each user. These patterns are stored in hash tree, and used in the prediction process.  The association rule mining, and rules archiving are performed by our proposed management server The management server monitors data requests from each user, and uses the discovered association rules to create a list of data requests, and the estimated request time for each data request. A priority factor is set for every data request, and then the list of requests is sent to our virtual distributed system. The priority factor of any request is calculated based on the request time, and the confidence of the association rule that is used in prediction of this request. The virtual distributed system performs a data request based on data availability, request priority, and PACS servers’ loads  Example 1  User requests an image using workstation 1 \(WS1 2  WS1 sends the request to IRMS 3  IRMS checks its database to find a workstation, that contains the required data, \(e.g. workstation 2 WS2 then IRMS sends the IP of WS2 to WS1 4  WS1 sends an image request to WS2 5  WS2 replies WS1 with the required image 6  After IRMS replies WS1 with the IP of WS2, it sends a copy of the request to Prediction System PS 7  PS uses its list of association rules to predict the list of next image requests, with priority and time of each and sends the requests list to IRIM 8  For every request in the list, IRIM checks its database to find the workstation that contains the required image, then IRIM sends the list of requests to WS1, and the list of  workstations and/or servers IPs that contain the required image 9  Assume the data of the first predicted request found in PACS archiving server; WS1 sends the image request with its priority to PACS archiving server 10  Archiving server adds the request in its queue of requests, based on request priority. When the request comes to the front of the queue, server will sends the required image to WS1 11  When the user enters the next image request, WS1 checks, if it was received from other workstation and/or server as a reply on the predicted request. If yes, WS1 reads the image from its Hard disk \(HD and displays it to the user. If no, WS1 sends the request to IRMS to start the cycle again  III  S IMULATION   In this section, we are going to evaluate our proposed design by simulating both a conventional design, and our proposed one, then running the two simulations at different loads. We shall simulate only the PACS part of the IMIS because, for the same number of data requests, the size of retrieved and transferred data in PACS, is the largest compared with the other medical information systems. This section is divided into two parts. In the first part, we shall list the simulation assumptions for this PACS. In the second part we are going to discuss a selected real implemented PACS system, by describing the hospital real data  


A. Simulation assumptions  1  Time interval between patient arrivals has exponential distribution 2  No delay due to an error, or other physical damage in network or servers 3  Acquisition and displaying workstations in PACS are used only for PACS operations 4  Delay due to transferred text data on the network is negligible compared to delay due to image transfer 5  The radiologists are available all time, i.e. no delay in accessing them 6  The database tables in the acquisition, display workstations, and IRMS, are small enough to be fetched in their local memory 7  In LRU strategy for replacing images in temporary space, the added image has the same size of the deleted image, i.e. there is no fragmentation in temporary data space, and no need for defragmentation strategy  B. Simulation data The case study is the PACS system that is physically implemented in the Klinikum Deggendorf hospital in Germany and was installed by Philips in 1998. The hospital has a comprehensive institute for diagnostic and interventional radiology. Data were available from a study of Philips about the effect of PACS on the performance of the hospital in the period from July 1998 to June 1999 [8 Th e hospital serves a population of about 120000 inhabitants, and contains 450 beds in seven departments. There are 18 different modalities connected to the PACS. 562000 radiological examinations were carried out on 49500 patients 37% of the examinations were carried out on in-bed patients and 63% on in-ambulant patients. The number of exposures per patient is 11.4. Dividing the total amount of data by the number of patients examined, and the number of examination gives a storage capacity requirement of about 19.8 Mbytes for each patient examined in the radiology department, and a value of 1.7 Mbytes per image. In 69% of the cases, the image of interest to the examiner that will be needed for the report comes immediately from examination, and in 31% of the cases, it requires the previous examinations   IV. R ESULTS  We used SimJava simulation package the simulation program is designed to simulate hospitals with different sizes and facilities. We run the simulation, assuming that the PACS is implemented in a university hospital. Junior radiologists and medical students trained on PACS, assuming that they access the same number of images, as do expert radiologists i.e. 50% of these images are from old cases, and the other 50% are from new cases  Figure 3, shows a comparison of the average waiting times on the PACS archiving server RAID, for different number of trainees, between conventional PACS, VDS only, PS only and both VDS and PS. As shown in figure, using VDS only provides better result than using PS only, and using the two systems together reduces the average waiting time by more than one order of magnitude Vs using one system only  Figure 4, shows the average queued image requests for different number of trainees in PACS archiving server. The figure shows that the performance of the proposed design is superior to conventionally designed PACS             V  C ONCLUSION  We have provided a solution that increases the efficiency of PACS used in applications that require repetitive image access for medical images e.g. medical education and medical decision support systems. The proposed solution is comprised of two techniques. The first one is based on managing and using the temporary copies of images by a virtual distributed system to reduce the number of image requests on PACS archiving server. The second one is based on reducing the probability of system chunks, by redistributing the image requests over time. The redistribution of requests is performed by a prediction system, based on association rule mining. The integration between the two proposed strategies increases the ability of PACS to integrate with other medical Fig. 4: The average queue length in archiving server for proposed and conventional systems Fig. 3: The average waiting time on archiving server RAID in proposed and conventional systems 


systems that require repetitive image access for medical images    R EFERENCES   T  C  W o n g  an d D A  Tj an dra A Di g ital L i brar y for Biomedical Imaging on the Internet IEEE Communication Magazine vol. 37, No.1, pp 84-91, January 1999  hm ed M. Gh a n e m M. E m ad M. R a s m y  an d Yas s er M Kadah, “Content-Based image retrieval strategies for medical image libraries SPIE Medial Imaging symposium, Image Processing conference, California February 2001  h m e d M. G h an e m M. E m ad M. R a s m y  a n d Yas s e r M Kadah, “Integration of content-based image retrieval system with PACS SPIE Medial Imaging symposium, PACS and Integrated Medical Information Systems conference California February 2001   A g ra w a l, T  Im ieli ns k i a n d A  S w a m i  M i n i n g association rules between sets of items in large databases in: Proceedings of ACM SIGMOD 1993, pp. 207–216  R  A g ra w a l  an d R  S r ik a n t F a s t a l g o rit h m s f o r m i n i n g  association rules in: Proceedings of International Conference on Very Large Data Bases 1994, pp. 487–499 6 A  K  H   T ung H  L u  J  H a n a n d L Fe ng  E f f i c i e nt  mining of intertransaction association rules IEEE Transactions on Knowledge and Data Engineering vol.15 No. 1 ,2003, pp. 43–56   J   T. L ee, an d C  S W a n g   An eff i cie n t al g o rithm for mining frequent inter-transaction patterns Elsevier international journal on Information Sciences 177 2007, pp 3453-3476  T   Weh r l e U  K u n zel a nd P. R e i n dl  P A C S  Workf l ow  and economic consequences PHILIPS medicamundi Magazine vol. 44, pp. 52-65, March 2000       


 Very few ows are high throughput Most ows are short lived Almost all ows are mice  Most ows have an average packet size medium Most ows are packet mice Almost all bulk ows are medium throughput Almost all bulk TCP ows are short-lived  Fig 5 Simple on-line linguistic summary of the CRAWDAD-Fall03 NetFlow collection truth values between brackets of rules to analyze In particular we disregarded those rules with a low support or with a low condence truth value Many interesting rules were found for the NetFlow records analyzed We list as examples a selection of them  Most DNS request ows occur both during the day and at night are mice and short lived with condence 0.970 in the WIDE-F-1-Aug collection  Most ows at night are mice with condence 0.890 and Most ows during the day are mice with condence 0.998 in the CAIDA-OC48-0-Apr collection  Most SSH trafc occurs during the day and consists of short lived mice ows with condence 0.892 in the CRAWDAD-Fall03 collection Linguistic summaries provide a novel method to describe qualitative relations in NetFlow collections using natural language Thus by using association rules mining to nd relevant summaries we have a suitable method for addressing a problem related to ow analysis nding invariants in trafc what is known as one the major goals of Internet Science VI C ONCLUSIONS We have addressed network trafc analysis at the ow level from the perspective of linguistic summaries Two approaches for summarizing NetFlow collections have been developed 1 on-line summarization via a predened and congurable set of potential interesting protoforms and 2 discovery of hidden relevant summaries by means of association rules mining A tool that implements both approaches has been developed Experimental results for a set of benchmark NetFlow collections conrm linguistic summaries as an alternative look into network ow statistics useful for both network users and practitioners The method presented is a novel technique to generate simple and human-interpretable reports but also provides a promising technique for nding invariants in network trafc and advancing Internet Science This can be seen as a rst step towards natural language based knowledge discovery for Internet Science A CKNOWLEDGEMENT We acknowledge the MAWI Working Group from the Wide Integrated Distributed Environment WIDE project for k indly p ro viding their  o w collections and support We are also indebted to the Cooperative Association for Internet Data Analysis CAIDA for providing their OC48 data collection  Support f or CAID A  s O C48 Traces Dataset is provided by the National Science Foundation the US Department of Homeland Security DARPA Digital Envoy and CAIDA Members We used the Dartmouth/campus data set from t he Community Resource for Archiving Wireless Data CRAWDAD Our work has beneted from the use of measurement data collected on the Abilene network as part of the Abilene Observatory Project http://abilene.internet2.edu/observatory R EFERENCES  C ooperati v e Association f or Internet D ata Analysis CAID A V i sualization Tools http://www.caida.org/tools/visualization  J  S ommers P  B arford a nd W  W illinger  SPLA T  A V i sualization Tool for Mining Internet Measurements in 7 t h Passive and Ac t ive Ne t work Measuremen t Workshop  Mar 2006 pp 31–40  C  E stan S  S a v age and G  V ar guese  Automatically Inferring P a tterns of Resource Consumption in Network Trafc in SI G C OMM 200 3  Karlsruhe Germany Aug 2003 pp 137–148  R  R  Y ager   A N e w Approach to the S ummarization o f D ata  I n f orma t ion S ciences  vol 28 pp 69–86 1982   Database D isco v e ry Using F uzzy Sets  I n t erna t ional Journal o fI n t elligen tSy s t ems  vol 11 1996  J  K acprzyk and R  R  Y ager   Linguistic Summaries of Data Using Fuzzy Logic I n t erna t ional Journal o f General Sy s t ems  vol 30 no 2 pp 133–1504 Jan 2001  J  K acprzyk and S  Z adro  zny Linguistic database summaries and their protoforms Towards natural language based knowledge discovery tools I n f orma t ion S ciences  vol 173 no 4 Mar 2005   Cisco I OS NetFlo w  h ttp://www cisco.com/en/US/products/ps6601 products ios protocol group home.html Nov 2007  B  C laise e t al  Specication of the IPFIX Protocol for the Exchange of IP Trafc Flow Information Internet Engineering Task Force IPFIX Working Group Revision 26 Sep 2007 Internet Draft  S Shaluno v a nd B T eitelbaum TCP Use a nd Performance on Internet2 in A C M SI G C OMM I n t erne t Measuremen t Workshop San Francisco USA 2001  L A Zadeh A Computational A pproach to Fuzzy Quantiers i n Natural Languages C ompu t ers and Ma t hema t ics wi t h Applica t ions  vol 9 pp 149–184 1983  R R Y a ger   O n O rdered W eighted A v eraging O perators in Multicriteria Decision Making IEEE Transac t ions on Sy s t ems Man and Cy berne t ics  vol 18 pp 183–190  1988  L A Zadeh  A P rototype-Centered Approach to Adding Deduction Capability to Search Engines-the Concept of Protoform in F irs t I n t erna t ional IEEE Sy mposium on I n t elligen tSy s t ems vol.1,Sep 2002 pp 2–3   The concept o f a linguistic v a riable and its application t o approximate reasoning I n f orma t ion S ciences  vol 8 no 3 pp 199 249 1975  A Broido Y  Hyun R Gao and k c claf fy   Their Share Di v e rsity and Disparity in IP Trafc in 5 t h Passive and Ac t ive Measuremen t Workshop  PAM   Antibes Juan-Les-Pins France 2004 pp 113–125  M Delgado N Mar  n D S  anchez and M.-A Vila Fuzzy Association Rules General Model and Applications IEEE Transac t ions on F u zzy Sy s t ems  vol 11 no 2 pp 214–225 Apr 2003  J Kacprzyk and S  Zadro  zny Linguistic Summarization of Data Sets Using Association Rules in IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ IEEE  St Louis USA May 2003 pp 702  707  R Agra w al H Mannila R Srikant H T o i v onen and A  V erkamo Advances in Knowledge Discover y and Da t a Mining  American Association for Articial Intelligence 1996 Fast Discovery of Association Rules pp 307–328  M Fullmer e t al  ow-tools http://www.splintered.net/sw/owtools Nov 2007  W i dely Inte grated Distrib u ted En vironment  WIDE P roject MAWI Working Group Packet traces from wide backbone http://tracer.csl.sony.co.jp/mawi 2006  CAID A O C48 T race Project CAID A OC48 T r aces 200304-24 collection http://imdc.datcat.org/collection/1-0018N=CAIDA+OC48+Traces  D K o tz T  Henderson and I  A byzo v   CRA WD AD data set dartmouth/campus v 2007-02-08 Downloaded from http://crawdad.cs.dartmouth.edu/dartmouth/campus Feb 2007 624 2008 IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ 2008 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as “for many”, “there are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logic”, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e composition”, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



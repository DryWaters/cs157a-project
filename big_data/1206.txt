Periodic web personalization aims to recommend the most relevant resources to a user during a speci\336c time period by analyzing the periodic access patterns of the user from web usage logs In this paper we propose a novel 
Baoyao Zhou 
ntu.edu.sg 
1 
 Siu Cheung Hui and Alvis C M Fong School of Computer Engineering Nanyang Technological University 50 Nanyang Avenue Singapore 639798 baoyao.zhou@hp.com 
An Effective Approach for Periodic Web Personalization 
asschui ascmfong 
  
Abstract 
web usage mining approach for supporting effective periodic web personalization The proposed approach 336rst constructs a user behavior model called Personal Web Usage Lattice from web usage logs using the fuzzy Formal Concept Analysis technique Based on the Personal Web Usage Lattice resources that the user is most probably interested in during a given period can be deduced ef\336ciently This approach enables the costly personalized resources preparation process to be done in advance rather than in real-time The performance evaluation of the proposed periodic web 
personalization approach is also given in the paper 
1 Introduction 
As the Web is huge and complicated users often miss their target pages when sur\336ng the Web Web personalization 2 is o n e o f th e p r o m i sin g ap p r o ach es to tack le th is problem by adapting the content and structure of websites to the needs of the users by taking advantage of the knowledge acquired from the analysis of the users\325 access behaviors Many techniques have been investigated for discovering various web access patterns from web usage logs for web personalization These include rule-based 336ltering ap 
proaches content-base 336ltering approaches 7 col l a borative 336ltering approaches a nd hybri d approaches 11  Most web usage mining techniques focus mainly on mining common access patterns However the periodic characteristics of access patterns are often neglected In practice many useful access patterns occur frequently only in a particular period such as every morning but not in other periods due to user sur\336ng habits Such access patterns are reperiodic access patterns 
1 The author is currently a research scientist in HP Labs China ferred to as 
 With periodic access patterns of a user we can easily deduce the resources that the user is most probably interested in during a speci\336c time period The personalized resources can then be prepared in advance and delivered to the user during that speci\336c time period We call such task as 
Periodic Web Personalization 
 Different from most web personalization approaches the periodic web personalization approach does not rely on the user\325s current access information which could be misleading as the current access might be just some intermediate web pages before reaching the target pages 
In this paper we propose a novel web usage mining approach based on fuzzy theory 13 and F ormal C oncept Analysis FCA  for c ons t r uct i n g a us er beha vi or model  and then uses it for supporting effective periodic web personalization for the user The performance evaluation of the proposed approach is also given in the paper 
2 Periodic Web Personalization 
Web usage mining 10  w hi ch mi nes w eb us age l ogs for user models and personalization is also a promising technique for periodic web personalization Research work 5 6 9 h as been carried out fo 
r discovering periodic patterns from time series databases However most of these works mainly focus on mining periodic patterns rather than applying such patterns for practical applications They only discuss some potential applications of periodic patterns For example Ozden 
et al et al 
 9 ment i oned t hat p eri odi c a s s o ci ation rules can be used for trend analysis prediction forecasting and decision making Li 
  s t ated that the calendar-based temporal association rules can be used to represent normal network activities in different time periods 
of a day Moreover Li and Deogun 5 a l s o d i s cus s e d t hat the periodic patterns can be used not only for data characterization but also for future periodicity prediction However to the best of our knowledge no approaches have been proposed for periodic web personalization Figure 1 shows the architecture of the proposed periodic web personalization system All web access requests of a 


user are 336rst recorded by the Web server and stored into its web usage logs The component then constructs the Personal Web Usage Lattice model of the user When the period conditions are speci\336ed by the user or the Web server the  We can clean out unnecessary entries according to the topics in the 322Semantic Annotation\323 336eld based on the selected resource attributes If a user accessed speci\336c resources periodically we can consider that the user has a  we need to process the original web usage logs in order to identify all personal access sessions for each individual user Similar preprocessing tasks i.e data cleaning user identi\336cation and session identi\336cation for traditional web server logs discussed in 1 can be us ed  If the difference between the timestamps of two consecutive requests from the same user is greater than a given timeout threshold it could be considered that a new access session has started We use 30 minutes as the default timeout threshold An access session M M M M S  t d d t t d t d S t 1 1 p r r r i i i i 1 i n 1 n n 212 1 n n n n  t 1 t 2 t 21/05/2005 08:20:01 21/05/2005 08:22:32 21/05/2005 08:22:50 21/05/2005 08:27:30 n n n n i i n Periodic Web Personalization Preprocessing 200 is a sequence of requested  Noon Night Late Night Early Morning Late Afternoon component will generate the personalized resources from the Personal Web Usage Lattice The Web server will then prepare and organize the corresponding resources and provide them to the user during the given time periods  and and and 001  For Evening 002 In that does not have 322  The duration periodic attributes or periodic access pattern which can be interpreted as 322A certain user is interested in speci\336c resources during a speci\336c period\323 Therefore we can use a set of Data cleaning resource attributes 006\006\006\001\007\004\005\b\004\005 323 its duration can be estimated by the average duration of the current session i.e  For analyzing personal access behavior unique users must be identi\336ed using the 322UserID\323 336eld 267\267\267 267\267\267 Figure 1 System overview Table 1 An example of a semantically enriched web usage log User1 of  1  UserID d 2 User Behavior Model Construction Preprocessing Semantic Annotation Period Conditions d t 1 Personal Web Usage Lattice   Personalized Resources Generation Personalized Resources 003    d 1  n  n t t 1   1 3.1 Preprocessing URL 1 URL 2 URL URL URL URL 000\001\002\003\004\001\003\002 000\001 002 003\004 003\003 003\005 006\007 004 003 b\t Morning Session identi\336cation 212 212  with timestamp 212 T3 T1  T1 T2 T3  User1 T7 T3 T5  User2 T1 T3 T8  User1 Early Afternoon web access activity Constructing Personal Web Usage Lattice to represent web access activities In this research we have de\336ned eight real-life temporal concepts namely URL1 URL2 URL7 URL3 Web Usage Logs The URLs recorded in web usage logs contain little semantic information about th e web contents accessed by users In this research we assume that each requested URL in web usage logs has been annotated with the corresponding semantic information i.e one or more prede\336ned topics or categories such as News Sports and Entertainment Such task can be done easily by the designer or administrator of the website manually or semi-automatically An example of semantically enri ched web usage log is given in Table 1 As shown in Table 1 the web usage log contains several 336elds on user identi\336cation UserID request time Timestamp requested URLs URL and topics Semantic Annotation The semantic annotation indicates the prede\336ned topics that are presented in the web page of the corresponding requested URL 003 respectively For subsequent processing we ignore the date information in the session start and end time and convert them into a value within the interval 0 24  For example the session start time 32221/05/2005 08:20:01\323 is converted into 8.33   i Timestamp User identi\336cation    i.e we only retain access sessions containing more than one requested URL Furthermore we can evaluate the start and end time of             000\001\002\003\004\005\002\006\007\b\t\n\003\004\013\n\f\002\r\004\016\n\017\001\020\003\021\022\020\t\n\017  023\002\003\t\n\f\t\022\004\024\002\025\004\023\002\003\001\n\017\007\r\t\026\007\020\t\n\017 can be estimated simply as  we need as 200 200 212 Entries in web usage logs are regarded as useful when the topics of their requested URLs refer to at least one resource attribute in d as periodic attributes Alternatively we can also use days of week e.g Monday Tuesday etc and other real-life temporal concepts e.g weekdays weekend or months as periodic attributes for more general purposes All prede\336ned topics for a certain website can be regarded as resource attributes for describing web access activities The selection of the appropriate domain-speci\336c topics depends on the applications For example the product names in product catalogs can be used for e-commerce\325s websites whereas the categories of news can be used for news websites        To compute 000\001\002\003\004\005 URL 3 User Behavior Model Construction 


007 004 De\336nition 1 De\336nition 2 De\336nition 3 De\336nition 4 005 006           0              and Z  m r   002 004 g k 001 G  te  g k  212 ts  g k  004 267\267\267  The membership value  where   Given a Web Usage Context Given a Web Usage Context 001 001 003 0  004 g k 001 G d  g k m r  004 period ki ki and an and and Web Usage Context  and the set of access sessions which have all the same attributes in can be computed using the total duration of  Based on the fuzzy periodic Web Usage Context the Personal Web Usage Lattice can be constructed of an access session can be used for estimating the user\325s interest level of that resource during the access session can also be denoted as a fuzzy set on the domain of  In this research the member function is de\336ned as   S S S S S S S S S  M  M  M G M M   g m B 265 g g S m the if is associated with a set of resource attributes if is if if in row As such each access session can be treated as a sequence of sets of resource attributes 006 for representing the semantics of the content of for a user for a periodic attribute periodic attributes  265 M M M M G M G B M G 004  004 001 R M in the access session  Each fuzzy relation to represent fuzzy relations between access sessions  i.e  In this research the member function is de\336ned as 265 r  g m r   we de\336ne the set of attributes common to access sessions in in all access sessions of the user which indicates the user\325s global interest of the resource  It is denoted as  which indicates the user\325s local interest of the resource m g 265 ts te ts ts te ts t m t m t m  we identify a user\325s web access activities and construct a Personal Web Usage Lattice from the personal access sessions of the user In practice different people may have different interpretations for real-life temporal concepts For requested resources the similar problem exists because it is dif\336cult to interpret accurately the i ntention of a user during an access session Fuzzy theory 13 i s one of t h e a ppropri a t e techniques to describe such vagueness in information and incorporated into Formal Con cept Analysis 3 for r epresenting both periodic attributes and resource attributes To do this we 336rst construct the Web Usage Context for a user from his/her preprocessed access sessions te te t d t d t d M I M I M I is de\336ned as the proportion of the duration of accessing the resource otherwise Suppose that each otherwise 004 A fuzzy periodic is de\336ned as the proportion of the total duration of accessing the resource In is de\336ned in Figure 2 which is modi\336ed from 8   0  15  14  13  12  11  10  9  8  7  6  5  4  3  2  16  17  18  19  20  21  22  23  1  24  1.0 Late Night Early Afternoon Evening 0.5 Early Morning Morning Noon Late Afternoon Night 0.0 265 p  t  m p  t hours Figure 2 Member function The membership value M        0 fuzzy support      004  1  M I 327  which can be computed as Based on the above de\336nition each access session     265 where i.e 004 resource attributes start time 004 24 24 24 1 1 006 b   A fuzzy periodic Web Usage Context can be represented by a cross table with rows indicating access sessions and columns indicating the periodic and resource attributes A membership value ax g in an access session in an access session indicates the fuzzy relation between the access session  and denoted as of a set of attributes and column Constructing Personal Web Usage Lattice for a resource attribute  The total duration for each and attribute       where 0 0 0 0   G A M  i.e 265   i i n n k n p r p p t 001 p p p r r r p r p r 001 G access sessions 002  004 004 004 004 004   0 within the access session is de\336ned as a continuous time interval with a is de\336ned as as as is a fuzzy set on the domain of p B 001 where where z  g m r  d  g m r  te  g  212 ts  g  M G M M 004 003 004 can be computed using the period of z 3.2 Constructing Personal Web Usage Lattice Sup S   p   S M M S  m S d 001 d 001 m K G M I G g m R 265  265 m m g M g 265 m g g p 265 265 265 265 m g m d Z m m m g m 265  g m g m K A A 002 B B 002 m K B B 265 m 265 M M 1      0  end time    ri ri rn ri  and attributes is a set of is a set of is a set of is represented by a membership value 1 2 if z  g m r   1 2 Z  m r  2 z  g,m r  Z  m r  212 1  if 1 2 Z  m r  001 z  g m r  001 Z  m r  1  if z  g m r  Z  m r  327 r r r k r i i k p r p r P r p r p p r r p r p r p p p p p p p r r r r r r r r r p r p r p r g 001 p r 004 004 004 005 005 005 005 005  004  004 005  007 005 005 A    265 m g                           M G M G M G M M 006 M     1 1 2 2 URL URL 004 M     M M  t   G 327   g m g m g m g m g m g m g m g m g m g m g m g m g m g m 


 denoted as v  B i  f W  denoted as v  B j   pri v  B i  to represent the hierarchy of web access activities Some ef\336cient approaches have been proposed in traditional FCA for computing concept lattice Among them the TITANIC algorithm 12 i s o n e o f th e m o s t e f 336 cien t l attice construction algorithms In this research we have modi\336ed the TITANIC algorithm with fuzzy support and fuzzy con\336dence for constructing the Personal Web Usage Lattice from the Web Usage Context based on a Personal Web Usage Lattice L P  W P  W respectively In addition v  t  t  005 001 001 B B 003 003  if there exists a pair  A B  is a sub-activity is a super-activity is a direct sub-activity is a direct super-activity is the super-activity of all other web access activities if ts 003 te 0 te  005  ts 24  is de\336ned as Sim p  v  B  p c   v p  B  n P f  p c    v p  B  005 P f  p c     265   265   m 265 v  M M p t m  which is denoted as p c  represent two fuzzy subsets of v  B  if if   and B n M r b  t and B 002  A and v r  B   m r 265  B m r   m r 004 B n M r  and B n M r and Conf  v  t   1  0  denoted as v  B i   W and B k b  B j  such that v  B i   W and an end time te 004 0  24 of a given period condition p c 004 W P  B n M p b  t  v  B i   B k b  B i otherwise and otherwise  a fuzzy set on B    For two period-supported activities v  B i  v  B j  004 SA p  p c L P  or     denotes the set of all web access activities of a user  W P  has a higher priority than that of v  B j  The fuzzy support The Personalized Resources Generation The period similarity The period-supported activities otherwise In addition the fuzzy period condition and there is no v  B k  004 W P and the fuzzy con\336dence component searches the Personal Web Usage Lattice of a user for generating a set of ordered personalized resources according to a given period condition for all periodsupported activities of p c basedona Web Usage Context K  G M p M r I  of a period condition p c Wealsode\336ne v  B  v p  B  005 v r  B  4 Personalized Resources Generation on domains of B n M p where are de\336ned as a set of web access activities  which are web access activities with similar periodic attributes to the fuzzy period condition P f  p c  1 is de\336ned as a fuzzy set  we call that v  B i    265 m m v  002  002 004  then v  B   m 265  B m   m 004 B  1 Given a Web Usage Context K   G M p M r I  of v  B  is a conditional probability For virtual web access activity v  t  of v  B j   if and only if B j 013 B i  Equivalently v  B j  of v  B i  of v  B j  of v  B i  of a user is L P  W P  W 006 where W P 001  M g m g m but Conf  v  B i  Conf  v  B j   A 002  B 001 M   where v p  B   m p 265  B m p   m p 004 B n M p  and v  B j   we de\336ne Sup  v  t   1  0  v  B j  004 W P   W  then v  B i   f W  De\336nition 5 De\336nition 6 De\336nition 7 De\336nition 8 De\336nition 9 De\336nition 10 De\336nition 11 m  B 006 M p 005 M r M max p p r r p  P v  B j  P P v  B j  P v  B k   W P v  B j  P v  B j  P P  P c P   p p p r r r f c p c p p p c p c i i P i f c p i f c SA L 001 with A 006 G is de\336ned as a continuous time interval with a start time ts 004 0  24 is the total number of web access activities A web access activity represents a periodic web access behavior of a user i.e it is an implication relation from periodic attributes to resource attributes min min    and  is called a web access activity For two web access activities of a user v  B i   called activity relationship is a partial order on W P is a partial order on W P is called a direct activity relationship and a given period condition p c 001  ts te   g g p p p p B B B p B p if 200 Sim p  v  B i  p c  Sim p  v  B j  p c  or 200 Sim p  v  B i  p c  Sim p  v  B j  p c  or 200 Conf  v  B i   Conf  v  B j  P where prob  267|\267  265 B 265 B P 265 v but Sup  v  B i   Sup  v  B j                         is the set of all web access activities and  W of a web access activity v  B  where 265  B m max g 001 B 001  265  g m   between a web access activity v  B  004 W P is de\336ned as a virtual web access activity is de\336ned as Sup  v  B   Sup  B  is de\336ned as Conf  v  B   prob  B n M r    B n M p   Sup  B  Sup  B 003 M  In particular if v  B i   W was de\336ned in Figure 2 In order to generate personalized resources we 336rst need to search the Personal Web Usage Lattice L P 002 002 v 001 001 m p m r p p p t p p P p where 265 p  t m p   W P   v  B i    Obviously the virtual web access activity v  t  A Personal Web Usage Lattice A period condition p c  From the discovered period-supported activities we can extract personalized resources 


b M            W p P P p P P p P o P o P o P r n a a a set of period-supported activities  t if if if  In order to distinguish the importance of personalized resources to the user we need to rank the resources according to the order of their priorities Search and Search Search be a collection of sets of personalized resources for overall web personalization and v  003  v   004 v   of a given period condition and and based on a Personal Web Usage Lattice of a user based on based on a Personal Web Usage Lattice of that user If has a higher membership value than that of end for end for end for end for Suppose we generate personalized resources 322 comprising all applicable sets of personalized resources The of each for generating a set of ordered personalized resources for a given period condition a set of ordered personalized resources into the current web access activity with period-supported activity personalized resources PR PSA PSA S m S m or in is given in Algorithm 4.1 In Line 5 the algorithm p p p InLine6 all period-supported activities a re sorted in descending order of priority In Line 7 since all personalized resources belong to the same period-supported activity they are only sorted in descending order of fuzzy membership value ri rj ri rj rj ri ri rj ri rj ri rj ri rj direct sub-activities of a Personal Web Usage Lattice 1 Initialize a Personal Web Usage Lattice 1 Initialize 004 265 resource-supported session c P P c c r i c r i r r c i c r i r c P c P c P c P c c P c c P c p r c r c r    The algorithm  of the generated personalized resources If 004 n  004 004 n 005  n 004     i.e  i.e based on a Personal Web Usage Lattice be an access session in the period Let of overall web personalization is de\336ned as is de\336ned as a set of resource attributes occurring in at least one activity in  denoted as m 004  To enhance the ef\336ciency of the period-supported activity searching process th e algorithm starts searching from the top node of the lattice and performs recursive searching for only the direct sub-activities satisfying with the period condition  L L L L L L L L PR 2 Algorithm 4.1 Algorithm 4.2 the period-supported activity of L v has a higher priority than that of The The has a higher priority than that of Algorithm 4.2 gives the algorithm have the same period-supported activity p P period-supported session mark 002 mark  mark 002 Process Process applicable applicability PR  r if or PR PR PR PR PR pri  De\336nition 12 De\336nition 13 De\336nition 14 De\336nition 15 W o  P  o  P  002 003 p  P  002 p  P  o  P  o  P  o  P  W p  P  p  P  002{\003 p  P  002 p  P  002 p  P  P      W else Search such that  we call that t 004 be the subset of  i.e with with In order to objectively evaluate the feasibility of our proposed approach we de\336ne the following two evaluation measures applicability and satisfaction In this section we evaluate the performance of the proposed periodic web personalization approach 5.1 Evaluation Measures  M  is given the highest priority For two personalized resources applicability m all all all 267\267\267 M P 0 a 323 for a given period condition    200 200 r   of the generated personalized resources m  L L L L  L PR PSA for all for all for all for all B m B m Gen SA SA SA W B 005 p L W v m m v m m m m m m  m m m v m m v 265 p L p L p p L p p p L S p p S 265 S m m 265 visited we call P P  P  P c P  P c c P c c P c r 004 r r c r c c c P  P c c i  004 P i  006 W i  i  005 f  p  i  b f  c  p  i  t f  c  c i  n c P i  c c P i  i  c L b then then then whichis PSA PSA PSA based on a Personal Web Usage lattice of a certain user    M Search Input Output Search Input Output p p B  004 B  p B  004 p p p p B  p p B  B B B  B B p  007  003 B p B p p B B p B B p 5 Performance Evaluation  we call it  we call  return return PR PR PR PR PR PR PR 1 PR PR PR PR Let p p B p  p B p B B B p p S S p  6  6  8 9 Append 2 3 4 7 8 10 11 12 13 2 3 4 5 7 9 10 11 12 unvisited                               which is given in Algorithm 4.2 is called for searching all period-supported activities for    a end if end if end if m L B  Gen  SA SA SA SA SA SA SA p L W v  v  v  m m m p L W v  v  v  v  v  v  v v v  v  do do do do but 5 Get period-supported activities a period condition in priority descending order in priority descending order a period condition for searching period-supported activities for a given period condition of a user If B M  L L L L L L L unvisited L v  L 


comprising all period-supported sessions of the personalized resources comprising all resource-supported sessions in for The proposed periodic web personalization approach is implemented in C The experiment is performed on a 3.4GHz Intel Pentium 4 PC machine with 1GB memory running on MS Windows XP The web usage logs are collected from a web forum called 322North Latitude One BBS\323 http://bbs.nlone.net This web forum consists of a total of 64 topics including 7 main topics such as Past In this paper we have proposed a novel web usage mining approach for supporting effective periodic web personis the subset of is the subset of t to four different values i.e is the whole period for periodic web personalization and As the Personal Web Usage Lattice only stores typical web access activities supported by some of access sessions in the training web usage logs if the period-supported activities cannot be found the generated set of personalized resources will be empty Therefore the applicability measure gives a rough idea on how often applicable personalized resources will be generated   0 1 0      0  1 003 and an average of 92.3 for all the four test users with period conditions longer than and equal to 0.5 hours                     0 10 20 30 40 50 60 70 80 90 100 0.5 1 2 4 Duration of Periods \(hours Applicability u13 u36 u48 u82 Figure 3 Performance results based on applicability    5 0 0 0 5 0 and the average satisfaction of 88.9 for all four test users satisfaction 0 PR i    PR i   PR i 001 PR a  PR PR PR PR PPR PR 0  t period conditions where each period condition satisfaction satisfaction satisfaction d i 327 d PR PR PR PR   1 2 4 T T s d i s s 001 1 i 003 n          The of the personalized resources is de\336ned as time Soccer in Sports etc The whole dataset contains a total of 6,828 acces s sessions from 01-May-2005 to 31-May-2005 with each session comprising requested URLs from the 64 topics The top 4 users with most access sessions are selected as test users We use access sessions of the 4 users from 01-May-2005 to 20-May-2005 as the training dataset to construct the Personal Web Usage Lattices for the 4 test users and use access sessions of the 4 users from 21-May-2005 to 31-May-2005 as the testing dataset to evaluate the performance of the proposed approach As a result the number of generated web access activities of users u13 u36 u48 and u82 are 912 1196 258 and 1005 respectively We then generate personalized resources for a set of prede\336ned period conditions and measure the performance based on the applicability and satisfaction measures with respect to the different durations of period conditions from 0.5 to 4 hours and the different numbers of personalized resources from 1 to 6 Suppose that be the set of all access sessions for testing if 004  In this experiment we set De\336nition 16 i p i i a  24 24 1 327  Figure 3 shows the applicability of the overall web personalization based on the different durations of period conditions from 0.5 to 4.0 hours The experimental results have shown that the proposed periodic web personalization approach has obtained an acceptable applicability for the prede\336ned period conditions with appropriate durations We have achieved at least 85.4 for the user u48 with Let and  6 Conclusions p i i r i p i p i i e t e 212 t s 212 d SS r  SS p   t The satisfaction measures how likely a user is interested in one of the personalized resources in the period-supported sessions 5.2 Experimental Results time Sports Computer etc and 57 sub-topics such as MovieTV in Past S S  d 004  n p t i 212 d d  d  d   otherwise The SS SS SS SS Figure 4 shows the satisfaction of the overall web personalization for the different durations of period conditions from 0.5 to 4.0 hours based on different numbers of personalized resources from 1 to 6 As shown in Figure 4 when the number of personalized resources increases the satisfaction also increases But the increase is not signi\336cant after the number of personalized resources is more than 4 Although the satisfaction can be further improved with more personalized resources e.g 6 too many personalized resources will affect the preparation process of useful resources for users With at most 4 personalized resources we have obtained the lowest satisfaction of 77.9 for the user u82 with satisfaction       SS   003  for overall web personalization is de\336ned as is the duration of each period condition Then we have a total of 


References Knowledge and Information Systems Proc of the 14th Intl Joint Conf on AI Proc of the 14th Intl Conf on Data Engineering Proc of the 9th Intl Conf on Cooperative Information Systems Comm of ACM Proc of the 15th Intl Symposium on Foundations of Intelligent Systems Proc of the 10th Intl Conf on Travel Behaviour Research Data Knowledge Engineering Journal of Information and Control  pages 924\320 929 1995 8 D  O la ru a n d B  S mith  M o d e llin g D a ily Ac ti v ity Sc h e d u le s with Fuzzy Logic In 1 R  C ool e y  B  M obasher  a nd J S r i v ast a v a  D at a P r e par a t i o n for Mining World Wide Web Browsing Patterns a c 5 0 0 0 Formal Concept Analysis Mathematical Foundations User Modeling and User-Adapted Interaction 0 1 2 4 Figure 4 Performance results based on satisfaction Proc of the 8th Intl Symposium on Temporal Representation and Reasoning     1\(1\:5\32032 1999 2 M  E irin a k i a n d M  V a z ir g ia n n is We b M in in g f o r We b P e r sonalization  3\(1\:1\32027 2003 3 B G a n te r a n d R W ille   40\(3\:77\32087 1997 5 D  L i a nd J S  D e ogun D i sco v e r i ng Par t i a l P er i odi c S equential Association Rules with Time Lag in Multiple Sequences for Prediction In  2003  B  O zden S  R amasw amy  and A S i l b erschat z C ycl i c Association Rules In  13\(4\:311\320372 2003  C S h ahabi  F  B Kashani  Y  S  C hen and D  M cL eod Yoda An Accurate and Scalable Web-Based Recommendation System In  42\(2\:189\320222 2002  L  A  Z a deh F u zzy S e t s   8:338\320353 1965 u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82  Springer-Verlag 1997 4 J  A  K o n s ta n  B N M ille r  D M a ltz  J  H e r lo c k e r  L  G o r don and J Riedl Grouplens Applying Collaborative Filtering to Usenet News  pages 332\320341 2005 6 Y  L i  P  N i ng X  S  W a ng and S  J aj odi a D i sco v e r i ng Calendar-Based Temporal Association Rules In  pages 111\320118 2001 7 H  L ie b e rma n  L e tiz ia  A n A g e n t th a t Assists W e b Bro w sing In  pages 412\320421 1998  D  P i er r a k o s G  Pal i our as C  P apat heodor ou and C  D  Spyropoulos Web Usage Mining as a Tool for Personalization A Survey  pages 418\320432 2001  G  S t umme R  T aoui l  Y  B a st i d e N  Pasqui er  a nd L Lakhal Computing Iceberg Concept Lattices with TITANIC b d d  d  d  d  0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction ACM TOIT alization using periodic access p atterns of individual users Different from non-periodic approaches the proposed approach can ef\336ciently determine which resources a user is most probably interested in during a given period without the use of the user\325s current access information This makes it possible to perform more costly personalized resource preparation in advance rath er than in real-time The experimental results have shown that the proposed approach has achieved very effective web personalization evaluated by the applicability and satisfaction measures for the prede\336ned period conditions 


G f d O??Et c f d tb ? f} g ? h c h d h Figure 2. A frequency tree example After we built a frequency tree, we then use the Quick-split technique to calculate the maximal frequent sets The Quick-split algorithm is given here Input: A frequency tree r Output: An array of BitSets representing Itemsets Quick-split\(Tree r 1: if\(r is leaf   2: for all x E r.subs do 3: subres[x] = Quick-split\(x x 4: result =newBSO 5: for all x E r.subs do 6: result = result &amp; subres[x 7: remove b E result, b.size:::; k 8: return result To speed up calculation, an itemset is represented by a bitset with 0 and I for specifying the absence or presence of an item at a corresponding position respectively. The Quick-split performs a calculation on a frequency tree and returns an array of bitsets, which represent a group of decomposed itemsets. Splitting is accomplished by calculating bitset results in a bottom  up fashion in the tree. In the above example, we have 8 items a, b, . . .  , h corresponding to positions 0-7 in a 8bit bitset. So p.JS = abcdefgh = {I III I Ill}; abcd ll1 10000}; bcdefgh = {OllillII}. The size of the bitset is the number of items in p.JS which is usually much smaller than the total item size in the dataset For the frequency tree in Figure 2, for the itemset abcdefgh and infrequent 3-itemsets {aef, aeg, aeh, afg ajh, agh, abe, abf, abg, abh, ace, acf, acg, ach, ade adf, adg, adh} , Quick-split returns the possible maximal frequent sets {abcd, bcdefgh The PD Algorithm Input: transaction dataset T Output: frequent patterns PD \( transaction-set T I : D 1 = {&lt;t, 1&gt;1 t E T}; k= I 2: while \(Dk   3: for all p E Dk do II counting 4: for all k-itemset s c;;; p.JS do 5: Sup\(s IDk 6: decide Lk and ?Lk Ilbuild Dk 7: Dk+]= PD-rebuild\(Dk, Lk , ?Lk 8: k 9: end 10: Answer = u Lk As shown above, PD is the top-level function that accepts a transaction dataset as its input and returns the union of all frequent sets as the result. At the kth pass steps 3-6 count for every k itemset of each pattern in Dk and then determine the frequent and infrequent sets Lk and ? Lk; step 7 uses Dk , Lk and ?Lk to rebuild Dk PD stops when Dk is empty The PD-rebuild Algorithm Input: Dataset Db frequent Lk, infrequent ?Lk Output: Dataset DB PD-rebuild \(Dlo Llo ?Lk 1: Dk  ht = an empty hash table 2: for all p E Dk do begin 3: / / q k, ?q k can be taken from previous counting qk={sls E p. JS nLk}; ?qk={tltE p. JS n ?Lk 4: u = PD-decompose\(p.JS, ?qk 5: v ={s E ul s is k-item independent in u 


5: v ={s E ul s is k-item independent in u 6: add &lt;u-v, p.Occ&gt; to Dk+1 7: for all s E v do 8: if sin ht then ht. s. Occ += p. Occ 9: else put &lt;S,p.Occ&gt; to ht 10: end 11: Dk+] = Dk+] u {p E ht The PD-rebuild shown above is to determine DB by Dk, Lk and ?Lk' For each pattern p in Db step 3 computes its qk and ?qk; step 4 calls PD-decompose algorithm to decompose p by ?qk. Note that qk is not used here for decomposing p. In steps 5 to 9, we use pattern separation rule to separate p. In steps 7 to 9 PD-rebuild merges the patterns separated from p with their identical ones via a hash table ht. Since PD follows the pattern decomposition rule to decompose patterns and the pattern separation rule for merging identical patterns that yield same support, the answers generated by PD are correct 3. Comparative Study Our experiments were performed on a 600 MHz Pentium PC machine with 256 MB main memory running on Microsoft Windows XP. All three algorithms were written in C++ language. The test dataset was generated in the same fashion as the IBM Quest project . We used dataset T25.I10.DIOOK . In the dataset, the number of items N was set to 1000. The corruption level for a seed large itemset was fixed obtained from a normal distribution with mean 0.5 and variance 0.1. In the dataset, half of all items were corruptible. In the dataset, the average transaction size ITI and average maximal potentially frequent itemset size III are set to 25 and 10, respectively, while the number of transactions IDI in the dataset is set to lOOK 3.1. Comparison of PD with DCP  Pattern Decomposition algorithm does not need to generate candidate sets which are the main improvement on DCP; the reduced dataset contains only itemsets whose subsets are all frequent  PD generates all frequent sets whether it is not certain in DCP. PD significantly reduces the dataset in each pass by reducing the number of transactions and their size to give better performance. So counting time is clearly less than DCP in a reduced dataset  PD is much more scalable than the DCP 8000 7000 6000 5000 lt;.i OOO E f OOO 2000 Minimum Support PD DCP Figure 3. Performance comparison 8 6 4 2 PD DCP owa_L??_L??_L??_L??_L??_L?? o 50 100 150 200 250 Number of Transactions\(k Figure 4. Scalability comparison Figure 3 shows the execution times for different 


Figure 3 shows the execution times for different minimum support. We can see that PD is about 15 times faster than DCP with minimal support at 2% and about 8 times faster than DCP at 0.25%. In Figure 4, to test the scalability with the number of transactions experiments on dataset D are used. The support threshold is set to 0.75 3.2. Comparison of PD with PIP  Predictive item pruning FP-tree algorithm has a complicated data structure in comparison to PD algorithm  PD works by decomposing transactions into short itemsets. Then regular patterns are combined together. Hence data set is being reduced at every pass. As a result, space efficiency is improved. On the other hand, PIP FP-tree, although prunes infrequent items, its hit ratio is not as efficient as PD. So, obviously its space efficiency is not better than PD  As PD always concerns with the current data set less time is required in comparison to PIP FP-tree algorithm  PD is more scalable than the PIP 100r  E F  60 40 0 20 PD  PIP Minimum Support Figure 5. Performance comparison 500 r 400 300 E F  oo 0 100     Number of Transactions\(k   PD  PIP   Figure 6. Scalability comparison 160 In Figure 5, both PIP and PD have good performance on D. But PIP takes substantially more time when minimum support in the range from 0.6% to 2%. When minimum support is less than 0.6%, the number of frequent patterns increased quickly and thus the execution times are comparable. In Figure 6, we compared the scalability of PD with PIP on the dataset D with minimum support = 0.75%. PD was clearly more scalable than that of PIP 4. Conclusion The programs were implemented in C++ very efficiently. Since really large datasets or data warehouse was not available for us, we run the programs of these three algorithms by using test datasets. So performance comparisons are not the absolute values. The results can vary on other 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



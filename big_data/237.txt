Discovering auantitative associations in databases A Shragai and M Schneider  Department of electrical Engineering Tel Aviv University  School of Computer Science Natanya College Abstract In this paper we introduce a technique for mining association rules fiom quantitative data tables. The proposed method integrates the fuzzy set concept and the apriori algorithm In this algorithm the 
design of the membership functions avoids discriminating the importance level of the points Additionally, our method incorporates the bias direction of an item fiom the center of a membership function region. Also the method emphasizes the distinction between three important parameters the support of a rule its strength and its confidence It avoids missing the distinction between small number of occurrences with high support intersections and large number of occurrences with low 
support intersections Introduction The goal of data mining process in data tables is to discover interesting rules of the type A-B which state association between the items A and B for this purpose Agrawal et a1 designed some algorithms I The data mining process was divided into two phases in the first one itemsets sets of attributes whose support number of occurrences in 
the database is above a certain threshold \(called minimum support are considered as large itemsets and move over to the next stage The second stage of the data mining process is the formation of association rules fiom the large itemsets Then the confidence percentage of transactions having B given that they also having A is computed for every association rule Those with confidence level above a certain threshold called 
minimum confidence are displayed as interesting association rules Minimum SUDDO criterion Many papers were writen about fmding boolean association rules  1 8 101 and quantitative association rules 2,3,4,5,6,7,9 In 1,2,3,4,9,10 the support threshold plays a major role in the judgement weather an itemset is a large one Assume two data points, A and B as depicted in 
Fig 1 The intersection support of the itemset AB as applied in 2,3 is very low. Thus the summation of the support from the whole database may be less than the support threshold even if the attributes A and B occur many times in the same environments meaning they are strongly associated Even methods that overcome this problem 5,6 do not distinguish between the 
two sides of the membership function apex, as long as the points are not in the area of overlapping between two membership function regions see Fig 2 These methods cause identical association rules when attribute B occurs at bl or b Algorithms for mininp auantitative laree itemsets In this section an algorithm based on the apriori data mining 
algorithm is described to discover large itemsets Fuzzy sets are used to handle quantitative values as described in 2 Our algorithm is applied with some differences Notation n  m  number of transactions in the database number of items attributes in the database 0-7803-7U78-3/0u$10.00 C IEEE Page 423 


di  the i-th transaction Ij  the j-th attribute Iij  the value of 1 for di pijk  Rjk  nUm\(Rjk  C  c  4\222  f,\221  L  1  num\(Il  Is  numR\(Ij  the membership grade of 1 in the region k the k-th fuzzy region of the attribute I the set of candidate itemsets with r attributes candidate itemset with r attributes the membership value of di in region s the fuzzy value of the itemset c in the transaction di the set of large itemsets with r items a large itemset with r items number of occurrences of the attribute region Rjk in the whole database where p,jk O the occurrences number ofthe itemset Il  Is the number of the membership hnction regions for the attribute I The quantitative values are first transformed into a set of membership grades by using predefined membership functions Every membership grade represents the agreement of a quantitative value with a linguistic term In order to avoid discriminating the importance level of data, each point must have membership grade of 1 in one membership function; Thus, the membership functions of each attribute produce a continuous line of p=l  Additionally, in order to diagnose the bias direction of an item fiom the center of a membership hnction region almost each point get another membership grade which is lower than 1 in other membership functions region Thus, each end of membership function region is touching close to or slightly overlapping an end of another membership function \(except the outside regions of course\\(Fig 3 By this mechanism as point \223a\224 moves right Mer fiom the center of the region 223middle\224 it gets a higher value of the label 223middle-high\224 additionally to the value 1 of the label \223middle\224 The algorithm Step 1 Step 2 Step 3 step 4 Step 5 Step 6 a b C For each transaction i For each attribute j 1:=\(hj1/Rjl+pij&27  pijk Where the superscript f denotes fuzzy set For each attribute region Rik count the number of occurrences, where whole database. The output is num\(Rjk p+O in the For each attribute region R,k check weather its frequency num\(R,k is larger than or equal to the predefmed number of occurrences minnum If Rik satisfies the above condition put it in the set of large 1-itemsets L That is LI={RjklnUm\(Rjk lSjlm llklnumR\(Ij r-1 r is the number of items that composed the large itemsets in the current stage Generate the candidate set fiom L in a way similar to that in the apriori algorithm that is the algorithm frst joins 1 and l assuming that r-1 items in the two itemsets are the same and the other one is different It then keeps in CWI the itemsets having all sub-itemsets of r items existing in L step 6 in 3 Here every item in an itemset is a fuzzy region Note that two regions belonging to the same attribute can not exist simultaneously in the same itemset For each newly formed candidate itemset cWl in CHI that is composed of the items sl For each transaction di calculate its intersection fuzzy value as l,\222=fl\222nf;n nfWl\222 where 4\222 is the membership value of the region s in di Calculate the frequency of cWI on the transactions where qc,+l num\(cWl\is output If the fiequency of the itemset is larger than or equal to the predefined number of Occurrences minnum put it in the set of large el-itemsets Ll s2   I do the following substeps   Page 424 


Step 7 Step 8 a b Step 9 Step 10 Step 11  ExamDle If kl is empty, than go to the next step Otherwise set r=r+l and go to step 5 For each large itemset I r22 do the following substeps Calculate its support as sup\(l Calculate its strength as str\(lr sup\(l l For each large itemset I r22, generate the possible association rules as in  11 For each association rule sl s2  s,,=>s   s calculate its confidence as num\(sl SZ S,,S  s sl s2  if the confidence is higher than the predefined threshold minconf, then output the rule as an association rule For each association rule sI s2 s,,=>s s record its strength as str\(s1 s2...sn,s  sr and its support as sup In this section an example is given to illustrate the improvements of the proposed algorithm compared with previous methods. The database of the example is a part of the database that is used in 3 and transactions No 1 and No 3 were changed in order to illustrate the advantage of the proposed method Examples for the differences between our method and previous methods are given The data set of students course grades, consisting of 10 transactions is shown in Table 1 Table 1  students course scores in the example Each case consists of three course scores whose initials appear above. Each course is an attribute Each attribute has five fuzzy regions low middle and high as in 3 but the membership functions are different and two additional fuzzy regions low-middle and middle-high that have been added according to our method Fig.4 Thus five membership grades belong to each course score. These values are shown in Table 2 as a result of step 1 The fiequency of each is shown in the bottom line as a result of step 2 The regions are identified by their initials Table 2 The membership grades of the data from Table 1 and their occurrences 0-7803-7078-3/Ol/$lOAM C IEEE Page 425 


Step 3 Step4 r-1 Step 5 Step 6 Assuming that in this example minnum is 3 All the fuzzy regions are put in L1 except OOPh Generate the candidate set Cr+l fiom L as an example the itemsets OOP,DBl OOP,DBI OOP,,,I,DBI OOP,,,t,DBI are generated a The intersection fuzzy values of the four itemsets above are shown in Table 3 Here the b The frequencies of the four itemsets above are shown on the bottom lines of table 3 c Since the frequency of all four itemsets above are larger than or equal 3 they are all put min operator is used for intersection in the set of large 2-itemsets Lz The results from this step for the example itemsets are shown in Table 3   Table 3 The intersection fuzzy values and summarizing parameters for itemsets in L2 Step 7 Step 8 Step 9 Step 10 Step 11 L2 is not empty. Step 5 generates for example the candidate itemset OOP,,,I,DB~STI in Cs note that not all the itemsets in Cz and are detailed in the example By step 6 the frequency of this itemset is 3 which states it as a large itemset The supports of the four above itemsets in are shown in the bottom lines of table 3 as well as their strength. The support of the itemset OOPmhDB~,ST1 is 2.8 and its strength is 0.93 From the large itemset OOPdDBt the association rule OOPd=>DBh is generated From the large itemset OOPdDBl the association rule OOPd=>DB1 is generated The itemset 00PdDB&T1 generates for example, the association rule OOP~=>DBI,,,STI The confidence of the rule 00Pd=>DB1 is 1 The confidence of the rule OOPd=>DBt is 0.75 The confidence of the rule OOPd=>DBhST is 0.75 Suppose that minconf=0.7 these three rules are output as association rules The support of the rule OOPh=>DBh is 3.8 and its strength is 0.95 The support of the rule OOPd=>DB is 2 and its strength is 0.67 It can be seen, that the bias of the rule OOPd=>DBl to the left with respect to the itemset DBh formed the rule OOPd=>DBt whose support is much lower than the support of the main rule that conects OOP,,,h to DB Also it can be shown that there is no rule in the right side of DBh The support ofthe rule OOPd=>DBhSTI is 2.8 and its strength is 0.93 It can be seen, that the three rules above would not be identified by some of the previous methods Also our method found the bias of the main rule 0-7803-7078-3/0U$l0.00 C IEEE Page 426 


Conclusions The suggested rules mining method avoids the missing of association rules that might happen as a consequence of arbitrary membership functions design Also our method considers the bias direction of an association f?om the main-rule regions The proposed algorithm distinguishes between three important parameters the total support of the rule the mean level of agreement the support intersection between the items in the itemset \(the \223strength\224 of the rule and the part of the relevant database which fidfils the association rule \(the confidence of the rule These three parameters are instead of the integration of the individual supports and confidence calculation afterwards Thus the distinction between small number of occurrences with high agreement and large number of occurrences with bad agreement do not disappear 1 2 3 4 5 6 7 8 9 10 R Agrawal T hielinski and A Swami Mining Association Rules between Sets of Items in Large Databases. Proceeding of ACM SIGMOD, 207-216 Washington, D.C 1993 T.P Hong C.S Kuo and S.C Chi: A Fuzzy Data Mining Algorithm for Quantitative Values 1999 Third Intemational Conference on Knowledge-Based Intelligent Information Engineering Systems. Proceedings. IEEE 1999, pp 480-3 T.P Hong C.S Kuo and S.C Chi Mining Association Rules fiom Quantitative Data. Intelligent Data Analysis vo1.3 no.5 nov 1999, pp363-376 Qiang Wei and Guoqing Chen Mining Generalized Association Rules with Fuzzy Taxonomic Structures 18 International Conference of the North American Fuzzy Information Processing Society  NAFIPS cat. No 99TH8397\IEEE 1999 pp. 477-8 1 Piscataway, NJ USA K.C.C Chan and W.H Au Mining Fuzzy Association Rules In Proc of the 6 ACM Int\222l Conf on Information and Knowledge Management Las Vegas Nevada Nov 1997, pp.209-2 15 W.H Au and K.C.C Chan FARM A Data Mining System for Discovering Fuzzy Association Rules FUZZ-IEEE 99 1999 IEEE International Fuzzy Systems Conference Proceedings Vazirgiannis M and Halkidi M Uncertainty handling in the data mining process with fuzzy logic Ninth IEEE Intemational Conference on Fuzzy Systems FUZZ-IEEE 2000 cat No 00CH37063\IEEE Part vol 1,2000 pp.393-8 vol 1 Piscataway NJ USA A Savasere, E. Omiecinski and S Navathe Mining for Strong Negative Associations in a Large Database of Customer Transactions ICDE 1998 pp 494-502 Chan Man Kuok Ada Fu and Man Hon Wong Mining Fuzzy Association Rules in Databases Sigmod Record vol 27 no 1 March 1998 pp 41-6 R Feldman, Auman Y and Kloesgen W Maximal Association Rules: A New Tool for Mining for Keywords co-occurrences in Document Collection. Proceeding of the KDD conference pp IEEE Part vol 3 1999 pp 1217-22 vol 3 167 170, 1997 0-7803-7U78-3/0U$lO.W C IEEE Page 427 


p=1 A B Fig 1 A Fig 2 Middle high LOW middle middle hieh p=1 Fig 3 high Low Middle 1 low middle middle high 61 70 86 95 Fig 4 0-7803-7078-3/0l/$l0.00 C IEEE Page 428 


1 08 Ob 04 02 123456 1 08 06 04 02 n 123456 123456 I 08 06 04 02 n I23456 123456 I 1 08 06 04 02 n 123456 I 1 08 Ob 04 02 0 123456 6l 12345 I 08 Ob 04 02 123456 1 08 06 04 02 n 123456 123456 Space Shuttle Sine cM Noisy Sine cubed ECG Manufacturing Water Level Tickwise 1 Tkkwise 2 Exchange Rate Radio Waver Figure 6 A comparison of the SWAB algorithm with pure batch Bottom-Up and classic Sliding Windows on ten diverse datasets, over a range in parameters Each experimental result ie. a triplet of histogram bars\is normalized by dividing by the performance of the worst algorithm on that experiment Reproducible Results Statement In the interests of competitive scientific inquiry all datasets and code used in this work are available together with a spreadsheet detailing the original unnormalized results by emailing the first author 6 References l Agrawal R Faloutsos C  Swami A 1993 Efficient similarity search in sequence databases Proceedings of the 4lh Conference on Foundations of Data Organization and Algorithms 2J Agrawal R Lin K I Sawhney H S  Shim K 1995 Fast similarity search in the presence of noise scaling and translation in times-series databases Proceedings of 21\221\224 International Conference on Very Large Data Bases pp 490-50 3 Agrawal R Psaila G Wimmers E L  Zait M 1995 Querying shapes of histories Proceedings of the 21\224\221 International Conference on Very Large Databases 4 Chan K  Fu W 1999 Efficient time series matching by wavelets Proceedings of the Ifh IEEE International Conference on Data Engineering 5 Das G Lin K Mannila H Renganathan G  Smyth P 1998 Rule discovery from time series Proceedings of 295 


the 3 International Conference of Knowledge Discovery and Data Mining pp 16-22 6 Douglas D H  Peucker T K.\(1973\Algorithms for the Reduction of the Number of Points Required to Represent a Digitized Line or Its Caricature Canadian Cartographer Vol IO No 2 December pp 112-122 7 Duda, R 0 and Hart, P. E 1973. Pattern Classification and Scene Analysis. Wiley, New York 8 Ge X  Smyth P 2001 Segmental Semi-Markov Models for Endpoint Detection in Plasma Etching To appear in IEEE Transactions on Semiconductor Engineering 9 Heckbert P S  Garland M 1997 Survey of polygonal surface simplification algorithms Multiresolution Surface Modeling Course Proceedings of the 24 International Conference on Computer Graphics and Interactive Techniques IO Hunter J  McIntosh N 1999 Knowledge-based event detection in complex time series data Artificial Intelligence in Medicine pp. 27 1-280 Springer I I Ishijima M et al 1983 Scan-Along Polygonal Approximation for Data Compression of Electrocardiograms IEEE Transactions on Biomedical Engineering BME I21 Koski A Juhola M  Meriste M. \(1995 Syntactic Recognition of ECG Signals By Attributed Finite Automata Pattern Recognition 28 I 2 pp 1927- 1940 I31 Keogh E Chakrabarti K Pazzani M  Mehrotra 2000 Dimensionality reduction for fast similarity search in large time series databases Journal of Knowledge and Information Systems I41 Keogh E  Pazzani M 1999 Relevance feedback retrieval of time series data Proceedings of the 221h Annual International ACM-SIGIR Conference on Research and Development in Information Ret rie va 1 15 Keogh E  Pazzani M 1998 An enhanced representation of time series which allows fast and accurate classification clustering and relevance feedback Proceedings of the 41h International Conference of Knowledge Discovery and Data Mining pp 239-241, AAA1 Press I61 Keogh E  Smyth P 1997 A probabilistic approach to fast pattern matching in time series databases Proceedings of the 3 International Conference of Knowledge DiscoveT and Data Mining pp 24-20 I71 Lavrenko V Schmill M Lawrie D Ogilvie P Jensen D  Allan J 2000 Mining of Concurent Text and Time Series Proceedings of the 61h International Conference on Knowledge Discovery and Data Mining pp 37-44 18 Li C Yu P  Castelli V.\(1998 MALM A framework for mining sequence database at multiple abstraction levels Proceedings of the 9 International Conference on Information and Knowledge Management pp 267-272 30 1 1 I91 McKee J.J Evans N.E  Owens F.J 1994 Efficient implementation of the FadSAPA-2 algorithm using fixed point arithmetic Auromedica Vol 16 pp 109-1 17 20 Osaki R Shimada M  Uehara K 1999 Extraction of Primitive Motion for Human Motion Recognition The 2"d International Conference on Discovery Science pp.35 1-352 21 Park S Kim S W  Chu W W. \(2001\Segment Based Approach for Subsequence Searches in Sequence Databases To appear in Proceedings of the I6Ih ACM Symposium on Applied Computing 22 Park S  Lee, D  Chu W W 1999\Fast Retrieval of Similar Subsequences in Long Sequence Databases Proceedings of the 3 IEEE Knowledge and Data Engineering Exchange Workshop  Pavlidis T 1976 Waveform segmentation through functional approximation IEEE Transactions on Computers 24 Perng C Wang H Zhang S  Parker S 2000 Landmarks a new model for similarity-based pattern querying in time series databases Proceedings of 16'h International Conference on Data Engineering 25 Qu Y Wang C  Wang S 1998 Supporting fast search in time series for movement patterns in multiples scales Proceedings of the 7Ih International Conference on Information and Knowledge Management  Ramer U 1972 An iterative procedure for the polygonal approximation of planar curves Computer Graphics and Image Processing 1  pp 244-256 27 Shatkay H 1995 Approximate Queries and Representations for Large Data Sequences Technical Report cs-95-03 Department of Computer Science Brown University 28 Shatkay H  Zdonik S 1996 Approximate queries and representations for large data sequences Proceedings of the 12 IEEE International Conference on Data Engineering pp 546-553 29 Sugiura N  Ogden R T 1994\Testing Change points with Linear Trend Communications in Statistics B Simulation and Computation 23 287-322 30 Vullings H.J.L.M Verhaegen M.H.G  Verbruggen H.B 1997 ECG Segmentation Using Time Warping Proceedings of the 2"d International Symposium on Intelligent Data Analysis 31 Wang C  Wang S 2000 Supporting content based searches on time Series via approximation Proceedings of the 12th International Conference on Scientific and Statistical Database Management 296 


Category Manual Automatic No of associations 63 30 No of rules 330 44 Max association size 6 4 Avg support 0.45 0.43 Avg rule con\256dence 0.80 0.82 Table 1 Manual versus automatic image content mining 4.2 Quality of results We should mention that there were no false association rules It did not happen that an object was incorrectly identi\256ed and then a rule was generated with the incorrect identi\256er In general when we found a match between two objects they were the same shape All the incorrect matches are 256ltered out by the support parameter and then the association rules are generated for objects correctly ideinti\256ed Also some redundant matches happened b ecause of the blobs that represented several shapes but these matches are 256ltered out by the rule support In Table 1 we present a summary of our experimental results with 100 hundred images We compare the results obtained by manually identifying objects in each image and then generating association rules from such identi\256ers Manual Column against the results obtained by our current implementation Automatic Column Ideally our image mining algorithm should produce the same results as the manual process So the table gives a standpoint to assess the quality of our experimental results For these 100 images unwanted matches either incorrect or involving many objects happened in at most 4 images and therefore their support was well below the minimum support frequency which was at 30 These experiments were run using the same parameters for object identi\256cation as in our small example with 10 images The parameters for object identi\256cation had the following values We set color standard deviation to 0.5 contrast standard deviation to 0.5 and anisotropy also to 0.5 The similarity threshold as needed by the similarity function was set to 0.6 We tuned these parameters after several experiments These parameters maximized the number of associations and decreased the errors in unwanted matches The association rule program was set to look for rules with a 30 support and 70 con\256dence The background represents an object itself Since association rules with the background were not interesting for our purposes it was eliminated from consideration by the object identi\256cation step It is important to note that this is done after objects have been identi\256ed We tuned the object identi\256cation step to 256nd similar objects changing values for several parameters in the following manner The most important features used from each object were color and contrast We allowed some variance for color 0.5 and the maximum allowed variance for contrast 0.5 The anisotropy helped eliminate matches involving several geometric shapes We ignored shape b ecause objects could be partially hidden and rotated Position was considered unimportant because objects could be anywhere in each image Anisotropy and polarity were i gnored because almost all our shapes had uniform texture Area was given no weight because objects could be overlapping and thus their area diminished this can be useful to make perfect matches when objects are apart from each other A few rules had high support One problem that arose during our experiments was that the same shape could have two different blob descriptors and these blob descriptors could not be matched with two other descriptors for the same shape in another image This caused two problems First a rule could be repeated because it related the same shapes Second a rule did not have enough support and/or con\256dence and therefore was discarded So the rules found were correct and in many cases had an actual higher support and also higher con\256dence To our surprise in some cases there were no object matches because an object was very close to another one or was located in a corner of the image When two or more objects were overlapping or very close they were identi\256ed as a single object This changed the features stored in the blob The problem was due to the ellipsoidal shape of the blobs and the fact that when a geometric shape was located in a corner thta changed its anysotropy and polarity descriptors Given a blob for an object very close to one corner means determining an adequate radius for the blob i.e ellipse Regular shapes such as the triangle square and hexagon were easily matched across images This is a direct consequence of the circular blob representation produced when the image is segmented In this case neither position nor rotation affect the mining process at all It was surprising that in some cases there were no matches for the circle in these cases it was in a corner or some other shape was very close or overlapping Another important aspect about shape is that we do not use it as a parameter to mine images but shape plays an important role during the segmentation step So shape does affect the image mining results quality The rectangle and the ellipse are the next shapes that are easily matched even though we did not use the shape feature The most complicated shape was the L In this case a number of factors affected matches When this shape was overlapped with other shapes a few matches were found b ecause a big blob was generated Also orientation changed dominant 


ofimages 50 100 150 200 1 feature 50292 80777 127038 185080 2 obj identif 210 338 547 856 3 aux image 3847 6911 10756 13732 4 assoc rules 6 3 6 4 Table 2 Measured times in seconds for each Image Mining step with different image set sizes colors and contrast When the L was close to another shape its colors were merged making it dissimilar to other L shaped objects This suggests that irregular shapes in general make image mining dif\256cult We worked with color images but it is also possible to use black and white images Color and texture were important in mining the geometric shapes we created However we ignored shape as mentioned above Shape may be more important for black and white images but more accurate shape descriptors are needed than those provided by the blobs 4.3 Performance evaluation We ran our experiments on a Sun Multiprocessor forge.cc.gatech.edu computer with 4 processors each running at 100 MHz and 128 MB of RAM The image mining program was written in Matlab and C The 256rst three steps are performed in Matlab The feature extraction process is done in Matlab by the software we obtained from UCB Object identi\256cation and record creation were also done in Matlab by a program developed by us An html page is created in Matlab to interpret results The association rules were obtained by a program written in C In this section we examine the performance of the various components of the image mining process as shown in Table 2 for several image set sizes These times were obtained by averaging the ellapsed times of executing the image mining program 256ve times 4.4 Running time analysis Feature extraction although linear in the number of images is slow and there are several reasons for this If image size increases performance should degrade considerably since feature extraction is quadratic in image size Nevertheless this step is done only once and does not have to be repeated to run the image mining algorithm several times Object identi\256cation is fast This is because the algorithm only compares unmatched objects and the number of objects per image is bounded For our experimental results time for this step scales up well Auxiliary image creation is relatively slow but its time grows linearly since it is done on a per image basis The time it takes to 256nd rules is the lowest among all steps If the image mining program is run several times over the same image set only the times for the second and the fourth step should be considered since image features already exist and auxiliary images have already been created 5 Application Image mining could have an application with real images The current implementation could be used with a set of images having the following characteristics 017 Homogeneous The images should have the same type of image content For instance the program can give useless results if some images are landscapes other images contain only people and the remaining images have only cars 017 Simple image content If the images are complex they will produce blobs dif\256cult to match Also the association rules obtained will be harder to interpret A high number of colors blurred boundaries between objects large number of objects signi\256cant difference in object size make the image mining process more prone to errors 017 A few objects per image If the number of objects per image is greater than 10 then our current implementation would not give accurate results since Blobworld in most cases generates at most 12 blobs per image 017 New information The image itself should should give information not already known If all the information about the image is contained in associated alphanumeric data then that data could be mined directly 6 Future Work Results obtained so far look promising but we need to improve several aspects in our research effort We are currently working on the following tasks We also need to analyze images with repeated geometric shapes If we want to obtain simple association rules this can make our program more general This can be done without further modi\256cation to what is working However if we want to mine for more speci\256c rules then we would need to modify our algorithm For instance we could try to 


produce rules like the following if there are two rectangles and one square then we are likely to 256nd three triangles The issues are the combinatorial growth of all the possibilities to mine and also a more complex type of condition We will also study more deeply the problem of mining images with more complex shapes such as the irregular one similar to the letter L We need a systematic approach to determine an optimal similarity threshold or at least a close one A very high threshold means only perfect matches are accepted On the other hand a very low similarity threshold may mean any object is similar to any other object Finding the right similarity threshold for each image type l ooks like an interesting problem Right now it is provided by the user but it can be changed to be tuned by the algorithm itself Also there are many ways to tune the eleven parameters to match blobs and the optimal tuning may be speci\256c to image type There also exists the possibility of using other segmentation algorithms that could perform faster or better feature extraction It is important to note that these algorithms should give a means to compare segmented regions and provide suitable parameters to perform object matching in order to be useful for image mining From our experimental results it is clear that this step is a bottleneck for the overall performance of image mining We can change the object identi\256cation algorithms to generate overlapping object associations using more features Our algorithm currently generates partititons of objects that is if one object is considered similar To another one the latter one will not be compared again By generating overlapping associations we can 256nd even more rules For instance a red rectangular object may be considered similar to another rectangular object and at the same time be similar to another red object Mining by position is also possible for instance two objects in a certain position may imply another object to be in some other position Since the software we are using for feature extraction produces eleven parameters to describe blobs we have 2 11 possibilites to match objects 7 Conclusions We presented a new algorithm to perform data mining on images and an initial experimental and performance study The positive points about our algorithm to 256nd association rules in images and its implementation include the following It does not use domain knowledge it is reasonably fast it does not produce meaningless or false rules it is automated for the most part The negative points include some valid rules are discarded because of low s upport there are repeated rules because of different object id's unwanted matches because of blobs representing several objects slow feature extraction step a careful tuning of several parameters is needed it does not work well with complex images We studied this problem in the context of data mining for databases Our image mining algorithm has 4 major steps feature extraction object identi\256cation auxiliary image creation and identi\256ed object mining The slowest part of image mining is the feature extraction step which is really a part of the process of storing images in a CBIR system and is done only once The next slowest operation is creating the auxiliary blob images which is also done once Object identi\256cation and association rule 256nding are fairly fast and scale up well with image set size We also presented several improvements to our initial approach of image mining Our experimental results are promising and show some potential for future study Rules referring to speci\256c objects are obtained regardless of object position object orientation and even object shape when one object is partially hidden Image mining is feasible to obtain simple rules from not complex images with a few simple objects Nevertheless it requires human intervention and some domain knowledge to obtain better results Images contain a great deal of information and thus the amount of knowledge that we can extract from them is enormous This work is an attempt to combine association rules with automatically identi\256ed objects obtained from a matching process on segmented images Although our experimental results are far from perfect we show that it is better to discover some reliable knowledge automatically than not discovering any new knowledge at all Acknowledgments We thank Chad Carson from the University of California at Berkeley for helping us setup the Blobworld system We also thank Sham Navathe and Norberto Ezquerra for their comments to improve the presentation of this paper References 1 R  A g r a w a l  T  I m i e lin s k i a n d A  S w a m i  M in in g a s s o ciation rules between sets of items in large databases In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data  pages 207\261 216 Washington DC May 26-28 1993  R  A gra w a l a n d R  S ri ka nt  F a s t a l gori t h m s for m i n i n g association rules in large databases In Proceedings of the 20th International Conference on Very Large Data Bases  Santiago Chile August 29-September 1 1994  S  B e l ongi e  C Ca rs on H  G r e e n s p a n  a nd J  Ma lik Recognition of images in large databases using a learning framework Technical Report TR 97-939 U.C Berkeley CS Division 1997 


 C  C a r s on S  Be l ongi e  H  G r e e n s p a n  a nd J  Ma l i k  Region-based image querying In IEEE Workshop on Content-Based Access of Image and Video Libraries  1997 5 G  D u n n a n d B  S  E v e r itt An Introduction to Mathematical Taxonomy  Cambridge University Press New York 1982  U  F a yya d  D  H a u s s l e r  a nd P  S t orol t z  M i n i n g s c i e n ti\256c data Communications of the ACM  39\(11\51\26157 November 1996  U  F a yya d G  P i a t e t s k y-S h a p i r o a n d P  S m y t h  T he kdd process for extracting useful knowledge from volumes of data Communications of the ACM  39\(11\:27\261 34 November 1996 8 D  F o r s y t h J M a l i k  M F l e c k H G r e e n s p a n  T L e ung S Belongie C Carson and C Bregler Finding pictures of objects in large collections of images Technical report U.C Berkeley CS Division 1997  W  J  F ra wl e y  G  P i a t e t s k y S ha pi ro a nd C J  Ma t h e u s  Knowledge Discovery in Databases  chapter Knowledge Discovery in Databases An Overview pages 1 261 27 MIT Press 1991  V  G udi v a da a n d V  R a gha v a n Cont e n t ba s e d i m age retrieval systems IEEE Computer  28\(9\18\26122 September 1995 11 R  H a n s o n  J  S t u t z an d P  C h ees eman  B ay es i a n c l a s si\256cation theory Technical Report FIA-90-12-7-01 Arti\256cial Intelligence Research Branch NASA Ames Research Center Moffet Field CA 94035 1990  M H o l s he i m e r a n d A  S i e be s  D a t a m i ni ng T h e search for knowledge in databases Technical Report CS-R9406 CWI Amsterdam The Netherlands 1993  M H out s m a a nd A  S w a m i  S e t ori e nt e d m i ni ng of association rules Technical Report RJ 9567 IBM October 1993  C O r done z a nd E  O m i e c i ns ki  I m a ge m i ni ng A new approach for data mining Technical Report GITCC-98-12 Georgia Institute of Technology College of Computing 1998  J  R Q u i n l a n Induc t i o n o f d e c i s i on t r e e s  Machine Learning  1\(1\81\261106 1986  A  S a v a s e re  E  O m i e c i ns ki  a nd S  N a v a t h e  A n e f 256 cient algorithm for mining association rules In Proceedings of the VLDB Conference  pages 432 261 444 Zurich Switzerland September 1995  O  R Z a i a ne  J  H a n  Z  N  L i  J  Y  Chi a ng a n d S Chee Multimedia-miner A system prototype for multimedia data mining In Proc 1998 ACM-SIGMOD Conf on Management of Data  June 1998 


Database 1 proc 2 procs 4 procs 8 procs T5.I2.D100K 20 17 12 10 T10.I4.D100K 96 70 51 39 T15.I4.D100K 236 168 111 78 T20.I6.D100K 513 360 238 166 T10.I6.D400K 372 261 165 105 T10.I6.D800K 637 435 267 163 T10.I6.D1600K 1272 860 529 307 Table 3 Naive Parallelization of Apriori seconds   0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2    0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD : With Reading Time Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2  Figure 4 CCPD Speed-up a without reading time b with reading time 13 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


Reading  f Total Time Database Time P 000 1 P 000 2 P 000 4 P 000 8 P 000 12 T5.I2.D100K 9.1s 39.9 43.8 52.6 56.8 59.0 T10.I4.D100K 13.7s 15.6 22.2 29.3 36.6 39.8 T15.I4.D100K 18.9s 8.9 14.0 21.6 29.2 32.8 T20.I6.D100K 24.1s 4.9 8.1 12.8 18.6 22.4 T10.I6.D400K 55.2s 16.8 24.7 36.4 48.0 53.8 T10.I6.D800K 109.0s 19.0 29.8 43.0 56.0 62.9 T10.I6.D1600K 222.0s 19.4 28.6 44.9 59.4 66.4 Table 4 Database Reading Time in section 4 320 computation balancing hash tree balancing and short-circuited subset checking The 336gure on the left presents the speed-up without taking the initial database reading time into account We observe that as the number of transactions increase we get increasing speed-up with a speed-up of more than 8 n 2 processors for the largest database T10.I6.D1600K with 1.6 million transactions r if we were to account for the database reading time then we get speed-up of only 4 n 2 processors The lack of linear speedup can be attributed to false and true sharing for the heap nodes when updating the subset counts and to some extent during the heap generation phase Furthermore since variable length transactions are allowed and the data is distributed along transaction boundaries the workload is not be uniformly balanced Other factors like s contention and i/o contention further reduce the speedup Table 4 shows the total time spent reading the database and the percentage of total time this constitutes on different number of processors The results indicate that on 12 processors up to 60 of the time can be spent just on I/O This suggest a great need for parallel I/O techniques for effective parallelization of data mining applications since by its very nature data mining algorithms must operate on large amounts of data 5.3 Computation and Hash Tree Balancing Figure 5 shows the improvement in the performance obtained by applying the computation balancing optimization discussed in section 3.1.2 and the hash tree balancing optimization described in section 4.1 The 336gure shows the  improvement r a run on the same number of processors without any optimizations see Table 3 Results are presented for different databases and on different number of processors We 336rst consider only the computation balancing optimization COMP using the multiple equivalence classes algorithm As expected this doesn\325t improve the execution time for the uni-processor case as there is nothing to balance r it is very effective on multiple processors We get an improvement of around 20 on 8 processors The second column for all processors shows the bene\336t of just balancing the hash tree TREE using our bitonic hashing the unoptimized version uses the simple mod d hash function Hash tree balancing by itself is an extremely effective optimization It s the performance by about 30 n n uni-processors On smaller databases and 8 processors r t s not as 14 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



Investigative Profiling with Computer Forensic Log Data\222and Association Rules Tamas Abraham and Olivier de Vel Information Networks Division Defence Science and Technology Organisation PO Box 1500 Edinburgh SA 51 11 Australia  tamas.abraham,olivier.devel dsto.defence.gov.au Abstract Investigative profiling is an importanr activity in com purer forensics that can narmw the search for one or more computerperpetrators Data mining is a technique rhar has produced good results in 
providing insight into large vol umes of data This paper describes how the association rule data mining technique may be employed to generate profilesfrom log data and the methodology used for the in terpretation of the resulting rule sets The process relies on background knowledge in the form of concept hierarchies and beliefs commonly available from or attainable bl the computer forensic investigative team Results obtained with the profiling system has identifed irregularities in computer logs 1 Introduction Computer 
Forensics undertakes the post-mortem or 223after-the-event\224 analysis of computer crime Of particu lar importance is the requirement to successfully narrow the potentially large search space often presented to investiga tors of such crimes This usually involves some form\(s\of guided processing of the data collected as evidence in order to produce a shortlist of suspicious activities Investigators can subsequently use this shortlist to examine related evi dence in more detail 161 Investigative profiling is an important activity in com puter forensics that can significantly narrow the search for 
the perpetrator and reason about the perpetrator\222s behaviour This is analogous to criminal profiling which focuses on es tablishing personality characteristics of an offender in order to identify the type of person involved in the crime under investigation e.g arson\Profiling can also aid in identify ing the type of activity the perpetrator is engaged in e.g e mail authorship analysis may identify the educational level or gender of the offender and may consequently be able to establish if an e-mail has been masqueraded 8 Data Mining is employed to 
analyse large data sets as 0-7695-1754-4/02 17.00 0 2002 IEEE 11 might occur in a typical computer forensics investigation in order to discover potentially useful, previously unknown regularities within data In contrast to other more conven tional technologies it has been able to produce good results on large data sets where both incompleteness and noise may be present e.g 9 Data mining for the more specific purpose of construct ing personal profiles has been used in the context of cus tomer personalisation 
Here marketing content and ser vices are tailored to an individual on the basis of knowl edge about their preferences and behaviour Applications include content-based and collaborative filtering-based rec ommendation systems, customer profiling 2 1 131 fraud detection IO web browsing activities 7 18 23 171 Content-based recommendation systems model the link be tween data content and a person\222s preferences for that con tent whereas collaborative recommendation systems model the link between a person\222s preferences and other persons\222 preferences for the given data content 
15 191 Customer profiling is growing in importance in e-commerce Both factual and individual behavioural information are derived from the customer\222s e-transactional history The personali sation of web browsing activities for the purpose of improv ing the user\222s access to the web has also attracted interest recently Techniques for the modeling of the user\222s web access behaviour are varied including the use of a page content interestingness metric N-grams for capturing a user\222s interests 7 web page navigation dependencies for page predictive pre-fetching 181 
web page clustering for deriving aggregate user profiles 17 sequential web page patterns for discovering negatively-correlated components within a web site structure 23 However, most web per sonalisation applications deal with aggregate or classes of user profiles rather than individual user profiles In this paper we describe techniques to profile and anai yse computer forensic data We use a combination of ex isting techniques not yet employed in this application do main, modified where necessary to accommodate the partic ular environment In Section 2 we introduce the elements 


used in our approach to computer forensic profiling. Further details are given in Section 3 about data preparation and the need for guiding the investigative process Section 4 describes the algorithms we use and how they have been adopted for our needs. Tests performed on actual computer log data are detailed in Section 5 followed by our conclu sions in Section 6 2 Background to Investigative Profiling An offender profile consists of two components namely the factual component and behavioural component The factual profile FP consists of factual background knowl edge about the offender such as their name employee sta tus computer user name@\relationships with other em ployees and organisations etc The behavioural profile BP incorporates knowledge about an offender\222s crime scene-related behaviour Behaviour profile knowledge is derived from a variety of sources namely log file transac tions, header and body of e-mails telecommunications call record data patterns and so on The behavioural profile BP can be modeled in differ ent ways For example, a BP can be represented as a union of sub-profile hierarchies PH such as authorship profile software application usage profile, log-in profile etc or BPt Uf\224 PHj A profile hierarchy is a knowledge representation scheme using a hierarchy of multi-slot frames, similar to a concept hierarchy described in Section 3.1 that characterises a be havioural profile Alternatively BP can also be modeled as a set of asso ciation rules BPc RJi l.2  N Here, the rule attributes can be obtained from the raw data andor selected from the profile hierarchy nodes. For exam ple the rule 223If user X is a system administrator then the application Y  nmap a stealth port scanner executed may he a valid rule in a system administrator profile as suming that port scanning as used in hisher current job context is employed for system hardening but probably not in a finance contractor profile In this paper we study user behavioural profiles derived from event data in log files These profiles are conveniently represented by a set of implications or association rules ti  1,2   N of the form R  antecedent  consequent These rules provide an intuitive and declarative way to describe user behaviour IO For example, the rule Ro  Stamype  admin A DayOfWeek  tuesday A Application  database j Access  valid states that 223Administration staff that work on Tuesday have a valid access to a database application\224. Note that an asso ciation rule indicates the presence of some correlation he tween the rule\222s antecedent and consequent hut does not necessarily imply any causality 2.1 Profiling with Association Rules Association rule generation has been one of the most successful techniques in data mining It originated as a tool for discovering sets of items that occur together in supermarket basket data 4 Since then it has evolved to address a multitude of other types of problems to a point where it can even be used for purposes such as multi-dimensional inter-transaction mining 16 Suppos ing 1  il,i2   in is a set of items occurring in a data set an association rule can be expressed by the for mula A  B  s where A B 2 1 are groups of items of size ka and kB respectively where ka  ka 5 m and An B  0 We refer to the combined collection of items in A and Bas an ifemset of length k  k LB The variables s and o express support and confidence percentages for the rule, where support Y indicates how frequently the items in A and B occur together in the data while confidence c is the conditional probability P\(B1A where the probability P\(z is estimated using the support percentage of the set z For example the rule breudAbutter  milk  15 70 produced from a supermarket transactional database states that customers that buy bread and butter together are also 70 likely to purchase milk with 15 of the total number of records supporting this claim One of the potential uses for associations is the build ing of rule sets that describe behavioural data 2 1.31 This may be data collected about people or the operation of some systems Often in computer forensic investigations this in formation could be found in log files on a computer sys tem The rule sets generated from this data can be con sidered to describe a profile contained within the data set Profiles produced this way however are usually not com plete The support percentage parameter used in associa tion mining introduces loss into the rule set. This is because only data that occurs frequently enough that is satisfies a pre-defined minimum support is used in the rule generation process In the forensic sense however this is not necessar ily a disadvantage Regularities that are not picked up in the profile due to not satisfying support may he looked at as non-habitual and can be investigated as contrary to regular behaviour if necessary Another important aspect of forensic profiling is that a user profile is generated using available evidence and does not change once produced Additional evidence may be added later hut this should be regarded as the incomplete ness of initial evidence rather than the evolution of an exist ing profile In this case, the profile should be re-generated 12 


Recognising temporal segments or evolution within a pro file however is quite important and analysis of such phe nomena can be a major part of the profile evaluation pro cess 2.2 Deviation in Association Rule Profiles One of the first steps in a computer forensic investigation is to look for unusual events For example if an attacker gains super-user privileges on a computer system he may use them to perform actions not normally instigated by the real super-user\(s This would clearly be a deviation from the super-user profile as supported by data up to the time of intrusion. There are two ways this may be evidenced in the data and the profile generated on the full data set 1 As data entries with not enough support to be repre sented as association rules In order to find such en tries there must exist a mechanism for the investigator to query the data set for entries not fitting the profile 2 As association rules making up pan of the profile It would hence be important to identify this section of the profile as being anomalous or at least different from other parts of the profile Assigning a temporal scope to rules making up the profile could help an investiga tor recognise that something potentially unusual may have occurred at a certain time in the life of the system being investigated There are of course caveats to the above The attacker may have covered hislher uacks for example by removing en tries from the log files If he/she was thorough he/she may have only removed entries corresponding to hisher own ac tions or alternatively. may have removed all records or every record stored during the period of the criminal activ ity In this case the lack of evidence may warrant further investigation 3 Building Profiles The data obtained for computer forensic investigations are usually information stored on computers and networks They range from system log files to databases personal user files and other items that may be located on a computer To build a profile for a particular user, many of these items may need to be examined both individually and as a collection of interrelated items with potential relationships existing he tween recorded activities Profiling algorithms are there fore expected to be of varying complexity A simple algo rithm may produce rules based on the sporadic occurrences of data observed in a single file another may be required to recognise temporal dependencies or causal relationships in user activity recorded across several files Since computer forensics undertakes the post-mortem analysis of computer crime much of the analysis is done off-line Therefore, emphasis is more often on effectiveness than efficiency in order to produce a smaller set of targeted conclusions and reduce overall human investigation time For example it is preferable to achieve a low rate of false negatives at the expense of increased computational time and number of false positives Much of the information found on a computer is ex pected to be in a format not suited for immediate analysis An investigator must facilitate this by providing details on the subsets of data intended for analysis their format and conversion requirements and available background knowl edge Some of this can be achieved through automated means. Filtering the removal of unwanted information and the aggregation of separate data items are some of the more important activities during this stage of the analytical pro cess 3.1 Concept Hierarchies and Beliefs Background knowledge in data mining is popularly ex pressed in the form of concept hierarchies and is often used in the rule generation process 21 1 I The hierarchies con vey a generalisation of concepts from node to root \(which is usually the concept any and can be represented as a set of parent-child relationships in a data file An investigator may be prompted with a set of node level concepts found in the data and asked to abstract it to higher level ones ac cording to hidher liking This hierarchy, which is generally domain-dependent in forensics investigations can then he used in the mining process to produce a profile that con tains rules with elements at an arbitrary level of abstraction There should be no requirement for a concept hierarchy to be complete for profiling to operate correctly A set of hier archy fragments is often more desirable as it helps to avoid over-generalisation by not including very high level con cepts in the search process Concept hierarchies may be employed in two different ways during profile generation In a drill-down approach rules are initially generated for high concept levels. Interest ing high-level rules can he further investigated by descend ing the concept hierarchies for some attributes In a drill-up approach..a larger number of rules are produced with a po tentially low support level requirement using the attribute values present in the data By ascending concept hierar chies, higher level rules with increased support levels may be obtained Evolution within a profile is an important indicator of potentially irregular activities A profiling algorithm is ex pected to be able to attach temporal tags to rules indicat ing intervals of validity if so required Concept hierarchies therefore. must accommodate such functionality This hap 13 


 D I 1 I IDD I Figure 1 Data flow diagram of the profiling process pens at two levels  changes in the structure of concept hier archy over time, and changes in the position of a leaf node value over time In addition to using hierarchical abstraction of attribute values, investigators may have pre-conceived beliefs about a case being investigated A separate collection of rules can be used to describe a set of such beliefs These can be used to focus the investigation by searching for specific regulari ties in profiles or may also be used to reduce the profile by discarding rules that are defined as trivial I Furthermore the use of these rules may allow a post-processing algorithm to identify rules that contradict existing beliefs 4 The Profiling Process The data flow diagram in Figure 1 describes the data rules and processes used for profiling purposes It incorpo rates references to background knowledge such as concept hierarchies and beliefs and the final conclusions resulting from the forensic analysis detailed in Section 4.2 4.1 Basic Profile Generation Algorithm The association mining algorithm implemented for forensic analysis is designed to generate a profile using a single input file Depending on the desired level of back ground knowledge to be employed three approaches can be distinguished Generating rules with no concept hierarchies and be liefs This method is likely to produce a large set of rules that may require extensive user analysis I Generating rules with concept hierarchies hut no be liefs This solution allows for production of high-level rules andor generalisation of lower level rules permit ting both drill-down and drill-up Generaling rules with concept hierarchies and beliefs This permits the same possibilities as above as well as filtering made possible by the availability of existing beliefs The usual steps of data filfering data conversion and when background knowledge is used the creation of con cept hierarchies and beliefs precedes profiling The association mining algorithm MZIS-c matrix to ternsets using concepts we employ, shown in Algorithm 1 is a version of the classic Apnori association mining algo rithm 5 Note that the algorithm is not a new improved implementation and was mainly selected because it suits our analytical environment Its novelty lies in the fact that it performs binary mining in memory in conjunction with concept hierarchy ascension Details of this process are out lined below Let A  Al Az  At be a set of I attributes Each attribute Ai i  1   I can take on a discrete set of mu tually exclusive values Let a record T be a conjunction of values taken from each available attribute Let B be a col lection of n records In this finite collection, each attribute Ai may take on a finite number of discrete values Let the number of these values be denoted by mi for attribute A The total number of distinct attribute values that appear in B is then E mi Let W  Hl,H2   HN be a set of domain-dependent concept hierarchies or attribute fax onomies Each concept hierarchy Hj,j 200 1,2   N in the concept forest is formulated as a direct acyclic graph DAG with none one or more hierarchies assigned to each attribute A i  1  1 Concept hierarchies are structurally similar to profile hierarchies discussed in Sec tion 2 The main difference is that each pair of adjacent nodes in a DAG H represents an is-a or generalisation specialisation relationship rather than multi-slot frame pro file content relationship Examples of concept hierarchies are the IP Internet Protocol domain name hierarchy the functional directory of an organisation etc Leaf nodes in concept hierarchies belonging to attribute A therefore generally \(but not necessarily represent values occurring in R Non-leaf-nodes in concept hierarchies represent higher level abstractions of leaf-nodes and can not be values that occur in the original data Denote the collection of con cept hierarchies- with these leaf-nodes removed by I  HI Hz   HN Let m denote the number of non leaf concept nodes defined in all hierarchies for a!tribute Ai in  or equivalently the number of nodes in W Let m  Et mi  iii be the length of a binary vector U  bl    bm where bit bi 6 O 1 uniquely corre sponds to an attribute value or concept occurring in R U 8 Require that bits corresponding to values and concepts of a given attribute be consecutive with concepts having higher indexes than attribute values That is 14 


Let M  T  U he a mapping of an actual record T in R to a hinary vector v such that each attribute value and its higher level concepts in corresponding hierarchies are represented by 1 in U with all other values set to 0 Let the function attr\(b for hit b E U return the attribute Ai j E l    l to which bi was mapped to According to the consecutiveness requirement above this means that if uttr\(6i uttr\(bj i;j E 11  rn},and i  j then the indexes for all hit-pairs for the two attributes involved will exhibit the same less than relationship This property is utilised in the algorithm below Aleorithm 1 MZIS-c  Inputs An n x m bit-matrix M an m x m concept relation ship bit-matrix C rninsup E 0,1 Outputs A collection of itemsets 2 satisfying minsup 2  Uk IX I Initialise I 2 For each column t=t  2.1 Initialise support P~:=Z b,..bij6{o.iJ 3 Add I-itemaets I toz where nup./nimsnsup 4 Increment k Stop if k>l otherwise for the current k of U 4 I Initialise k-ilemret count count.:=o 4.2 Generate potential k-itemsel from existing k-i by finding next pair I  JJ  JJ so that I ad  k-2 s:-'<i and 9F-l is not in a concept rel&ship with 9f-l 4.3 For potential itemset l~j calculate support sup in U by counting the rows where all bits appearing in I are ret countk 4.4 If 3upin?mlnaup add I into z as a k-itemref and incremem 4.5 Go to Step 4 I until all potential k-itemrets are found 5 Sto if covntl o otherwise 00 to Ste 4 An extension to the Apriori algorithm in M2IS-c is the incorporation of concept hierarchy values into the mining process by including them in the hinary mapping This is desirable in cases where individual values may not have enough support to he represented in a profile hut their higher level equivalents have A consequence of this ap proach is the introduction of potential itemsets with both child and parent concepts present. Itemsets containing such pairs express trivial relationships and need to be pruned as they dilute the final rule set The removal of itemsets containing child-parent pairs is an additional feature of the modified algorithm used in the profiling process This en sures that the maximum length of any itemset produced is limited to the number of attributes 1 in the original data set Child-parent relationships can he represented by a hit matrix with ones indicating relationship and zeroes not2 As this lookup can be achieved in a single step we refer the Note that the use of memory for storage of the main bit-mauix may be problematic for large data seis OD non-spcialised systems 2A single matrix would suffice for this purpose Individual matnces for each atuibute could be preferable for memory efficiency as ones can only reader to the original article for discussion of the complex ity of the algorithm 5 4.2 Profile Analysis Algorithms The generation of profiles is only the first step in an in vestigation Algorithms for analysing the profiles need to he provided and utilised either interactively or by automated means Some of the functionality required can he described by the following list Filtering profiles This process allows investigators to reduce the profile set to concentrate on subsets that may he of higher interest It can be guided by a pre viously defined set of beliefs about the expected he haviour of the profile Rules complying with beliefs may automatically he dropped while rules in contra diction with beliefs may be assigned higher priority in the investigative process Contrasting raw darn ru profiles This produces a list or summary of data entries that deviate from the pro file It is generated for data that did not have enough support to he part of the profile, hut convey potentially unexpected information different from the profile Generating intra-profile contrasts This means finding rules in a profile that are in contradiction with other rules in the same profile These rules may indicate a shift in behaviour whose causes may need to be inves tigated To measure difference between rules a dis tance metric will he required We propose a simple profile analysis algorithm to measure the degree of anomalies in the profile elements 4.3 A Metric for Profile Element Distance One of the more interesting and complex issues in the analysis of a profile is the discovery of contradicting ele ments within the profile These contradictions may he iden tified both at the itemset level and in the final ruleset. In this paper we concentrate on contradictions in itemsets using a Manhattan distance based metric that makes differences easy to detect For example. some of the characteristics of a particular person may he repeated in several itemsets with only a single attribute value being different. This difference can he attributed to Repetition. In this case the attribute represents a value for example day of the week that indicates that the same set of characteristics is valid for multiple occa sions appear along the diagonal in m wi x m e subsets for atmibutes A,,i=l  I 15 


Generalisation The attribute value has heen replaced by the higher level concept that retains the same set of characteristics hut possibly with larger support Contradiction The attribute value is in contradiction with another potentially pre-defined as a belief For example auser may he allocated a parlicularcomputer but the profile indicates the use of a different one The recognition of the occurrences of these differences may be automated Some may be combined repetition or discarded as unimportant generalisation or trivial beliefs Others may require inspection by investigators to decide if they are worth following up. Algorithm 2 Irem$er itemxet fame describes the calculation of a metric that indicates the closeness or similarity of two k-itemsets by comparing their elements It employs the attr function defined prior to presenting Algorithm 1 and assumes that the itemsets to be compared are represented by bits from the hit-vector U format defined there Because of the consecutiveness re quirement it follows that the hits at position o in a k-itemset he in three distinct relationships 1 They may belong to different attnbutes A  A 2 They may belong to the same attribute A and he the same attribute value or concept or have a child-parent relationship 3 They may belong to the same attribute A but he dif ferent valueslconcepts with no relationship Algorithm 2 IS2IS-dist Inputs K-itemsets I  b     bi and Ij  g  q an m x m concept relationship bit-matrix C attribute function attr\(b Outputs Distance d E 0     k  11 1 Initialised  0 2 Foro  1 to k 2.1 If attr\(bp  by set d  k  1 and stop 2.2 If bp  b A b not in child-parent relationship with by increment d It can be seen that distance d of Algorithm 2 can he less than the length of the itemset k only if the same attribute valuelconcept is found duplicated \(i.e. equals or is in a con cept relationship with at least once in the two itemsets he ing compared It also follows that the total number of such duplicates found and d equals k with d  0 only if the re spective elements of the two itemsets are the same or are in a concept relationship Thus the metric is a non-negative in Figure 2 Example time slice of past and cur rent user login information as obtained by ex ecuting the UNIX last command hold nil values for attributes not originally in the itemset then comparing this itemset with the data record the same way as comparing two I-itemsets The difference between Algorithm 2 and this modified version is that d is not in cremented for attributes where the itemset holds a nil value This limits d to a maximum value of k 5 Data Experiments and Results To evaluate the profiling methodology proposed in this paper, a number of experiments have been performed Both Algorithms 1 and 2 have been implemented as well as IS2DAT-dist As input log files captured by executing the UNIX last command were used which searches the wtmp system log file and lists past and current user login informa tion for a computer An example output from executing the last command is shown in Figure 2 Note that the data used in our experiments are actual log data recorded by a UNIX-based computer set up as a server with remote login access However in order to preserve anonymity the data attribute name instances have been modified Furthermore there was no implication of inappropriate behaviour in the data set Of several columns of information generated six at tributes were copied or composed into a table containing formatted input. Some filtering was performed at this stage to remove incomplete current and non-user e.g shut down logins The table, using additional higher level con cepts from attribute hierarchies was then mined to produce a profile containing association rules. Intra-profile and data to-profile contrasting was then performed The distance metric of IS2IS-dist and IS2DAT-dist was employed to produce reports for both contrasting methods 5.1 Intra-Profile Experiments Intra-profile contrasts were calculated only for itemsets teger 2 E 0    k 11 from which only values 0 d  k    of the same length For example in one test from about 2000 original data records approximately 2200 itemsets are or interest A similar algorithm can be devised to calculate the distance hetween a k-itemset and a data record IS2DAT with than element were produced Intra-profile con dist This can he achieved by expanding the itemset trasting produced roughly 43000 distances that were less This algorithm is not presented due to its similarity to AlgonUlm 2 than the lengths of the itemsets being compared Although 16 


this is a far smaller number than what it potentially could have been it is still more than what can be perused manu ally To rcduce this set further, additional strategies need to be devised One option is to prioritise attributes That ih if difference is measured only in a particular attribute that may not be carrying imponant information \(such as day of the week then pairs exhibiting distance only in such at tributes may be dropped Similarly a strategy may be em played to drop contrasts that are too high That is the distance metric for a particular itemset length may be re garded as high even though it satisfies the initial constraint of being less than the length This may for example render all distances produced for 2-itemsets unnecessary Finally focusing techniques may be provided to filter the distances for certain attributes or attribute values One of the more interesting contrasts produced by IS2IS-dist during testing was the I-distance pair io  User  pedru A Origin  viiunli 11  User  pedro A Origin  adeluide which indicates that the same user has been logging in from two very different geographic locations Further inspection of this contrast revealed that the user in question left his place of work in Adelaide for another in Miami while still regularly accessing his old Adelaide account 5.2 Data-to-Profile Experiments The filtering requirement to reduce the set of distances to manageable proportions becomes even more evident with data-to-profile contrasts Without pre-processing each itemset needs to be compared to every data record po tentially producing a much larger result set than for intra profile contrasts This is partly due to the fact that a number of records are not included in the profile due to unsatisfac tory support Each of these records could produce small dis tances to itemsets similar to it that made it into the profile As in the case of intra-profile contrasts measures can be taken to reduce the final result set In addition to the strate gies outlined in Section 5.1 duplicate records may be re moved by post-processing the results Also data-to-protile distances may be zero if a particular data record was one of those used to generate the itemset it is being compared to These distances should also be pruned from the results Figure 3 shows some of the distances from a test calcu lated for a particular itemset of length 5 top row Non zero distances up to a maximum value of 2 were allowed in order to list contrasts where difference is present in not too many attributes Duplicates were removed and as men tioned some attributes were sanitised to remove contiden tial information from the data The itemset contains gen eralised concepts for both the User and Origin attributes while Durarion is represented by concepts categorising a Figure 3 Example data-to-profile distances from ISZDAT-dist for a sample profile element and a collection of data records, ordered by User for readability potentially large number of discrete values From the def inition of the metric valueslconcepts in the same hierar chy have a distance of zero, which explains the diversity of rows of \(non-generalised values in the data having similar distances For readability we give here some of the concept relationships from the otherwise rather large hierarchies that exist for User and Origin mar,milo,pedro stuort c lecturer cs.x?/u.edu.au 188.191.47 c cs.xyu.edu.au C zyu.edu.au c adelaide  tnt2.tow.net.au 198.twun0103.twn.net.ou C ISP.adelaide c adelaide Using this information the first data row with d  1 shows that user Clyde is not a lecturer whilst for lecturers viuz and pedru who log onto university computers we can ob serve that the same wtmp login information is valid for sev eral weekdays other than Monday Figure 3 as is contains superfluous information De pending on the support used in mining the profile some or most of the data records contribute to itemsets gener ated by the algorithm Comparing a k-itemset to data that contributes to another k-itemset is a repetition of compar ing an itemset with another Crosschecking a data record against every other k-itemset prior to calculating a distance would, however, be even less cost-effective Instead a strat egy of producing distances in a matrix form for k-itemsets k  2   1 then discarding rows with at least one zero in it would be a better solution Alternatively a separate algorithm may parse the data set to locate individual occur rences of records that do not contribute to any itemset of a given length and then run the contrasting algorithm against this filtered data set only This is indeed the requirement proposed in Section 4.2 for data-to-profile contrasting 17 


6 Conclusions and Future Directions The initial implementation of the profiling analysis pro cess described in this paper has resulted in promising results capable of identifying irregularities in computer logs that can serve as useful evidence in computer crime investiga tions Protile analysis, however forms only a pan of the in vestigative process and relies heavily on expert knowledge It is therefore best perceived as a component in a larger col lection of tools designed to aid the forensic investigator The profiling tool presented in this paper presents further opportunities for enhancement One such area is the han dling of multiple log information in a single process Multi dimensional mining may offer a solution for this problem with some interesting work already found in the literature 16 201 Alternatively it may be possible to 223flatten\224 sev eral logs into a sequence of 223events\224 for which more tradi tional sequential mining techniques can be applied Further improvements may be achieved by replacing the mining 81 gorithm used in protiling One obvious candidate is the attribute-oriented induction technique  141 This technique compacts a collection of records into a generalised relation or a conjunction of generalised records where individual at tribute values are replaced by higher level concepts by as cending concept hierarchies One of the advantages of this technique is that the final rule set incorporates information about every record in the original data set Further work is also to be carried out in the intelligent presentation of results notably in the provision of appropriate visual inter pretation of the profiles and its potential contrasts. Contrast measures currently used are itemset-specific Deriving dis tance measures for rules such as the value distance metric VDM 221 may yield better results in identifying discrep ancies Some of the better known data mining interesting ness measures 12 or variations of may also be adopted for this purpose References I G Adomavicius and A Tuzhilin Expert-driven valida tion of rule-based user models in personalization applica tions Data Mining and Knowledge Discovery 5\(1/2 58,2001 121 G Adomavicius and A Tuzhilin Using data mining meth ads to build customer profiles Computer 34\(2 2001 3 C Aggamal Z Sun and P Yu Online algorithms for find ing profile association rules In Proceedings of the ACM Internatinno1 Conference on Informorion and nowledge Management CIKM-98 Bethesda MD USA 1998  R Agrawal T Imielinski and A Swami Mining associ ations between sets of items in massive databases In Pro ceedings ofthe ACM SIGMOD hi Conference on Manage ment ofDara Washington, DC USA May 1993 SI R Agrawal H Mannila R Srikant H Toivonen and A Verkamo Advances in Knowledge Discovery and Data Mining chanter Fast discoverv of association rules AAA1 224 Press 1996 161 E Casev Dipifal Evidence and Computer Crime Academic  Press 2w0.\221 171 P K Chan A non-invasive learninx amroach to building   224 web user profiles In Proceedings of the Workshop on Web Usage Analysis and User Profiling WEBKDD\22299 1999 8 0 de Vel A Anderson M Corney and G Mohay Mining e-mail content for author identification forensics SIGMOD Record 30\(4 2001 191 M Ester H.-P Krieeel J Sander and X Xu A densitv  based algorithm for discovering clustc~s in large spatial databases with noise In Proceedings of the Second Ini Con ference on Knowledge Discovery ond Dam Mining 1996 IO T Fawcett and F Provost Adaptive fraud detection Data Mining and Knowledge Discovery 1\(3 1997 1111 J Han and Y Fu Discovery of multiple-level assmiation rules from large databases In Proceedings of2lst VLDB Conference September 1995 I21 R 1 Hilderman and H I Hamilton Knowledge discovery and interestingness measures A survey Technical Repon CS-99-04 Dept of Computer Science University of Regina 1999 I31 M Hirsh, C Basu. and B Davidson Learning to personal ize Communicarions ofthe ACM 43\(8 2ooO I41 H 1 Y Cai and N Cercone Knowledge discovery in databases an attribute-oriented approach In Proceedings ofl8th hr Conference on Very Large Databases 1992 I51 1 Konstan B Miller D Malte J Herlocker L Gordon and 1 Riedl Grouplens Applying collaborative filtering to usenet news Communications ofthe ACM 40\(3 1997 Beyond intra-transaction assmiation analysis mining multi-dimensional inter transaction rules ACM Transactions on Information Sw I61 H Lu L Feng and J Han terns 18\(4 2000 1171 B Mobasher H Dai T Luo Y Sun and J Wiltshire  Discovery of aggregate usage profiles for web personaliz tion In Proceedings ofthe Workhop on Web Mining for E-Commerce WEBKDD\222OO August 2000 IS A Nanopoulos D Katsaros and Y Manolapoulos Ef fective prediction of web-user accesses a data mining ap proach In Proceedings of the Workshop on Mining Logdata Accross All Customer Touchpoints WEBKDD\222OI 2001 I91 S Nesbitt and 0 de Vel A collaborative filtering agent system for dynamic virtual communities on the web In Proceedings of the Conference on Learninp and Discoven CONALD98 June 1998 1201 T Oates and P R Cohen Searchine for structure in multiole I streams of data In Proceedings of the Thirteenth Interno rional Conference on Machine Learning 1996 ZI R Srikant and R Agrawal Mining generalized assmiation rules In Proceedings ofZlsr VLDB Conference 1995 221 C Stanfill and D Waltz Toward memory-based reasoning Communications of the ACM 29\(12 1986 23 P N Tan and V Kumar Mining indirect assmiations in web data In Proceedings oflhe Workshop on Mining Logdata Accross All Customer Touchpoints WEBKDD\222OI 2001 18 


Category Manual Automatic No of associations 63 30 No of rules 330 44 Max association size 6 4 Avg support 0.45 0.43 Avg rule con\256dence 0.80 0.82 Table 1 Manual versus automatic image content mining 4.2 Quality of results We should mention that there were no false association rules It did not happen that an object was incorrectly identi\256ed and then a rule was generated with the incorrect identi\256er In general when we found a match between two objects they were the same shape All the incorrect matches are 256ltered out by the support parameter and then the association rules are generated for objects correctly ideinti\256ed Also some redundant matches happened b ecause of the blobs that represented several shapes but these matches are 256ltered out by the rule support In Table 1 we present a summary of our experimental results with 100 hundred images We compare the results obtained by manually identifying objects in each image and then generating association rules from such identi\256ers Manual Column against the results obtained by our current implementation Automatic Column Ideally our image mining algorithm should produce the same results as the manual process So the table gives a standpoint to assess the quality of our experimental results For these 100 images unwanted matches either incorrect or involving many objects happened in at most 4 images and therefore their support was well below the minimum support frequency which was at 30 These experiments were run using the same parameters for object identi\256cation as in our small example with 10 images The parameters for object identi\256cation had the following values We set color standard deviation to 0.5 contrast standard deviation to 0.5 and anisotropy also to 0.5 The similarity threshold as needed by the similarity function was set to 0.6 We tuned these parameters after several experiments These parameters maximized the number of associations and decreased the errors in unwanted matches The association rule program was set to look for rules with a 30 support and 70 con\256dence The background represents an object itself Since association rules with the background were not interesting for our purposes it was eliminated from consideration by the object identi\256cation step It is important to note that this is done after objects have been identi\256ed We tuned the object identi\256cation step to 256nd similar objects changing values for several parameters in the following manner The most important features used from each object were color and contrast We allowed some variance for color 0.5 and the maximum allowed variance for contrast 0.5 The anisotropy helped eliminate matches involving several geometric shapes We ignored shape b ecause objects could be partially hidden and rotated Position was considered unimportant because objects could be anywhere in each image Anisotropy and polarity were i gnored because almost all our shapes had uniform texture Area was given no weight because objects could be overlapping and thus their area diminished this can be useful to make perfect matches when objects are apart from each other A few rules had high support One problem that arose during our experiments was that the same shape could have two different blob descriptors and these blob descriptors could not be matched with two other descriptors for the same shape in another image This caused two problems First a rule could be repeated because it related the same shapes Second a rule did not have enough support and/or con\256dence and therefore was discarded So the rules found were correct and in many cases had an actual higher support and also higher con\256dence To our surprise in some cases there were no object matches because an object was very close to another one or was located in a corner of the image When two or more objects were overlapping or very close they were identi\256ed as a single object This changed the features stored in the blob The problem was due to the ellipsoidal shape of the blobs and the fact that when a geometric shape was located in a corner thta changed its anysotropy and polarity descriptors Given a blob for an object very close to one corner means determining an adequate radius for the blob i.e ellipse Regular shapes such as the triangle square and hexagon were easily matched across images This is a direct consequence of the circular blob representation produced when the image is segmented In this case neither position nor rotation affect the mining process at all It was surprising that in some cases there were no matches for the circle in these cases it was in a corner or some other shape was very close or overlapping Another important aspect about shape is that we do not use it as a parameter to mine images but shape plays an important role during the segmentation step So shape does affect the image mining results quality The rectangle and the ellipse are the next shapes that are easily matched even though we did not use the shape feature The most complicated shape was the L In this case a number of factors affected matches When this shape was overlapped with other shapes a few matches were found b ecause a big blob was generated Also orientation changed dominant 


ofimages 50 100 150 200 1 feature 50292 80777 127038 185080 2 obj identif 210 338 547 856 3 aux image 3847 6911 10756 13732 4 assoc rules 6 3 6 4 Table 2 Measured times in seconds for each Image Mining step with different image set sizes colors and contrast When the L was close to another shape its colors were merged making it dissimilar to other L shaped objects This suggests that irregular shapes in general make image mining dif\256cult We worked with color images but it is also possible to use black and white images Color and texture were important in mining the geometric shapes we created However we ignored shape as mentioned above Shape may be more important for black and white images but more accurate shape descriptors are needed than those provided by the blobs 4.3 Performance evaluation We ran our experiments on a Sun Multiprocessor forge.cc.gatech.edu computer with 4 processors each running at 100 MHz and 128 MB of RAM The image mining program was written in Matlab and C The 256rst three steps are performed in Matlab The feature extraction process is done in Matlab by the software we obtained from UCB Object identi\256cation and record creation were also done in Matlab by a program developed by us An html page is created in Matlab to interpret results The association rules were obtained by a program written in C In this section we examine the performance of the various components of the image mining process as shown in Table 2 for several image set sizes These times were obtained by averaging the ellapsed times of executing the image mining program 256ve times 4.4 Running time analysis Feature extraction although linear in the number of images is slow and there are several reasons for this If image size increases performance should degrade considerably since feature extraction is quadratic in image size Nevertheless this step is done only once and does not have to be repeated to run the image mining algorithm several times Object identi\256cation is fast This is because the algorithm only compares unmatched objects and the number of objects per image is bounded For our experimental results time for this step scales up well Auxiliary image creation is relatively slow but its time grows linearly since it is done on a per image basis The time it takes to 256nd rules is the lowest among all steps If the image mining program is run several times over the same image set only the times for the second and the fourth step should be considered since image features already exist and auxiliary images have already been created 5 Application Image mining could have an application with real images The current implementation could be used with a set of images having the following characteristics 017 Homogeneous The images should have the same type of image content For instance the program can give useless results if some images are landscapes other images contain only people and the remaining images have only cars 017 Simple image content If the images are complex they will produce blobs dif\256cult to match Also the association rules obtained will be harder to interpret A high number of colors blurred boundaries between objects large number of objects signi\256cant difference in object size make the image mining process more prone to errors 017 A few objects per image If the number of objects per image is greater than 10 then our current implementation would not give accurate results since Blobworld in most cases generates at most 12 blobs per image 017 New information The image itself should should give information not already known If all the information about the image is contained in associated alphanumeric data then that data could be mined directly 6 Future Work Results obtained so far look promising but we need to improve several aspects in our research effort We are currently working on the following tasks We also need to analyze images with repeated geometric shapes If we want to obtain simple association rules this can make our program more general This can be done without further modi\256cation to what is working However if we want to mine for more speci\256c rules then we would need to modify our algorithm For instance we could try to 


produce rules like the following if there are two rectangles and one square then we are likely to 256nd three triangles The issues are the combinatorial growth of all the possibilities to mine and also a more complex type of condition We will also study more deeply the problem of mining images with more complex shapes such as the irregular one similar to the letter L We need a systematic approach to determine an optimal similarity threshold or at least a close one A very high threshold means only perfect matches are accepted On the other hand a very low similarity threshold may mean any object is similar to any other object Finding the right similarity threshold for each image type l ooks like an interesting problem Right now it is provided by the user but it can be changed to be tuned by the algorithm itself Also there are many ways to tune the eleven parameters to match blobs and the optimal tuning may be speci\256c to image type There also exists the possibility of using other segmentation algorithms that could perform faster or better feature extraction It is important to note that these algorithms should give a means to compare segmented regions and provide suitable parameters to perform object matching in order to be useful for image mining From our experimental results it is clear that this step is a bottleneck for the overall performance of image mining We can change the object identi\256cation algorithms to generate overlapping object associations using more features Our algorithm currently generates partititons of objects that is if one object is considered similar To another one the latter one will not be compared again By generating overlapping associations we can 256nd even more rules For instance a red rectangular object may be considered similar to another rectangular object and at the same time be similar to another red object Mining by position is also possible for instance two objects in a certain position may imply another object to be in some other position Since the software we are using for feature extraction produces eleven parameters to describe blobs we have 2 11 possibilites to match objects 7 Conclusions We presented a new algorithm to perform data mining on images and an initial experimental and performance study The positive points about our algorithm to 256nd association rules in images and its implementation include the following It does not use domain knowledge it is reasonably fast it does not produce meaningless or false rules it is automated for the most part The negative points include some valid rules are discarded because of low s upport there are repeated rules because of different object id's unwanted matches because of blobs representing several objects slow feature extraction step a careful tuning of several parameters is needed it does not work well with complex images We studied this problem in the context of data mining for databases Our image mining algorithm has 4 major steps feature extraction object identi\256cation auxiliary image creation and identi\256ed object mining The slowest part of image mining is the feature extraction step which is really a part of the process of storing images in a CBIR system and is done only once The next slowest operation is creating the auxiliary blob images which is also done once Object identi\256cation and association rule 256nding are fairly fast and scale up well with image set size We also presented several improvements to our initial approach of image mining Our experimental results are promising and show some potential for future study Rules referring to speci\256c objects are obtained regardless of object position object orientation and even object shape when one object is partially hidden Image mining is feasible to obtain simple rules from not complex images with a few simple objects Nevertheless it requires human intervention and some domain knowledge to obtain better results Images contain a great deal of information and thus the amount of knowledge that we can extract from them is enormous This work is an attempt to combine association rules with automatically identi\256ed objects obtained from a matching process on segmented images Although our experimental results are far from perfect we show that it is better to discover some reliable knowledge automatically than not discovering any new knowledge at all Acknowledgments We thank Chad Carson from the University of California at Berkeley for helping us setup the Blobworld system We also thank Sham Navathe and Norberto Ezquerra for their comments to improve the presentation of this paper References 1 R  A g r a w a l  T  I m i e lin s k i a n d A  S w a m i  M in in g a s s o ciation rules between sets of items in large databases In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data  pages 207\261 216 Washington DC May 26-28 1993  R  A gra w a l a n d R  S ri ka nt  F a s t a l gori t h m s for m i n i n g association rules in large databases In Proceedings of the 20th International Conference on Very Large Data Bases  Santiago Chile August 29-September 1 1994  S  B e l ongi e  C Ca rs on H  G r e e n s p a n  a nd J  Ma lik Recognition of images in large databases using a learning framework Technical Report TR 97-939 U.C Berkeley CS Division 1997 


 C  C a r s on S  Be l ongi e  H  G r e e n s p a n  a nd J  Ma l i k  Region-based image querying In IEEE Workshop on Content-Based Access of Image and Video Libraries  1997 5 G  D u n n a n d B  S  E v e r itt An Introduction to Mathematical Taxonomy  Cambridge University Press New York 1982  U  F a yya d  D  H a u s s l e r  a nd P  S t orol t z  M i n i n g s c i e n ti\256c data Communications of the ACM  39\(11\51\26157 November 1996  U  F a yya d G  P i a t e t s k y-S h a p i r o a n d P  S m y t h  T he kdd process for extracting useful knowledge from volumes of data Communications of the ACM  39\(11\:27\261 34 November 1996 8 D  F o r s y t h J M a l i k  M F l e c k H G r e e n s p a n  T L e ung S Belongie C Carson and C Bregler Finding pictures of objects in large collections of images Technical report U.C Berkeley CS Division 1997  W  J  F ra wl e y  G  P i a t e t s k y S ha pi ro a nd C J  Ma t h e u s  Knowledge Discovery in Databases  chapter Knowledge Discovery in Databases An Overview pages 1 261 27 MIT Press 1991  V  G udi v a da a n d V  R a gha v a n Cont e n t ba s e d i m age retrieval systems IEEE Computer  28\(9\18\26122 September 1995 11 R  H a n s o n  J  S t u t z an d P  C h ees eman  B ay es i a n c l a s si\256cation theory Technical Report FIA-90-12-7-01 Arti\256cial Intelligence Research Branch NASA Ames Research Center Moffet Field CA 94035 1990  M H o l s he i m e r a n d A  S i e be s  D a t a m i ni ng T h e search for knowledge in databases Technical Report CS-R9406 CWI Amsterdam The Netherlands 1993  M H out s m a a nd A  S w a m i  S e t ori e nt e d m i ni ng of association rules Technical Report RJ 9567 IBM October 1993  C O r done z a nd E  O m i e c i ns ki  I m a ge m i ni ng A new approach for data mining Technical Report GITCC-98-12 Georgia Institute of Technology College of Computing 1998  J  R Q u i n l a n Induc t i o n o f d e c i s i on t r e e s  Machine Learning  1\(1\81\261106 1986  A  S a v a s e re  E  O m i e c i ns ki  a nd S  N a v a t h e  A n e f 256 cient algorithm for mining association rules In Proceedings of the VLDB Conference  pages 432 261 444 Zurich Switzerland September 1995  O  R Z a i a ne  J  H a n  Z  N  L i  J  Y  Chi a ng a n d S Chee Multimedia-miner A system prototype for multimedia data mining In Proc 1998 ACM-SIGMOD Conf on Management of Data  June 1998 


Database 1 proc 2 procs 4 procs 8 procs T5.I2.D100K 20 17 12 10 T10.I4.D100K 96 70 51 39 T15.I4.D100K 236 168 111 78 T20.I6.D100K 513 360 238 166 T10.I6.D400K 372 261 165 105 T10.I6.D800K 637 435 267 163 T10.I6.D1600K 1272 860 529 307 Table 3 Naive Parallelization of Apriori seconds   0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2    0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD : With Reading Time Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2  Figure 4 CCPD Speed-up a without reading time b with reading time 13 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


Reading  f Total Time Database Time P 000 1 P 000 2 P 000 4 P 000 8 P 000 12 T5.I2.D100K 9.1s 39.9 43.8 52.6 56.8 59.0 T10.I4.D100K 13.7s 15.6 22.2 29.3 36.6 39.8 T15.I4.D100K 18.9s 8.9 14.0 21.6 29.2 32.8 T20.I6.D100K 24.1s 4.9 8.1 12.8 18.6 22.4 T10.I6.D400K 55.2s 16.8 24.7 36.4 48.0 53.8 T10.I6.D800K 109.0s 19.0 29.8 43.0 56.0 62.9 T10.I6.D1600K 222.0s 19.4 28.6 44.9 59.4 66.4 Table 4 Database Reading Time in section 4 320 computation balancing hash tree balancing and short-circuited subset checking The 336gure on the left presents the speed-up without taking the initial database reading time into account We observe that as the number of transactions increase we get increasing speed-up with a speed-up of more than 8 n 2 processors for the largest database T10.I6.D1600K with 1.6 million transactions r if we were to account for the database reading time then we get speed-up of only 4 n 2 processors The lack of linear speedup can be attributed to false and true sharing for the heap nodes when updating the subset counts and to some extent during the heap generation phase Furthermore since variable length transactions are allowed and the data is distributed along transaction boundaries the workload is not be uniformly balanced Other factors like s contention and i/o contention further reduce the speedup Table 4 shows the total time spent reading the database and the percentage of total time this constitutes on different number of processors The results indicate that on 12 processors up to 60 of the time can be spent just on I/O This suggest a great need for parallel I/O techniques for effective parallelization of data mining applications since by its very nature data mining algorithms must operate on large amounts of data 5.3 Computation and Hash Tree Balancing Figure 5 shows the improvement in the performance obtained by applying the computation balancing optimization discussed in section 3.1.2 and the hash tree balancing optimization described in section 4.1 The 336gure shows the  improvement r a run on the same number of processors without any optimizations see Table 3 Results are presented for different databases and on different number of processors We 336rst consider only the computation balancing optimization COMP using the multiple equivalence classes algorithm As expected this doesn\325t improve the execution time for the uni-processor case as there is nothing to balance r it is very effective on multiple processors We get an improvement of around 20 on 8 processors The second column for all processors shows the bene\336t of just balancing the hash tree TREE using our bitonic hashing the unoptimized version uses the simple mod d hash function Hash tree balancing by itself is an extremely effective optimization It s the performance by about 30 n n uni-processors On smaller databases and 8 processors r t s not as 14 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



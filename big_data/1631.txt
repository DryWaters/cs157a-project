Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 MINING ASSOCIATION RULE ORIENTED DATA CUBE AND ITS APPLICATION HONG SM ZHANG ZHENG\224 221\224Dept of Computer Science and Engineering, Taiyuan Heavy Machinery Institute, Taiyuan 030024 224School of Electromechanical Engineering, Beijing Institute of Technology; Beijing 10008 1 E-MAIL shh5 1 sina.com Abstract The data warehouses oriented data mining 
is one of the hot studies in data mining field which can improve the mining efficiency and simplify the mining process At present some effective platforms for mining have been proposed yet those are versatility and do not aim at the characteristic of particular mining task and thns restrict the mining efficiency To the question of mining association rules we presents a model of mining association rule oriented data cube through 
analyzing the character of mining association rule and OLAP in this paper The model has been proved correctly and feasibly by analyzing the application example Keywords Association rule OLAP; Data cubes 1 Introduction One of the emphasis in data mining field is the integration of OLAP with data mining resently which is to process data mining based on OLAPR 222 3 221I OLAP is a on-line analytical processing tool provided by data warehouses for the interactive analysis of multidimensional 
data of varied granularities[\222 and it processes all kinds of analysis operations based on the data stored in data warehouses according to the users\222 question and hypothesis and returns the analytical result back to users in intuitionistic and comprehensible form. Its definition can be generalized as Fast Analysis of Shared Multidimensional Information for short FASMIL3 Data mining is the process to extract useful and implicit information or knowledge which can be expressed as a concept a rule a pattern etc from a large amount of original data and returned the result using visual tools Its prominent character is the automatization of analysis process and 
the discovery of implicit knowledge Two models OLAM on-line analytical mining and influence fieldf6\222 and several platforms for the integration of OLAP with data mining have been proposed. There are two main platforms in them DBMiner17\222 which is developed by Data Mining Research Group led by Jiawei Han based on OLAP and MSMiner\224\222 which is developed by Institute of Computing Technology, Chinese Academy of Sciences DBMiner integrates data mining technologies such as association rules classification prediction and clustering with OLAP for mining amounts of data and outputs the result visually. MSMiner describes data sources, algorithms and steps 
of mining and the meta data of users with object oriented technology, integrates these mining technologies the decision tree, association rules cluster analysis, neural network, and can add mining algorithms dynamically, then it has preferable expansibility and generalization. There are some other similar platforms such as SAS Company\222s SAS Enterprise Miner, IBM\222s Intelligent Miner and Solution\222s Clementine[\222o1 Owing to using various mining technologies, the above models conceal the chitacter of respective mining technology and thus affect the mining efficiency. DBMiner proposes the interactive mining methodc5\222, which makes too much users\222 interference then restricts the mining process and provides the data cubes by users which cannot better embody the particular need of particular mining task and 
result in the lower efficiency This motivates us to present a special mining method having less artificial factors based on OLAP We presents the model of mining association rule oriented data cube to the question of mining association rule based on the integration of OLAP with data mining in this paper and it has proved correctly and feasibly by analyzing the application example 2 Question analysis The function of OLAP and data mining is different OLAP is a data summarization tool and helpful to simplifying the data analysis[\224, while the almost analysis is interactive, having too much interference of users, then the users\222 subjective restriction is taken 
into analysis and affects the final conclusion; Data mining can automatically find out the implicit knowledge in a large amount of data[\222 Then it is a process of no teaching which cari result in the problem of blind searching and lower usefulness of result in the condition of huge data amounts. Besides data mining covers both data description and data modeling and not only can analyze the existing data in a data warehouse, but also can analyze the data at more detailed granularities than the summarized data provided in a data warehouse and transactional, spatial, textual, and multimedia data that are 0-7803-7508-4/02/$17.00 02002 IEEE 705 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 difficult to model with current multidimensional database technology[21 The above shows that OLAP may discover the superficiality, but data mining can find out the deepness Data mining and OLAP both can be used in the decision support system, and they are both analysis tools and have some relationship between them OLAP is a tool provided by data warehouses, whose construction is a process of data integration data cleaning and data and the operations provided by OLAP, such as roll-up, drill-down slice and dice etc, can choose the interesting data for users to deal with The data preprocessing of data mining also needs to do data integration data cleaning and data collection, and needs to choose special data to process data mining owing to users\222 different interests The ab,ove shows that data mining can acquire the knowledge deeply and can be good used for decision support but it has complicate data preprocessing while OLAP can afford ready data and some functions such as roH-up drill-down etc but it only can gain the superficial knowledge Then if integrating them together we should process data mining more efficiently for decision support 3 Constructing model of mining association rule oriented data cube 3.1 Datacube The multidimensional data model of OLAP views in the form of a data cube. The data cube which allows data to be modeled and viewed in multiple dimensions is defined by dimensions and facts: dimension is the angle with respect to which an organization wants to keep records for example we want to create a 221sales\222 data warehouse to keep records of a supermarket sales with respect to the transaction item transaction time and so on, then according to the definition we should create the dimensions such as item, time and so on in the data warehouse. Each dimension may have a table associated with it called a dimension table which further describes the attribute of dimension A multidimensional data model is typically organized around a central theme which is represented by a fact table Facts are numerical measures. Think them as the quantities by which we want to analyze relationships between dimensions; examples of facts for a sales data warehouse include sales amount in money number of units sold The fact table contains the names of the facts or measures, as well as the keys to each of the related dimension tables[\222 3.2 Constructing data cube model 3.2.1 Constructing abstract model for mining association rule The integration of OLAP with mining association rule is based on OLAP and data warehouse, its character is to use the multidimensional data model which is existed as data cube in OLAP[21 To process data mining based on OLAP we should think about how to use data cube for mining Since data mining is to discover the implicit and useful knowledge, we can get the requirements of data mining 1 the database storing amounts of data which is the data source of mining 2 the environment and form of storing data which is the result of data cleaning, should be useful for data mining 3 the data mining technology matching with the environment of data, which is the essential of data mining is the most important part The construction of mining association rule oriented data cube is to satisfy the former two conditions integrating the character of mining association rule, that is, to arrange and store the transaction data in a suitable form and environment which is data cube in this paper How to arrange and store is suitable The first, mining association rule is to deal with the data in transaction database which reflects the itemsets contained in every transaction for mining association rule that is the data should be set as measure and then the table stored the corresponding data can be indicated as the fact table The second is to confirm the dimensions environment for the existing of the fact table. Considering the process of mining association rule, the environment should contain the keys of item and transaction at least. Only integrating them together we can accurately reflect the items of each transaction and the transaction related to each item, from which we need to construct the dimensions of item and transaction. The item dimension should embody the items contained in transaction and the relationships among their levels then according to it to construct corresponding dimension table The transaction dimension is used for distinguishing the different transaction mainly then only the corresponding key is given in the dimension table The above is the basic configuration of dimensions When need to mining association rule from other angles, such as the customer we may add relatively dimension and expand the model easily The basic abstract model is constructed as follows figure 1 Since the fact table being constituted by the keys of all dimension tables and measures the fact table and dimensions have some relationship, then we should modify fact table after confirmation of the dimensions the first is to add or modify the keys of all dimensions into the fact table to construct the relationship between the fact table and dimensions The second is to ascertain the measures to express the information with respect to in the model which should be the corresponding relationship between transaction dimension and item dimension at least For example if having 221b\222 item in 221a\222 transaction, the value of its corresponding measure can be expressed by logicals 221l\222 in contrast if not 221b\222 in 221a\222 the values of measure is 2210\222 Except for the logicals the value of measure can also be expressed by the measure\222 of number of units sold examples if having n 221b\222 items in 221a\222 transaction, the value of measure can be expressed by 221n\222 that is not 221O\222 then the measure being used for expressing the mining association rule can be set as the number of units sold 706 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 To summarize from the above we point out the conditions of mining association rule oriented data cube and construct the abstract model of mining association rule oriented data cube In order to complete the model we should confirm dimension tables 3.2.2 Constructing dimension tables of model The most popular data model for data warehouse contains dimension table and fact table.. Dimension table reflects the content contained in each dimension, especially the concept hierarchy contained in some dimensions How to express the hierarchy It is reflected through the dimension table dimension Item dimension Fig 1 The abstract model of mining association rule oriented data cube According to the demand of structure data model for data warehouse may exist in form of a star schema a snow schema or a fact constellation schema Star schema is the most common model, whose character is that it includes a fact table having a large amount of data and some redundancy and a group of dimension tables in which each dimension is represented by only one table and each table contains a set of attributes with the dimension tables displayed in a radial pattern around the fact table The snowflake schema is a variant of the star schema model, the major difference between the snowflake model and star schema model is that the dimension tables of the snowflake model may be kept in normalized form to reduce redundancies Such a table is easy to maintain and saves storage space. However, this saving of space is negligible in comparison to the typical magnitude of the fact table Furthermore the snowflake structure can reduce the effectiveness of browsing since more joins will be needed to execute a query. Consequently the system performance may be adversely impacted; Fact constellation schema may require multiple fact tables to share dimension tables Owing to being one fact table in this study we choose a star schema or a snow schema Moreover one of the key for mining association rule is efficiency which is the main principle we choice between the two models A snow schema needs more joins to execute a query and to process the operation of drill down or roll up among different levels during mining association rule which may impact the system performance. Choosing the data redundancy for the efficiency, we use the star schema for the model Then the model is as follows Transaction key Lowest item key Unit price Number of unit Profit I Fact table  Other dimension 7 Transaction key Transaction dimension Tag all levels from 0 to n Lowest item key Lowest item name 1-st concept hierarchy 1-st concept hierarchy name 2-nd concept hierarchy key 2-nd concept hierarchy name N-th concept hierarchy key N-th concept hierarchy name unit key  Item dimension Fig.2 The model of mining association rule oriented data cube 3.2.3 Mining numerical association rule The above model is aiming at the boolean association rule which shows the relationships among discrete objects but how can we do for the numerical association rule which views the association that involves numerical attributes The algorithm of mining association rule can not deal with this numerical data directly and should be discretized dynamically I There are several different methods to process discretized: the one method is to part the ranges of quantitative attributes into intervals which are dynamic in that they may later be further combined during the mining process; The second one is to part the ranges of quantitative attributes into intervals with same or different width Another one is the dynamic mining distance-based association and so on. How to dispose the data after discreteness? There are two methods can be thought about The first: put the data into the corresponding dimension and setup the values of sets as the next concept hierarchy If there was not the corresponding dimension we add it and setup the values of sets being the values of dimension then the number of dimensions may be more. For example we think about the influence of the customers age to the trend of purchase, first part the ranges of age into intervals, and put them in customer dimension owing to being the attributes of customer At the same theory the annual salary should be put in the customer dimension too The second: Put the data into item dimension We need to part the same attribute data into different sets in the different mining task then it is not easy to match the different sets with the static value of dimension. And the more dimensions are, the lower efficiency is Then we think 707 


Proceedings of the First International Conference on Machtne Learning and Cybernetics Beijing 4-5 November 2002 708 about decreasing the number of dimensions We can put a numerical attribute into one dimension-item dimension as an item and set its partition as the next concept hierarchy Such as the examples in the first the age, the annual salary should be put in the item dimension We choose the second method considering the efficiency 33 Model analysis The above describes the construction of data cube\222s model for mining association rule what characteristics has the model The first maneuverability In the model we can mine association rule only by using two dimensions whose tables can be acquired easily The transaction dimension table only needs to contain the transaction key by which can construct the relationship between the transaction dimension and the fact table The item dimension table includes all the items involved in the transaction and the hierarchy relationships among them And the tables is existed generally and acquired easily by regulating simply according to need The second expansibility It has two meanings The first is the easy expansion of model We only need to add a dimension or even add the relative attribute as an item into the item dimension when adding respect to some angle. By this way, we can realize the expansion of model simply and improve the efficiency of mining The second is the expansion of data We can use the different incremental updating process for data afforded directly by OLAP to realize the data expansion The third Enhancing the efficiency. The first method is the using of aggregation: We can set a proper aggregation for measure in data cube, and the aggregation can be set as count max, min etc In this paper, the model of data cube is for mining association rule and the value of measure expresses whether the items respected to is in each transaction From which we can set the aggregation as the function of count to embody the number of item contained in each transaction and construct the index to the aggregation to decrease the number of comparisons and then advance the efficiency. For example if we need to count the k-itemsets then the transaction whose item number that is aggregation is less than k can not be thought to increase the count of the k-itemsets which reduces the number of comparison greatly and advances the efficiency largely The second method to increase the efficiency is the operation of OLAP for example the operation roll up drill down can be used for mining the multilevel association rule and slice, lice can be used in the updating of mining association rule j 4 Application instance In this part we analyze the application example of some supermarket to construct the model for mining association rule and decision support The analysis is as follows The first is to ascertain the decisive analytical  requirements. The objective of mining association rule in supermarket is to arrange the commodity to analyze the market to increase the number of sold, and to increase the profit etc The second is to confirm the facts Since all the mining process depends on the sales of commodities, the data of sales in the database can be facts The third is to ascertain all the dimensions related with decision support In this instance, corresponding to the item dimension in model is the commodity dimension then we construct the commodity dimension and the transaction dimension first Besides the two dimensions we construct several other dimensions the customer dimension to reflect the character of customer, such as different ranges of ages salaries which influence their purchase; the time dimension the time character, such as season and festival has great effect on the customers\222 purchase and the sales promotion dimension the area dimension etc The fourth is to construct the dimension table relative to all the dimensions The commodity dimension has different concept hierarchies which are helpful to the operation of OLAP and decision-makers to confirm the fields who respect to In the instance The commodities are parted into three levels The first level is 20 sets of wares and the second level is the 228 kinds and the third is the 15169 commodities. Then we fix on the other dimension tables at the same theory The final model is as follows figure 3 The fifth is to modify the fact table after confirming all the dimension tables which contains the adding of all dimension tables\222 key and confirms the measures that may be used and cannot be less than one In the distance, we set the number of units sold as a measure owing to the above Thinking about the expansion of the model we may add the unit price and profit etc. as measures too At last we confirm the aggregation according to the above According to the analysis, the model has been creteded by SQL Server 2000 in which, Enterprise Manager affords the database and Analysis Services constructs the data cube and OLAP tests and proves that the model is correct and feasible 5 Conclusions The integration of OLAF\222 with data mining is one of the hotspots in the field but almost the studies think about the integration from the angle of general data mining which conceals the character of respective mining task and affects the mining efficiency. Pointing to the condition this paper studies the integration of OLAP with data mining from the angle of respective mining task-mining association rule\222s character and presents the model of mining association rule oriented data cube. This paper not only thinks about the Boolean association rule but also the numerical association rule and presents the proper using aggregation of OLAP to improve the efficiency by the experience from relative 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 Transaction key Commodity key Customer key Date databases oriented mining association rule The construction process of the model has been analysed by the application example clearly and then the model has been proved correctly and feasibly Commodity key Kind key Sales promotion key Commodity name Sales promotion dimension Kind name References l Wang Hong Wang Aimin The research based on the unified modeling technology of OLAP and DM Computer engineering and application: 2002\(2 166 167 2 J Han M Kambr Data Mining concepts and Techniques Morgan Ka'ufmann Publishers, 2000 3 Nigel Pendse What is OLAP http://www olapreport.com/fasmi.htm 4 M Kamber J Han J Y Chiang Metarule-guided mining of multidimensional association rules using data cubes In Proc 3rd Int Conf Knowledge Discovery and Data Mining KDD97 Newport Beach, California, August 1997 207--210 5 M Kamber J Han J Y Chiang. Using data cubes for metarule-guided mining of multi-dimensional association rules. Tech rep Simon Fraser University Database Systems Research Laboratory, 1997 Shi lei The research and development of unified framework for OLAP and dat mining Computer science, 2000,27\(5\45-49 7 J Han OLAP mining An integration of OLAP with data mining In Proceedings of the 7th IFIP 2.6 Working Conference on Database Semantics \(DS-7 6 1997,l--9 8 http://www.dbminer.com/products/index.html 9 You Xiangyong General multi-strategy data mining tool-MSMiner Journal of computer research  development, 2001,38 2  581-586  101 Shi Zhongzhi 2002 Knowledge discovery Beijing The publishing of tsinghua I Shopping key k Sales promotion key 1  Unit price Unit sold Profit  I Customer Profession Earning Week Season Fact table I Customer dimension ion Shopping key Shopping name City code City name Area key Area name Area dimension Set key Set name Unit 1 Commodity dimension 1 Transaction key Transaction dimension Fig.3 The model of application example 709 


2.718 If there are no analogies i=O analogies the performance will be purely statistical In this case, the output will reduce to the one of the SRN which is reflected on the upper right hand side of the equation If there are analogies all the analogies are added \(lower right hand side of equation and divided by the total number of analogies plus 1 which reflects the purely statistical prediction IV CONCLUSIONS It was postulated that the underlying processes of human sequence learning in this task seem to be fuzzy to at least some extent Many times an interaction is found between purely statistical and partly rule-based processes As demonstrated in other papers I ZO the rules that help to generalize to novel sequences with the same underlying structure are induced by making analogies to the rules in the trained sequences if some thresholds of rule-awareness have been passed e.g in less numerous sequences whilst the performance remains statistical if none of the thresholds of rule-awareness have been passed Our model presents one possible way to simulate these results including the gradual and often partial acquisition of rules It briefly sketches how these tules could interact with a purely statistical neural network Although other ways to integrate fuzzy logic and neural networks exist this model shows that fuzzy representations give rise to an interesting phenomenon in partly statisticalhle-based human sequence learning References 111 Spiegel R and McLaren I.P.L Human Sequence Learning Can Associations Exolain EvcMhine  Proceedines of the 23   I Annual Conference of the Cognitive Science Society pp 976 981, Edinburgh, August 14,2001 Mitchell, T.M., Machinc Learning, McGraw-Hill, 1997 Lebiere C and D Wallach Seouence Leamine in the ACT-R 121 131 141 Sun R and C.L Giles Sequence Learning Paradigms Algorithms, and Applications, Springer 2001 SI S Pinker Out of the Minds of Babes Science  Vol 283 pp 40-41 1999 161 G.F Marcus S Vijayan S Bandi Rao and P.M Vishton Rule learning in sevcn-month-old infants Science Vol 283 pp 77 80 1999 S Pinker and A Prince On language and connectionism Analysis of a parallel distributed processing model of language acquisition Cognition Vol 28, pp 73-193 1988 Marcus G.F The Algebraic Mind Integrating Connectionism and Cognitive Science, MIT-Press 2WI Spiegel R and McLaren I.P.L A Hybrid Model Approach to Generalization in Sequence Learning INNSilEEE Joint Neural Nehvork Conference, Washington DC July 15-19 2001 Zadeh L Fuvv Sets Information and Control Vol 8 DD  I   338-353 1965 M.J Nisscn and P Bullemer Attentional requirements of learning Evidence from performance measures  Cognitive Psyehology Vol 19,pp 1-32 1987 D.B Willingham M.J Nissen and P Bullemer On the development of procedural knowledge  Journd of Experimentol Psychology Learning Memory ond Cognilion Vol 15 pp 1047-1060, 1989 Spiegel R and McLaren I.P.L Rccurrent Neural Networks and Symbol Grounding  INNSiIEEE Joint Neural Network Conference, Washington, DC, July 15-19,2001 J.L Elman Finding swchxe in time  Cognitive Science Val 14,pp 179-211, 1990 French R and A Cleeremans Implicit learning and consciousness An empirical, philosophical and computational consensus in the making Psychology-press 2001 Hofstadter D and M. Mitchell The Copycat project A Model of Mental Fluidiw and Analoev-Makine in IHofstadter 19951 I 1    pp 205-267 199 Hofstadter D Fluid Concepts and Creative Analogies Basic Books 1995 Mitchell M Analogy-Making as Perception A Computcr Model, MIT-press, 1993 Marshall J.B Metacat A Self-watching Cognitive Architechlre for Analogy-Making and High-Level Perception PhD-thesis Indiana University, 1999 Spiegel R and McLaren I.P.L Modeling the Resulu of Spiegel and McLaren ZOOI Proceedings of the 23'4 Annual Conference of the Cognitive Science Society p 1239 CD ROW Edinburgh, August 14,200l B G Home and C L Giles An cxperimental comparison of recurrent neural networks In G Tesaum D Tauretzky and T Leen Eds Advances in neural information processing systems 7, pp 697-704, MIT-press, 1995 S C Kremer Spatiotemporal Connectionist Networks A Taxonomy and Review Neural Compulotion Vol 13 pp. 249 306,2M I C Chappelier M Gori and A Grumbaeh Time in Connectionist Models In R Sun and C.L Giles Eds Sequence Learning Paradigms, Algorithms and Applications 7 pp 105-134, Springer 2000 Werbos P Beyond regression new tools for prediction and analysis in behavior seienccs PhD Thesis Harvard University Cambridge MA 1974 Y Le Cun Une hoe dvre d Apprenlissage pour R sea Sed Asym trique Cognitiva 85 A la Frontierc de I Intelligence Artificielle des Scicnees de la Canaissance des Neurosciences pp. 599-604, 1985 Parker D.B Learning logic, Technical Report TR-47. Center for Computational Research in Economies and Management Science MIT, Cambridge MA 1985 Rumelhart D.E G.E Hinton and R.J Williams Learning lntemal Representations by Error Propagation  in  Rumelhart McClelland 19861 pp 318-362, 1986 Rumelhart D.E and J.L McClelland Parallel distributed processing, Val I MIT-Press, 1986 0-7803-7280-8/02/$10.00 02,2002 EEE 345 


T 2 001 in Figure 6 e two connected subtrees have the same root label 2  In Figure 6 the pair of tree ids are shown as x  y in parentheses on each node where x and y are e original and new tree ids r espectively After merging the root node has 3 children Without the new tree ids it could generate an invalid subtree e.g 2 1 1 3 1 since children with labels 1 and 3 do not appear to be the children of the node with label 2 at the same time By checking the new tree ids such invalid subtrees are avoided since the two children have different new tree ids  1 6 T2\220 8 2 3 4 5 2 5 10 Subtree: S2 15 2 1:3 1:3 1:3 1 6 After Merging 1:2,1:3 1:2,1:3 1:2 1:2 1:3 5 2 3 1:2 4 Subtree: S1 2 3 4 5 6 1:2 1:2 1:2 1:2 1:2 Original Tree Trimed Trees After Merging Figure 6 Handling Duplicate Labels The frequency counting is changed as follows for weighted support the frequency at each node is the number of new tree ids and for unweighted support the frequency is the number of original tree ids 4 Experimental Results The performance of PathJoin was examined through a series of simulation experiments All experiments were conducted on a Sun Blade 1000 with 1GB main memory and running Sun OS 5.8 The algorithm was implemented in C using Standard Template Library Three synthetic data sets D10 F5 and T1M were tested These data sets were generated using the method in 12 The synthetic data generation mimicks the Web site browsing behavior of the user The parameters used in the data generation include the number of labels N  100  the number of nodes in the master tree M  10000  the maximum fanout of a node in the master tree F 10  F 5 for data set F5 and the maximum depth of the master tree D 10  and the total number of trees in the data set T  100000  T  1000000 for T1M Two variations of the PathJoin algorithm were compared to examine the effect of pruning in candidate subtree generation one uses pruning in candidate subtree generation i.e function FST PathJoin checks whether the subsets of a candidate itemset are frequent and the other does not We did not compare our algorithm to others because of the difference of the problem de\223ned by us from others 4.1 Execution Time and Number of Candidate Subtrees The execution time for the three data sets with varying minimum support is own in Figures 7 and 8a The ecution time increases as the minimum support decreases since there are more frequent subtrees with smaller minimum support It can be also seen that the two variations of the algorithm with or without pruning in candidate subtree generation have no big difference in execution time This is because the pruning does not prune away many candidate subtrees less than 5 as shown in Figure 8b Thus the overhead for checking e subsets of the candidate subtrees offsets the saved e for frequency counting of the pruned candidate subtrees Similar results were obtained for the other two data sets which are not shown due to space limit The reason that the pruning is not very effective is that e candidate subtree generation in function computeF ST is limited to the children of a node in a tree in Forest i.e it is localized Such localizatio n reduces the number of candidate subtrees compared to apriori gen in 1 which i s applied to all the frequent itemsets found in a pass 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 0.05 0.01 0.005 0.001 0.0005 Execution time\(seconds Support threshold PathJoin-NoPruning  PathJoin-Pruning  a set F5 0 5 10 15 20 25 30 0.05 0.01 0.005 0.001 0.0005 Execution time\(seconds Support threshold PathJoin-NoPruning  PathJoin-Pruning  b set D10 Figure 7 Execution Time 20 40 60 80 100 120 140 0.05 0.01 0.005 0.001 0.0005 Execution time\(seconds Support threshold PathJoin-NoPruning  PathJoin-Pruning  a\ecution Time 0 2000 4000 6000 8000 10000 12000 14000 0.05 0.01 0.005 0.001 0.0005 Candidate subtrees Support threshold\(unweighted PathJoin-NoPruning  PathJoin-Pruning  b of Candidate Subtrees Figure 8 Data set T1M Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


4.2 Memory Usage and Scaleup The memory usage for the compact data structure FSTForest has two parts one for the compressed tree structure the other for the tree ids The memory for the compressed tree structure is 223xed for a data set given some minimum support threshold while the memory for the tree ids will grow as the number of trees in the data set increases In the experiments the data set s with different number of trees were generated with the same parameters as for data set T1M The minimum support was 223xed to 0.5 Figure 9a shows the memory usage at two stages of the algorithm the lower curve shows the the memory before expanding all subtrees with the same label and the upper curve after computing the maximal frequent paths and merging the treeids upward It can be seen that the memory usage is about doubled after expansion and merging Figure 9 also shows that both the memory usage and the execution time scales linearly with respect to the change of the number of trees in thedataset  0 20 40 60 80 100 120 140 160 180 0 500 1000 1500 2000 2500 3000 3500 4000 Memory usage\(MBs Number of trees\(in 1000\220s FST-Forest\(before expanding  FST-Forest\(after MFP  a Memory usage 0 20 40 60 80 100 120 140 0 500 1000 1500 2000 2500 3000 3500 4000 Execution time\(seconds Number of trees\(in 1000\220s PathJoin-Pruning b Scaleup Figure 9 Memory Usage and Scaleup 5 Conclusion A new type of tree mining maximal induced subtrees in unordered trees is de\223ned in the paper A novel algorithm PathJoin is proposed to discover all maximal frequent subtrees given some minimum support threshold The algorithm uses a compact data structure FST-Forest to compress the trees in the database and at the same time still keeps the original tree structure A localized candidate subtree generation method is used in the algorithm which reduces the number of candidate subtrees substantially The algorithm is evaluated with synthetic data sets The future work includes 1 earlier identi\223cation of maximal frequent subtrees which could potentially save a lot of e for computing the non-maximal frequent subtrees 2 extension of FST-Forest for mining maximal frequent embedded subtrees which allow ancestor/descendent relationship Acknowledgement We would like to thank Prof Mohammed J Zaki for sending us the source code for e tree generation program References  R  A gra w al and R  S r i kant  F ast al gori t h ms for m i n i n g a ssociation rules in large databases In Proceedings of the Twentieth International Conference on Very Large Databases  pages 487\205499 Santiago Chile 1994  R  A gra w al and R  S r i kant  M i n i n g s equent i a l p at t e rns In Proceedings of the 11th International Conference on Data Engineering  Taipei Taiwan Mar 1995 IEEE Computer Society Press  T  A sai K Abe S  Ka w a so e H Arimura H Satamoto and S Arikawa Ef\223ciently substructure discovery from large semi-structured data In Proceedings of the 2nd SIAM Int\325l Conference on Data Mining  april 2002 4 M  S  C h en J S  Par k  and P  S  Y u  E f 223 ci ent dat a m i n i n g for path traversal patterns IEEE Transactions on Knowledge and Data Engineering  10\(2\:209\205221 1998 5 G  C ong L  Y i  B  L i u  a nd K W a ng Di sco v e r i ng f r e quent substructures from hierarchical semi-structured data In Proceedings of the 2nd SIAM Int\325l Conference on Data Mining  Arlington VA april 2002 6 J  H an J P e i  and Y  Y i n  M i n i n g f r e quent pat t e r n s w i t hout candidate generation In Proceedings of the M SIGMOD Conference  2000 7 A  I nokuchi  T  W ashi o and H Mot oda An apr i or i based al gorithm for mining frequent substructures from graph data In Proceedings of the 4th European Conference on Principles of Knowledge Discovery and Data Mining  sep 2000 8 M  K ur amochi and G Kar ypi s F r equent subgr aph di sco v ery In Proceedings of the 1st IEEE Int\325l Conference on Data Mining  nov 2001 9 D  S hasha J W a ng and R  Gi ugno Al gor i t h ms and appl i cations of tree and graph searching In Proceedings of the 21st M SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems  pages 39\20552 Madison Wisconsin june 2002  Y  Xi ao and M H Dunham E f 223 c i e nt mi ni ng of t r a v er sal patterns Data and Knowledge Engineering  39:191\205214 2001  X Y a n a nd J Han gspan Gr aphbased subst r uct ur e pat tern mining In Proceedings of the 2002 IEEE International Conference on Data Mining ICDM 2002 9-12 December 2002 Maebashi City Japan  pages 721\205724 IEEE Computer Society 2002  M J Z a ki  E f 223 ci ent l y mi ni ng f r e quent t r ees i n a f or est In Proceedings of the 8th M SIGKDD Int\325l Conference on Knowledge Discovery and Data Mining  Edmonton Canada jul 2002 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


association-cube, base-cube and population-cube are derived from the volume cube; the confidence-cube is derived from the association cube and population cube and the support-cube is derived from the associationcube and base-cube. The slices of these cubes shown in Figure 2 correspond to the same list of values in dimension merchant, time, area and customer_group  Multidimensional and multilevel rules Representing association rules by cubes and underlying cubes by hierarchical dimensions, naturally supports multidimensional and multilevel rules. Also these rules are well organized and can be easily queried  First, the cells of an association cube with different dimension values are related to association rule instances in different scopes. In the association cube CrossSales cell CrossSales product \221A\222, product2 \221B\222  customer_group 221engineer\222, merchant \221Sears\222, area \221Los Angeles\222, time 221Jan98\222 represents the following multidimensional rule x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x,\221B\222  275 customer_group = \221engineer\222, merchant = \221Sears\222, area 221Los  Angeles\222, time =  \221Jan98\222 If this cell has value 4500, and the corresponding cell in the population cube has value 10000, then this rule has confidence 0.45 Next as the cubes representing rules can have hierarchical dimensions, they represent not only multidimensional but also multi-level association rules. For example, the following cells CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221Jan98\222 CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221 Year98 222 represent association rules at different area levels \(i.e the city level and the state level\d different time levels \(i.e., the month level, the year level x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221Jan98\222 x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221 Year98 222 The cell CrossSales\(product \221A\222, product2 \221B\222,  customer_group 221top\222, merchant \221top\222, area \221top\222,  time \221top\222 represents the customer-based cross-sale association rule for all customers, merchants, areas, and times in the given range of these dimensions, expressed as x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222 4.3  Generating Association Rule Related Cubes The basic task of our OLAP based association rule mining framework, either at the GDOS or at an LDOS is to convert a volume cube i.e. the cube representing the purchase volumes of customers dimensioned by product  area etc, into an association cube a base cube and a population cube These cubes are then used to derive the confidence cube and the support cube of multidimensional association rule instances. The following general steps are involved in cross-sale association rule mining 267  Roll up the volume cube SaleUnits by aggregating it along merchant, time, area dimensions 267  Derive cube NumOfBuyers from SaleUnits based on the antecedent condition SaleUnits 0 267  Populate cube NumOfShoppers by the counts of customers dimensioned by merchant, area  time not by product\at satisfy the antecedent conditions 267  Derive cube CrossSales from SaleUnits based on the association conditions SaleUnits  product  p 1  0 and SaleUnits  product2  p 2 0 267  Derive cube Confidence and cube Support using cell-wise operations 214  Confidence = CrossSales  NumOfBuyers 214  Support  CrossSales  NumOfShoppers  Cubes Confidence  Support  CrossSales are dimensioned by product  product2 customer_group,merchant  time, area NumOfBuyers is dimensioned by product  customer_group, merchant time, area  NumOfShoppers is dimensioned by customer_group, merchant  time, area Rules with confidence and support that exceed specified thresholds  may be considered interesting 4.4. Rules with Conjoint Items Cubes with conjoint dimensions can be used to represent refined multidimensional association rules For example, using OLAP, we can derive association rules across time  Time-variant or temporal association rules such as 


x 316 Customers buy_product\(x,\222 A\222, \221 Jan98\222  336 buy _product\(x, \221B\222, \221 Feb98\222   275 area = \221Los Angeles\222 can be used to answer such questions as \223 How are  the sales of B in Feb98  associated with the sales of A in Jan98 224 The items in this rule are value pairs of dimensions product and time In order to specify this kind of association rule we introduce a conjoint dimension product, time and mirror it with dimension product2, time2 This allows a cell in the association cube to cross two time values. Accordingly, the cubes related to association rule mining are defined as follows Association cube  CrossSales.2 \(<product, time>, <product2, time2 customer_group, merchant, area  Population cube  NumOfBuyers.2  \(<product, time>, customer_group merchant, area Base cube  NumOfShoppers.2  \( customer_group, merchant, area Confidence cube Confidence.2 \(<product, time>, <product2, time2 customer_group, merchant, area Support  cube  Support.2  product, time>, <product2, time2 customer_group, merchant, area  The steps for generating these cubes are similar to the ones described before. The major differences are that a cell is dimensioned by, besides others product, time and product2, time2 and the template of the association condition is  SaleUnit s  product p 1 time t 1  0 and  SaleUnits  product2 p 2 time2 t 2  0 where, in any instance of this condition, the time expressed by the value of time2 is not contained in the time expressed by the value of time The template of the antecedent condition is SaleUnits   product p 1 time t 1  0 In general, other dimensions such as area may be added to the conjoint dimensions to specify more refined rules 4.5. Functional Association Rules A multidimensional association rule is functional if its predicates include variables, and the variables in the consequent are functions of those in the antecedent.  For example, functional association rules can be used to answer the following questions, where a_month and a_year are variables q  What is the percentage of people in California who buy a printer in the next month after they bought a PC x 316 Customer buy_product\(x, \221PC\222, a_ month 336 buy_product\(x, \221printer\222, a_month+1  275 area = \221California\222 q  What is the percentage of people who buy a printer within the year when they bought a PC  x 316 Customer: buy_product\(x, \221PC\222, a_ year 336 buy_product\(x, \221printer\222, a_year 275 area = \221California\222 To be distinct, we call the association rules that are not functional as instance association rules; e.g x 316 Customer: buy_product\(x,\222 PC\222, \221Jan98\222 336 buy_product\(x,\222 printer\222, \221Feb98\222  275 area =  \221California\222 Time variant, functional association rules can be derived from time variant, instance association rules through cube restructuring. Let us introduce a new dimension time_delta that has values one_day, two_day 205, at the day level, and values one_month, two_month, \205, at the month level, etc. Then, let us consider the following functional association rule related cubes Association cube  CrossSales.3 \(product, product2, customer_group merchant, area, time_delta  Population cube  NumOfBuyers.3 \(product, customer_group, merchant area Base cube  NumOfShoppers.3 \( customer_group, merchant, area Confidence cube  Confidence.3 \(product, product2, customer_group merchant, area, time_delta Support cube  Support.3 \(product, product2, customer_group, merchant area, time_delta The association cube CrossSales.3  can be constructed from CrossSales.2   The cell values of CrossSales.2  in the selected time and time2 ranges are added to the corresponding cells of CrossSales.3 For example, the count value in cell  CrossSales.2\(<PC, Jan98>, <printer, Feb98>\205 is added to cell \(bin CrossSales.3\(PC, printer, one_month,\205 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



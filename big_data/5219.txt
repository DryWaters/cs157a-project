A Multi-Objective Evolutionary Algorithm for Mining Quantitative Association Rules Diana Mart  n and Alejandro Rosete Dept Artiìcial Intelligence and Infrastructure of Informatic Systems Higher Polytechnic Institute Jos  e Antonio Echeverr  a Cujae 19390 La Habana Cuba Email  dmartin rosete  ceis.cujae.edu.cu Jes  us Alcal  a-Fdez and Francisco Herrera Dept Computer Science and Artiìcial Intelligence CITIC-UGR University of Granada 18071 Granada Spain Email  jalcala herrera  decsai.ugr.es Abstract Data mining is most commonly used in attempts to induce association rules from database Recently some researchers have suggested the extraction of association rules as a multi-objective problem removing some of the limitations of current approaches In this way we can jointly optimize quality measures which can present different degrees of tradeoff depending on the database used and the type of information can be extracted from it In this work we extend the well-known multi-objective evolutionary algorithms NSGA-II to perform an evolutionary learning of the intervals of attributes and a condition selection in order to mine a set of quantitative association rules with a good trade-off between interpretability and accuracy To do that this method considers three objectives maximize the interestingness comprehensibility and performance Moreover this method follows a database-independent approach which does not rely upon minimum support and minimum conìdence thresholds The results obtained over two real-world databases demonstrate the effectiveness of the proposed approach Keywords Data Mining Quantitative Association Rules Multi-Objective Evolutionary Algorithms NSGA-II I I NTRODUCTION Discovering association rules is one of several Data Mining DM techniques described in the literature Association rules are used to represent and identify dependencies between items in a database These are an e xpression of the type X  Y  where X and Y are sets of items and X  Y    It means that if all the items in X exist in a transaction then all the items in Y are also in the transaction with a high probability and X and Y should not have a common item Many previous studies for mining association rules focused on databases with binary or discrete values however the data in real-world applications usually consists of quantitative values Designing DM algorithms able to deal with various types of data presents a challenge to workers in this research eld In the last years many researchers have proposed Evolutionary Algorithms EAs for mining quantitati v e association rules 24 from databases with quantitati v e v alues EAs particularly Genetic Algorithms GAs are considered to be one of the most successful search techniques for complex problems and it has proved to be an important technique for learning and knowledge extraction The main motivation for applying GAs to knowledge extraction tasks is that they are robust and adaptive search methods that perform a global search in place of candidate solutions for instance rules or other forms of knowledge representation Recently some researchers have suggested the extraction of association rules as a multi-objective problem instead of a single objective removing some of the limitations of current approaches Several objectives are considered in the process of extracting association rules obtaining a set with more interesting rules and accurate 13 In this way we can jointly optimize measures such as support conìdence and so on which can present different degrees of trade-off depending on the database used and the type of information can be extracted from it Since this approach presents a multiobjective nature the use of Multi-Objective Evolutionary Algorithms MOEAs 7 to obtain a set of solutions with different degrees of trade-off between the different measures could represent an interesting way to work by considering these measures as objectives In this work we propose an extension of the wellknown MOEA Non-dominated Sorting Genetic Algorithm II NSGA-II to mine a set of quantitati v e association rules NSGA-II-QAR with a good trade-off between interpretability and accuracy To do that this method performs an evolutionary learning of the intervals of the attributes and a condition selection for each rule considering three objectives maximize the interestingness comprehensibility and performance understanding for performance the product between conìdence and support Moreover this method follows a database-independent approach which does not rely upon the minimum support and the minimum conìdence thresholds which are hard to determine for each database This paper is arranged as follows Next section presents a brief study of the existing MOEAs for general purpose In Section III we present our proposal to learn the intervals of the attributes and to perform a condition selection in order to obtain a set of high quality association rules Section IV shows the results of the proposed mining algorithm applied 1397 978-1-4577-1676-8/11/$26.00 c  2011 IEEE 


over two real-world databases Finally Section V points out some concluding remarks II M ULTI O BJECTIVE E VOLUTIONARY A LGORITHMS EAs simultaneously deal with a set of possible solutions the so-called population which allows to nd several members of the Pareto optimal set in a single run of the algorithm Additionally they are not too susceptible to the shape or continuity of the Pareto front e.g they can easily deal with discontinuous and concave Pareto fronts The rst hint regarding the possibility of using EAs to solve a multi-objective problem appears in a Ph.D thesis from 1967 in which ho we v e r  no actual MOEA w a s developed the multi-objective problem was restated as a single-objective problem and solved with a genetic algorithm David Schaffer is normally considered to be the rst to have designed a MOEA during the mid-1980s Schafferês approach called Vector Evaluated Genetic Algorithm VEGA consists of a simple genetic algorithm with a modiìed selection mechanism However VEGA had a number of problems from which the main one had to do with its inability to retain solutions with acceptable performance perhaps above average but not outstanding for any of the objective functions After VEGA the researchers designed a rst generation of MOEAs characterized by its simplicity where the main lesson learned was that successful MOEAs had to combine a good mechanism to select non-dominated individuals perhaps but not necessarily based on the concept of Pareto optimality combined with a good mechanism to maintain diversity tness sharing was a choice but not the only one The most representative MOEAs of this generation are the following Nondominated Sorting Genetic Algorithm NSGA Niched-P areto Genetic Algorithm NPGA and Multi-Objecti v e Genetic Algorithm MOGA A second generation of MOEAs started when elitism became a standard mechanism In fact the use of elitism is a theoretical requirement in order to guarantee convergence of a MOEA Many MOEAs have been proposed during the second generation which we are still living today However most researchers will agree that few of these approaches have been adopted as a reference or have been used by others In this way the Strength Pareto Evolutionary Algorithm 2 SPEA2 and the NSGA-II 8 can be considered as the most representative MOEAs of the second generation also being of interest some others as the Pareto Archived Evolution Strategy PAES and the Multiobjective Evolutionary Algorithm Based on Decomposition MOEA/D Table I shows a resume of the most representative MOEAs of both generations Finally we have to point out that nowadays NSGA-II is the paradigm within the MOEA research community since the powerful crowding operator that this algorithm uses Table I C LASSIFICATION OF MOEA S  Reference MOEA 1 st Gen 2 nd Gen 12 MOGA  16 NPGA  23 NSGA  3 micro-GA   18 MOEA/D  MOEA/D-DE  10 NPGA 2  8 NSGA-II  17 PAES   6 PESA  PESA-II   27 SPEA  SPEA2  usually allows to obtain the widest Pareto sets in a great variety of problems which is a very appreciated property in this framework III A MOEA FOR M INING Q UANTITATIVE A SSOCIATION R ULES The proposed algorithm extends the well-known MOEA NSGA-II in order to mine a set of quantitati v e association with a good trade-off between interpretability and accuracy To do that we consider as objectives the comprehensibility interestingness and performance of the rules In the following the main characteristics of this approach are presented coding scheme initial gene pool objectives genetic operators and genetic model A Coding scheme and initial gene pool Each chromosome is a vector of genes that represent the attributes and intervals of the rule We have used a positional encoding where the i-th attribute is encoded in the i-th gene has been used To combine the condition selection with the learning of the intervals each gene consist of three parts  The rst part  ac  represents when a gene is involved or not in the rule When this part is 1 this attribute is not involved in the rule and when this part is 0 or 1 this attribute is part of the antecedent or consequent of the rule respectively All genes that have 0 on their rst parts will form the antecedent of the rule while genes that have 1 will form the consequent of the rule  The second part represents the lower bound  lb fthe interval of the attribute  The third part represents the upper bound  ub fthe interval of the attribute Notice that lb and ub will be equal in the intervals of nominal attributes Finally a chromosome C T is coded in the following way where m is the number of attributes in the database Gene i  ac i lb i ub i  i 1 m  C T  Gene 1 Gene 2 Gene m 1398 2011 11th International Conference on Inte lligent Systems Design and Applications 


In order to avoid the intervals to grow up until spanning the total domain we deìne amplitude as the maximum size the interval of a determined attribute can get Thus the amplitude of a attribute i is deìned as Amplitude i  Max i  Min i   where Max i and Min i are the maximum and minimum values of the domain of attribute i respectively and  is a value given by the system expert that determines the tradeoff between generalization and speciìcity of the rules The initial population will be consisted of a rule set with only one attribute in the consequent with a good coverage of the database To do that rst we select at random the attributes that will be part of the antecedent and consequent of the rule Then we select at random an example from database and generate the interval of each attribute with a size equal to 50 of the amplitude of each attribute and with the values of the example selected in the center of each of them Finally the examples covered for this rule are removed of the database This process is repeated until initial population is completed Notice that if all examples are removed of the database all of them will be added again to the database B Objectives Three objectives are maximized for this problem Interestingness Comprehensibility and Performance Performance is the result of the product between conìdence and support which allow us to obtain accurate rules and a good trade-off between local and general rules These measures support and conìdence for a rule X  Y are deìned as Support  X  Y  SUP  XY    D  Confidence  X  Y  SUP  XY  SU P  X  where SUP  XY  is the number of examples of the database covered by the antecedent and consequent of the rule and SUP  X  is the number of examples of the database covered by the antecedent of the rule Interestingness measures how much interesting the rule is which allow us to extract only those rules that may be more interesting to the users In this case we have used the interestingness measure lift which represents the ratio between the conìdence of the rule and the expected conìdence of the rule This is deìned as Lif t  X  Y  SUP  XY    D   SUP  X    D  SUP  Y    D  where SUP  Y  is the number of examples of the database covered by the consequent of the rule Finally comprehensibility tries to quantify the understandability of the rule The generated rules may have a large number of attributes involved thereby making it difìcult to understand If the generated rules are not Figure 1 A simple example of the crossover operator understandable to the user the user will never use them Here the comprehensibility of a rule X  Y is measured by the number of attributes involved in the rule and is deìned as Comprehensibility  X  Y  Attr X  Y where Attr X  Y is the number of attributes involved in the rule C Genetic Operators The crossover operator generates two offspring interchanging randomly the genes of the parents exploration Figure 1 shows a simple example of the performance of this operator The mutation operator consists in modifying randomly the interval  lb and ub  and ac of a gene selected at random This operator selects at random one of the bounds of the interval and increases or decreases its value randomly We have to be specially careful in not overcoming the xed value of amplitude The value for ac is randomly selected within the set  1,0,1   D Repairing operator After mutation operator if any rule doesnêt have antecedent or consequent or has more than one attribute in the consequent a repairing operator is performed to modify these rules If there are more than one attribute in the consequent one attribute is randomly selected as consequent between them and the remaining of attributes are passed to the antecedent If there is not any attribute in the antecedent and/or consequent these are randomly selected between the attributes not involved Finally the size of the intervals are decreased until the number of examples covered is smaller than the number of examples covered by the original intervals in order to obtain more simple rules E NSGA-II Genetic Model As in other EAs rst NSGA-II generates an initial population Then an offspring population is generated from the current population by selection crossover and mutation The next population is constructed from the current and offspring populations The generation of an offspring population and the construction of the next population are iterated until a stopping condition is satisìed The NSGA-II algorithm has two features which make it a high-performance MOEA One is the tness evaluation of each solution based on Pareto 2011 11th International Conference on Inte lligent Systems Design and Applications 1399 


ranking and a crowding measure and the other is an elitist generation update procedure Each solution in the current population is evaluated in the following manner First Rank 1 is assigned to all nondominated solutions in the current population All solutions with Rank 1 are tentatively removed from the current population Next Rank 2 is assigned to all non-dominated solutions in the reduced current population All solutions with Rank 2 are tentatively removed from the reduced current population This procedure is iterated until all solutions are tentatively removed from the current population i.e until ranks are assigned to all solutions As a result a different rank is assigned to each solution Solutions with smaller ranks are viewed as being better than those with larger ranks Among solutions with the same rank an additional criterion called a crowding measure is taken into account The crowding measure for a solution calculates the distance between its adjacent solutions with the same rank in the objective space Less crowded solutions with larger values of the crowding measure are viewed as being better than more crowded solutions with smaller values of the crowding measure A pair of parent solutions are selected from the current population by binary tournament selection based on the Pareto ranking and the crowding measure When the next population is to be constructed the current and offspring populations are combined into a merged population Each solution in the merged population is evaluated in the same manner as in the selection phase of parent solutions using the Pareto ranking and the crowding measure The next population is constructed by choosing a speciìed number i.e population size of the best solutions from the merged population Elitism is implemented in NSGA-II algorithm in this manner Considering the components previously deìned and the descriptions of the authors in NSGA-II consists of the next steps 1 A combined population R t is formed with the initial parent population P t and offspring population Q t initially empty 2 Generate all non-dominated fronts F  F 1 F 2    of R t  3 Initialize P t 1 0 and i 1  4 Repeat until the parent population is lled 5 Calculate crowding-distance in F i  6 Include i th non-dominated front in the parent population 7 Check the next front for inclusion 8 Sort in descending order using crowded-comparison operator 9 Choose the rst  N  P t 1   elements of F i  10 Use selection crossover mutation and repairing operator to create a new population Q t 1  11 Increment the generation counter Table II P ARAMETERS CONSIDERED FOR COMPARISON  M ethod P arameters GENAR PopSize  100  N Eval 50  000  P sel 0  25  P cro 0  7  P mut 0  1  nRules 30  FP 0  7  AF 2 MODENAR PopSize  100  N Eval 50  000  Threshold 60  CR 0  3  W sup 0  8  W conf 0  2  W comp 0  1  W ampl 0  4 NSGA-II-QAR PopSize  100  N Eval 50  000  P mut 0  1   2 IV E XPERIMENTAL R ESULTS In order to analyze the performance of the proposed mining algorithm we have considered two real-world databases  Stulong  It is a database concerning a study of the risk factors of atherosclerosis in a population of 1419 middle-aged men in the years 1976 1999 1  Here we extract ve quantitative attributes out of a total of 64 attributes The selected attributes are height weight systolic blood pressure diastolic blood pressure and cholesterol level  House 16H  It concerns a study to predict the median price of the houses in a region by considering both the demographic composition and the state of housing market This data was collected as part of the 1990 US census For the purpose of this database only a level State-Place was used and data from all states was obtained This database contains 22,784 examples and 17 quantitative attributes 2  We compare the proposed algorithm with a monoobjective algorithm and a MOEA for mining quantitative association rules GENAR and MODEN AR 1 respectively The parameters of the analyzed methods are shown in Table II With these values for our proposal we have tried to facilitate comparisons selecting standard common parameters that work well in most cases instead of searching for very speciìc values The parameters of the remaining methods were selected according to the recommendation of the corresponding authors within each proposal Furthermore for all the experiments conducted in this study the results shown in the tables always refer to association rules having a minimum conìdence greater than or equal to 0  8  The results obtained for the database Stulong by the analyzed methods are shown in Table III where  R is 1 The study STULONG was performed at the 2 nd Department of Medicine 1 st Faculty of Medicine of Charles University and Charles University Hospital under the supervision of Prof F Boudk with collaboration of M Tomeckov and Ass Prof J Bultas The data were transferred to electronic form by the European Centre of Medical Informatics Statisticsand Epidemiology of Charles University and Academy of Sciences The data resource is on the web page http://euromise.vse.cz/challenge2004 At present the data analysis is supported by the grant of the Ministry of Education CR Nr LN 00B 107 2 This database was designed on the basis of data provided by US Census Bureau http://www.census.go under Lookup Access http://www.census.go Summary T ape File 1 1400 2011 11th International Conference on Inte lligent Systems Design and Applications 


Table III R ESULTS FOR THE DATABASE S TULONG  Algorithm  RAv Sup Av Conf Av Lif t Av Amp  Tran GENAR 30 0.88 0.98 1.00 5.0 95.27 MODENAR 85 0.56 0.97 1.39 2.6 99.57 NSGA-II-QAR 90 0.52 0.93 43.74 3.1 100.00 Table IV R ESULTS FOR THE DATABASE H OUSE 16H Algorithm  RAv Sup Av Conf Av Lif t Av Amp  Tran GENAR 30 0.43 0.98 1.01 17.0 87.29 MODENAR 98 0.62 0.97 1.00 6.0 96.64 NSGA-II-QAR 96 0.46 0.96 443.91 3.6 99.99 the number of the generated association rules Av Sup and Av Conf are respectively the average support and the average conìdence of the rules Av Lif t is the average value for the measure lift of the rules Av Amp is the average length of the rules in terms of attributes involved and  Tran is the percentage of transactions covered by the rules on the total examples in the database Analysing the results presented in this table we can present the following conclusions  The MOEAs returned sets of rules with less number of attributes and better coverage of the database than the mono-objective algorithm giving the advantage of easier understanding from a userês perspective  The method proposed allow us to obtain a set of association rules involving few attributes and with the best average lift and coverage of the database providing the user with high quality rules The results obtained for the database House H16 by the analyzed methods are shown in Table IV Analysing the results presented in Table IV we can stress the following facts  In this database with more attributes the rule sets obtained by MOEAs involve again few attributes in the rules and present a good coverage of the database  Moreover the method proposed mine again the rules set with best average lift and coverage of the database Fig 2 shows the relationship between the conìdence and support of the rules obtained by our proposal and the numbers of evaluations for the database Stulong It can be easily seen from this gure that the average conìdence of the rules increases with the increase of the number of evaluations and the distribution of the rules different supports is maintained in the population It means that the proposed method allows us to obtain an association rule set with a high conìdence and a good trade-off between speciìc and general rules Figure 2 Relationship between conìdence/support of the rules in the population and number of evaluations in the database Stulong The line represents the average conìdence of the rules in the population V C ONCLUSION In this work we have proposed an extension of the well-known MOEA NSGA-II to mine a set of quantitative association rules with a good trade-off between interpretability and accuracy To do that this method performs an evolutionary learning of the intervals of attributes and a condition selection for each rule considering three objectives maximize the interestingness comprehensibility and performance understanding for performance the product between conìdence and support Moreover this method follows a database-independent approach which does not rely upon the minimum support and the minimum conìdence thresholds which are hard to determine for each database The results obtained over two real-world databases have shown how the method proposed let us to mine rule sets with a good trade-off between the different objectives obtaining association rules with few attributes and with the best average lift and coverage of the dataset providing the user with high quality rules A CKNOWLEDGMENT This paper has been supported by the Spanish Ministry of Education and Science under grants TIN2008-06681-C0601 2011 11th International Conference on Inte lligent Systems Design and Applications 1401 


R EFERENCES  B Alatas E Akin and A Karci MODENAR Multi-objective differential evolution algorithm for mining numeric association rules  Applied Soft Computing 8 pp 646-656 2008  R Agra w al T  Imielinski and A Sw ami Mining association rules between sets of items in large databases  SIGMOD Washington D.C May 1993 pp 207Ö216  C Coello and G T oscano A Micro-Genetic Algorithm for multiobjective optimization  First Int Conf on Evolutionary Multi-Criterion Optimization LNCS 1993 London UK 2001 pp 126Ö140  C Coello G Lamont and D V a n V eldhuizen Evolutionary Algorithms for solving multi-objective problems  Kluwer Academic Publishers 2002  D Corne J Kno wles and M Oates The Pareto Envelopebased Selection Algorithm for multiobjective optimization  Parallel Problem Solving from Nature VI Conf LNCS 1917 Paris France 2000 pp 839Ö848  D Corne N Jerram J Kno wles and M Oates PESA-II Region based selection in evolutionary multiobjective optimization  Genetic and Evolutionary Computation Conf San Francisco CA 2001 pp 283Ö290  K Deb Multi-objective optimization using evolutionary algorithms  Kluwer Academic EE.UU 2001  K Deb S Agra w al A Pratab and T  Me yari v an A fast and elitist multiobjective genetic algorithm NSGA-II  IEEE Trans Evolutionary Computation 6:2 pp 182Ö197 2002  A.E Eiben and J.E Smith Introduction to Evolutionary Computing  SpringerVerlag 2003  M Erickson A Mayer  and J Horn The Niched Pareto Genetic Algorithm 2 applied to the design of groundwater remediation systems  First Int Conf on Evolutionary MultiCriterion Optimization LNCS 1993 London UK 2001 pp 681Ö695  M.V  Fidelis H.S Lopes and A.A Freitas Discovering comprehensible classiìcation rules with a genetic algorithm  Proceedings of the 2000 Congress on Evolutionary Computation CA USA 2000 pp 805Ö810  C.M F onseca and P J Fleming Genetic algorithms for multiobjective optimization Formulation discussion and generalization  5th Int Conf on Genetic Algorithms San Mateo CA 1993 pp 416Ö423  A Ghosh and B Nath Multi-objective rule mining using genetic algorithms  Information Sciences 163 pp 123-133 2004  D.E Goldber g Genetic Algorithms in Search Optimization and Machine Learning  Addison-Wesley Longman Publishing Co Inc 1989  J Han and M Kamber  Data Mining Concepts and Techniques  Second Edition Morgan Kaufmann 2006  J Horn N Nafpliotis and D.E Goldber g A niched pareto genetic algorithm for multiobjective optimization  First IEEE Conf on Evolutionary Computation IEEE World Congress on Computational Intelligence 1 Piscataway NJ 1994 pp 82 87  J.D Kno wles and D.W  Corne Approximating the non dominated front using the Pareto archived evolution strategy  Evolutionary Computation 8:2 pp 149Ö172 2000  H Li and Q Zhang Multiobjective Optimization Problems With Complicated Pareto Sets MOEA/D and NSGA-II  IEEE Transactions on Evolutionary Computation 13:2 pp 284Ö302 2009  J Mata J Alv arez and J Riquelme Mining Numeric Association Rules with Genetic Algorithms  5th International Conference on Artiìcial Neural Networks and Genetic Algorithms Prague 2001 pp 264-267  S Ramasw amy  S  Mahajan and A Silberschatz On the Discovery of Interesting Patterns in Association Rules  24rd International Conference on Very Large Data Bases San Francisco CA USA 1998 pp 368Ö379  R.S Rosenber g Simulation of genetic populations with biochemical properties  MA Thesis Univ Michigan Ann Harbor Michigan 1967  J.D Schaf fer  Multiple objective optimization with vector evaluated genetic algorithms  First Int Conf on Genetic Algorithms Pittsburgh USA 1985 pp 93Ö100  N Srini v as and K Deb Multiobjective optimization using nondominated sorting in genetic algorithms  Evolutionary Computation 2 pp 221Ö248 1994  X Y an C Zhang and S Zhang Genetic algorithm-based strategy for identifying association rules without specifying actual minimum support  Expert Systems with Applications 36:2 pp 3066Ö3076 2009  Ch Zhang and S Zhang Association Rule Mining Models and Algorithms  Lecture Notes in Computer Science LNAI 2307 2002  E Zitzler  and L Thiele Multiobjective evolutionary algorithms a comparative case study and the strength Pareto approach  IEEE Trans Evolutionary Computation 3:4 pp 257 271 1999  E Zitzler  M  Laumanns and L Thiele SPEA2 Improving the strength Pareto evolutionary algorithm for multiobjective optimization  Evolutionary Methods for Design Optimization and Control with App to Industrial Problems Barcelona Spain 2001 pp 95Ö100  Q Zhang and H Li MOEA/D A Multiobjective Evolutionary Algorithm Based on Decomposition  IEEE Transactions on Evolutionary Computation 11:6 pp 712Ö731 2007  A Zhou B.-Y  Qu H Li S.-Z Zhao P  Nagaratnam Q Zhang Multiobjective evolutionary algorithms A survey of the state of the art  Swarm and Evolutionary Computation 1 pp 32-49 2011 1402 2011 11th International Conference on Inte lligent Systems Design and Applications 


a A       V, W, X Y Absolute value of temperatures All other factors, as well as A Growth rate 1 1   Figure 4.  Growth tendency of electricity consumption and corresponding national economic accounts indices of a municipality  Figure 5.  Growth tendency of electricity consumption and corresponding population, investment, trade and price indices of a municipality IV. EMPIRICAL RESULTS AND DISCUSSION The main process of mining fuzzy association rules can be divided into four steps: First, the candidate factors are standardized and then transformed into fuzzy attributes by using the membership functions. Second, large fuzzy patterns are generated from the database by applying particular algorithm depicted in Fig.1. Then, Based on the large fuzzy patterns, the desired fuzzy association rules with the minimum confidence \(min_conf = 0.5 value of confidence, the quantitative association degrees between electricity consumption and its influencing factors are finally achieved. Table 2 shows the empirical results. The conclusion on dominant factors identification is displayed as well Figure 6.  Growth tendency of electricity consumption and corresponding income, industiral value, and government finace indices of a municipality TABLE II.  EMPIRICAL RESULTS No. Association Rules Conf. Conclusion 1 T? A 0.665 


Dominant factors: Output value of industry, Secondary industry product, GPD, as well as Per capita GDP 2 D? A 0.649 3 G? A 0.644 4 B? A 0.613 5 R? A 0.575 Sub-dominant factors: Total value of imports and exports Per capita disposable income Non-agricultural population Total investment in fixed assets and Peak summer temperature 6 J? A 0.556 7 AB? A 0.555 8 F? A 0.537 9 V? A 0.520  The analytical result shows a heavy dependence of electricity consumption, and hence the power load growth, on industrial output value and per capita GDP Total value of imports and exports, income, nonagricultural population and total investment in fixed assets are found out as the sub-dominant factors to growth in electricity Weather conditions in summer influence peak load level, along with the proliferation of air conditioning load. Peak summer temperature is thus found relevant to some extent as well. The remaining 18 candidate variables, therefore, are suggested to be ignored in power load analysis and forecast V. CONCLUSION In this paper, we have introduced a new data mining methodology to investigate association degrees between Chinese power load growth and 27 different candidate factors This methodology offers some advantages as, for example allowing us to properly extract interesting association rules from large historical database. By ordering confidence of selected rules, four dominant factors and five sub-dominant factors boosting the electricity consumption in China are identified, which can been adopted for better understanding the growth law and more accurately predicting the electricity demand Future work includes the development of a new prediction 


method for electricity demand using the dominant variables identified in this research as inputs. Furthermore, other data mining techniques, such as clustering analysis, are also being considered REFERENCES 1] J. Kraft, A. Kraft, On the relationship between energy and GNP Journal of Energy and Development, vol.3, pp.401-403, 1978 2] E. S. H. Yu, J. Y. Choi, The causal relationship between electricity and GNP: an international comparison, Journal of Energy and Development vol.10, pp.249-272, 1985 3] U. Erol, E. S. H. Yu, On the relationship between electricity and income for industrialized countries, Journal of Electricity and Employment, vol.13, pp.113-122, 1987 4] D. C. Bohm, Electricity consumption and economic growth in the European Union: A causality study using panel unit root and cointegration analysis, 5th International Conference on European Electricity Market, 2008 5] A. Ciarreta, A. Zarraga, Economic growth and electricity consumption in 12 European countries: A Causality Analysis Using Panel Data, 6th International Conference on the European Energy Market, Leuven, 2009 6] U. Soytas, R. Sari, Energy consumption and GDP: causality relationship in G-7 countries and emerging markets, Energy Economics pp.33-37, 2003 7] S. H. Yoo, Electricity consumption and economic growth: evidence from Korea, Energy Policy, pp.1627-1632, 2005 8] C. C. Lee, Energy consumption and GDP in developing countries: A cointegrated analysis, Energy Economics, pp.415-427, 2005 9] S. T. Chen, H. I. Kuo, C. C. Chen, The relationship between GDP and electricity consumption in 10 Asian countries, Energy Policy, pp.26112621, 2007 10] C. C. Lee, C. P. Chang, Energy consumption and economic growth in Asian economies: A more comprehensive analysis using panel data Resource and Energy Economics, pp.50-65, 2008 11] A. Shiu, P. L. Lam, Electricity consumption and economic growth in China, Energy Policy, pp.47-54, 2004 12] G. D. Li, D. Yamaguchi, H. S. Lin, The simulation modeling about the developments of GDP, population and primary energy consumption in China based on MATLAB, 2006 IEEE Conference on Cybernetics and Intelligent Systems, Bangkok, 2006 13] L. P. Wang, Study on the relationship between economic development and energy consumption in Henan Province of China, 2008 International Seminar on Business and Information Management, 2008 


14] X. Zhang, Y. Mao, The relationship between energy consumption and economic growth in China based on ANFIS, International Workshop on Intelligent Systems and Application, ISA2009, Wuhan, 2009 15] H. R. Cui, D. Wang, The study on the relationship between energy consumption and economy growth in China based on VAR model 2009 First International Workshop on Database Technology and Applications, 2009 16] M. Delgado, N. Marn, D. Snchez, M. A. Vila, Fuzzy association rules general model and applications, IEEE Transactions on Fuzzy Systems vol.2, pp.214-225, 2003 17] R. Agrawal, T. Imielinski, A. Swami, Mining association rules between sets of items in large databases the ACM SIGMOD Conference on Management of data. Washington DC, pp.207-216, 1993 18] D. Dubois, H. Prade, T. Sudkamp, On the representation, measurement and discovery of fuzzy associations, IEEE Transactions on Fuzzy Systems, vol.2, pp.250-262, 2005   


means that the service is in the same branch, but at a lower level in the hierarchy of services execution. Therefore, this service will only be conducted if an error has occurred in the execution of the previous one. As shown in chart II the latter service uses an image resource in charge of showing some information at the MIDlet display and whose content is also stored on the device Besides, the MIDlet allows in a simple way to modify all those parameters that define the execution of the services and their use. As commented before, a user could not want that a service is executed automatically and requires manual confirmation. For that, he/she only would need to change the value of the execution parameter of the service into manual. In the same way, the user can activate or deactivate the use of resources just by modifying the value of the state attribute into off. Even more, it is possible to add new resources, if, together with their definition some content needed for their execution is included Therefore, it can be checked as, even when the user define an initial interaction for a scenario and even when the same deployment is done in different devices, each user could easily adapt and customize the interaction to its needs and preferences afterwards Equally, the user could activate or deactivate a service changing the execution order and modifying the hierarchy initially defined for them. Herewith, the same scenario could be customized and act in a different way depending of the person that interacts with it V. DISCUSSION IoT is not a reality yet, but a prospective view of a series of technologies that, combined, could sharply modify the interaction mode with our environment and the working of our society in the following years. In order to establish the IoT philosophy, it would be needed an advance of the development and dissemination of elements as sensors, new communication technologies \(as well as their intercommunication mobile devices able to integrate them, a proper infrastructure and above all software applications that supports them and are able to integrate all those elements, as well as to fulfills the needs and requirements of the users Those new systems must also be adapted to the different interaction scenarios and, mainly, to the different 


characteristics, requirements, preferences and needs of the people that interact with the environment. In this paper we present a model that provides a solution to this issue The model is based in augment different objects among a scenario with Tags, by the assignment of services and resources defined in an abstracted hierarchy that allows configuring a customized interaction model. Thus, for the same scenario, the model is able to define different interaction contexts. So, a context is defined as the aggregation of: a certain scenario formed by a set of intelligent objects offering a set of services, b characteristics, preferences and needs, c and d Under the proposed model a tool that allows the definition and scenario deployment has been built. A neuter MIDlet installed in the NFC device is the one in charge of guiding the 13 interaction through the definition of the scenarios stored in a XML file. This architecture allows that the same MIDlet could be used with any scenario and that the user could adapt the interaction to his preferences Currently we are working in the completeness of the model and the complex interaction scenarios generalization, being the latter based in rules systems that allows adapting the different interaction contexts to the users ACKNOWLEDGMENT This work was supported by the Ministry of Science and Innovation of Spain \(MICINN Project TIN2009-07184 REFERENCES 1] M. Weiser. The Computer for the Twenty-First Century. Scientific American, 1991, pp. 91-104 2] G. Broll, S . Siorpaes, E. Rukzio, M. Paolucci, J. Hamard, M. Wagner and A. Schmidt. Supporting Mobile Service Usage through Physical Mobile Interaction, 5th Annual IEEE International Conference on Pervasive Computing and Communications, White Plains,NY, USA 2007 3] C. Floerkemeier, M. Langheinrich, E. Fleisch, F. Mattern and S.E Sarma. The Internet of Things. Proceedings of First International Conference, IOT 2008, Zurich, Switzerland. Lecture Notes in Computer Science, vol. 4952, 2008 4] Revising Europes ICT Strategy, ftp://ftp.cordis.europa.eu/pub/ist/docs 


istag-revising-europesict-strategy-final-version_en.pdf 5] E. Rukzio, G. Broll, K. Leichtenstern, A. Schmidt. Mobile Interaction with the Real World: An Evaluation and Comparison of Physical Mobile Interaction Technique, Ambient Intelligence. Lecture Notes in Computer Science, vol. 4794, 2007, pp. 1-18 6] J. Hong and E. Suh, S. Kim. Context-aware systems: A literature review and classification, Expert Systems with Applications. 2009 Elsevier 7] A.K. Dey and G.D. Abowd. Towards a better understanding of context and context-awareness, Proceedings of the Workshop on the What Who, Where, When and How of Context-Awareness, ACM Press, New York. 2000 8] H. Chen, T. Finin and A. Joshi.An Intelligent Broker for ContextAware Systems, Adjunct Proceedings of Ubicomp 2003 9] H. Chen, F. Perich, T. Finin, A. Joshi. SOUPA: standard ontology for ubiquitous and pervasive applications, The First Annual International Conference on Mobile and Ubiquitous Systems: Networking and Services, 2004, MOBIQUITOUS 2004 10] M. Roman, C. Hess, R. Cerqueira, A. Ranganathan, R.H. Campbell and K. Nahrstedt. GAIA: A middleware infrastructure for active spaces IEEE Pervasive Computing, vol. 1, no. 4, 2002, pp. 74-83 11] Service Platform for Innovative Communication Environment \(SPICE An Integrated Project in European Unions IST 6th Framework Programme, http://www.ist-spice.org 12] Open Platform for User-centric service Creation and Execution OPUCE Framework Programme, http://www.opuce.tid.es 13] MobiLife, an Integrated Project in European Unions IST 6th Framework Programme, http://www.ist-mobilife.org 14] L. Lamorte. A platform for enabling context aware telecommunication services, Third Workshop on Context Awareness for Proactive Systems. 2007 15] C. Venezia, C.A. Licciardi Improve ubiquitous Web applications with Context Awareness, 11th ICIN 2007 16] J.J. Chen, C. Adams. Short-range wireless technologies with mobile payments systems, Proc. ICEC 04, ACM Press, 2004, pp. 649 656 17] K. Cheverst. Experiences of developing and deploying a context-aware tourist guide: The GUIDE project, 6th International Conference on Mobile Computing and Networking, Boston, August 2000, pp. 2031 18] D.J. Cooka, J.C. Augusto, V.R. Jakkula, Ambient intelligence Technologies, applications, and opportunitie, Pervasive and Mobile Computing. 2009 


19] J. Hong, E. Suh, S. Kim. Context-aware systems: A literature review and classification, Expert Systems with Applications. Elsevier. 2008 20] G. Matas Miraz, I. Luque Ruiz, M.A. Gmez-Nieto. How NFC can be used for the Compliance of European Higher Education Area Guidelines in European Universities. Proceedings 1st International IEEE Workshop on Near Field Communication. 3-8. 2009   14 


dataset contains a stream of TCP connection records from two weeks of LAN traffic over MIT Lincoln Labs. It consists of 42 attributes that usually characterize network traffic behavior, both categorical attributes and quantitative attributes such as duration of the connections, protocol type etc. Attribute src_byte denoting the number of data bytes from source to destination and attribute dst_bytes inverse are selected in this experiment.  They are both quantitative attributes The user specified parameters are set as follows 5, 0.3, 0.03, 0.01,W min_sup preMinsup T 0.5, 0.4, 30.min_confidence max_MFB min_num_triples And the number of transactions in each time slot is 250 It is assumed that there are no more than three fuzzy sets or intervals in the datasets i.e. 3F Four different approaches to mine association rules are compared using the following notations: Fuzzy+MFB: the approach that use both fuzzy method and MFB_measure with 1 3.0? = and 2 0 .5 2 0.5? = , Fuzzy+P: the approach using fuzzy method with 1 3.0? = and 2 0.5? = also but repressing the first part of the MFB_measure that ignores the changed rate of the membership function, Discrete1: the approach using discrete method with 1 2 1.5? ?= =  and Discrete2 : the approach using discrete method with 1 2 2.5 TABLE I. RESULT OF EXPERIMENT ONE NUM_C NUM_FI NUM_RULE TIME\(s 1 \(50,50 2 \(60,60 3 \(70,70 4 \(80,80 5 \(90,90 6 \(100,100 7 \(110,110 8 \(120,120 9 \(130,130 10 \(140,140 Volume 4] 2010 2nd International Conference on Computer Engineering and Technology V4-157 0 0.5 1 1.5 2 x 104 


0 200 400 600 800 1000 1200 1400 Size of Databases\(250 Ex ec u tio n Ti m e\(s ec  Fuzzy+MFB Discrete1 Discrete2 Fuzzy+P Figure 3. Comparison of Execution Time Fig. 3 shows the execution time of the four approaches The runtimes of them grow linearly as the data stream grows which confirms that they are scalable with respect to the size of data stream, and it is mainly because of the usage of sliding window model. Fuzzy+P uses the least time Fuzzy+MFB has similar execution time to Discrete2, and Discrete1 has the most execution time. The difference of runtimes between them is mainly influenced by the clustering operations they use. The more clustering operations were executed, the more runtime it was Fig. 4 and Fig. 5 show the number of frequent itemsets and interesting rules found with the data stream increased Fuzzy+P and Fuzzy+MFB used less clustering operations than Discrete1 and Discrete2. Fuzzy+MFB nearly finds the most number of frequent fuzzy sets and interesting rules with the second least of clustering operations. Sometimes Discrete2 returns nearly the same number of fuzzy sets and interesting rules but with more clustering operations and the 


semantics of Discrete2 are meaningless as discussed in experiment one. Furthermore, the number of interesting rules found by Discrete1 is even less than Fuzzy+P that used the clustering operations least which illustrates the superiority of the method using fuzzy sets V. CONCLUSIONS In this paper, a novel fuzzy ARM algorithm called FFI_Stream is presented to tackle quantitative attributes in data streams and some techniques are proposed in the algorithm. Both synthetic and real datasets are used to evaluate the performance of the proposed algorithm. The experimental results show both the effectiveness and efficiency of the proposed algorithm.  In comparison with the discrete method, the proposed algorithm using fuzzy sets and MFB_measure gets a trade-off between the number of interesting rules and efficiency ACKNOWLEDGMENT This work is supported by The National High Technology Research and Development Program of China 863 Program 2008AA042902 Technology Research and Development Program of China 863 Program 2009AA04Z162 Project \(B07031 0 500 1000 1500 2000 2500 3000 3500 4000 0 2000 4000 6000 8000 10000 12000 Size of Databases\(250 N um be r o f F re qu e n t I 


te m se ts Fuzzy+MFB Discrete2 Discrete1 Fuzzy+P Clustering Operation Figure 4. Number of Frequent Itemsets 0 500 1000 1500 2000 2500 3000 3500 4000 0 1000 2000 3000 4000 5000 6000 7000 8000 Size of Databases\(250 Nu m be r o f I n te re st in g Ru le s Fuzzy+MFB Discrete2 Discrete1 Fuzzy+P Clustering Operation Figure 5. Number of Interesting Rules REFERENCE 1] R. Srikant and R. Agrawal, Mining Quantitative Association Rules 


in Large Relational Talbes, Proc. ACM SIGMOD, 1996, pp. 1-12 2] A.W. Fu et al. Finding Fuzzy Sets for the Mining of Fuzzy Association Rules for Numerical Attributes, In Proceedings of the First International Symposium on Intelligent Data Engineering and Learning \(IDEAL'98 3] C. M. Kuok, A. Fu and M. H . Wong, Fuzzy Association Rules in Large Databases with Quantitative Attributes, In ACM SIGMOD Records, vol. 27, 1998, pp. 41-46 4] X. Dang, V. Lee, W. K. Ng and K.L Ong, Incremental and Adaptive Clustering Stream Data over Sliding Window, Database and Expert Systems Applications, vol. 5690, 2009, pp. 660-674 5] M. Kaya,?R. Alhajj, F. Polat, and A. Arslan, Efficient Automated Mining of Fuzzy Association Rules, Database and Expert System Applicaton, vol. 2453, 2002, pp.133-142 6] http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 7] S. Guha, A. N. Mishra, R. Motwani, L. OCallaghan, Clustering Data Streams: Theory and Practice,  Proc. IEEE Transactions on Knowledge and Data Engineering, vol. 15, May/Jun. 2003, pp. 515528 8] C. Aggarwal, J. Han, J. Wang, P. Yu, A Framework for Clustering Evolving Data Streams,  Proc. VLDB Conference, 2003,  pp. 81-92 9] C. K. S. Leung, B. Y. Hao, Mining of Frequent Itemsets from Streams of Uncertain Data,  Proc. IEEE International Conference on Data Engineering \(ICDE 09 10] C. C. Aggarwal, Y. Li, J. Y. Wang, and J. Wang, Frequent Pattern Mining with Uncertain Data, Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Jun. 2009, pp 29-37 11] P. M. Tsai, Mining Frequent Itemsets in Data Streams using the Weighted Sliding Window Model, Expert Systems and Applications vol. 36, Nov. 2009, pp.11617-11625 V4-158 2010 2nd International Conference on Computer Engineering and Technology [Volume 4 


In all charts reported in this section, the X-axis is k, which denotes the size of sample under the space of a target rule drawn from deep web. The sample size for each point on X-axis is k x, where x is a ?xed value for our experiment, and depends upon the dataset. At each time, queries are issued to obtain kx data records under the space of a target rule. Overall, all our experiments show the variance of estimation, sampling costs and sampling accuracy with varying sample size Figure 1 shows the result from our strati?ed sample methods on the US census data set. The size of pilot sample is 2000, from which all of the 50 initial rules are derived. In this experiment the ?xed value x is set to be 300, which means the smallest sample size at k = 1 is 300, and the largest sample size at k 10 is 3000. Figure 1 a the ?ve sampling procedures. Figure 1 b cost for the sampling procedures. In order to better illustrate the experiment result, in each execution of sampling, the variance of 330 6DPSOLQJ9DULDQFH            9D UL DQ FH R I V WL PD WL RQ  


9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW           6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF            5 


 9DU 9DU 9DU 5DQG c Fig. 1. Evaluation of Sampling Methods for Association Rule Mining on US Census Dataset estimation and sampling cost for the sampling procedures var7 var5, var3, and rand are normalized by the corresponding values of Full Var. Thus, in our experiment, the values of sampling cost and variance of estimation for sampling procedure Full Var are all 1. Furthermore, Figure 1 c sampling procedures From Figure 1 a pared with sampling procedures Var7, Var5 and Var3, Full Var has the lowest estimation variance and the highest sampling cost. From sampling procedures Var7, Var5, and Var3, we can see a pattern that the variance of estimation increases, and the sampling cost decreases consistently with the decrease of the weight for variance of estimation. At the largest sample size of k = 10, the estimation variance of sampling procedure Var3 is increased by 27% and the sampling cost is decreased by 40 compared with sampling procedure Full Var. The experiment shows that our method decreases the sampling cost ef?ciently by trading off a percent of variance of estimation. Similar to variance of estimation, the sampling accuracy of these procedures also decreases with the decrease of the weight on variance of estimation. For the largest sample size at k = 10, we can see that the AER of sampling procedure Var3 is increased by 20 compared with sampling procedure Full Var. However, for many users, increase of the AER will be acceptable, since the sampling cost is decreased by 40%. By setting the weights for sampling variance and sampling cost, users would be able to control the trade-off between the variance of estimation, sampling cost, and estimation accuracy In addition, compared with sampling procedure of Full Var Var7, Var5, and Var3, sampling procedure Random, has higher estimation of variance, sampling cost and lower estimation accuracy. Thus, our approach clearly results in more effective methods than using simple random sampling for data mining on the deep web Figure 2 shows the experiment result of our proposed strati?ed 


sampling methods on the Yahoo! data set. The size of pilot sample on this data set is 2,000, and the ?xed value x for sample size is 200. The results are similar to those from the US census dataset. We can still see the pattern of the variance of estimation increasing with the decrease of its weight. Besides, the sampling accuracy is also similar to the variance of estimation. However although the variance estimation of sampling procedure Random is 60% larger than sampling procedure Full Var, the sampling cost of Random is 2% smaller than Full Var. This is because Full Var does not consider sampling cost. It is possible that Full Var assigns a large sample to a stratum with low ?, which denotes the probability of containing data records under the space of A = a, resulting the larger sampling cost than that of simple random sampling. Sampling procedures Var7, Var5, Var3 consider sampling cost as well, and have smaller variance estimation and sampling cost, compared with Random. Furthermore, Random has smaller sampling accuracy than Full Var, Var7 and Var5, but has larger sampling accuracy than Var3. This is because Var3 assigns much more importance to the sampling cost, and loses accuracy to a large extent To summarize, our results shows that our proposed strati?ed sampling are clearly more effective than simple random sampling on the deep web. Moreover, our approach allows users to tradeoff variance of estimation and sampling accuracy to some extent while achieving a large reduction in sampling costs B. Differential Rule Mining In this section, we present results from experiments based on differential rule mining. Particularly, we look at the rules of the form A = a ? D1\(t t categorical attribute and t is an output numerical attribute, while other categorical attributes in the data set are considered as input attributes In this experiment, we also evaluate our proposed method with different weights assigned to variance of estimation and sampling cost. Five sampling procedures, Full Var, Var7, Var5,Var3 and Random, have same meanings with those in the experiments of association rule mining. Similarly, 50 rules are randomly selected from the datasets, and each of the 50 differential rules are reprocessed 100 times using 100 different \(pilot sample, sample iterations 5000 runs First, we evaluated the performance of these procedures on 


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



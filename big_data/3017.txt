The application of Association rule in Library system  JianWei Li JiaYing University Library Guangdong Province MeiZhou City, China Leejw2004@163.com PingHua Chen Computer College of Guangdong University of Technology Guangdong Province GuangZhou City, China phchen@gdut.edu.cn   With the constant development of modern library, the function of library has changed gradually. How to improve the utilization rate of library resources, how to serve the readers better, and how to play more active roles, all have been becoming the concrete task of library in future. The data mining of the books circulation and user needs in library automation system provided effective support for library management. Furthermore the strong association rules of all kinds of literature extracted from all reader's loan records help library to optimize resources and layout usefully, and provided personalized information services for readers directly as well as speculate the potential needs of users, which will be a good aim for serving readers Data mining; Association rule; Library system I  I NTRODUCTION  Data mining, also called Knowledge-Discovery in Databases \(KDD\process of automatically searching large volumes of the practical application data which is incomplete, noise, ambiguous and random for patterns  With the library information services have been included into international e-commerce, data mining is not only favored in businesses and financial analysts, but also it is increasingly used in library to extract information from the enormous data sets generated by the modern Library automation System. The application of data mining has become a focus of attention Data mining is a complex topic and has links with multiple core fields such as computer science and adds value to rich seminal computational techniques from statistics information retrieval, machine learning and pattern recognition. It could be divided into such as classifications or models according to the task of data mining: classification data summary, clustering, association rules, sequential pattern dependency, trends and so on The dependency rules fetched from large amounts of data by the association rules have certain credibility. APriori algorithm is a more mature algorithm by making full use of association rules, and it is clear and easy to be implemented II T HE ASSOCIATION RULES  From we can see that the de finition of association rules: for I K k=1,2,...,m\all items, I K k=1,2,...,m\. A collection of items is called itemsets. An itemsets having k items is called the kitemsets. An affairs T is an itemsets which is a subset of itemsets I, and every affairs have an identifier associated TID All different affairs constitute the affairs Set D, which constitute the affairs database necessary for Discovery of Association Rules. If itemsets said affairs T supports affairs X, also known as affairs T include affairs X Association Rules is a form of implication and and The property of association rules Correlates with 4 parameters: namely Support, Confidence Expected Confidence and Lift, and the support and Confidence can describe the nature of the association rules more directly A Support If the s% affairs of the affairs Set D support itemsets X or support itemsets Y, then the support of the association rules X Y is s%. Support described the frequency of the itemsets of X Y in all the affairs     Among them  means the number of elements in sets B Confidence If there are c% affairs in which support itemsets X support the itemsets Y at the same time in affairs Set D, then the Confidence of the association rules X => Y is c%. So confidence described the frequency of the itemsets X and Y in the affairs which support itemsets X 3 How to choose effective association rules is mainly based on the support and confidence. In accordance with the definition of association rules, the support measures the frequency of association rules in affairs database, and the confidence measures the strength of association rules In affairs database, the association rules can be extracted in any two itemsets. But people only interest in the association rules which meet a certain degree of support and Confidence in practical application. So itês necessary to determine the two thresholds: a minimum support \(minsup\inimum confidence \(minconf\n extracting the association rules. The association rules which meet the minimum support and 978-1-4244-35 31-9 08/$25.00©2008 IEEE 


confidence at the same time are the strong association rules. In the studies of association rules, the most famous algorithm is Apriori proposed by Agrawal III A PRIORI ALGORITHM  Apriori is the Classical algorithm of association rules proposed by Rakesh Agrawal and Rnamakrishnan Srikant in 1994, which also is the core of all association rules algorithm The processes of association rules will be divided into two partitions by Apriori algorithm: First, Access to all the frequent itemsets which meet the minimum support in affairs database; secondly extract all the strong association rules which meet the minimum confidence from the frequent Item  Fetching  the frequent Itemsets is the core issue for extracti ng association rules. An itemsets having k items is called the k-itemsets. If the itemsets meets the minimum support, then the itemsets is frequent itemsets. K-frequent itemsets are usually recorded as L k  Specifically: First of all, find out the frequent 1-itemsets recorded as L1; use of the L1 and then have a further option to set C2, on the C2 of the items excavated to determine L2 that is often 2-itemsets; This continuous cycle until it can not find more frequent k-of-date. L K each layer of excavation on the need to scan the entire database again Apriori found that frequent use of the level of circulating collection, algorithm follows L 1 find_frequent_1-itemsets \(D For \(k=2; L k-1 k C k apriori_gen \(L k-1 min_sup For each transaction t D {//scan D for counts C t subset \(C k t\of t that are candidates For each candidate c C t  c.count  L k c C k c.countmin_sup  Return L k L k    IV T HE ACTUAL DATA MINING IN LIBRARY SYSTEM  A Analysis of the relevance of the books Papers make full use of the real lending records of library automation systems in order to carry out data mining about the booksê relevance in library. First of all, seeking the 50 most popular books based on booksê lending statistics. In 2006, there are 5392 records related to the 50 most popular books after screening 125,586 detailed lending records, and then all these records are divided on the reader in order to form an affairs database, a total of 1988 affairs  Figure 1 Select the TOP 50 books SELECT TOP 50 CtrlNo, COUNT \(*\AS Count INTO BOOK_COUNT FROM DATAIN2006 GROUP BY CtrlNo ORDER BY Count DESC   Figure 2 Generated Data Item Tables SELECT * INTO DATAIN2006_TOP50 FROM DATAIN2006 WHERE CtrlNo IN \(SELECT CtrlNo FROM BOOK_COUNT  The stored procedure BOOK_PROC is used to achieve the process of translating data from the library loan records to the affairs tables. The codes follow  CREATE PROCEDURE BOOK_PROC AS DECLARE @ID VARCHAR\(255 DECLARE @MARC VARCHAR\(255 DELETE FROM LIBSYS_LEND_D INSERT INTO LIBSYS_ LEND_D\(TID DISTINCT CardNo FROM DATAIN2006_TOP50 DECLARE LENDCURSOR CURSOR FOR SELECT CardNo, CtrlNo FROM DATAIN2006_TOP50 OPEN LENDCURSOR FETCH NEXT FROM LENDCURSOR INTO @ID MARC WHILE \(@@FETCH_STATUS=0 BEGIN IF \(SELECT ITEM FROM LIBSYS_LEND_D WHERE TID=@ID  Detailed Loan records DATAIN2006  CtrlNo CardNo PName cDateLoan F200   Records of 50 books BOOK_COUNT  CtrlNo Count  Select The stored procedure BOOK_PROC Detailed Loan Records  DATAIN2006 Detailed Loan Records  DATAIN2006_TOP50 The affairs table  LENDITEM_TOP50 


UPDATE LIBSYS_LEND_D SET ITEM=@MARC WHERE TID=@ID ELSE UPDATE LIBSYS_LEND_D SET ITEM=ITEM MARC WHERE TID=@ID FETCH NEXT FROM LENDCURSOR INTO ID MARC END CLOSE LENDCURSOR DEALLOCATE LENDCURSOR GO The database required for extracting association rules have been constructed after data preparation process, as shown in Figure 3. TID is the identification number of affairs, and it is on behalf of the actual identification number of the readers ITEM is a set of affairs, and it is the collection of borrowing records  Figure 3 Item tables of books In the case of the minimum support is 0.2 percent and the minimum Confidence is 50 percent, a total of 7 rules are extracted by using Apriori algorithm to carry out data mining The results shown in Figure 4  Figure 4 Result of booksê association analysis Rule 7, as an example to analyze the rules Rule 7: 37247, 140271=>133213; support: 0.252 percent Confidence: 83.333 percent 37247,140271,1 33213 are the identification numbers of books. According to the numbers, the titles of the three books can be found, they are "Jin Yong's works set [m  Xuan Xia Ling du Yu [monogra Hua ng Yi", "The Complete Martial Arts Works of Jin Yong [com Yong". Rule 7 means that: there are more than 83.333 percent readers who borrow "Jin Yong's works set ""Xuan Xia Ling du Yu "at the same time will borrow "The Complete Martial Arts Works of Jin Yong". So the relevance of the three books is great B Analysis of the relevance of Chinese Library Classification\(CLC First, fetching the 10 most popular Sub CLC to carry out experiment based on booksê lending statistics  Figure 5 Counts of booksê Sub_CLC SELECT TOP 10 Sub_CLC, COUNT INTO Sub_CLC_COUNT FROM DATAIN2006 GROUP BY Sub_CLC ORDER BY Count DESC  In 2006, there are 70 23 records belonged to students of grade 2004 related to the 10 most popular Sub CLC after screening 125,586 detailed lending records  Figure 6 Records of booksê Sub_CLC SELECT CardNo, PName, DispName, F200, CLC Sub_CLC INTO Sub_CLC _04_2006 FROM DATAIN2006 WHERE Sub_CLC IN \(SELECT Sub_CLC FROM Sub_CLC_COUNT\AND RIGHT \(Grade, 2\04  All these 7023 records are divided on the reader in order to generate an affairs database about sub CLC, a total of 2356 Affairs  Figure 7 The item tables of booksê sub CLC In the case of the minimum support is 15 percent and the minimum Confidence is 50 percent, a total of 12 rules are extracted by using Apriori algorithm to carry out data mining The results shown in Figure 8  Figure 8 Result of booksê sub CLC association analysis Rule 8, as an example to analyze the rules Rule 8: TP, H3 => I2; support: 18.973% percent Confidence: 70.952% percent TP, H3 and I2 are the sub Chinese Library Classifications and the titles are "Automation & Computer technology Foreign languages", " Chinese literature". Rule 8 means that there are more than 70.952 percent readers who borrow books 


about "Automation & Computer technology" and "Foreign languages" at the same time will borrow books about "Chinese literature ". So the relevance of TP, H3 and I2 is great V T HE IMPLEMENTATION OF A SSOCIATION RULES IN LIBRARY  In traditional library, the decisions are subjective, onesided or blind most of the time because the decision-making rely on the experience, then they could not adapt to the development times   fied foc us decision-m aking information available could be extracted from a variety of internal and external information involved in the Library Information System data after processed and converted by data mining Data mining, whatês that could prevent errors caused by the lack of information in decision-making. Using data mining could provide strong support for the leadership to make scientific decisions A Access to utilization of documents, optimize the layout of the collection and improve resource utilization First of all, with these strong association rules of the booksê classification, the library can have good decisionmaking to achieve optimal allocation of resources and devices have reasonable and better procurement of all types of literature, and have rational distribution of stock and resources For example, Rule 2: K8, I2 => H3 \(support: 17.784% and Confidence: 70.777%\ule 2 means that: there are more than 70.777% percent readers who bo rrow books of K8 biography and I2 \(Chinese literature\the same time will borrow books of H3 \(commonly foreign languages\en these books should be arranged on adjacent position  while considering these types of books should be convenient for readers to borrow in order to speed up the circulation of books Secondly, the efficient procurement of books affecting the better operation of library system is the first key of library But now, most of booksê procurements are based on librariansê own wish usually, that is the procurements are lack of adequate survey of the booksê inventory and utilization, and are lack of readersê demand investigation. Whatês that causes the situation that no one interests in new books on shelves for months, even years, and what the readers really need is scarcity Taking the purchasing decision support system is lack in library into consideration, the structure of booksê collection and distribution in library should be optimized and adjusted by making use of data mining technology The data mining results showed that the general behavior characteristic of studentsê books borrowing in library is "large amount but a few kinds ". So the copies of the books which are relatively close with curriculum and have a strong relevance in category are necessary to increase Teachers in university required for a wide range of professional information for scientific research, so the books procurement for teachers should be ça few amount but large kindsé. For lack of funds, it is proposed to increase supplies of e-books which are more popular for readers. After all, e-books have a great price advantage contrast with paper books. If literary books are the reader's favorite boo ks, then the literary e-books can have more purchase. The books purchased by librarian who had a better understanding about the needs of readers, teaching and scientific research can be made the better use to reduce idle and to achieve goal-directed resource optimization B Access to the needs of readers, to provide personalized information services The traditional library has been in accordance with the concept of "waiting for readers", and the concept and models will no longer be able to adapt for the service of modern  collecting and processing information involving lots of acts of read ers in borrowing books, Data Mining identified the interests, habits, tend and demand of specific individuals or groups of readers, then inferred the next acts of the corresponding group or individual. So the specific services for the custom content can be supplied for them This personalized information services not only increase satisfaction of readers and get better use of resources, but also it is conducive to the libraryê further development compared to the passive service of "waiting for readers For example, while readers visiting the new information or bibliographic data which recommended by library in a timely manner, the strong association rules of books will promote related topics information for readers or guide readers to find information through tips in order to give books recommendation and to achieve better personal service. As an example Rule 7: 37247, 140271=>133213 \(support: 0.252 Confidence: 83.333%\brary recommended "Jin Yong's works set " and "Xuan Xia Ling du Yu " when readers borrow The Complete Martial Arts Works of Jin Yong", the recommendation will enhance the interest of readers as well as the loyalty to library. Although the reader's interest will change along with the development of the times, the library system have the ability to discover the latest needs of readers automatically with the application of data mining technology  R EFERENCES    Fan Ming, and Meng Xiao-Feng, The concept and te chnology o f data mining, Machinery Industry Press, Beijing, 2005  Zhu Ming, Data m i ning, China Science and Techno logy University Press, Hefei, 2002  Feng W e n The research and design of the data m i n i ng algorith m of   2004  W a ng Fang. The research and i m plem entation of the data m i ning algorithm of association rule mi  Normal University, 2004  Zhao Song. The im p r ovem ent and application of Apriori algorith m  D  Harbin Polytechnic University, 2006  Bao Chui-Mei W a ng Zun-Xin, a nd Bai Ru-Jian g, çData m i ning technology and its application in the libraryé, Journal of Intelligence, Xi An, 2004 \(09\, pp. 49- 51  Yuan Jun-Hua, an d Lin Yuan, çT he resea rch of custom i zation servic es model based on Push-technology é, Journal of Intelligence, Xi An, 2005 11\, pp. 75-77  


TABLE III D ATABASE WITH MEMBERSHIP VALUES  TID Age Salary Young M iddle Old Low Medium High 1 0.8 0.2 0 0.75 0.25 0 2 0.5 0.5 0 0 1 0 3 0.25 0.75 0 0.25 0.75 0 4 0 0.5 0.5 0 0.5 0.5 eter determining the degree of dependency on the iteration number In this paper  5 D GNP Structure for Association Ru l e Minin g GNP examines the attribute values of database tuples using judgment nodes and calculates the measurements of association rules using processing nodes 9 Attrib utes and their values correspond to judgment nodes and their judgments in GNP respectively Therefore the connections of judgment nodes are represented as association rules The measurements include support  conﬁdence and  2 value described in the next section Fig 7 shows an example of the connection of nodes in GNP for association rule mining P 1 is a processing node and is a starting point for calculating association rules Each processing node has an inherent numeric order  P 1  P 2   P s  and is connected to a judgment node Yes-side of the judgment node is connected to another judgment node Judgment nodes can be reused and shared with some other association rules because of GNP’s features No-side of the judgment node is connected to the next numbered processing node Fig 7 A connection of nodes in GNP for association rule mining In Fig 7 N is the number of total tuples and a  b  c and d are the numbers of tuples moving to Yes-side at each judgment node Once a GNP individual starts the searching for association rules the membership values are employed to determine the transition from one judgment node to another that is according to the membership value of the attribute A i described in section B the probability of selecting the judgment result Yes  No is calculated E Findin g Association Ru l es usin g GNP The number of kinds of the judgment node functions are equal to the number of attributes multiplied by the number of kinds of linguistic terms in a database For example supposing that we examine tuple 1  TID  in the judgment node of  A i is F iq  A i   a random number from the interval  is compared with the v alue calculated by F iq  A i   Then if the random number is smaller that the value the transition moves to Yes-side otherwise it moves to No-side If the examination of the connection from the starting point P s ends then GNP examines tuple 2  TID likewise Thus all tuples in the database will be examined The total number of tuples moving to Yes-side at each judgment node is calculated for every processing node which is a starting point for calculating association rules All GNP individuals are searched in parallel at the same time If Yes-side connection of judgment nodes continues and the number of the judgment nodes becomes a cutoff value maximum number of attributes in extracted association rules then Yes-side connection is transferred to the next processing node obligatorily F Measurements of the Association Ru l es usin g GNP Table IV shows the measurements such as support and conﬁdence of the association rules In Fig 7 and Table IV A 1 High,A 2 Low A 3 Mid and A 4 High are example of  A i is F iq  A i   where the membership functions have three kinds of linguistic terms such us Low Medium and High i.e  F i 1  Low  F i 2  Medium and F i 3  High  and A i is the fuzzy variable corresponding to attribute A i  The proposed method measures the signiﬁcance of associations via the  2 test for correlation used in classical statistics For example we are able to calculate the support of A 3 Mid and A 3 Mid  A 4 High  if we change the connection of P 1 node from A 1 High node to A 3 Mid node in Fig 7 We can repeat this like a chain operation in each generation Now we deﬁne important association rules by the ones which satisfy the following  2  2 min  5 support 012 sup min  6 Where  2 min and sup min are the minimum  2 and support values given by supervisors In this deﬁnition if the rule  X  Y  is important then X  Y  X  Y  X   Y Y  X Y  X  Y  X and  Y  X are also important rules If required we can also add conﬁdence to the deﬁnition The extracted association rules are stored in a pool all together through generations When an important rule is extracted by GNP the overlap of the attributes is checked and it is also checked whether an important rule is new or not i.e  whether it is already in the pool or not If the rule is new it is stored in the pool with its support  conﬁdence and  2  If the association rule is not new because the linguistic terms that describe the attributes are different from the ones of the association rule in the pool the association rule with higher  2 value is stored then the pool is updated in every generation and only important association rules with higher  2 values are stored See Fig 17 60 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 


TABLE IV S UPPORT AND CONFIDENCE OF ASSOCIATION RULES   association rules support conﬁdence A 1 High  A 2 Low b  N b  a A 1 High  A 2 Low  A 3 Mid c  N c  a A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  a A 1 High  A 2 Low  A 3 Mid c  N c  b A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  b A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  c Fig 8 The pool is updated generation by generation G Fitness of GNP Fitness of GNP is deﬁned by F   r  R   2  r   n ante  r   1  n con  r   1  new  r   7 The items are as follows R  set of sufﬁxes of extracted important association rules satisfying 5 and 6 in a GNP individual  2  r    2 value of the rule r  n ante  r   the number of attributes in the antecedent of the rule r  n con  r   the number of attributes in the consequent of the rule r   new  r   additional constant deﬁned by  new  r    new the rule r is new 0 the rule r has been already extracted 8  2  r   n ante  r   n con  r  and  new  r  are concerned with the importance complexity and novelty of the rule r  respectively H Genetic Operators of GNP The following genetic operators are executed to GNP individuals  Crossover Operator producing offspring from parents Uniform crossover is used Judgment nodes are selected as crossover nodes with the probability of P c  Two parents exchange the gene of the corresponding crossover nodes  Mutation-1 Operator that affects one individual The connection of the judgement nodes is changed by mutation rate of P m 1   Mutation-2 Operator that also affects one individual The function of the judgment nodes is changed by mutation rate P m 2  All GNP individuals in a population have the same number of judgment and processing nodes however the node with the same node number does not have the same function All the connections of the processing nodes are changed randomly in order to extract rules efﬁciently I Use of Acquired Information We can use the frequency of the attributes of all extracted rules or rules extracted in some of the latest generations when doing Mutation-2 We deﬁne the probability of selecting the attribute F iq  A i  for judgment nodes by the following P g iq  n g  F iq  A i   C  k  K  q  n g  F kq  A k   C   9 Where P g iq is the probability of selecting F iq  A i  using the information on the association rules extracted in the latest g generations n g  F iq  A i  is the frequency of the attribute F iq  A i  in the rules extracted in the latest g generations K is the set of sufﬁxes of attributes If no rules are extracted in the recent g generations then P g iq is equal to the inverse of the number of attributes C is a constant given by the supervisor Fig 9 shows the owchart of our proposed method VI S IMULATION R ESULTS The performance of the proposed method was evaluated by doing two simulations In simulation 1 the extraction of association rules is done by using xed parameters of the fuzzy membership functions that is they remain xed for all generations In simulation 2 the parameters of the fuzzy membership functions evolve by non uniform mutation in 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 17 6 1 


Fig 9 Flowchart of the GNP based data mining method order to get suitable parameters and increase the number of association rules stored in the pool All experiments were run on a real database that contains continuous attributes about VOCs Volatile Organic Compounds It consists of 10 attributes  A i  i 1  2  10  and 825 tuples In simulations the population size of GNP individuals is 120 The number of processing nodes and judgment nodes are 10 and 78 respectively We use 5   2 min  6.63 6  sup min 0  1  and 8   new  150  In addition the detailed conditions of extracting association rules in the simulations are as follows n ante  r  n con  r  012 6  n ante  r   5  n con  r   5  The probability of crossover and mutation are P c 15  78  P m 1 1  3 and P m 2 1  5 78 corresponds to the number of judgment nodes The number of changing the connections of the processing nodes at each generation is 5 The simulations were executed for 500 generations and 20 trials are studied here for all the experiments changing the random sequences All algorithms were coded in Java Experiments were done on a 1.50GHz Pentium M with 504MB RAM A Simu l ation 1 In this simulation when transforming each continuous attribute of the database into a fuzzy attribute the parameters    and  of the trapezoidal and triangular membership functions remain xed for all generations it means that for the transition from one judgment node to another in GNP individuals the xed membership functions are used for all generations As an illustration the original membership function for one attribute is shown in Fig 10 Fig 11 shows the number of association rules extracted in the pool It is shown from this gure that the number of rules increases gradually as the generation goes on However the performance is not so good compared with Simulation 2 where the membership functions are also evolved Fig 12 shows the average tness values of the GNP individuals They remain almost at the same level during all generations B Simu l ation 2 In this simulation the parameters    and  of the membership functions are evolved using non uniform mutation Fig 10 An example of the original fuzzy membership function Fig 11 Association rules stored in the pool when membership functions are xed Fig 12 Average tness value of GNP individuals when membership functions are xed it means that for the transition from one judgment node to another in GNP individuals evolved membership functions are used in every generation Fig 13 shows the number of association rules extracted in the pool while Fig 14 shows the average tness values of the GNP individuals It is found that both the number of rules extracted and the average tness value increased compared to Simulation 1 It shows that the evolution of the membership functions generation by generation is helpful for extracting many rules and for improving the performance of the GNP individuals’s tness value Fig 15 shows the evolved membership function of Fig 10 In this simulation the pool of the association rules is updated in every generation exchanging an association rule with lower  2 value for the same association rule with higher  2 value as a result association rules are stored with the parameters of the evolved membership functions 17 62 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 


Fig 13 Association rules stored in the pool when membership functions are evolved Fig 14 Average tness value of the GNP individuals when membership functions are evolved Fig 15 An example of the evolved fuzzy membership function VII C ONCLUSIONS AND F UTURE W ORK In this paper we have proposed an association rule mining algorithm based on Genetic Network Programming and Fuzzy Sets Theory to extract association rules from databases with continuous values Extracted association rules are stored in a pool all together through generations in order to nd new important rules The pool is also updated in every generation exchanging the same association rule with lower  2 value for higher  2 value These rules are reﬂected in genetic operators as acquired information Our method measures the signiﬁcance of association rules using conﬁdence support and  2 test We have performed experiments and estimated the performances of the proposed algorithm The results have shown that the proposed method extracts important association rules effectively in short time Adjusting the membership functions according to the frequency of the attributes stored in the pool in order to nd the most suitable parameters is our future work R EFERENCES  R Agra w al T  Imielinksi and A  S w ami Mining association rules between sets of items in large databases The 1993 ACM SIGMOD Conference pp 207-216 1993  R Agra w al T  Imielinksi and A  S w ami Database mining a p erfor mance perspective in The IEEE Transactions on Knowledge and Data Engineering Vol 5 No 6 pp 914-925 1993  I Graham and P  L  Jones Expert Systems Kno wledge Uncertainty and Decision Chapman and Computing Boston pp.117-158 1988  A Kandel Fuzzy Expert Systems CRC Press Boca Raton pp 8-19 1992  T  Eguchi K Hirasa w a  J  H u and N Ota  A study of Ev olutionary Multiagent Models Based on Symbiosis IEEE Trans on S y st Man and C y bernetics Part B  Vol.36 No.1 pp.179-193 2006  S Mab u  K  Hirasa w a and J Hu  A Graph-Based Ev olutionary Algorithm Genetic Network Programming and Its Extension Using Reinforcement Learning Evolutionary Computation MIT press Vol 15 No.3 2007  K Hirasa w a  M  Okubo H Katagiri J Hu and J Murata Comparison between Genetic Network Programming and Genetic Programming In Proc of Con g ress of E v o l utionar y Computation  pp.1276-1282 2001  K Shimada K Hirasa w a and J  Hu Genetic Netw ork Programming with Acquisition Mechanisms of Association Rules Journa l of Adv anced Computationa l Inte ll i g ence and Inte ll i g ent Informatics  Vol 10 No 1 pp.102-111 2006  K Shimada K Hirasa w a and J  Hu Class Association Rule Mining with Chi-Squared Test Using Genetic Network Programming In Proc of IEEE SMC 2006  pp.5338-5344 2006  C Zhang and S  Zhang Association Rule Mining models and algorithms Springer Sydney Australia 2002 pp 238  S Brin R Motw ani and C Silv erstein Be yond mark et bask ets generalizing association rules to correlations In Proc of the 1997 ACM SIGMOD Conf  pp.265-276 1997  R.J Miller and Y  Y ang Association rules o v er interv al data In Proc of ACM SIGMOD Conf Mana g ement of Data  1997  K Hirota and W  Pedrycz Linguistic data mining and fuzzy modelling Proc IEEE Internat Conf Fuzzy Systems Vol 1 1996  K.C.C Chan and W H Au An E f fecti v e Algorithm for Mining Interesting Quantitative Association Rules in Proc of the 12th ACM Symp on Applied Computing Feb 1997  K.C.C Chan and W H Au Mining Fuzzy Association Rules  i n Proc of the 6th ACM Int’l Conf on Information and Knowledge Management Las Vegas Nevada 1997  H Ishib uchi T  Nakashima T  Y a mamoto Fuzzy association rules for handling continuous attributes IEEE ISIE 2001  E Hullermeier and J Beringer  Mining implication-based fuzzy association rules in databases 2003 Elsevier  A Gyenesei Mining weighted association rules for fuzzy quantitati v e items TUCS Technical Report No 346 May 2000  A Gyenesei A fuzzy approach for mining quantitati v e association rules TUCS Technical Report March 2000  R Srikant and R  Agra w al Mining Quantitati v e Association Rules in Large Relational Tables Proc of ACM-SIGMOD Montreal Canada 1996  M Kaya and R Alhajj Genetic algorithm based frame w o rk for mining fuzzy association rules Elsevier 2004  T  P  Hong C H Chen Y  L W u and Y  C  Lee Mining membership functions and fuzzy association rules The 2003 Joint Conference on AI Fuzzy System and Grey System 2003  R Mendez F  V o znika A Freitas and J Nie v ola Disco v e ring Fuzzy Classiﬁcation Rules with Genetic Programming and Co-Evolution in Proc of the 5th European Conference on Principles of Data Mining and Knowledge Discovery PKDD 2001 LNAI 2168 pp 314-325 Springer Berlin 2001  M L y man and G  L e w ando wsk y  Genetic Programming for Association Rules on Card Sorting Data in Proc of the 2005 conference on Genetic and evolutionary computation GECCO 2005 pp 1551-1552 USA 2005  Z Michale wicz Genetic Algorithms  D ata Structures  E v olution Programs 3rd Edition Springer 1996 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 17 6 3 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 



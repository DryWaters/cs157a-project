Suggesting Software Components for Reuse in Search Engines Using Discovered Knowledge Techniques Alexandre Costa Martins Federal University of Pernambuco UFPE Reuse in Software Engineering RiSE Recife Brazil acm3@cin.ufe.br Vinicius Cardoso Garcia Federal University of Pernambuco UFPE Reuse in Software Engineering RiSE Recife Brazil vcg@cin.ufe.br Eduardo Santana de Almeida Reuse in Software Engineering RiSE Recife Brazil esa@rise.com.br Silvio Romero de Lemos Meira Federal University of Pernambuco UFPE Reuse in Software Engineering RiSE Recife Brazil srlm@cin.ufe.br Abstract The software reuse initiatives are better implemented when there is an ef\002cient way to 002nd the reusable assets However the search and retrieval of such information is considered a big deal in literature once there is a gap between what the software engineer would like to retrieve and what is stored in the repository Thus this paper presents an ef\002cient way to reduce this problem and aid search engines applying data mining techniques on log mechanisms to extract knowledge about the historic data In order to evaluate the results an initial experiment is also discussed Keywords software reuse search engines information retrieval data mining association rules I I NTRODUCTION Software reuse is the process of creating software systems from existing software rather than building them from scratch Hence when it is systematically per formed it presents bene\002ts such as improvements in timeto-market quality and costs reduction since it uses assets already tested certi\002ed and documented Ho we v er  to achieve success on reuse initiatives often it is necessary to provide an ef\002cient way to search and retrieve the assets since according to To reuse a software component you 002rst have to 002nd it  The literature presents some search and retrieval tools as pointed by Garcia et al to aid the reuse process However some research 15 sho w that the main obstacle with these tools is to retrieve a component that corresponds to the developer's need once there is a gap between the problem formulation in developer's mind and the component description in the repository Se v eral solutions 15 ha v e been proposed to attenuat e it However the user still needs to build queries every time and it is hard as also highlighted by Another problem is associated with the dependencies among the components since sometimes the returned assets do not solve the entire problem and the developer has to 002nd additional components to complement the entire solution Thus the dependencies are identi\002ed only on demand when the developer realizes it and tries to search for another component In this way this paper proposes an approach that uses data mining techniques to solve it by reducing the conceptual gap on the queries built The solution is based on the reduction of performed queries Thus the main goal is to optimize the component search and retrieval through its historic use which is monitored by a log mechanism such as 002le or database This work is part of the B.A.R.T Basic Asset Retrieval Tool  project whose main goal is to de v elop a robust tool to search and retrieve software components In this project we had experimented new trends related to search and retrieval such as active search conte xt  folksonomy 26 semantic 5 f acets 18 and Data Mining These ef forts ha v e presented initial 002ndings which stimulate the research in this direction Hence we believe that our approach is a complement solution for the previous approaches because the suggestions have no relations with a speci\002c technique of search i.e It can be used together II R ELATED W ORK In the literature some work propose different tools to aid the information search and retrieval CodeBroker presents a tool that 002nds asset about components that are relevant for activities realized in the same moment According to ad-hoc e v aluations presented that this type of strategy is effective to promote reuse It allows the exploration from a new style of collaboration between users and machines Based on the same concepts Strathcona uses softw are agents to implement an acti v e search mechanism to search source code examples and to aid the developers in the codi\002cation process It presents examples extracted of repositories based on six different heuristics The related work presented are associated with source code reuse based on search and retrieval Our approach complement these work allowing reuse based on the historic use We believe that the approaches are complementary and can be used together as we did with any search engine 
2009 35th Euromicro Conference on Software Engineering and Advanced Applications 978-0-7695-3784-9/09 $25.00 © 2009 IEEE DOI 10.1109/SEAA.2009.61 412 
2009 35th Euromicro Conference on Software Engineering and Advanced Applications 978-0-7695-3784-9/09 $26.00 © 2009 IEEE DOI 10.1109/SEAA.2009.61 412 


The use of association rules was experimented too in to improve search engines However the rules were used to suggest queries for users and its dataset was composed of almost 3 millions of lines from yahoo website III B.A.R.T S EARCH E NGINE According to the idea that reuse can be performed in a systematic way supported by an e n vir on m ent to aid in the software development process activities we constructed B.A.R.T  Basic Asset Retrieval Tool  B.A.R.T is a component search engine to aid the software engineer to 002nd component which implements the problem that needs to be solved B.A.R.T is based on the client-server architecture where the client side communicates to the server side through a web service layer The client side is represented by Eclipse and MS Word plug-ins besides a brand new web interface which searches reusable assets on the server side  Its architecture w as designed to be e xtensible by providing the capacity to add new features by including new components Initially this proposal concentrates its efforts only on an external client and in architectural modules of server side The basic modules which comprise the entire architecture are searcher retriever indexer 002lter and repository manager The main components of B.A.R.T are detailed next 017 Repository manager this module checkouts assets from Concurrent Version System CVS repositories on the Internet and maintains the entire repository scheme of the system It is also possible to schedule updates from previous checkouts in order to capture brand new assets 017 Filter after automatic checkout this module 002lters those assets which do not satisfy some conditions such as unnecessary extension and lack of documentation particularly applied to source codes 017 Indexer this module indexes the reuse repository and creates the index base which is essential for the search occurrence 017 Searcher this module is responsible for processing the user query and prepares it to seek the assets through the index base answering semantic constraints 017 Retriever after a successful search the user can download assets listed in the B.A.R.T client application This module is responsible for transferring them to the user directory or to a speci\002c Eclipse project The current version of B.A.R.T presents functionalities such as keyword semantic and folksonomy search Therefore a robust infrastructure was implemented to manage users extract statistics register logs and etc IV T HE M AIN R EQUIREMENTS Once presented the context of our tool we will discuss how apply the knowledge discovery techniques for software reuse For that some requirements were proposed These requirements are based on studies about existing solutions in the literature systematic analysis of reuse tools that aid the software development and our interaction with the industry in projects in this direction Thus the main speci\002ed requirements are 1  Suggest Associated Asset  This tool must be developed to suggest associated assets for the search engine users These associations are based on knowledge extraction of log 002les as exempli\002ed previously 2  Extract Association Rules  The associations mentioned previously are provided by association rules extraction This approach must extract the rules using well-de\002ned algorithms such as Apriori  Dynamic Itemset Counting DIC  and FP-Growth  3  Parser from Log Mechanisms Artifacts  The log mechanisms accepted by this tool are log 002les The knowledge extraction process uses these data to extract the rules 4  Provide a Visual Interface  The tool must provide an alternative interface to aid the user to assimilate the suggestions For this interface to become more intuitive it must be based on graphs V A RCHITECTURE S PECIFICATION AND THE O UTLINE OF I MPLEMENTATION The current architecture is divided in two modules Association Rules Extractor AR Extractor and Association Rules Viewer AR Viewer  The 002rst one is responsible for the knowledge extraction using log 002les whose 003ow is i parser the 002le and ii extract the association rules The second module is responsible for showing the results to the user These results are plotted as a graph and show the recommendations The inputs are a log mechanism result such as 1 002le or database and a 2 XML Descriptor  This XML describes the log structure and aids the log parser process Some con\002gurations such as limits of measures algorithm type are set by 3 Properties Con\002gurations and the result is a rule collection as a 4 XML result The result and search engine responses are received by the second module 5 AR Viewer  The viewer renders the results as a graph for the user The modules integrate an environment whose responsibility is to provide a better way to search and retrieve assets In Figure 1 the complete 003ow is showed The 002rst step is the query request by the user 1 using Remote Method Invocation RMI or Web Services WS connection Next the query is processed by the search engine 2 that uses the data from 002les localized in databases 002le systems or CVS This system usage generates a log that represents the real use of the search engine 3  Thus the AR Extractor uses this 002le to extract association rules 4 that will aid the user The 002nal result is the sum of the search engine response and the rules associated with it 5  The 002nal result is built by AR Viewer as a graph that presents the response of the user query and the suggestions 
413 
413 


Figure 1 Architecture and its interaction with the user An important issue is that it must be integrated with any search engine that uses a log 002le After this as shown in Section IV the algorithm can be changed and alternative implementations can be used A Association Rules Extractor The AR Extractor is divided in three sub-modules XML Descriptor Extractor  Algorithm Manager and XML Generator  as seen in Figure 2 The XML Descriptor is parsed and next the lines are grouped in transactions These transactions represent the 002les that each user downloaded in a speci\002c time window This number must be provided by search engines to demark the information collected in a time window Figure 2 Intern Architecture of AR Extractor Module In the Algorithm Manager  the data mining phase is processed and the algorithm is selected This choice depends on each situation as a distributed or singles databases and some characteristics must be analyzed such as performance CPU process memory usage and return time During the evaluation some rules are accepted and the others are left behind This step is important to improve the 002nal rules quality 1 Rule Filtering The extracted rules can have a lot of antecessors and successors in this composition Thus some rules must be pruned to simplify the suggestion and reduce the noise 017 Antecessor Quantity The rules that have two or less antecessors will be accept Rules with more than two antecessors are so complicated to the user and it causes more noises in the 002nal visualization Ex FileA.java FileB.java FileC.java  FileD.java 017 Successors Quantity The suggestions must be based in rules that have only one sucessor Ex FileA.java  FileD.java FileF.java B Association Rule Viewer The AR Viewer is detailed in Figure 3 and it has four sub-modules The Communication layer provides a way to connect the client and server side This layer was implemented using Web Services and RMI  The Interpreters Rules and Query Result are used to transform the XML returned from the server and prepare it to graph render This graph is provided by the last sub-module that will plot the result for the user Figure 3 AR Viewer Module Architecture In Figure 4 the graph represents a 002nal result The rectangles directly linked with central node describe the result query by the search engine The more extern rectangles show the suggestion a  If the user requests the query player then the system returns some 002les However if the user selects the 002le JMFPlayer.java to download the system suggests that the 002le AudioPlayerAdapter.java should be downloaded too 1  In the right of the Figure 4 two concepts of Visual Data Mining are used and the both were based on the tool called that pro vides a visualization of the 002elds of each node on demand a  In addition some controllers are provided to improve the interactivity and visualization such as graph rotation edge size adjust and nodes quantity c  The AR Viewer uses other important concept that tries to help the user This concept is related with the user interface and uses Visual Data Mining which is a visual channel to become the process more intuitive for humans  Another w ay to present the suggestions using a non intrusive mechanism is the simple text format In Figure 5 there is an example using B.A.R.T Search Engine where the suggestion 1 is represented in a text line This alternative solution cannot represent rules with two or more antecedents because this interface cannot show the interconnection among the results 
414 
414 


Figure 4 Example of resulted graph Figure 5 Example of suggestion on simple text format VI E VALUATION In this section we detail the achieved results of the experimental study performed in order to validate our tool The experiment was focused on the quality analysis of the generated rules to assure the suggestions quality Previous search and retrieval experiments of the RiSE group such as and 26 ha v e de\002nitely collaborated to this one In addition to the important points such as structure and the required issues to be analyzed the other points to be improved were also observed and tried to be overcame in this instantiation Both experiments  shared a common dataset or test database what in fact this is positive because they can show the evaluation of the search mechanisms with more con\002dence On the other hand over than 1000 Java 002les were utilized without total knowledge of the dataset By this reason for this experiment the number of classes in the dataset was reduced to 100 with the condition that each class should be properly analyzed classi\002ed and catalogued in standard dataset for future reuse 18 The experiment followed the guidelines de\002ned in which can be divided into the following main activities De\002nition  where the experiment is de\002ned in terms of problem objective and goals Planning  where the design of the experiment is determined the instrumentation is considered and the threats to the experiment are evaluated Operation  in which measurements are collected analyzed and evaluated in the analysis and interpretation  Finally the results are presented and packaged in the presentation and package  Each activity is detailed next A De\002nition Wohlin et al follo w the GQM Goal-QuestionMetric template for the goal de\002nition The GQM is based upon the assumption that for an organization to measure in a purposeful way it must 002rst specify the goals for itself and its projects then it must trace those goals to the data that are intended to de\002ne those goals operationally and 002nally provide a framework for interpreting the data with respect to the stated goals 1 Goal The goal of this experiment was to analyze the use of data mining techniques to improve search engines  In this way it was analyzed the quality of the 
415 
415 


generated rules for purpose of measure the effectiveness of our solution to generate suggestions This evaluation has the view point based on a software developer that using a search engine to reuse assets This experiment ran in the context of a in-house process in order to evolve the structure to make an industrial evaluation For this phase no subjects were used and the dataset was generated based on an heuristic to control the result and next evaluates its bene\002ts 2 Questions In order to achieve this goal several questions were de\002ned Q1 Is it possible generate suggestions using association rule approach Q2 When the amount of records increase the quality of generated rules increases too Q3 Does the time to process the rules and transactions depends on the used algorithm Q4 Does the response time of the search engine increases when our approach is enabled 3 Metrics The quality evaluation of the generated rules is based in objective measures explained in Section V-A The values are based using an empirical analysis about our dataset The support value analyzes the coverage of an speci\002c rule Thus the value of this metric must be close of 3 because the content of dataset is so heterogeneous The Con\002dence will analyze the rule strongness in this way the rules must be a high value and in our case we are using 50 Support The generated rules must be generated with minimum support equals to 3 Con\002dence The generated rules must be generated with minimum con\002dence equals to 50  Response Time The time to return the set of results for the user Extraction Time The time to extract the transactions and rules Correctness Percentage The correctness is evaluated using the sets generated before the datasets generation B Planning The experiment was executed off-line not in an industrial software development with no subjects Since the focus of this evaluation is the quality of generated rules the instruments used to validate were the data extracted during the experiment which was composed of generated data groups based on 100 java 002les as explained before Over this base were generated groups with 2 or 3 002les and 6 sceneries were designed For this experiment two types of data were analyzed The 002rst one is a Homogeneous data in this case it was used a regular time between the set of downloads 10 minutes second one is a heterogeneous case which was generated with a random time range from 1 until 10 minutes Based on these two base types 6 datasets were generated using the java 002les cited before 017 Scenery 1 Homogeneous and Small 2500 records 017 Scenery 2 Homogeneous and Medium 25000 records 017 Scenery 3 Homogeneous and Large 50000 records 017 Scenery 4 Heterogeneous and Small 2500 records 017 Scenery 5 Heterogeneous and Medium 25000 records 017 Scenery 6 Heterogeneous and Large 50000 records 1 Variables Selection Experiments usually employ a set of variables that link causes and effects for this experiment independent and dependent variables were taken into account 017 Independent variables are attributes actively manipulated when comparing different situations 017 Dependent variables are the outputs whose values are expected to change according to changes to the independent variables In the context of this experiment the independent variables refer to the dataset size and type homogeneous or heterogeneous and which algorithm was used to extract the transaction and the rules The dependent variables are the time to process the transactions and rules set percentage of and correctness for rules and transactions extracted and the response time This study evaluation was based on the following hypotheses 2 Null hypothesis It is the hypothesis that the experimenter wants to reject with as high signi\002cance as possible 1 Transaction Identi\002cation 017 H 0 a  026 The percentage of correct transaction identi\002cation is lower than 85 017 H 0 b  026 The percentage of execution time for the algorithm Kmean  is higher tha n the old algorithm by Time Window  017 H 0 c  026 The percentage of correctness for the algorithm Kmeans is lower than the old algorithm by Time Window  2 Rule Extraction 017 H 0 d  026 The percentage of correct suggestions is lower than 90 017 H 0 e  026 No rules are generated with con\002dence higher than 50 and support higher than 3 3 Execution Environment 017 H 0 f  026 The execution time with the suggestion mechanism enabled is 10 higher than without suggestions 3 Validity Threats In order to provide a set of valid results we de\002ned some threats to the validity of the experiment Internal validity depended upon the number of registered downloads and searches we assumed that the quantity and sceneries of the registreed downloads provided a good internal validity However we identi\002ed a conclusion validity related with a dataset as low statistical power because our dataset was generated and it is not a real dataset 
416 
416 


C Operation The experimental study was conducted in-house during October 1 2008 October 31 2008 at Federal University of Pernambuco Brazil For this experiment was used one computer with 2GB of RAM Core2Duo Processor\(1.73Ghz and 160GB of Hard disk As explained in Section VI-B six sceneries were speci\002ed and populated using as variation the algorithms for transaction identi\002cation and association rule extraction In this case were used 2500 25.000 and 50.000 records of downloads for homogneous and heteregeneous data In order to process these data was used the following algorithms 017 Transaction Identi\002cation K-means and Time Window 017 Association Rule Extraction FP-Grouwth and Apriori D Analysis and Interpretation This section describes the analysis and interpretation of the experimental study 1 Percentage of transaction identi\002cation correctness The average of the transaction identi\002cation correctness was 85,97 Thus this rejects the null hypothesis H 0 a as shows Figure 6 This is the evidence that the groups identi\002ed by the algorithms of transaction identi\002cation generates a good data to extract association rules Figure 6 Percentage of Transaction Identi\002cation Correctness 2 Percentage of Execution Time Comparison between Kmeans and Time Window Analyzing the results of the transaction identi\002cation execution time was possible to identify that the adaptation of Kmeans algorithm proposed in this work was in average 40 more faster than Time Windo Thus this rejects the null h ypothesis H 0 b as shows Figure 7 3 Percentage of correctness between Kmeans and Time Window The results of the transaction identi\002cations show that did not occur variation among the results Thus this rejects the null hypothesis H 0 c as shows Table I Figure 7 Time Window and Kmeans Time Execution Comparison seconds Table I T IME W INDOW AND K MEANS C ORRECTNESS C OMPARISON T imeW indow KM eans 85,82 86,12 4 Percentage of Correct Suggestions The generated rules presents 100 of correctness However it rejects the null hypothesis H 0 d  but is necessary more tests with a real dataset 5 Quantity of Generated Rules The results of the rule extraction show that the proposed minimum support and con\002dence in average generates 31 rules Thus this rejects the null hypothesis H 0 e as shows Figure 8 Figure 8 Quantity of Generated Rules per Type 6 Search Execution Time Analyzing the results of the execution time during the search was possible to identify that the response time between the search engine with and without suggestion did not present signi\002cant difference For this test were used 13 queries the average of the search with suggestion was 0.020 seconds and without suggestions was 0.019 Thus the difference was 5 and this rejects the null hypothesis H 0 e as shows the Figure 9 
417 
417 


Figure 9 Comparison of Search Execution Time E Lessons Learned After concluding the experimental study some aspects should be considered in order to repeat the experiment since they were seen as limitations of the 002rst execution Real World Data  Instead of uses a controlled dataset it is necessary obtains a real dataset in order to validate the rules In our case the transaction identi\002cation phase generated a set with 89  correctness and it generated rules with 100 of correctness However in a real environment with millions of log lines the results would be more precise Subjects  In order to evaluate the impact of our tool for the users the next experiment must have software engineers to evaluate the usability F Improvements The correctness of our proposed transaction identi\002cation algorithm needs improvement in its correctness The current version is so closer of Time Window Proposal but the time to extract in the Kmeans case was 40 lower VII C URRENT S TAGE Nowadays the 002rst version is under test phase in an industrial context at C.E.S.A.R 1  The B.A.R.T Search Engine is being used in this test phase through the interfaces presented in the Section V However the bene\002ts of an alternative interface based on graphs the AR Viewer  will be measured using the user feedback the amount of use of each interface type and downloads Both interfaces are available for all user testers VIII C ONCLUDING R EMARKS AND F UTURE W ORK Software reuse is a critical issue for companies to obtain the bene\002ts of costs and development time reduction However for software reuse to be disseminated in companies sometimes the use of tools as search engines is a viable solution This work proposed a way to improve the search engines avoiding unnecessary queries For this 1 Currently this company is CMMi level 3 and has about 700 employees http://www.cesar.org.br the log 002les were monitored to extract a historic pattern allowing to preview the searches However these data from log 002les are so raw and huge In order to solve it we use data mining techniques called association rules and clustering to aid the knowledge extraction since the data cleaning until the result evaluation The extracted knowledge was presented to user using an alternative way based on graphs to become the suggestions more intuitive However the normal vision as plain text was kept to reduce the introduction for components suggestion In addition an initial experiment was performed and it shows that there are some evidences that our tool can aid the search engines The most important evidence is the performance of transaction identi\002cation because the use of Kmeans to group the transactions resulted in 40 of time reduction However the correctness of this identi\002cation can be improved In order to conclude the efectiveness in an industrial environment a new experiment with a real and huge dataset must be executed We will integrate the AR Viewer on the developer environment In this way we will use a plug-in to Eclipse and Visual Studio to become the solution less intrusive since this environment very popular in companies A CKNOWLEDGMENT The authors would like to thank the Recife Center for Advanced Studies and Systems C.E.S.A.R Brazilian innovation institute that contributed with the evaluation of the mechanism This work is sponsored by Brazilian Agency CNPq process number 475743/2007-5 R EFERENCES   R Agrawal and R Srikant Fast algorithms for mining association rules in large databases In VLDB 94 Proceedings of the 20th International Conference on Very Large Data Bases  pages 487499 San Francisco CA USA 1994 Morgan Kaufmann Publishers Inc   V R Basili G Caldiera and H D Rombach The goal question metric approach In Encyclopedia of Software Engineering  Wiley 1994   S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data In SIGMOD 97 Proceedings of the 1997 ACM SIGMOD international conference on Management of data  pages 255264 New York NY USA 1997 ACM   R Cooley B Mobasher and J Srivastava Data preparation for mining world wide web browsing patterns Knowl Inf Syst  1\(1 1999   F A Dur  ao T A Vanderlei V C Garcia E S Almeida and S R de L Meira Applying a semantic layer in a source code search tool In SAC 08 Proceedings of the 23rd ACM symposium on Applied computing  Fortaleza CE Brazil 2007 ACM 
418 
418 


  B M Fonseca P B Golgher E S de Moura and N Ziviani Using association rules to discover search engines related queries In LA-WEB 03 Proceedings of the First Conference on Latin American Web Congress  page 66 Washington DC USA 2003 IEEE Computer Society   W B Frakes R P D  021az and C J Fox Dare Domain analysis and reuse environment Annals of Software Engineering  5:125141 1998   W B Frakes and S Isoda Success factors of systematic reuse IEEE Softw  11\(5 1994   V C Garcia E S de Almeida L B Lisboa A C Martins S R L Meira D Lucredio and R P de M Fortes Toward a code search engine based on the state-of-art and practice In APSEC 06 Proceedings of the XIII Asia Paci\002c Software Engineering Conference  pages 61 70 Washington DC USA 2006 IEEE Computer Society   V C Garcia D Lucr  edio F A Dur  ao E C R Santos E S de Almeida R P de Mattos Fortes and S R de Lemos Meira From speci\002cation to experimentation A software component search engine architecture In CBSE 06 Proceedings of the 9th International Symposium on Component-Based Software Engineering  pages 8297 2006   J Han J Pei and Y Yin Mining frequent patterns without candidate generation SIGMOD Rec  29\(2 2000   S Henninger An evolutionary approach to constructing effective software reuse repositories ACM Trans Softw Eng Methodol  6\(2 1997   R Holmes and G C Murphy Using structural context to recommend source code examples In ICSE 05 Proceedings of the 27th international conference on Software engineering  pages 117125 New York NY USA 2005 ACM   C W Krueger Software reuse ACM Comput Surv  24\(2 1992   D Lucredio A F do Prado and E S de Almeida A survey on software components search and retrieval In EUROMICRO 04 Proceedings of the 30th EUROMICRO Conference EUROMICRO'04  pages 152159 Washington DC USA 2004 IEEE Computer Society   A C Martins V C Garcia E S Almeida and S R L Meira Enhancing components search in a reuse environment using discovered knowledge techniques In 2nd Brazilian Symposium on Software Components Architectures and Reuse SBCARS  Porto Alegre Brazil 2008   J C C P Mascena S R de Lemos Meira E S de Almeida and V C Garcia Towards an effective integrated reuse environment In GPCE 06 Proceedings of the 5th international conference on Generative programming and component engineering  pages 95100 New York NY USA 2006 ACM   R C Mendes A search and retrieval of reusable source code using faceted classi\002cation approach Master's thesis Federal University of Pernambuco Brazil August 2008   H Mili A Mili S Yacoub and E Addy Reuse-based software engineering techniques organization and controls  Wiley-Interscience New York NY USA 2001   M C M Neto M Mendonc¸a and C A S Santos Graphminer Uma ferramenta de minerac  ao visual de dados em bases relacionais In Jornadas Iberoamericanas de Ingenier  021a del Software e Ingenier  021a del Conocimiento  pages 305316 Madrid Spain 2004   O Niggemann Visual Data Mining of Graph-Based Data  PhD thesis University of Paderborn 2001   P A Perry D and J L Votta Scalable parallel data mining for association rules In SIGMOD 97 Proceedings of the 1997 ACM SIGMOD international conference on Management of data  pages 277288 New York NY USA 1997 ACM   R Prieto-Diaz and P Freeman Classifying software for reusability IEEE Softw  4\(1 1987   E C R Santos F A Dur  ao A C Martins R Mendes B J M M Cassio A Melo V C Garcia E S de Almeida and S R L Meira Towards an effective context-aware proactive asset search and retrieval tool In WDBC 06 Proceedings of the 6th Workshop on Component-Based Development  pages 105112 December 1996   P.-N Tan M Steinbach and V Kumar Introduction to Data Mining First Edition  Addison-Wesley Longman Publishing Co Inc Boston MA USA 2005   T A Vanderlei a Frederico A Dur A C Martins V C Garcia E S Almeida and S R de L Meira A cooperative classi\002cation mechanism for search and retrieval software components In SAC 07 Proceedings of the 22nd ACM symposium on Applied computing  pages 866871 Seoul Korea 2007 ACM   M Vieira and D Richardson Analyzing dependencies in large component-based systems In ASE 02 Proceedings of the 17th IEEE international conference on Automated software engineering  page 241 Washington DC USA 2002 IEEE Computer Society   C Wohlin P Runeson M H  ost M C Ohlsson B Regnell and A Wessl  en Experimentation in software engineering an introduction  Kluwer Academic Publishers Norwell MA USA 2000   Y Ye and G Fischer Supporting reuse by delivering taskrelevant and personalized information In ICSE 02 Proceedings of the 24th International Conference on Software Engineering  pages 513523 New York NY USA 2002 ACM 
419 
419 


We consider the following access control constraints  exclusive/inclusive ordered pairs EOP Payment   Insurance  IOP BookHotel   BookFlight   disallowed delegation sequences  w 1 o 3  w 6 o 5  w 7 o 6   w 1 o 4  w 6 o 5  w 7 o 6   Obviously, the adjusted FSMs of both w 4 and w 5 contain no Book Hotel so as to preserve IOP, and w 6 has to be excluded due to its violation of EOP We called our approach Adjusted AR because it selects the performer of each task based on the aggregated reliabilities of the adjusted composition Adjusted AR is compared to two other approaches namely random and AR The random selection method randomly chooses a qualified performer for each task without checking access control constraints The AR selection method makes the performer selection based on the aggregated reliabilities of the original \(un-adjusted\mposition. For the two approaches, access control constraints are consulted only at the end of each execution to determine the success or failure of an execution instance To evaluate the performance of our proposed approach, we chose the success rate as the primary performance metric, which measures the ratio of the execution sequences whose tasks are all successfully delegated to and executed by component WSs without violating any access control constraint. For both AR and random methods, at the end of each execution, the specified access control constraints have to be verified. Thus, we also report for the two approaches the denial rate for EOP and IOP and the denial rate for disallowed delegation sequences. The former indicates the ratio of all execution sequences denied by the specified EOP/IOP constraints, while the later measures the ratio of all execution sequences violating some disallowed delegation sequences Our experiments ran on a PC with a Intel CoreDuo L2400 CPU\(1.66 GHz\d 1GB RAM running Windows XP professional. We randomly generated 10,000 execution sequences of the target workflow and assumed a fixed reliability probability for each operation or activity \(called delegation reliability\. Figure 15 shows the success rates of each algorithm under various delegation reliabilities. It can be seen that the success rates of Random and Adjust AR gradually increase with the delegation reliability and Adjusted AR has the highest success rates.  AR strategy has the lowest success rates when the delegation reliabilities are greater than 0.7, because the delegation that leads to the largest aggregated reliability tends to violate some access controls resulting in failed execution. This is justified by the observation shown in Figure 16 that AR has much higher EOP + IOP denial rates when the delegation reliabilities are greater than 0.7. Figure 17 shows that Adjusted AR has the lowest denial rates induced from the violation of disallowed delegation sequences   Figure 15. Success rates of the three methods across different delegation reliabilities   Figure 16. Denial rates due to the violation of exclusive/inclusive ordered pairs of the three methods  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


 Figure 17. Denial rates due to the violation of disallowed delegation sequences of the three methods  6. Conclusion  This paper investigates the problem of performer selection for each task in a workflow in presence of access control constraints. We proposed to use exclusive/inclusive ordered pairs and disallowed delegation sequences to model many types of access control constraints in the literature. The exclusive/inclusive ordered pairs are used to adjust the FSMs of component WSs and participants before composition. The disallowed delegation sequences are checked at runtime to enable the selection of a better performer for each task in the workflow The proposed approach is evaluated using synthetic data and is shown to result in the execution that is less likely to violate any specified access control constraints  The current approach involves the evaluation of the disallowed delegation sequences at runtime which could be time consuming. We are currently investigating more efficient methods for handling the disallowed delegation sequences. In addition, more experiments are needed to shed the light on the efficiency and other measures of the proposed approach in a more systematic way. Finally Incorporating access control with QoS measures other than reliability will be explored in the future  7. References    E. Bertin o, E. F e rrari, an d V. A t l u ri T h e  Specification and Enforcement of Authorization Constraints in Workflow Management Systems ACM Transactions on Information and System Security vol. 2  no. 1, 1999, pp. 65 - 104   E. Bertin o, J. C r a m pton a nd F. P a ci A cces s Control and Authorization Constraints for WSBPEL Proc  IEEE International Conference on Web Services \(ICWS 2006 2006, pp. 275 - 284   E. B e rtin o, A  C. Squ i cciarin i  I P a l o scia, an d L   Martino, "Ws-AC: A Fine Grained Access Control System for Web Services World Wide Web vol. 9  no. 2, 2006, pp. 143 - 171   R. B h atti, E. B e rtin o, an d A  Gh a f oor A T r u s tBased Context-Aware Access Control Model for Web-Services Distributed and Parallel Databases vol. 18  no. 1, 2005, pp. 83 - 105   E. C h ris t e n s e n  F   C u rbera, G. Meredith an d S   Weerawarana, "Web Services Description Language \(WSDL\ 1.1 http://www.w3.org/TR/wsdl Jun. 15, 2008, 2001 6  L  C l em en t   A  H a t ely   C   V  R i e g en  an d T  Rogers, "Universal Description Discovery Integration \(UDDI\Version 3.0.2 http://uddi.org/pubs/uddi-v3.0.2-20041019.htm  Jun. 15, 2008, 2004   J. C r am pton  A R e f e ren ce M o n itor f o r Work f l o w  Systems with Constrained Task Execution Proc  The tenth ACM symposium on Access control models and technologies Stockholm Sweden, 2005, pp. 38 - 47   M. Gu dg in M. Hadle y N. Men d elsoh n  J  J   Moreau, H. F. Nielsen, A. Karmarkar, and Y Lafon, "Simple Object Access Protocol \(SOAP 1.2 http://www.w3.org/TR/soap 2007 9  S  Y  H w a n g  E  P  L i m  C  H  L e e  a n d C  H   Chen, "On Composing a Reliable Composite Web Service: A Study of Dynamic Web Service Selection Proc  IEEE International Conference on Web Services \(ICWS 2007 2007, pp. 184 191   G. Nak o s a n d D. J o y n er Linear algebra with applications Brooks/Cole Pub. Co., 1998   R  S  S a n dhu E. J. C o y n e  H. L   F e ins t ei n  a n d C. E. Youman, "Role-based Access Control Models Computer vol. 29  no. 2, 1996, pp. 38 47 12  M  Sr iva t sa   A  I y e nga r  T  M i ka lse n  I   Rouvellou, and J. Yin, "An Access Control System for Web Service Compositions Proc  IEEE International Conference on Web Services ICWS 2007 2007, pp. 1-8   J T h om a s F  Paci, E. Be rtin o, an d P. Eu g s ter User Tasks and Access Control over Web Services Proc  IEEE International Conference on Web Services \(ICWS 2007 2007, pp. 60-69  T o l o n e G.J  A h n   T   Pai, an d S  P Hong   Access Control in Collaborative Systems ACM Computing Surveys vol. 37  no. 1, 2005, pp. 29 41  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


the following characteristics to maximize user experience in mobile advertising: 1 and suitable user interface maximizes user experience 2 communication between mobile marketer and consumer, 3 telecommunications platforms and also location based technologies. For mobile advertising to succeed business models that can capture the synergy of two existing industries, advertising and telecommunications, must be conceived. In any future sustainable business model, all players will have to reach a consensus on the structure of the system and on the importance of each player in that system [9]. The factors affecting the mobile advertising media are: 1 Players; key players and their roles, 2 relationship and cross media working in mobile advertising value chain, 3 regulation which place sets of rules for the collection and procession of location-based data  This paper delineates the results of an empirical study conducted to evaluate the strength of set of hypotheses around selected conceptual model. A five point Likert-Scale survey of a convenience sample of 115 Mobile marketing experts was conducted to help evaluate the hypotheses and statistical hypothesis testing techniques have been employed at 95 confidence level to evaluate the results. The paper also documents some valuable suggestions received from the mobile marketing expert community  The results of the survey have proven the conceptual model in the respective areas of Consumer Privacy, Purpose &amp; Performance Content Credibility and Customization Price Process &amp; Policy believe that this proposed Conceptual Model/Framework can serve as a solid base for the evaluation of the critical success factors for a marketworthy mobile advertising strategy  The main objective of this article was to explore mobile advertising?s challenges and future directions by evaluating factors that seem to influence mobile advertising. The theoretical contribution of this article lies in outlining the key factors of mobile advertising Author hopes that this article opens new dialogues on multiple unexamined issues concerning mobile advertising industry. The paper has addressed an important and topical subject, as there has not been sufficient empirical evidence to date to substantiate any of the theoretical models that have been proposed regarding the factors that influence the success of mobile advertising. This paper its conclusions will be a valuable contribution to the debates in academia  A potential extension of our research is to field this same set of survey  questions, \(which was fielded to mobile advertising experts for the sake of this paper be fielded to mobile phone consumers across different demographics in different countries to assess how the consumers? perceptions stack-rank against the experts opinions. The authors hopes that this article opens new dialogues on multiple unexamined issues concerning mobile advertising industry  6. References   1] Balasubramanian S., Peterson R. A. and Jarvenpaa, S. L Exploring the Implications of MCommerce for Markets and 


Exploring the Implications of MCommerce for Markets and Marketing", Journal of the Academy of Marketing Science 30\(4 2] Stewart D. W. and Pavlou, P. A. "From Consumer Response to Active Consumer: Measuring the Effectiveness of Interactive Media", Journal of the Academy of Marketing Science 30\(4 3] Bulander R., Decker M., Schiefer G., and Kolmel B Comparison of Different Approaches for Mobile Advertising? Proceedings of the 2nd IEEE  International Workshop on Mobile Commerce and Services \(WMCS '05 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7  IEEE Computer Society, Munich, Germany, July 2005. pp 174-182 4] Vatanparast R., Asil M. ?Factors Affecting the Use of Mobile Advertising? International Journal of Mobile Marketing, December 2007  Volume 2, No 2 5] Becker M. ?Effectiveness of Mobile Channel Additions and A Conceptual Model Detailing the Interaction of Influential Variables? access Nov. 2005 http://www.iloopmobile.com/news/mb_research_111705.htm access Jan 2007 6] Kotler P. "Marketing Management", Pearson Education Upper Saddle River, New Jersey, 2003 7] Koranteng J., ?ZAP! There?s no escaping the mobile ad Ad Age Global, January, Vol. 1, No. 5, 2001, p.9 8] Ogilvy D., "Confessions of an Advertising Man Ballantine Books, New York, 1963 9] Lepp  niemi M., Karjaluoto H., and Salo J., ?The success factors of mobile advertising value chain?, EBusiness Review IV, 2004 pp. 93-97 10] Duchnicky, R. L., and Kolers, P. A. \(1983 of text scrolled on video display terminals as a function of window size. Human Factors, 25, 683-692  11] Bauer H. H, Barnes S. J., Reichardt T. and Neumann M M., "Driving Consumer Acceptance of Mobile Marketing: A Theoretical Framework and Empirical Study," International Journal of Electronic Commerce, Vo. l6, No.3, 2005, pp 181-192 12] Koranteng J., ?ZAP! There?s no escaping the mobile ad?, Ad Age Global, January, Vol. 1, No. 5, 2001, p.9 13] Ogilvy D., "Confessions of an Advertising Man Ballantine Books, New York, 1963 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 pre></body></html 


acquisition of transport information by selecting OWLQoS documents which describe quality of Web services from a repository that contains 3 OWL-QoS documents discovered previously. Similar to the example in Figure 2, the Filter Schema FS1 is used to read and select appropriate OWL-QoS documents, and the Filter Schema FS2 to create new OWL-QoS documents for the place ?OWL-QoS document?. As Filter Schema provides no means for formulating inequality operators like ?&gt;? and ?&lt;=?, which are usually used to express constraints with parameters whose quantitative values are limited to a certain interval, transition inscriptions Figure 4. XML net for Web service discovery Figure 5. Filter Schemas for Web service discovery definitions 1 service name: \\s*flight\\s*/i c definitions service name: \\s*train\\s*/i b a definitions 1 1 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 can be used in combination with Filter Schemas to formulate QoS constrains Suppose that the traveler wants to use only the Web services that cost no more than 100 US Cent. The Filter Schema FS1 should then be created as shown in Figure 7. The variable of the attribute filter ?rdf: resource? of the element filter ?owl: onProperty? is instantiated with a regular expression to filter OWL-QoS documents specifying the property ?costUSCent?. To ensure that the maximal cost of the Web service doesn?t exceed 100 US cent, the inscription of the transition ?select transport info service? should be formulated as owl:maxCardinality &lt;= 100?. In process simulation or execution, the inscription is parsed and integrated into XQuery statements using XPath inequality operators  6. Conclusions  In this paper we presented a WSC method based on XML nets, which inherit advantages of Petri nets such as formal semantics and graphical expression. XML nets have additional strengths in the description of process and data objects, and the exchange of XMLbased structured data. The advantage of using XML nets for WSC is that control flow modeling, data and data flow modeling, and WS discovery and selection can be realized using a uniform powerful modeling language. Some uncomplicated tasks, as illustrated before, can be fulfilled without developing or using additional software components or agents. Naturally XML nets can also be combined with other Web service techniques to fulfill more complicated and demanding tasks  7. Acknowledgement  The authors would like to thank the anonymous referees for many valuable comments on an earlier version of this paper  8. References  1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching 


1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching Web Service Coordination and Composition by Means of Petri Nets: the Case of the Nets-within-Nets Paradigm?, ICSOC 2005, LNCS 3826, pp.185-197, 2005 2] M. ter Beek, A. Bucchiarone, and S. Gnesi, ?Web Service Composition Approaches: From Industrial Standards to Formal Methods?, Second International Conference on Internet and Web Applications and Services \(ICIW?07 Computer Society, 2007 3] X.N. Feng, Q. Liu, and Z. Wang, ?A Web Service Composition Modeling and Evaluation Method Used Petri Net?, LNCS Volume 3842/2006, pp. 905-911, SpringerVerlag, 2006 4] H. Foster, S. Uchitel, J. Magee, and J. Kramer, ?Modelbased verification of Web Service Compositions?, 18th IEEE International Conference on Automated Software Engineering, pp. 152- 161, 2003 5] X. Fu, T. Bultan, and J.W. Su, ?Analysis of Interacting BPEL Web Services?, WWW2004, pp. 17-22, New York USA, May 2004 6] J.D. Ge, H.Y. Hu, P. Lu, H. Hu, and J. L  Translation of Nets Within Nets in Cross-Organizational Software Process Modeling?, SPW 2005, LNCS 3840, pp. 60-375 Springer-Verlag, 2005 7] Group for program system, faculty of Information Technique University Dortmund, ?PDDL?, http://ls5www.cs.uni-dortmund.de/~edelkamp/ipc-4/pddl.html 8] R. Hamadi and B. Benatallah, ?A Petri Net-based Model for Web Service Composition?, Fourteenth Australasian Database Conference \(ADC2003 CRPIT, Vol. 17, pp. 191-200, 2003 9] S. Hinz, K. Schmidt, and C. Stahl, ?Transforming BPEL to Petri Nets?, BPM 2005, LNCS 3649, pp. 220?235, Springer-Verlag, 2005 10] H. Kang, X.L. Yang, and S.M. Yuan, ?Modeling and verification of Web Services Composition based on CPN 2007 IFIP International Conference on Network and Parallel Computing-Workshops, pp. 613-617, 2007 11] H.M. Kim, A. Sengupta, and J. Evermann, "MOQ: Web Services Ontologies for QOS and General Quality EvaluaFigure 6. XML net for Web service selection Figure 7. Filter Schema for QoS-aware WS selection owl:Ontology owl:Class rdfs:subClassOf owl:Restriction rdf :resource : "\\s+#costUSCent owl:onProperty owl:maxCardinality   rdf:RDF Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 tions", European Conference on Information Systems \(ECIS 2005 12] S. Klink, Y. Li, and A. Oberweis, "INCOME2010 - a Toolset for Developing Process-Oriented Information Systems Based on Petri Nets", International Workshop on Petri Nets Tools and APplications \(PNTAP 2008, associated to SIMUTools 2008 March 2008 13] O. Kluge, ?Petri nets as a Semantic Model for message Sequence Chart Specifications?, proceedings of INT 2002 pp. 138-147, 2002 14] K. Lenz and A. Oberweis, ?Inter-Organizational Business Process Management with XML Nets?, H. Ehrig, W Reisig, G. Rozenberg, H. Weber \(Eds gy for Communication Based Systems, LNCS 2472, pp. 243263, Springer-Verlag, 2003 15] K. Lenz and A. Oberweis, "Workflow Services: A Petri Net-Based Approach to Web Services", Int. Symposium on Leveraging Applications of Formal Methods, pp. 35-42, Pa 


Leveraging Applications of Formal Methods, pp. 35-42, Paphos/Cyprus, November 2004 16] L. Lin and I.B. Arpinar, ?Discovery of Semantic Relations between Web Services?, IEEE International Conference on Web Services \(ICWS?06 17] Q. Lin, J.D. Ge, H. Hu, and J. Lu, ?An Approach to Model Cross-Organizational Processes using Object Petri net?, 2007 IEEE Congress on Services \(SERVICES 2007 pp. 146-152, July 2007 18] H. Ludwig, A. Keller, A. Dan, R. P. King, and R Franck, ?Web Service level Agreement \(WSLA Specification version 1.0?, IBM, 2003 19] N. Lohmann, P. Massuthe, C. Stahl, and D. Weinberg Analyzing Interacting BPEL Process?, S. Dustdar, J.L. Fiadeiro, and A. Sheth \(Eds 32, Springer-Verlag, 2006 20] S.A. Mcllraith and T.C. Son, ?Adapting Golog for Composition of Semantic Web Services?, 8th International Conference on Knowledge Representation and Reasoning KR2002 21] S.A. Mcllraith, T.C. Son, and H.L. Zeng, ?Semantic Web Services?, IEEE Intelligent Systems, March/April 2001 16\(2 22] N. Milanovic and M. Malek, ?Current Solution for Web Service Composition?, IEEE Internet Computing, NovemberDecember 2004 23] S. Narayanan and S.A. Mcllraith, ?Simulation, Verification and Automated Composition of Web Service?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 24] The Organization for the Advancement of Structured Information Standards \(OASIS Process Execution Language Version 2.0?, 11 April, 2007 http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.pdf 25] S.R. Ponnekanti and A. Fox, ?SWORD: a Developer Toolkit for Web Services Composition?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 26] Z.Z. Qian, S.L. Lu, and L. Xie, ?Colored Petri Nets Based Automatic Service Composition?, 2007 IEEE AsiaPacific Services Computing Conference, pp. 431-438, 2007 27] C. Ouyang, E. Verbeek, W.M.P. van der Aalst, S. Breutel1, M. Dumas1, and A.H.M. ter Hofstede1, ?Formal semantics and analysis of Control flow in WS-BPEL?, BPM center Technical Report, BPM-05-15, 2005 28] J.H. Rao and X.M. Su, ?A Survey of Automated Web Service Composition Methods?, SWSWPC 2004, LNCS 3387, pp. 43-54, Springer-Verlag, 2005 29] J.H. Rao, P. Kuegas, and M. Matskin, ?Application of Linear Logic to Web Service Composition?, 1st International Conference on Web Services, Las Vegas, USA, June 2003 30] J.H. Rao, P. Kuegas, and M. Matskin, ?Logic-based Web Services Composition: From Service Description to Process Model?, 2004 International Conference on Web Services, pp.446-453, San Diego, USA, July 2004 31] M. Sgroi, A. Kondratyev, Y. Watanabe, L. Lavagno and A. Sangiovanni-Vincentelli, ?Synthesis of Petri Nets from Message Sequence Charts Specifications for Protocol Design?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp. 193-199, 2004 32] W.M.P. Van der Aalst, "The Application of Petri Nets to Workflow Management", The Journal of Circuits, Systems and Computers, 8\(1 33] The World Wide Web Consortium \(W3C Semantic Markup for Web Services?, 22 November, 2004 http://www.w3.org/Submission/OWL-S 34] The World Wide Web Consortium \(W3C vices Choreography Description Language Version 1.0?, 17 December, 2004, http://www.w3.org/TR/2004/WD-ws-cdl10-20041217 35] The World Wide Web Consortium \(W3C vice Choreography Interface \(WSCI 


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






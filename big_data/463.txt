Two Satellites Positioning Algorithm Based on AGPS System with Two Clock Bias Ji-zhong LI School of Mathematics and Information Science Qingdao Agricultural University Qingdao 266109, China apanther@163.com Abstract Assisted Global Positioning System \(AGPS structure is used and Marquardt algorithm with additional earth ellipsoid equation is put forward in order to position and improve the positioning accuracy when only two satellites are captured intermittently in weak signal condition for global positioning system \(GPS\ positioning data through General Packet Radio Service \(GPRS\ork Positioning can be achieved when two satellites signals are captured twice between a short time. The big errors caused in solving the singular equation groups with Gauss-Newton algorithm can be remove by using Marquardt algorithm. In this algorithm, growth factor is used and adaptively adjusts the step according to the change of objective function. Compared to Gauss-Newton algorithm, the mean positioning bias decreases from about 500m to about 120m and there is less than 1.5 times computation in creasing in Marquardt algorithm Keywords- navigation principle; assisted Global positioning system; positioning algorithm; positioning accuracy computation I I NTRODUCTION In 1994, The Federal Aviation Agency \(FAA\declared Global positioning system \(GPS ready for aviation use. It can provide positioning, veloc ity and timing service for arbitrary multi-user in Ref. [1 essfully applie d in many subjects, such as navigation, meteorological monitoring, lithosphere mon itoring, resources survey geodynamics and agriculture in Ref. [2]. Its application is continuously enlarging along th e endless improvement of the system and the perfection of software and hardware To get the location, traditional positioning algorithm needs to observe four or mo re satellites' sig  to be received besides satellite synchronous si gnal. This causes that time to first fix \(TTFF\which is mo re than 2~3 minutes and the location canêt be solv ed if satellite signal canêt be captured continuously so that the full satellite data to position canêt be achieved in th is period. Currently, mobile station \(MS\ is no-full-sky view in many circumstances and location canêt be solved with measured satellites. The phenomenon to capture two satellites in short time often appears. This causes 1 information to calculate satellite location isnêt obt ained, 2\ are constituted with measured data and MSê three dimensional coordinates canêt be solved. Reference  researched that at least one satellite signal was captured so that the clock bias was same in two measurements, otherwise it is impossible to position This paper researched two satellite positioning algorithm when MS only captured two satellitesê signal in short time The positioning stru cture was chosen according to that circumstance. Then the solvi ng equation group was constituted with earth ellipsoid equation according to two satellite signal synchronized and MS location was solved with Marquardt algorithm. Finally, the positioning result was analyzed II AGPS SYSTEM Continuous positioning and tracking can be realized when the received satellites is enough in current positioning system. New positioni ng structure process, which is called the AGPS structure proposed, are designed to guarantee the positioning function and to overcome the above-mentioned problems, such as continuously receiving and long TTFF, as shown in Figure 1. Satellites signals are captured by both serving mobile location cen ter \(SMLC MS\nformation transmits throug h wireless network in the system so that no new communication environment is needed to constitute. Data comm unication is transmitted by using general packet radio se rvice \(GPRS\ between SMLC and MS. The auxiliary data is p acked and transmitted on secure user plane location \(SUPL location protocol \(RRLP  and Ref. [6 SMLC provides the auxiliary da ta which could speed up the capture of satellites signals and the corresponding ephemeris data for AGPS positioning. In a single location, the position request is sent from the receiver to the main control server in order to speed up the capture of satellites signals and to reduce the positioning time, so that a-fe w-minutesê waiting-time is no longer needed. In a conti nuous location of weak signal condition where satellites signals canêt be received continuously, the receiver could receive the ephemeris data from SMLC instead of the satellites to achieve positioning V2-416 978-1-4244-6349-7/10/$26.00 c  2010 IEEE 


 2. RRLP\(Measure Position Request 3. RRLP\(Protocol Error 4. PPLP\(Measure Position Response 4. RRLP\(Measure Position Reponse SMLC MS 1. Assistance Data Delivery Procedure Figure 1 Position me asurement procedure The satellite signal should be very weak when only two satellitesê signal is received in MS location. AGPS system aids to capture satellite signal and to provide auxiliary data to quicken the speed of capture. Satellite signal is captured by MS only in two moments of a certain time lag and MS neednêt receive ephemeris. This can realize positioning III M ARQUARDT POSITIONING ALGORITHM Two equations could be set out according to satellite coordinate   iii SSS x yz i S calculated by satellite ephemeris and MS coordinate   x yz R Two measures and earth ellipse equation constitute five equations 1 2 222 5 222      1 2      3 4  1  i i i i ftri ftri xyz f ah ah bh     i i XSR  XSR  X i  Where iii i sv rQt I P   is the pseudorange to the ith satellite  and respectively clock bias in MS and in satellite i Q 1 t 2 t i SV t ii I P respectively the bias in ionosphere and troposphere h the height of MS. There are five unknowns 12     T x yz t X t in the approximation above, the three components of MS location   x yz R and the ranges  derived from MS clock bias 1 t 2 t The objective function could be derived from above formula  5 2 1   i i Ff XX The location was solved trad itionally with Gauss-Newton  Marquardt algorithm   s  research The steps of positioning algorithm are as following 1 The initial location 1 1 1 1 1 1 12  x yztt X is base station \(BS 000   x yz R and clock bias is zero. The initial parameter is  increasing factor 1 0 1 and permissible error 0  Calculate , in which 1  F X  1 1 k  2 Set   then calculate     15       kk k ff L fX X T      11111 12      55555 12   kkkkk kkkkk fffff xyzt t fffff xyzt t    M k XXXXX  A XXXXX   3 Solve equation    Tk kk k  Tk A AId Af  Obtain the direction let  k d  1   kk XXd k  4 Calculate . If then go to step 6, otherwise to step 5 1  k F X 1   kk FF XX 5 If  Tk k Af then stop calculating and achieve solution 1 k X X Otherwise, set  and go to step 3 6 If  Tk k Af then  stop calculating and achieve solution 1 k X X Otherwise, set 1 kk and go to step 2 The parameter valu es in the solving were 1 0.1 10 0.1  IV P OSITIONING ALGORITHM PERFORMANCE A Theory analysis The direction was solved with formula  k d 7\ in GaussNewton Volume 2 2010 2nd International Conference on Computer Engineering and Technology V2-417 


  Tk T kk k k A Ad A f  Two equations have strong rela tivity which are obtained from same satelli te in a short period when location is solved with two satellites, so that this makes equation group ill   The bias of ionosph ere, troposphere and satellite clock bias will cause the small bias of k f The bias of ephemeris will do the small bias of k A  ge error in ill equation group. So Marquardt algorithm shown in formula 8\d    Tk kk k k  Tk A AId Af  k is a positive real number is Gauss-Newton direction when and inverse  k d 0 k 1  T kk k A AI depends on k I so that closes to the steepest descent direction of in point  k d  F X k X when k is sufficiently large. When the direction determined by formula 0  k   k d 8\is between Gauss-Newton direction and steepest descent. Therefore k value is too small not to ensure to be descent direction and  k d k is too large to slow convergence speed. The choice of k will consider both descent direction and convergence speed. In this research fluctuant k method is adopted in step 2 and step 5 in which the change of k depends on the descent of until   k F X    Tk k Af  B Positioning accuracy analysis The positioning device is designed independently and innovatively with SIM508 chip of SiRF company. The auxiliary data is provided by SiRF company. The average value of positioning result with NovAtel high performance receiver is 39.959103∞ latitude, 116.352853∞ longitude and 56.23 m height. They are taken as the reference value of real location. According to the real height, eleven height values were chosen which is respectivel y -44m, 16, 36, 46, 51, 56 61, 66, 76, 96 and 156m. These heights are about 0m, 5, 10 20, 40, 100m from the real hei ght. The bias statistics tables of 300 positioning results are list in TABLE I.  and TABLE II in which respectively adopted Gauss-Newton algorithm and Marquardt and the interval is 2 min in two measures It is concluded from TABLE I.  and TABLE II. that the positioning accuracy with Marquardt algorithm has large increase compared with that with Gauss-Newton. When initial height is close to real height, the positioning bias decreased to about 120m from about 500m and positioning bias cut-off 90% decreased to about 300m from about 1300m Because the positioning statistics result with height above real height is basically the same with height below the height the mean bias of time interval measured as 2min, 4,6,8min are list in Figure 2. and Figure 3. only when heights are respectively 56m, 76, 96 and 156m TABLE I B IAS STATISTICS TABLE WITH G AUSS N EWTON ALGORITH  M H/m 90 80 70 60 50 mean 44 16 36 46 51 56 61 66 76 96 156 1305.26 1274.25 1279.76 1301.80 1304.35 1308.10 1314.19 1318.35 1326.59 1334.00 1394.83 841.46 827.43 799.28 798.31 802.88 805.94 804.12 810.82 822.34 840.15 941.79 566.96 568.89 583.48 576.50 569.78 580.64 591.48 590.13 591.21 601.51 643.06 460.11 405.30 394.51 398.42 393.33 399.55 397.07 399.19 398.70 405.01 414.26 326.79 298.37 299.47 288.30 283.60 288.28 280.21 280.16 276.11 276.84 309.28 539.46 502.20 495.78 494.31 493.95 493.84 494.04 494.58 496.01 500.36 529.42 TABLE II B IAS STATISTICS TABLE WITH M ARQUARDT ALGORITHM  M H/m 90 80 70 60 50 mean 44 16 36 46 51 56 61 66 76 96 156 302.19 228.61 214.88 222.47 223.53 186.54 202.11 224.62 224.51 238.51 242.25 250.95 190.94 175.10 177.60 178.53 160.57 178.01 178.61 178.08 193.97 195.83 210.62 162.81 146.58 150.45 152.91 146.59 155.75 153.48 154.29 161.60 164.25 172.38 140.52 130.49 131.99 133.77 123.30 131.09 134.09 133.30 138.75 138.64 142.42 121.82 112.82 115.11 114.20 108.34 113.84 113.57 112.52 117.57 118.28 157.11 126.76 119.00 118.91 119.25 110.79 116.90 118.91 119.00 128.31 128.58 As are shown in Figure 2 and Figure 3. , measured time interval is shorter and the improvement of positioning accuracy is larger. When the interval is 2min, two previous equations constituted by two satellites have large relativity to behind two equations by the same two satellites so this causes equation group ill. In this circumstance, the validity of solving ill equation group with Marquardt algorithm had shown in which positioning accuracy had large improvement V2-418 2010 2nd International Conference on Computer Engineering and Technology Volume 2 


 2 4 6 8 0 200 400 600   height: 56m mean bias/m Gauss-Newton  Marquardt  2 4 6 8 0 200 400 600   height: 76m interval time min mean/m Gauss-Newton  Marquardt  Figure 2 The positioning mean bias of different measurement interval when height as 56m and 76m 2 4 6 8 0 200 400 600   height: 96m mean bias/m Gauss-Newton  Marquardt  2 4 6 8 0 200 400 600   height: 156m interval time/min mean bias/m Gauss-Newton  Marquardt  Figure 3 The positioning mean bias of different measurement interval when height as 96m and 156m C Algorithm computation analysis Compared Marquardt algorithm with Gauss-Newton one the calculating process of variable factor k and the additive process in formula 5\his calculation is very little in all solution so th at it is negligible Therefore the computation depended on the iterative times of algorithm chosen. The mean iterative times were shown in TABLE III. when the time interval of two measures was 2min and the height was chosen as different value As can be seen from TABLE III. , the computation of Gauss-Newton algorithm is same and the computation of Marquardt algorithm is little different which increases less than 1.5 times in contrast with Gauss-Newton algorithm TABLE III T HE MEAN ITERATIVE TIMES OF POSITIONING ALGORITHM algorithm 56m 76m 96m 156m Gauss-Newton Marquardt computation ratio 2.000 2.783 1.392 2.000 2.877 1.439 2.000 2.690 1.345 2.000 2.810 1.405 V C ONCLUSION We can see from positioning result and analysis that the positioning result with Marquardt algorithm is far more accurate than with Gauss-Newton algorithm when two measurements are processed in short time and only two satellites can be measured in every measurement. The largest mean positioning bias is about 1 20m. It is difficult that receiver directly receives data transmitted by satellites when two satellites are observed every time and the satellites signal is very weak in no-fu ll-sky view. In this circumstances AGPS positioning method is adopted in which auxiliary data can be achieved from server and enhance receiver capturing ability to satellite signal to quicken capturing speed. Link earth ellipse equation to constitu te equation group and solve location with Marquardt algorithm. This improves positioning accuracy at large extent. The positioning accuracy could meet the function to inquiry service based location so that improve GPS positioning function R EFERENCES  Dziadczyk E, Za bierowski W, N a pieralski A Satel lite Navigation System GPS // CADSMê2007. Piscataway: IEEE, Feb 2007: 504 506  Hegarty C J, Cha tre E. Evolati on of the global navigation satellite  system \(GNSS\roceeding of the IEEE, 2008, 96\(12  GPS Navstar J o int Program  Office Navstar GPS Space Segment/Navigation User Interfaces IS-GPS-200, Re GPS Navstar Joint Program Office, El Segundo, CA, Dec 7, 2004  Jizhong LI, Muq ing W U Xiaoye LI. Two satellit es positioning method of AGPS with Marquardt algorithm. Journal of Beijing university of posts and telecommunications 2009, 32\(2\: 39-42,61  Tolga G, Ozgun B  Secure User-Plan e Location \(SUPL For Assisted GPS \(A-GPS\: IEEE, August 2008: 229-234  European Telecomm u nications Sta ndards Institute TS 144 031 V6.7.0[S]. France: ETSI, Jan, 2005  Dailey D J, Bell B M. A m e thod for GPS positioning[J]. Aerospace  and Electronic Systems, 1996, 32\(3\:1148-1154  Baolin CHEN, Op tim ization theory  and algorith m s 2n d ed. Beijing China: Tsinghua university press, 2005\(in Chinese  Dem m el J W. Ap plied nu m e ri cal linear algebra. Guorong W ANG trans. Beijing, China: Posts telecom press, 2007\(in Chinese  Kaplan E D Heg ar ty C J  ed Un der standing GPS pr inciples and application. Guan-hong KOU, trans. 2nd ed. Beijing, China: Publish House Electronics Industry, 2007\(in Chinese Volume 2 2010 2nd International Conference on Computer Engineering and Technology V2-419 


5 Figure 8 Borrow Pit truth DEM   Figure 9  Image of the Lakebed captured by the thirty degree fov camera   Figure 10: Lakebed DEM  Lakebed  The Lakebed is the second man made target site and is also located at NASA Dryden Flight Research Center.  With its flat, featureless surface, the naturally occurring dry lakebed is an ideal site for determining the LIDAR\325s ability to detect targets.  To this end, nine hemispheres of various sizes and albedos, a s ingle one meter cardboard cube, a cluster of four one meter cardboard cubes and eleven attitude targets where placed there.  The site was surveyed and a truth DEM was created  Figure 9  and Figure 10 show t he Lakebed site as seen by the thirty degree field of view camera and the truth DEM, respectively  Mars Hill  Seen in Figure 11 Mars Hill is the only naturally occurring target sight of FT1.   Located within Death Valley National Pa rk this site is approximately 200 miles away from the Lakebed and Borrow Pit.  With its natural rocks, slopes and lack of vegetation this site is a perfect analog for lunar terrain.  Plywood attitude targets, seen as white dots on the right of the hill and cardboard boxes were placed at Mars Hill   Figure 11  Mars Hill captured by the thirty degree fov camera   5  T RAJECTORY R E CONSTRUCTION  Overview  For FT1 the objective of the trajectory reconstruction process is to provide the position and attitude of the LIDAR for every LIDAR sample relative to a target Initially, it was proposed to develop an Extended Kalman Filter EKF to produce the LIDAR attitude and position by combining the GPS position  data the IMU  angular rate data  and the camera based attitude estimates However the development of the filter stalled  In order to provide results in a more timely fashion a simpler method was adopted  The new process is as follows  To begin the raw GPS data is processed to pro duce the position measurements accurate to a standard deviation of two centimeters.  Second, the images produced by the wide angle camera are manually sorted through to find images 5% Rock Field  10% Rock Field  Artificial  Craters  Cardboard  Boxes  


 6  that contain six or more attitude targets  Once the images were identified  they are used to determine the camera attitude Because the cameras infrequently captured images of the attitude targets the camera generated attitudes are used to initialize IMU based attitude  propagation   Finally g yro propagation is combined with t he GPS measurement to provide the full LIDAR pose \(postion and attitude  T his section details the reconstruction process  Initially w e present the GPS processing methodology followed by the imagery based attitude estimation process  After that t he equations used to propagate the attitude estimate based on the IMU data are given   Finally we provide how the camera estimates, gyroscope propagation and GPS position data are all combined to re produce the LIDAR pose  G PS Data Processing  The  GPS hardware co nfiguration of FT1 consists of two receivers, one is a static base station on the ground, and the other mounted on the helicopter. The data recorded by both receivers is analyzed to derive the precise positions of each  To obtain the precise position of a receiver, the data logged by the receiver is processed together with satellite orbit position and clock information. The quality of the GPS orbit and clock information used in the data processing defines the accuracy of the receiver position solution  In the final processing of the GPS data for FT1  we use the precise GPS orbit and clock information called the FLINN product. This product is produced at JPL by processing tracking data from 80 globally distributed ground stations, with about 10 days  latency and 3 cm accuracy The product is routinely generated and submitted to Interna tional GNSS Service IGS\to support precise applications i n science and industry communities           Figure 12  GPS data post processing for trajectory reconstruction  Our solution approach is illustrat ed in  Figure 12 At the left of the image is the data collected during a flight.  The center column represents a GPS processing method and the right hand side is the product and its solution accuracy  Each method is now described in detail  Base Station Static Point Positioning 321 The base station receiver d ata is processed using the FLINN GPS orbit and clock product The combination of GPS measurements at two different frequencies, commonly known as L1 and L2 are used to remove the effect of the ionosphere on the  measurements To further improve accuracy data points with tracking elevation angle below seven degrees are excluded Given two hours or longer hours of data the typical accuracy of the static point position solution is three centimeters  Helicopter Kinematic Point Positioning 321 Initially, the flight receiver data is processed to determine the helicopter\325s position using a kinematic point positioning technique  Again L1 and L2 GPS measurem ents are used to remove the effect of the ionosphere  Then using the best FLINN GPS orbit and clock information, the absolute the kinematic point positioning is determined to within twenty centimeters Here, the main error source for the solution is the correlation between the troposphere delay and the position height component   This solution is used as the initial trajectory for the relative positioning solution  Helicopter Kinematic Relative Positioning 321 The base station receiver data and the flight r eceiver data are processed together to determine the helicopter\325s position relative to the base station. In the relative positioning, those errors that are common to both the base station receiver data and the flight receiver data, such as the GPS orbit an d clock errors and troposphere and ionosphere delay errors, cancel out over a short baseline In our process the base station position is fixed to the st atic point positioning solution and the helicopter\325s position is solved iteratively starting with the kinematic point positioning solution To do so we use the GPS pseudorange and carrier pha se measurement at frequency L1   Typically the helicopter\325s position error relative to the bas e station has a two centimeter standard deviation   Image Based Attitude Estimation  The objective of the image based attitude estimation is to provide attitude measurements while over a test site  Because the image based attitude estimation does not drift as the IMU does it serves as an anchor point  for the IMU data processing and the final trajectory reconstruction  The initially proposed procedure for the image based attitude estimation was the following  First the image sequences containing a sufficient number of attitude targets were manually extracted  Then using these images the image pose was estimated.  Last we appl ied a bundle adjustment using the estimated pose and selected track features of an image series to improve attitude and position estimates  However many image sequences  contained a lack of distinguishable features  or the target field was Flight  Receiver  Data  Kinematic  Point  Positioning  20 cm level  Trajectory  GPS  Orbit & Clock  Data  Differential  Positioning  Process  2 cm level  Relative  Trajectory  Base  Receiver  Data  Static  Point  Positioning  3 cm level  Static  Position  


7 relatively small compared to the full  image For these  bundle adjustment produced bad results  Therefore a method was adopted that relied on the  kinemat ic relative GPS position rather than estimating it from imagery This method is as follows  Image Rectification  and  Attitude Target Extraction 321 Initially  seq uences of images containing six or more attitude targets were found Prior to inspection we use d the camera CAHVOR model 4  to rectify each image.  Then  a manual scan was  made of every eighth frame  If any attitude targets were  seen the skipped frames were  examined to determine the exact frame in which the targets initia lly appeared.  By comparing this frame to the surveyed locations of the attitude targets each target was  identified and its x  and y pixel loca tion were  recorded Th e se  locations  are  then used to initialize an automatic tracking algorithm  To track  the target locations each image frame in a sequence  containing the attitude targets wa s passed through a Scale Invariant Feature Transform SIFT Keypoint De tector 7  Comparing the SIFT points between consecutive images allow ed  for the computation of the Homography transform which map ped  the pixels from one image into the next   By i nitializing the locations of the targets in the first frame with a location recorded earlier the  Homography transform is  applie d to propagate the x and y pixel locations forward through the entire  series When  h owever there was  poor matching between pictures the propagation fail ed  When  the above f ail ed  the algorithm automatically shift ed  the target grid of one image horizontally and vertically over the other.  For every shift, the normalized sum of the pixel  values  under the targets is computed and the optimal shift was  found  Since the targets a re white this is the shift at which the sum of pixels is the maximum  In order for automatic shifting to succeed the targets must clearly contrast the background and the target grid s in both frames must be relatively in the same configuration  When  either condition was not met, the automatic shift algorithm fail ed  In this case a target was  hand selected and the shift from one image to the next was manually determined.  All targets were shifted by this amount and the x and y pixel location propagation continue d  Starting with the manual shift the local maximum was found to find the best local target location  When the propagation of the target locations completed the results were visually inspected for correctness by plotting the predicted attitude target locations back onto the image frames Figure 13 illustrates the entire target tracking algorithm  Solving for the Camera Attitude 321 Once a series of rectified images are produced and the pixel locations of the targets a re known, the attitude of the camera can be found.  For a CAHVOR calibrated camera, every x and y pixel location corresponds to a known three dimensional ray expressed in the camera frame.  Given the set of three dimensional points P i  expressed in the GPS  frame and a corresponding set of two dimensional points v i  expressed in image coordinates the x,y pixel locations  it is possible to derive a unit length ray v i in the camera frame using the camera calibration data Let r  be the camera location as measu red by the  GPS  and w i    w 1  311 w n  be a set of unit length rays from the camera to each P i i.e    1  where || . || is the vector norm  T hen solving for the full camera pose amounts to computing the rotation between w i and set v i  v 1, \311 v n To do so, we define V as the n  3 matrix consisting of  v i   W as the n  3 matrix consisting of w i  and R as the rotation matrix that rotates V T such that  W T RV T   2  In practice 2 does not have an exact solution and is computed either by  R=AB T  where A  B T W T V  is the singular value decomposition of W T V  or by  R=Pinv\(W where Pinv is the Moore Penrose pseudoinverse Note that if W T W  is non singular  then  Pinv\(W T W  W T W 1 W T  and, therefore  R = \(W T W 1 W T V    Figure 13: Block diagram of target tracking algorithm   Auto Adjustment Automatic Shift  


8 Next, we find the best attitude estimate using the RANdom SAmple Consensus RANSAC method  3 From the set P i   P 1  311 P n  th r ee points are selected and used to form an attitude estimate.  Using the resulting R matrix, the attitude targets are pro jected into the image and the projection error is calculated  Using a predetermined threshold erroneous members of  P i  are identi fied and rejected  Then the best attitude estimate is that formed from the remaining points  The resulting matrix R is the image based attitude estimate   IMU Based Attitude Propagation  For a given flight the resulting imagery based attitude estimates exist only when the wide angle camera capture d a sufficient number of attitude targets which occurred at a maximum rate of once a second Given the high rotational velocities of the gimbal this was  insufficient for  reconstructing the LIDAR trajectory  To this end we determine the attitude ever y 2.5 milliseconds using the LN 200 gyroscope s  To use the gyroscope s we first define an inertial frame.  Then, using the camera attitude estimates  to initialize the attitude  we propagated the attitude over the t ime that the  LIDAR was sampling data   The following sections provide the details of each step  T he inertial frame 321 We utilize an  Earth Centered Inertial ECI\frame We define the inertial frame to be the location of the WGS84 frame at the initial time  in a flight that the wide angle camera captures enough  attitude targets to produce an attitude estimate  Determining the initial attitude  from a series of attitude estimates 321 In this section, we find the initial attitude of the IMU relative to our ECI frame   The attitude of the IMU relative to the inertial frame is denoted M R I   This was  determined for every imagery based attitude estimate The product of the image based estimates was the attitude of the camera with respect to the GPS  frame.  Call it  E R C  From the i th estimate  E R C i   the IMU attitude relative to the initial frame was determined by the successive rotations  M R I i  M R C  E R C i  1  E R I t    3 Here  M R C  is the kn own rotation between IMU frame and the camera frame  and E R I accounts for the rotation between the GPS frame and the ECI frame  For propagating attitudes quaternions are numerically better suited. Therefore, each  M R I i  is converted to the equivalent quaternion  M q I i   Now that we expressed the attitude of the IMU re lative to an inertial frame in quaternion form we  propagated  it using the delta angles measured by the gyroscopes and using the 4     M q k 1 I  1 4  1 2 T  1  1 4 T    2 2  1 8 T    3 3                     M q k I  4 Here   and 1 4 is the 4  4 identity matrix The angles  x   y and  z are the angles provided by the x  y and z gyroscope measurements, respectively.  This equation is the result of truncating the infinite series expansion of the quaternion kinematic equation 8   Recall that image based attitude estimates are only available when the camera images at least six attitude targets.  Also the estimates come from sequen ces of consecutive  images For each sequence we attempt to find a good initial attitude to begin our  propagation of the attitude over the entire flight To start, we s elected  the initial estimate  from a sequence  and propagate d  the attitude  forward until the end of it  Note that each sequence  was  a small  portion of the entire flight Figure 14 shows an example of  M q I  generated from a section of data collected over the  Borrow Pit target site.  As seen here, the image based attitude estimates agree with the gyroscope propagation    Figure 14 Plot of attitude estimate based on camera vers us attitude propagated with IMU  Having both a propag ated quaternion and camera based  estimates during the same time span we found the mean error between them  For clarity we now denote the propagated quaternion as M p I and retain the M q I notation for attitude estimates  The  error quaternion mapping the Camera Estimate  321 IMU Propagation  q 1  q 4  q 3  q 2  Note   Jumps at  t 40 and  t 120 are the result of quaternion properization   Seconds since targets appeared in camera field of view   0  50  100  150  200  150  0.8  0 6  0 4  0 2  0.0  0.2  0.4  0.6  0.8  1  0 0 0 0.0 0.2 0.4 0.6 0.8 Quaternion Elements \(Unitless   


9 difference between the propagated attitude and the estimated attitude is given by  q e  M p I  1    M q I   5  Here   M p I  1  is the inverse  quaternion of  M p I  and   is the quaternion product  From the error quaternion the equivalent Euler angle of rotation   and unit Euler axis of rotation a  can be determined. Using   and a we define the scalar error quantity e s    and the vector error e v e s a   At this point   we have an error vector e v  and scalar e s  for every attitude estimate Taking u e to be the mean of all e v and u s to be the mean off all e s  we create the correction quaternion q c  u e T  sin u s 2  cos u s 2 T   Applying the correction quaternion to first camera based estimate  M q I 1 provide d the initial quaternion used to propagate the attitude for the entire flight, such that M q I 0  M q I 1  q c   To illustrate the effects of this procedure, we include  Figure 16  which because of its size has been placed  in the Appendix Here, f rames \(A\ and \(B\ are the value s of e s and e v  respectively created when the attitude was propagated starting at  M q I 1 a nd C and D was propagated starting at M q I 0  By improving the starting point the maximum scalar error e s has dropped from 0.26 degrees to 0.18 degrees and the standard deviation has dropped from 0.06 degrees to 0.03 degrees.  The vector error has the same shape, but now has zero mean  Determining the attitude of the IMU with respect to ECI 321 During a flight several passes at the target site are made At each pass, the wide angle camera takes a series of images used to estimate the attitude  S ee Figure 15   This figure shows the IMU LIDAR and camera timestamps for the second Borrow Pit flight  Here nine sequences  of attitude estimates are clearly visible  However it can be seen that LIDAR data is available between each sequence To provide attitude estimates between each series we propagate the estimates using the IMU.  As the propagation continues the estimate accuracy degrades due to error sources such as the gyroscope bias and numerical inaccuraci es Here we attempt to compensate for these errors   Minutes since start of data acquisition  Figure 15 Sample t imes of IMU, LIDAR and camera  Initially, it was proposed to combine GPS, camera data and the IMU with an EKF  However  development of the filter stalled and remains the subject of future work.  For FT1  we utilize d the following ad hoc method We beg an by finding the initial quaternio n for each sequence of image based attitude estimates  as determined by the previous section In addition to q 0 the standard deviation of e s for each  sequence  was calculated.  Starting from the initial quaternion of each sequence we propagate the attitude across the entire flight While propagating the accuracy of the attitude was  also tracked via   k t  0  b\(t k t q0   6 where  0   is the standard deviation of e s  for a given sequence    indicates the absolute value b is an arbitrary scale factor  t k is the timestamp of the k th measurement and t q0  is the timestamp  of  q 0  Take  M  to be the number of imaged based attitude estimate.  For the flight illustrated in Figure 15  M 9.  Since we propagated the attitude starting at each sequence 325s  q 0  there were  M  different propagated attitudes at every time step  Each of these were  combined using a weigh t ed average     7  where   j  and  a j  are the Euler angle and axis that defin e a propagated quaternion p j w j   j 1 is the weight of p j and W is the sum of all weights  Notice, that by using  and a  u is the average of the attitudes axis angle form    Finally for every time step u  was  converted to the quaternion M q I u     v T  sin   _ cos   T where v  u  u and   u 2 Also note that this scheme favors samples where there is good camera and IMU agreement  Constructing the LIDAR trajectory  The objective of the trajectory reconstruction  effort was  to determine the position and attitude of the LIDAR with respect to a target  site  Finding the attitude requires the following successive rotations  T q L  T q E    E q I t   M q I  1    M q L   8  Above T q E  and M q L  are the known relative attitudes The first i s the attitude of the target frame relative to the GPS  frame and the latter is the attitude of the LIDAR with respect to the IMU frame.  The other term introduced in \(8 E q I t is the attitude of the GPS frame with r espect to the ECI frame at time t  To  find the position of the LIDAR in the target frame we first linearly interpolate d  the 1 Hz GPS position measurement  r L/E  to the 8 Hz necessary for the LIDAR Then   we remove d  the offset between the GPS  and target frame r E/T  and rotate d the interpolated measurements from the GPS  frame into the target frame  using the rotation matrix T R E which is the rotation matrix equivalent to \(8  r T  T R E r L/E 320 r E/T   9  The attitude provided by \(8\ and the GPS measured position via 9 gave  the full pose of the LIDAR for each flight  0  80  70  60  50  40  30  20  10  


 10  6  I NSTRUMENT V ERIFICATION  To verify the accuracy of the reconstructed trajectory we  us ed the LIDAR by shift ing the LIDAR data until the minimum correlation error between the sensor data and truth DEM was found T he LIDAR camera boresite vector corresponds to the LIDAR z axis and t he sensor array rows and columns define the x and y axes  Therefore, any position shift in the z direction can be interpreted as a range error.  Shifts in the x and y axes co rrespond to yaw   and pitch  errors as follows   tan 1  y d  z  1    10   tan 1   x d  z  1    11  where  x   y and  z  represent the x, y and z shifts, and d is the distance to the target. Notice that yaw is the rotation abou t the LIDAR y axis  and pitch is the rotation about the LIDAR x axis R oll and pitch errors have been calculated using this method for Lakebed and Borrow Pit flights and plotted in Figure 17 A and Figure 18 A respectively  Additionally, we compare d the attitude determined by \(7\ to the image based estimates and plotted the results in  Figure 17 B and Figure 18  B   The maximum observed errors  observed by the LIDAR during the Borrow Pit flight were 0.25 and 0.16 degrees for pitch and yaw respectively These are comparable to the camera generated values of 0.12 and 0.15 degrees \(seed Figure 17 B\\.  For the Lakebed flight, seen in Figure 18  A the maximum LIDAR determined error was 0.37 and 0.58 degrees for pitch and yaw respectively  However the pitch and yaw errors seen in Figure 18  B for the cameras were significantly worse 0.33 and 2.50 degrees, respectively  In Figure 17 B and Figure 18  B  a non random process noise is apparent and is the likely cause of the larger than expected errors.  Currently, the source of this error has not been identified  however f or the ad hoc method described here  gyroscope scale factor errors, sense axis misalignments and bias have not been accounted for Additional error sources for the camera and IMU include the numerical inaccuracies introduced by 4 and timing errors For the LIDAR the largest source of e rror is the timing uncertainty. Efforts have been made to identify the timing of the LIDAR sampling.  Unfortunately, it changes from flight to flight and is not easily identifiable  Despite the larger than expected error the trajectory reconstruction me thod was s ufficient enough to place the LIDAR hazards within one meter horizontally of the truth hazards  The combination of the mainly horizontal trajectory errors and the time varying range bias inherent to the LIDAR caused the LIDAR data to be misaligne d relative to the truth DEM. To eliminate this misalignment, the flash LIDAR data and truth DEM were correlated using a procedure based on the HRN algorithm 6 was used. The end result was precise alignment to 1 DEM pixel \(0.1m or less  Even though the results from the method presented here were sufficient to achieve the ALHAT objectives i t may be desirable in the future to try to  achieve the expected attitude performance of 0.71 degrees   In that case  methods to identify the error sources will be developed  One such option is the use of an unconstrained nonlinear optimization  such as the MATLAB\250 function fminsearch   By formulating the effects that gyroscope misalignments, biases and timing offsets has on the propagated trajectory the parameter  values that minimize error between the camera estimates and the propagated trajectories can be found Although this approach is simple, the time for the nonlinear optimizer to find the parameters will be gre at  and it will not compensate for the numerical inaccuracies  A more complex alternative is to complete the EKF and extend it to an optimal smoother.  The filter will directly solve for gyroscope biases and drift due to the averaging between sensors and  reduce the impact of the numerical By running the filter multiple times and observing the effects that shifting timing offsets has on the filter residuals the best timing offset of the camera and IMU can be identified  Similarly by shifting the timing of the LIDAR samples and observing the effects on  x   y and  z the best LIDAR offset for each flight can be found  7  C ONCLUSIONS  The expected performance of the reference system was .12 cm for position and 0 071 degrees for attitude.  Although the ma ximum observed attitude error of 0.33 degrees was five times worse than expected the error for the Borrow Pit flight never exceeded the FT1 requirement However this was not the case for the Lakebed flight Examination of the error  seen in  Figure 17 B and Figure 18   B clearly demonstrates a yet unidentified, non random process noise By compensating for gyroscope misalignments, scale factor errors, gyro biases and timing, this error should dramatically reduce Despite the larger than expected errors, this method was sufficient to achieve the FT1 ALHAT objectives.  In case a better level of accuracy is required in the future, the  sources of error will be analyzed and the methods to compensate for them will be developed  Two approaches are the use of an unconstrained nonlinear optimizer or the development of an Extended Kalman Filter.  The results of these efforts are expected to achieve the expected 0.071 degree performance for FT1  A CKNOWLEDGMENT S  We thank Asif Ahmed of the Jet Propulsion Laboratory for his guidance  patience and tutelage during the trajectory reconstruction effort  The work described in this publication was performed at the Jet Propulsion Laboratory California Institute of 


 11  Technology under contract from the National Aeronautics and Space Administration The work was funded by the NASA Exploration Technology Development Program and would not have been possible without the flash LIDAR  sensor provide by NASA Langley and the field test system provided by JPL  R EFERENCES  1  Bulyshev Alexander Pierrotte t Diego Amzajerdian Farzin; Busch, George; Vanek, Michael; Reisse, Robert 322Processing of three dimensional flash lidar terrain images generating from an airborne platform\323 roc SPIE, Vol. 7329 April 2009  2  Epp  Chirold and Tom Smith, \322Autonomous Precisio n Landing and Hazard Detection and Avoidance Technology ALHAT\,\323 Proc IEEE Aerospace Conf Big Sky, MT, March 2007  3  Fischler Martin A and Robert C Bolles Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography  Comm Of the ACM 24 June 1981 381 320 395  4  Gennery D.B 322Least Squares Camera Calibration Including Lens Distortion  and Automatic Editing of Calibration Points,\323 Workshop Calibration  and Orientation of Cameras in Computer Vision XVI I Congress  of the International Society of Photogrammetry and Remote Sensing Washington DC, August  2, 1992  5  Johnson Andrew E Jason A Keim and Tonislav Ivanov  322Analysis of Flash Lidar Field Test Data  for Safe Lunar Landing\323 IEEE Aerospace Conferenc e  March 6 13, 2010, Big Sky, Montana  expected  6  Johnson  Andrew E  and Miguel SanMartin Motion Estimation from Laser Ranging for Autonomous Comet Landing Proc Int'l Conf Robotics and Automation pp. 132 138, April 2000  7  Lowe, David G. "Distinctive image features from scale invariant keypoints International Journal of Computer Vision vol. 60.2 \(2004\: 91 110  8  Wertz, James R Spacecraft Attitude Determination and Control  Boston Kluwer Academic Publishers 1978  558 566  9  Melvin \(Jay\ White II, Tom Criss, and Dewey Adams  322 APLNav Terrain Relative Navigation Helicopter Field Testing 323 AIAA Guidance Navigation and Control Conference  August 2009, Chicago, Illinois   B IOGRAPHY  Jason Keim received his B S.B.M.E from the University of Southern California and  M.S.M.E from California State University, Los Angeles. Since 2002, Jason has been a member of the Guidance and Control Analysis Group at the NASA Jet Propulsion Laboratory. His primary focus has been the development and validation of formation flight algorithms and technologies for missions such as NASA Starlight TPF and DARPA F6  Additionally, he has contributed to the autonomous surface operations of the Mars Science Laboratory data processing and t rajectory reconstruction for the Autonomous Landing and Hazard Avoidance Technology program and other research and technology development programs  Dr Sohrab Mobasser is a Senior Member of the Engineering Staff at the National Aeronautics and Space Admi nistration\325s NASA Jet Propulsion Laboratory JPL Sohrab has more than 26 years of aerospace industry experience most of it in spacecraft attitude determination His work can be found on many planetary missions from the Galileo mission to Jupiter to t he successful Pathfinder mission to Mars and the Cassini mission to Saturn His current interests are new technology and applications for autonomous spacecraft attitude determination  Sohrab is the Field Test Lead for ALHAT project    Dr Yang Cheng  Dr Y ang Cheng is senior staff member at JPL and he has been involved in many NASA and reimbursable robotic projects for many years He is the key algorithm developer for the Descent Image Motion Estimation System \(DIMES which played a critical role for Mars Exploration Rovers landing safely on Mars. He was also the key software developer for the MER onboard visual odometry which has been used during critical rover maneuvers and traverses.  In addition, he was also involved in novel vision algorithm developme nt for future Mars and Lunar safe and pinpoint landing   Tonislav Ivanov is an Associate Member of Technical Staff in the Computer Vision Group at JPL He works on lidar data processing  field test setup, and is helping develop the hazard detection algori thm for the Autonomous  Landing and Hazard Avoidance Project He also works on recognition using stereo data for robot human awareness and lunar terrain characterization for future missions to the Moon    320  


12 Dr Da Kuang  received his Ph.D in Aerospace Engineering from The University of Texas at Austin in 1995. He joined the Orbiter and Radio Metric Systems Group at JPL in 1996 His work has been focused on analyzing GPS and GPS like tracking data for precise orbit determ ination and precise relative positioning  Dr Andrew Johnson  is a Principal Member of Technical Staff in the Optical Navigation Group at JPL  He is the JPL Project Manager and  terrain sensing algorithm lead for the Autonomous Landing and Hazard Avoida nce Project which is developing technology for safe and precise landing for the next generation manned lunar lander At JPL he works on development validation and flight implementation of computer vision systems for planetary landers and Mars rovers  Ha nnah R Goldberg  received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively. She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano class spacecraft and microsystems   Garen Khanoyan  is a member of the Advanced Co mputer Systems  Technologies group at JPL He has been involved with field testing activities and the development of the Command  Data Storage Unit since 2008 for ALHAT and MSL projects. Garen received his B S.E.E and M S.C.S from the University of Southern California   David B. Natzic received his B.S.C.S. from the Department of  Computer Science at the Universi ty of Management and Technology He has been employed as a n Associate Member of Technical Staff in the Guidance Navigation and Control Group at JPL Dave Joined JPL in 1992 and currently serves as a n  essential ALHAT team member focusing on the design integration and field testing of Flash LIDAR instruments onboard aerial platforms 


13 A PPENDIX    Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view    A         B      Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view   C         D Figure 16  The error between the propagated and estimated attitude  A is the scalar error and B is the vector error before the corrections.  \(C\ is the scalar error and \(D\ is the vector error after the correction   200  180  160  140  120  100  80  60  40  20  0  200  180  160  140  120  100  80  60  40  20  200  180  160  140  120  100  80  60  40  20   200  180  160  140  120  100  80  60  40  20  0.35  0.30  0.25  0.10  0.05  0  0  Degrees  0.20 0.15  0.35  0.30  0.25  0.10  0.05  0  Degrees  0.20  0.15  0  0.15  0.10  0  0.15  0.20  0.25  Degrees  0.05  0.10  0.05  0.15  0.10  0  0.15  0.20  Degrees  0.05  0.10  0.05  0  


14   A        B  Figure 17: Yaw and pitch errors from second Borrow Pit flight for \(A\ the LIDAR and \(B\ the camera      A        B  Figure 18: Yaw and pitch errors from the third Lakebed flight for \(A\ the LIDAR and \(B\ the camera  Degrees  Seconds into flight  Seconds into flight  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  500  2000  2500  1000  1500  3000  3500  Seconds into flight  500  2000  2500  1000  1500  3000  3500  Seconds into flight  1000  1500  500  2000  2500  0  0.20  1000  1500  500  2000  2500  0  0.20  


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






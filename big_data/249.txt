An Efficient Hash-Based Method for Discovering the Maximal Frequent Set Don-Lin Yang Ching-Ting Pan and Yeh-Ching Chung Department of Information Engineering Feng Chia University, Taichung Taiwan 407 TEL 886-4-245 1-7250x3700 FAX 886-4-2451-6101 Email  dlyang ctpan ychung\@iecs.fcu.edu.tw Abstract The association rule mining can be divided into two steps The first step is to find out all frequent itemsets whose occurrences are greater than or equal to the user-specified threshold The second step is to generate reliable association rules based on all frequent itemsets found in the 
first step Identifying all frequent itemsets in a large database dominates the overall performance in the association rule mining In this paper, we propose an efficient hash-based method HMFS for discovering the maximal frequent itemsets The HMFS method combines the advantages of both the DHP Direct Hushing arid Pruning and the Pincer-Search algorithms The combination leads to two advantages First the HMFS method in general can reduce the number of database scans Second the HMFS can filter the infrequent candidate itemsets and can use 
the filtered itemsets to find the maximal frequent itemsets These two advantages can reduce the overall computing time of finding the maximal frequent itemsets In addition the HMFS method also provides an efficient mechanism to construct the maximal frequent candidate itemsets to reduce the search space We have implemented the HMFS method along with the DHP and the Pincer-Search algorithms on a Pentium I11 800 MHz PC The experimental results show that the HMFS method has better performance than the DHP and the Pincer-Search algorithms for most of test cases In particular 
our method has significant improvement over the DHP and the Pincer-Search algorithms when the size of a database is large and the length of the longest itemset is relatively long 1 Introduction The data mining refers to extract knowledge from a large database IO In recent years data mining has attracted a growing amount of attention in the database community One of the most important reasons is the fast growing huge amount of data that is far from the ability of human to analyze Discovering association 0-7695-1372-7/01 10.00 0 2001 IEEE rules from 
a database is an important technique in the data mining area For example for the retail business a database may contain sales transactions We can analyze customers buying habits through discovering the associations among products that is, a customer who buys some products will also buy other products in the same transaction These mined rules are very useful for the retailer to improve the marketing strategies Other popular applications include mining web contents mining web path traversal patterns  1 I etc The process of mining association rules can be decomposed into two steps  131 
The first step is to find out all frequent itemsets whose occurrences are greater than or equal to the user-specified threshold The second step is to generate reliable association rules based on all frequent itemsets found in the first step The cost of the first step is much more expensive than the second step Therefore much research focused on developing efficient algorithms for finding frequent itemsets A well-known Apriori algorithm proposed by R Agrawal and R Sriank 13 was the first efficient method to find the frequent itemsets The main contribution of the Aprinri algorithm is 
that it utilizes the downward closure property i.e any superset of an infrequent itemset must be an infrequent itemset to efficiently generate candidate itemsets for the next database scan By scanning a database k times the Apriori algorithm can find all frequent itemsets of a database where k is the length of the longest frequent itemset in the database Many methods based on the Apriori algorithm have been proposed in the literature In general they can be classified into three categories reduce the number of candidate itemsets, reduce the number of database scans 
and the combination of bottom-up and top-down search Reduce the number of candidate itemsets: Methods in this category try to generate a small number of candidate itemsets efficiently in order to reduce the computational cost The hash-based algorithm DHP Direct Hashing and Pruning proposed by Park et al 6 is an example The main contribution of the DHP algorithm is that it uses a hash table to filter the huge infrequent candidate itemsets before the next database scan However the 51 1 


DHP algorithm needs to perform database scans as many times as the length of the longest frequent itemset in a database 0 Reduce the number of database scans Scanning a database iteratively is time consuming Thus methods in this category try to reduce database scans aiming at reducing disk I/O costs The Partition algorithm proposed by Savasere et al l generates all frequent itemsets with two database scans The Partition algorithm divides the database into several blocks such that each block in the database can be fitted into the main memory and can be processed by the Apriori algorithm However the Partition algorithm examines much more candidate itemsets than the Apriori algorithm Brin et al I71 proposed the DIC algorithm that also divides the database into several blocks like the Partition algorithm Unlike the Apriori algorithm, once some frequent itemsets are obtained the DIC algorithm can generate the candidate itemsets in different blocks and then add them to count for the rest blocks However the DIC algorithm is very sensitive to the data distribution of a database The combination of bottom-up and top-down search Methods in this category are also based on the downward closure They obtain the frequent itemsets in a bottom-up fashion like the Apriori algorithm In the mean time they use the infrequent itemsets found in the bottom-up direction to split the maximal frequent candidate itemsets in the top-down direction in each round The advantage is that once the maximal frequent itemsets are obtained all subsets of the maximal frequent itemsets are also identified Therefore all subsets of the maximal frequent itemsets do not need to be examined from the bottom-up direction Without the top-down pruning they need to scan database as many times as the length of the longest frequent itemset However the improvement is not clear when the length of the longest frequent itemset is relatively short The Pincer-Search algorithm proposed by D Lin et al 2 and the MaxMiner algorithm proposed by R.J Bayardo 6 are two examples In these two methods the generation of the maximal frequent candidate itemsets is not efficient They may spend a lot of time on finding the maximal frequent itemsets In this paper we propose an efficient hash-based method to generate the maximal frequent itemsets HMFS in the category of the combination of bottom-up and top-down search The proposed method combines the advantages of both the DHP and the Pincer-Search algorithms Unlike the DHP algorithm the HMFS method is very efficient in reducing the number of database scans when the length of the longest frequent itemset is relatively long Unlike the Pincer-Search algorithm the HMFS method can filter the infrequent itemsets with the hash technique from the bottom-up direction and then can use the filtered itemsets to find the maximal frequent itemsets in the top-down direction In addition the HMFS method also provides an efficient mechanism to construct the maximal frequent candidate itemsets To evaluate the performance of the HMFS method, we have implemented this method along with the DHP and the Pincer-Search algorithms on a Pentium I11 800 MHz PC The experimental results show that our method has better performance than the DHP and the Pincer-Search algorithms for most of test cases In particular our method has significant improvement over the DHP and the Pincer-Search algorithms when the size of a database is large and the length of the longest itemset is relatively long The rest of the paper is organized as follows Section 2 introduces the terminology used in this paper The detail of the proposed HMFS method is presented in section 3 The experimental results of the proposed method are presented in section 4 2 Preliminaries In this section we introduce some basic definitions of the associ;ition rule mining Let 1   il iz   i be a set of distinct items Definition 1 A database D is a set of transactions, where each transaction T contains a set of items in 1 Definition 2 A subset of I is called an itemset An itemset is called a k-itemset if it contains k items Definition 3 The support of an itemset X I for a database denoted as support\(X is the number of transactions in the database that contain all items in X Definition 4 An itemset is called a frequent itemset if its support is greater than or equal to some user-specified minimum support Otherwise it is an infrequent itemset The set of all frequent k-itemsets is denoted as Lk Definition 5 Given the set of all candidate k-itemsets Ck is defined as Lk x LX  Xu Y I X Y E LX I Xn Y I k-2},wherek 1 Definition f A frequent itemset is called a maximal frequent iternset if it is not a subset of any other frequent itemsets Definition 7 An association rule is defined as X 3 Y where X Y The task of the association rule mining is to discover all association rules that satisfy the minimum support and the minimum confidence We now give an example to explain the terms described above Consider the database shown in Table 1 Assume that I  A B C D E F and there are five transactions in the database D Let the minimum support and the minimum confidence be 40 and 100 respectively All frequent itemsets are shown in Table 2 The itemsets whose support smaller than 5~40  2 are infrequent itemsets In this example itemsets D AB and AE are infrequent itemsets Note I X Yf 0 and X n Y  0 512 


1 I 2 1 B C E F I A. C D I 3 1 A B C.E F 1 Support 2 3 A I 4 Itemsets AF BC BF CE EF ACF, BCE BCF BEF CEF BCEF A B E F AC BE CF c I 5 I A. C F I Table 2 All frequent itemsets 3 The HMFS Method Our HMFS method combines the advantages of both the DHP and Pincer-Search algorithms In the HMFS method it uses the hash technique of the DHP algorithm to filter infrequent itemsets in the bottom-up direction Then lit uses a top-down technique that is similar to the Pincer-Search algorithm to find the maximal frequent itemsets The main difference of the top-down techniques between the HMFS method and the Pincer-Search algorithm is that the HMFS method provides a more efficient mechanism to initialize the set of maximal frequent candidate itemsets than that of the Pincer-Search algorithm By combining the advantages of the DHP and Pincer-Search algorithms the number of database scans and the search space of items can be reduced The algorithm of the HMFS method is given as follows Algorithm HMFS 1 2 3 call cunstruc~~maximulfrrque~itcandidate_irem.~ets\(C H2 4 5 6 7 8 9 Enhuf-algorithm In the first round, scan the database D to count the support of all Cz is constructed by LlxLl and is filtered by Hz In the second round, divide D into several blocks for all blocks h E D do Count the supports of itemsets in C2 and MFCS call process-cullision\(C2 H2 to process the collisions of the hash Move the maximal frequent itemsets from MFCS to the hash tree l-itemsets and build a hash table H2 buckets Apply the Pincer-Search algorithm to the rest of rounds Function construct~maximalfrequen~~eandi~lu~~~iren~sets\(C H2 I C,n,u  x XIXZX  x 1x1~2 xlx3   xlx E C2 where n  2 2 m=3;MFCS=0 3 for all x  xlxzx3 x E C do 4 5 6 7 8 9 IO Push x into the stack initially while the stack is not empty do Popup an element x from the stack while m f n do k  h2\(xj for i  2 3  m-I if H2\(k  minimum support then  h2 is a hash function Split 1x2~3 x into two \(n-1 x xIx2x  x X,~.I~~~+I x and xu x1x2xXJ x,.lx8+l X,n*;"+l x if i.~_maximal_carrdi~lulare_iremser\(x   true then II 12 else discard x 13 14 then continue processing x 15 m 16 else x'is discarded 17 break 18 19 return MFCS End_ofTonstruct_max~mal~r~quent~~u~~~i~late~itein,~rt Function is-maximal-candi~lute_itrmsrr\(itemset x I 2 if all items in x are also in s then return false 3 else return true End-of_is_maximul-candi~late-it~m.set Function procrss_coIlision\(C2 H2 I 2 3 4 push into the stack if is-mw;imal-cuncii~lute-items~t\(x j  true if m  n and the length of x  2 then MFCS  MFCS U x for all itemset s in the stack do for all blocks h E D do for all H2\(k 2 minimum support do for all c E C2 that hashed into H2\(k where i  I 2   n do if H,\(k  2 suppon c  support c I  minimum support Vj  1,2 ___ n  5 6 End-of proces.y-colli.sion then use the infrequent 2-itemset cj to split the itemsets in MFCS Remove the infrequent 2-items-t cj from CZ In the algorithm HMFS lines 1-2 use the hash technique to filter the infrequent itemsets in C2 in the bottom-up direction Line 3 constructs the set of maximal frequent candidate itemsets MFCS Line 6 counts the supports of itemsets in MFCS and C Line 7 splits the maximal frequent candidate itemsets if some conditions are satisfied Line 8 moves the maximal frequent itemsets from MFCS to the hash tree Line 9 performs the Pincer-Search algorithm to get the maximal frequent itemsets We first explain how the function construct-maxirnalJrequent-candidate-itemsets works Line 1 constructs C with all 2-itemsets that have the same first item in C Lines 3-19 generate the set of maximal frequent candidate itemsets MFCS The generation process is as follows Assume that an itemset x in C is denoted as x1x2x 3...x Consider the first m 513 


items in 1~2x3  x for m  3  n and examine the 2-item subset x,xm of x for i  2 3  m-I If the number of 2-itemsets in the corresponding hash bucket of x,x is smaller than nunimum support i.e x,x is not in C2 split x into x\222  XIXZX  Y  x,~.~x~+~...x and x\224  1x2~3  x,.Ix,+I  x,,,x,,.I  x Itemsets x\222and x\224are then compared with elements in the stack We have the following four cases Case 1 All items in x\221and x\222\222are also in any element in the stack Both x\222and are discarded The next itemset is popped up from the stack and the generation process continues Case 2 Only items in x\222are also in any element in the stack Itemset x\222 is discarded The generation process continues to examine x,+Ix of x\224 Case 3 Only items in x\222\222are also in any element in the stack Itemset x\224 is discarded The generation process continues to examine the x,x,+I of x Case 4 Otherwise itemset x\224is pushed into the stack and the generation process continues to examine x,xm of X The generation process continues until rn  n Then we get a maximal frequent candidate itemset Once one maximal frequent candidate itemset is generated, the next itemset in the stack is popped up and the generation process is applied until the stack is empty C  AB AC AD AE AF BC BF. CD. CE CF ABCDEF c i 2234 ABCIDEF C A B CD EFJ  4 B C IDEF BCisin C ABCDIEF i 1 4 B C D 1 E F BD IS no1 an c2  I A I I EF CDisin c I AB C E I F. BEis no1 n C   7 IACDEIF  C D E 1 F DE is not m C discard ACEF c Figure 1 An example of the split process An example of the generation process is shown in Figure 1 Let C2  AB AC AD AE AE BC BE CD CE CF C is ABCDEF Consider the first 3 items ABC in ABCDEF Since BC is in Cz we examine ABCD in ABCDEF Since BD is not in Cr ABCDEF is split into ABCEF and ACDEF Compare ABCEF and ACDEF with elements in the stack we have Case 4 ACDEF is pushed into the stack and the generation process continues with ABCEF Since BE is not in C2 ABCEF is split into ABCF and ACEF Compare ABCF and ACEF with elements in the stack we have Case 2 ACEF is discarded A maximal frequent candidate itemset ABCF is obtained Since the stack is not empty itemset ACDEF is popped up from the stack and the generation process continues in a similar manner Finally all maximal frequent candidate itemsets ABCF ACD and ACE are generated from ABCDEF In HMFS method the collision of the hash buckets cannot be avoided by using the hash technique The collision may result in an infrequent itemset be used to construct the maximal frequent candidate itemsets For example, assume that C2 AB AC, AD AE AE BC, BE CD CE CF is given One of the maximal frequent candidate itemsets of C2 is ABCF Assume that AC a frequent itemset and AF an infrequent itemset are hashed into bucket 2 Since AC and AF are in the same bucket AF cannot be filtered and will be used to construct the maximal frequent candidate itemsets Function process-colli\222sion provides a solution of this problem In the following we explain how it works First it divides the database into several blocks In the second round the supports of elements in C2 and MFCS are counted The number of 2-itemsets hashed into bucket k in H2 is denoted as H2\(k Assume that there are n 2-itemsets cI c2  c in Cz hashed into bucket k An infrequent itemset c can be identified by the following equation H2\(k  c  1 I minimum support b\222j  1,2  n where the supports of c and c among the k blocks are denoted as mpport\(c and support\(c respectively In each block scanning all infrequent itemsets in C2 are identified and are deleted from C2 The identified infrequent itemsets are used to split itemsets in MFCS as well We now give an example to explain Equation 1 Assume that the number of transactions in a database is 10,000 the minimum support is OS and H2\(k is 100 After scanning several blocks in the database supporf\(AC is 70 and support\(AF is 10 By applying Equation l 100-\(70+10  30  10,000X0.5  50 Thus we can identify AF is an infrequent itemset and AF can be discarded The purpose of dividing a database into several blocks is that some infrequent itemsets in Cz may be determined earlier when some blocks are scanned The maximal frequent candidate itemsets that contain these infrequent itemsets cannot be counted further Therefore the division may lead us to identify those maximal frequent candidate itemsets that contain infrequent itemsets earlier and reduce the time of finding the maximal frequent itemsets 514 


4 Experimental results D T I L Number of transactions Average size of transactions Average size of the maximal potentially large itemsets Number of potentially large itemsets NI Number of items IW 025 050 071 u,",Mmrrppm 19 To evaluate the performance of the proposed method we have implemented the HMFS method in C language along with the DHP and the Pincer-Search algorithms on a Pentium 111 800 MHz PC with 512MB of main memory The program designed by IBM Almaden Research Center is used to generate synthetic databases 5 This program has been widely used by many researchers l 2 6 7 8 9 12, 14 171 By setting up parameters of the program we can generate desired databases as benchmarks to evaluate the performance of our method Table 3 describes all the parameters used in the program In our experiments, we set N  1000 and L  2000 The number of the hash buckets is 500,000 We designed two tests In the first test we compare the relative performance and the number of database scans for the three algorithms on four databases The results of the first test are shown in Figure 2 and Figure 3 Figure 2 shows the execution time of these three algorithms for test databases with various minimum supports In Figure 2 our method is a little slower than the DHP algorithm on TlOI4DlOOK when the minimum support is I In this case the execution time of the DHP algorithm and the HMFS method are 4 and 6 seconds respectively The reason is that the length of the longest itemset is two for T1014DlOOK when the minimum support is 1 i.e only two database scans are required for T1014D100K The HMFS method and the DHP algorithm all require two database scans However the HMFS method needs to spend some time on constructing the maximal frequent candidate itemsets based on C2 Therefore it takes more time than the DHP algorithm For other test cases the HMFS method outperforms the DHP and the Pincer-Search algorithms The summary reasons are given as follows 1 In contrast with the DHP algorithm the HMFS method finds the frequent itemsets not only in the bottom-up direction but also in the top-down direction The execution time is improved since the number of database scans is reduced The number of database scans is shown in Figure 3 The number of database scans required by the DHP algorithm is the length of the longest frequent itemset In general the number of database scans of the HMFS method is half of that of the DHP algorithm when the minimum support  0.25 and j ox OJO 07s cm WlnirmmSvppm I 0.5 2 In contrast with the Pincer-Search algorithm the HMFS method still has better performance than the Pincer-Search algorithm even though the number of database scans required by the HMFS method is the same as the Pincer-Search algorithm There are two reasons First the HMFS method uses the hash table to filter a huge number of infrequent 2-itemsets in the C instead of actually counting the supports of all 2-itemsets Second it constructs the maximal frequent candidate itemsets by using the hash technique instead of the combination of all distinct 1-itemsets in a database The search space is reduced substantially a T1014D1 OOK b T1514D1 OOK  IW 1 021 050 075 IW w,"urum*poni 1 0250500'5 u,"lmm*pprn IS c T2014D1 OOK d T2016DlOOK Figure 2 The execution time of the HMFS method DHP and Pincer-Search algorithms on various test databases with increasing minimum supports In the second test we evaluate the performance of the HMFS method and the DHP algorithm on the test databases with various database sizes The results of the second test are shown in Figure 4 The performance of the Pincer-Search algorithm is not included since it takes 515 


too much time to get the execution results for the test databases In Figure 4 the number of transactions in the test databases is set from lO0K to 500K and the minimum support is 0.75 From Figure 4 we can see that both the execution time of HMFS and DHP increases when the number of transactions increases However the execution time of the DHP algorithm is near linear to the size of test databases The HMFS method is not so sensitive to the size of a database compared to the DHP algorithm Therefore our HMFS method performs much better when the database size is larger IWK XQK 3WK WOK SWK IWX iooY WOK IWX raor  I D.hCSE Drllv lur a TlO14 b T1.514 iuirs 4-0 I la  224 k_ we   Ll1*Da.sr c T2014 d T2016 Figure 4 The execution time of the HMFS method and the DHP algorithm on the test databases with various database sizes Minimum Support  0.75 5 Conclusions In this paper we have proposed an efficient hash-based method HMFS for discovering the maximal frequent itemsets The method combines the advantages of the DHP and the Pincer-Search algorithms The combination leads to two advantages First the HMFS method in general can reduce the number of database scans Second the HMFS method can filter infrequent itemsets and use the filtered itemsets to find the maximal frequent itemsets faster In addition an efficient mechanism to construct the maximal frequent candidate itemsets is provided To evaluate the performance of our method we have implemented the proposed method along with the DHP and the Pincer-Search algorithms on a Pentium I11 800 MHz PC The experiments were conducted on various benchmark databases The experimental results show that our method has better performance than the DHP and the Pincer-Search algorithms for most of test cases In particular our method has significant improvement over the DHP and the Pincer-Search algorithms when the size of a database is large and the length of the longest itemset is relatively long References I A Savasere E Omiecinski and S Navathe 223An Efficient Algorithm for Mining Association Rules in Large Databases\224 In Proceedings oj\2242lst VLDB pp 432-444 1995 2 D Lin and Z M Kedem 223Pincer-Search A New Algorithm for Discovering the Maximum Frequent Set\224 In Proceedings of VI Intl Conference on Extending Database Technology 1998 3 Eui-Hong Han George Karypis and Vipin Kumar 223Scalable Parallel Data Mining for Association Rules\224 IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 MAYlJUNE 2000 4 H Toivonen 223Sampling Large Databases for Association Rules\224 VLDB pp 134-145 1996 5 IBM Quest Data Mining Project 223Quest Synthetic Data Generation Code\224 223http\224//www almaden ibm codcslquestlsyndata html\224 1996  J S Park M S Chen and P S Yu 223An Effective Hash Based Algorithm for Mining Association Rules\224 Proceedings of the ACMSIGMOD pp 175-186 1995 7 M Houtjma and A Swami 223Set-Oriented Mining of Association Rules in Relational Databases,\224 11th Int\222l Conference on Data Engineer 1995 8 M J Zak.i S Parthasarathy M Ogihara and W Li 223New Algorithms for Fast Discovery of Association Rules\224 3rd Int\222l Corference oi2 Knowledge Discovery 8i Data Mining KDD Newport CA August 1997 9 Mohammed J Zaki 223Scalable Algorithm for Association Mining\224 IEEE Transactions on Knowledge and Data Engineering Vol 12, No 3 MAY/JUNE 2000 IO M S Chen J Han and P S Yu 223Data Mining An Overview froin a Database Perspective\224 IEEE Transactions on Knowledge and Data Engineering Vol 8 No 6 December 1996 l I M S Chen J S Park and P S Yu 223Efficient Data Mining for Path Traversal Patterns\224 lEEE Transactions on Knowledge and Data Engineering Vol IO No 2 1998 pp 209-220 12 R Agrawal T Imilienski and A Swami 223Mining Association Rules between Sets of Items in Large Databases\224 In Proceedings of the ACM SlGMOD Intl Conference on Management of Data pp 207-216 May 1993 13 R Agrawal and R Srikant 223Fast Algorithm for Mining Association F.ules in Large Databases\224 In Proceedings of 1994 Int\222l Conference on VLDB pp 487-499 Santiago Chile Sep 1994 I41 R Agrawal H Mannila R Srikant H Toivonen and A lnkeri Verkamo 223Fast Discovery of Association Rules,\224 Advances in Knowledge Discovery and Data Mining U Fayyad and et al eds pp 307-328 Menlo Park Calif AAA1 Press 1996 I51 R Agrawal and J Shafer 221\221Parallel Mining of Association Rules,\224 IEEE Transactions on Knowledge and Data Engineering Vol 8 No 6 pp 962-969, Dec 1996 16 R J Bayardo Jr 223Efficiently Mining Long Patterns from Databases\224 In Proceedings of the ACM SIGMOD Conference on Management of Data pp 85-93 Seattle Washington June 1998 I71 S Brin R Motwani J D Ullman and S Tsur 223Dynamic Itemset Counting and Implication Rules for Market Basket Data\224 1997 ACM SIGMOD Conference on Management of Data pp 255-264 1997 516 


1 2 3 4 5 6 7 8 9 10 References P. Cabena P Hadjinian R Stadler J Verhees and A Zanasi Discovering Data Mining: From Concept to Implementation Prentice Hall 07458,1997 pp 12 30 N Lavac E Keraunou and B Zupan 223Intelligent Data Analysis in Medicine and Pharmacology.\224 IDAM4P-97 Nagoya Japonska Kluwer Acedemic Publishers 1997 pp 61-67 W Horn 223Artificial Intelligence in Medicine on its Way from Data-Intensive to Knowledge-Intensive\224 Austrian Research Institute for Artificial Intelligence Technical Report TU-2001-01 Vienna Austria Val 23 NO 1,2001 pp 5-12 N Lavrac 223Data Mining in Medicine Selected Techniques and Applications\224 In Proc of the Second Intemational Conference on ne Practical Applications of Knowledge Discovery and Data Mining pp 11-31 S Startchik Geometric and Illumination Invariant Object Representation Application to Content-based Image Retrieval Ph.D Dissertation No 3009 University of Geneva, Switzerland, July 1998 T Zrimaec 223A Medical Image Information System\224 VISIM Workshop Utrecht Netherlands Oct 2001 Paper 2 G.D Magoulas and A Prentza, \223Machine learning in Medical Applications\224 Workshop on Machine Leaming in Medical Applications ACAI-99 1999 pp.53-58 P A Devijer and J Kitter Pattem Recognition A Statistical Approach Prentice-Hall 1982 K Woods Automated Image Analysis Techniques in Digital Mammography Ph.D Thesis, Department of Computer Science and Engineering University of South Florida, December 1994 W Chu I Leong R Taira C Breant 223A Temporal Evolutionary Object Oriented Data Model and its Query Language for Medical Image Management\224 Proceedings of the Id KLDB conference Vancouver Canada 1992 pp.53-64 11 V Megalooikonomou J For L Shen F Makedon Data Mining in Brain Imaging Statistical Methods in Medical Research 2000 pp 359-394 12 0 R Zaiane Resource and Knowledge Discovery fiom the Internet and Multimedia Repositories PhD Thesis School of Computing Science Simon Fraser IJniversity, March 1999 13 M Antonie 0 Zaiane A Coman 223Application of Data Mining Techniques for Medical Image Classification\224 In Proceedings of the Second i\221nternational Workshop on Multimedia Data Mining with ACM SIGKDD Coi?ference \(MDM/KDD\2222001 San Francisco USA Aupst 26,2001 14 J Hipp V Guntzer and G Nakhaeizadeh 223Algorithms for Association Rule Mining. A General Survey and Comparison.\224 ACM SIGKDD Volume 2 Issue 1 July 2000 pp 58 64 15 R Aggrawal and R Srikant 223Fast Algorithms for Mining Association Rules\224 In Proceeding of the 20th International Conference of Very Large Data Eases VLDB Chile 1994 pp 487 499 16 Ginneken B Romeny Statistical Local Texture Analysis Applied to Computer- Aided Diagnosis in Chest Radiography Statistics of Shapes and Textures Copenhagen summer school in computer vision September 4-8 2000 17 B Ginnekan Computer Aided Diagnosis in Chest Radiography PhD thesis, Utrecht University March 2001 pp 14-17 18 C Ordonez C Santana and L Brad 223Discovering Interesting Association Rules in MedicaI Data\224 ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2000 pp 78-85 19 C Aggrawal and P Yu 223Mining Large Itemsets for Association Rules\224 In Bulletin of the IEEE Computer Society Technical Committee on Data Engineering V01.2 N0.1~1998 Pg 23-31 20 C Ordonez and E Omiecinski 223Discovering Association rules Based on Image Content\224 In Proceedings of the IEEE Advances in Digital libraries Conference ADL 222993 Pg 38 49 21 K Lee 221\221Intelligent Shape based Image Analysis\224 Department of Computer Science, University of Iowa 55:247 Project 2001 2:2 J.Han J Pei and Y Yin 223Mining Frequent Patterns without Candidate Generation\224 In Proceedings of SIGMOD-2000 Dallas, May 2000,pp 1  12  1187  


3 3.5 fixed-style adap-style Er 4 S1 White burst the transient signal s1 is white and Gaus40 02~45\260\260 10 rn 0 sian with zero mean S2 Single exponentially-decaying sinusoid 30 60 20 X 4050 f S2\(i Ce f cos\(27f i/foq5 33 20  0   260 30   for i I l  M with the phase  randomly chosen from   20   0 2 7 and the frequency f randomly generated in the range 10   10       1 Js 4 1\260 10 1 0 0 0 0.75 0.7~~~~~~~~~~~~~~~~~~~~~~0 0.9 0.85 00 0 0 0 000 ogpq 0 0 0 1 02 1 03 legt le 1 1h02 1033 3 Exponentially-enveloped white burst transient length transient length Figure 9 Exponential case The right plot gives compariS3 i efS si i 34 son of the bias and thresholds used in the new adaptive Page procedure to those of the fixed-style Page scheme tailored to for i 1   M each specific transient length In all cases T 10l6 The agS4 Narrowband burst S4 iS created by passing white gregate SNR SL corresponding to the bias used in the fixed Gaussian noise through a narrowband filter whose bandwidth Page schme is pltted in he left igure.1S 0.3wr and whose center frequency iS chosen randomly 8 10\26065 _F 0~~~~~~~~~~~~~~~~~~~0 bL where bL denotes the bias for the fixed-style comparison only Page designed for length L 4 SIMULATION STUDY Again considering the fixed-style Page scheme first based The purpose of this section is to study the performance of the on the thresholds h's calculated by the FFT approach we above designed adaptive Page test regardless of the transient find from figure 8 that the behavior of the Page test designed signal's form strength and location The signal model is for particular transient lengths L does not provide constant detectability and thus modification according to our adaptive Ho x  w 31 Page procedure is desirable Therefore b and h\(L are ob tained according to 23 and 21 The corresponding fixed H1 x\(n  s\(n n men  n  n  nd bias b and variable threshold h\(L are plotted and compared s\(n  w\(m nS  n  mS  Td to those used in the fixed-style Page tests in figure 9 The 32 performance of the adaptive Page procedure is given in figure 10 and a gratifying detection improvement is observed in which x denotes the observation vector w is white Gausespecially for shorter transient lengths sian noise with zero mean and unit variance the vector s is the transient signal of interest The transients are of short du-1 ration M compared with the observation length N In our 60r 7 r 1.5 simulations we always use N  128 M  30 fs  16  2  and A  0.5 unless stated otherwise The transients are as 2.5 50   2.5  follows 50 10\260 1021o2 100 t analysis fixed-style envelope sient lengh0 0 simulation fixed-styld te envelope betwen7flse0larm0is  l6 Te udatetake theform Pagetestoptiize  anansiena adap style simulation adap style Page 0.4 designed for L200 loo 101 0 2 10 oo 101102103 transient length transient length Figure 8 Detect"ab"ility of exponential transients using fixedFigure 10 Performance of the adaptive Page scheme in style Page procedures designed for various but specific tranExponential transient problem The Pd envelope from the sient length L In all cases Pd 0.8 and the average time normal fixed-style Page procedure and the performance of the between false alarms is T 106  The update takes the form Page test optimized for transient length L=200 are shown for g\(x x 


2 35 04 T 2 0.4 0.2 0.2 provides the best performance over a wide range of transients 10 15 20 25 10 15 20 Unlike the Page detector the transient duration M is required here and Tmax does indeed show some sensitivity as regards c d this parameter as illustrated in figure 11 for transient signal 7  sl Similar relationship between Tmax and M is observed for 0.8 0.8 other types of transients 0.2 0.75 0 Cl 10 15 20 25 10 15 20 0.7  a aggregate Certainly this is not an exhaustive menu of transients but a for v is 2.5 when information about M is completely unavailwide range is covered able In fact several new power-law detectors were developed in 19 for instance we have We apply the adaptive Page detector designed in section 3 the Gaussian shift-in-variance case to the above transient's T a _da Page 0.6 Tma 0.6 Mf-1+i 0.6 l0.6 0.8 0.4 0.4 0.2 X X XN 37 detection The b and h\(L derived according to 21 is 12\(N Z\(Xi  X+\261 3 used in this adaptive detector where Pd  8 T  106 and t N  128 The assumptions on which the adaptive Page proSimilarly by combining 3 contiguous FFT bins we can write cedure is built are those of Si the detector is weakly suited Tf 3 It was found that for most practical transient signals Tf 2 to S3 and would seem to bear little affection for either S2 or and Tf 3 were preferable to Tpl S4 a b To illustrate the performance of our adaptive Page detector we compare it to other detectors In 18 it was found that 0.8  0.8 Nuttall's maximum detector 14 SNR dB aggregate SNR dB 0.65  Figure 12 Detection performances of the adaptive Page scheme The transient duration is M  30 samples different oT 0.6  panels refer to different transient signals with a transient signal sl b transient signal 82 c transient signal 83 and 0.55  d signal 84 0.5  We plot Pd versus the aggregate SNR in figure 12 in which Pf a  10-4 It is noted that the adaptive Page procedure 0.45 provides very close performance to that of the maximum detector in all four situations which is best in all cases as 0.4 0 20 40 60 M 80 100 120 in 18 This is exciting as we recall that M is tuned in the maximum detector and that our adaptive Page test reFigure 11 Detection performances of Tmax vs Al for quires no such prior information It is additionally noted that transient signal sl The true transient duration is M  30 qursnschpirnfmao.Itsadtoalyoedht transient  sina  Th tretasetduaini.l 3 the adaptive Page procedure provides performance superior samples and the aggregate SNR is 18dB The dash-dotted line indicates the best performance of Tmax when true M to even the improved power-law detector Tf12 in most cases is chosen The dotted line indicates the performance of the with the exception of S2 in which the transient is highly naradaptive Page scheme rowband Nuttall's Tmax looks for an increase in empirical variance as 5 SUMMARY does our Page processor In  1 8 it was found that another detector due to Nuttall works particularly well for narrowband The standard Page test is designed to detect a change in distritransient signals this based on the power-law statistic 15 bution amongst a conditionally independent observation pool defined as but works nicely at detecting even transient changes provided N they are of known character The standard Page update has Tp1 N 5 i 36 implicit a fixed negative bias and a detection is recorded i upon passage by this update of a fixed threshold these the In 36 v is an adjustable exponent and the Xi  are bias and threshold are determined by the ambient and tranmagnitude-squared FFT bins corresponding to the observasient distributional models fO and fil Specifically when fO tions x It has been found that the best compromise value and fi are close the bias is light and threshold high and 9 1 0 T with v=2.5 0.4 Tmax max S 


when fo and fi are distinct the Page test uses heavy bias and quence of Random Variables Biometrika Vol 57 No low threshold 1 pp 1-17 1970 6 B Broder and S Schwartz Quickest Detection ProceNotionally a transient signal that is long-and-quiet and one dures and Transient Signal Detection ONR Technical that is short-and-loud ought to have approximately the same Res and Transier 1990 detectability However these two engender very different Report 2 November 1990 Page tests and unfortunately the test designed for one can 7 D Casasent J-S Smokelin A Ye Wavelet and Gabor work quite poorly for the other Consequently in this paper Transforms for Detection Optical Engineering Vol an adaptive Page processor has been developed it uses a con31 No 9 pp 1893-1898 September 1992 stant bias but has a threshold that adaptively changes with the 8 S Del Marco and J Weiss M-band Wavepacket-Based number of samples since the most recent reset Transient Signal Detector Using a Translation-Invariant Wavelet Transform Optical Engineering Vol 33 No The new detector has been studied extensively in the Gaus7 pp 2175-2182 July 1994 sian shift-in-mean and shift-in-variance and also in the expo[9 T Dyson Topics in Nonlinear Filtering and Detecnential shift-in-scale cases It works very well and essentially tion PhD Thesis Princeton University Princeton NJ traces the envelope of performance achievable with the best 1986 Page processor tuned to each transient length the proposal is reasonable but ad-hoc but apparently we hardly could do 10 B Friedlander B Porat Performance Analysis of better Transient Detectors Based on a Class of Linear Data Transforms IEEE Transactions on Information TheTransient detection is interesting because one does not know ory Vol 38 No 2 pp 665-673 March 1992 in advance the sort of transient signal one has to look for it 11 C Han P Willett and D Abraham Some Methods could be narrowband or not it could have a sharp attack or it to Evaluate the Performance of Page's Test as used to could increase slowly and disappear abruptly Many transient Detect Transient Signals IEEE Transactions on Signal detectors are tuned to one type of transient and comparatively Processing pp 2112-2127 August 1999 blind to others What tends to unite transient signals of prac[12 G Lorden Procedures for Reacting to a Change in Distical interest however is that they are an organized agglomtribution Annals o Mathematical Statistics vol 42 eration of energy into contiguous or nearby time samples 1897-1908 1971 Now assuming a unit-normal ambient a transient detector pp 1 that assumes nothing but this local scale-change and one that 13 G Moustakides Optimal Stopping Times for Detectis reasonably insensitive to other characteristics such as specing Changes in Distributions Annals of Statistics vol trum is that based on the Page structure for Gaussian shift14 pp 1379-87 1986 in-variance The adaptive Page test developed here is also 14 A Nuttall Detection Capability of linear-And-Power insensitive to transient length it has here been tested for a Processor for Random Burst Signals of Unknown Locavariety of transient signals for which it is not on the surface tion NUWC-NPT Tech Rep 10,822 August 1997 well-suited and its performance has been found remarkably N o-Law Progood 15 A Nuttall Detection Performance of Power-LwPo good.a cessors for Random Signals of Unknown Location REFERENCES Structure Extent and Strength NUWC-NPT Technical Report 10,751 September 1994 1 D Abraham Asymptotically Optimal Bias for a Gen[16 E Page Continuous Inspection Schemes Biometrika eral Nonlinearity in Page's Test IEEE Transactions vol 41 pp 100115 1954 on Aerospace and Electronic Systems pp 1-8 January 17 B Porat and B Friedlander Performance Analysis of 1996 a Class of Transient Detection Algorithms-A Unified 2 M Basseville and I Nikiforov Detection of Abrupt Framework IEEE Transactions on Signal Processing Changes Theory and Application Englewood Cliffs Vol 40 No 10 pp 2536-2546 October 1992 NJ Prentice Hall 1993 18 Z Wang and P Willett A Performance Study of Some 3 A Shiryaev On Optimum Methods in Quickest DetecTransient Detectors IEEE Transactions on Signal Protion Problems Theory Prob Appl Vol 8 No 1 pp cessing Vol 48-9 pp 2682-2686 September 2000 22-46 1963 19 Z Wang and P Willett All-Purpose and Plug-In 4 M Basseville Edge Detection Using Sequential MethPower-Law Detectors for Transient Signals IEEE ods for Change in Level-Part  Sequential Detection Transactions on Signal Processing November 2001 Of Change in Mean IEEE Transactions on Acoustic 20 P Willett and B Chen A New Sequential Detector Speech and Signal Processing Vol ASSP-29 No 1 for Short Duration Signals Proceedings of ICASSPFeb 1981 98 Seattle WA May 1998 5 D Hinkley Inference About the Change-Point in a Se[21 P Willett and Y Bar-Shalom Track Testing for Single 10 


Targets in Clutter Proceedings of the SPIE Aerosense Now using the above procedure we can calculate hL for tranConference on Signal Processing for Small Targets sient duration L L  1  N given T and thus the timeApril 2000 varying threshold h\(L via 21 and also the performance in terms of Pd of the Page and our adaptive Page tests APPENDIX 2 EVALUATE PERFORMANCE OF ADAPTIVE 1 THE FFT APPROACH TO EVALUATE PAGE TEST PERFORMANCE OF FIXED-STYLE PAGE TEST For the transient change problem modeled as in 10 the runlength metrics 5 and 1 are of less interest than they would be for the permanent change problem Further and perhaps more important given their context in this paper these approximations do not apply at all in the case of a time-varying Uration A Page update Thus given the update rule and the average time-between-false alarms T we employ the FFT approach introduced in 11 to obtain the requisite threshold h that satisfies it and then to get the detection performance Pd Interested readers please refer to 11 for detail since here only a j l brief description is given AYvvfj Consider Page's test as an iterated sequential test ST with 7 n sample ihdex n    sbti-Sb lower and upper thresholds 0 and h Each individual ST is defined as an update rule Figure 13 Illustration of a Page implementation 20 with Z Z.i  g\(x non-zero initial point The change starts at point nm indicated by the dotted line and a decision rule as in 20 The procedure to calculate the probability of detection for the Thus the pdf of Zn is adaptive Page scheme is complicated by the fact that the Page bn Z  fn\(Z  fg Z 38 statistic be non-zero at the start point of a change Figure 13 shows such an example where the transient change begins at where fg is the pdf of the update g\(xn fn-i denotes the point nm and the threshold index i  5 at the start point nm pdf of Zn given that the test has continued to time n and due to the non-zero initialization Since the threshold index  denotes convolution the convolution can be made both i plays an important role in the adaptive scheme a non-zero accurate and quick via a fast Fourier transform FFT Then initialization could result in a different detection decision It we compute is thus necessary to calculate detection probabilities for difOn Z ferent threshold index i corresponding to the start point nm fn\(z f h n  0  z  h 39 Overall under the H1 hypothesis we have JO fn z dz 00 as a direct normalization In a straightforward manner under Pd\(nd S p\(i nd i 42 the Ho hypothesis one can express T as i=l F Eo  F1 N 40 where nd is the transient length and i is the threshold index T n=Z P1\(n corresponding to the start point nd According to the definiwhere Ei N is the expected number of samples to a decision tion the pmf p\(i is decided by the characteristics of the test for hypothesis Hi and pi n Pr\(ST ends at n and decides Hl Ho Under the H hypothesis assuming the standard situation we p\(i Pon i 1 Ho 43 have E 0 Pon nm Ho ndl1 Pd nd 5 Pr detect k resets 41 where Pon n l Ho Pr ST will continue to time-step n I I Ho k=o Under the Ho hypothesis assuming fo z  d\(z with the where nd is the transient length6 update g  we can calculate the pdf fr,\(z H0 according to 39 and thus calculate Pon nm Ho0 correspondingly 61n 11 it was noted that the probability of detection is increased both by latent detections caused by diffusive threshold-crossings after a transient's For each index i to calculate the corresponding Pd md i in end and also by a non-zero CUSUM value at the inception of a transient  Both of these can be accounted for via the direct FFT approach and for 42 we need to study stopping probabilities both for the case details we invite the reader to examine 11 fo Z f&i-1\(Z Ho and for fo z 5\(z  For the case that 11 


fo z fi 1 z Ho we consider a decision rule Z Jane Wang Z Jane Wang received the BSc degree from Tsinghua Univer[h\(n+i-1 stopanddecideH sity China in 1996 and the MS and ZC  h[\(n  i1 c ntine dtest 44 PhD degrees from the University of Con 0 h\(m  i 1 continue test necticut in 2000 and 2002 respectively oc 0 stop and decide Ho all in electrical engineering She spent two years as Research Associate of ElecAd b d ts d rtrical and Computer Engineering DeAnd based on this decision rule 44 we compute the imporpartment and Institute for Systems Research at the Univertant quantities sity of Maryland She is now an Assistant Professor in the Department of Electrical and Computer Engineering at the pO\(m  Pr\(ST ends at n and decides Ho University of British Columbia Her present research interests are in the broad areas of statistical signal processing p n  Pr ST ends at n and decides Hi r4 in Pr\(ST ends at in and decides H1 information security and wireless communications Respectively for the case that fo z  d\(z we consider a decision rule Peter Willett Peter Willett is a Profesh c s and decide H sor of Electrical and Computer EngiZne 0,h cstop 1 neering at the University of ConnectiZn E 1 0,h\(n continue test 45 _ cut Previously he was at the University oo 0 stop and decide Ho of Toronto from which he received his BASc in 1982 and at Princeton University from which he received his PhD in and compute the corresponding quantities p\260\(n and po n 1 H h w e mrt Now using p n and p n and pog\(n and po n we can  E 18.Hha rte,mogterop Now,'using a a  ics about the processing of signals from volumetric arrays calculate Pd nd i as in 41 and finally calculate the overall decentralized detection information theory CDMA learPd nd in 42 It is worth to mention that for theoretical d  ing from data target tracking and transient detection He analysis we use the infinite as the upper bound of i in 42 is a Fellow of the IEEE and is a member of the IEEE Sighowever we use a finite reasonable upper bound in practical nal Processing Society's SAM technical committee He is an calculation For instance in the Gaussian shift-in-mean appliassociate editor both for IEEE Transactions on Aerospace cations we plot p\(i vs i in figure 14 From this figure it is and Electronic Systems and for IEEE Transactions on Sysclear that p\(i decays quickly with the increase of i therefore tems Man and Cyberetics He is a track organizer for it is reasonable to consider the truncated pmf Similar obserRemote Sensing at the IEEE Aerospace Conference 2001vations could be found for the Gaussian shift-in-variance and 2003 and was co-chair of the Diagnostics Prognosis and the Exponential cases System Health Management SPIE Conference in Orlando He also served as Program Co-Chairfor the 2003 IEEE Systems 02 Man  Cybernetics Conference in Washington DC 0.18 0.16  0.14 0.12 a 0.1 0.08 0.06 0.04 0.02 100 101 102 103 Figure 14 The pmf p\(i in the Gaussian shift-in-mean case 12 


Database 1 proc 2 procs 4 procs 8 procs T5.I2.D100K 20 17 12 10 T10.I4.D100K 96 70 51 39 T15.I4.D100K 236 168 111 78 T20.I6.D100K 513 360 238 166 T10.I6.D400K 372 261 165 105 T10.I6.D800K 637 435 267 163 T10.I6.D1600K 1272 860 529 307 Table 3 Naive Parallelization of Apriori seconds   0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2    0 2 4 6 8 10 12 0 2 4 6 8 10 12 Speedup Number of Processors CCPD : With Reading Time Ideal  T5.I2.D100K.t2   T10.I4.D100K.t2   T15.I4.D100K.t2   T20.I6.D100K.t2   T10.I6.D400K.t2   T10.I6.D800K.t2   T10.I6.D1600K.t2  Figure 4 CCPD Speed-up a without reading time b with reading time 13 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


Reading  f Total Time Database Time P 000 1 P 000 2 P 000 4 P 000 8 P 000 12 T5.I2.D100K 9.1s 39.9 43.8 52.6 56.8 59.0 T10.I4.D100K 13.7s 15.6 22.2 29.3 36.6 39.8 T15.I4.D100K 18.9s 8.9 14.0 21.6 29.2 32.8 T20.I6.D100K 24.1s 4.9 8.1 12.8 18.6 22.4 T10.I6.D400K 55.2s 16.8 24.7 36.4 48.0 53.8 T10.I6.D800K 109.0s 19.0 29.8 43.0 56.0 62.9 T10.I6.D1600K 222.0s 19.4 28.6 44.9 59.4 66.4 Table 4 Database Reading Time in section 4 320 computation balancing hash tree balancing and short-circuited subset checking The 336gure on the left presents the speed-up without taking the initial database reading time into account We observe that as the number of transactions increase we get increasing speed-up with a speed-up of more than 8 n 2 processors for the largest database T10.I6.D1600K with 1.6 million transactions r if we were to account for the database reading time then we get speed-up of only 4 n 2 processors The lack of linear speedup can be attributed to false and true sharing for the heap nodes when updating the subset counts and to some extent during the heap generation phase Furthermore since variable length transactions are allowed and the data is distributed along transaction boundaries the workload is not be uniformly balanced Other factors like s contention and i/o contention further reduce the speedup Table 4 shows the total time spent reading the database and the percentage of total time this constitutes on different number of processors The results indicate that on 12 processors up to 60 of the time can be spent just on I/O This suggest a great need for parallel I/O techniques for effective parallelization of data mining applications since by its very nature data mining algorithms must operate on large amounts of data 5.3 Computation and Hash Tree Balancing Figure 5 shows the improvement in the performance obtained by applying the computation balancing optimization discussed in section 3.1.2 and the hash tree balancing optimization described in section 4.1 The 336gure shows the  improvement r a run on the same number of processors without any optimizations see Table 3 Results are presented for different databases and on different number of processors We 336rst consider only the computation balancing optimization COMP using the multiple equivalence classes algorithm As expected this doesn\325t improve the execution time for the uni-processor case as there is nothing to balance r it is very effective on multiple processors We get an improvement of around 20 on 8 processors The second column for all processors shows the bene\336t of just balancing the hash tree TREE using our bitonic hashing the unoptimized version uses the simple mod d hash function Hash tree balancing by itself is an extremely effective optimization It s the performance by about 30 n n uni-processors On smaller databases and 8 processors r t s not as 14 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



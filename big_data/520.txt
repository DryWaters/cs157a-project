A Case Study for Distributed Business Transaction Coordination across Hete rogeneous Platforms  Bin Mu Xianing Zhang Shijin Yuan School of Software Engineering Tongji University Shanghai, 201804, P.R China E-mail: binmu99@163.com School of Software Engineering Tongji University Shanghai, 201804, P.R China E-mail: tongjixianing@gmail.com School of Software Engineering Tongji University Shanghai, 201804, P.R China E-mail:  ysj1975@tom.com  Abstract Recently, more and more enterprises with large EIS systems have increasing business demands on enhancing the 
system's scalabilities and serviceabilities. They may want to reuse the existing business logic code deployed in the legacy systems, e.g core banking systems, in the newly developing systems to meet the new business requirements. Therefore, a big challenge lies on that how to integrate these distributed business transactions running on modern and legacy systems and moreover, how to synchronize these distributed transitions to guarantee the transaction’s ACID properties across heterogeneous platforms In this paper, we adopts Web Service Atomic Transaction \(WSAT\ mechanism to propose a conceptual solution to address the problems of transactions’ integration and coordination. A 
detailed analysis of the characterization of the proposed solution is carried out to obtain a flexible and extendable framework for the fast distributed transactions’ coordination.  A research WSAT based distributed communication system, which has been developed on IBM Mainframe Customer Information Control System \(CICS\nd Microsoft Windows WebSphere Application Server \(WAS\ and experimental results indicate that a full WSAT based communication architecture can remarkably increase the EIS’s reliability, flexibility and interoperability Keywords\0006\000\\\000V tem integration; Distributed transactions coordination ; Web Services;  Data consistency 
I   I NTRODUCTION  In most EISs there exist many business distributed transactions which are executed simultaneously to accomplish a whole business processing logic. These distributed transactions always have the following characteristics 1 They run on heterogeneous platforms separately 2 Each of them has its own independent data source 3 They have various technical implementing methods e.g. different programming languages So the most difficult thing is how to integrate these distributed transactions within a single business processing flow. Currently, there are some transactional connectors which 
can be used for integrating the distributed transactions However, they are manufacturer-oriented which means that they are tightly coupled with some particular transaction processing software. For example, IBM CICS Transaction Gateway \(CTG\n only be used to coordinate the transactions running on the IBM platforms such as CICS or WebSphere This constrains the system’s extendibility. If we want to integrate e.g. the transactions running on the MS .Net platform and IBM CICS, we have to develop a new connector fit for these both platforms. We hope to find a loosely coupled method to integrate the distributed transactions without being 
restrained by the platforms Web Service Atomic Transaction \(WS-AT\s a compound technology which uses the transaction processing technology via the web service to cross the platforms, integrate and synchronize the distributed transactions. Because of its open standard capability WS-AT allows distributed transactions to be integrated seamlessly across platforms In this paper, we present an approach for WS-AT based distributed system and choose CICS Transaction Server as the legacy system on which the application is implemented in Enterprise COBOL and WebSphere Application Server as the modern system on which the application is implemented in 
Java \(J2EE\. It is valuable for several reasons 1 It presents a conceptual architecture for integrating the distributed transactions in legacy and modern systems based on WS-AT 2 It is based on Mainframe and PC platforms which typically indicate the heterogeneous characteristics of the distributed platforms 3\ It leverages traditional distributed processing technology to a web service based transaction processing technology that is not limited by the network transport protocol and application’s implementation technology and can be easily deployed in Service Oriented Architecture \(SOA\ environment 
3   The main focus of this paper is on the application level architecture for WS-AT based distributed transaction systems In Section II, we introduce how a traditional distributed transaction processing method is mapped to a WS-AT based method. In Section III, we present a demo WS-AT based distributed system and its conceptual architecture design and implementation. Meanwhile we test the whole system with different scenarios and analyze its workload in Section IV 
2010 International Conference on Electrical and Control Engineering 978-0-7695-4031-3/10 $26.00 © 2010 IEEE DOI 10.1109/iCECE.2010.1107 4584 
2010 International Conference on Electrical and Control Engineering 978-0-7695-4031-3/10 $26.00 © 2010 IEEE DOI 10.1109/iCECE.2010.1107 4584 


Finally, we summarize the findings of this research study in Section V II  T RADITIONAL DISTRIBUTED TRANSACTIONS V.S  WSA TOMIC T RANSACTIONS  A  Traditional distributed transactions The ACID properties \(atomicity, consistency, isolation, and durability\of transaction guarantee that all the actions or operations in a single transaction are always in a known and consistent state. Now consider a situation where there are several transactions which need to cooperate in a single activity e.g. the transfer service of a bank involving two transactions illustrated in Figure 1       Figure 1  Single activity contains various recoverable transactions B  Web Service Atomic Transactions WS-AT is essentially driven by several protocols or specifications with the following functionalities 1  Providing the ability for Web service applications to participate in global transactions, which means you can build a global transaction to control the distributed transactions 2  Guaranteeing the data integrity and ACID properties atomicity, consistency, isolation, and durability\ of transactions 3  Providing flexibility and interoperability for distributed activities processing Compared with the traditional distributed transaction process, WS-AT defines the standard protocols or specifications for the applications exchanging their messages That means in the traditional distributed transactions there are mostly non-universal communicating mechanisms that sometimes only worked between certain combinations of entities \(applications, resource managers, and coordinators or transaction monitors\ while in WS-AT transactions, with the combination of some open standard specifications such as Web services, WS-Coordinatio W S-A d dr e ssi ng  4  a nd WSAtomic Transaction[5  dis t ri bu te d  t r an s act ion s can  communicate with each other seamlessly Figure2 illustrates how the traditional distributed transaction processing flow with two transactions is mapped to a WS-AT based flow. At any execution time, the transactional application which invokes Transaction1 and Transaction2 via Web service regards Transaction1 and Transaction2 as one single transaction and it can use any transaction control mechanism e.g. Java Transaction API \(JTA\ to synchronize them. The two sycnpoints can guarantee the ACID properties of these two distributed transactions during the execution flow                Figure 2.  WS-AT based distributed transactions processing flow During the execution life cycle, every atomic transaction has a minimal set of states as follows       state t active registered completed aborted failed cancelled 002 Af ter initialized, the state of a transaction’s instance can be either activated or aborted. Once it is active, the instance can normally continue its execution or it can be cancelled during its execution. In the first case, it can achieve its objective and successfully completes or it can fail. The abortion condition can guarantee the atomic transactions to roll back the previous updates on their data sources before the global transaction is completed. More formally the activation and abortion conditions for every atomic transaction 1 i i in t 003\003 can be illustrated as follows 2 1   j i i j i n ActiveCond t t reg istered  004 003  000\037  Here we exclude 1  ActiveCond t which is the condition when the coordinator creates the coordination context for its sub-atomic transactions 1   1   ij j j in jnj i AbortCond t t t t aborted f cancelled ailed 004\003 003 005 005 003 003 006  III  A CONCEPTUAL WS-AT BASED DISTRIBUTED INFORMATION SYSTEM  A  System Architecture In this demo system, which is a commodity and stock management system with the functions of placing orders inquiring catalogs and dispatching orders, the transactions run on two kinds of platforms: one is CICS Transaction Server on IBM Mainframe z/OS which contains the core business logic and the other is WebSphere Application Server \(WAS\ on A single activity   Take money from account-1 database   Put account-1’s money into account-2 database Transaction1 Transaction2 All or nothing outcome  Commit Trans Begin Trans  Sycnpoint1  Sycnpoint2 WS-AT 2PC Protocol WS-AT Completion Protocol    WS-C Registration Protocol  Sate=In Commit Or In Rollback  Prepare p hase  Commit phase  WS-C Activation Protocol Transaction1 Transaction2 Coordinator  Transactional APP  Create Coordination Context  
4585 
4585 


Microsoft Windows which allows a user to use the above functions via web interfaces. Figure3 illustrates the whole system’s architecture  Figure 3  Architecture of the conceptual system Correspondingly there are four deployed applications each of which has an independent data source: VSAM file in CICS1 application containing the commodity catalog data including the item number, item name and stock amount, one Mainframe DB2 table in CICS2 application containing the ordered commodity data including item number and amount of the ordered commodities, and two Windows DB2 tables in WAS1 WAS2 applications recording the ordering and dispatching information The system architecture can be abstracted into two basic types of models 1\. Chain model: In this model, there's a primary \(or root coordinator \(WAS1 application\hat invokes a Web Service and the invoked Web Service then invokes a second Web Service. The entire atomic transaction is controlled by the primary coordinator. The middle system \(CICS1 application takes on the role of a coordinator and the role of a participant at different times in its life cycle. When the primary coordinator instructs the middle system during transaction termination, the system acts as a participant. However, before it responds to the primary coordinator, it takes on the role of coordinator of its own participants \(WAS2 application 2\ Hub model: In this model, the primary coordinator invokes one Web Service \(CICS2 application\and then another. It then coordinates them together Simply, we can adopt the hub model in which a single coordinator controls all the distributed transactions. However this will increase the coordinator’s capacity, so in the chain model the applications in the middle nodes will take over the coordinating responsibility when there are too many bundles of transactions at a time In our model, the execution time of the global business transaction depends on the pre-defined expiration time for each atomic transaction, atomic transactions’ waiting time and the sum of each sub-atomic transaction’s execution time. It can be computed as follows  1 1 n global atom ic execute wait i i TT T n     000 1  exp 1  1 1 max   ire i n atomic wait i i wait in Tn TT      000 2 For the atomic transaction’s waiting time  1 atomic wait i Tin   it depends on the additional holds [10  of th e av ail a ble r e s o u r ces f o r ea ch  W S A T  r e qu e s t  which is computed as follows   max{0     1 additional iii H thtartin 007 3 At the 2PC prepare phase, the coordinator will grant some holds for the participants on one unit of available resource, and it is denoted by a positive number i a  1 1  i ai n 010 and once the participant\(atomic transaction\ gets a hold on one resource, the resource will be locked  i ht is the number of active holds at time t and  i rt is the number of requests at time t The number of the holds left for new requests at time 2 t depends on the number of requests and the number of holds granted for resources at time 1 t  12 tt  If there are more additional holds for atomic requests, the possibility of waiting decreases, that is, the  1 atomic wait i Tin   decreases For example, in our system assuming that there are 7 active holds at time 1 t  1  i ht 7 i a 2 and there are three WS-AT requests 1  i rt 3\. When a new request is proved to have a hold at prepare phase at time 2 t  21 tt   2  additional H t is max {0, \(7-1\2*\(3-1\ = 2 \(Equ.\(3\\On the other hand, if we assumed 1  i ht 4 2  additional H t would be max {0, \(4-1\2*\(3-1\ = 0, that is, the new request would be pending. The global transaction’s waiting time can characterize the performance of the whole system whose corresponding data are shown in the part B of section IV B  Setup WS-AT infrastructure Due to lack of space we just list some key points of our system’s implementation whose detail steps are illustrated in our former tutorial article [1 h e app l i c a t i o n r unni ng o n CICS was developed by COBOL programming language. To integrate the CICS application with the WebSphere application we need to map the COBOL language structure to the XML based data structure meanwhile we need to publish the business interfaces of the CICS application as Web Services. TABLE I and TABLE II illustrate how a COBOL copybook is mapped to a XML based data structure T ABLE 1  E XAMPLE OF A COBOL COPYBOOK          T ABLE II  E XAMPLE OF A XML DATA ACCORDING TO A SEGMENT OF THE COBOL COPYBOOK  Catalogue COMMAREA structure 03 CA-REQUEST-ID                    PIC X\(6 03 CA-RETURN-CODE                PIC 9\(2\ DISPLAY 03 CA-RESPONSE-MESSAGE        PIC X\(79  
4586 
4586 


          At run time we use data mapping files which are defined in CICS as one of the PIPELINE resources for the data conversion work and use WSDL and URIMAP to locate the services In the WebSphere application we use Java Transaction API JTA\to demarcate a global transaction. In the global transaction we invoke the CICS transactions via Web services and synchronize them by WS-AT mechanism as shown in TABLE III T ABLE III  G LOBAL TRANSACTION INSTANCE WITH JTA          In fact, to enable WS-AT does not require the system developers’ extra coding effort. Many middlewares have implemented the WS-AT specification and the only thing for the developers is the configuration work [1, 6  in w h ich w e  figure out how the distributed applications communicate with each other by specifying the WS-Addressing endpoints and what kind of roles they should play in the whole system architecture, that is, how to coordinate them in an atomic transactional flow. But the most important thing is to make the system web service driven and integrate the distributed transactions with a rational architecture IV  E XPERIMENTAL RESULTS  A  Test scenarios We test the system in normal and abnormal scenarios respectively. Our test environment is shown in TABLE IV  T ABLE IV  T EST ENVIRONMENT  Mainframe PC z/OS v1.7 Windows XP Pro CICS Transaction Server V3.1 with two CICS regions WebSphere Application Server 6.0.2.17 z/OS DB2 V7 DB2 V8.2.1 with XA data sources One LPAR with 3 CPUs and 20 GB memory IE 6.0 Intel Pentinue4 2.4GH z CPU; 1GB Memory In the normal scenario, the coordinator initializes the global WS-AT transaction which synchronizes the other three atomic transactions and all the updates in data sources \(VSAM file and DB2 tables\ are made correctly and permanently In the abnormal scenario we add some exception code during the flow execution. We let the application throw a Java RemoteException error in syncpoint2 \(see Figure2\. So this time the global transaction rolls back and all the updates are backed out from DB2 table “order on windows DB2 table “dispatch on windows CICS VSAM file DB2 table “onorder on z/OS Figure4 illustrates the business process of placing orders with the WS-AT message exchange flow in the normal scenario              Figure 4  Message exchange diagram  For tracking the coordination messages we use the WebSphere TCP/IP monitor to catch the SOAP messages sent and received by WebSphere and print the trace messages of the SOAP header processing programs of CICS. Here we list the placeOder” and “dispatchOder” WS-AT request and response SOAP messages  T ABLE V  P LACE O RDER W EB S PHERE REQUEST SOAP MESSAGE     xsd:sequence xsd:element name="ca_request_id" nillable="false xsd:simpleType xsd:restriction base="xsd:string xsd:maxLength value="6 xsd:whiteSpace value="preserve xsd:restriction xsd:simpleType xsd:element xsd:element name="ca_return_code" nillable="false xsd:simpleType xsd:restriction base="xsd:unsignedShort xsd:maxInclusive value="99 xsd:minInclusive value="0 xsd:restriction xsd:simpleType xsd:element xsd:sequence  UserTransaction userTransaction = null try InitialContext context = new InitialContext userTransaction=\(UserTransaction context.lookup\("java:comp/UserTransaction userTransaction.begin invoke atomic transactions  commit userTransaction.commit catch \(java.rmi.RemoteException re try userTransaction.rollback    6  Register Response WebSphere2 14  2PC commit 7  Return message Order in dispatch 5  Register  4  Invoke dispatchOrder Web Service with CoordinationContext CICS2 CICS1 15   2PC commit 12  Return message Order successfully updated 11   Register Response 10  Register 9   Invoke onOrder Web Service with CoordinationContext 13  2PC commit  8   Return message Order successfully placed  3 Register Response 2  Register 1  Invoke placeOrder  Web Service with CoordinationContext WebSphere1 
4587 
4587 


                    T ABLE VI  P LACE O RDER CICS RESPONSE SOAP MESSAGE                B  Workload analysis Using WS-AT can remarkably increase the system’s extendibility and scalability but whilst the whole system’s workload is accordingly augmented. The main factors in the workload costs are related to the XML parsing and distributed transactions coordinating For the XML parsing costs, because the maximum COBOL data name length is 30 bytes we collected the following benchmark results a s  sh ow n i n T A B L E V I I    T ABLE VII  XML PARSING COST IN TWO EXTREME CONDITIONS   1 byte XML tag name 30 byte XML tag  name Every 100 elements Inbound 0.27ms CPU 0.56ms CPU Every 100 elements Outbound 0.18ms CPU 0.39ms CPU  In our demo system there are 29 inbound elements and 17 outbound elements with average tag sizes of 15 bytes so the calculation of the extra costs would be computed as follows  max min min max min    100 in out tag NN T T Cost S T SS     4 Inbound elements processing costs \(Equ.\(4 0.56 - 0.27\*15/ \(30-1\ + 0.27\*29/100 = 0.12 ms CPU Outbound elements processing costs \(Equ.\(4 0.39 - 0.18\*15/ \(30-1\ + 0.18\*17/100 = 0.05 ms CPU So approximately an extra 0.17 ms of CPU time is added per transaction For the costs of distributed transactions coordinating, we use Enterprise Workload Manager \(EWLM\ Tool to collect the CPU usage data as shown in Figure5. Due to the multiple CPUs available during the transaction processing period, CPU usage rate recorded was greater than 100  Figure 5.  CPU usage of WS-AT access The increasing trend of CPU usage is tremendous when the number of transactions increase. According to the analysis of our system model in the part A of Section III \(see the Equ. \(2 and Equ.\( 3\\, the reason for this tremendous increase is that during the transaction processing the coordinator adds an exclusive lock for each of the atomic transactions and when multiple transactions request a common resource simultaneously they have to wait for others releasing the lock which affects the system’s performance especially when there exist long and short processing transactions at the same time in a single processing flow soapenv:Envelope xmlns:soapenc xmlns:wscoor="http://schemas.xmlsoap.org/ws/2004/10/wscoor soapenv:Header wscoor:CoordinationContext soapenv:mustUnderstand="1 wscoor:Expires>Never</wscoor:Expires wscoor:Identifier>com.ibm.ws.wstx:00000110be001306 wscoor:Identifier wscoor:CoordinationType http://schemas.xmlsoap.org/ws/2004/10/wsat  wscoor:CoordinationType wscoor:RegistrationService       xmlns:wscoor wsa:Address xmlns:wsa http://9.181.93.144:9080/_IBM SYSAPP/wscoor/services/RegistrationCoordinatorPort  wsa:Address wsa:ReferenceProperties xmlns:wsa websphere-wsat:txID xmlns:websphere-wsat  com.ibm.ws.wstx:00000110be00130  websphere-wsat:txID websphere-wsat:instanceID xmlns:websphere-wsat  com.ibm.ws.wstx:00000110be00130 websphere-wsat:instanceID wsa:ReferenceProperties wscoor:RegistrationService wscoor:CoordinationContext soapenv:Header soapenv:Body p635:DFH0XCMNOperation xmlns:p635 001\002  p635:DFH0XCMNOperation soapenv:Body soapenv:Envelope SOAP-ENV:Envelope  xmlns:wsa="http://schemas.xmlsoap.org/ws/2004/08/addressing xmlns:wscoor="http://schemas.xmlsoap.org/ws/2004/10/wscoor xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance SOAP-ENV:Body DFH0XCMNOperationResponse xmlns="http://www.DFH0XCMN.DFH0XCP5.Response.com ca_request_id>01ORDR</ca_request_id ca_return_code>0</ca_return_code ca_response_message>ORDER SUCESSFULLY PLACED ca_response_message ca_order_request ca_userid>req1</ca_userid ca_charge_dept>oracle  </ca_charge_dept ca_item_ref_number>10</ca_item_ref_number ca_quantity_req>1</ca_quantity_req ca_order_request DFH0XCMNOperationResponse SOAP-ENV:Body SOAP-ENV:Envelope 
4588 
4588 


V  C ONCLUSION  In this paper, we present a conceptual solution for the architecture of distributed systems and propose some evaluation functions for its performance and workload. It is based on WS-AT to provide flexible and loosely coupled services for integrating and synchronizing distributed transactions. As a proof of concept for the Quality of Service QoS\ implementation in mainframe, the system was demonstrated on the IBM First China CICS User Group Meeting 2008 However, WS-AT is not suitable for processing the transactions with long time spans and will in some cases increase the system’s workload. But with WS-AT support we can completely ignore the differences of the heterogeneous platforms to reuse the legacy IT assets in modern systems and make our existing EIS’s architecture more extendable, flexible reliable and interoperable to enhance our system’s quality of service in an open SOA environment A CKNOWLEDGMENT   This research study was supported in part by the IBM CSDL CICS Team, IBM Hursley Lab and IBM Tech. Center of Tongji University. Luis Lopez and Nigel Williams from IBM ITSO Organization shared many useful suggestions and provided a good sample application for this research study. The experimental workload data were collected with the help of IBM EWLM Testing Team R EFERENCES  1  Xia Ning Zhang, Guo Qiang Li. “Use WS-AtomicTransaction to integrate and synchronize CICS and WebSphere distributed transactions”, IBM world wide developerWorks, August 2007 https://www6.software.ibm.com/developerworks/education/ws-atomic 2  Luis Felipe Cabrera, George Copeland, Jim Johnson, David Langworthy. “Coordinating Web Services Activities with WSCoordination, WS-AtomicTransaction, and WS-BusinessActivity January 2004, http://msdn2.microsoft.com/enus/library/ms996526.aspx#wsac_topic4a 3  Mark Endrel, Jenny Ang, Ali Arsanjani. “Service-Oriented Architecture and Web Services”, April 2004 http://www.ibm.com.redbooks 4  Web Services Addressing \(WS-Addressing http://www.w3.org.Submission/ws-addressing, September 2005 5  OASIS \(Organization for the Advancement of Structured Information Systems\. Business transaction protocol primer version 1.0 http://www.oasis-open.org June 2002  6  Nigel Williams, Grant Ward Able, Paolo Chieregatti Implementing CICS Web Services”, March 2006 http://www.ibm.com/redbooks 7  Feng Liu, Gesan Wang, Li Li, Wu Chou. “Web Service for Distributed Communication Systems Proc. IEEE International Conference on Web Services \(ICWS 2005 September 2006, pp 393-400  8  M. Mukarram, et al, "Introducing Dynamic Distributed Coordination in Web Services for Next Generation Service Platform", Proc. IEEE International Conference on Web Services \(ICWS 2004\, July 2004, pp 296-305 9  Wu Chou, Li Li, Feng Liu. "Web Service Enablement of Communication Services Proc. IEEE International Conference on Web Services \(ICWS 2005 July 2005, pp. 393-400    Jonghun Park, Ki-Seok Choi. “An adaptive coordination framework for fast atomic multi-business transactions using web services”, Decision Support Systems, Volume 42, Issue 3, December 2006,Pages 1959-1973   V.F. Pais and V. Stancalie, “Using web services for remote data access and distributed applications”, Fusion Engineering and Design, Volume 81, Issues 15-17, , 5th IAEA TM on Control Data Acquisition, and Remote Participation for Fusion Research 5th IAEA TM, Pages 2013-2017, July 2006    Sami Bhiri  Claude Godart, Olivier Perrin. “Transactional Patterns for Reliable Web Services Compositions  ACM International Conference Proceeding Series Vol. 263, Pages 137-144, July 2006    Sami Bhiri, Claude Godart, Olivier Perrin. “Ensuring required failure atomicity of composite Web services  Proceedings of the 14th international conference on World Wide Web Pages 138-147, May 2005    John Burgess, Trevor Clarke. “IBM's CICS Transaction Server V3.1 Web services Performance ftp://ftp.software.ibm.com/software/htp/cics/presentations/CICS_TS_3.1 _Performance_Report.pdf , March 2006   L. Z. Zeng, B. Benatallah, A. H. H. Ngu, M. Dumas. QoS-aware middleware for web services composition. IEEE Trans. Softw. Eng 2004, Vol. 30\(5\: 311  327   
4589 
4589 


  7 In the following discussion we use this transition model Other models can be incorporated similarly, including models which use roadway constraints and higher order motion terms In the experiments we discuss later, this model is valid \(i.e the diffusivity of the target is captured statistically by the diffusivity coefficient in the model\es where robust modeling of the target dynamics is not possible, one typically appeals to a multiple model approach [13 wh i c h adds robustness to the filtering by allowing it to select from a number of candidate motion models The state probability density is represented on a discrete grid and so this differential equation must be used to update that representation. This discrete update is computed from time to time  using a backward Euler method as              13 This approach has nice stability properties in both and For more details, see [1  This is illustrated graphically in Figure 4, where the left hand side represents the posterior from the k th time step and the right hand side represents the prediction for the k+1 th  time step. The white dot represents the true target position In this example, the target is moving in the positive x  direction, causing the probability mass to evolve preferentially along the positive x direction This computation method is linear in the number of grid cells used in the discretizatio n. Linear dependence on grid cell number is achieved using the backward Euler method above, yielding a tridiagonal system of equations which is efficiently solved using Thom as\222 algorithm Fi gu r e 5  illustrates this dependency from empirical tests  Figure 5\226 Computation is linear in number of grid cells Temporal update of the target present probability The target present and absent probabilities are updated according to the simple mixing model described in eq. \(8 corresponding physically to targets arriving and leaving at a constant rate. Since this is a discrete PMF with only two possible events \(target present and target absent implemented by simply storing a single floating point number corresponding to the target present probability Measurement update of the tracking probability As discussed above, evaluating the measurement likelihood for each cell performs the target state probability update   14 This simply requires computation of the likelihood ratio at each cell Specializing again to the two-node, bearings only situation, at each time step each sensor node makes measurements at all \(discretized bearings \(beams he sensor model describes statistically the likelihood of each measurem ent conditioned on target  Figure 4\226 The temporal update of th e target state probability density 


  8 present, as illustrated in Figure 6. Note that different node locations yield different beam widths and spatial information By assumption, the joint likelihood of the measurements conditioned on target present \(the numerator\he product of the two individual likelihoods \(i.e., the noise is independent from sensor to sensor  15 where from the end of Section 3 we know   16 Here is the bearing cell \(beam\ into which projects at sensor node 1. Therefore, for each grid cell in the discrete representation of we compute the hypothesis probability as proportional to    17 As mentioned above, the hypothesis \(the denominator of the likelihood ratio\rresponds to the composite hypothesis that either \(i\neither sensor has target energy in the target bearing, or \(ii\ one of the two sensors \(but not both\has energy in the target bearing. Therefore, the probability of the hypothesis is evaluated by appealing to the GLRT as          18 Finally, the measurement update for cell is computed as           19 Measurement update of the target present probability As discussed in Section 3, the measurement update of the target present probability is performed as    20 By comparison, it is seen that the inner term in this integral is the measurement update done on the target state probability density \(eq. \(14\\erefore, the update of the target present and absent probabilities simply requires summing the \(non-normalized\et state probability after the measurement update is performed, followed by a normalization step which forces  For computational purposes, it is desirable that the target state grid contain the fewest number of cells that allow robust estimation. Cells which contain zero probability mass are useless computation and should be avoided. However since we are tracking moving ta rgets, the locations of the grid cells needed to estimate the target state density change over time. Therefore, we use a moving grid, which constantly re-centers around the estimated state of the target every update. In practice, we onl y allow the grid to translate a small number of cells at each time step, which minimizes the chance that a small number of bad measurements can shift the target off the grid  Figure 6\226 Single Sensor conditional likelihoods 


  9 On Grid Resolution As mentioned to earlier, the resolution \(spacing\of the target detection and tracking spatial grid cells is of critical importance. In our method, we choose to allow each cell center to represent the entire cell. An alternative approach would treat each cell as containing many sub-cells and requiring a weighted update. This has a similar computational burden as making the grid cell finer, and provides a benefit in the single target tracking case However, in the multitarget tracking case discussed later it introduces other problems. A discussion of these problems is deferred until later In the single target tracking case where cell centers represent the cell, the main c oncern is to ensure the cell spacing is fine enough. Th is avoids cases where the conditional likelihood has energy in large parts of a cell but does not overlap with the cell center. Figure 7 illustrates this. In this figure, cell boundaries are indicated by white lines, and cell centers by black dots. The true target location is given by the green dot. The conditional probability density is indicated by the color scale showing the intersection of the two sensor node beams. Because the grid resolution is insufficient, the cell center in the cell the target actually occupies does not corr espond to the peak of the conditional as it should. This mismatch leads to the target containing cell incorrectly r eceiving low likelihood in the measurement update  Figure 7 - Grid cells must be spaced finely enough to avoid degenerate cases where no cell center corresponds to the peak of the likelihood function The remedy for this issue is to make the cells more finely spaced. Also note that unless the grid cells are spaced grossly inadequately \(as they are in the example given Figure 11 later\is problem does typically does not persist from time step to time step as the target is moving. The most catastrophic consequence of poor grid cell resolution is track fragmentation. In the case of overly coarse cell discretization, the track existence probability will be artificially driven lower resu lting in \(incorrectly\moving the track. A new track would then be instituted very shortly On Computational Requirements The dominant properties that e ffect computations are \(i number of grid cells and \(ii\he number of targets. Section 5 discusses algorithm scaling with the number of targets. Here we focus on the single target case and note that the algorithm scales linearly with number of grid cells \(which is the product      Figure 8 illustrates empirically the tradeoff between cell resolution, tracking, and algorithm run time in the single target detection and tracking case. As the grid cell resolution decreases \(i.e., the number of cells used to represent the probability density increase\e tracking error decreases. It reaches an asymptote which is dictated by the sensor resolution. Furthermore, as the grid cell resolution decreases i.e., the number of grid cells increases\the computation time increases   Figure 8 \226 For single target tracking, performance improves as grid cells become more finely spaced. This is at the cost of increased computation time A second way to deal with th e degeneracy caused by large grid cells is to compute the cell likelihood function by weighting the likelihood of the beams into which the cell projects. In other words, inst ead of using the cell center to represent the entire cell, treat the cell as the continuum of points it represents.  Doing this exactly is computationally prohibitive, but approximate methods such as averaging discrete points in a cell are feasible. This is a net computation savings over simply making the grid cells smaller because it avoids increasing the number of cells that require temporal update In the multitarget case, the problem is more complicated Since many cells will correspond to the peak of the conditional likelihood, blindly shrinking cell size or interpolating the conditional will lead to false \(double initializations of targets. We will discuss this further in Sections 6 and 7 


  10 5  M ULTITARGET D ETECTION AND T RACKING T HEORY  In principle, multiple target detection and tracking requires estimation of the joint multitarget probability density   21 where denotes the number of targets present at time k   and  are the individual states of those targets The state space of this joint multitarget probability density grows exponentially with the number of targets and hence precise computation grows ex ponentially as well. Bruteforce multitarget discrete grid representations of this high dimensional posterior become intractable with more than two or three targets in a fo ur dimensional state space Fortunately, high fidelity modeling of the joint coupling is only necessary when targets are close together, i.e., widely spaced targets can be treated nearly optimally by solving multiple single target detection and tracking problems. In the \(unrealistic\g case, where all targets are well separated in measurement space numerical estimation of the joint density grows linearly with the number of targets rather than exponentially A more sophisticated approach to this problem is to automatically factorize the joint density into small groups of targets which must be treated jointly and develop a computational solution which is a compromise between the exponential growth of the joint computation and the linear growth of the fully factored computation. A detailed discussion of a joint density adaptive factorization approach and the precise algorithmic details in a related environment are discussed at length in [5  and  6    In our present implementation, we have chosen to simply treat the multiple target situation as a collection of single target detection and tracking problems. To account for the sub-optimality of this approach when targets are nearby in measurement space, we employ a data-censoring algorithm which operates when targets are close - i.e., we make the approximation    22 and censor some of the data fr om nearby trackers to prevent improper evaluation of the conditional likelihood Future work will extend this to high fidelity sensor modeling and joint density calculation for closely spaced targets when necessary. A sk etch of this extension analogous to the approach in [5 ws. Fi rst, th e target state and relevant uncertainty will be estimated for each target. Then those targets th at are close together will be treated in clusters. The \(now joint\ probability density for the cluster of targets will be temporally and measurement updated as a group. This computation is superlinear in the number of targets, but will only operate on targets in that cluster, rather than the entire target set. This method allows for careful physics-based modeling of the sensor returns when targets are close together e.g., including the expected coherent sums of energy from nearby targets and accurately modeling sidelobe interference\d will allow for more effective handling of crossing targets and convoy movements 6  A MBIGUOUS T ARGETS  In addition to left-right ambigu ity arising from linear arrays in the present setting there are intersection ambiguities. In the multisensor, multitarget, bearings-only environment we study here there are ambiguities arising from the \(persistent intersection of bearing measur ements across sensors from e.g., \(sensor 1, target 1\and \(sensor 2, target 2 Figure 9 gives an example of this phenomenon, by showing the multisensory conditional lik elihood surface in a highSNR and low-SNR case, respectivel y. In this example, there are two passive sensors, one lo cated at the northeast and one at the southeast of the surveillance region. There are two real targets indicated by white circles. Each passive sensor receives high energy at the b earings corresponding to the true targets as expected. This results in \(correct intersections at the true locati ons of the targets. However there are also false intersections, which correspond to the mismatched beams \(i.e., a beam from sensor 1, target 1 intersection with a beam from sensor 2, target 2 


  11 Ambiguous targets often move physically for some time and for that time are indistinguishable from real targets. This short term phenomenon is not a problem with the tracker but is a fundamental issue of physics. However, over time, the ambiguous targets can be distinguished from real targets in a tracking environment as they will move in a non-physical manner. Typically this non-physical motion takes the form of a jump movement as the ambiguities approach a line of symmetry defined by the nodes Figure 10 provides an illustration of this behavior. For the first 500 time steps \(shown at left\both the true targets green\d the ambiguous targ ets \(red\anner that is plausible physically. Ho wever, as shown at right after time step 500 the ambiguous targets move in a dramatically non-physical manner. This behavior is common and in this case is co rrelated with the ambiguity position moving through a sensor line of symmetry 7  M ULTITARGET D ETECTION   T RACKING I MPLEMENTATION  As discussed earlier, we have chosen to factorize the joint density into a collection of single target densities. This approach is optimal when targ ets are well separated but is inappropriate as targets beco me close in sensor space Future work includes an adaptive approach which will appropriately treat these closel y spaced targets jointly. In the present work however, we employ an engineering approach to cope with this sub optimality which prevents measurement sharing among cl osely spaced trackers. These algorithmic modifications mean that the final product is not simply multiple single target detection and tracking algorithms running in parallel First, we partition the surveillance region into multiple overlapping static detection grids. Each detection grid is a single target detector as described above for detecting   Figure 9 \226 Bearings intersections corresponding to true targets \(white circles nd ambiguous intersections There are two sensors, located NE and SE of the image, resp ectively. Each sensor has hi gh energy returns at the bearings corresponding to the true targ ets, yielding intersections at the true target locations. However, there are also false intersections between, for example, \(s ensor 1, target 1\ and \(sensor 2, target 2   Figure 10\226 Left: true and ambiguous trajectories for the fi rst 500 time steps of the simulation. Right: After time step 500, the ambiguous targets make large non-physical jumps 


  12 targets in its sub-region. We compute the target present hypothesis independently for each detector grid. It is desirable that each detector gr id is small in total spatial extent to allow detection of closely spaced targets since each individual detection grid is only capable of accurately modeling the target absent/present hypothesis when there is either a single target presen t or no targets present. In contrast, it is desirable that each grid is large enough \(in total spatial extent\o capture multiple time steps of measurements on a moving target to allow accurate computation of the target present hypothesis Second, the single target detector/tracker equations discussed above\update each detector grid. The temporal and measurement updates proceed as if there were a single target present on the grid, updating the target present hypothesis with the new data. In this manner, each detector grid performs the Bayes-optimal single target detection and tracking algorithm for its spatial region If the target present hypothesis associated with a detector exceeds a threshold, the algorith m declares a new target and initializes a tracking grid to follow the target. This target grid is mobile and continually re-centered on the predicted target location. It is desirable that this tracking grid is as small as feasible for both computational reasons and also to allow multiple closely spaced targets to be tracked on their own grids. However, the grid must be large enough in spatial extent to account for temporal uncertainties in target motion and measurement error The individual target temporal updates proceed exactly as in the single target case. The measurement updates of the detection and tracking grids use a measurement-censoring step not present in the single target tracker. This measurement censoring step is executed in lieu of fully estimating the joint multitarget density, and should be looked upon as an engineering method for dealing with closely spaced targets that is less costly than fully estimating the joint density. In experiments with real data it has been found that this method often provides sufficient accuracy to perform adequate tracking. However, it is our plan to look at joint density estimation as in [5  fu ture work To elaborate, measurements that fall into the spatial extent of any tracker are censored from the detectors. Second trackers compete for measurem ents based on their prior probabilities. These steps prevent multiple targets from being incorrectly detected at the same location, and also prevent multiple nearby trackers from simply following the strongest target On Grid Resolution Like the case of single target tracking, it is important that grid cell spatial resolution be chosen judiciously. If grid cells are too coarse, it is possible no cell centers will project into the maximum of the conditional likelihood \(refer back to Figure 7\However, even if the grid size too large, the behavior of the tracker may not be catastrophic. Typical behavior is that a detector initiates a track; the tracker follows the target for some period of time and terminates the track; then the detector reinitiates a tracker on the same target. Figure 11 illustrates the effect of grid cell resolution on tracking performance. The left panel shows performance when the grid is too coarsely spaced. The red dots show track termination points, and illustrate that a single target track is routinely broken and restarted when the grid spacing is too coarse. The right panel shows performance when grid spacing is appropriately sel ected. All track s are followed throughout the entire vignette w ith no track fragmentation Unlike the case of single target tracking, the multitarget case exhibits problems when the grid resolution is too small. In particular, since the multitarget detectors constantly seek new targets, small grid cell resolution can have the unintended consequence of allowing energy from the conditional update to bleed onto both a tracker \(correctly and the underlying detector \(incorrectly\nd thus generate   Figure 11 \226 Left: Multitarget tracking with \(too\coarse grid resolution. Right: Multitarget tracking with appropriately selected resolution. In both panels, red dots show track termi nation points, green lines show true target trajectories, and the other colo red lines show the track estimates 


  13 false \(double\argets Figure 12 illustrates this situation. The conditional update correctly updates the tracker wh ich is tasked with following the target. However, the detector which is partially spatially coincident with the tracker also receives energy from the conditional update. This can lead the detector to initiate falsely\second target nearby the first target This effect can be countered a number of ways. First, we can adjust the speed at which the tracker re-centers itself The double initialization phenomenon occurs when the PDF peaks near the edge of the tracker grid. However, this method has the side effect of potentially allowing probability to fall off of the grid in low SNR environments causing track loss. Of course if the SNR is low enough or measurement outages occur tracks will be dropped. Second a guardband around the tracker that does not allow any detector sufficiently near the tracker to receive reinforcement via the conditional density can mitigate the double target problem. However, this has the side effect of preventing detection of closely spaced targets. Third increasing the spatial extent of the tracker has a similar effect as the using a guardband. It does require increased computation, but generates a better representation of the posterior There are several engineering tradeoffs. The first is that large tracker grids \(or large guard bands\ prevent falsely detecting new targets because of conditional probability spill over. However, if applied too aggressively, this will prevent correctly detecting cl osely spaced targets. Second quick tracker grid translation correctly centers the target mass, again preventing spillover into nearby detectors However, overly liberal trac ker repositioning may in fact move trackers to spurious energy locations and drop true targets off of the finite grid On Ambiguous Targets As discussed earlier, ambiguous targets will eventually move non-physically and this will cause the tracker to remove them via its natural prediction and update process Figure 13 illustrates this phenomenon. There are two real targets that create two persistent ambiguities. All four are detected and tracked automati cally. The ambiguous targets however, eventually move non-physically due to their reliance on the node bearing angles. The tracker automatically penalizes the non-physical motion and the targets\222 present hypothesis decrease quickly over time Ambiguous target removal is done automatically in the Bayesian framework as follows The PDF on target state is predicted forward in time according to the kinematic model True targets will have behavior consistent with the kinematic model \(note the kinematic model is a statistical model so it is predicting a range of possibilities for the future target state\biguous targets may behave consistently with this model for a period of time, but eventually they will appear to perform a non-physical maneuver \(these epochs typically come when the ambiguous target crosses a line of symmetry in the sensor\this point, the predicted target position will be in strong disagreement with the inco ming measurements on that target. This mismatch in predicted target position and measurements leads to a decr ease in the target present hypothesis as calculated in eq. \(4\long, only true targets remain   Figure 12 \226 Improper selection of grid resolution leads to multiple initializations on the same target. Left Measurement update of a Tracker \(red=highest likelih ood, blue=lowest\Right Measurement update of a detector which lies near the Tracker.  Since the track er size has been improperly chosen, some energy from the measurements of a single target leak s on to the detector. This can le ad to false double-initializations 


  14 8  C ONCLUSION  This paper has described a Bayesian approach to detecting and tracking multiple moving targets using acoustic data from multiple passive arrays In contrast to traditional undersea acoustic systems, which develop tracks at the single array level and require track association, our approach fuses data at the m easurement level and operates directly in the target state space We have detailed a well known nonlinear filtering approach to single target detection and tracking [1, 4 and desc ri be d our computationally efficient finite-grid approach to the required density estimation. We have furthermore extended this to the multiple target case by employing a bank of single target detector tracke rs and approximation methods that adjust for closely spaced targets. This approximate approach avoids fully treating the computationally complex joint multitarget problem Future work includes modified approaches to posterior estimation including dynamic grid extent, dynamic grid resolution, and particle filtering. It is anticipated that adaptive sampling of the posterior will lead to computational savings. Furthermore, future work includes more detailed modeling and estimation of closely spaced targets allowing a more accurate representation of the joint target density. Naively implemented, this implies exponential growth \(in the number of targets\r the probability state space being es timated. However, recent work in a related tracking domain on adaptive density factorization [5 c h a stic sa m p lin g  p article filtering    pr ovi de m e t h o d s t h at m i t i g at e t h i s com put at i o n gr owt h  when the full joint density is treated  A PPENDIX  This section discusses the details of how the single target probability density is time evolved on a discrete grid. This discussion is similar to that found elsewhere [15, 14, 13 We wish to compute the single target probability density at time      from the density at time     The relation between these two densities can be expressed using the law of total probability as                We expand     using a second order Taylor series as               where  is the vector of partial derivatives, i.e and is the matrix of second order partial derivatives Then the relation of \(23\ approximated as   Figure 13\226 Left: P h1 over time for four targets, two of which are real and two of which are ambiguous. Although the ambiguous intersections are persistent, eventually the false targets ha ve non-physical motion. The target present hypothesis quickly goes to zero for these targets and they are elimin ated. Right: the tracker estimate of target position and red circles indicating the removal point fo r the false targets 


  15             Where denotes the expectation with respect to the transition distribution    and the omitted terms involve similar terms involving and and cross terms between the and coordinates We use the nearly constant velocity \(NCV\model to specify the transition distribution    This assumption corresponds to one where the target moves at constant velocity except for random jump changes \(i.e nearly constant velocity\is is a plausible model when  is small as it is here Specifically, the NCV model assumes step changes in target velocity defined by the Ito Equations     This model implies  and likewise for  It is furthermore assumed that th e noise processes in each coordinate are independent Under this model, we can eval uate the required terms from 25\ as follows          And likewise for terms involving and Notice that all cross terms \(e.g  have expectation due to the assumption that the noise process is independent in the two coordinates This model simplifies \(25\ to         where the terms omitted are replicas involving the  coordinate Under the assumption that is small, this can be rewritten as    For implementation, this is approximated using an implicit Euler scheme wh ere      Where the indices  represent the discrete    locations where the probability mass is captured Likewise, using forward differencing      and          and similarly for the y coordinate system When substituted into \(28\is leads to a series of equations of the form                This series of equations defi ne the probability at each point at time  It can be efficiently solved via Thomas\222 algorithm \(rather than simply inverted\he matrix is tridiagonal     


  16 R EFERENCES    R o y E. Bet h el Benjam i n Shapo, C h r i st opher M   Kreucher, \223PDF Detection and Tracking\224, under review IEEE Transactions on Aerospace and Electronic Systems  2 y. E B eth e l an d G. J. Paras, \223A PDF Mu lt it arg et Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 30, no. 2, pp. 386-403, April 1994 3   R o y E  B e t h e l a n d G  J  P a r a s  223 A P D F M u l t i s e n s o r  Multitarget Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 34, no. 1, pp. 153-168 January 1998  L   D   Stone, C. A. Bar l ow, and T. L Corwin, \223Bayesian  Multiple Target Tracking\224  Boston: Artech House, 1999  l la and A. Hero, \223Multitarget Tracking using the Joint Multitarget Probability Density\224 IEEE Transactions on Aerosp ace and Electronic Systems  vol. 41, no. 4, pp. 1396-1414, October 2005  M  M o relande, C. Kreucher, K. Kastella, \223A Bay e sian  Approach to Multiple Target Detection and Tracking\224 IEEE Transactions on Signal Processing vol. 55, no. 5 pp. 1589-1604, May 2007  B  Shapo, and R  E B e t h el  223An Overvi ew of t h e Probability Density Function \(PDF\er\224 Oceans 2006 Boston, Sept. 2006  R oy L. St r e it 223M ult i s ensor M ul tit arget Int e nsit y Fil t er 224  International Conference on Information Fusion  Cologne, Germany July 2008  M  Ort on and W Fi t z geral d 223A B a y e si an approach t o  tracking multiple targets using sensor arrays and particle filters\224 IEEE Transactions on Signal Processing, vol. 50 no. 2, pages 216-223, Feb 2002  A. Doucet B Vo, C Andri e u, and M Davy 223Par t i c le filtering for multi-target tracking and sensor management\224, IEEE International Conference on Information Fusion, 2002  H Van T r ees, \223Det ecti o n Est i m a t i on, and M odul at i o n  Theory IV:  Optimum Array Processing\224  J. C St ri k w erda, Fi nit e  Di fference Sch e m e s and Partial Differential Equations, Ch apman & Hall, New York 1989   K. Kast el la and C Kreucher, \223M ult i p l e  M odel Nonl i n ear  Filtering for Low Signal Ground Target Applications\224 IEEE Transactions on Aerospace and Electronic Systems vol. 41, no. 2, April 2005, pp. 549-564  Z. Tang and \334. \326zg\374n er, \223Sensor Fu si on for Target Track Maintenance with Multiple UAVs based on Bayesian Filtering Method and Hospitability Map\224 Proceedings of the 42 nd IEEE Conference on Decision and Control pages 19-24, December 2003  K. Kast ell a 223Fi n it e di ff erence m e t hods for no nl i n ear filtering and automatic target recognition\224 MultitargetMultisensor Tracking: Applications and Advances vol III, pages 233-258, Artech House, 2000 B IOGRAPHY  Chris Kreucher received his Ph.D. in Electrical Engineering from the University of Michigan in 2005. He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan. From 1998 to 2007, he was a Staff Scientist at General Dynamics Advanced Information Systems' Michigan Research & Development Facility \(formerly ERIM\. His current research interests include nonlinear filtering \(specifically particle filtering Bayesian methods of multitarget tracking, self localization information theoretic sensor management, and distributed swarm management Ben Shapo earned his Ph.D. in El ectrical Engineering in 1996 from the University of Michigan.  He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan.  From 2003 to 2008 he was a Lead Engineer at General Dynamics, where he contributed to a number of RF and acoustics signal processing and tracking efforts.  Dr. Shapo has 12 years experience in the DoD research community in the areas of detection, tracking, and data fusion, with emphasis on highfidelity simulations and applying new methods to real data  Dr. Roy Bethel is currently employed at The MITRE Corporation in McLean, VA. He has been actively involved in development, testing, and evaluation of signal processing and detection and tracking systems. In particular, he has developed many systems that have been implemented on United States Navy airborne, surface, and submerged platforms. He is currently engaged in research and development of innovative approaches to multitarget detection and tracking  A CKNOWLEDGEMENTS  This work was partially funded by the Office of Naval Research contract N00014-08-C-0275. The authors would like to thank Dr. John Tague for his support, and Mr. Scott Spencer and Dr. Charles Choi for their assistance 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 



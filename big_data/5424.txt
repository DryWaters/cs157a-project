Mining Maximal Patterns Based on Improved FP-tree and Array Technique Hua-jin Wang School of Information Engineering Jiangxi University of Science and Technology Ganzhou, China wanghj128@163.com Chun-an Hu School of Information Engineering ngxi University of Science and Technology Ganzhou, China Abstract Mining frequent patterns is important for mining association rules. However, because of the inherent complexity mining complete frequent patterns from a dense database could be impractical, and the quantity of the mined patterns is usually very large, it is hard to understand and make use of them Maximal frequent patterns contain and compress all frequent 
patterns, and the memory needed for saving them is much smaller than that needed for saving complete patterns, thus it is greatly valuable to mine maximal frequent patterns. In this paper the structure of a traditional FP-tree is improved , an efficient algorithm for mining maximal frequent patterns based on improved FP-tree and array technique, called IAFP-max, is presented. By introducing the concept of postfix sub-tree, the presented algorithm needn’t generate the candidate of maximal frequent patterns in mining process and therefore greatly reduces the memory consume, and it also uses an array-based technique to reduce the traverse time to the improved FP-tree The experimental evaluation shows that this algorithm outperforms most exiting algorithms MAFIA, GenMax and 
FPmax   Data mining; Maximal frequent pattern; Improved FP-tree Array technique I I NTRODUCTION Association rules is an important research field on KDD presented firstly by those people including Agrawal. Rules represent the interesting associations or relations between item sets in database. Mining frequent patterns is the fundamental and essential part in many data mining applications including the discovery of association rules, sequential patterns, and so on. Apriori algorithm  and its improved ones are mostly adopted to mine frequent item sets in the past researches, all these algorithms make use of the character “all subsets of frequent pattern are frequent”, but generate plenty of candidate 
item sets in mining process, and need to scan the original database many times, thus the mining efficiency is cut down Therefore, people including Jiawei Han presented an algorithm without candidate generation—FP-growth  which only need to scan database twice:  frequent 1-item sets are gained in the first scanning database, and in the second time non-frequent item sets in original database are filtered with frequent 1-item sets and the FP-tree is built, then the complete frequent patterns are mined by performing recursively mining method in FP-tree Experiments show that FP-growth is about an order of magnitude faster than Apriori The drawback of mining complete frequent itemsets is that if there is a large frequent itemset with size 
l then almost all 2 l candidate subsets of the items might be generated. However since frequent itemsets are upward closed, it is sufficient to discover only all maximal frequent itemsets. In addition, there are some mining applications which only need to discover maximal frequent patterns, not to discover complete ones, thus it is greatly significative to mine maximal frequent patterns The previously presented representative algorithms for mining maximal frequent patterns are MaxMiner 3 DepthProject 4  MAFIA  GenMax 6 and FPmax  etc MaxMiner extends Apriori to mine only “long” patterns 
maximal frequent itemsets\. To reduce the search space, it performs not only subset infrequency pruning such that a candidate itemset that has an infrequent subset will not be considered, but also a “lookahead” to do superset frequency pruning. Though superset frequency pruning reduces the search time dramatically, it still needs many passes to get all long patterns. DepthProject performs a mixed depth-first/breadthfirst traversal method and also use both subset infrequency pruning and superset frequency pruning. In the algorithm, the database is represented as a bitmap. Each row in the bitmap is a bitvector corresponding to a transaction, each column corresponding to an item. Experiments show that it outperforms MaxMiner by at least an order of magnitude 
MAFIA is similar to DepthProject, also uses a bitmap representation, where the count of an itemset is based on the column in the bitmap \(called “vertical bitmap”\. To get the bitvectors for any itemset, the bitvector and operation 002 need to be applied on the bitvectors of the items for any itemset Besides subset infrequency pruning and superset frequency pruning, the pruning technique called Parent Equivalence Pruning is also used in MAFIA. GenMax also uses a vertical representation of the database. However, for each itemset, it stores a t ransaction identifier or TIS, rather than a bitvector The algorithm takes a novel technique called 
progressing focusing to maximality testing. This technique maintains a set of local maximal frequent itemsets, LMFI’s. The newly found FI is firstly compared with itemsets in LMFI. Most nonmaximal FI’s can be detected by this step, thus reducing the number of subset tests. FPmax* extends the earlier algorithm 0006\000X\000S\000S\000R\000U\000W\000H\000G\000\003\000E\000\\\000\003\000W\000K 000W\000K\000H\000\003\000\003\000<\000R\000X\000W\000K\000\003\0006\000F\000L\000H\000Q\000F\000H\000\003\000\\000Q\000G\000D\000W\000L\000R\000Q\000\003\000R\000I\000\003\000'\000H\000S\000D\000U\000W\000P\000H\000Q\000W\000\003 000R\000I\000\003\000\(\000G\000X\000F\000D\000W\000L\000R\000Q\000\003\000\003\000R\000I\000\003\000-\000L\000D\000Q\000J\000[\000L\000\003\0003\000U\000R\000Y\000L\000Q\000F\000H\002È\0001\0002\000\021 000*\000-\000-\000\023\000\034\000\030\000\025\000\025\000\003 
Third International Symposium on Intelligent Information Technology and Security Informatics 978-0-7695-4020-7/10 $26.00 © 2010 IEEE DOI 10.1109/IITSI.2010.185 567 


FPmax, it only scans all FP-tee once by using array technique and uses MFI-tree to store all already discovered MFI’s, adopts efficient method for subset testing. Experimental evaluation shows that FPmax* outperforms MAFIA and GenMax in many cases, especially for datasets with short average transaction length and long average pattern length In this paper, an efficient algorithm, called IAFP-max, for mining maximal frequent patterns based on improved FP-tree and array technique is proposed, the algorithm improves the conventional FP-tree and by introducing the concept of the postfix sub-tree, avoids generating the maximal frequent candidate patterns in mining process and therefore greatly reduces the memory consume, it also uses an array-based technique to reduce the traverse time to the improved FP-tree So it greatly improves the mining efficiency and saves the cost in time and space II PROBLEM DESCRIPTION Let I = {i 1 i 2  001\002 i m be a set of literals, called items. Let database T = {t 1 t 2  001\002 t n be a set of transactions, where each transaction t j j=1,2 001\002 n\ is a set of items such that t j 003 I. Each transaction is associated with a unique identifier, called TID Let P be a set of items \(or a attern\, a transaction t is said to contain P if P 003 t. The support of P is the number or the percentage of transactions in the database that contain P. P is frequent if the support of P is no less than a user defined minimum support threshold \(min_sup Definition 1 Let I be a frequent pattern, if there is not another frequent J which J 004 I, I is called a maximal frequent pattern A Improved FP-tree FP-tree and conditional FP-tree built by FP-growth algorithm need to generate in a top-down order, but the mining process of frequent patterns employs the bottom-up strategy Because of the recursively generation of  conditional FP-tree both FP-tree and conditional FP-tree need to be able to traverse in two directions, the nodes in these trees require plenty of pointer, thus a great deal of memory is required for saving FPtree and conditional FP-tree Improved FP-tree \(IFP-tree\is similar with FP-tree and each node in IFP-tree consists of four fields item, count, ahead and next Where item registers which item this node represents count registers the number of transactions represented by the portion of the path reaching this node ahead links to the left child or the parent of the node, and next links to the right brother of the node or the next node in IFP-tree carrying the same item or null if there is none. We also define two arrays nodecnt and link and link item r e g i st e r s a p o in te r w h i c h  points to the first node in the IFP-tree carrying this item  nodecnt item re gi st er s t h e supp or t co unt sum o f t h o s e n o d e s  i n  IFP-tree which carry the same item  In comparison with FP-tree, IFP-tree doesn’t contain the path from root to leaf-node, contains fewer pointer than FP-tree in mining process, so may greatly save cost in memory The construction method of IFP-tree is similar with that of FP-tree, the difference from FP-tree exits in the process of inserting  frequent item sets in each transaction into IFP-tree. In this paper, we don’t adopt the method of recursively performing the procedure, insert_tree \([p|P  t  b u t  e m p l o y a dynamic pointer to complete it. The  algorithm constructing IFP-tree as follows Procedure  FP-tree_construct \(T, min_sup 1 Scan T and count the support of each item, derive a frequent item set \(F\ and a list \(L\of frequent items in which items are ordered in frequency-descending order 2 The root of IFP-tree is created and labeled with root 3 For  each transaction t 004 T  do  Frequent item set I t t 001 F, in which items are listed to S t according to the order of L, define a dynamic pointer \(p_current\ which points to root For each item k 001\031 S t do If  there is a child\(u\ of p_current, and u.item k.item Then  u.count =u.count +1 Else create a new child \(u\f p_current and u.item= k.item, u.count = 1  4 Traverse IFP-tree in a root-first order and transfer the pointers of ahead and next, count the sum of nodes’ support carrying the same item and then list together On the third step ahead points to the left child of nodes and next points to the right brother of nodes. After the fourth step ahead points the parent of nodes and next points to the next node in IFP-tree carrying the same item Then in IFP-tree there is no path from a node to its children or to its brothers For example, let transaction database T be illustrated by TABLE I, and the minimum support \(min_sup\4, then we can get the list \(L\ of frequent items, L = {\(c,6 001\027 f,6 001\027 a,5 001\027 b,4 001\027 m,4 001\027 p,4\, then IFP-tree is illustrated by Fig 1 TABLE I TRANSACTION DATABASE  T TID Item Set S t t 1  a b c f m o c f a b m t 2 a c f q d c f a t 3 a f h m b f a b m t 4 b c k s p c b p t 5 f a c d i m p c f a m p t 6 f h j r f 
568 


 TID Item Set S t t 7 a f c e l p m n c f a m p t 8 d c g b k p c b p Figure 1 IFP-tree of transaction T B Postfix Sub-tree Firstly let a order 003 be the order of the list L, that is ,the support descending order of frequent items. Let the letters i,j 001\002 k\ denote items in database, then i is called the minimum item and k is called the maximum item if i 003 j 003¶\001\002\003 k Definition 2 Let the letters \(i k 001\002 i 1 k 0011   no t e i t e m s and i k 003¶\001\002\003 i 1 P be a path from root to the node N in IFP-tree If there exits a child node N 001\004 of the node N and the items i k 001\002 i 1 appear the sub-path from N to N 001\004 in order, that is, the item i k corresponds to the node N and i 1 corresponds to N 001\004  then P is called the path with the postfix of the item sets i k  001\002 i 1 the support count of the node N 001\004 also is called the base count of P Definition 3 All paths with the postfix of the item sets i k  001\002 i 1 in IFP-tree contain  root, accordingly these paths form a sub-tree ,called the sub-tree with the postfix {i k  001\002 i 1  and labeled with PT\(i k  001\002 i 1  Let M be a node in PT\(i k  001\002 i 1 the sum of  base counts of those paths with the postfix  {i k  001\002 i 1 which pass through the node M is called the support count of the node M. In this paper we define an integer array PT\(i k  001\002 i 1 nodecnt t o re gi st e r t h e  support count of all nodes in PT\(i k  001\002 i 1 rrying the same item Lemma 1 Let M be a node of PT\(i k  001\002 i 1 nd M 1  001\002 M j j 0011 1\ be the children of M in the sub-tree PT\(i k  001\002 i 1  then the support count of M equals to the sum of support count of M 1  001\002 M j  Lemma 2 If the item i m is a node of PT\(i k  001\002 i 1 the support count of the pattern { i k 001\002\002 i 1 i m equals to the value of PT 002 i k 001\002\002 i 1 002 nodecnt[i m    The two mentioned lemmas can be proved according to the definition2, definition3 and the description of IFP-tree. Due to the lack of space, we omit this part Let k be an item in frequent item sets F, the postfix subtree PT\(k\can be built by traversing IFP-tree in bottom-up order. The detailed description of this method is the following All paths from root to node k in IFP-tree form a sub-tree, in which the support count of each leaf-node equals to that of corresponding node in IFP-tree, and the support count of each inner node \(except root\ equals to the sum of support count of its children, then we delete all leaf-nodes, thus achieve the subtree PT\(k The process of building PT\(m\is the following: firstly each node in IFP-tree whose value of item is m is retained in PT\(m\, the support count of each inner node \(except root\ is initialized to be zero. Secondly, for each node, we summate the support count of its children. For example, the support count 3 of the node \(a,3\quals to the sum of support counts of its children: \(b,1\ and \(m,2\ TABLE II shows the result. Finally delete all leaf-nodes. The PT\(m\ is illustrated by Fig 2 TABLE II SUPPORT COUNTS OF  PT  M  S CHILDREN item nodecnt c 3 f4 a4 b2 Figure 2 The Example of PT\(m III MINING MAXIMAL PATTERNS A An Array Technique The main work done in the mining process is traversing the postfix sub-tree to count the support of itemsets and constructing new postfix sub-tree, Recall that for each item i of conditional PT\(x\, two traversals of PT\(x\ are needed for constructing the new sub-tree PT\(k,i\The first traversal finds all frequent items and their counts of support, the second traversal constructs the new sub-tree PT\(k,i\. In this paper, we use the array technique presented by reference [7  T h e following example will explain the idea. In TABLE I supposing that the minimum suppoet is 4, after the first scan of the original database, we sort the frequent items as c:6,f:6,a:5,b;4,m:4,p:4. During the second scan of the database 
569 


we will construct PT 001 and an array A 001, this array will store the counts of all 2-itemsets. All cells in the array are initialized as 0 Figure 3 Two Array Examples In A 001, each cell is a counter of a 2-itemset, such as , A 001[b,c is the counter for itemset {b,c}. During the second scan for constructing the tree PT 001, for each transaction , first all frequent items in the transaction are extracted. Suppose these items form itemset I To insert I into PT 001, the items in I are sorted according to the order in the header of PT 001. When we insert I into PT 001, at the same time A 001[i,j is  in cr em en ted  b y 1 if  i,j} is contained in I After the second scan , array A 001 keeps the counts of all pairs of  frequent items, as shown in table \(a of Fig 3 Therefore ,for each item i in PT 001, the array A 001makes the first traversal of PT 001 unnecessary, and PT\(i\an be initialized directly from A 001. For the same reason, from a sub-tree PT\(x when we construct a new PT\(x,i\, for an item i, a new A X 001 i is calculated. During the construction of the new PT\(x,i\ the array A X 001 i is filled. For example, the cells of array A b is shown in table \(b\ of Fig 2 B Algorithm Description As shown in Fig 2, we can mine the local maximal frequent pattern \(LMFP m in which m is the maximal item that is {\(f,a,m\,4}, by examining whether each item of PT 002 m 002 nodecnt[item in t h e TA B L E I I is n o less th a n  m i n _ s u p  or not. The support count of LMFP m is the minimum of that of all items in LMFP m  The idea of IAFP-max is introduced as follows: for each item i in L, we build PT\(i\ and mine LMFP i then combine all local maximal frequent patterns to gain the ultimate result According to the correctness of FP-growth method, we can conclude that IAFP-max returns all and only the maximal frequent patterns in the given dataset. The following is the main procedure of algorithm Procedure  IAFP-max \(IFP-tree, L, min_sup MFPs 005  MFPs is the set of all maximal frequent patterns For each  i 001\031 L do  PT\(i\struct \( IFP-tree, i Mine LMFP i from PT\(i MFPs = MFPs 001 LMFP i    In the step of MFPs 001 LMFP i if LMFP i 003 MFPs 002 then MFPs keep changeless, else insert LMFP i into MFPs, then performs subset-checking if there is a pattern I 003 MFPs, and I 003 LMFP i then delete I from MFPs Let the items in L be ranked into 1 003¶\001\002\003 k, and 1 006 i 006 k The following is the procedure of constructing PT\(i Procedure  PT_construct \(IFP-tree, i  for j = 1 to i-1 do link[j  nul l a nd no d e c n t  j   0   for each node N in link  basecnt = N.count basecnt is the base count let M be the parent of node N while  \(M.item 007 1  if   M isn’t in link[M.item  Then insert M into link[M.item a n d  M.count = basecnt else M.count = M.count + basecnt nodecnt[M.item  n odecn tp[M.ite m  bas ecn t let M be its new parent again    By using the algorithm, the set of maximal frequent patterns  b\4},{\(f,a,m\,4},{\(c,p C Algorithm Optimization The construction of postfix sub-tree PT\(i\ is the key step of mining process, decides the mining efficiency of IAFP-max There are two optional traversal orders while building all PT\(i i 001\031 F\ the original order of L or the reverse order of L. In this paper, we adopt the former, that is, the items with large support count are built earlier than those with small support count If the postfix sub-trees are built in the original order of L because i 001\031 LMFP i i 010 MFP, LMFP i 011 MFPs, so in the step of MFPs 001 LMFP i we can omit testing whether LMFP i 003 MFPs or not and directly insert LMFP i into MFPs, then go to the step of subset-checking If the reverse order of L is adopted, it is likely to exist LMFP i 003 MFPs, so we needn’t insert LMFP i into MFPs. However, in many practical mining applications Let i,j 001\031 F, i 003 j, the probability of LMFP i 012 LMFPj is not very large. For example, as shown by Figure 1, a 003 b, but LMFP a c,f,a\MFP b b\4}, LMFP a 011 LMFP b  Otherwise, if the original order of L is adopted to construct PT\(i\e construction process doesn’t transform the structure of IFP-tree, therefore the storage of IFP-tree and the construction of PT\(i\ be carried out in a same kind of data structure and avoid repeatedly constructing and deleting PT\(i in the mining process. Consequently, avoid the waste of the 
570 


efficiency in time and space and greatly improve the performance of the proposed algorithm IV E XPERIMENTAL EVALUATION The experiments were conducted on 2.4 Ghz Pentium 001\014 with 512 MB of memory running Microsoft Windows XP. All codes was compiled using Microsoft Visual C++ 6.0. We used Connect-4 downloaded form a websit to test and compared IAFP-max with GenMax, MAFIA and FPmax*, which is a real and dense dataset Fig 4 shows the experimental results. Here we can see that FPmax* outperforms GenMax and MAFIA for high levels of minimum support, but it is slow for very low levels. On the other hand, IAFP-max outperforms FPmax* and it is about one to two orders of magnitude faster than GenMax and MAFIA for all levels of minimum support 000\023\000\021\000\023\000\024 000\023\000\021\000\024 000\024 000\024\000\023 000\024\000\023\000\023 000\024\000\023\000\023\000\023 000\034\000\023 000\033\000\023 000\032\000\023 000\031\000\023 000\030\000\023 000\027\000\023 000\026\000\023 000\025\000\023 000\024\000\023 000P\000L\000Q\000L\000P\000X\000P\000\003\000V\000X\000S\000S\000R\000U\000W\000\013\000\010\000\014 000&\0003\0008\000\003\000W\000L\000P\000H\000\013\000V\000\014 000\\000P\000D\000[\000\015 000*\000H\000Q\0000\000D\000 0000\000$\000\\000 000,\000$\000\\000\020\000P\000D\000 Figure 4 Comparison in Connect-4 V CONCLUSIONS In this paper, an efficient algorithm, called IAFP-max, for mining maximal frequent patterns based on improved FP-tree and array technique is proposed, the algorithm improves the conventional FP-tree and by introducing the concept of the postfix sub-tree, avoids generating the maximal frequent candidate patterns in mining process and therefore greatly reduces the memory consume, it also uses an array-based technique to reduce the traverse time to the improved FP-tree Therefore it greatly improves the mining efficiency in time and space scalability. Experimental results show that it possesses high mining efficiency and scalability R EFERENCES 1 R A g ra w a l T I m i e li n s k i an d A S w a m i  M in in g a s s o c i a t i o n r u les  between sets of items in large database’, Proceedings of the ACM SIGMOD International Conference Management of Date, Washington pp.  207-216,1993 2 J H a n J P e i a n d Y Y i n M i n i n g f r e que nt p a tte r n s w itho u t c a n d i d a te  generation”, Proceedings of  Special Interest Group on Management of Data, Dallas, pp. 1-12, May 2000 3 R J B a y a rd o  E ffi c i e n t l y mi ni n g lon g p a t t e rn s from da t a b a se s   Proceedings of special Interest Group on Management of Data, Seattle WA, pp . 85-93, June 1998 4 R C Ag g a r w a l  C C Ag a r wa l a n d V V V P r a s a d   D e p t h Fi r s t Ge n e r a t i o n  of Long Patterns”, Proceedings of the 6 th ACM SIGMOD International Conference on Knowledge Discovery & Data Mining, Boston, MA USA, August 20-23, 2000 5 B ur di ck D o ug  C a l i m l im M a n u e l a n d G e hr ke J o ha n n e s  A Max i m a l  Frequent Itemset Algorithm for Transactional Database”, Proceedings of the 17 th International Conference on Data Engineering, Heidelberg Germany,  pp . 443-452, April 2001 6 K  G o uda a n d M J Z a k i  E f f i c i e n tl y Mini ng Max i m a l F r e que nt  Itemsets”, 1 st IEEE International Conference on Data Mining, San Jose pp . 163-170, November 2001 7 G  G r ahne an d J Z h u   E f f i cie n tl y U s i n g P r e f ix t r e e s in M i ni ng F r e que nt  Itemsets”, First Workshop on Frequent itemset Mining Implementation FIMI’03\, Melbourne, FL, 2003 
571 


Figure 5 shows the P 002 R graphs obtained from the graylevel histogram features of the M RI dataset Analyzing Figure 5 we see that our method again presented a gain in precision of up to 14 for a recall level of 20 in comparison with the original features and those selected by the mining process using the third re\002ned training set In this case the feature vector size were approximately reduced to up to 11.6 times less dimensions in comparison with the dimension of the complete feature vectors Figure 4 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Haralick features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 5 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Gray-level Histogram features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 6 illustrates the results over the Zernike moments features We can notice that the proposed method achieved a precision gain of up to 11 in comparison with the original features considering a recall level of 60 It is important to highlight that the feature vector size again was reduced to up to 2.2 times less dimensions in comparison with original ones i.e 256 features Figure 6 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Zernike Moments features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 7 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Haralick features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figures 7 8 and 9 show the P 002 R graphs obtained from the Haralick features gray-level histogram features and Zernike moments of the M RI dataset using L 1 distance Analyzing the graph of Figure 7 we observe that the proposed method not only clearly improves the precision of the similarity queries but also achieved a considerable dimensionality reduction The precisions obtained by the relevant features selected in cycles 1 2 and 3 show that the curves practically ties presenting a gain of 20 over the precision of the original features i.e 140 features for a recall level of 40 Analyzing Figure 8 one can see that our method again present a gain in precision of up to 9 for a recall level of 25 in comparison with the original features considering the third interaction Figure 9 illustrates the results over the Zernike moments features We can notice that in Figure 9 the method achieved a precision gain of up to 11 in comparison with the original features considering a recall level of 50 
132 
328 
328 


Figure 8 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Gray-level Histogram features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 9 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Zernike Moments features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 10 shows an example of a k NN  k 7 query execution using the top left image as the query center Figure 10\(a shows the result using the original features and Figure 10\(b shows the result using our proposed method with fewer features The images highlighted by a dashed line means false positive images A false positive image is a returned image whose class differs from the class of the query center Clearly an improvement on the results was reached when applying our method We also performed analyses based on the time requirements to execute similarity queries since our method reduces in a great extent the dimensionality of the features vectors All values presented were obtained by the average of 680 queries over the M RI dataset with k=200 We performed several tests under Windows Vista 32bit running on a machine equipped with an Intel Core 2 Duo 2.00GHz processor 3GB of RAM and a SATA HD of 320GB and 5.400RPM Figure 11 presents the results of these experiments consideFigure 10 An example of k NN  k 7 query using the top left image as query center a Using the original features b Using our proposed method The images wrapped by a dashed line means false positives images ring a Haralick features texture b histogram features color and c Zernike features shape Analyzing the curves of Figure 11 a we can notice that the proposed method performed the queries about 6 times faster considering the third feedback iteration in comparison with the time obtained by the original features Figure 11 b illustrates a higher gain in the queries time execution up to 10 times faster when compared with the time required by the queries using the original features Finally in Figure 11 c the proposed method again reached a considerable gain in time execution up to 4.1 times faster in comparison with the time required by the original features Therefore notable gains were also accomplished regarding not only in terms of the precision of the similarity queries but also with respect of the time execution of them V C ONCLUSION In this paper we proposed a new approach to improve the CBIR quality dealing with the dimensionality curse and the semantic gap problems It gathers from the users their intentions during the similarity queries and performs a feature selection guided by user perception By coupling the relevance feedback and the mining processes we maximized the accuracy of the feature selection process gathering the user in the CBIR process performing feature selection guided by the user's perception The feature selection performed allowed the reduction of the feature vector up to 11.6 times less dimensions from 256 to 22 tuning the mining process according to the specialist expectation Moreover for each user a speci\002c training set was built according to his/her expectation providing the personalization of the system A simple and well-known RF method was employed only to show the proposed method 
133 
329 
329 


Figure 11 Graphs of k-NN queries execution times using L 2 obtained over the M RI dataset represented by a Haralick features b histogram features and c Zernike features comparing the time execution between the original features and employing our proposed method applying 3 cycles of relevance feedback power The use of more robust RF methods could increase the gain further Analyses done also show that the number of three RF cycles is the most common since after that a saturation point is reached and the gain practically remains the same The experiments showed that the proposed method is effective in improving the query precision contributing to bridge the semantic gap and achieving improvement in the query results of up to 30 Moreover the proposed approach can be straightforwardly extended to other types of relevance feedback techniques feature selection methods and distance functions A CKNOWLEDGMENTS This work has been supported by FAPESP Sao Paulo State Research Foundation CNPq National Council for Scienti\002c and Technological Development CAPES Brazilian Federal Funding Agency for Graduate Education Improvement and Microsoft-Research R EFERENCES   S Jeong S.-W Kim and B.-U Choi Dimensionality reduction in high-dimensional space for multimedia information retrieval in Proceedings of the International Conference on Database and Expert Systems Applications  Regensburg Germany Springer Berlin  Heidelberg 2007 pp 404–413   K S Beyer J Godstein R Ramakrishnan and U Shaft When is nearest neighbor meaningful in Proceedings of the International Conference on Database Theory  vol 1540 Jerusalem Israel Springer Verlag 1999 pp 217–235   T M Deserno S Antani and R Long Ontology of gaps in content-based image retrieval Journal of Digital Imaging  vol 1 no 1 pp 1–14 2008   D R Wilson and T R Martinez Improved heterogeneous distance functions Journal of Arti\002cial Intelligence Research  vol 6 no 1 pp 1–34 1997   Y Liu D Zhang G Lu and W.-Y Ma A survey of contentbased image retrieval with high-level semantics Pattern Recognition Letters  vol 40 no 1 pp 262–282 2007   N Doulamis and A Doulamis Evaluation of relevance feedback schemes in content-based in retrieval systems Signal Processing Image Communication  vol 21 no 4 pp 334–357 2006   J J Rocchio Relevance Feedback in Information Retrieval  ser The SMART Retrieval System Experiments in Automatic Document Processing Englewood Cliffs New Jersey Prentice-Hall 1971   M X Ribeiro A G R Balan J C Felipe A J M Traina and C Traina Jr Mining statistical association rules to select the most relevant medical image features in Proceedings of the International Workshop on Mining Complex Data  Houston USA IEEE Computer Society 2005 pp 91–98   Y Aumann and Y Lindell A statistical theory for quantitative association rules Journal of Intelligent Information Systems  vol 20 no 3 pp 255–283 2003   I Kononenko Estimating attributes  Analysis and extension of relief in Proceedings of the European Conference on Machine Learning  Catania Italy Springer Berlin  Heidelberg 1994 pp 171–182   C Cardie Using decision trees to improve case-based learning in Proceedings of the International Conference on Machine Learning  Amherst USA Morgan Kaufmann 1993 pp 25–32   R A Baeza-Yates and B Ribeiro-Neto Modern Information Retrieval  Boston MA USA Addison-Wesley Longman Publishing Co Inc 1999   R M Haralick K Shanmugam and I Distein Textural features for image classi\002cation IEEE Transactions on Systems Man and Cybernetics  vol 3 no 6 pp 610–621 1973   A Khotanzad and Y H Hong Invariant image recognition by zernike moments IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 12 no 5 pp 489–497 1990   H M  uller N Michoux D Bandon and A Geissbuhler A review of content-based image retrieval systems in medical applications-clinical bene\002ts and future directions International Journal of Medical Informatics  vol 73 no 1 pp 1–23 2004 
134 
330 
330 


0     0     1 0     0     0 0     0     0 153 target e-shopper for the past nT ?  periods prior to time T are given, it is important for marketer how to predict e-shoppers purchase behavior at timeT For solving the above problem, the following measures are taken. First, transaction clustering is conducted, so that all the transactions of e-shoppers are clustered. The SOM technique is used to cluster target e-shoppers transactions Then it is necessary to detect the evolving e-shopper purchase sequences as time passes. These e-shopper behaviors, which are derived from a change in the cluster number of each e-shopper, are kept in the purchase sequence database. Finally sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. The sequential purchase patterns are then stored in the association rule database Although SOM technique can obtains transaction clusters SOM clustering technique often breaks down when handling very high-dimensional data. So it is proposed that using product classes represents the hierarchical relationships among products. The method can make an effective dimensionality reduction while improving clustering results Assume that a product class set P  is classified into n different subclasses, and that each subclass consists of subclasses at a lower level, or eventual leaf products, as follows PPPPP nn ,, 121 ?= "                          \(1 Suppose that C is the set of the transactions of m e-shoppers during s periods before timeT . More specifically letC be composed as follows CCC kTmkTkTC ???= ,,2,1 ,, "                   \(2 11,0 ?= sk "  2?s WhereC kTj ?, ?C  is a non-empty subset of products Each C kTj ?,  represents the product class or classes from which e-shopper j purchased products at time kT EveryC kTj ?,  is transformed into an input matrix composed of a bit vector, and the matrix to be transformed is used in the transaction clustering. The time-ordered vectors for a particular e-shopper represent the purchasing history of the 


e-shopper; this input matrix can be thought of as the dynamic profile of the e-shopper. A dynamic e-shopper profile is defined as follows Let C _ be a dynamic e-shopper profile. Then, C _ is defined by the following matrix for n product classes and m e-shoppers over the course of s periods  3 mj "2,1 11,0 ?= sk " 2?s Where                         1 if Pi?C kTj   All the transactions of e-shoppers in the training e-shopper purchase database are transformed into dynamic e-shopper profiles based on their prior purchase behaviors. Then we use the SOM clustering technique to assign each transaction to a group. This transaction clustering facilitates the discovery of the dynamic cluster sequence of e-shopper The transaction clustering results in the following set of q clusters DDDD q"21 ,=                             \(4 Where each Di is a subset of C _ the given in \(3 A rearrangement of these clusters by  e-shopper  and by time  period is necessary for the identification of the dynamic behavior of each e-shopper. It is possible to learn the cluster sequence of a e-shopper by identifying the cluster to which each transaction of the e-shopper belongs, during each time period. To formalize this concept, we use the following terminology Let BP j be the behavior pattern of e-shopper j . Then, the behavior pattern BPi is identical to the changes in the cluster number of e-shopper j during s periods and is defined as follows  5 Where D kTj ?, ?D ,11,0 ?= sk "  2?s The  process  of searching for  a behavior path can 


be simply conducted through transaction clustering. All e-shoppers  have  a behavior path based on their prior transactions. The association rule technique is well suited for determining the most frequent pattern with confidence, since it provides automatic filtering capabilities. To discover the behavior path of a target e-shopper at time T based on his/her past behavior, the input data should be divided into a conditional part and a consequential part. Association rules are descriptive patterns of the form X?Y, where X and Y are statements regarding the values of attributes of an instance in a database. X is termed the left-hand-side, and is the conditional part of an association rule. Meanwhile, Y is called the right-hand-side, and is the consequent part. The conditional part is composed of the left-hand-side assigned to the consequential part R j represents the association rule about the user specified minimum support and confidence in the following form R j 6 A rule R j  indicates that, if the path of a e-shopper is DD TjsTj 1,1, , ?+? " , then the behavior cluster for that e-shopper is D Tj, at timeT It is necessary to know the degree to which the behavior path of a target e-shopper during 1?s periods beforeT  is similar to the association rule. The cluster path of a target e-shopper, transformed via the SOM, is compared with the association rules derived from other e-shoppers paths, and then the best-matching path is determined. Execution of this 0 if Otherwise    C kTj 154 process requires new measures for calculating the degree of correspondence between the association rules and the behavior path of a target e-shopper. This similarity measure is defined as follows     


1 1  s i i kTj i j SSD                            \(7 Where        1 if RD kTikTi   Si kTj 0 otherwise mj "2,1 11,0 ?= sk " 2?s ni "2,1 The above definition indicates that, if the behavior path of a target e-shopper i is equal to the conditional part of association rule j in the same period, then S j kTi ?,  is equal to one, otherwise is equal to zero. However, even if the similarity measure is high, a choice of the association rule suited to the prediction of the cluster of a target e-shopper at timeT is difficult, since such a rule is not general, given that the support and confidence of the association rule may be remarkably low. Therefore, to assure a good fit between the behavior path of a target e-shopper and the conditional part of the association rule, it is necessary to measure fitness. Fitness is defined as follows Suppose FDij be a degree of the goodness-of-fit between the behavior path i and the association rule j . Then, FDij is defined as follows ConfidenceSupportSDFD jjjiij = ,             \(8 Using the above definition, we can determine the cluster of a target e-shopper at timeT is a consequential part R Tj, of the association rule j with maximum FDij IV.  ILLUSTRATIVE EXAMPLE In this paper, we use Table 3 as example given to illustrate proposed method. The set of product classes given in Table 3 is P={Candy, Can, Milk, Bread, Biscuit}. The transactions of e-shopper CID006 are C June,006 {Candy}, =C May,006 {Can}, =C July,006 {Milk 


Therefore, the dynamic purchase profile of CID006 buying the set of products {Candy, Can, Milk Bread, Biscuit} from May to July may be represented as { }0,0,0,0,1,006 _ C June , { }0,0,0,1,0,006 _ C May and 0,0,1,0,0,006 _ C July . CID016 and CID006 are exactly same as both bought the same products during the same month Therefore, similarly, the transactions of target e-shopper CID016 are =C June,016 {Candy} and =C May,016 {Can The dynamic purchase profile of CID016 buying the products may be represented as 0,0,0,0,1,016 _ C June , { }0,0,0,1,0,016 _ C May TABLE IV. BEHAVIOR PATH OF E-SHOPPER CID 1+? sT  1?T  T 006 007 008  015 016 10 10 3   10 3 1 10   3 9 


3 4  9 9  Suppose 3=s , according to formula \(5 of CID006, BP006  is{ }9,3,10 , as shown in table 4,  which indicates  that  e-shopper  CID006 belonged to the tenth cluster in May and moved into the third cluster in June thereafter reaching the ninth cluster in July According to formula \(6 from e-shoppers path with regard to a minimum support of 0.1 and a minimum confidence of 0.5. The association rules are as shown in table 5. The similarities  between the path of e-shopper CID016  and the derived rules are 22016 =SD and 11016 =SD . Therefore, e-shopper CID016 belongs to the ninth cluster at timeT , since the fitness between CID016 and the rules are =FD2016 0.2 and =FD 1 016 0.2001. Therefore, we predict that the products which e-shopper CID016 is likely to buy are Bread, and Biscuit  TABLE V. THE DERIVED ASSOCIATE RULES Rule 1+? sT  1?T  T  Support Confidence 1 2 3  15 16 10 10 3   10 3 1 10  


 3 9 3 4  9 9 0.3 0.1 0.1 0.2 0.1 0.1 1.0 1.0 1.0 0.5 1.0 1.0 V. CONCLUSION The preferences of e-shopper change over time. In this study, we describe a new approach for mining the changes of e-shopper  purchase behavior over time and discuss solutions to several problems. For predicting e-shoppers purchase behavior, the following concepts are proposed: BP j SDij and FDij . The SOM technique is used to detect the evolving e-shopper purchase sequences as time passes. The purchase sequences are derived from the changes in the cluster number of e-shopper. The sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. Then the sequential purchase patterns are stored in the rule database Finally, we give the example to elaborate the new methodology. The research presented in this paper makes a 155 contribution to mining  e-shoppers purchase behavior basing on transaction data. E-retailer may be able to perform effective  one-to-one marketing campaigns by providing individual target e-shoppers with personalized Product basing on using purchase sequences In the future, some possible extensions to this work are as 


follows. From the results of this study, we know which products target e-shoppers are likely to buy, but we have not yet explored the times at which these purchases are likely to occur. Further research analyzing e-shoppers past purchasing patterns should likewise enable prediction of the most appropriate times. Furthermore, one interesting research extension would be the setting up of a real marketing campaign, in which e-shoppers would be targeted using this methodology, which could then be evaluated with regard to its performance REFERENCES 1]Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 2] Kuo, R. J., Chen, J. H., Hwang, Y. C. An intelligent stock trading decision support system through integration of genetic algorithm based fuzzy neural network and artificial neural network[J]. Fuzzy Sets and Systems, 2001 118\(1 3] Agrawal, D., Schorling, C. Market share forecasting: An empirical comparison of artificial neural networks and multinomial logist model Journal of Retailing[J]. 1997, 72\(4 4] Weigen, A. S., Rumelhart, D. E.Generalization by weight-elimination with application to forecasting. Advances in Neural Information Processing Systems[J]. 1999, 3:875882 5] Chen, M, S, Han, J. Data mining: an overview from a database perspective[J]. IEEE Transactions on Knowledge and Data Engineering, 2006 8\(6 6] Schafer, J. B., Konstan. E-commerce recommendation application[J Journal of Data Mining and Knowledge Discovery, 2001, 16:125153 7] Giudici, P, Passerone, G. Data mining of association structures to model e-shopper behavior. Computational Statistics and Data Analysis[J]. 2002 38:533541 8]Changchien, S. Mining association rules procedures to support on-line recommendation by e-shoppers and products fragmentation[J]. Expert Systems with Applications, 2001, 20\(4 9] Song, H, Kim, J. Mining the change of e-shopper behavior in an Internet shopping mall[J]. Expert System with Applications, 2001, 21\(3 10] Anand, S, Patrick, A. A data mining methodology for cross-sales[J Knowledge-Based Systems, 2006, 10:449-461 11] G. Adomavicius, A. Tuzbilin. Using data mining methods to build e-shopper profiles[J]. IEEE Computer, 2006, 34 \(2 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



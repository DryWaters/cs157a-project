 The Application of Association Rules Algorithm on Web Search Engine  Lu Nan 1 Zhou Chun-Guang 2 Cui Lai-Zhong 3  1 College of Computer and Software Shenzhen University, China 2 Jilin University, China 3 Tsinghua University, China lunan@szu.edu.cn, cgzhou@jlu.edu.cn, cuilaizhong@gmail.com  Abstract  Aiming at the prevalently concerned mining problem about constructing concept search in current Web search engine area, especially applying the Vector Space Model VSM to web search mining based on the association rules, this paper provides a highly efficient mining algorithm EARS. The EARS algorithm implements the association rules pruning based on VSM via constru cting associa tion library and computing similarity. The EARS stores the frequent itemsets via multi-dimensional linked lists and utilizes the recurrence relation among the frequent itemsets in order to effectively obtain the association rules. We verify the extended function of retrieving and querying on the web and the results of these experiments indica te that our method is effective and feasible  1 Introduction  With the rapid development of Internet, Web has been a major information source. Due to the huge and mass information involve d, it becomes more and more difficult that find out useful information fast and accurately. Although the search engine based on key words is widely used its precision ratio and recall-precision are hot issues of all time. For this reason, the concept-based re d   which is an outcome combining data mining technology with search engine mechanism and also is one of realizing intelligent information retrieval methods Concept-based retrieval expand the users’ query requests in form of concep ts via the transformation of association between co ncepts, namely the transformation associated library, and then submits them to retrieval systems outputting the query results eventually. Since concept-based retrieval understood and dealt with the users’ requests from the level of a word’s conceptual meanin g, breaking through the defect that keyword match ing is restricted to appearance form, it can effectively eliminate the difference between query requests expressed by the users and the query results by the system executing thus increasing precision ratio and recall-precision of the system two key technologie s are the transformation of semantic library and query expansion The transformation of associated library making use of association rules mining algorithm automatically mines the association between words form the text to structure, in favor of query expansion and adjustment. Currently, there are two major methods to structure associated library  using manual method to structure associated library, demanding domain experts to accomplish It is a rather time-consuming project and the associated library can not reflect the change between concepts in time automatically extracting concepts and words from the text set and then discovering the correlation between the concepts and the words, structuring the associated library finally Query expansion is based on the association library and conducts the co rrelation query expansion according to correlation and degree of correlation Therefore, association rules mining technology has been an important step of realizing intelligence search for query expansion [3 Base d on the  associated library, the query requests of the users will be correspondingly expand ed, to make retrieval Copyright © 2009 by the Institute of Electrical and Electronics Engineers, Inc. All rights reserved 


 intelligent and increasing the precision ratio and recall-precision Due to the knowledge di scovery in mass data, the quality and efficient of mining algorithm are always the bottleneck in the application and extension of association rules. A lot of researchers conduct a great of research about the topic of association rules mining, expecting to improve and optimize the original algorithm for better efficiency of algorithm The representative algorithm DHP Partition Samp and so on  This paper proposes an improved association rules mining technology, which can automatically export the correlation between concept and word from the text. This method applies the vector space model \(VSM\ining algorithm, in order to discover the correlation between concept and word in the text., according to which structuring the associated library. The associated library can effectively solve the problem of query expansion to achieve the purpose of increasing precision ratio and recall-precision  2. Web vector space and association rules  The major task of concept searching is building feature extraction and Vector Space Model formed by the term frequency count and applying the association rules and corr elation process to establish the feature words association library  2.1 Vector Space Model VSM  Since the rong computability and operability, it has been widely applied to many applications in information retrieval areas as text retrieval automatic abstraction keyword automatic extraction text classification and search engine achieving good effects. In VSM, a document space is regard as a vector space consisting of a orthogonal word vector set, in which each document d represents a standardizing eigenvector V\(d\=\(i 1 w 1 d\; … ;i j w j d\; … ;i m w m d  i j is word item w j d is the weight value of i j in d  which is generally defined as a function of tf j d the frequency of i j s occurrences in d namely w j d tf j d  tf j d represents the frequency of characteristic item i j s occurrences in d. There are many patterns of in which the classic and widely used computable function is TF·IDF. Its form is as follows tf j d log  N/n j  In which N is the amount of all the documents and n j is the amount of docume nts including word item i j  2.2 The calculation of similarity degree  We compute the similarity degree based on the cosine distance which can be formally defined as     1  2.3 The transformation of associated library The construction of the association library is a crucial step in realizing concept searching, aiming at automatically extracting co ncepts and words from document sets and finding out the correlations among them  2.3.1 The concept of association rules In association rules, itemset I={i1,i2, …, in  represents a set consisting of n different data items For a given transaction database D each transaction T is a subset of itemset I The implication of association rules is X Y in which X I,Y I and X Y and its support and confidence are respectively defined as support X Y  P  X Y   2 confidence X Y  P  Y|X  3 The task of association rules mining is find out all strong association rules, making support larger than the given support’s threshold and confidence larger than the given confidence’s threshold. From \(2\we can see that support reflects the frequency of the implication X Y s occurrences in transaction T and the itemset whose frequency is larger than the given threshold is defined as frequent itemset. The 


 generation of frequent itemset indicates that there is a certain similarity between corresponding objects. In VSM, a document is regard as an object and a word is regard as an object item. If some object items always in some documents, we th ink that these document items have a certain similar ity. Through \(3 compute the confidence between  document items  and then make sue the similarity between document items 2.3.2 The pruning of association rules If the association rules mined by current association rules algorithm are directly added into associated library for query expansion, it will be found out that th ere are a lot of useless rules in the mining results. Once these rules are added into the associated library, some e rrors will occur in the process of query expansion and it also decrease the precision ratio and recall-precision. In order to make the rules in associated library more meaningful and convenient for query expans ion, we make some limits in the process of mining as follows 1\Support threshold value limit. Support reflects the itemsets in the database are whether universal laws or not. In order to make sure the frequent itemsets with more universal laws, we demand the frequency of frequent itemsets’ occurrences must be larger than 20 in the database with 1000 items namely the least support th reshold value is 0.02. You can certainly increase the support threshold value to make the frequent itemset more meaningful 2\onfidence threshold value limit. If the confidence threshold value is set too small, the rules with too small confidence will also be mining out And if these rules are added into associated library, it will make the query expansion set too large and decreasing the precision ratio, simultaneously increasing the retrieval cost. In this paper, the least confidence threshold value is set as 0.7 3\onstraints limit. In general, the number of left and right in the association ru les is not limited. When retrieving, query string is generally 1-2 words, and as in query expansion, only 1-2 will be expanded. So we needn’t generate the rules with the number of left and right lager than 2. Adding number constraint condition in mining algorith m not only increases the efficiency of algorithm but also eliminates the invalid rules 4\orrelation interest threshold value limit Though we can eliminate i nvalid rules via above limits, we must make out whether the rules with high support and high confidence is really valid or not and reflect the real correlation between words or not. To solve the problem, we intro duce the interest threshold of association rules to judge the association rules. For a given transaction set D the interest of association rule X  Y in D is defined as  4 According to \(4\ is small than 1, it indicates more interest in this rule, namely its practical value lager in use. If interest is equal to 1, it indicates that X and Y are mutually independent and this rule should be eliminated. Through above steps process, the association rules mined out are basically in accord with the reality and they could be added into the associ ated library 2.3.3 The structure of associated library The associated library includes two structure tables hierarchy relationship table and correlation relationship table. Hierarchy relationship describes hierarchical relation between words and its basic element is word node. The attribute of word node is described as follows struct Concept char itemid   hierar ch y number which a node in  char itemname  name of a wo r d node  double psweight; //the weight value from father       node to the node itself double spweight; //the weight value from the node itself to its father node  struct concept *son; //a point to a array of child  nodes  


 The correlation relationship table describes the correlation between words, specific representation as following struct Relationship char itemstring1   wor d string  char itemstring2   wor d string  double weight  w eight valu e o f con fiden ce  In the expression, itemstring1 and itemstring2 could be a string consisting of multiple words 3. The architecture of web search engine based on association rules The structure of web search engine based on association rules usually includes two parts: query service in client and background processing in server which are shown as in the figure 1.The query service in client includes three parts consisting of the user’s query request, concept associative spread and pattern match. The background processing includes four parts consisting of document collection, feature extraction, transformation of associated library and adjustment of associated library   Figure1. The Architecture of Web Search Engine  Based On Concept Retrieval   3.1 The background processing in server  The major process is build ing document library  word associated libra ry The  document library could be constructed using the information acquisition tool to collect document files including original documents and their URLs. VSM storing each document’s major feature words and word frequency is a word frequency matrix formed by feature word extracting and the word frequency counting for the documents in the document library The feature word associated library is build up after the process of association rules mining algorithm mining the correlation between feature words in VSM 3.2 The foreground query request in client When a user submits a query request, the system will find out the corresponding feature words from the feature words associated library and process the concept expansion to form a string of related concepts. They are regarded as query request submitted to the system for pattern matching and the documents meeting conditions will be submitted to the user. If system doesn’t find out the feature words corresponding with the qu ery request, system will re-mining the corresponding feature words from the VSM, do the expansion process and adjust the associated library 4. The improved mining algorithm EARS The key points of increasing association mining efficiency are usually including the followings  decreasing the amount of scanning database and reducing the I/O load generating small candidate frequency set making rational use of relationship between back and forth items solving the sub-problems in the process of generating association rules optimizing implementation code to reduce the space complexity as far as possible. We provide an improved mining algorithm called EARS to do these The main idea is that we use a multi-dimensional list structure to store the Tid set of each frequency set in database and recursion relations between levels of each frequency set and effectively obtain association rules via list operation and set operation at last 4.1 Correlation theory For any two itemsets X, Y if X Y, X is the father itemset of Y and Y is the child itemset of X If X Y  and X 1 Y Y is the proper sub-itemset. The proper sub-itemset is a special child itemset. If Y the proper sub-itemset of X is a frequency set Y is the proper sub frequency set of X Let D be the number of records in database Tid be the identifier of a record in database L k be the set of  frequency set in level k  


 usually called large k itemset L k,m be the m th of the set consisting of large k itemsets L k,m  i  i th item of the m th element of large k-itemset X be the number of elements that X includes X.Set be the set of all items composing the itemset X  X.Se be the i th item of itemset X in which i 0  X  SupTidSet be the i th Tid number of itemset X s support Tid set X.sup be the supports of itemset X namely the number of elements belonging to X.SupSet  X.Tid be the Tid number which records X in database X.Level  be the level number, namely X  X.NearOffspring be the proper sub frequency set nodes queue of X  Theory 1  X is any a k itemset and Y, Z are two different itemsets. If Y,Z X Y Z there are Y Z=X  X.SupTidSet  Y.SupTidSet  Z.SupTidSet  Theory 2 If the frequency sets in k 1 level are in ascending order, all the items included by the every frequency set will also be in ascending order. When the frequency itemsets in k level are found, we use dual cycle to matching mine the two itemsets in k 1 level from small to large. The generated items included by the frequency sets sort ascending and then the large itemset L k in k level will sort ascending Theory 3 For nonempty itemset X and Y the number of both X.set and Y.set s items is m and X Y  X.Set   X.Set    X.Set  m  Y.Set 1  Y.Set 2 Y.Set  m  If the sam e  ite m   is deleted from \(or inserted into X and Y simultaneously obtaining X and Y the size relationship of X and Y  is the same as the size relationship of X and Y  4.2 Data structure The core data structure of the algorithm is a multi dimensional list. The vertical list stores the frequency set nodes. Each node includes X.Set X.SupTidSet X.Sup X.Level X.NearOffspring The horizontal list consists of queues pointed by each frequency set node’s NearOffspring each node of which store a pointer pointing to a proper sub frequency set node of X.Set These pointers re-point to frequency set in the vertical list and the node store three fields Rules-Route Off-Set and Con-Set  Rules-Route is a path pointer, generating rule s. When mining rules, we depend on breadth-first search to expand the queue to deduce all the rules Off-Set stores extra items that proper sub frequency set Y is bigger than current frequency set X  Con-Set stores rule’s consequent of association rules, namely the conclusion part. The major structure of the list is shown in Figure 2 Where L 1,1 L 1,2 L 1,m L 2,1 L 2,2 L 2,n L 3,1 L 3 represents respectively frequency set node from each level, composing vertical queue X  expresses the pointer pointing to node X    Figure 2. The Structure of Multi Dimensional List The feature of data structure is that each frequency set node is adjacent to its proper sub frequency itemset sequence, and through the widely used list operation, breadth-first sear ch, we can conveniently get all the child frequency set of any a frequency set As breadth-first search is used, the obtained child frequency set sequence has been arranged as from low to high level, of which we can make use to increase the efficiency of algorithm in the course of algorithm design 4.3 Algorithm description Let Tid number of a record in database be unique in the whole database and the records in database sort ascending as Tid In this condition, the algorithm EARS can be parted into three steps Step1 By scanning database once, it generates all the order frequency set L 1 and X.SupTidSet and X.Sup  are recorded. If we set minsup to 0.5, the process of L 1 s generation is shown as table 1 and table 2  Step 2 By multiple cycles based on L 1 it generates all the large itemset L k in level k k 2     


 Table 1  Database Table Tid Items 001 a c d 002 b c e 003  a b c e 004 b e Table 2. The List Structure After  Big Itemset of Level L 1 Is Obtained  X  X  L 1  X.Sup X.SupTidSet a} 2 001 003 b 3 002 003 004 c 3 001 002 003 e 3 002 003 004 In this process, it matching mine two large itemsets in k-1 level from small to large via dual cycles. For any two frequency sets L k-1,m and L k-1,n  m<n  k-1 if the conditions are satisfied that L k-1,m 1 L k-1,n 1 L k-1,m   L k-1,n 2 L k-1,m k-2 L k-1,n kL k-1,m k L k-1,n k-1 X.Set=L k-1 m.Set  L k-1 n.Set  is respectively a k itemset According to theory 1, there is X.SupTidSet L k-1,m SupTidSet L k-1,n SupTidSet  If X.Sup minsup D in which X.Sup belongs to k itemset X  X is frequency set in level k otherwise X is a weak itemset  We can use theory 2 to accelerate dual cycle scanning for this process For any a frequency in level k, it can be obtained by matching the least two frequency sets in level k 1 consisting of k 1 elements from L k,x namely L k-1,m  L k-1,1 L k-1,2  L k-1,k-3 L k-1,k-2 and L k-1,n  L k-1,1 L k-1,2  L k-1,k-3 L k-1,k-1  When deducing frequen cy set in level k if the first k 2 items of L k-1, m and L k-1,n are different, the smaller frequency needn’t to match the following other frequency sets, in other words, the inner cycle can be stopped. After deducing a frequency set L k,x by using L k-1,m and L k-1,n  m<n  L k,x is added into the vertical list and the support set and support number of L k,x are written into corresponding domain. The pointer node pointing to L k,x is added into the proper sub nodes sequences pointed by respective NearOffspring of frequency L k-1,m and L k-1,n  and the item obtained from L k,x L k-1,m  is recorded into the off-set domain of proper sub node newly added into L k-1,m meanwhile, the item obtained from L k,x L k-1,n  is recorded into the off-set domain of proper sub node newly added into L k-1,n It searches the frequency sets which also regard L k,x as its proper sub frequency set in the frequency sets sequence at level k-1 after L k-1,n Table 3 describes the storage structure of mu ltiple list generated by example1 through step2  Table 3. The Storage Structure of Ultiple List Generated By Example  L X. Sup X. SupTidSet X. NearOffspring a 2 001 003 a c b 3 002 003 004 b c b e c 3 001 002 003 a c b c  c e e 3 002 003 004 b e  c e a c 2 001 003  b c 2 002 003 b c e b e 3 002 003 004 b c e c e 2 002 003 b c e b c e 2 002 003  Step 3 By using the information of current data structure, it gets the association rules meeting the minconf. In other words, it regards any a frequency set in vertical list as the antecedent  of association rules, and then mines out the conclusion meeting minconf, namely the rule’s consequent. When frequency set X is a rule’s antecedent, first, the next pointer of each node in NearOffspring is copied into Rules-Route pointer of current node and the value of Off-Set is copied into Con-Set forming an initial Rules-Route which generates rules. Through scanning this list to get a node, the Con-Set value Y of this node is the rule’s consequent and the support of corresponding frequency set Z can be obtained from the pointer of this node, in which according to the generation process, we know that Z=X Y If confidence X Y   Z.Sup  X.Sup  minconf it is a strong rule meeting the requirement, otherwise, it’s a weak rule. If confidence X Y a weak rule apparently the child nodes of Z don’t combine with X to generate a strong ru le. Otherwise, the NearOffspring list of Z is scanned. If it is not null each node in the list is fetched one by one and Y is copied into the Con-Set domain of the node in the list Simultaneously, the item of Off-Set domain is inserted into Con-Set making the item of Con-Set  sort ascending to form rule’s consequent M  


 Comparing M with rule’s consequent N of the last node in Rules-Route if N  M or N  M and N  M Theory 3\node will be linked to the end of Rules-Route Scan the next node of Rules-Route and repeat the above pro cess until to the last node. When example 1 uses frequency set c as rule’s antecedent Table 4 lists the Rules-Route queue and its corresponding association rules generated by the derivations. As long as the minconf is given, it could judge which are the strong rules meeting the requirement  Table 4. The Rules-Route Queue And Its Association Rules The node point  to freq-set Off Set Con Set Sup.of freq-set Asso Rules Conf a c A a 2 c a 0. 667 b c B b 2 c b 0. 667 c e E e 2 c e 0. 667 b c e E b e 2 c b e 0. 667  5. The results and analysis of experiment   To verify the efficiency of EARS’s expansion function in searching and retrieval, we test on a computer with CPU 2.4 G, Memory 2GB and Windows XP operating system. The original documents are from the TREC-7 document set downloaded from the Internet, including 23251 documents. Choosing ten thousand words as feature word, the documents are carried on the feature extraction and word frequency counting, forming word frequency matrix stored in the Oracle9i database. When minsup 0.04 minconf 0.4, the number of records in the database increases from 2,000 to 10,000 and the execute efficiency of EARS and Apriori is shown as Figure 3.From Figure 3, we can see that as records increasing, both of the runtime are prone to increase, while, from the perspective of data, the increment speed of EARS’ runtime is slower than Apriori’s. In addition, the runtime of EARS is less than Apriori’s at any time                        Theoretically speaking  EARS scans the database once only when discovering the large 1-itemset in the whole process of mining, whic h solves the problem about the heavy load of I/O With the help of Tid sets recorded in the memory the algorithm doesn’t generate candidate large itemset C k  The advantage of using the data structure multiple dimensional po inters, is that when generating association rules, the expenditure of matching time is decreased as much as possible by making the best use of previous work  The design of the algorithm makes use of the ordered data structure and set operations Therefore, the execute efficiency of EARS is improved effectively 6. Conclusion In the current developing process of network search engine technology, how to using web data mining technology is a ke y point. In the research process of the web search engine technology, this paper analyses in depth on the query expansion technology based on the association rules. We propose an association rul es mining algorithm EARS based on multiple dimensional list. The results of experiment indicate that the efficiency of EARS is higher than Apriori’s and the runtime of EARS varies within a small range, namely having a good flexibility. It thus is concluded that EARS is an effective and scalable association rules algorithm which can be widely used to query expansion in web information retrieval  


 7. Reference    Fetzer C,Hagstedt, K,Felb er P  Autom atic Deteciton  and Masking of Non-Atomic Exception Handling International Conference On Dependable Systems and Networks, \(DSN2003\10-116    Y e n S J, Lee Y S. “Mining Interesting  Associatio n  R u l es  and Sequential Patterns”. International Journal of Fuzzy Systems, 2004-6 \(4   Alasf f ar A  H, Deogun J S. “Concept-b a sed Retr iev a l with Minimal Term Sets”. Foundations of Intelligent Systems: 11th Int’l Symposium, Springer, Poland, 2004 114- 122   Qiu Y ong gang,Frei H P  Concept B a sed Quer y   SIGIR’03,2003:16 0-169   Saltom G  W ong A, Y a ng C  S. “A V ector Sp ace Model for Automation Indexing”. Communications of the ACM 2005, 18\(5\-620   Agrawal R, Srikant R. “Fast Algorithm f or Mining Association Rules in Large Databases.” Proceedings of the 20th International Conference on Very Large DataBases Santiago , Chile , 2004   Park J S. “Using A Hash-Based Method with Transaction Trimming forMining Association Rules.” IEEE Transactions on Knowledge and Data Engineering, 2007   Savasere A, Omiecinski E Navathe S  An Ef ficient Algorithm for Mining Association Rules in Large Databases.” Proceedings of the 21st International Conference on Very large Database, Switzerland, 2002  


              


   


                        






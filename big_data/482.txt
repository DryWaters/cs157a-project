Proceedings of the Second International Conference on Machine Learning and Cybernetics Xi\222an 2-5 November 2003 THE UNIFIED STOWAGE METHOD OF THREE KINDS OF DATA MINING RESULTS ZHONGYANG XIONG W-FANG ZHANG DAI-JIE CHENG Department of Computer science Chongqing University, Chongqing 400044 China E-MAIL zyxiong@cqu.edu.cn Abstract Because lacking of unified stored structure of data mining results in existing data mining systems 
it cannot share the mining results among different applications In order to store data-mining results all together in pattern base the storage method of data-mining results association rules classification rules sequential patterns\are intensively studied and analyzed These three storage methods using the formal relational algebra description are proposed After analyzing the common way of three storage methods the consistent storage method of three data mining results in relational database is put forward As a result of extensive application of relational database this improves 
existed storage method and provides unified platform for sharing data-mining results in different mining systems Keywords Data mining pattern store; relation schema 1 Introduction The maintenance and storage of data mining result can improve the efficiency of data mining Pattern base is an important composition of data mining result storage system Many kinds of data mining results are stored in the pattern base. Besides the basic database function it would have the special fimction of pattern base management ll The results 
that get from different data mining tools are stored together in the pattern base Meanwhile the matured database mechanism and abundant interfaces can be used This not only enhance the mining efficiency but also analyze the results in different time duration and different kinds of mining tools mhermore it assists decision-making and exerts the real effect of data mining This paper first analyzes the storage method of association rule classification rule and sequential patterns and then gives the schema of storing these three mining results all together 2 Association Rule 
2,l The Definition of Association Rule Association rules are often used in retail transactional database It reveals the rules like 223A customer who purchase the bread also tend to buy butter at the same time\224 A transaction is composed of the processing time merchandise and sometimes consumer ID for example credit card The formal description of association rule is let Z  il i i be a set of m distinct attributes also called items Each transaction T in the database 
D of transactions has a unique identifier called TID and contains a set of items such that T c I An association rule is an implication of the form x 2 Y  where X c I  Y c I are sets of items called item sets and XnY    The rule X 3 Y holds in the 
transaction set D X is called body Y is head\with support s where transaction set D contains transactions X U Y  and has confidence c where c is the percentage of the transactions containing X also contain Y The task of association rule is to mining rules that satisfy both a minimum support threshold min-sup and a minimum confidence threshold min-conf 2.2 Association Rule Storage 2.2.1 The Storage Method of 
File Form The popular data mining tools, such as the DBMiner Intelligent Miner etc generally store the mining results into files For example the data mining results of Intelligent Miner 6.1 are stored into a file named resXn.dut and can be accessed from the file provided by a group of API I There are three steps to read the association rules in the result files in other mining tools First it defines a 0-7803-7865-2/03/$17.00 02003 IEEE 284 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Xi\222an 2-5 November 2003 structure, then, it calls the function IDMAsrParserInitialize to initialize. Finally, it calls the function IDMAssocRules to read the association rules The procedure of obtaining association rules in such a way is complicated. Different data mining tools have different results format It is also difficult to share the mining results among different mining tools 2.2.2 The Storage Method of Relational Table Form The structure of relational database storing association rule was depicted in reference 13 Table 1 The single relational table for storing association rules Association rule instances are shown in table 1 fields Item are items in the transaction data set k specifies the total amount of items included in the data set i.e the maximum length of association rule NullM stands for the null-mark of an association rule. If there are n items in an association rule the item value after position n should be set null RuleM specifies the rule\222s division mark between bodies and heads If an association rule having m bodies the value of RuleM should be m+l The column 221NullM4\222 in table 1 represents the rule consists of 4 items. \221RuleM=3\222 denotes there are 2 items in the rule head 221Null\222 is applied to fill the rest of fields So this row represents the association rule 223a consumer who purchased bike and pumper would purchase lock and helmet, with confidence of 60 and support of 3 The expression of this association rule is Bike A Pumper 3 Lock A helmet  0.6,s  0.03 There are thousands upon thousands of items in transactional database Adopted this structure will lead to the huge amount of fields with null and the redundancy is high Whenever the amount of items in transaction dataset changes the possible max length of association rules will be changed, too This may cause a reconstruction of the whole rule table In some situations, such as retail market this change is frequent It is insufferable in actual implementation to reconstruct frequently when stored many rules The common disadvantage of these two storage methods is the lack of relative time stamp of association rule which stands for the change of historic data 2.3 The Improved Storage Method of Association Rule schema ASSOCI_RIL4ID BODI HEAQCONESUI TIME  ID represents the identification of the rules The value of column BODY and HEAD, which is the item of transaction database constitutes an association rule The value of column Conf and Supp denotes the minimal confidence threshold and minimal support threshold. Reference 41 uses the project operation to project the relation over some attributes and decompose it into three relation schemas In relation BODY\(ID BODY  Il ID,BODY ASSOCI RULE HEAD ID HEAD   IIID,Hmo ASSOCI  RULE  PA MID CONE SUP TIME  nlD,CoNF,sVP,Tl~~~ASSOCI RULE The schema BODY describes the body part of an association rule the schema HEAD describes the head part of an association rule, and the PARA parameters Adopted this schema an association rule is divided into three parts body head and para. All tuples having the same ID represent an association rule. The set of fields in column BODY with the same ID forms the body item set and column HEAD forms the head item set, while PARA forms the parameters of the association rule In each \(N+M\association rule, the body items appear N times and the head items M times The union operation using identical ID among three tables composes a corresponding association rule The characteristics of this storage method are: The association rule schema is criteria and can be shared with different mining systems With these schemas data redundancy is low and query speed is high It\222s easy to extract association rules in this storage method by joining the body head and parameter according to the rule\222s ID 3 Classification Rule 3.1 The Definition of Classification Classification is an important task of data mining Its aim is to establish a classification function or model through training data set or training samples meanwhile the model is used for classification for the data The model is constructed by analyzing database tuples described by attributes and is represented in the form of classification rules or decision trees For example, given a database of customer credit information classification rules can be learned to identify customers as having either excellent or fair credit ratings. The rules can be applied to categorize future data samples as well as provide a better understanding of the database contents That 223if 285 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Xi'an 2-5 November 2003 I good 40 I good salary>5000 and 40<age<50 then CrediFgood is a classification rule salary credit age credit efficient is low and the extension is not good I 5 tc50 A 40 Good 3.3 Improved Storage Method of Classification Rule leaf I 3.2 Classification Rule Storage A relational table structure used for storing classification rules in improved decision tree is mentioned in reference I A typical classification rule is shown in table 2 It represents the concept good credit standing Table 2 The storage of classification rule hild nodes in-node 5000 ed e 5000 in-node Alter table 2 into table 3 can solve the problem mentioned before Table 3 classification storage 1 BD CONDITION WSULT IC-attribute h-attribute NO denotes the node locates which layer of course nodes in the same layer have the same NO This decomposition eliminates the redundancy A classification rule contained N+M items will be appeared N times in condition table and M times in result table And the classification rule is built through the same ID joint with two tables Adopted this schema has the advantage of the storage form is normal and easy to share in different system less redundancy and higher query rule Also it is easy to obtain the classification rule and to figure out decision tree 4 Sequential Pattern 4.1 The Definition of Sequential Pattern Sequential pattem is an important category of data mining Similar to association rule mining its task is to mine frequently occurring patterns related to time or other sequences An example of a sequential pattem is  A customer who bought a computer and modem a month ago is likely to buy a printer The question described by sequential pattern mining is to search the time-series and sequence data in the transaction database through setting minimum confidence value and minimum support value A time-series database consists of sequences of values or events changing with time and sequence database is any database that consists of 286 


Proceedmgs of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 ID BODY HEAD conf sup bme 1 computer printer 60 3 2002-1-1 1 modern printer 60 3 2002-1-1 sequences of ordered events. The task of sequential pattern mining is to find out the all most frequent consecutive sequences which satisfy the minimum confidence value and minimum support value and time interval in the transaction database 4.2 Sequential Pattern Storage overcoming its shortage But the time related information is not mentioned in the abovestructure 4.3 Improved Sequential Pattern Storage Method 1 We change the above structure into the table 4 for A relational table structure used for storing sequential pteml Bnol I..$temk bnok ben bonf bupl Attribute Item is the item set of transaction data set k represents the total amount of items in data set, i.e the most capable length of sequential pattern Len represents the total amount of items in sequential pattern also the length of sequential pattern Enq denotes the position of item where appeared in the sequential pattern For example sequential pattern like 223 A customer who bought a computer and modem a month ago is likely to buy a rinter\224 can be stored in the following form omputerll bodem11 brinter I 2!Null bullti 10.6 10.31 There are three items in this sequential pattern so Len=3 computer and modem are the first element Enol=Eno2=l printer is the second element Eno3=2; the confidence and support value are the same as association rule A tuple directly represents a sequential pattern There exists limitation when millions of items are contained in the transaction database The null value of item attribute in pattern base will be increased tremendously when the items become hugeness Whenever the amount of items in transaction dataset changes the possible max length of sequential pattern will be changed too This may lead to reconstruct the structure of pattern base It is intolerance in real situation to frequent reconstruct Generally the end-users of data mining system are more interested in the sequential pattern in the some time interval not the whole pattern is mentioned in reference 61 4.4 Improved Sequential Pattern Storage Method 1 Taking the projection over some attributes on the schema described in table 4 three schemas are obtained Each describes the body head and parameter section BODY\(ID, BODY NO  I\222I,,BoD SEQUENTIAL PATTERN HEAD ID HEAD   TIID,HEAD SEQUENTIAL PATTERN  PARA\(ID, CONF, SUP TIME  n ID,coNF,sup,TIME SEQUENTIAL- PATTERN NO denotes the position of body in a sequential then\224 pattern to express its mining results after analyzing pattern Join three tables with the same ID creates a the storage method of association rules, classification rules sequential pattern 222 and sequential patterns We use three schemas CONDITION ACTION PARA to store the mining 5 The Unified Storage Method of Three Mining results The CONDITION schema represents the condition attribute of classification rule the body attribute of association rule and sequential pattern The ACTION Pattern The common ground is that it can be used with 223if 287 


Proceedmgs of the Second International Conference on Macbe Learning and Cybernetics Xi\222an 2-5 November 2003 schema represents the result attribute of classification rule is added in the CONDITION schema A denotes association the head attribute of association rule and sequential pattern rule C represents classification rules and S the sequential The PARA schema holds the all parameters owned by pattern association rules classification rules and sequential Three schema storing association rules classification patterns i.e confidence support time and time interval rules and sequential patterns can be described as To distinguish these three mining result the class attribute CONDITION\(CLASS ID CONDITION, ATTRIBUTE PARENT NO ACTIOA\(CUS ID ACTIO& ATTRIBUTL$PARENI PARA\(CLASS ID, CONF SUP TIME INTV  Table 5 the unified storage of three mining results I ACTTON II PARA caner NUN Null t2 I Each mining result is joined the three schema through the same ID This storage method takes the benefits as following It is easy to share the mining result in the 0 0 Less data redundancy 0 0 different systems The value of added attribute class can be extended to suitable with other kinds of mining result It is easy to pick up a mining result through joining operation among condition action and para tables with the same ID 6 Conclusions This paper proposes a uniform storage method for data mining result after analyzing association rule, classification rule and sequential pattern separately The expression of formal relational algebra is given and the three mining results can be stored into the s.ame relation table. Based on the relation schema storage of association rule classification rule and sequential pattern in relational database can be easily realized The advantage of this construction is low redundancy and easy rule extraction The consistent storage method provides the uniform platform for sharing mining result among different mining systems 2001BA101A07-02 and Chongqing University fund 2002 References Li fei etc the design and realization of knowledge management and expression in the data mining computer engineer and application 2001 14 25-28 Application Programming Interface and Utility Reference Version 6 Release 1 IBM Inc 1999 Hongen Z Mining and visualization of association rules over relational DBMS UF MS thesis August 2000 Zhongyang Xiong etc Research of Storage Method for Association Rules with Relational Algebra IEEE TENCON\22202 Oct 2002, Beijing China Chen Jianwen the research of data mining algorithm and its application Master degree dissertation Department of computer Chongqing University Chongqing Pages 41,2001.5 S Thomas and S Sarawagi Mining Generalized Association Rules and Sequential Patterns Using SQL Queries Proceedings of KDD-98 4th International Conference on Knowledge Discovery and Data Mining AAA1 Press 1998 Acknowledgements The author is partially supported by national fund 288 


18 Number of nodes 2 4 8 Number of nodes 2 4 8 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 amount of transaction WS cluster NPA CC Shift 0.148 0.117 0.258 2.180 2.180 0.766 1.855 1.855 0.469 SR2201 0.369 0.356 0.889 0.385 0.385 1.114 0.378 0.378 0.842 Figure 4 The execution time and the commu nication time vs the number of transactions 3 140 160 i Shin  cc  i _  20 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 number of transactions Figure 5 The ratio of the execution time for each parallel algorithm to the execution time for corresponding sequential algorithm shows that the execution time and the communication time for all algorithms increase in proportion to the number of transactions The execution time for the Shift is shorter than those for the other algorithms The advantage of parallelization is evident when the number of transactions is more than 2500 Figure 5 shows that the ratio of the execution time of a parallel algorithm to that of a sequential algorithm decreases as the number of transactions increase 5.3 Relation between execution time and the number of nodes The execution time and the communication time of three parallel algorithms on the WS cluster when the number of transactions was 5000 and the minimum support was 1 are plotted in Figure 6 against the number of nodes For all algorithms the execution time 6 5 4 I3 _ E 2 1 0 2 4 8 16 32 number of nodes Figure 6 The execution time and the commu nication time vs the number of nodes decreases when the number of nodes increases, whereas the communication time increases when the number of nodes increases The performance of Shift algorithm is the best and there is little difference between the performances of the NPA and CC algorithms 5.4 Results on the parallel computer The execution time and the communication time of the three algorithms running on the parallel computer when the number of transactions was 5000 and the min imum support was 1 is plotted in Figure 7 against the number of nodes The communication times for three algorithms running on the 11's cluster and on the par allel computer are listed along with the numbers of nodes in Table 3 Table 3 shows that the communication times for NPA and CC algorithms are shorter on the parallel computer than they are in the WS cluster environment 366 


NPA  1 EO 1 number of nodes Figure 7 The execution time and the commu nication time on the SR2201 On the other hand, the communication time for Shift algorithms is shorter on the WS cluster than that on the SR2201 6 Discussions 6.1 Execution on a workstation cluster The execution times for NP.4 and CC algorithms increase rapidly with a decrease in the minimum sup port This is because the number of candidate itemsets increases when the minimum support decreases and these algorithms scan the all candidate itemsets in the transaction database at each node But because the Shift algorithm partitions the candidate itemsets into each node the execution time of scanning is shorter than that for the other algorithms and does not in crease as rapidly when the minimum support decreases The execution times for all algorithms increase with an increase in the number of transactions and the ra tio of the execution time of each parallel algorithm to the execution time of the corresponding sequential al gorithm decreases with an increase in the number of transactions This ratio for the Shift algorithm reaches a minimum value when the number of transactions is 4000 and the algorithm converges more rapidly than the other algorithms The execution times for all algorithms decreases with an increase in the number of nodes The re duction of the communication time in Shift operations seems to be due to the scanning processing and com munication processing being executed asynchronously Because data are searched in parallel and all amounts of searched data are almost the same for all these al gorithms CPU processing time which is the difference of the communication time from the execution time is almost the same for all algorithms Our cost analysis showed that the amount of com munication was smallest for the CC algorithms but the execution times for NPA and CC algorithms were almost the same in our experiments This seems to be because that the size of data used in our experiment is not so large 6.2 Execution on the parallel computer The execution times for all algorithms were much longer on the parallel computer than that were in the WS cluster environment We think this is because amount of CPU memory available on the parallel com puter was insufficient On the other hand the com munication time was more stable on the parallel com puter and the time for communication between nodes is shorter on the parallel computer In other words the ratio of the communication time to the execution time is large in a WS cluster environment and the commu nication time has a great influence on the execution time In the WS cluster environment the communication time for the Shift algorithm which uses shift opera tions is less than that for the CC algorithm which uses broadcast operations On the other hand, the commu nication time for the Shift algorithm on the parallel computer is lager than that for the CC algorithm The Shift algorithm is therefore effective in a LVS cluster environment that can execute shift operations rapidly 7 Conclusion The distributed algorithms proposed in this pa per are effective when parallel processing distributed throughout clustered computers is used to mine databases for association rules When we implemented these algorithms on a SVS cluster and on a parallel com puter so that we could evaluate their performance we found that the Shift algorithm was the most effective when there was a large number of candidate itemsets and processor nodes in the WS cluster environment This is because the ratio of communication time to ex ecution time is large in a WS cluster environment and the communication time therefore has a great influence on the execution time We intend to perform more analysis about the com munication cost between nodes We also intend to per form further experiments with large size data which are used at companies and institutes We also intend to develop a new algorithm to share the loads among nodes because real data are often distributed unevenly 367 


References 141 111 121 31 R Agrawd and R Srikant 223Fast Algorithms for Mining Association Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.487-499 1994 R Srikant and R Agrawal 223hslining Generalized Asso ciation Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.407-419 1995 N Megiddo and R Srikant 223Discovering Predictive As sociation Rules,\224 Proc ofthe 4th Int\222l Conf on Knowl edge Discovery an Databeses and Data Mining 1998 I51 161 E.H Han G Karypis and V Kuniar 223Scalable par allel data mining for association rules;\224 Proc of ACM SIGMOD Int\222l Conf pp.277-288 1997 T Shintani and M Kitsuregawa 223Iniplenientation of Parallel Mining Association Rules and their Evalua tion,\224 JSPP\22296 pp.97-104 June 1996 L Harada N Akaboshi K Ogihara and R Take 223Par allel Algorithm with Load Balancing for Mining Associ ation Rules,\224 IEZCE Trans on Info and Syst V-ol.J82 D-1 No.1 pp.70-81 January 1999 368 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



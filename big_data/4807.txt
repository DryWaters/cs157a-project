 
 
  
 
   
  


         


       


             


 GAR H  S  s l1  s l 2   c l  Input: H   a hierarchy concept for every attribute S  U  A  V an information system, where U are objects A are attributes, and V are their values s l1   threshold for a minimum Right Support at level l s l2   threshold for a minimum Left Support at level l c l   threshold for a minimum Confidence at level l  Step 1 Find the frequent generalized closed factor-sets: the sets of factors that have minimum left and right supports at highest level Step 1.1 Find the domain of each concept at level l and its support count above the predefined s l1 or s l2  AV  Get all distinct attribute-concept-value pairs for all attribute-concept-value pair  a,v  do begin HD  A, CV, L, D\:=Get domain of each concept value CV – concept value, L – Level value, 1, 2, 3,…., D – domain While L 007 1 do For each concept value If Card\(HD  min \(s l1 s l2    qualified attribute-value pairs  a, v  distinctValueQueue  006  a,v   end if end for end while end for Step 1.2 Find the frequent generalized closed factor-set Step 1.2.1 1-factor-sets N:= Get all elements at level  1 from distinctValueQueue M:= Get all elements at level  1 from distinctValueQueue while subLevelDistinctValueQueue changed do  for each attribute-value pair  a n v n  do For each attribute-value pair  a m v m  do If  a n  a m  AtomicFactor  a l  v n 005 v m   If  supL  AtomicFactor  012 s l1 supR  AtomicFactor  012 s l2  atomicFactorQueue 006  AtomicFactor  subLevelDistinctValueQueue 006 subLevelDistinctValue  end if end if end for N:= Get all elements from subLevelDistinctValueQueue M:= Get all elements from subLevelDistinctValueQueue end for end while  Step 1.2.2 2-factor-sets F:= Get all atomic factors  from atomicFactorQueue every factor denotes as f=\(a, v 005 v n:= F.size         // the total number of primitive factors in F for  i:=0; i++; i>n  do for  j  i+1  j++; j>n  do if  f i a 007 f j a  newCandidate  f i 015 f j  if \( supL  newCandidate  s 11  supR  newCandidate  s 12  add this new factor-set into the frequent factor-set queue and mark its length with 2 frequentFactorQueue 006  newCandidate    end if end if end for end for Step 1.2.3 Find the frequent k factor-sets, where k 2.  This step is iteratively generating new k factor-sets using the frequent \(k1\ctor-sets found in the previous iteration until there are no new frequent factor-sets generated P:=Get all frequent  k 1  factor-sets from frequentFactorQueue n:= the total number of \(k-1\-factor-sets  in P For  i:=0; i++; i>n  do If the first \(k-2\ factors are identical in f i and f j newCandidate  f i 015 f j  If \( supL  newCandidate  s 1 supR  newCandidate  s 2  If all subsets of newCandidate 023 frequentFactorQueue add this new factor-set into the frequent factor-set queue and mark its length with k frequentFactorQueue 006  newCandidate  end if end if end if end for Step 1.2.4 F max get all frequent factor-sets f with max Length from frequentFactorQueue maxLength:= the length of a factor-set in F max CompactFactorQueue  006 F k for  i   maxLength-1  i- -, i  1  do F i get all frequent factor-sets f’ with length i from frequentFactorQueue for each f’ in F i do if f  supL > max  010 f.supL in F i+1  if f  supR > max  010 f.supR in F i+1   CompactFactorQueue  006 f  end if end if end for end for Step 2. Generate strong Rules having the confidence above c  For each frequent factor-set f in frequentFactorQueue do n := f.length //the length of the frequent factor-set EQ for elementQueque EQ:= Parse the factor-set into factors and store each factor with level of 999 for the length of  the premise i from 1 to n-1 get next available premise for all factors in EQ Consequence  f- premise.factor   end for ruleCandidate  premise 000 Consequence  if \(conf\(ruleCandidate  012 c add rule the output and place a positive mark results 006 ruleCandidate mark EQ.level with level i //place a Positive mark end if end for end for print all Reclassification rules from result Figure 2. Pseudo-code of algorithm GAR 
2008 
2020 


5. Generalized Reclassification Rules Authors in [15  n tro d u ce h i erarch y  tax o n o m y  into association rule mining to identify more interesting rules and their results show promise. In this paper, we also studied generalization in mining, but used a different mining paradigm, actionable rule mining.  We developed a similar approach, called Generalized Actionable Rules \(GAR\, in order to find a concise set of reclassification rules.  The algorithm GAR is a breadth-first approach to mining a set of all frequent generalized closed factor-sets within concept hierarchies from top to lower level abstraction and then constructs reclassification rules straightforward by partitioning the valid factor-sets into a IF-THEN representation A generalized closed factor-set 000 G in S is defined as 000 G  a 1  013 1 005 014 1  015  a 2  013 2 005\014 2  015  015  a p  013 p 005\014 p  iff 000 G 023 000 and none of its factors is the ancestor factor of others A frequent generalized closed factor-set 022 G is defined as 022 G  a 1  013 1 005 014 1  015  a 2  013 2 005\014 2  015  015  a p  013 p 005\014 p  is a frequent generalized closed factor-set at level l iff 022 G 023 000 G  supL 022 G  012 s l1 and supR 022 G  012 s l2 where s l1 and s l2 are the user specified minimum left support  and minimum right support thresholds at level l respectively If a factor occurs rarely, its descendants will be even less frequent. For finding generalized actionable rules, different minimum left support right support, and confidence thresholds can be specified at different levels.   By doing this, if users want to find actionable rules at relatively lower levels of abstraction, the minimum left and right supports can be set relatively low without compromise, generating many valid uninteresting rules at higher or intermediate levels A generalized reclassification rule 000U G in S is defined as a statement 000U G  000 000 000<\000\017\000\003\000\017 where 000  000<\000\017\000\003 003\022 G  000 007 000<\000\017  000 016 000<\000\017\000\003  017 and no factor-set in 000 is an ancestor of any factor-set in 000 in the concept hierarchy Algorithm GAR consists of two main steps: \(1 generate all frequent generalized closed factor-sets, \(2 generate strong generalized reclassification rules Below is the short description of the algorithm and the pseudo-code of GAR is presented in Figure 2 5.1 Generate all Frequent Generalized Closed Factor-Sets  This step computes the frequent factor-sets in the data set through several iterations and the breadth-first top-downward approach is utilized. In each iteration we generate new candidates from frequent generalized closed factor-sets found in the previous iteration; the left support and right support for each candidate is then computed and tested against the user-specified thresholds for that level.  It examines the highest top level of abstraction to generate frequent closed factorsets and then progresses deeper into their frequent descendants at lower concept levels. The lower level concepts will be evaluated only when its ancestor has large left and right supports at the corresponding upper level.  End users have the power to gradually decrease the minimum left and right support thresholds at lower levels of abstraction in order to discover rules at different levels 5.2 Generate Generalized Rules  A reclassification rule is extracted by partitioning the factor-set W into two non-empty subsets X and Y and represented as X 000 Y where X, Y 023 W  X, Y 024 F S and X  W Y A level-wise approach is utilized for generating rules, where each level corresponds to the number of factors belonging to the rule premise The rule-premise is extended one factor at a time.  It starts with one factor on the rule-premise, such as X If the rule confidence is above the predetermined threshold, it is called a strong rule and marked with a positive mark  The principle of minimum description length is also adopted to identify the general rules.  Therefore, in the next iteration, it generates new candidates from only unmarked rules found in the previous iteration by moving one of the consequence-type factors to the rule premise, now X is a 2-factor-set.  Repeat the previous step until there is only one flexible factor on the rule consequent, such as Y By doing this, the resulting set of rules is comprised of those with the shortest length of premise, not all the lengths 
2009 
2021 


6.   Conclusion This paper addressed the problem of discovering generalized actionable rules in a dataset.   We investigated the properties of Reclassification Rules presented the notions of generalized closed factor-sets generalized reclassification rules, and introduced algorithm GAR This new algorithm is based on the concept of frequent generalized closed factor-sets to generate a very concise set of rules. The proposed framework provides more generalized knowledge from data than previous existing methods by incorporating concept hierarchy into mining procedure.  In addition the quality of the extracted rules in terms of their interestingness and understandability is improved Therefore, it would be easier for the user to comprehend the rule result in a timely manner.   In the future, we intend to apply this approach to a large variety of databases and application domains 7. References 1 A grawal R   Imiel i n s ki  T an d  S w ami, A M i n i n g  association rules between sets of items in large databases. In Proceedings of the ACM SIGMOD International Conference on the Management of Data. P. Buneman and S. Jajodia, Eds ACM Press, Washington DC, 1993, pp. 207–216   B e ne dit t o  M  E M  D  a nd Ba r r o s L  N d Us ing  Concept Hierarchies in Knowledge Discovery. A.L.C Bazzan and S. Labidi \(Eds.\: SBIA 2004, LNAI 3171, pp 255–265, 2004. Springer-Verlag Berlin Heidelberg 2004   G r z y m a l a B us se   J  A ne w v e r s i on of the r u le induc t i on system LERS. In: Fundamenta Informaticae, 31\(1\, 1997, pp 27-39  Ha n  J  Ca i  Y   and Ce r c one  N  Da t a D ri v e n D i s c ov e r y  of Quantitative Rules in Relational Databases. In: IEEE Trans. Knowledge and Data Eng., vol. 5, pp. 29-40, 1993   Ha n J   a nd Fu Y   D i s c ov e r y  of  m u lt ipl e l e v e l  association rules from large databases. In Proc. of the 21st Int'l Conference on Very Large Databases Zurich Switzerland, September 1995  H e  Z  Xu, X  a nd De ng  S  M i ning  Cl us te r D e f i ning  Actionable Rules. In: Proceedings of NDBC’04, 2 004   H e Z X u X  D e ng S a nd M a R  M i ning A c t i on Rules From Scratch. Expert Systems with Applications. Vol 29, No. 3, 691--699 \(2005   I m S and R a 001\036 Z.W.: Action Rule Extraction from a Decision Table: ARED.  In: 17th International Symposium on Methodologies for Intelligent Systems \(ISMIS\, pp 160—168. Springer,  Toronto, Canada \(2008 9 i n g  C  X Che n T  Y a ng Q a nd Che n   J  M i ni ng  Optimal Actions for Intelligent CRM. In: 2002 IEEE International Conference on Data Mining, pp.767--770 IEEE Computer Society, Maebashi City, Japan \(2002 9 i u B   H s u  W   a nd M a  Y    I d e n ti f y ing  Nona c t i ona ble  Association Rules. In: Proceedings of KDD 2001, pp. 329-334. San Francisco, CA, USA \(2001  a s quie r N    B a st i d e Y T a oui l R a nd L a k h a l   L    Discovering Frequent Closed Itemsets for Association Rules In: the 7th international conference on database theory ICDT’99\ pp 398--416, Jerusalem, Israel \(1999 11 P a wlak Z   In f o r m at io n S y st em s   Th eo ret i ca l Foundations. Information Systems Journal. Vol. 6, pp. 205-218 \(1981  i a t e s k y S ha pi ro G   a nd M a t h eu s C   J    T h e  interestingness of deviations. In: Proceedings of AAA Workshop on Knowledge Discovery in Database, pp. 25--36 AAAI Press, Menlo Park, CA \(1994  n la n J   R  C4.5: program for machine learning  Morgan Kaufmann, 1992  m a k r i s hns n  S  a nd R a k e s h  A    M i ni ng G e ne ra l i z e d  Association Rules. In: Proceedings of ICDM’03, pp 685688. IEEE Computer Society, Florida, USA \(2003  a 001\036 Z.W. and Tsay, L.-S.: Discovering Extended Action-Rules \(System DEAR\. In: Proceedings of the IIS'2003 Symposium, Advances in Soft Computing, pp. 293300. Springer, Zakopane, Poland \(2003  001\036 Z.W. and Wieczorkowska, A.: Action Rules: How to Increase Profit of a Company. In: Principles of Data Mining and Knowledge Discovery, Proceedings of PKDD'00, LNAI, pp. 587-592. Springer, Lyon, France 2000  T s a y L  S a nd Ra 001\036 Z.W.: Action Rules Discovery System DEAR2, Method and Experiments. Journal of Experimental and Theoretical Artificial Intelligence, Vol. 17 No. 1-2, pp. 119-128. Taylor and Francis \(2005  s a y L  S a nd Ra 001\036 Z.W.: E-Action Rules. In: Lin T.Y., Xie, Y., Wasilewska, A., and Liau, C.-J. \(eds Foundations of Data Mining, Studies in Computational Intelligence, pp. 261--272. Springer, Berlin / Heidelberg 2007  s ay   L  S a nd Ra 001\036 Z.W.: Discovering the Concise Set of Actionable Patterns. In: 17th International Symposium on Methodologies for Intelligent Systems \(ISMIS\ LNAI, Vol 4994, pp. 169--178. Springer \(2008 20  Tsay  L  S   R as  Z  W   an d Im, S   Re class i ficat io n  Rules. In: IEEE/ICDM Workshop on Foundations of Data 
2010 
2022 


Mining \(FDM 2008\, pp. 619--627. IEEE Computer Society Pisa, Italy \(2008  T s a y L  S   a nd I m   S    M i ni ng NonRe dunda nt Reclassification Rules.  In: Proceedings of the Twenty Second International Conference on Industrial, Engineering Other Applications of Applied Intelligent Systems IEA/AIE'09\, Tainan, Taiwan, June 24-27, 2009, 806-815  W ong R  C  W a nd Fu A   W  C    I S M   It e m  Se le c t ion for Marketing with Cross-selling Considerations. In the Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining \(PAKDD  pp. 431--440. Sydney, Australia 2004  ng Q Yi n  J   L i n  C  X   a nd C h e n  T     Postprocessing Decision Trees to Extract Actionable Knowledge. In Proceedings of ICDM’03, pp 685-688 IEEE Computer Society, Florida, USA \(2003  Z h a n g   H  Zha o Y  C a o, L  a nd Zha n g   C    C o m b i n e d  Association Rule Mining. In: Advances in Knowledge Discovery and Data Mining, Proceedings of the PAKDD Conference, Lecture Notes in Computer Science, 5012, pp 1069-1074. Springer, Antwerp, Belgium \(2008  n g  T  Ra m a k r i s hna n, R a nd L i v n y  M   B I R C H  An efficient data clustering method for very large databases In: Proceedings of ACM SIGMOD Conference, Montreal Canada, pp. 103–114 
2011 
2023 



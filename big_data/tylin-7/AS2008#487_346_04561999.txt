How To Improve Medical Image Diagnosis through Association Rules The IDEA Method Marcela X Ribeiro 1  Agma J M Traina 1  Caetano Traina Jr 1  Natalia A Rosa 2  and Paulo M A Marques 2 1 Department of Computer Science University of S  ao Paulo at S  ao Carlos Brazil 2 School of Medicine of University of S  ao Paulo at Ribeir  ao Preto Brazil 1 f mxavier agma cateano g icmc.usp.br 2 f naty,pmarques g fmrp.usp.br Abstract In this paper we present a new method called IDEA which employs association rules to assist in medical image diagnosis IDEA mines association rules relating visual features with the knowledge gotten from specialists and employs the associations to suggest possible diagnoses for a given medical image IDEA incorporates two new algorithms called Omega and ACE Omega performs simultaneously feature selection and data discretization very ef\002ciently with linear cost on the number of feature values ACE is a new associative classi\002er which has the particular ability of suggesting multiple keywords to compose the diagnosis for a given medical image The IDEA method has an important characteristic that makes it different from other CAD methods it suggests multiple diagnosis hypotheses for an image and ranks them based on a measure of quality The IDEA method was implemented in a prototype IDEA system for radiologists evaluate it The radiologists showed enormous interest in employing the system to aid them in their daily work The IDEA system was applied to real datasets and the results presented high accuracy up to 96.7 The results testify that association rules are wellsuited to support the diagnosing task 1 Introduction A vast amount of medical images is daily generated in hospitals and medical centers Consequently the radiologists have an increasing number of images to analyze manually After analyzing a small number of images the process of diagnosing them becomes tiresome and consequently more susceptible to errors Computational techniques can be provided to assist the physician's work The computerized analysis of medical images have evolved from automated computer diagnosis to computer-aided diagnosis CAD where the radiologists use the computer output as a second opinion to assist them speeding up the diagnosing task and bringing more con\002dence to it CAD systems support radiologists in analyzing digital images and to 002nd out possible diseases CAD is an interdisciplinary research 002eld that combines techniques of data mining digital image processing radiology and usability among others In this work we propose a new approach to employ association rules to support CAD systems The process of mining association rules corresponds to searching a database for patterns relating items that often occur together Association rules re\003ect how human beings learn and memorize new knowledge We will show in this paper that association rules can be successfully applied to support medical image diagnosis In this paper we present the IDEA  I mage D iagnosis E nhancement through A ssociation rules method to support medical image diagnosis through association rules The IDEA method has an important characteristic that makes it different from other CAD methods it allows multiple diagnosis hypotheses to be suggested for the same image and employs a measure of quality to rank them Although we present in this paper the results achieved in mammogram analysis the IDEA method can be employed to analyze other types of medical images if an adequate feature extractor is employed The IDEA system was applied to real datasets and the results show high accuracy up to 96.7 The remainder of this paper is structured as follows Section 2 presents the related work and the background Section 3 details the IDEA method and Section 4 discusses the experiments Finally Section 5 summarizes the conclusions of this work 2 Related Work and Background Recently CAD systems have been developed to support diagnosis of diseases in the breast lung colon and brain It has been shown that radiologists fail to manually detect 
21st IEEE International Symposium on Computer-Based Medical Systems 1063-7125/08 $25.00 © 2008 IEEE DOI 10.1109/CBMS.2008.55 266 
21st IEEE International Symposium on Computer-Based Medical Systems 1063-7125/08 $25.00 © 2008 IEEE DOI 10.1109/CBMS.2008.55 266 
21st IEEE International Symposium on Computer-Based Medical Systems 1063-7125/08 $25.00 © 2008 IEEE DOI 10.1109/CBMS.2008.55 266 
21st IEEE International Symposium on Computer-Based Medical Systems 1063-7125/08 $25.00 © 2008 IEEE DOI 10.1109/CBMS.2008.55 266 


lung nodules in up to 30 of the positive cases To reduce the number of missed lung nodules in a method is presented to detect regions of lung images with abnormalities Studies presented in sho w an impro v ement in the performance of radiologists supported by a CAD system in detecting abnormalities in mammograms Also the diagnosis of colon cancer which is the second leading cause of cancer-related death in the world benef\002ts with the development of CAD tecniques In a method is presented that employs topographical height maps to analyze colon images and to reduce the false-positive colon cancer detection rate In a fuzzy c-means cl ustering technique is employed to classify the colon data Other very promising works in CAD 002eld have been developed to work with brain and li v er 5 In 10  a frame w ork which uses a decision-tree inductor is employed to discover relevant knowledge for medical image analysis and diagnosis Relevant works also applied association rules for image analysis 9 4 Association rule mining is one of the most important tasks in the data mining 002eld and it has been extensively studied and applied to market basket analysis The problem of mining association rules was 002rstly stated in  as follo ws Let I  f i 1      i n g be a set of literals called items A set X 022 I is called an itemset Let R be a table with transactions t involving elements that are subsets of I  An association rule is an expression of the form X  Y  where X and Y are itemsets X is called body or antecedent of the rule Y is called head or consequent of the rule The support is the ratio between the number of transactions of R containing the itemset X  Y and the total number of transactions of R  Con\002dence is the fraction of the number of transactions containing X that also contain Y  The problem of mining association rules as it was 002rstly stated consists of 002nding association rules that satisfy the restrictions of minimum support minsup and con\002dence minconf speci\002ed by the user CAD systems employ image mining a more complex process than the traditional data mining Image mining employs image processing algorithms to extract relevant features from the images organizing them in feature vectors The feature vectors are employed in place of the images to model them as transactions which are used in the mining process Features quantify intrinsic visual characteristics of the images such as color shape and texture leading to vectors with hundreds or even thousands of elements However a large number of features to represent the image can lead to the curse of dimensionality problem where the significance of each feature decreases To avoid this problem the IDEA method incorporates the Omega algorithm that also performs feature selection eliminating redundant and noisy features of the feature vector In this paper we present IDEA  a method based on association rules to support the diagnosis of medical images which is detailed in the next section 3 The IDEA Method IDEA is a supervised method that mines association rules relating visual features automatically extracted from images with the reports given by radiologists about the training images The reports are composed of a set of keywords Figure 1 shows the pipeline and the Algorithm 1 summarizes the steps of the IDEA method Algorithm 1 The steps the IDEA Method Input Training images a test image Output Report set of keywords 1 Extract features of the training images 2 Execute Omega algorithm 3 Mine association rules 4 Extract features of the test image 5 Execute ACE 6 Return the suggested report set of keywords Figure 1 Pipeline of the IDEA method In the training phase see Algorithm 1 features are extracted from the images and feature vectors are used to represent the images line 1 The feature vectors and the class of the training images are submitted to Omega which removes irrelevant features from the feature vector and gives a discretization of the remaining features line 2 The class of an image is the most important keyword chosen by the specialist to describe the image In the training phase a processed feature vector is merged with the diagnosis keywords about the training images producing the transaction representation of the images The transaction representations of all training images are submitted to the Apriori algorithm for association rule mining line 3 limiting the minimum con\002dence to high values In the test phase lines 
267 
267 
267 
267 


4-6 the feature vector of the test image is extracted line 4 and submitted to the ACE algorithm line 5 which uses the association rules to suggest possible keywords to compose the diagnosis of the test image We discuss each step of the IDEA method as follows 3.1 Feature Extraction When dealing with medical images the earliest stage of a CAD system demands to extract the main image features regarding a speci\002c criterion One question that should be answered when working with image mining is which features best represent the semantical meaning of a given image Essentially the most representative features vary according to the image type e.g mammogram brain and lung and according to the focus of the analysis e.g to distinguish nodules and to identify brain white matter For instance when working with mammograms histogram features give a very poor identi\002cation of breast lesions However features of shape can work well to distinguish malignant and benign breast lesions Nevertheless most shape features demand a previous step of lesion segmentation and this step increases the computational effort to a great extent The IDEA method can work with various types of medical images with different focus of analysis However for each type of image and goal an appropriate feature extractor should be employed In our experiments we used two datasets of mammograms The images of the 002rst dataset are regions of interest and the focus of analysis is to identify characteristics of morphology histology and the severity of the lesions To represent this dataset we used a compact feature vector that combines texture shape and color characteristics The images of the second dataset are full mammograms and the focus of analysis is to identify the breast side the mammogram view and the breast density For this dataset a more robust feature vector is employed detailed in Section 4 3.2 The Omega Algorithm Omega is a new supervised algorithm that smartly prepares the feature vectors for the mining of association rules The Omega algorithm performs simultaneously data discretization and feature selection A measure of inconsistence is employed to determine the 002nal number of intervals and to select features As the number of intervals gets smaller the number of inconsistence increases Omega aims at keeping the minimal number of intervals with minimal inconsistency establishing a tradeoff between these measures A cut point is a limit of an interval of real values An interval is also called bin and the most frequent class in a bin is called majority class of the bin An inconsistence is an occurrence of a class different from the majority class in an interval Omega 002rst sorts the continuous values and de\002nes the initial cut points Every time that a change in the class label of the instances occurs a cut point is created In this step Omega produces pure bins wherein the entropy is the lowest possible zero In a second step Omega restricts the minimum frequency that a bin must present avoiding a huge number of cut points Omega removes the right cut points of the intervals that do not satisfy the minimum frequency restriction given by an input parameter H min  The higher the value of H min  the fewer the bins obtained in this step However some caution should be taken before adjusting the H min value the higher the H min  the higher the inconsistencies generated by the discretization process In a third step Omega fuses consecutive intervals using the inconsistence rate to determine which intervals should be merged Let M T i be the majority class of an interval T i  Equation 1 gives the inconsistence rate 020 T i of an interval T i  020 T i  j T i j 000 j M T i j j T i j 1 In Equation 1 j T i j is the number of instances in the interval T i and j M T i j is the number of instances of the majority class in T i  The Omega algorithm fuses consecutive intervals that have the same majority class and also have inconsistence rates below or equal an input threshold 020 max 0 024 020 max 024 1  The last step of Omega algorithm is to perform feature selection Let T be the set of intervals in which a feature is discretized For each feature Omega computes the global inconsistence 020 G value according to Equation 2 020 G  P T i 2 T  j T i j 000 j M T i j  P T i 2 T j T i j 2 The feature selection criterion employed by Omega removes from the set of attributes every attribute whose global inconsistence value is greater than an input threshold 020 G max  Since the number of inconsistencies of the features is the factor that most contribute to disturb the learning algorithm discarding the most inconsistent attributes can contribute to improve the accuracy and to speed up the learning algorithm 3.3 Association Rule Mining The IDEA method employs the Apriori algorithm to mine association rules The output of the Omega algorithm and the keywords of the report of the training images are submitted to the Apriori algorithm A constraint which restricts the diagnosis keywords to the head of the rules is added to the mining process The body of the rules is composed of indexes of the features and their intervals The 
268 
268 
268 
268 


values of minimum con\002dence are set to be high greater than 97 An example of rule mined in this step is   malignant mass 0.05,1.0 This rule indicates that the images having the 4 st feature value in the closed interval 0  1 000 0   tend to be images of malignant masses The values 0.05 and 1.0 indicate respectively the support and the con\002dence values of the rule The support of 0.05 indicates that 5 of the training images has the 4 st feature value in 0  1 000 0   and also are malignant mass The con\002dence of 1.0 indicates that 100 of the training images which has the 4 th feature value in interval 0  1 000 0   are malignant masses The mined rules are used as input of the ACE algorithm 3.4 The ACE algorithm Before discussing the ACE  A ssociative C lassi\002er E ngine algorithm it is necessary to clarify some terms We say that an image matches a rule if the image features satisfy the whole body of the rule An image partially matches a rule if the image features only satisfy part of the rule's body An image does not match a rule if the image features do not satisfy any part of the rule's body ACE is a new special classi\002er able to return multiple classes keywords when processing a test image The ACE algorithm stores all itemsets set of keywords belonging to the head of the rules in a data structure An itemset h is returned by ACE in the suggested diagnosis if the following condition is satis\002ed M  h  025 1 and w  3 M  h  P  h  3 M  h  P  h  N  h  025 w min where M  h  is the number of matches of the itemset h  P  h  is the partial number of matches and N  h  is the number of no matches w is the weight of the itemset It indicates the strength that an itemset belongs to the diagnosis The higher the value of weight  the higher the con\002dence that h belongs to the diagnosis of the image A threshold of minimum weight w min 0 024 w min 024 1  is employed to limit the weight of an itemset in the suggested diagnosis If w min  0  all itemsets that have at least one match is returned Figure 2 shows an example of ACE working In this example M  h   1  P  h   1 and N  h   1 for the itemset h  f benign g  Therefore if 4 5 025 w min  the itemset h  f benign g is returned by the algorithm otherwise it is discarded Figure 2 Example of ACE working This section presented our proposed method As we will show in the section of experiments our proposed method is well-suited to suggest diagnoses for medical images enhancing and bringing more con\002dence to the diagnosing process 4 Experiments The experiments were performed employing 10 of the images from the datasets for testing and the remaining images for training The parameters of the Omega algorithm were set to H min  2  020 max  0  2 and 020 G max  0  3  which are tunning parameters of the algorithm The parameters of the algorithms remained the same for both experiments The values of minimum support minsup=0.005 and con\002dence minconf=1.0 were used as Apriori input parameters The value w min  0  which maximizes the ACE accuracy was employed as ACE input parameter 4.1 Experiment 1 the ROI Dataset The ROI dataset consists of 446 images of ROIs Regions of Interest comprising tumoral tissues taken from mammograms collected from the Breast Imaging Reporting and Data System of the Department of Radiology of University of Vienna www.birads.at These ROIs were used to train new students of radiology Each image has a diagnosis composed of three main parts morphology mass or calci\002cation BI-RADS Breast Imaging Reporting and Data System and histology In the feature extraction step the images were segmented and features of texture shape and color were extracted from the segmented regions The segmentation process were performed eliminating from the image the regions with graylevel smaller than 0.14 in a gray-scale ranging and applying the well-known Otsu's technique to the resultant image The features shown in Table 1 were extracted from the segmented regions and used to compose the feature vector representation of the images Table 1 Features extracted from the ROI dataset and their positions feature position average intensity contrast 1-2 smoothness skewness 3-4 uniformity entropy 5-6 invariant moments 7 to 13 histogram mean standard deviation 14-15 The Omega algorithm was applied to the image features removing the 13 th feature It means that the 13 th feature is the least differentiating feature for the ROI dataset The output from Omega was submitted to Apriori algorithm where 
269 
269 
269 
269 


662 rules were mined The association rules generated and the test images were submitted to the ACE algorithm which produced suggestions of diagnosis for each test image In a batch execution the test images were submitted to the IDEA system and the accuracy obtained considering the main parts of the diagnosis morphology and Bi-RADS were Morphology 91.3  BI-RADS value 96.7  Since BI-RADS categorization has a fuzzy separation among consecutive levels even for a human being we considered correct if the BI-RADS level suggested was the same or adjacent of the level annotated by the radiologist in the image report This result indicates that the employed features represent more the BI-RADS level of the lesion than the morphological properties of the images Table 2 shows the values of accuracy sensitivity and speci\002city achieved by IDEA in detecting the BI-RADS levels Table 2 Results achieved by IDEA in detecting the BI-RADS levels over the ROI dataset Accuracy 96.7 Sensitivity 91.3 Speci\002city 71.4 The system was also evaluated by two radiologists who demonstrated a high degree of acceptance for it They reported that the system had indicated lesions that they did not see in a 002rst analysis Figure 3 shows a screenshot of the system when analyzing the image on left of the screenshot The system shows the weight of each diagnosis keyword between parentheses The weight indicates the strength of the respective diagnosis part The higher the weight the higher the con\002dence that the keyword re\003ects the true diagnosis of the image Figure 3 Screenshot of the IDEA system 4.2 Experiment 2 the Mammogram Dataset The Mammogram dataset is composed of 1,080 mammograms collected in the Clinical Hospital of University of Sao Paulo at Ribeir  ao Preto The Mammogram dataset contains images classi\002ed in 4 levels of breast tissue density 1 mostly fatty 362 images 2 partly fatty 446 images 3 partly dense 200 images and 4 mostly dense 72 images Figure 4 illustrates examples of the images of this dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in compounding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue level 1 level 2 level 3 level 4 Figure 4 Examples of images from the Mammogram dataset Images from left to right correspond respectively to mammograms of density levels 1 2 3 and 4 The visual analysis of mammograms by radiologists is a subjective task and suffers from a high degree of variability Thus it is a fair criterion to set as relevant not only the images of the same density class of the query image but also the images in the adjoining classes This is the approach used in this paper The same steps of the 002rst experiment were performed in this experiment In the training phase Omega algorithm reduced 34 of the feature vector size keeping only 56 of the original 85 features Apriori mined 30,996 association rules In the test phase the association rules and the features of test images were submitted to the ACE algorithm We measured the ability of IDEA in distinguishing a breast side  right breast or left breast  b type of the view medio-lateral oblique or cranio-caudal and c density level The values of accuracy obtained considering these parts of the diagnosis were Side 73.5  View 85.1  Density 94.8  Figure 5 shows a screenshot of the system when analyzing the image on the left of the screenshot Observe that the system suggests density 1 and 2 for the analyzed image However density=2 gets a higher value of weight than density=1 thus indicating that most likely the image is from 
270 
270 
270 
270 


density=2 which is the density of the image that is in the specialist's report The system can suggest more than one diagnosis hypotheses to the radiologists work on However the hypotheses with a higher value of weight should be 002rstly considered by them Figure 5 Screenshot of the IDEA system The results of the Experiments 1 and 2 are very promising because they show a very small error rate regarding the main part of the diagnosis BI-RADS and density level for Experiments 1 and 2 respectively making the system more reliable 5 Conclusions In this paper we presented the IDEA approach based on association rules to assist the specialists in the task of image diagnosing IDEA encompasses four main steps feature extraction feature selection and discretization association rule mining and generation of diagnosis suggestions Two new algorithms were developed to support the method Omega and ACE Omega executes two tasks in a single step feature selection and supervised discretization The ACE algorithm generates diagnosis suggestions by assigning multiple keywords to a test image The results of using real datasets show that the proposed method achieves high accuracy up to 96.7 being more sensitive than speci\002c what is desirable in medical domain The radiologists demonstrated acceptance for the IDEA system showing enormous interest in employing the system to aid them in their daily work The IDEA method has an important characteristic that makes it different from other CAD methods it can suggest multiple diagnosis hypotheses for the same image and employs a measure of quality to rank them The results indicate the proposed method is very suitable for the task of suggesting diagnosis of medical images enhancing and bringing more con\002dence to the diagnosing process Acknowledgment We thank the Brazilian funding agencies FAPESP CAPES and CNPq References  R Agra w al T  Imielinski and A  N Sw ami Mining association rules between sets of items in large databases In The ACM SIGMOD ICMD  1993  R Agra w al and R Srikant F ast algorithms for mining association rules In Intl Conf on VLDB  1994  M Al-Shalalf a and R Alhajj A ttracti v e feature reduction approach for colon data classi\002cation In 21st Intl Conf on Advanced Information Networking and Applications Workshops   M.-L Antonie O R Zaane and A Coman Associati v e classi\002ers for medical images In LNAI 2797 MMCD  pages 6883 Springer-Verlag 2003  E.-L Chen P C Chung C.-L Chen H.-M T  A H.-M Tsai and C.-I C A C.-I Chang An automatic diagnostic system for ct liver image classi\002cation IEEE Transactions on Biomedical Engineering  45\(6 1998  K Do i and H Huangb  Computer aid ed diagnosis cad and image-guided decision support Computerized Medical Imaging and Graphics  31\(4-5 2007  S K Kinoshita P  M d Aze v edoMarques R R P  Jr  J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\(2 2007  N Otsu A thresholding selection method from grayle v el histogram IEEE Transactions on Systems Man and Cybernetics  9:6266 1979  H P an J Li and Z W ei Mining interesting association rules in medical images In Advance Data Mining and Medical Applications   P  Perner  Image mining issu es frame w ork a gener ic tool and its application to medical-image diagnosis Engineering Applications of Arti\002cial Intelligence  15\(2 2002  S Quek C Thng J Khoo and W  K oh Radiologists detection of mammographic abnormalities with and without a computer-aided detection system Australasian Radiology  47\(3 2003  O T alak oub J Alirezaie and P  Babyn Lun g se gmentation in pulmonary ct images using wavelet transform In J Alirezaie editor Acoustics Speech and Signal Processing 2007 ICASSP 2007 IEEE Intl Conf on  volume 1 pages I453I456 2007  X W ang M Smith and R Rang ayyan Mammograp hic information analysis through association-rule mining In IEEE CCGEI  pages 14951498 2004  J Y a o J Li and R Summers Ct colonograph y computer aided polyp detection using topographical height map In J Li editor IEEE Intl Conf on Image Processing  volume 5 pages V  21V  24 2007  W L Zhang and X.-Z W ang Feature e x traction and classi\002cation for human brain ct images In X.-Z Wang editor Intl Conf on Machine Learning and Cybernetics  volume 2 pages 11551159 
271 
271 
271 
271 


IEEE Intelligent System 2004 Volume 23 \(8  Telford W.M Geldart, L.P. and Sheriff R.E. \215Applied Geophysics\216 1990\d 600-750   Chakraborty K Mubarak, Al H, Nimmagadda, S.L. and Ray, J 215Exploration Data Integration, an effective reengineering process for new petroleum plays in Gulf Offshore Basins\216, presented at the 2006 International Conference of 2004\, 47 \(7\, pp 77-80 1998\, 13\(1   Shanks, G. Tans ley  E W e ber R. \215Using Ontol ogy to validate conceptual models\216 2005 Australia   Nim m agadda, S.L, and Dreher, H. \215 M apping of Oil and Gas Business  Data Entities for Effective Operational Management\216, presented and published in the held in Phitsanulok 2008  Meers m an R.A 215Fou ndation s, implementations and applications of web semantics, parts 1, 2, 3\216 s, 14\(1\, \(1999\, pp. 27\20536   Jasper, R. and Uschold, M. A 215Framework for understanding and classifying ontology applications\216, published in the International Conference of IEEE in Industry Informatics Forum February, Tripoli, \(2007\, Libya   Nim m agadda, S L. and Dreher, H. Ontology based W a rehouse Tim e Depth Data Modelling Framework for Improved Seismic Interpretation in Onshore Producing Basins, a paper presented and published in the   Nim m agadda, S.L. and Dr eher H 215Ontolo gy of W e ster n Austr alian  petroleum exploration data for effective data warehouse design and data mining\216, presented and published in the 38 th Hawaii International Conference on Information System Sciences 2006   Nim m agadda, S.L., and Dreher H. \215Ontology based data warehouse modelling and mining of earthquake data: prediction analysis along Eurasian-Australian continental plates\216, a paper accepted for presentation in the w, \(1996\, 11\(2   Shanks, G. Tansley  E. and W e ber, R. \215Representing composites in conceptual modelling\216 AAPG 2007   Nim m agadda, S.L. and Dr eher H Ontology Based Data W a rehouse Modelling \205 a Methodology for Managing Petroleum Field Ecosystems, a paper presented and published in the on IT, \(2004   Rudra, A. and Ni mmagadda, S.L. \215 Roles of m u ltidi mensionality and granularity in data mining of war ehoused Australian resources data\216 presented at the Knowledge Engineering Review presented at the 7th international conference 2005\Hawaii, USA   Nim m agadda, S.L. and Dr eher, H. \215Ontology-Base Data warehousing and Mining Approaches in Petroleu m Industries\216: in Negro, H.O Cisaro, S.G., and Xodo D., \(Eds.\, Data Mining with Ontologies Implementation, Findings and Framework, a book published in 2007 by Idea Group Inc http://www.exa.unicen.edu.au/dmontolo  November, Perth, Australia  Chakraborty  K AlHajeri, M and Nimmagadda, S.L. \2153D Seismic Data Attributes Analysis for Predicting Wara reservoir qualities in the Al-Khafji Field, Middle East\216 proceedings of the International Petroleum Technology Conference IPTC Knowledge Engineering Revie communications of the ACM Curtin Business School, 2004   Valente, A., Russ, T., Ma cGrego r, R., and Swartout, W. \215Building and re\logy of air campaign planning\216 proceedings of the 3 rd international IEEE conference on Industrial Informatics proceedings of the IJCAI-99 ontology workshop proceedings of the 4 th International Conference of IEEE Industry Informatics proceedings of the 2 nd International Conference of IEEE-DEST 2007   Nim m agadda, S.L. and Ru dra A. \215Data sources and requirement analysis for multidimensional database modeling \205 an Australian Resources Industry scenario\216 Lecture Notes presented at School of Information Systems 1999\, p.1-20   Uschold, M.E. \215Knowledge level m odeling: concepts and terminology\216 2003\, 46\(10\, pp 85-89   Hoffer, J.A, Presscot, M.B and Mc Fadden, F.R. \215Modern Database Management\216, \(2005\, 7 th Edition, Prentice Hall   Pujari, A.K 215 D ata Mining Techni ques\216, Universities Press \(India  Private Limited, \(2002  Ozkarahan E 215Database Ma nagement, Concepts, Design and Practice\216, \(1990   Uschold, M. & Gr uninger M. Onto logies 215Principles m e thods and applications\216 VI CONCLUSIONS AND RECOMMENDATIONS 1 Ontology based design of data acquisition; data processing and interpretation are more effective in extracting knowledge on structural and petroleum geology domains. This is indeed a revolutionary concept in the fields of exploration and development of petroleum fields, which has more future scope of commercial research 2 Data instances from CDP, COP, CRP, CSP dimensions can easily be structured and integrated in a warehouse environment for the purpose of interpreting seismic signals and their attributes as required by geologists, well planners, reservoir and production engineers 3 Framing of business rules, constraints among usage of attributes within th e integration process and design of business rules have definite impact on correlation and mapping and thus on data mining 4 Ontology based data structuring has definite advantage, especially when attributes and their relationships are conceptualized using appropriate semantics and contexts 5 Integrating on tologically structured data in a warehousing environment has more flexibility and consistency in attribute mapping and interpretation during data mining stage 6 Structural data views taken from implemented warehoused metadata fo llow definite structure shapes, in terms of seismic high and low data instances, depicting geological knowledge 7 Integration of exploratio n data, modeled from different hierarchically derived multiple dimensions; facilitate the data mining process thus extracting knowledge of commercial petroleum plays. Issues of reuse and interoperability of denormalized fine-grained exploration data structures have also been emphasized in the context of implementing ontology based warehousing in petroleum exploration industries This research work addresses new methodologies, which have the potential to revolutionize the exploration and resources industries worldwide This is an on-going commercial research work at Curtin Business School Curtin University of Tech nology, Au stralia. Industry collaboration is accommodated through the University\220s commercialization arm \205 contact the second named author R EFERENCES   Beau m ont E.A and Foster, N.H. \215Exploring for Oil & Gas Traps  AAPG Publications of Millennium Edition\216, \(1999 2  Gilbert, R Liu Y. Abriel  W. an d Preece R. \215 R eservoir m odeling  integrating various data at appropriate scales\216 presented at the 2007 3 rd North African/Mediterranean Petroleum & Geoscience Conference Exhibition Communications of ACM Leading Edge 


TREC ONTO p-value Macro-FM 0.388 0.386 0.862 Micro-FM 0.356 0.355 0.896 MAP 0.290 0.284 0.484 Table 1 Other Experimental results downgrade For the average macroand microF 1 Measures also shown on Table 1 the TREC model only outperformed the ONTO model by 0.002 0.5 in macro F 1 and 0.001 0.2 in micro F 1  The two models achieved almost the same performance The evaluation result is promising The statistical test is also performed on the experimental results in order to analyze the evaluation's reliability As suggested by we use the Student's Paired T-Test for the signi\002cance test The null hypothesis in our T-Test is that no difference exists in two comparing models When two tests produce substantially low p-value usually  0.05 the null hypothesis can be rejected In contrast when two tests produce high p-value usually  0.1 there is not or just little practical difference between two models The T-Test results are also presented on Table 1 The pvalue s show that there is no evidence of signi\002cant difference between two experimental models as the produced pvalue s are quite high  p-value 0.484\(MAP 0.862\(macroFM and 0.896\(micro-FM far greater than 0.1 Thus we can conclude that in terms of statistics our proposed model has the same performance as the golden TREC model and the evaluation result is reliable The advantage of the TREC model is that the experimental topics and the training sets are generated by the same linguists manually They as users perfectly know their information needs and what they are looking for in the training sets Therefore it is reasonable that the TREC model performed better than the ONTO model as we cannot expect that a computational model could outperform a such perfect manual model However the knowledge contained in TREC model's training sets is well formed for human beings to understand but not for computers The contained knowledge is not mathematically formalized and speci\002ed The ONTO model on the other hand formally speci\002es the user background knowledge and the related semantic relations using the world knowledge base and local instance repositories The mathematic formalizations are ideal for computers to understand This leverages the performance of the ONTO model As a result as shown on Fig 2 and Table 1 the ONTO model achieved almost the same performance as that of the TREC model 6 Conclusions In this paper an ontology-based knowledge IR framework is proposed aiming to discover a user's background knowledge to improve IR performance The framework consists of a user's mental model a querying model a computer model and an ontology model A world knowledge base is used by the computer model to construct an ontology to simulate a user's mental model and the ontology is personalized by using the user's local instance repository The semantic relations of hypernym/hyponym holonym/meronym and synonym are speci\002ed in the ontology model The framework is successfully evaluated by comparing to a manual user model The ontology-based framework is a novel contribution to knowledge engineering and Web information retrieval References   C Buckley and E M Voorhees Evaluating evaluation measure stability In Proc of SIGIR 00  pages 3340 2000   R M Colomb Information Spaces The Architecture of Cyberspace  Springer 2002   D Dou G Frishkoff J Rong R Frank A Malony and D Tucker Development of neuroelectromagnetic ontologies\(NEMO a framework for mining brainwave ontologies In Proc of KDD 07  pages 270279 2007   S Gauch J Chaffee and A Pretschner Ontology-based personalized search and browsing Web Intelligence and Agent Systems  1\(3-4 2003   X Jiang and A.-H Tan Mining ontological knowledge from domain-speci\002c text documents In Proc of ICDM 05  pages 665668 2005   J D King Y Li X Tao and R Nayak Mining World Knowledge for Analysis of Search Engine Content Web Intelligence and Agent Systems  5\(3 2007   D D Lewis Y Yang T G Rose and F Li RCV1 A new benchmark collection for text categorization research Journal of Machine Learning Research  5:361397 2004   Y Li and N Zhong Mining Ontology for Automatically Acquiring Web User Information Needs IEEE Transactions on Knowledge and Data Engineering  18\(4 2006   H Liu and P Singh ConceptNet a practical commonsense reasoning toolkit BT Technology  22\(4 2004   A D Maedche Ontology Learning for the Semantic Web  Kluwer Academic Publisher 2002   S E Robertson and I Soboroff The TREC 2002 002ltering track report In Text REtrieval Conference  2002   M D Smucker J Allan and B Carterette A Comparison of Statistical Signi\002cance Tests for Information Retrieval Evaluation In Proc of CIKM'07  pages 623632 2007   X Tao Y Li and R Nayak A knowledge retrieval model using ontology mining and user pro\002ling Integrated Computer-Aided Engineering  15\(4 2008   X Tao Y Li N Zhong and R Nayak Ontology mining for personalzied web information gathering In Proc of WI 07  pages 351358 2007   T Tran P Cimiano S Rudolph and R Studer Ontologybased interpretation of keywords for semantic search In Proc of the 6th ICSW  pages 523536 2007   Y Y Yao Y Zeng N Zhong and X Huang Knowedge retrieval KR In Proc of WI 07  pages 729735 2007 
513 
517 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



Abstract An efficient algorithm for mining important association rule from multi-relational database using distributed mining ideas. Most existing data mining approaches look for rules in a single data table However most databases are multi-relational. In this paper we present a novel distributed data-mining method to mine important rules in multiple tables relations\ and combine the method with genetic algorithm to enhance the mining efficiency. Genetic algorithm is in charge of finding antecedent rules and aggregate of transaction set that produces the corresponding rule from the chief attributes. Apriori and statistic method is in charge of mining consequent rules from the rest relational attributes of other tables according to the corresponding transaction set producing the antecedent rule in a distributed way. Our method has several advantages over most exiting data mining approaches. First, it can process multi-relational database efficiently. Second, rules produced have finer pattern Finally 
we adopt a new concept of extended association rules that contain more import and underlying information I INTRODUCTION Data mining algorithms look for patterns in data Most existing data mining approaches are propositional and look for patterns in a single data table [5 ex am p l e, a p r io ri algorithm is the most popular model for mining association rules from databases Association rule in the form of 'If X then Y  X  Y  is interpreted as "database tuples satisfying that X are likely to satisfy Y The support-confidence framework is proposed by Agrawal et al B u t  i n to day  s worl d m o s t 
commercial data are stored in relational databases using multiple tables that are contacted by ID. Relational databases not only have the complex structure, but also store more information. So, the association rules that can response more concrete commercial information are needed Standard association-rule mining \(ARM 1 2   can n o t discover these association rules directly. Instead the data need to be preprocessed or transformed. Several solutions and drawbacks are proposed by Svetlozar Nestorov [7  Regu lar ARM based these approaches for finding answers to questions involving multiple dimensions can overwhelm the system with requests for resources 
So in recent years, the most common types of patterns and Wenxiang Dou Jinglu Hu Kotaro Hirasawa are with the Graduate School of Information, Product and Systems Waseda University, 2-7 Hibikino Wakamatsu, Kitakyushu-shi, Fukuoka, 808-0135, Japan william@ruri.waseda.jp   jinglu@waseda.jp and hirasawa@waseda.jp Gengfeng Wu is with the Graduate School of Computer Engineering and Science, Shanghai University, Shanghai200072, P. R China gfwu@shu.edu.cn approaches considered in data mining have been extended to multi-relational cases. Multi-relational data mining \(MRDM is a multi-disciplinary field dealing with knowledge discovery from relational databases consisting of multiple 
tables [8  No w  MRD M e n c o m p asses m u lti-r el ation al M R association rule discovery, MR decision trees and MR distance-based methods, among others [5  M a ny of M R D M are based on inductive logic programming \(ILP   Typically, ILP techniques perform a search through some large hypothesis space, during which many hypotheses are generated and evaluated 6  So, if the n u m b er of hyp o t h e ses evaluated is very large, it will influence the efficiency In this paper, we combine a genetic algorithm GA\ with the traditional apriori algorithm and statistic method to mine data in relational business database. Then we adopt a new extended concept to describe the association rules that 
contain more concrete commercial information The proposed method has two steps. Firstly, we use the GA to mine antecedent rules and aggregate of transaction set that produces the corresponding rule from the chief attributes Secondly, mines the consequent rules from the rest relational attributes of other tables by using the apriori algorithm and statistic method in terms of the corresponding transaction set producing the antecedent rule in a distributed way The difference with a standard ARM is that our consequent rules consist of some rules mined from other relational tables and contain more information. Finally produces the extended 
association rules through incorporating the antecedent and consequent rules A standard ARM will produce a large number of rough rules and you have to waste time to process and select important rules But in our method you donêt have to do this, because every rule has the finer pattern and contains important and underlying commercial information The organization of the rest of paper is as follows. In Section II we describe the basic ideas of the distribution through an instance of multi-relational data. Section III introduces the GA and illustrates its application in multi-relational data mining together with the apriori algorithm Section IV gives the experimental results. Section 
V is the conclusions and the future work II THE IDEAS OF THE DISTRIBUTED MINING A Multi-Relational Data Mining in Relational Database Dimensional modeling which is the most prevalent technique for commercial data storing organizes tables into fact tables containing basic quantitative measurements of a Distributed Multi-Relational Data Mining Based on Genetic Algorithm Wenxiang Dou, Jinglu Hu Kotaro Hirasawa and Gengfeng Wu 744 978-1-4244-1823-7/08/$25.00 c  2008 IEEE 


business subject and dimension tables that provide descriptions of the facts being stored The data model that is produced by this method is known as a star-schema   Figure 1 shows a simple star-schema model of a commercial database The order table contains the sale figures for each order transaction and the foreign keys that connect it to the three dimensions: Order Details, Customer and Employee A standard ARM discovers correlations among items within transactions. The correlations are expressed in the following form Transactions that contain X are likely to contain Y as well Letters X and Y represent sets of items. There are two important quantities measured for every association rules support and confidence. The support is the fraction of transactions that contain both X and Y The confidence is the fraction of transactions containing X which also contain Y 2  Consider the relational database depicted by Figure 1 A standard association-rule mining question is often defined as the following What products are frequently ordered together This question examines the order table as it relates to the product dimension only. But this database has multiple dimensions, which are completely ignored by the above single-dimension question A CEO or manager could ask more information to analyze, the question could be extended like this following What products are frequently ordered together and how much quantities and whatês the possible order date and how are the customers about these products This question examines multiple dimensions of the order table So standard ARM algorithms cannot find the answer to this question directly. In fact, a standard ARM may not discovery any association rules in situations when there are several meaningful associations that involve multiple dimensions  From the above question we can see that every extended question asked by a manager is relative to the products that are frequently ordered and the additional attributes involved by these questions distribute in other relational tables respectively. Therefore, when we mine the frequent product sets, if we could get the information of their corresponding transaction sets \(In this instance, the information is foreign key\en we can mine the extended rules from other relational tables in a distributed way through the foreign key Figure 2 shows our basic ideas of the distributed mining In the following we will define a new extended association rule to answer the extended question and give a solution about distributed mining B Extended Association Rules According to the extended questions and the ideas of distributed mining, we can aim at these products ordered by customers frequently and describe the additional information like this Product1,Product2\=>\(Quantity1=20,Quantity2=30,Or derDate=1996\(80%\,Customer=\(Sales Administrator Germany\\(%70 Formally we define extended association rules as follows Definition Let T be a relational database where X set of values of the chief attributes. Let Y i  i 1,2,É,n\set of values of the rest attributes from other relational table of T  Then X   Y 1  Y 2  Y n  is an extended association rule with the following interpretation: Transactions that contain X are likely to contain  Y 1  Y 2  Y n  Though the extended association rules are natural extensions of the standard association rules, they contain  Fig. 1 Example Star-Schema Fig. 2.  Distributed Mining Idea 2008 IEEE Congress on Evolutionary Computation CEC 2008 745 


12345 101100 20 1 1 1 0 30 0 1 0 1 41 1 1 1 0 50 1 1 1 1 Pd Pd Pd Pd Pd Trans Trans Trans Trans Trans Fi g  3.  Exam p le Matrix Structure about transaction record more concrete and diverse information There are several distinct advantages. First some underlying information can be found For example a manager wants to know what products are frequently ordered together and their quantities A standard ARM can find these products, but it canêt add up the quantity that every customer ordered. Or, he wants to know the order situation of the rule  Product1  Product2 n some year. If the rule just satisfies the minimum support and 80 percent of transactions containing the rule are ordered in 1996. Then, a standard ARM also cannot find the information because the support of the rule Product1  Product2,1996 s less than the minimum support. Second, containing more information makes it much easy to devise a marketing strategy For example according to the order date and quantities, general scale of production will be predicted and according to the information of customers, ships that can carry these products to the countries of customers will be prepared Third, for the same support threshold the number of discovered extended association rules is much less than the number of standard rules. The reason is that the extended association rules involve more attributes and these attributes will be mined by using distributed method. Thus transactions that support them fit a more detailed pattern than standard rules Intuitively standard rules show associations of a coarser granularity while the extended rules show finer associations C Solution Matrix Grouping Method Now, let us return the question how to mine the multi-relational data. In the above depiction, we have proposed a method of distributed mining. Based on the ideas we have to find a solution that can not only mine the frequent items, but also retain the information of the transaction set that contains these items. But, let us consider it on other way round. If we can find this transaction set of which some products are ordered in every transaction, then, we can get the rule from the transaction set For finding these transaction sets, a matrix grouping method occurred to us. Let us see an example Figure 3 shows a matrix structure about some transaction record Pdi  i 1É5\ denotes some product and Transj  j 1...5 denotes some transaction. If Pdi is ordered by Transj then we write 1 in the i th column of the j th row Otherwise, we write 0 In this example we suppose that the minimum support is 60 percent. That means the rule must appear at least in three transactions. So, at first, we make each three transactions as a group If there some products are ordered in every transaction of some group, then extracting these products as a rule For example Trans2  Trans4  Trans5   Pd2  Pd3  Pd4   Trans1  Trans2  Trans4  Pd2  Pd3  Trans1  Trans4  Trans 5  Pd2  Pd3  and so on In this example, it can produce C 5 3 groups and retain the groups that can get the rules. Second we incorporate the groups that have the same rules and calculate the support for every rule according to size of groups For example, incorporating  Trans1  Trans2  Trans4   Pd2  Pd3 d Trans1  Trans4  Trans5   Pd2  Pd3 e can get Trans1  Trans2  Trans4  Trans5  Pd2  Pd3 d its support will be 80 percent As we can see that the proposed matrix grouping method can not only find all the rules, but also retain the information of groups extracting these rules \(the information is the foreign key be relative to other tables\us, this method can solve our distributed mining problem However, if the database is large, for example it contains one thousand, ten thousand or hundred thousand transactions You can image how many groups will be produced by using the matrix grouping method In addition, most groups are useless because they cannot extract rules So the matrix grouping method is just suitable for the small database For enhancing the mining efficiency in large database, in the next section, we will introduce the GA which adopts heuristic genetic operators to find those groups that can extract rules and avoid wasting more calculating time in the unmeaning groups, and its application for distributed mining together with apriori algorithm and statistic method III GA BASED DISTRIBUTED DATA MINING A Genetic Algorithm with Modifications As mentioned in the previous section, when databases are large, it needs an effective method for discovering the groups containing rules GA, which is one of the evolutionary computation techniques, has powerful ability of global search and optimization [1  Th us we c o m b i n e G A a nd t h e grouping concept to find rules It doesnêt like a matrix grouping method that produces all the groups for discovering rules Our GA based method, which finds the groups containing rules as more as possible and avoid producing much more unmeaning groups through using heuristic genetic operators, will consume much less time than the matrix grouping method in large database The basic flow of this method is: First, let each transaction be a chromosome. The individual will consist of these transactions Second, Initial individuals are the partition of transactions according to the minimum support. Third executes heuristic genetic operators including selection crossover and mutation on these individual to find rules Finally, incorporates all the groups to extract the antecedent 746 2008 IEEE Congress on Evolutionary Computation CEC 2008 


 Fig. 4.  Example Individual of GA rules. Figure 4 shows an example of the individual Suppose the minimum support is set 3 So every individual has three transactions. If an itemset appears in all transactions of the individual we call the individual can produce a rule satisfying the minimum support. In this case the individual can produce Pd2  Pd3  The population of our GA will become larger and larger along with the increase of the generation, because every discovered individual that can extract a rule will be retained for attending the latter genetic operation Users can set the number of the generation or the number of rules as the end condition. So it is also an advantage that GA can stop in any time and star form the stop position In the following, we will introduce the detailed implementation about the production of initial individuals some parameters defined and genetic operators of the GA B Initial Individuals Selection For most genetic algorithms, a random policy is adopted to initialize individuals. But, for our problem of rule-mining, the group that cannot extract a rule is useless and a random police maybe produce many useless groups. So, we will use a special method to initialize individuals for avoiding producing this kind of group In an apriori algorithm the frequent one-item set is the foundation for producing the latter frequent n-items sets So we initialize individuals from these transaction sets that can extract a rule containing at least one item Let us see Fig. 3 again. The frequent one-item set satisfying the minimum support 60 percent is Pd2  Pd3  Pd4 nd the transaction sets containing these items are respective  Trans1  Trans2  Trans4  Trans5   Trans1  Trans2  Trans3  Tra ns4  Trans5 d Trans2  Trans4  Trans5  the individuals will be initialized among these transaction sets. In this examples, the individuals will be Trans1  Trans2  Trans4   Trans5  Trans1  Trans2   Trans1  Trans2  Trans3   Trans4  Tra ns5  Trans1   Trans2  Trans4  Trans5 This method not only can produce better groups for the latter genetic operation, but find all the rules at least containing one attribute C Parameter Definition Before introducing the genetic operators, some parameters should be explained because they will be used in the latter operation. Let us use Trans1  Trans2  Trans3  an individual to illustrate these parameters \(See Fig. 3 Individual Identity  IVI  consists of the symbols of chromosomes in the individual. Every chromosome has a unique symbol that is the serial number of the corresponding transaction. This can distinguish these individuals For example, the IVI of the individual Trans1  Trans2  Trans3 s  1-2-3  Chromosome Fitness CF  reflects the probability that this chromosome is combined with other chromosomes to extract a rule. Formal definition is as in \(1 1 1 n i i i p CF Na 1 The n is the number of gene in the chromosome N is the number of total chromosomes i p is the value of the i th gene 0 or 1\ and i a is the number of the i th gene that has the value 1 in total chromosomes. For example, about the individual  Trans1  Trans2  Trans3  CF  Trans1 s 3/2 CF  Trans2  11/6 and CF  Trans3 4 Individual Fitness IVF  is the number of items contained by the rule of the individual. It means that if the individual cannot extract a rule, then IVF is 0, otherwise IVF is the number of items the rule contains. For example because the individual  Trans1  Trans2  Trans3 extract rule Pd3  the IVF is 1 Upgrade Index  UI  shows a distance for getting or expanding the rule of the individual, and is denoted by a negative number. The larger the value of UI is, the more possible the rule is got or expanded through using genetic operators For example the individual  Trans1  Trans2  Trans3 can extract rule Pd3 t if Pd2 also is ordered in the Trans3 the individual can expand the rule as  Pd2  Pd3  UI of the individual is -1. About the individual  Trans2  Trans4  Trans5 can extract rule Pd2  Pd3  Pd4 If Pd1 can be is ordered in the Trans2 and Trans5 the individual can expand the rule as  Pd1  Pd2  Pd3  Pd4  UI of the individual is -2 Upgrade Genes UG  is set of genes items needed by the individual for enhancing the UI  In most situations we want to know not only whether the individual can produce rule, but also which genes contained by these chromosomes influence the rule to be produced or expanded So, the UG can help us to answer the question. Let us see the above example. For the individual  Trans2  Trans4  Trans5 we can find some transaction containing Pd1  Pd2  Pd3  Pd4 to replace the Trans2 or Trans5 or transaction containing  Pd2  Pd3  Pd4  Pd5 to replace the Trans2 or Trans4 the UI of this individual will become -1. So, the UG of the individual is the set of Pd1  Pd5 When the value of UI reaches 0 it means the individual gets or expands the rule and the UI will be reset In the next phase, we introduce how to execute the genetic operation by using these parameters 2008 IEEE Congress on Evolutionary Computation CEC 2008 747 


D Genetic Operators Our genetic operators are like a standard GA including selection, crossover and mutation but the implementation is different Our objective is to find the individuals containing rules as more as possible according to the common feature of chromosomes. Therefore, we adopt heuristic genetic operators to search better individuals by using the above defined parameters In addition initial individuals will be as the reserved group and not attend the selection and mutation because they contain all the information of transactions Let us see the following genetic operators Selection For retaining rules, we select all the individuals whose value of IVF is larger than 0. During the selection, for making each individual be unique, we exclude the individuals that have been selected according to the value of IVI  Crossover For not losing rules our crossover operation will retain the parents. There are two crossover strategies One is that selects chromosomes having different symbol to produce a new individual from both parents in terms of the value of CF The larger the CF is, the more possible the chromosome is selected. Another is that checks whether there are some appropriate chromosomes that can make the UI of another parent enhance through replacing operation in a parent \(See the definition of UG If this kind of chromosomes exists we produce a new individual by replacing other chromosomes of another parent .We pair the individuals randomly and adopt the two strategies for every pair Mutation The objective of the mutation is to make the individual easy to get or expand the rule. The process of the mutation is to find some chromosome containing any union of the subset of the UG and items set contained by the rule of the individual to replace any chromosome of this individual which can enhance the value of UI  For example, the individual Trans2  Trans4  Trans5 See Fig 2\ract rule Pd2  Pd3  Pd4 nd its UG is Pd1  Pd5 See the definition of UG the mutation of this individual is to find some chromosome containing Pd1  Pd2  Pd3  Pd4 or Pd2  Pd3  Pd4  Pd5 or Pd1  Pd2  Pd3  Pd4  Pd5  to replace any chromosome of this individual, which can make the UI be -1 When some individuals get or expand a rule through mutation operation, the UI and UG of the individuals will be reset. Otherwise, just UG will be reset and let UI equals to UI plus 1 The mutation operation will scan total transaction set to find the appropriate chromosome. The best situation is to find it in the initial position and the worst doesnêt find. So the mutation probability will be according to the value of UI The larger the value of UI is, the more possible the individual takes place the mutation After satisfying the end condition, we incorporate all the individuals extracting same rules and calculate their support E Flow of Distributed mining Now we can combine our GA with the apriori algorithm and statistic method to mine multi-relational data. The basic architecture of our distributed mining system is shown in Fig.5 In relational databases, some attributes are unmeaning for commercial decision for example, the fax or the phone of customers So we just mine rules among the valuable attributes. The flow of the distributed mining will be shown as follows First, we extract valuable relational data from multiple tables through the foreign key and store them in the corresponding arrays according to the respective table belonged to by using uniform key to connect them In here we use the sequence number of array as the uniform relational key because in the latter we can find the data of relational attributes quickly through the sequence number of array Second, we mine the antecedent rules among the chief attributes data \(Generally are the information of products and produce corresponding relational key set of every rule by using our GA Third mines the extended consequent rules from other arrays by using the apriori algorithm and statistic method in terms of the relational key set in a distributed way The statistic method is in charge of mining the attribute needed to be added up. For example, the Quantity attribute in Order Details table \(See Fig. 1  Fig. 5.  System Architecture of Distributed Mining for the Multi-Relational Data Minin g 748 2008 IEEE Congress on Evolutionary Computation CEC 2008 


Finally, shows the extended association rules IV EXPERIMENTS For our experiments we used SQL Server2000 relational DBMS running on a 1.50GHz Pentium M with 504MB RAB The data we used is from the Northwind database of the SQL Server2000 and the relational structure is shown in Fig. 1 The sizes of the tables are as follows The Order Details table has 2155 tuples The Order table has 830 tuples The Customers table has 91 tuples We select 77 kinds of products as the chief attributes to mine the antecedent rules and select Quantity from Order Details table, OrderDate from Order table and ContactTitle and Country from Customers table as the relational attributes to mine the extended consequent rules The minimum support is set 0.5% and the extended minimum confidence is set 40 We will find these antecedent rules containing at least two products Thus, the antecedent rules mined by using our GA will answer the following question What products are frequently ordered together The extended consequent rules mined by using apriori algorithm and statistic method can answer these additional questions as follows How much quantities, what the possible order date is and how the customers are about these products frequently ordered together Figure 6 shows the generations and the number of rules during the GA mining process Table I shows the experimental results after incorporating and extracting the rules containing at least two products Table II shows fourteen extended association rules In the proposed method, the GA found most anteceden t rules. The matrix grouping method will extract anteceden t TABLE I T HE EXPERIMENTAL RESULT OF RULES MINED BY THE GA Quantity Accuracy of the support Proportion of total rules  Antecedent rules 14 92.86 77.78 TABLE II T HE EXTENDED ASSOCIATION RULES Antecedent rules Extended consequent rules Product21 Product51 0.60 Quantity21=81,Quantity51=66 Orderdate=\(1997\(60 80 Product16 Product31 0.84 Quantity16=243,Quantity31=182 Orderdate=\(1997\(42.86%\,1998\(42.86 42.86 Product16 Product60 0.72 Quantity16=196,Quantity60=280 Orderdate=\(1997\(50 Product31 Product51 0.60 Quantity31=186,Quantity51=225 Orderdate=\(1997\(80 Customers  Sales Associate, Ireland\\(40%\ \(Sales 40 Product21 Product61 0.96 Quantity21=176,Quantity61=156 Orderdate=\(1997\(62.5 50 Product16 Product62 0.72 Quantity16=120,Quantity62=89 Orderdate=\(1997\(66.67 50 Product56 Product65 0.60 Quantity56=197,Quantity65=101 40 60 Product31 Product72 0.72 Quantity31=194,Quantity72=199 Orderdate=\(1996\(50 Product60 Product71 0.72 Quantity60=235,Quantity71=197 50 Product10 Product77 0.60 Quantity10=130,Quantity77=132 Orderdate=\(1998\(80 Customers=\(\(Accounting Manager\\(40 Product30 Product54 0.72 Quantity30=67,Quantity54=120 Orderdate=\(1997\(66.67 Product17 Product33 0.60 Quantity17=158,Quantity33=86 Orderdate=\(1998\(60 40 40 Product55 Product62 0.60 Quantity55=135,Quantity62=61 40 40 Product59 Product76 0.60 Quantity59=131,Quantity76=80 Orderdate=\(1997\(80 40  40          Fig. 6. The number of rules and generations 2008 IEEE Congress on Evolutionary Computation CEC 2008 749 


rules through producing C 830 5 groups while our GA just uses 23968 groups to produce rules. Finally, the extracted extended association rules satisfy the condition of importance and have the qualification for commercial decision. Therefore we need not store retrieve, prune and sort a large number of rules for classification as traditional method V C ONCLUSIONS In this paper we introduce a new data mining method to mine rules from multi-relational databases Our approach has two novel points: One is the ideas of distributed mining by using GA and traditional apriori mining algorithm. Another is the definition of the new extended association rule for supporting the commercial decision better. In our experiment the GA based method is more efficient on the antecedent rules mining than the matrix method and the distributed mining method is also different with other multi-relational data mining methods that need query-processing using SQL language The extended association rule has finer pattern and contains more commercial information. Meanwhile, the number of rules is much less than the standard data mining method producing large candidate rules In the future research we will apply our method to the real world databases with large data and intend to combine the fuzzy logic and our method to predict data R EFERENCES  R. Agrawal and T  Im ielinski and A Swam i Mining Association Rules Between Sets of Items in Large Databases in Proc. of .ACM SIGMOD Conf., 1993, pp.207-216  R Agrawal and R. Srikant, çFast Algo r ithm f o r M in ing Association Rules,é in Proc. of .the 20 th VLDB Conf., 1994, pp.487-499  J Roberto and Jr  B a y ar d o a n d R  A g ra wa l Mining the M o s t Interesting Rules,é in Proc of the 5th ACM SIGKDD Conf. 1999 pp.145-154   Christia n Bo r g e lt and Rudolf Kr use  Introduction of As socia tion Rule s Apriori Implementation,é in Proc. of .the 15th Conf on Computational Statistics. 2002, pp.1  Saùo Dûeroski Multi-R elatio nal Data Mining: An Introduction in Proc. of .ACM SIGKDD Conf 2003, pp.1-16   Hendrik Blockeel an d Mich le Sebag, çScalability and ef f iciency in multi-relational data mining in Proc. of .ACM SIGKDD Conf 2003 pp.17-30  Svet lo z a r N es torov a n d Ne nad Jukic  A d-H o c A s socia tion-Rule Mining within the Data Warehouse,é in Proc. of .the 36th HICSS Conf 2002, pp.10  Hendrik Blockeel and Saùo Dûeros k i   M u ltiRelational Data Mining 2005: workshop report,é in Proc. of ACM SIGKDD Conf. 2005 pp.126-128   T. Fukud a Y. Morim oto S. M o r i shita and T. Tokuy am a  D ata Mining with Optimized Two-Dimensional Association Rules,é in Proc. of .the ACM TODS Conf. 2001, pp.179-219   Kaoru S him a da, Kotaro Hirasawa and Jinglu Hu  Class Association Rule Mining with Chi-Squared Test Using Genetic Network Programming in Proc of the Conf on Systems, Man, and Cybernetics 2006, pp.5338-5344   Ma nish Sagga r A s h i s h K u m a r A graw a l a nd A bhim any u L a d Optimization of Association Rule Mining using Improved Genetic Algorithms in Proc. of .the Conf on Systems, Man, and Cybernetics 2004, pp.3725-3729   S Muggle to n e d itor Inductive Logic Program m i ng  Academic Press London, 1992  S Ch a u dhri a n d U D a y a l An o v e r v ie w o f  D a t a  W a r e housi n g a n d OLAP Technology,é in Proc. ACM SIGMOD Conf 1997, pp. 65Ö74  Riyaz Sikora and Selwyn Piramuthu, çFramework for efficient feature selection in genetic algorithm based data mining,é presented at the European Journal of Operational Research 2007 pp. 723Ö737  Ja naki Gopal an E r kan K o rkm az  Reda A l hajj and K e n B a rke r  Effective Data Mining by Integrating Genetic Algorithm into the Data Preprocessing Phase,é in Proc. of .the ICMAL Conf. 2005, pp.6  J.H Holland Adaptation in Natural and Artificial System,é Ann Arbor MI: Univ. Michigan Press, 1975  D.E Goldber g Genetic Algorithm Search, Optimization & Machine Learning Addison Wesley, 1989 750 2008 IEEE Congress on Evolutionary Computation CEC 2008 


TREC ONTO p-value Macro-FM 0.388 0.386 0.862 Micro-FM 0.356 0.355 0.896 MAP 0.290 0.284 0.484 Table 1 Other Experimental results downgrade For the average macroand microF 1 Measures also shown on Table 1 the TREC model only outperformed the ONTO model by 0.002 0.5 in macro F 1 and 0.001 0.2 in micro F 1  The two models achieved almost the same performance The evaluation result is promising The statistical test is also performed on the experimental results in order to analyze the evaluation's reliability As suggested by we use the Student's Paired T-Test for the signi\002cance test The null hypothesis in our T-Test is that no difference exists in two comparing models When two tests produce substantially low p-value usually  0.05 the null hypothesis can be rejected In contrast when two tests produce high p-value usually  0.1 there is not or just little practical difference between two models The T-Test results are also presented on Table 1 The pvalue s show that there is no evidence of signi\002cant difference between two experimental models as the produced pvalue s are quite high  p-value 0.484\(MAP 0.862\(macroFM and 0.896\(micro-FM far greater than 0.1 Thus we can conclude that in terms of statistics our proposed model has the same performance as the golden TREC model and the evaluation result is reliable The advantage of the TREC model is that the experimental topics and the training sets are generated by the same linguists manually They as users perfectly know their information needs and what they are looking for in the training sets Therefore it is reasonable that the TREC model performed better than the ONTO model as we cannot expect that a computational model could outperform a such perfect manual model However the knowledge contained in TREC model's training sets is well formed for human beings to understand but not for computers The contained knowledge is not mathematically formalized and speci\002ed The ONTO model on the other hand formally speci\002es the user background knowledge and the related semantic relations using the world knowledge base and local instance repositories The mathematic formalizations are ideal for computers to understand This leverages the performance of the ONTO model As a result as shown on Fig 2 and Table 1 the ONTO model achieved almost the same performance as that of the TREC model 6 Conclusions In this paper an ontology-based knowledge IR framework is proposed aiming to discover a user's background knowledge to improve IR performance The framework consists of a user's mental model a querying model a computer model and an ontology model A world knowledge base is used by the computer model to construct an ontology to simulate a user's mental model and the ontology is personalized by using the user's local instance repository The semantic relations of hypernym/hyponym holonym/meronym and synonym are speci\002ed in the ontology model The framework is successfully evaluated by comparing to a manual user model The ontology-based framework is a novel contribution to knowledge engineering and Web information retrieval References   C Buckley and E M Voorhees Evaluating evaluation measure stability In Proc of SIGIR 00  pages 33ñ40 2000   R M Colomb Information Spaces The Architecture of Cyberspace  Springer 2002   D Dou G Frishkoff J Rong R Frank A Malony and D Tucker Development of neuroelectromagnetic ontologies\(NEMO a framework for mining brainwave ontologies In Proc of KDD 07  pages 270ñ279 2007   S Gauch J Chaffee and A Pretschner Ontology-based personalized search and browsing Web Intelligence and Agent Systems  1\(3-4 2003   X Jiang and A.-H Tan Mining ontological knowledge from domain-speci\002c text documents In Proc of ICDM 05  pages 665ñ668 2005   J D King Y Li X Tao and R Nayak Mining World Knowledge for Analysis of Search Engine Content Web Intelligence and Agent Systems  5\(3 2007   D D Lewis Y Yang T G Rose and F Li RCV1 A new benchmark collection for text categorization research Journal of Machine Learning Research  5:361ñ397 2004   Y Li and N Zhong Mining Ontology for Automatically Acquiring Web User Information Needs IEEE Transactions on Knowledge and Data Engineering  18\(4 2006   H Liu and P Singh ConceptNet a practical commonsense reasoning toolkit BT Technology  22\(4 2004   A D Maedche Ontology Learning for the Semantic Web  Kluwer Academic Publisher 2002   S E Robertson and I Soboroff The TREC 2002 002ltering track report In Text REtrieval Conference  2002   M D Smucker J Allan and B Carterette A Comparison of Statistical Signi\002cance Tests for Information Retrieval Evaluation In Proc of CIKM'07  pages 623ñ632 2007   X Tao Y Li and R Nayak A knowledge retrieval model using ontology mining and user pro\002ling Integrated Computer-Aided Engineering  15\(4 2008   X Tao Y Li N Zhong and R Nayak Ontology mining for personalzied web information gathering In Proc of WI 07  pages 351ñ358 2007   T Tran P Cimiano S Rudolph and R Studer Ontologybased interpretation of keywords for semantic search In Proc of the 6th ICSW  pages 523ñ536 2007   Y Y Yao Y Zeng N Zhong and X Huang Knowedge retrieval KR In Proc of WI 07  pages 729ñ735 2007 
513 
517 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



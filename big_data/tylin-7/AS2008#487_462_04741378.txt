CRMMS 002 An Algorithm of Classification Rule Mining with Multiple Support Demand Chunhua Ju Computer Science Department, Zhejiang Gongshang University Hangzhou, Zhejiang, China Email:juchunhua@hotmail.com  ABSTRACT T 002  The paper presents an algorithm CRMMS of classification rule mining with multi-support demand, which adopts the frequent classification item-set tree FCIST to organize the frequent pattern sets, and builds the array-based threaded transaction forest ATTF, and applies multiple supports for classification rules mining. The CR MMS uses the breath first strategy assisted by the depth first strategy, and adopts pseudo projection, which makes it unnecessary to scan the database and to construct the projected transaction subsets repeatedly The algorithm reduces the memory and time cost, and makes the projection more efficient and scalable. The CRMMS algorithm can be used in the consumerês basket analysis consumption behavior rules mining in the retailing industry  Keyword s frequent pattern, rules mining Classification rule, FCIST, ATTF   1 INTRODUCTION The association rule mining is an important research topic of data mining, especially the multi-support association rule mining. The current researches on classification rules mainly focus on the mining of the unevenly distributed and huge databases  The existing algorithms of classification rules mining support either multi-support thresholds or scalability of store memory. These algorithms mainly adopt the strategies of breadth-first, depth first, or both of them. However the algorithms with breath first strategy lik 2 3 are inefficient for dense datasets that contain long patterns. The algorithms with depth first strategy such 5    and et c, do no t scal e to large sparse datasets and are time-wasting in mining dense datasets. Some algorithms  8 p u tting br eath fir st and dep th fir st strateg ies  together but using single support are not good for mining unevenly-distributed business databases. Although algorithms  adopt multi-support method they ar e not scalable for store space with the limitation of memory  This paper presents a novel algorithm, multi-support algorithm CRMMS, for mining classification rules in business databases which is efficient on dense databases at all levels of support threshold, and scalable to very large databases. Our contributions are as follows: first, we present frequent classification item-set tree for constructing frequent pattern sets, and adopt both breath first and depth first strategies which enhances the build of frequent pattern tree. Second, we propose an array-based format for classification tree for pseudo projection with high efficiency and low memory cost and adopt multi-support thresholds to mine more potential and effective association rules Finally, we design and implement a multi-support algorithm CRMMS of classification rules mining. And with the compare experiments with Apriori FP-Growth and OP, CRMMS has certain advantages in mining efficiency and scalability of the large business databases    2 CONSTRUCTION OF FREQUENT  CLASSIFICATION ITEM-SET TREE  2.1. Problem Descriptions Definition 1 The classification database D=\(O,I,C\in which O is the finite set of da ta objects, I is the set of data attributes and C is the set of classification items  The data attribute set also known as an item set I={i1,i2 001\002 im}, in which ik is called data attribute. The data object set O={\(tid1 002 t1 002»\001\002 tidn 002 tn\which 002 tidk 002 tk 002 presents a data object or a transaction, and tidk is the identifier of the object or transaction, tk is the attribute set of classification objects, and tk 001 I 001 C 000 tk \002C 000 1. The classification item set C={c1 002»\001\002\002 cs}, in which ck stands for a classification item  According to the definition above, the database in table 1 can be described as I ={a,b,c,d,e,f,g,h,j,k,l,m,p,s C={ c1, c2 O={\(01,t1\,\(02,t2 001\002 08,t8\ composed by 8 transactions, in table 1  c 2 b e k s 08 c 2 a d e g f j p 07 c 1 a k l 06 c 2 a e f m p s 05 c 2 b e f m p 04 c 1 a b e j p 03 c 2 a c e f g j l p 02 c 1 a b c d e f h p s 01 Class Items Tid c 2 b e k s 08 c 2 a d e g f j p 07 c 1 a k l 06 c 2 a e f m p s 05 c 2 b e f m p 04 c 1 a b e j p 03 c 2 a c e f g j l p 02 c 1 a b c d e f h p s 01 Class Items Tid Table 1. The classification database Definition 2 Classification\ pattern p I is frequent if support\(p 0011 minsupk, minsupk is the minimum support\(threshold\class ck 003 Definition 3 If support \(X 001 ck} ,T 0011 minsupk , and support \(X 001 ck} ,T\t \(X,T 0011 minconf, X< I ,ck 001\031 C , then X 001\027 ck} is a classification rule   2.2. Frequent Classification Item-set Tree Frequent classification item sets can be represented by a tree namely frequent classification item-set tree, abbreviated as FCIST, and in order to avoid repetitiveness, we impose an ordering on the items  FCIST is an ordered tree, where each node is labeled by an item, and associated with a weight. The ordering of items labeling the nodes along any path \(top down\and the ordering 
International Conference on Cyberworlds 2008 978-0-7695-3381-0/08 $25.00 © 2008 IEEE DOI 10.1109/CW.2008.123 687 


of items labeling children of any node \(left to right\the imposed ordering. Each frequent classification item set is represented by one and only path starting from the root and the weight of the ending node is the support of the item set. The null root corresponds to the empty item set. The weights associated with nodes need not be actually implemented   Each node has its own classification projected transaction set abbreviated as CPTS\at support the item set represented by the path starting from the root to the node. CPTS of the null root is the original database CPTS of any node other than the null root is obtained by projecting transactions in CPTS of its parent node, according to the priori property. One CPTS is filtered if each transaction in the CPTS only maintains items that contribute to the further construction of descendants. In other words, filtered CPTS of a node only contains items that label the sibling of its parent node. Otherwise, the CPTS is unfiltered. Apparently, items in filtered CPTS are local frequent in its parent CPTS  Each FCIST node is represented by[i,w1 001\002  followed b y  its own CPTS, ws is the weight of item i belonged to the classification cs. Let 000 001 be the dictionary order, then the classification database in Table 1 can be represented as Figure 1 with the support thresholds minsup1 002 2 and minsup2 002 3 The pa 000  000 e,2,4 000 a,2 represents the  classification item sets{a,e,p c1} with support of 2 and{a,e,p,c2} with support of 3. The unfiltered CPTS of the root, namely priori classification database has 8 transactions in which transactions 01, 02, 03, 04, 05, 07 support item p and transactions 01 and 03 belong to classification c1 transactions 02, 04, 05 and 07 belong to classification c2. So the CPTS of is com pos ed by such 6 transactions. The CPTS of all the nodes except the root is filtered, only containing the brother nodes ahead c 2 b e k s 08 c 2 a d e g f j p 07 c 1 a k l 06 c 2 a e f m p s 05 c 2 b e f m p 04 c 1 a b e j p 03 c 2 a c e f g j l p 02 c 1 a b c d e f h p s 01 c 2 b e k s 08 c 2 a d e g f j p 07 c 1 a k l 06 c 2 a e f m p s 05 c 2 b e f m p 04 c 1 a b e j p 03 c 2 a c e f g j l p 02 c 1 a b c d e f h p s 01 c 1 a 03 c 1 a 01 c 1 a 03 c 1 a 01  a,3,3  b 2 2   a,2,0 e,2,5 c 2 b 08 c 2 a 07 c 2 a 05 c 2 b 04 c 1 a b 03 c 2 a 02 c 1 a b 01 c 2 b 08 c 2 a 07 c 2 a 05 c 2 b 04 c 1 a b 03 c 2 a 02 c 1 a b 01 a,2,3 c 1 a 03 c 1 a 01 c 1 a 03 c 1 a 01 b,2,2 a,2,0 f,1,4 c 2 a e 07 c 2 a e 05 c 2 b e 04 c 2 a e 02 c 1 a b e 01 c 2 a e 07 c 2 a e 05 c 2 b e 04 c 2 a e 02 c 1 a b e 01 a,1,3  e  1 4 c 2 a 07 c 2 a 05 c 2 a 02 c 1 a 01 c 2 a 07 c 2 a 05 c 2 a 02 c 1 a 01 p,2,4 c 2 a e f 07 c 2 a e f 05 c 2 b e f 04 c 1 a b e 03 c 2 a e f 02 c 1 a b e f 01 c 2 a e f 07 c 2 a e f 05 c 2 b e f 04 c 1 a b e 03 c 2 a e f 02 c 1 a b e f 01 a,2,3 c 1 a 03 c 1 a 01 c 1 a 03 c 1 a 01 b,2,0 a,2 e,2,4 c 2 a 07 c 2 a 05 c 2 b 04 c 1 a b 03 c 2 a 02 c 1 a b 01 c 2 a 07 c 2 a 05 c 2 b 04 c 1 a b 03 c 2 a 02 c 1 a b 01 a,2 c 1 a 03 c 1 a 01 c 1 a 03 c 1 a 01 b,2,0 a,2,0 a,1 f,1 c 2 a e 07 c 2 a e 05 c 2 b e 04 c 2 a e 02 c 1 a b e 01 c 2 a e 07 c 2 a e 05 c 2 b e 04 c 2 a e 02 c 1 a b e 01 a,1,3  e 1 4 c 2 a 07 c 2 a 05 c 2 a 02 c 1 a 01 c 2 a 07 c 2 a 05 c 2 a 02 c 1 a 01 a,1,3 Figure.1 The FCIST in the example   2.3. Representing CPTS by ATTF and Pseudo-projecting  An array-based threaded transaction forest, ATTF, is adopted to represent CPTS because of its low memory spending. And two different pseudo-projecting methods are used to construct the FCIST. ATTF consists of two parts: an item list \(IL\, and a forest. Each local item in CPTS has an entry in the IL, with three fields: an item-id, multiple supports, and a pointer namely e.item, e.conut and e.link respectively. And the multiple supports e.count can be divided into ||C|| different parts, called e.count \(k\ representing the support in classification ck. Entries in IL are ordered by the imposed ordering. Each transaction in the CPTS is represented by one and only one path in the forest. Each node in the forest is labeled by an array [i,w1 001\002   where i is an item and wk  is a count that is the number of transactions in classification ck represented by the path starting from the root ending at the node. Items labeling nodes along any path are sorted by the same ordering as IL. All nodes labeled by the same item are threaded by the entry in IL with the same item. ATTF is filtered if only local frequent items appear in ATTF, otherwise unfiltered  For example, the filtered ATTF representation for the CPTS of the null root in Figure 1 is shown in Figure 2, where the path  b,2 0 e,2,0 p,2,0 repr esents tr ansactio n 01 and 03   e,0 2 f,0,1 p,0,1  r e pr esents transactio n 04, and  so on. The third item in FIL is item e, with multi supports 2 and 5 in classifications c1 and c2 respectively. The pointer arrow-headed broken line\s the nodes [e,2 e,0,3 and  tog ether   From the ATTF representation of the CPTS of a parent node in FCIST, we can project its childrenês ATTFs either in a bottom up way or in a top down way. The FCIST in Figure 1 is constructed in a top down projecting way, so we will introduce this way in the paper  In the top down way, the pseudo ATTF of a child CPTS consists of sub forest whose leav es are threaded together in its parent ATTF. Firstly, we choose the IL items one by one from the parent ATTF in the imposed ordering. Secondly, by traversing the sub forest threaded by the chosen IL, we can delimitate the CPTS by re-threading nodes in the sub forest count the support of each item in the sub forest by re-calculating the count of each node according to the leaves multi supports. For example, in Figure 3, the sub forest whose leaves, [f,0 a nd [f,0,1 are th readed b y  the e n tr y of it em f compresses transactions that support item f. By traversing this sub forest, we get local multi supports of item a, b and e of  0,1 and 0 4 respectiv el y, and the count of first node label by a is changed from [3,3 to [0,3 and n ode [b,0 2 is adjusted into node [e,0,2  into [e,0,1  Therefore the sub forest of the pseudo ATTF consists of two paths  e,0,3 and [b,0 1 e,0,1  The IL is {\([a,0 ptr  ptr  e,0,4 ptr is a r ecursion pro cess e.g  the child ATTF of the node [e,0 in Figure 3can be pseudo  projected as shown in Figure 4    
688 


   Such method of pseudo projection avoids recursively building projected transaction set, which is in the same number as frequent item sets. This method is not only space efficient in that no additional space is needed for any child ATTF, but the counting and projecting operation is also highly CPU-efficient Especially we adopt different supports for classification items which makes the FCIST construction more efficient   3 ALGORITHM CRMMS  Now we present the multi-support algorithm of classification rules mining, abbreviated as CRMMS, which integrates depth first and breadth first strategies, array-based threaded tree forest representation and filtered projection. First, CRMMS creates a null node for the root of the FCIST, whose CPTS is the priori classification database. Second, CRMMS calls BreadthFirst to grow the upper portion of FCIST by breadth first search until the reduced set of transactions can be held in a memory based structure. Third, DepthFirst is called to build the lower portion of FCIST by depth first search MSC 002 O 000 Minsup 002 create FCIST root R and let R.PTS=O BreadthFirst R,L 000  001 Minsup DepthFirst T 000  001 Minsup   BreadthFirst attaches counting vectors to all nodes at the current level L to accumulate local supports for items in the CPTS of each node. The counting vector has an element for the item of each sibling node that is before the node attached according to the imposed ordering 000 We project the transaction t along the path from the root to nodes at the current level L and accumulate counting vectors. If a transaction can be projected to a level L node and contribute to its counting vector, it may also be projected to level L+1 therefore record it in Dê. Otherwise it can be removed from further consideration. Then we create children for each node at the current level L for its local frequent items whose element in the counting vector has a value over the multi-support thresholds. The BreadthFisrt is a recursive procedure. We use the available free memory as parameter to control breadth first search process BreadthFirst\(R,L 001 000  001 Minsup,D for each node v at level L top down by 000 001 do CreateCountingVector\(v D for each transaction t in D do ProjectAndCount\(t,L,D for each node v at level L do GenerateChildren\(v If\(NoMem\(Dí\n BreadthFirst\(T,L+1 000  001 Minsup else return\(D   If bread first projecting ends at level L, then DepthFirst is called to build the sub trees with roots of the leaves in level L DepthFirst v 000  001 Minsup for each node e in v.PTS.IL top down by 000 001 do if e.count\(k 0011 minsupk for some class ck in C then create a child node d for v d.item= e.item d.weight\(k\= e.cuont\(k PseudoProj\(v,d 001 000  DepthFirst d 001 000  001 Minsup   In DepthFirst, first, the IL item s are chosen by the imposed ordering; second, if the classification items of the IL item are frequent then creates the corresponding children nodes; third calls the PseudoProj process. The PseudoProj process will adjust the weights and re-threading the sub trees to guarantee the children CPTS be contained in the parent CPTS   4 PERFORMANCE EVALUATIONS  To evaluate the efficiency and effectiveness of our algorithm CRMMS, we have done experiments on the dataset Forest from UCI machine learning data warehousing by comparing with Apriori and FP-Growth on a 286MHz Pentium III PC with 512 MB main memory and 30 GB hard drive, running on Windows 2000 Professional  The empirical results indicate that CRMMS is one to three orders of magnitude more efficient than Apriori and FP-Growth. For example, in Figure 5, when the support thresholds are lower than 0.1%, CRMMS is 2 to 12 more efficient than Apriori and 1.5 to 8 than FP-Growth. At the reasonable low support threshold of 0.05%, CRMMS requires 16 seconds, whereas FP-Growth requires 31 seconds and Apriori requires 65 seconds. At the even lower support threshold of 0.02 %, CRMMS requires 20, while FP-Growth  requires 72 seconds and Apriori requires 155 seconds. The rankings of algorithms are CRMMS 002 FP-Growth 002 Apriori  Figure 5. Performance comparison of frequent item set mining  10 100 1000 0.010.020.030.040.05  0.06  0.08  0.1  threshold   5 CONCLUSIONS AND FUTURE WORK The paper introduced a multi-support algorithm CRMMS of classification rules mining, which adopts array-based threaded transaction forest method and pseudo projection to highly improve the efficiency of classification rules mining. The future work will be focus on th e association rules mining in the busin     6 REFERENCES  R Agrawal, R Srikant Fast algorithms for mining association rulesé, The 1994 VLDB, Santiago, Chile 1994, pp. 487-499  S Brin R Motw ani J Ullman et al, çD y n amic item set counting and implication rules for market basket analysisé, The 1997 ACMSIGMOD, Tucson , AZ , May 1997, pp. 255-264  Lu Jie, Zhan g Zhijing, çAn Improved Apriori Algorithm for Mining Association Rules Microelectronics & Computer, Beijing, China, volume 23, No.2, 2006, pp. 10-12  J Han, J Pei Y Yin, çMinin g fr equent patt erns without candidate generationé, The 2000 ACM2SIGMOD Dallas, TX, 2000, pp. 1-12 000&\0005\0000\0000\0006  000$\000S\000U\000L\000R\000U\000L  time s 000\\000\020\000*\000U\000R\000Z\000W\000K 
689 


 Song Yuqing Zhu Yuquan S un Zhihu i, Chen Geng An algorithm and its updating algorithm based on FP-Tree for mining maxi mum frequent itemsets Journal of Software, China, volume 14, No.9, 2003 pp.1586-1592  J. Pei, J. Han  H  Lu S. Nishio S. Tang  and D Yang H-Mine:Hyper-Structure Mining of Frequent Patterns in Large Databasesé, Proc. 2001 Int. Conf. on Data Mining ICDM'01\. 2001, pp.441-448   Liu JQ, Pan YH, Wang K, Han J. Mining frequent item sets by opportunistic projection. In: Hand D, et al, eds Proc. of the 8th ACM SIGKDD Intêl. Conf. on Knowledge Discovery and Data Mining. Alberta: ACM Press, 2002, pp.229-238   Liu Junqiang, P a n Yunhe, çAn efficient algorithm for mining closed itemsetsé, Journal of Zhejiang University Science, Zhejiang, China, Jan 2004, pp. 8-15  Liu Junqian g Sun Xiao y i ng, Wang Xun Pseudo projection algorithm for mining of classification rules Computer application & Software, China, Sept 2003, pp 8-10  Geoff Hulten, Laurie Spen cer, Pendro Domingos Mining time-changing data streamsé, In Proc.ACM Int.Conf. on Knowledge Discovery and  San Francisco, California, 2001,pp.71-80 
690 


In this paper, the test samples are composed of 15 large hail examples in all 699 images, 17 slight hail examples in all 459 images and 12 rainstorm examples in all 594 images, which are offered by weather bureau of a city. The result obtained by Association Rules is shown in Table.3            As shown in Table.3, 1 monomer and 2 monomers were alert failure respectively in hail examples Because hail melted when falling and can not sense on the ground, 3 monomers in 459 images wonít cause disaster The results show that hail echo ensemble forecast model based on association rules has higher accuracy compared with the PUP products. And the hail cloud detection based on association rules satisfies practical applications. It supports forecasters to make more accurate forecasts   6. Conclusion  1\ A novel method of image mining is proposed in the hail detection model. And a system that is concerned on the automatic hail echo detection based on mining rules was built. This system is applied to distinguish hail cloud to rainstorm cloud and super-refraction effectively  2\ The accuracy of the hail cloud detection is obviously higher by classifying the production rules than that by the PUP products  3\ The system can help forecasters to make accurate forecasts Theoretical analysis and experiment results show that the automatic hail echo detection based on mining rules is effective. This method is a whole new route and made great contribution for the automatic hailstone detection. This research of this paper is a challenging and developing work, and is worth in-depth studies in the future  References   u rl  M  C e t  a l   M i n i n g f o r Im a g e Co n t e n t    Systemics, Cybernetics and Informatics  Information Systems  Analysis and Synthesis \(SCI-ISAS99  Orlando, FL  Jul.1999  2 J i a w ei H a n  an d M i c h el in e K a m b er   Data Mining  Concepts and Techniques Morgan Kaufmann Publishers, Beijing , 2000   u j i n Z h a n g  Image Engineering Tsinghu University Press, Beijing, 2002    u j i n Z h a n g   Content-based Visual Information Retrieval Science Press, Beijing, 2003   5 Y a n  C a i an d D e s h an g F u  C la s s i f i ca t i o n o f B a s e d  on Satellite Data and Its Program Design Journal of Nanjing Institute of Meteorology Sept.1999, Vol.22 No.3, pp. 416-422   u l o n g H a o  B a oy i C h e ng Y i n F a n  a n d H o n g j un Zhang, ìAuto-recognition of Typhoon Based on the Character of Layout of Texture Direction Journal of Image and Graphics Dec. 2002, Vol.7, No.12,pp 1319-1322   a n q i n g  T i a n  P i ng G u o  a n d P i ngqi ng L u   T e x t u r e  Feature Extraction of Multiband Remote Sensing Image Based on Gray Level Co-occurrence Matrix Computer Science 2004, Vol.31, No.12, pp. 162-163   8 P i n g Y u e X i a o y u n Li u  Li an g cai G u o an d  Changhong Lv, ìIdentification Geosynchronous Satellite Infrared Image and Detection Violent Convective Weather System in Flood Season by Textural Analysis Technique Arid Meteorology Jul 2005, Vol.23, No. 2, pp. 50-53     Rafael C. Gonzalez and Richard E. Woods   Digital Image Processing   Prentice Hall, 1993  10 P et er S t an c h ev  U s i n g I m a g e M i n i n g F o r I m ag e Retrieval IASTED Conf. Computer Science and Technolog Mexico, May 19-21, 2003, pp.214-218  11 O  R  Zai a n e an d J  WH an F in d i n g S p at ia l Associations in Images Proceeding of SPIE 14th Int Symposium Orlando, FL, 2000, pp. 138-147     D a t c u a nd K  S e i de l   I m a ge I n f o r m a t i o n Mining: Exploration of Image Content in Large Archives IEEE Conference on Aerospace 2000  Vol.3, pp.255-259  Tabl e 3   Results of different forecast models  699 images \(large hail examples 459 images \(slight hail  examples 74 images \(rainstorm  examples  Alert failure monomer false alarm monomer Alert failure monomer false alarm monomer Alert failure false alarm monomer Association Rules 1 455 3 108 0 1479 PUP production 2 1436 3 376 0 6123 Note: The hail and storm example with the same monomers 
43 


 Very few ows are high throughput Most ows are short lived Almost all ows are mice  Most ows have an average packet size medium Most ows are packet mice Almost all bulk ows are medium throughput Almost all bulk TCP ows are short-lived  Fig 5 Simple on-line linguistic summary of the CRAWDAD-Fall03 NetFlow collection truth values between brackets of rules to analyze In particular we disregarded those rules with a low support or with a low condence truth value Many interesting rules were found for the NetFlow records analyzed We list as examples a selection of them  Most DNS request ows occur both during the day and at night are mice and short lived with condence 0.970 in the WIDE-F-1-Aug collection  Most ows at night are mice with condence 0.890 and Most ows during the day are mice with condence 0.998 in the CAIDA-OC48-0-Apr collection  Most SSH trafc occurs during the day and consists of short lived mice ows with condence 0.892 in the CRAWDAD-Fall03 collection Linguistic summaries provide a novel method to describe qualitative relations in NetFlow collections using natural language Thus by using association rules mining to nd relevant summaries we have a suitable method for addressing a problem related to ow analysis nding invariants in trafc what is known as one the major goals of Internet Science VI C ONCLUSIONS We have addressed network trafc analysis at the ow level from the perspective of linguistic summaries Two approaches for summarizing NetFlow collections have been developed 1 on-line summarization via a predened and congurable set of potential interesting protoforms and 2 discovery of hidden relevant summaries by means of association rules mining A tool that implements both approaches has been developed Experimental results for a set of benchmark NetFlow collections conrm linguistic summaries as an alternative look into network ow statistics useful for both network users and practitioners The method presented is a novel technique to generate simple and human-interpretable reports but also provides a promising technique for nding invariants in network trafc and advancing Internet Science This can be seen as a rst step towards natural language based knowledge discovery for Internet Science A CKNOWLEDGEMENT We acknowledge the MAWI Working Group from the Wide Integrated Distributed Environment WIDE project for k indly p ro viding their  o w collections and support We are also indebted to the Cooperative Association for Internet Data Analysis CAIDA for providing their OC48 data collection  Support f or CAID A  s O C48 Traces Dataset is provided by the National Science Foundation the US Department of Homeland Security DARPA Digital Envoy and CAIDA Members We used the Dartmouth/campus data set from t he Community Resource for Archiving Wireless Data CRAWDAD Our work has beneted from the use of measurement data collected on the Abilene network as part of the Abilene Observatory Project http://abilene.internet2.edu/observatory R EFERENCES  C ooperati v e Association f or Internet D ata Analysis CAID A V i sualization Tools http://www.caida.org/tools/visualization  J  S ommers P  B arford a nd W  W illinger  SPLA T  A V i sualization Tool for Mining Internet Measurements in 7 t h Passive and Ac t ive Ne t work Measuremen t Workshop  Mar 2006 pp 31ñ40  C  E stan S  S a v age and G  V ar guese  Automatically Inferring P a tterns of Resource Consumption in Network Trafc in SI G C OMM 200 3  Karlsruhe Germany Aug 2003 pp 137ñ148  R  R  Y ager   A N e w Approach to the S ummarization o f D ata  I n f orma t ion S ciences  vol 28 pp 69ñ86 1982   Database D isco v e ry Using F uzzy Sets  I n t erna t ional Journal o fI n t elligen tSy s t ems  vol 11 1996  J  K acprzyk and R  R  Y ager   Linguistic Summaries of Data Using Fuzzy Logic I n t erna t ional Journal o f General Sy s t ems  vol 30 no 2 pp 133ñ1504 Jan 2001  J  K acprzyk and S  Z adro  zny Linguistic database summaries and their protoforms Towards natural language based knowledge discovery tools I n f orma t ion S ciences  vol 173 no 4 Mar 2005   Cisco I OS NetFlo w  h ttp://www cisco.com/en/US/products/ps6601 products ios protocol group home.html Nov 2007  B  C laise e t al  Specication of the IPFIX Protocol for the Exchange of IP Trafc Flow Information Internet Engineering Task Force IPFIX Working Group Revision 26 Sep 2007 Internet Draft  S Shaluno v a nd B T eitelbaum TCP Use a nd Performance on Internet2 in A C M SI G C OMM I n t erne t Measuremen t Workshop San Francisco USA 2001  L A Zadeh A Computational A pproach to Fuzzy Quantiers i n Natural Languages C ompu t ers and Ma t hema t ics wi t h Applica t ions  vol 9 pp 149ñ184 1983  R R Y a ger   O n O rdered W eighted A v eraging O perators in Multicriteria Decision Making IEEE Transac t ions on Sy s t ems Man and Cy berne t ics  vol 18 pp 183ñ190  1988  L A Zadeh  A P rototype-Centered Approach to Adding Deduction Capability to Search Engines-the Concept of Protoform in F irs t I n t erna t ional IEEE Sy mposium on I n t elligen tSy s t ems vol.1,Sep 2002 pp 2ñ3   The concept o f a linguistic v a riable and its application t o approximate reasoning I n f orma t ion S ciences  vol 8 no 3 pp 199 249 1975  A Broido Y  Hyun R Gao and k c claf fy   Their Share Di v e rsity and Disparity in IP Trafc in 5 t h Passive and Ac t ive Measuremen t Workshop  PAM   Antibes Juan-Les-Pins France 2004 pp 113ñ125  M Delgado N Mar  n D S  anchez and M.-A Vila Fuzzy Association Rules General Model and Applications IEEE Transac t ions on F u zzy Sy s t ems  vol 11 no 2 pp 214ñ225 Apr 2003  J Kacprzyk and S  Zadro  zny Linguistic Summarization of Data Sets Using Association Rules in IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ IEEE  St Louis USA May 2003 pp 702  707  R Agra w al H Mannila R Srikant H T o i v onen and A  V erkamo Advances in Knowledge Discover y and Da t a Mining  American Association for Articial Intelligence 1996 Fast Discovery of Association Rules pp 307ñ328  M Fullmer e t al  ow-tools http://www.splintered.net/sw/owtools Nov 2007  W i dely Inte grated Distrib u ted En vironment  WIDE P roject MAWI Working Group Packet traces from wide backbone http://tracer.csl.sony.co.jp/mawi 2006  CAID A O C48 T race Project CAID A OC48 T r aces 200304-24 collection http://imdc.datcat.org/collection/1-0018N=CAIDA+OC48+Traces  D K o tz T  Henderson and I  A byzo v   CRA WD AD data set dartmouth/campus v 2007-02-08 Downloaded from http://crawdad.cs.dartmouth.edu/dartmouth/campus Feb 2007 624 2008 IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ 2008 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as ìfor manyî, ìthere are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logicî, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e compositionî, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



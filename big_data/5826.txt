Colon cancer survival prediction using ensemble data mining on SEER data  Reda Al-Bahrani, Ankit Agrawal, Alok Choudhary Dept. of Electrical Engg. and Computer Science Northwestern University Evanston, IL 60208, US rav650,ankitag,choudhar}@eecs.northwestern.edu   Abstract We analyze the colon cancer data available from the SEER program with the aim of developing accurate survival prediction models for colon cancer Carefully designed preprocessing steps resulted in removal of several attributes and applying several supervised classification methods. We also adopt synthetic minority over-sampling technique \(SMOTE the survival and non-survival classes we have. In our experiments, ensemble voting of the three of the top performing classifiers was found to result in the best prediction performance in terms of prediction accuracy and area under the ROC curve. We evaluated multiple classification schemes to estimate the risk of mortality after 1 year, 2 years and 5 years of diagnosis, on a subset of 65 attributes after the data clean up process, 13 attribute carefully selected using attribute selection techniques, and SMOTE balanced set of the same 13 attributes, while trying to retain the predictive power of the original set of attributes. Moreover, we demonstrate the importance of balancing the classes of the data set to yield better results  Keywords—Prediction, Ensemble, Colon Cancer Machine Learning I  I NTRODUCTION  Cancers of the colon and rectum are of two of the most common types worldwid e. Early diagnosis and treatment can greatly improve the chances of survivability [1 The Surveillance, Epidemiology, and End Results SEER ier source of domestic statistics of cancer. The collected data from SEER represents 28% percent of the US population across several geographic regions. This data is available from the SEER website upon submitting a SEER limited-use data agreement form In this paper we analyze the colon cancer data available from the SEER program with the aim of developing accurate survival prediction models for colon cancer. The data analyzed in this study is from the surveillance, epidemiology and end results \(SEER Colon and Rectum cancer incidence data in the years of 1973-2009. The SEER Colon and Rectum cancer incidence data consist of four datasets named yr1973_2009.seer9, yr 2000_2009.ca_ky_lo_nj_ga yr2005.lo_2nd_half, and yr1992_2009 sj_la_rg_ak. The follow-up cutoff date of the datasets is December 31 2009 [2 Here we use supervised classification methods to predict survival of colon cancer patients, at the end of 1 year, 2 years and 5 years of diagnosis. We carried experiments with several classifiers to find that many meta classifiers used with decision trees and functions can give better results compared to basic classifiers These results can be improved by adopting SMOTE to balance the survival and non-survival classes, and by combining the resulting prediction probabilities from several classifiers using an ensemble-voting scheme The rest of the paper is organized as follows: Section 2 summarizes related work, followed by a brief description of the prediction system used in this study in Section 3. A description of the data used in this work is described in Section 4. In Section 5 a list of the classification schemes used in the study is presented along side with a brief desc ription. Experiments and results are presented in Section 6, followed by the conclusion and future work in Section 7 II  B ACKGROUND  With SEER data being publicly available, there is a mature literature on SEER data studies. SEER provides SEER*Stat a statistical software which provides convenience to analyze the data In addition, there have been data mining applications developed for various types of cancer based on SEER data. A number of techniques based on data mining have been proposed for the survivability analysis of various  and artificial neural networks for survivability analysis  neural networks, decision trees and, logistic regression for predicting breast cancer survivability. Comparisons  year survivability of breast cancer diagnosed patients They compared seven methods: artificial neural 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 9 


 network, naïve bayes, bayes network, decision trees with J48  SEER data to study survival patterns in of lung cancer  survivability of lung cancer for patients diagnosed between the years of 1988 and 2001 Studies were also conducted on colorectal cancer  prediction rates in relation to the number of hidden neurons in the Artificial Neural Networks \(ANN  they utilize a data analytics suite named FasterAnalytics to build a machine-learned Bayesian Belief Network \(ml-BBN model for clinical decision support \(CDS\ang et al  cer survival based on stage age, gender, and race. Data mining applications and studies of colorectal cancer are not covered as much as breast or lung cancers III  P REDICTION S YSTEM  The most important step of the process is to understand and clean the data. Our system consists of several stages. These stages consist of: SEER-related preprocessing, Problem specific preprocessing Predictive modeling and Evaluation, as depicted in Figure 1 1  SEER-related preprocessing The data provided by SEER is in raw format. A script was developed to convert the data into csv form at. Also, in this stage the following conversions/calculations were performed on the datasets to format the ra w data to appropriate values  a  Convert apparently numeric attributes to nominal, e.g., marital status, sex b  Convert Size of Tumor to cm from SEER’s coding. E.g. code 100 is equivalent to 10.0 cm c  Calculate the survival time in months numeric 2  Problem-specific preprocessing In this stage the following filters were applied and class attributes were derived  a  Filter data records for the period of interest Period of  b  Filter data records that are related to the cancer in study. Primary Site [C  c  Filter all attributes that may indicate that vital status of the patient d  Derive appropriate binary attributes for survival, e.g., 5-year survival e  Remove attributes that do not vary at all or that vary too much. Const ant attributes are removed and attributes that exce ed a maximum variance threshold e.g. 99 3  Predictive modeling This is where supervised classification methods ar e employed to construct predictive models for cancerspecific survival, on the preprocessed data. The two st raightforward steps of this stage are  a  Split the data into training and testing sets or use cross-validation b  Conducting experiments using the different classification schemes 4  Evaluation In this stage the models were compared with respect to different metrics from the predictive modeling stage. These metrics include  a  Percent of correct classified instances b  Area Under the Receiver Operating Characteristic \(ROC Curve IV  D ATA C LEANUP  The data used in these experiments is from the period 1998 to 2003. Since the follow-up cutoff date of the datasets is December 31, 2009 and a large number of the attributes are applicable for records of years 2004 we considered data until December 31, 2003. This decision was made to conduct the study for 5-year survivability. Also, to minimize the number of missing data due to the applicability of the attribute we have, our datasets start from January 1, 1998 Since SEER data of colon and rectum cancers are represented together we had to filter the data to include only colon cancer cases. Any instances with cause of death not related to colon cancer were removed After finishing the cleanup process we had a total of 65 attributes plus the class The class can be 1 year, 2 years, or 5 years survivability. The data from SEER consisted of 788,892 records it was truncated to 105,133 records after selecting the period and type of cancer Table 1 shows the class distribution of the data used in our experiments Fig. 1.   Prediction System Flow 10 


 TABLE I  C LASS D ISTRIBUTION  Table Head Survival Classes 1 Year 2 Years 5 Years Not Survived 21.44 30.44 42.06 Survived 78.56 69.56 57.94  We took the resulting set of attributes and performed attribute selection using Correlation Feature Selection CFS attributes from the 65 attri butes. In figure 2 we plot relative information gain for each of these 13 attributes The information is presented side by side for the three periods of interest along with the average As a result of this data clean up process we have two sets of attributes to evaluate. The first model includes all the available attributes after filtering the data and removing the useless attri butes to our study, which consisted of 65 attributes. The second model consists of 13 attributes, which we obt ained after running feature selection methods on the 65 attributes. The last model consists of 13 attributes, which we obtained after running SMOTE to balance the two class instances of survived and non-survived patients and then selecting the same 13 attributes in the second model The following subsections provide information about the SMOTE pre-processing step, and definitions for the 13 selected attributes fr om the SEER Dictionary obtained with the data A  Synthetic Minority Over-sampling Technique SMOTE As presented in table 1 the data we have is imbalanced. SMOT to balance the different classes in the data.  The data set was balanced by using the SMOTE filter in Weka. The minority class in the 1 year, 2 years, and 5 years sets were oversampled by 266%, 128%, and 38% respectively. The SMOTE algorithm generates synthetic examples by oversampling the minority class and introducing new synthetic patient records B  Selected Attributes 1  EOD-Extension Documented extension of tumor away from the primary site  2  SEER modified AJCC Stage 3rd ed \(1988-2003 The modified version stages cases that would be unstaged under strict AJCC staging rules  3  Birth Place Place of birth encoded  4  EOD-Lymph Node Involv Recode for highest specific lymph node chain that is involved by the tumor  5  Regional Nodes Positive Records the exact number of regional lymph nodes examined  6  RX Summ-Surg Prim Site Describes a surgical procedure that removes and/or destroys tissue of the primary site performed as part of the initial work-up or first course of therapy 7  Histologic Type ICD-O-3 Describes the microscopic composition of cells and/or tissue for a specific primary  8  Reason for no surgery Documents the reason that surgery was not performed on the primary site  9  Age at diagnosis Represents the age of the Fig. 2.   Relative Information Gain for the set of 13 attributes 11 


patient at diagnosis for this cancer  10  Diagnostic Confirmation Records the best method used to confirm the presence of the cancer being reported. The data item is not limited to the confirmation at the time of diagnosis; it is the best method of confirmation during the entire course of the disease  11  EOD-Tumor Size Records the largest dimension of the primary tumor in millimeters  12  Behavior \(92-00 Behavior codes of the cancer  13  Primary Site Identifies the site in which the primary tumor originated V  C LASSIFICATION S CHEMES  The classification schemes used in our experiments are of two types: basic classi fiers, and meta classifiers The basic classifiers consist of trees, functions, and statistical methods. The meta classifiers are used to boost these basic classifiers and improve their performance. This section describes the classifiers used in our experiments A  Basic Classifiers 1  J48 decision tree J48 \(or C4.5 based classifier. While constructing the decision tree the J48 algorithm u st be used to split the tree further based on the notion of information gain/gini impurity  2  Reduced error-pruning tree Commonly known as REPT plem entation of a fast decision tree learner, which builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning  3  Random Forest The Random classifier consists of multiple decision trees. The final class of an instance in a Random Forest is assigned by outputting the class that is the mode of the outputs of individual trees, which can produce robust and accurate classification, and ability to handle a very large number of input variables  4  Alternating decision tree ADTree [1 i s  decision tree classifier, wh ich supports only binary classification. It consists of two types of nodes decision and prediction  5  Logistic Regression  used for prediction of the probability of occurrence of an event by fitting data to a sigmoidal S-shaped logistic curve. Logistic regression is often used with ridge estimators to improve the parameter estimates and to reduce the error made by further predictions  B  Meta Classifiers 1  Bagging  improve the stability of classification and regression algorithms by reducing variance  2  AdaBoost  ensembling technique for boosting a nominal class classifier. In general, boosting can be used to significantly reduce the error of any weak learning algorithms  3  Random SubSpace The Random Subspace  decision tree based classifier consisting of multiple trees, which are constructed systematically by pseudo-randomly selecting subsets of features, trying to achieve a balance between overfitting and achieving maximum accuracy  4  Voting Voting is a popular ensemble technique for combining multiple classifiers. It has been shown that ensemble classifiers using voting may outperform the individual classifiers in certain cases [20 VI  E XPERIMENTS AND R ESULTS  In our experiments, we used the WEKA toolkit for  evaluation. Cross-validation is used to evaluate the prediction performance of data mining models to avoid over-fitting. In k-fold cross-validation, the input data is divided into k random segments. k 1 segments are used to build the model and the remaining segments are used to evaluate the model. In 10-fold cross-validation this process is repeated 10 times and the final validation result is the average of the 10 repetitions. We used prediction accuracy and area under the ROC curve to evaluate the models in our experiments. The area under the ROC curve is recommended as a performance metric to evaluate different machine learning algorithms [22  A total of 20 classification schemes were used. 5 basic classifiers, and a co mbination of the 3 meta classifiers with the 5 basic classifiers as an underlying classifier. We also performe d ensemble voting of 3 of the performing classification schemes Each of these 20 classification schemes was evaluated for 1 year, 2 years and 5 years. Figures 3 , 5 and 6 show the percentage accuracy for the classifiers that finished execution plus ensemble voting for 3 of the top classifiers on the datase t of 13 attributes obtained after SMOTE class blanacing Figures 4, 6, and 8 respectively show the corresponding area under the ROC curve for results of 1 year, 2 years, and 5 years survivability. As described ear lier, the original dataset consisted of 134 attributes that was reduced to 65 attributes by removing useless attributes related to the period and cancer related our study. Further attribute selection using CFS and Information Gain yielded a subset of 13 features. Moreover, another dataset of 13 12 


  features has been generated using SMOTE balancing of survived and non-survived classes As evident from the figures, there are many classification schemes that perform well. After combining the top 3 perfor ming classification schemes on the SMOTE balanced dataset and using ensemble voting to combine their predictive powers we noticed that ensemble voting shows the best results in our study The ensemble voting model has predictive percentage accuracy of 90.38%, 88.01%, and 85.13% for 1 year, 2 years, and 5 years respectively and an AUC of 0.96 0.95, and 0.92 for 1 year, 2 years, and 5 years respectively Fig. 4.   1 year survivability area under the curve \(AUC ison of 65 attributes, 13 attributes and 13 attributes after SM OTE class balancing Fig. 3.  1 year survivability percentage accuracy comparison of 65 attributes, 13 attributes and 13 attributes after SMOTE clas s balancing 13 


VII  C ONCLUSION AND F UTURE W ORK  In this paper, we used different basic and meta classification schemes to construct models for survival prediction for colon cancer patients. Prediction accuracies of 90.38%, 88.01 and 85.13%and an AUC of 0.96, 0.95, and 0.92 were obtained for the 1-year, 2year and 5-year colon cancer survival prediction using the ensemble voting classification scheme. We have identified 13 attributes that have approximated the predictive power of 65 attributes. We also demonstrate how balancing the classes in the dataset yields better results if the imbalance is big Future work includes exploring more techniques to deal with imbalanced data. Also, we plan to build a colon cancer outcome calculator. An outcome calculator can accurately estimate survivability of a colon cancer patient. Moreover, it can aid doctors in decision-making and provide a better understanding of the risks involved in a particular treatment procedure, based on patientspecific attributes. Further more we also plan to do similar analysis for other cancers VIII  A CKNOWLEDGMENTS  This work is supported in part by the following grants: NSF awards CCF-0833131, CNS-0830927, IIS0905205, CCF-0938000, CCF-1029166, and OCI1144061; DOE awards DE-FG02-08ER25848, DESC0001283, DE-SC0005309, DESC0005340, and DESC0007456; AFOSR awar d FA9550-12-1-0458 R EFERENCES  1  Parkin DM, Whelan SL, Ferlay J, Teppo L, Thomas DB. Cancer incidence in five continents. Lyon: International Agency for Research on Cancer. Vol. VIII. IARC Scient. Publ. No. 155 2002 2  Surveillance, Epidemiology, and End Results \(SEER 1973-2009 Cancer Institute, DCCPS, Surveillance Research Program Surveillance Systems Branch, released April 2012, based on the November 2011 submission 3  Z.H. Zhou and Y. Jiang, Medical diagnosis with c4.5 rule preceded by artificial neural network ensemble, IEEE Transactions on Information Technology in Biomedicine 7\(1 2003 4  D. Delen, G. Walker and A. Kadam, Predicting breast cancer survivability: a comparison of three data mining methods 2005 5  A. Endo, T. Shibata and H. Tanaka, Comparison of seven algorithms to predict breast cancer survival, Biomedical Soft Computing and Human Sciences 13\(2 2008 6  D. Chen, K. Xing, D. Henson, L Sheng, A. Schwartz and X Cheng, Developing prognostic systems of cancer patients by ensemble clustering Journal of Biomedicine and Biotech nology 2009 2009 7  D. Fradkin, Machine learning methods in the analysis of lung cancer survival data, DIMACS Technical Report 2005-35 February 2006 8  Fathy, Sherif Kassem. "A predication survival model for colorectal cancer." In Proceedings of the 2011 American conference on applied mathematics and the 5th WSEAS international conference on Computer engineering and applications, pp. 36-42. World Scientific and Engineering Academy and Society \(WSEAS 9  Stojadinovic, Alexander, John S. Eberhardt, Elizabeth Ben Ward, Aviram Nissan, Eric K. Johnson, Mladjan Protic, George E. Peoples, Itzhak Avital, and Scott R. Steele. "Clinical Decision Support and Individualized Prediction of Survival in Colon Cancer: Bayesian Belief Network Model." Annals of surgical oncology 20, no. 1 \(2013 10  Wang, Samuel J., Clifton D. Fuller, Rachel Emery, and Charles R. Thomas Jr. "Conditional survival in rectal cancer: a SEER database analysis." Gastrointestinal cancer research: GCR 1, no 3 \(2007 11  M. Hall, Correlation-based feature selection for machine learning, PhD thesis, Citeseer, 1999 12  Chawla, Nitesh V., Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. "SMOTE: synthetic minority oversampling technique arXiv preprint arXiv:1106.1813 2011 13  J. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993 14  I. Witten and E. Frank, Data Mining: Practical Machine Learning Tools and Techniques, Morgan Kaufmann, San Fran cisco, CA, 2005 15  L. Breiman. Bagging predictors Machine Learning, 24\(2 140, 1996 16  Y. Freund and L. Mason, The alternating decision tree learning algorithm, in: Proceeding of the 16th International Conference on Machine Learning, Morgan Kaufmann, Citeseer, 1999, pp 124–133 17  J. Friedman, T. Hastie and R. Tibshirani, Special invited paper Additive logistic regression: a statistical view of boosting Annals of Statistics 28\(2 2000 18  Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. 1996 19  T. Ho, The random subspace method for constructing decision forests, IEEE Transactions on Pattern Analysis and Machine Intelligence 20\(8 1998 20  J. Kittler, Combining classifiers: a theoretical framework Pattern Analysis and Applications 1\(1 1998 21  M. Hall, E. Frank, G. Holmes B. Pfahringer, P. Reutemann and I.H. Witten, The weka data mining software: an update SIGKDD Explorations 11\(1 2009 22  Bradley, Andrew P. "The use of the area under the ROC curve in the evaluation of machine learning algorithms." Pattern recognition 30, no. 7 \(1997 14 


  Fig. 6.   2 years survivability area under the curve \(AUC ison of 65 attributes, 13 attributes and 13 attributes after S MOTE class balancing Fig. 5.  2 years survivability percentage accuracy comparison of 65 attributes, 13 attributes and 13 attributes after SMOTE clas s balancing 15 


   Fig. 8.   5 years survivability area under the curve \(AUC ison of 65 attributes, 13 attributes and 13 attributes after S MOTE class balancing Fig. 7.  5 years survivability percentage accuracy comparison of 65 attributes, 13 attributes and 13 attributes after SMOTE cla ss balancing 16 


overhead of job initialization in Hadoop is much larger than cNeural VIII C ONCLUSION AND F UTURE W ORK The past several years have witnessed an ever-increasing growth speed of data To address large scale neural network training problems in this paper we proposed a customized parallel computing platform called cNeural Different from many previous studies cNeural is designed and built on perspective of the whole architecture from the distributed storage system at the bottom level to the parallel computing framework and algorithm on the top level Experimental results show that cNeural is able to train neural networks over millions of samples and around 50 times faster than Hadoop with dozens of machines In the future we plan to develop and add more neural network algorithms such as deep belief networks into cNeural in order to make further support training large scale neural networks for various problems Finally with more technical work such as GUI done we would like to make it as a toolbox and open source it A CKNOWLEDGMENT This work is funded in part by China NSF Grants No 61223003 the National High Technology Research and Development Program of China 863 No 2011AA01A202 and the USA Intel Labs University Research Program R EFERENCES  C Bishop Neural networks for pattern recognition  Clarendon press Oxford 1995  J Collins Sailing on an ocean of 0s and 1s  Science  vol 327 no 5972 pp 1455…1456 2010  S Haykin Neural networks and learning machines  Englewood Cliffs NJ Prentice Hall 2009  R Hecht-Nielsen Theory of the backpropagation neural network in Proc Int Joint Conf on Neural Networks,IJCNN IEEE 1989 pp 593…605  Y  Loukas  Arti“cial neural netw orks in liquid chromatography Ef“cient and improved quantitative structure-retention relationship models Journal of Chromatography A  vol 904 pp 119…129 2000  N Serbedzija Simulating arti“cial neural netw orks on parallel architectures Computer  vol 29 no 3 pp 56…63 1996  M Pethick M Liddle P  W erstein and Z Huang P arallelization of a backpropagation neural network on a cluster computer in Proc Int Conf on parallel and distributed computing and systems PDCS  2003  K Ganeshamoorthy and D Ranasinghe On the performance of parallel neural network implementations on distributed memory architectures in Proc Int Symp on Cluster Computing and the Grid CCGRID  IEEE 2008 pp 90…97  S Suresh S Omkar  and V  Mani P arallel implementation of back-propagation algorithm in networks of workstations IEEE Trans Parallel and Distributed Systems  vol 16 no 1 pp 24…34 2005  Z Liu H Li and G Miao Mapreduce-based backpropagation neural network over large scale mobile data in Proc Int Conf on Natural Computation ICNC  vol 4 IEEE 2010 pp 1726…1730  M Glesner and W  P  ochm  uller Neurocomputers an overview of neural networks in VLSI  CRC Press 1994  Y  Bo and W  Xun Research on the performance of grid computing for distributed neural networks International Journal of Computer Science and Netwrok Security  vol 6 no 4 pp 179…187 2006  C Chu S Kim Y  Lin Y  Y u  G  Bradski A Ng and K Olukotun Map-reduce for machine learning on multicore Advances in neural information processing systems  vol 19 pp 281…288 2007  U Seif fert  Arti“cial neural netw orks on massi v ely parallel computer hardware Neurocomputing  vol 57 pp 135…150 2004  D Calv ert and J Guan Distrib uted arti“cial neural netw ork architectures in Proc Int Symp on High Performance Computing Systems and Applications  IEEE 2005 pp 2…10  H Kharbanda and R Campbell F ast neural netw ork training on general purpose computers in Proc Int Conf on High Performance Computing HiPC  IEEE 2011  U Lotri  c and e a Dobnikar A Parallel implementations of feed-forward neural network using mpi and c on  net platform in Proc Int Conf on Adaptive and Natural Computing Algorithms  Coimbra 2005 pp 534…537  Q V  Le R Monga and M e a De vin Building high-le v e l features using large scale unsupervised learning in Proc Int Conf on Machine Learning ICML  ACM 2012 pp 2…16  J Ekanayak e and H e a Li T wister a runtime for iterati v e mapreduce in Proc of the 19th ACM International Symposium on High Performance Distributed Computing  ACM 2010 pp 810…818  Y  Bu B Ho we M Balazinska and M D Ernst Haloop Ef“cient iterative data processing on large clusters Proc of the VLDB Endowment  vol 3 no 1-2 pp 285…296 2010  M Zaharia M Cho wdhury  T  Das A Da v e  J  Ma M McCauley M Franklin S Shenker and I Stoica Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing in Proc USENIX Conf on Networked Systems Design and Implementation  USENIX Association 2012 pp 2…16 384 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



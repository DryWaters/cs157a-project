Mining Fuzzy Rules in A Donor Database for Direct Marketing by A Charitable Organization   Keith C.C. Chan Wai-Ho Au Berry Choi Department of Computing The Hong Kong Polytechnic University Hung Hom, Kowloon, Hong Kong Email  cswhau, cskcchan, c9626403  comp.polyu.edu.hk   Abstract  n Hong Kong, we propose to use a new data mining technique to discover fuzzy rules for direct marketing The discovered fuzzy rules employ linguistic terms, which e 
tations, to e data.  The proposed approach utilizes an objective g associations from g of inty measure and e discovered tion is e response of a donor is affected by his demographics \(e.g., age, education n histories \(e.g 
uency, the average n amount, etc.\.  We applied the proposed tabase in order to mine a set of fuzzy rules.  The experimental results showed that our te prediction of e s and formulated some direct mail strategies for future use  1.  Introduction  In this paper, we describe how to discover interesting eting in a donor database given by a charitable organization in Hong Kong.  The name of the 
tial upon its request.  The domain expert from the organization is interested at finding how the response of a donor is affected by his e, education, occupation, salary etc.\ and his donation histories \(e.g., the average yearly e monthly donation amount, etc.\  In order to reveal association relationships hidden in the data, existing data mining algorithms \(e.g 1-2, 14, 16 a r e t y pi c a l l y de v e l o pe d t o de a l w i t h c r i s p  
values and the association rules discovered may therefore be difficult for human users to understand.  Furthermore these algorithms require human users to supply two thresholds pport and minimum confidence to determine whether an association is interesting or not.  A weakness of such approach lies in the difficulty in sholds should be To allow human users to better understand the ose to use a new data mining technique to discover fuzzy rules in the donor database 
The discovered fuzzy rules employ linguistic terms users to understand because of the affinity with the human knowledge representations to represent the revealed association relationships.  The use of linguistic terms, which are in turn defined by fuzzy sets, also allows the proposed approach to be resilient to noises in the data Furthermore, the proposed approach uses residual analysis 3-7 o d i s t i ngui s h i n t e r e s t i ng a s s o c i a t i o n s f r o m  asure can be considered as an 
objective interestingness measure because it does not require any user-specified thresholds.  In addition to using e interestingness measure, our approach also allows quantitative values to be inferred by the discovered fuzzy rules Applying our approach in the donor database, it is able to mine a set of fuzzy rules concerning with donor\222s response.  Based on the discovered fuzzy rules, the domain expert is able to formulate direct marketing strategies for future use The rest of this paper is organized as follows.  In 
Section 2, we describe the related work.  The donor database is described in Section 3.  The details of the n 5 applying Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


our approach to the donor database.  Finally, in Section 6 we conclude this paper with a summary  2.  Related work  Association rule mining is originally defined in [1  over Boolean attributes in market basket data and has been extended to handle categorical and quantitative attributes [16   I n  its mo s t g e n e r a l f o r m   a n  as s o c i atio n  rule is defined over attributes of a database universal relation T It is an implication of the form X  001  Y where X and Y are conjunctions of conditions.  A condition is either A i  a i where a i  001  dom  A i f A i is categorical or A i  001  l i  u i  002  003 if A i is quantitative.  The association rule X  001  Y holds in T with support defined as the percentage of tuples satisfying X and Y and confidence defined as the percentage of tuples satisfying Y given that they also satisfy X An association rule is interesting if its support and confidence are greater than or equal to the userspecified pport and ce  respectively.  A weakness of such approach is that many ld be If it is set too high, a user may miss some useful rules but if it is set too low, the user may be overwhelmed by many irrelevant ones  To handle quantitative attributes, many data mining algorithms \(e.g., [12 r e qui r e t h e  do m a i n  o f  t h e s e  attributes to be discretized into crisp intervals.  The discretization can be performed as a part of the algorithms e.g., [16 r a s a p r e p r o c e s s i n g s t e p b e fo r e da t a  m i ni n g  e.g   A f t e r t h e do m a i n o f qua nt i t a t i v e a t t r i b ut e s  has been discretized, algorithms for mining Boolean association rules \(e.g., [1-2, 14  c a n b e ap p lie d to  t h e  discretized data.  The discovered association rules can be used later for user examinations and machine inferences e.g., classification [12   Regardless of how the values of quantitative attributes are discretized, the intervals might not be concise and meaningful enough for human users to easily obtain nontrivial knowledge from association rules  Linguistic summaries introduced in [17  express knowledge in linguistic representation, which is natural for human users to comprehend.  In addition to ary discovery process, which utilizes fuzzy is-a hierarchies as domain knowledge, has been described in    T h i s  technique aims at discovering a set of tuples  Unlike association rules, which involve implications t attributes, linguistic summaries and generalized tuples provide summarization on different attributes only.  The idea of implication has not been taken into consideration and hence these techniques are not developed for the task of rule discovery Furthermore, the applicability of fuzzy modeling techniques to data mining has been discussed in [1   Given a relational table X and a context variable A the zzy clustering method aims at revealing structure in X in the context of A Since this method can only manipulate quantitative attributes, the values of categorical attributes are first encoded into numeric values.  It is then applied to the encoded data for t A Although the encoding technique allows this method to deal with categorical attributes, the distances between the encoded numeric values, which do not possess any meaning in the original categorical attributes, are used to induce clusters.  The associations concerned with these attributes discovered by this method may therefore be misleading Furthermore, an information-theoretic fuzzy approach has been proposed in [13 t o d i s c ov e r un r e l i a b l e  data in databases.  This approach first defines some attributes as input or target attributes in a given relational constructs a connectionist network to evaluate the reliability of values of target attributes in every record as a fuzzy measure.  Unreliable values of utes can be removed from the database or corrected to the values predicted by the network.  In addition to evaluating data reliability, the highest connection weights in the network can also be translated les.  Although the informationtheoretic fuzzy approach is able to evaluate the reliability degree of data as a fuzzy measure, it requires the domains of quantitative attributes to be discretized into crisp intervals.  To better handle quantitative data, it can be further extended to use fuzzy variables to represent quantitative attributes  3.  The donor database  The donor database contains the data collected in a in April 2001.  In this campaign, the organization sent mails to single-gift during the between April 1999 and March 2001.  A single-gift donor is defined as a person who does not commit to t has made one-off donation occasionally.  The organization sent direct mails to these  donations and to persuade them to donate regularly.  In the direct mail campaign, the organization sent mails to onded.  In other 11.7 The donor database is stored in a commercial relational database management system and is composed of 5 relations.  These relations and their descriptions are w    Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


Table 1.  Summary of the relations in the donor database Relation Description DonorMaster Demographics of donors, e.g., gender age, occupation, etc DonationHistory Donation histories of donors, e.g., date of donation, amount of donation, etc PromotionHistory Direct mails that the donors received e.g., direct mail campaign, date, etc SourcesInformation Details of direct mail materials, e.g., type of materials, distribution date, etc EventHistory Activities that donors participated in e.g., event, attendance, etc  aims at finding how the response of a donor is affected by his demographics, the direct mail materials he received, the activities he attended, etc. so as to formulate direct marketing strategies for future use.  Using the data transformation technique proposed in  t h e do n o r database is transformed into a new relation, which ples.  Of these tuples, 7,634 \(i.e 11.7%\re respondents and the remaining 57,518 \(i.e 88.3%\ are non-respondents.  We refer to this relation as the donor relation in the rest of this paper.  Each tuple in the donor relation is characterized by 93 attributes, of which 49 attributes are categorical and the remaining 44 attributes are quantitative.  These attributes can be ories listed in the following  004\005 hic data of donors 004\005 n behaviors of donors 004\005 Reponses of donors to the pervious direct mail aigns 004\005 Themes of direct mails that donors responded to 004\005 Promotion materials that donors responded to; and 004\005 Events that donors participated in  can apply the proposed fuzzy data mining approach to the donor relation and present the discovered fuzzy rules to the domain expert for formulating direct mail strategies  4.  A fuzzy approach for data mining  Our approach is capable of mining fuzzy rules in large databases without any need for user-specified thresholds or mapping of quantitative into binary attributes.  A fuzzy rule describes an interesting relationship between two or more linguistic terms.  The s is presented in Section 4.1 The details of this approach are then given in Section 4.2 In Section 4.3, we describe how interesting fuzzy rules can be identified.  A confidence measure, called weight of evidence 3-7  i s t h e n d e fi n e d i n S e c t i o n 4  4 t o pr ovi d e a  means for representing the uncertainty associated with the ict les  4.1.  Linguistic terms  Given a set of records D each of which consists of a set of attributes J  I 1 205 I n where I v  v 1, \205 n can be quantitative or categorical.  For any record d  001  D  d  I v  denotes the value i v in d for attribute I v For any quantitative attribute I v  001  J let dom  I v  l v  u v  002  003  denote the domain of the attribute.  Based on the fuzzy set theory, a set of linguistic terms can be defined over the domain of each quantitative attribute.  Let us therefore denote the linguistic terms associated with some quantitative attribute I v  001  J as L vr  r 1, \205 s v so that a onding fuzzy set L vr can be defined for each L vr  The membership function of the fuzzy set is denoted as vr L 006 and is defined as   1   0     007 vL I dom vr 006   The fuzzy sets L vr  r 1, \205 s v d as   001 001 002 001 001 003 004 b 001 002 continuous  is  if  discrete  is  if    v I dom v vL v I dom v vL vr I i i I i i L v vr v vr 006 006   for all i v  001  dom  I v The degree of membership of some value i v  001  dom  I v  L vr is given by vr L 006  Note that I v  001  J gorical and crisp.  In t    1 v vm vv iiI dom b denote the domain of I v In order to handle categorical and quantitative attributes in a uniform manner, we can also define a set of s L vr  r 1, \205 m v al attribute I v  001  J where L vr t L vr such that  vr vr i L 1 b   Using the above technique, we can represent the original attribute J using a set of linguistic terms L  L vr  v 1, \205 n  r 1, \205 s v where s v  m v for categorical attributes.  Since each linguistic term is represented by a fuzzy set, we have a set of fuzzy sets L  L vr  v 1, \205 n  r 1, \205 s v Given a record Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


d  001  D and a linguistic term L vr  001  L which is, in turn t L vr  001  L the degree of membership of the values in d with respect to L vr is given by   vL Id vr 006  d is characterized by the  L vr to the degree   vL Id vr 006 If 1   b vL Id vr 006  d  is completely characterized by the term L vr If 0   b vL Id vr 006  d is not characterized by the term L vr at all.  If 1  0 t\t vL Id vr 006  d is partially characterized by the term L vr  Realistically d  than one linguistic term.  Let n be a subset of integers such that n  v 1 205 v m where v 1 205 v m  001 1, \205 n  v 1  013 205 013  v m and n  h  f 1.  We further suppose that J n  I v  v  001  n Given any J n it is associated with a set of linguistic terms L n r  r 1, \205 s n where r 001 b n n v v ss  Each L n r is defined by a set of linguistic terms LLL 001 mm rvrv    11 The degree  d r n 016 L to which d is characterized by the term L n r is defined as        min  1 11 m m r m vrvr vLvL IdIdd 006 006 016 n b L   D ted by a set of fuzzy data F  which is characterized by a set of linguistic attributes L  L 1 205 L n For any linguistic attribute L v  001  L the value of L v in a record t  001  F is a set of ordered pairs such that         11 vv vsvs vvv t 006 006 LLL b   where L vk and 006 vk  k  001 1, \205 s v are a linguistic term and its degree of membership, respectively For any record t  001  F let  to k pq n LL be the degree to which t is characterized by the linguistic terms L pq and L n k  p  017  n   to k pq n LL is defined as    min  k pq k pq LL to n n 006 006 b LL 1  We further suppose that k pq deg n LL is the sum of degrees to which records in F d by the linguistic terms L pq and L n k  k pq deg n LL is given by   001 001 b F LLLL t to deg k pq k pq  n n 2  Based on the linguistic terms, we can apply our approach to mine fuzzy rules in fuzzy data and present them to human users in a way that is much easier to understand.  Due to the use of fuzzy technique blurring the boundaries of adjacent intervals of numeric qualities our approach is resilient to noise such as inaccuracies in physical measurements of real-life entities  algorithm  It is important to note that a fuzzy rule can be of t orders.  A first-order fuzzy rule can be defined to be a rule involving one linguistic term in its antecedent; a second-order rule can be defined to have two; and a thirds etc.  Our approach is given in Figure 1 below  1 R 1 first-order fuzzy rules 2 for  m 2 R m 226 1  013  020  m  do  3 begin  4 C each condition in the antecedent of r  r  001  R m 226 1  5 forall  n composed of m elements in C  do  6 begin  7 forall  t  001  F  do  8 forall  L pq  006 pq  001  t  L p   L n k  006 n k  001  t  L n   p  017  n  do  9  min k pq k pq deg n 006 006 n b\021 LL  10  forall  L pq  006 pq  001  t  L p   L n k  006 n k  001  t  L n   p  017  n  do  11   if  interesting  L pq  L n k  then  12 R m  R m  022  legen  L pq  L n k  13 end  14 end  15 001 m m R b R  Figure 1.  The fuzzy data mining algorithm  4.3.  Discovering interesting rules in fuzzy data  In order to decide whether a relationship between a linguistic term L n k  L pq is interesting, we determine whether    k pq k k pq n n n L LL LL by  zed characteri  records which to degrees  of  sum  and  by  zed characteri  records which to degrees  of  sum  Pr b 3  is significantly different from   M pq pq L L by  zed characteri  records which to grees  of  sum  Pr b 4  where 001\001 b\b b p i pu s u s i deg M 11 n n LL If this is the case, we consider the relationship between L n k and L pq interesting Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


tively  residual   defined as    k pq k pq k pq z d n n n 023 LL LL LL b 5  where k pq z n LL is the standardized residual 3 n d i s  given by   k pq k pq k pq k pq e e eg d z n n n n LL LLLL LL 024 b 6  where k pq e n LL is the sum of degrees to which records are d by L n k and L pq It is defined as   M degdeg e p k pu i pq k pq s u s i 001\001 b\b b 11 n n n n LLLL LL 7  and k pq n 023 LL is the maximum likelihood estimate 3 o f  the variance of k pq z n LL and is given by   001 001 001 001 001 001 002 003 004 004 004 004 004 004 005 006 024 001 001 001 001 001 001 002 003 004 004 004 004 004 004 005 006 024\b 001\001 b\b M deg M deg p k pu i pq k pq s u s i 11 1 1 n n n n 023 LLLL LL 8  If 96 1 025 k pq d n LL the 95 percentiles of the normal nclude that the discrepancy between Pr L pq  L n k nd Pr L pq is significantly different and hence the relationship between L n k and L pq is interesting.  Specifically, the presence of L n k implies the presence of L pq In other words, it is more likely for a record having both L n k and L pq   4.4.  Uncertainty representation  Given that a linguistic term L n k is associated with another linguistic term L pq we can form the following fuzzy rule     k pq w pq k n n LL LL 001   where k pq w n LL is the ce measure that is defined as follows Since the relationship between L n k and L pq is interesting, there is some evidence for a record to be d by L pq given it has L n k The weight of evidence measure is defined in terms of an information retic measure known as mutual information Mutual information measures the change of uncertainty about the presence of L pq in a record given that it has L n k is and, in rn, defined as    Pr  Pr log  pq k pq k pq I L LL LL n n b 9  Based on mutual information, the weight of evidence measure is defined in [3-7 as     Pr  Pr log  001 001 qi pi k pq k qi k pi k pq IIw k pq 013 013 b 024\b LL LL LLLL LL n n n n n 10  k pq w n LL can be interpreted intuitively as a measure of the difference in the gain in information when a record with L n k aracterized by L pq and when characterized by L pi  i  013  q The weight of evidence measure can be used to weigh the significance or importance of fuzzy rules Given that L n k is defined by a set of linguistic terms LLL 001 mm kvkv    11 we have a high-order fuzzy rule as follows        11 k pq mm w kvkv n LL pq LLL 001   where v 1  205  v m  001  n   4.5.  Predicting unknown values using fuzzy rules  Given a record d  001  dom  I 1  026  205  026  dom  I p  026  205  026  dom  I n let d be characterized by n attribute values 027 1  205  027 p  205  027 n where 027 p is the value to be predicted Let L p  p 1 205  s p be the linguistic terms corresponding to the class attribute I p We further let l p be a linguistic term with domain    1 p ps pp l dom LL b The value of 027 p is given by the value of l p To predict the correct value of l p our approach searches the fuzzy rules with L pq  001  dom  l p nts.  For any combination of attribute values 027 n  p  017  n of d it is characterized by a Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


linguistic term L n k to a degree of compatibility  d k n 016 L  for each k  001 1 205  s n Given those rules implying the assignment of L pq     k pq w pq k n n LL LL 001 for all k  001  030  002 1 205  s n the evidence for such assignment is given by   001 001 031\b 030 027 n n n 016 k dww kk pqpq  LLLL 11  at, of the n  226 1 attribute values excluding 027 p only some combinations of them 027 1  205  027  j   205  027  032   with 027  j   027 i  i  001 1 205  n  226  p are found to match one or more rules, then the overall weight of evidence for the value of l p to be assigned to L pq is given by   001 b b 032 027 1   j q j pq ww L 12  As a result, the value of 027 p is given by           11 pp s ps q pq p www LLL When a crisp value is to be assigned to 027 p the following methods are depending on I p is categorical or quantitative In case that I p is categorical l p is assigned to L pc if  w c  w g  g 1 205  p s 033 and g  013  c 13  where p s 033  034  s p plied by the rules 027 p is therefore assigned to i pc  001  dom  I p  If I p is quantitative, a new method is used to assign an  027 p Given the linguistic terms p ps p LL    1 and their overall weight of evidence p s ww    1 let  pL i pu 006 033 degree of membership of i p  001  dom  I p o the fuzzy set L pu  u  001 1 205  s p   pL i pu 006 033 is given by    pLupL iwi pupu 006 006 031\b 033 14  where i p  001  dom  I p nd u 1 205  s p The defuzzified value  1 1 001 p s u pu LF b 024 which provide an appropriate value for 027 p is then defined as    001 001 022\022 022\022 b 024 033 031 033 b     1 1    1 1 p p ps p p p ps p p I dom ppLL I dom pppLL s u pu di i di ii LF 006 006 001 15  where  max  iii YXYX 006 006 006 033\033 b 033 022 for any fuzzy sets X  and Y For quantitative predictions, we use the percentage error as a performance measure.  Given a set of test records D let n be the number of records in D  For any record r 001  D let t r be the target value of the class attribute in r and o r be the value predicted by our error error is defined as   001 001 024 b Dr r rr o ot N error 1 16  5.  Experimental Results  propriate linguistic s for the quantitative attributes in the donor relation For example, 5 linguistic terms are defined for attribute AVGEVER which represents the average amount of monthly donation.  These linguistic terms are shown in Figure 2  0 1 0 200 400 600 800 1000 AGVEVER Deg r e e of  M e m ber s h i p Very Low L ow M edium H igh Very High  Figure 2.  Linguistic terms for attribute AVGEVER  ample, 5 linguistic terms are defined for attribute FREQEVER which represents the average number of donations in a year.  These linguistic terms are shown in Figure 3 We randomly selected 30% \(i.e., 19,546 in total\ of the tuples in the donor relation for testing by deleting from them the values of attribute RESPONSE which represents whether a donor responded in the direct mail campaign.  Our approach was then used to mine rules from the rest of the donor relation \(i.e., 70% or 45,606 tuples\.  The discovered rules were then used to predict the missing RESPONSE values in the test tuples.  Our 31,865 rules from the training tuples and the classification accuracy on the test tuples is lt task, the domain expert Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


considers the accuracy achieved by the proposed approach is good   0 1 0246810 FREQEVER Degr ee o f  M e m b e r s h i p Very Low L ow M edium H igh Very High  Figure 3.  Linguistic terms for attribute FREQEVER  Furthermore, we ranked and presented the discovered rules to the domain expert and she found that some of them are very useful in a way that she is able to formulate s A rule, which the domain expert found to be useful, is given in the following  Rule 1 ENROLL  Yes  001  RESPONSE  Yes   w 4.45 s 1.28 c 74  where w  s and c denote weight of evidence, support, and confidence, respectively.  This rule states that if a donor enrolled on any donor activities or gatherings in the past he will probably respond to the direct mail he received Instead of sending direct mails to all the donors, the ld send mails to those who enrolled any donor activities or gatherings in the past Another rule, which is found to be very useful and related to Rule 1, is  Rule 2 ENROLL  Yes  035  ATTENDED  No   001  RESPONSE  Yes   w 7.67 s 1.23 c 96  This rule states that if a donor enrolled on any donor activities or gatherings but he did not attend or his enrollment was not a ccepted, he will probably respond to 1 222 s weight of evidence is greater than Rule 2 222 s by 7.67 226 4.45 036 4.45 = 72.36% but Rule 1 222 s support is less than Rule 2 222 s by 0.05% only.  Taking this fact into consideration, the domain expert further suggests that the the donors who enrolled any donor activities or gatherings but they did not attend or their enrollments were not accepted.  The tremely useful because of the organization 222 s limited resources Let us consider the following rules the domain expert finds useful  Rule 3 FREQEVER  Medium  001  RESPONSE  Yes   w 1.62 s 1.39 c 28 Rule 4 FREQEVER  High  001  RESPONSE  Yes   w 1.84 s 0.48 c 32 Rule 5 FREQEVER  Very High  001  RESPONSE  Yes   w 3.12 s 0.09 c 53  These rules state that a donor who donated with very high frequency in the past will probably respond increases with the donation frequency.  They confirm the rule of thumb that one who donated frequently in the past will be more likely to donate in the future  6.  Conclusions  n reveal how the response of a donor is affected by his demographics \(e.g., sex, age histories e.g., average yearly donation frequency, average monthly donation amount, etc.\.  In order to accomplish the task we proposed to use a new fuzzy data mining algorithm to discover a set of fuzzy rules from the donor database These fuzzy rules employ linguistic terms, which are natural for human users to understand because of the affinity with the human knowledge representations, to represent the interesting association relationships hidden in the data.  To distinguish interesting associations from approach uses residual analysis, which can be considered as an objective interestingness measure because it does not require any user-specified thresholds.  Our approach also allows the ranking of discovered rules according to an uncertainty measure and allows quantitative values to be inferred by les the donor database and discovered a set of fuzzy rules.  Our approach achieved a classification accuracy of 63.57 and the domain expert from the organization considered nd is difficult Furthermore, we ranked and presented the discovered rules to the domain expert.  The domain expert found that Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


the rules are very useful in a way that she can formulate direct mail strategies for future use based on these rules  Acknowledgments  t A-P209 and G-V918  References  1  R  A g ra w a l  T  I m ie lin s k i a n d A  S w a m i   223 Mining Association Rules between Sets of Items in Large Databases 224 in Proc. of the ACM SIGMOD Int 222  ta D.C., 1993, pp. 207-216 2 R  A g r a wa l a n d R  S r ik a n t  223 Fast Algorithms for Mining Association Rules 224 in Proc. of the 20th Int 222 nf. on Very Large Data Bases ile, 1994, pp. 487-499 3 W  H  A u a n d K  C  C  C h a n  223 An Effective Algorithm for Discovering Fuzzy Rules in Relational Databases 224 in Proc of the 7th IEEE Int 222 l Conf. on Fuzzy Systems Anchorage Alaska, 1998, pp. 1314-1319 4 W  H  A u a n d K  C  C  C h a n  223 FARM: A Data Mining System for Discovering Fuzzy Association Rules 224 in Proc of the 8th IEEE Int 222 l Conf. on Fuzzy Systems Seoul, Korea 1999, pp. 1217-1222 5 W  H  A u a n d K  C  C   C h a n  223 Classification with Degree of Membership: A Fuzzy Approach 224 in e 1st IEEE Int 222 Mining San Jose, CA, 2001, pp. 35-42 6 K  C  C  C h a n  a n d W  H A u  223 ciation Rules 224 in e 6th Int 222 formation and Knowledge Management Las Vegas, Nevada, 1997, pp 209-215 7 K  C  C  C h a n  a n d W  H A u  223 ciation onal and Transactional Data 224 in A. Kandel, M. Last, and H. Bunke Eds Data Mining and Computational Intelligence New York, NY: Physica-Verlag, 2001, pp. 95-114 8  J  H a n a nd M  K a m b e r   Data Mining: Concepts and Techniques San Francisco, CA: Morgan Kaufmann, 2001 9  D  H a nd  H  M a nn i l a a n d P Sm y t h  Principles of Data Mining Cambridge, MA: The MIT Press, 2001   K  H i r o t a a nd W  Ped r y c z   223 Fuzzy Computing for Data Mining 224  Proc. of the IEEE vol. 87, no. 9, pp. 1575-1600 1999 11  D H. L e e a n d  M  H. Ki m   223 Database Summarization Using s 224  IEEE Trans. on Systems, Man etics 226 Part B: Cybernetics  671-680, 1997   B  L i u  W  H s u a n d Y   M a n  223 Integrating Classification and Association Rule Mining 224 in e 4th Int 222 l Conf. on Knowledge Discovery and Data Mining New NY, 1998   O  M a i m o n   A   K a nde l  and M   L a s t   223 InformationTheoretic Fuzzy Approach to Data Reliability and Data Mining 224  Fuzzy Sets and Systems 183-194 2001 14  H   M a n n i l a  H  T o i von e n   a n d A  I  V e r k a m o  223 Efficient Algorithms for Discovering Association Rules 224 in Proc. of the AAAI Workshop on Knowledge Discovery in Databases  Seattle, Washington 1994, pp. 181-192 15 J  R   Q u in la n   C4.5: Programs for Machine Learning San Mateo, CA: Morgan Kaufmann, 1993   R  S r i k ant  and R  A g r a w a l   223 Mining Quantitative Association Rules in Large Relational Tables 224 in Proc. of the ACM SIGMOD Int 222 nagement of Data  Montreal, Canada, 1996, pp. 1-12 17 R R Ya g e r   223 On Linguistic Summaries of Data 224 in G Piatetsky-Shapiro and W.J. Frawley \(Eds Knowledge Discovery in Databases Menlo Park, CA: AAAI/MIT Press, 1991, pp. 347-363  L   Z a deh   223 Fuzzy Sets 224  Inform. Control vol. 8, pp. 338353, 1965  Proceedings of the First IEEE International Conference on Cognitive Informatics \(ICCI\22202 0-7695-1724-2/02 $17.00 \251 2002 IEEE 


ranges around 10  15 Once the increment is larger than the original size the overhead decreases very rapidly from 10 to 5 This is a very encouraging result because it shows that FUP not only can benefit update with small increment it actually works very well in the case of large increment 4.6 Performance in scaled-up databases Our last experiment is done in a scaled-up database The database is T10.I4.D1000.d10 which contains 1 million transactions The performance ratio between DHP and FUP in this scaled-up database ranges from 3 to 16 The result shows that the gain from FUP will in fact increase if the database becomes larger This shows that FUP is very adaptive to size increase and can be applied to very large databases 5 Discussion and Conclusions We studied an efficient fast incremental updating technique for maintenance of the association rules dis covered by database mining The developed method strives to determine the promising itemsets and hope less itemsets in the incremental portion and reduce the size of the candidate set to be searched against the original large database The method is implemented and its performance is studied and compared with the best algorithms for mining association rules studied so far The study shows that the proposed incremen tal updating technique has superior performance on database updates in comparison with direct mining from an updated database The incremental updating technique is applicable to the databases which allow frequent or occasional updates when new transaction data are added to a transaction database We have also investigated the cases of deletion and modification of a transaction database Recently there have been some interesting stud ies at finding multiple-level or generalized association rules in large transaction databases 6 111 The exten sion of our incremental updating technique for mainte nance of multiple-level or generalized association rules in transaction databases is an interesting topic for fu ture research References R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases In Proc 1993 ACM-SIGMOD Int Conf Management of Data 207-216 May 1993 R Agrawal and R Srikant Fast algorithms for mining association rules. In Proc 1994 Int Conf Very Large Data Bases pages 487-499 Santiago Chile September 1994 D.W Cheung A W.-C Fu and J Han Knowledge discovery in databases A rule-based attribute-oriented approach In Proc 1994 Int 2221 Symp on Methodologies for Intelligent Systems pages 164-173 Charlotte North Carolina Octo ber 1994 U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy Advances in Knowledge Dis covery and Data Mining AAAI/MIT Press 1995 J Han Y Cai and N Cercone Data driven discovery of quantitative rules in relational databases IEEE Trans. Knowledge and Data En gineering 5:29-40 1993 J Han and Y Fu Discovery of multiple-level association rules from large databases In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 M Klemettinen H Mannila P Ronkainen H. Toivonen and A I Verkamo Finding inter esting rules from large sets of discovered associa tion rules In Proc 3rd Int\222I Conf on Informa tion and Knowledge Management pages 401-408 Gaithersburg Maryland Nov 1994 R Ng and J Han Efficient and effective cluster ing method for spatial data mining In Proc 1994 Int Conf Very Large Data Bases pages 144-155 Santiago Chile September 1994 J.S Park M.S Chen and P.S Yu An effec tive hash-based algorithm for mining association rules In Proc 1995 ACM-SIGMOD Int Conf Management of Daia San Jose CA May 1995 G Piatetsky-Shapiro and W J Frawley Knowl edge Discovery in Ratabases AAAI/MIT Press 1991 R Srikant and R Agrawal Mining generalized association rules In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 114 


The disadvantage of this rule-oriented control strategy is that it imposes a restriction on the mixing of forward and backward chaining rules such that a forward chaining rule cannot read any data written by backward chaining rules STO87 To describe this problem let the following be a series of rules Ra to Rd and the resuls REa to REd derived by these rules Ra Rb Rc Rd DB  R  REb  R  REd Also let Ra and Rb be defined as backward chaining rules and Rc and Rd as forward chaining rules If the original database DB is updated rules Rc and Rd though they are forward chaining rules will not be triggered to update the result REd until someone requests the data of REb Thus REd may be iriconsistent with the base data To overcome this problem we use a result-oriented control strategy in which we specify for each result derived subdatabase whether it is to be pre-evaluated or post evaluated The same rule may follow the forward or backward chaining strategy depending on whether the derived subdatabae is to be pre or post-evaluated To illustrate by the example above assume that REd is defined as pre-evaluated and REb is defined as post evaluated Whenever the database DB is updated the rules Ra Rb Rc and Rd will be triggered in the forward chaining fashion to keep REM which is explicitly stored up-to-date REb on the other hand will be evaluated whenever a retrieval operation is issued against it In this case the rules Ra and Rb that derive REb are applied in the backward chaining fashion Thus Ra and Rb follow one control strategy when deriving RFxl and the other control straregy when deriving REb This technique offers more flexibility and alleviates the restriction in POSTGRES described above 7 Conclusion In this paper we have introduced the induced generalization association construct and presented a deductive rule-based language for object-oriented databases The world of subdatabases is closed under this language which facilitates defining inference chains in which each rule derives a new subdatabase based on the subdatabases derived by previous rules in the chain The transitive closure operation can be specified in our language in the form of looping rather than in a recursive form A result-oriented control strategy to be used as the underlying implementation technique has also been introduced in this paper ACKNOWLEDGEMENTS Research on the rule-based language was supported by the U.S West Advanced Technologies grant number UPN 88071315 Work on the Object-Oriented Query Language OQL was supported by the Navy Manufacturing Technology Program through the National Institute of Standards and Technology formerly the National Bureau of Standards grant number 60NANB4wO17 and by the National Science Foundation grant number DMC-8814989 The development efforts are supported by the Florida High Technology and Industry Council grant number UPN 85100316 BIBLIOGRAPHY ALA89a A.M Alashqur S.Y.W Su and H Lar OQL A Quy Language for Manipulating Object-onented Datah Accepted for Publication the 15th VLDB Int Con 1989 ALA89b A.M Alashqur A Query Model and Query and Knowledge Definition Langwi~es for Object-oriented Databases a Ph.D BAN87 BAT85 cER86 CHA84 COD79 DEL88 DIT86 HS87 FOR88 GAL84 HAM81 m7 JAR84 LAM89 MAI88 RAS88 STO87 SU89 TY88 U85 VAS84 Thesis Univedty if Florida 1989 Jay Banerjee et al Data Model Issues for Object-Oriented Aplications ACM Trans on Ofice Information Systems January 1987 D Batory and W Kim Modeling Concepts for VLSI CAD objects ACM TODS September 1985, pages 322-346 Stefan0 Ceri George Gottlob and Gio Wiederhold Interfacing Relational Databases and Prolog Efficiently Roc of the 1st Intl Con on Expert Database Systems 1986 C L Chang and A Walker PROSQL a PROLOG Programming Interface with SQLDS F'mxdngs of the 1st Intl Workshop on Expert Database Systems 1984 E Codd Extend~ng the Database Relational Model to Capture More Meaning ACM TODS Vol 4 No 4 1979 Lois ML Delcambre and James N Etheredge A self Controlling Interpreter for the relational Production Language Roceedings of ACM SIGMOD Conference on Management of Data 1988, pages 396403 KR Dimich Object-oriented Database Systems the Notion and Issues Roc of rhe Intl Workshop on Object-Oriented Database Systems califomia September 1986 D.H Fishman et al Iris An Object-Oriented Database Management System ACM Transaction on Oftixe Informarion Systems January 1987 Pages 4869 S Ford et al Zeitgeist Database support for object-oriented rogramming in the F  gs of the Second International Workshq on Object-oriented Database Systems 1988 Heme Gallaire Jack Mier and Jean-Marie Nicolas Logic and Databases A Deductive Approach ACM Computing Surveys June 1984 Pages 153-185 M Hammer and D McLeod Database Description with SDM A Semantic Associon Model ACM TODS Sepember 1981 R Hull and R King Semantic Database Modeling Survey Applications and Research Issues ACM Computing Surveys September 1987 Mauhias Jark Jim Clifford and Yannis Vassiliou An Optimizing hlog Front-End to a Relational Query System Roc of ACM SIGMOD Con on Management of Data 1984 H.M Lam S Su and A.M Alashqur Integrating the Concepts and Techniqws of Semantic Data Modeling and the Objectdented wradigm Roc of the 13th Intl Computex Software and ApptiCationS Conference COMSAC 89 1989 Christcphe de Maindreville and Eric Simon A Production Rule Based Approach to Deductive Databases Roc of the 4th Intl Con on Data Engineering California 1988 L Raschid and S.Y.W Su A Transaction-oriented Mechanism to Control Precessing in a Knowledge Base Management System Pmc of the Intl Con on Expert Database Systems 1988 Michael Stonebraker Eric Hanson and Chin-Heng Hong The Design of the POSTGRES Rules System Roc of the 3rd Intl Con on Data Engineering California 1987 S.Y.W Su V KrishnamurIhy and H Lam An Object oriented Semantic Association Model OsAM appearing in A.I in Indus&l Engineering and Manufacturing Theoretid Issues and Applications S Kumara et al eds American Institute of Industrial Engineering 1989 Frederick Ty G-OQL Graphics Interface to the Object Oriented Query Language OQL Master thesis University of Florida 1988 Jeffrey ullman Implementation of Logical Query Languages for Databases ACM TODS September 1985 Y Vassiliou J Clifford and M Jark Access to Specific Declarative Knowledge by Expert Systems The Impact of hg"'ning Decision Suppat Systems 1 1 1984 67 


 s_suppkey s_nationkey ps_partkey ps_suppkey ps_supplycost p_partkey p_name   l_partkey l_discount l_quantity l_orderkey l_suppkey l_extendedprice o_orderkey o_orderdate n_nationkey n_name p_partkey p_name   246\262 1 2 3 4 5 7 6 8 9 10,#11,#12,#13 14 15 16 17 18 1 2 Figure 11 Execution plan of TPC-D query 9 for transposed files 2 0 20 40 60 80 100 0 50 100 150 200 Time [s CPUusage NetSend NetRecv Disk 10 8 6 4 0 Throughput [MB/s CPU usage 8 9 10 13 Figure 12 Execution trace of TPC-D query 9 with transposed files 11 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


of I/O But the resulting speedup compared with the previous plans exceeds 2 which is quite satisfactory Table 3 shows the results of above right-deep rd left-deep ld and transposed file tp methods along with the reported results of other commercial systems for 100GB TPC-D query 9 Because our system lacks the software and maintenance price metrics the overall system price can\220t be determined accurately Hardware components themselves cost less than 0.5M We can observe that our system achieves fairly good performance Above all the execution time with the transposed files is twelve times as short as the most powerful commercial platform These results strongly support the effectiveness of the commodity PC based massively parallel relational database servers  System Exec Time Price Teradata on NCR 5100M 160 000 133MHz Pentium 20GB Main Memory 400 Disk Drives 953.3 17M Oracle 7 n DEC AlphaServer 8400 12 000 437MHz DECchip 21164 24GB Main Memory 84 Disk Drives 1884.9 1.3M Oracle 7 n SUN UE6000 24 000 167MHz UltraSPARC 5.3GB Main Memory 300 Disk Drives 2639.3 2.1M IBM DB2 PE on RS/6000 SP 306 96 000 112MHz PowerPC 604 24GB Main Memory 96 Disk Drives 2899.4 3.7M Oracle 7 n HP9000 EPS30 12 000 120MHz PA7150 3.75GB Main Memory 320 Disk Drives 7154.8 2.2M Our Pilot System 100 000 200MHz Pentium Pros 6.4GB Main Memory 100 Disk Drives rd 193.7 ld 177.2 tp 77.1 see text Table 3 Execution time of 100 GB TPC-D Q9 on several systems 12 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


4 Data mining 4.1 Association rule mining Data mining which is a recent hot research topic in the database field is a method of discovering useful information such as rules and previously unknown patterns existing behind data items It enables more effective utilization of transaction log data which have been just archived and abandoned Among the major applications of data mining is association rule mining so called 217\217basket analysis.\220\220 Each of the transaction data typically consists of a set of items bought in a transaction By analyzing them one can derive some association rule such as 217\21790 of the customers who buy both A and B also buy C.\220\220 In order to improve the quality of obtained rules a very large amount of transaction data have to be examined requiring quite a long time to complete First we introduce some basic concepts of association rule Let 000 000 001 000 1 001\000 2 001\002\002\002\001\000 000 002 be a set of items and 003 000 001 003 1 001\003 2 001\002\002\002\001\003 001 002 be a set of transactions where each transaction 003 002 is a set of items such that 003 002 004\000  n itemset 004 has support 005 in the transaction set 003 if 005  f transactions in 003 contain 004  here we denote 005 000 005\006\007\007\b\t 003 001 004 002 An association rule is an implication of the form 004 005 n  where 004\001 n 004 000  and 004 006 n 000 007  Each rule has two measures of value support and confidence  The support of the rule 004 005 n is 005\006\007\007\b\t 003 001 004 b n 002  The confidence 013 of the rule 004 005 n in the transaction set 003 means 013 of transactions in 003 that contain 004 also contain n  which can be written as 005\006\007\007\b\t 003 001 004 b n 002 f\005\006\007\007\b\t 003 001 004 002  For example let r 1 000 001 1 001 3 001 4 002  r 2 000 001 1 001 2 001 3 001 5 002  r 3 000 001 2 001 4 002  r 4 000 001 1 001 2 002  r 5 000 001 1 001 3 001 5 002 be the transaction database Let minimum  support and minimum confidence be 60 and 70 respectively First all itemsets that have support above the minimum support called large itemsets  are generated In this case the large itemsets are 001 1 002 001 001 2 002 001 001 3 002 001 001 1 001 3 002  Then for each large itemset 004  n association rule 004 t n 005 n 001 n 004 004 002 is derived if 005\006\007\007\b\t 003 001 004 002 f\005\006\007\007\b\t 003 001 004 t n 002 n minimum confidence  The results are 1 005 3 001 005\006\007\007\b\t 003 000 60 001 b\016\017 000\020\021\016\013\021 000 75 002 and 3 005 1 001 005\006\007\007\b\t 003 000 60 001 013\b\016\017 000\020\021\016\013\021 000 100 002  The most well known algorithm for association rule mining is the Apriori algorithm[1 We have studied several parallel algorithms for mining association based on Apriori One of these algorithms called HPA Hash Partitioned Apriori is discussed here Apriori first generates candidate itemsets and then scans the transaction database to determine whether each of the candidates satisfies the user specified minimum support and minimum confidence Using these results the next candidate itemsets are generated This continues until no itemset satisfies the minimum support and confidence The most naive parallelization of Apriori would copy the candidates over all the processing node and make each processing node scan the transaction database in parallel Although this works fine when the number of candidates is small enough to fit in the local memory of a single processing node memory space utilization efficiency of this method is very poor For large scale data mining the storage required for the candidates exceeds the available memory space of a processing node This causes memory overflow which results in significant performance degradation due to an excessive amount of extra I/Os HPA partitions the candidate itemsets among the processing nodes using a hash function as in the parallel hash join which eliminates broadcasting of all the transaction data and can reduce the comparison workload significantly Hence HPA works much better than the naive parallelization for large scale data mining The 022 th iteration pass 022  f the algorithm is as follows 1 Generate the candidate itemsets Each processing node generates new candidate itemsets from the large itemsets of the last  001 022 t 1 002 th iteration Each of the former itemsets contains 022 items while each of the latter itemsets contains 001 022 t 1 002 items They are called 022 itemsets and 001 022 t 1 002 itemsets respectively The processing node applies the hash function to each of the candidates to determine the destination node ID If the candidate is for the processing node itself it is inserted into the hash table otherwise it is discarded 13 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 


